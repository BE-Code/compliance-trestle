{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Compliance-trestle (also known as trestle ) \u00a4 Trestle is an ensemble of tools that enable the creation, validation, and governance of documentation artifacts for compliance needs. It leverages NIST's OSCAL as a standard data format for interchange between tools and people, and provides an opinionated approach to OSCAL adoption. Trestle is designed to operate as a CICD pipeline running on top of compliance artifacts in git , to provide transparency for the state of compliance across multiple stakeholders in an environment friendly to developers. Trestle passes the generated artifacts on to tools that orchestrate the enforcement, measurement, and reporting of compliance. It also provides tooling to manage OSCAL documents in a more human-friendly manner. By splitting large OSCAL data structures into smaller and easier to edit sub-structures, creation and maintenance of these artifacts can follow normal git workflows including peer review via pull request, versioning, releases/tagging. Trestle provides three separate but related functions in the compliance space: Manage OSCAL documents to allow editing and manipulation while making sure the schemas are enforced Transform documents from other formats to OSCAL Provide support and governance to author compliance content as markdown and drawio. Trestle provides tooling to help orchestrate the compliance process across a number of dimensions: Help manage OSCAL documents in a more human-friendly manner by expanding the large OSCAL data structures into smaller and easier to edit sub-structures while making sure the schemas are enforced. Transform documents from other formats to OSCAL Provide governance for markdown documents and enforce consistency of format and content based on specified templates Tooling manage authoring and governance of markdown and drawio files withn a repository. Support within trestle to streamline management within a managed git environment. An underlying object model that supports developers interacting with OSCAL artefacts. Important Note: \u00a4 The current version of trestle supports NIST OSCAL 1.0.2. There was a breaking change in OSCAL moving from version 1.0.0 to 1.0.2 mainly due to prop becoming props in AssessmentResults. As a result, the current development path of trestle requires OSCAL 1.0.2, but for those who require OSCAL 1.0.0 please use trestle version 0.37.x. That version is stable but will not have any features added, and we encourage users to move to OSCAL 1.0.2 and trestle 1.0.x. OSCAL version 1.0.0 files are still handled on import but any AssessmentResults must conform to the OSCAL 1.0.2 schema, with props instead of prop. And all files created by trestle will be output as OSCAL version 1.0.2. Why Trestle \u00a4 Compliance suffers from being a complex topic that is hard to articulate simply. It involves complete and accurate execution of multiple procedures across many disciplines (e.g. IT, HR, management) with periodic verification and audit of those procedures against controls. While it is possible to manage the description of controls and how an organisation implements them in ad hoc ways with general tools (spreadsheets, documents), this is hard to maintain for multiple accreditations and, in the IT domain at least, creates a barrier between the compliance efforts and the people doing daily work (DevOps staff). Trestle aims to reduce or remove this barrier by bringing the maintenance of control descriptions into the DevOps domain. The goal is to have changes to the system (for example, updates to configuration management) easily related to the controls impacted, and to enable modification of those controls as required in concert with the system changes. Trestle implicitly provides a core opinionated workflow driven by its pipeline to allow standardized interlocks with other compliance tooling platforms. Machine readable compliance format \u00a4 Compliance activities at scale, whether size of estate or number of accreditations, require automation to be successful and repeatable. OSCAL as a standard allows teams to bridge between the \"Governance\" layer and operational tools. By building human managed artifacts into OSCAL, Trestle is not only able to validate the integrity of the artifacts that people generate - it also enables reuse and sharing of artifacts, and furthermore can provide suitable input into tools that automate operational compliance. Supported OSCAL elements and extensions \u00a4 trestle implicitly supports all OSCAL schemas for use within the object model. The development roadmap for trestle includes adding workflow around specific elements / objects that is opinionated. Supported file formats for OSCAL objects. \u00a4 OSCAL supports xml , json and yaml with their metaschema tooling. Trestle natively supports only json and yaml formats at this time. Future roadmap anticipates that support for xml import and upstream references will be enabled. However, it is expected that full support will remain only for json and yaml . Users needing to import XML OSCAL artifacts are recommended to look at NIST's XML to json conversion page here . Python codebase, easy installation via pip \u00a4 Trestle runs on most all python platforms (e.g. Linux, Mac, Windows) and is available on PyPi so it is easily installed via pip. It is under active development and new releases are made available regularly. Development status \u00a4 Compliance trestle is currently stable and is based on NIST OSCAL version 1.0.2, with active development continuing. Contributing to Trestle \u00a4 Our project welcomes external contributions. Please consult contributing to get started. License & Authors \u00a4 If you would like to see the detailed LICENSE click here . Consult contributors for a list of authors and maintainers for the core team. # Copyright (c) 2020 IBM Corp. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # https://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License.","title":"Trestle overview"},{"location":"#compliance-trestle-also-known-as-trestle","text":"Trestle is an ensemble of tools that enable the creation, validation, and governance of documentation artifacts for compliance needs. It leverages NIST's OSCAL as a standard data format for interchange between tools and people, and provides an opinionated approach to OSCAL adoption. Trestle is designed to operate as a CICD pipeline running on top of compliance artifacts in git , to provide transparency for the state of compliance across multiple stakeholders in an environment friendly to developers. Trestle passes the generated artifacts on to tools that orchestrate the enforcement, measurement, and reporting of compliance. It also provides tooling to manage OSCAL documents in a more human-friendly manner. By splitting large OSCAL data structures into smaller and easier to edit sub-structures, creation and maintenance of these artifacts can follow normal git workflows including peer review via pull request, versioning, releases/tagging. Trestle provides three separate but related functions in the compliance space: Manage OSCAL documents to allow editing and manipulation while making sure the schemas are enforced Transform documents from other formats to OSCAL Provide support and governance to author compliance content as markdown and drawio. Trestle provides tooling to help orchestrate the compliance process across a number of dimensions: Help manage OSCAL documents in a more human-friendly manner by expanding the large OSCAL data structures into smaller and easier to edit sub-structures while making sure the schemas are enforced. Transform documents from other formats to OSCAL Provide governance for markdown documents and enforce consistency of format and content based on specified templates Tooling manage authoring and governance of markdown and drawio files withn a repository. Support within trestle to streamline management within a managed git environment. An underlying object model that supports developers interacting with OSCAL artefacts.","title":"Compliance-trestle (also known as trestle)"},{"location":"#important-note","text":"The current version of trestle supports NIST OSCAL 1.0.2. There was a breaking change in OSCAL moving from version 1.0.0 to 1.0.2 mainly due to prop becoming props in AssessmentResults. As a result, the current development path of trestle requires OSCAL 1.0.2, but for those who require OSCAL 1.0.0 please use trestle version 0.37.x. That version is stable but will not have any features added, and we encourage users to move to OSCAL 1.0.2 and trestle 1.0.x. OSCAL version 1.0.0 files are still handled on import but any AssessmentResults must conform to the OSCAL 1.0.2 schema, with props instead of prop. And all files created by trestle will be output as OSCAL version 1.0.2.","title":"Important Note:"},{"location":"#why-trestle","text":"Compliance suffers from being a complex topic that is hard to articulate simply. It involves complete and accurate execution of multiple procedures across many disciplines (e.g. IT, HR, management) with periodic verification and audit of those procedures against controls. While it is possible to manage the description of controls and how an organisation implements them in ad hoc ways with general tools (spreadsheets, documents), this is hard to maintain for multiple accreditations and, in the IT domain at least, creates a barrier between the compliance efforts and the people doing daily work (DevOps staff). Trestle aims to reduce or remove this barrier by bringing the maintenance of control descriptions into the DevOps domain. The goal is to have changes to the system (for example, updates to configuration management) easily related to the controls impacted, and to enable modification of those controls as required in concert with the system changes. Trestle implicitly provides a core opinionated workflow driven by its pipeline to allow standardized interlocks with other compliance tooling platforms.","title":"Why Trestle"},{"location":"#machine-readable-compliance-format","text":"Compliance activities at scale, whether size of estate or number of accreditations, require automation to be successful and repeatable. OSCAL as a standard allows teams to bridge between the \"Governance\" layer and operational tools. By building human managed artifacts into OSCAL, Trestle is not only able to validate the integrity of the artifacts that people generate - it also enables reuse and sharing of artifacts, and furthermore can provide suitable input into tools that automate operational compliance.","title":"Machine readable compliance format"},{"location":"#supported-oscal-elements-and-extensions","text":"trestle implicitly supports all OSCAL schemas for use within the object model. The development roadmap for trestle includes adding workflow around specific elements / objects that is opinionated.","title":"Supported OSCAL elements and extensions"},{"location":"#supported-file-formats-for-oscal-objects","text":"OSCAL supports xml , json and yaml with their metaschema tooling. Trestle natively supports only json and yaml formats at this time. Future roadmap anticipates that support for xml import and upstream references will be enabled. However, it is expected that full support will remain only for json and yaml . Users needing to import XML OSCAL artifacts are recommended to look at NIST's XML to json conversion page here .","title":"Supported file formats for OSCAL objects."},{"location":"#python-codebase-easy-installation-via-pip","text":"Trestle runs on most all python platforms (e.g. Linux, Mac, Windows) and is available on PyPi so it is easily installed via pip. It is under active development and new releases are made available regularly.","title":"Python codebase, easy installation via pip"},{"location":"#development-status","text":"Compliance trestle is currently stable and is based on NIST OSCAL version 1.0.2, with active development continuing.","title":"Development status"},{"location":"#contributing-to-trestle","text":"Our project welcomes external contributions. Please consult contributing to get started.","title":"Contributing to Trestle"},{"location":"#license-authors","text":"If you would like to see the detailed LICENSE click here . Consult contributors for a list of authors and maintainers for the core team. # Copyright (c) 2020 IBM Corp. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # https://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License.","title":"License &amp; Authors"},{"location":"cli/","text":"trestle CLI Overview and OSCAL Usecases \u00a4 The trestle CLI has three primary use cases: Serve as tooling to generate and manipulate OSCAL files directly by an end user. The objective is to reduce the complexity of creating and editing workflows. Example commands are: trestle import , trestle create , trestle split , trestle merge . Act as an automation tool that, by design, can be an integral part of a CI/CD pipeline e.g. trestle validate , trestle tasks . Allow governance of markdown documents so they conform to specific style or structure requirements. To support each of these use cases trestle creates an opinionated directory structure to manage governed documents. Opinionated directory structure \u00a4 Trestle relies on an opinionated directory structure (trestle workspace), similar to git , go , or auditree , to manage the workflow. Most trestle commands are restricted to working within an initialized directory tree. The directory structure setup by trestle has three major elements: A .trestle hidden folder. A dist folder. Folders for each of the top level OSCAL models. The outline of the schema is below: . \u251c\u2500\u2500 .trestle \u251c\u2500\u2500 dist \u2502 \u251c\u2500\u2500 catalogs \u2502 \u251c\u2500\u2500 profiles \u2502 \u251c\u2500\u2500 component-definitions \u2502 \u251c\u2500\u2500 system-security-plans \u2502 \u251c\u2500\u2500 assessment-plans \u2502 \u251c\u2500\u2500 assessment-results \u2502 \u2514\u2500\u2500 plan-of-action-and-milestones \u251c\u2500\u2500 catalogs \u251c\u2500\u2500 profiles \u251c\u2500\u2500 component-definitions \u251c\u2500\u2500 system-security-plans \u251c\u2500\u2500 assessment-plans \u251c\u2500\u2500 assessment-results \u2514\u2500\u2500 plan-of-action-and-milestones .trestle directory is a special directory containing various trestle artefacts to help run various other commands. Examples include configuration files, caches and templates. dist directory will contain the assembled version of the top level models located on the source model directories. The bulk of the folder structure is used to represent each of the top level schemas or top level models such as catalogs and profiles . For each of these directories the following root structure is maintained: \u251c\u2500\u2500 .trestle \u2514\u2500\u2500 TOP_LEVEL_MODEL_PLURAL \u2514\u2500\u2500 NAME_OF_MODEL_INSTANCE \u2514\u2500\u2500 TOP_LEVEL_MODEL_NAME.{json,yaml,yml} which appears, for a catalog a user decides is titled nist-800-53, as: \u251c\u2500\u2500 .trestle \u2514\u2500\u2500 catalogs \u2514\u2500\u2500 nist-800-53 \u2514\u2500\u2500 catalog.json In most of the places in the documentation we use json format for specifying model files, but they are equally applicable to yaml format also. The default format is json , and yaml is supported on best effort basis. Within one model directory the two different formats should not be mixed. Support for subdivided document structures \u00a4 The files constructed by OSCAL can run into tens of thousands of lines of yaml or formatted json. At this size the files become completely unmanageable for users. To combat this, trestle can trestle split a file into many smaller files and later merge those split files together. Directory structures such as the one below can represent OSCAL document structures. Users are strongly encourage to rely on split and merge to code these structures. Users can query the contents of files using trestle describe , and probe the contents more deeply using it in combination with element paths. . \u251c\u2500\u2500 .trestle \u251c\u2500\u2500 dist \u2502 \u2514\u2500\u2500 catalogs \u2502 \u2514\u2500\u2500 nist800-53.json \u2514\u2500\u2500 catalogs \u2514\u2500\u2500 nist800-53 \u251c\u2500\u2500 catalog.json \u2514\u2500\u2500 catalog \u251c\u2500\u2500 metadata.json \u251c\u2500\u2500 metadata \u2502 \u251c\u2500\u2500 revision-history \u2502 \u2502 \u251c\u2500\u2500 00000__revision-history.json \u2502 \u2502 \u251c\u2500\u2500 00001__revision-history.json \u2502 \u2502 \u2514\u2500\u2500 00002__revision-history.json \u2502 \u2514\u2500\u2500 responsible-parties \u2502 \u251c\u2500\u2500 creator__responsible-party.json \u2502 \u2514\u2500\u2500 contact__responsible-party.json \u2514\u2500\u2500 groups \u251c\u2500\u2500 00000__group.json \u251c\u2500\u2500 00000__group \u2502 \u2514\u2500\u2500 controls \u2502 \u251c\u2500\u2500 00000__control.json \u2502 \u2514\u2500\u2500 00001__control.json \u251c\u2500\u2500 00001__group.json \u2514\u2500\u2500 00001__group \u2514\u2500\u2500 controls \u251c\u2500\u2500 00000__control.json \u2514\u2500\u2500 00001__control.json ... Specifying attributes / elements within trestle commands. \u00a4 OSCAL models are rich and contain multiple nested data structures. Given this, a mechanism is required to address elements / attributes within an oscal object. This accessing method is called 'element path' and is similar to jsonPath . Commands provide element path by a -e argument where available, e.g. trestle split -f catalog.json -e 'catalog.metadata.*'. This path is used whenever specifying an attribute or model, rather than exposing trestle's underlying object model name. Users can refer to NIST's json outline to understand object names in trestle. Rules for element path \u00a4 Element path is an expression of the attribute names, in json form , concatenated by a period ( . ). E.g. The metadata in a catalog is referred to as catalog.metadata Element paths are relative to the file. e.g. For metadata.json roles would be referred to as metadata.roles , from the catalog file that would be catalog.metadata.roles Arrays can be handled by a wild card * or a numerical index for a specific index. catalog.groups.* to refer to each group in a catalog catalog.groups.*.controls.* to refer to 'for each control under a top level group' For NIST 800-53 catalog.groups.0.controls.0. On *nix platforms if using the wildcard the element path argument should be wrapped in quotes to prevent problems with the shell interpreting the wild card before trestle can When dealing with an array based object, the array syntax may be skipped when passing a model e.g. a control could be catalog.controls.control or catalog.groups.controls.control This syntax is required as OSCAL, across the schema, has conflicting element definitions. A note for software developers using trestle. \u00a4 Trestle provides utilities for converting from element path to trestle's python object model. The (slightly simplified) model is: Class attributes are converted from dash-case to dash_case (aka snake_case) Class names are converted from dash-case to DashCase (aka CamelCase) trestle init \u00a4 This command will create (initialize) a trestle workspace in the current directory with the necessary directory structure and trestle artefacts. For example, if we run trestle init in a directory, it will create the directory structure below for different artefacts: . \u251c\u2500\u2500 .trestle \u251c\u2500\u2500 dist \u2502 \u251c\u2500\u2500 catalogs \u2502 \u251c\u2500\u2500 profiles \u2502 \u251c\u2500\u2500 component-definitions \u2502 \u251c\u2500\u2500 system-security-plans \u2502 \u251c\u2500\u2500 assessment-plans \u2502 \u251c\u2500\u2500 assessment-results \u2502 \u2514\u2500\u2500 plan-of-action-and-milestones \u251c\u2500\u2500 catalogs \u251c\u2500\u2500 profiles \u251c\u2500\u2500 component-definitions \u251c\u2500\u2500 system-security-plans \u251c\u2500\u2500 assessment-plans \u251c\u2500\u2500 assessment-results \u2514\u2500\u2500 plan-of-action-and-milestones .trestle directory is a special directory containing various trestle artefacts to help run various other commands. dist directory will contain the merged or assembled version of the top level models located on the source model directories which are: catalogs , profiles , component-definitions , system-security-plans , assessment-plans , assessment-results and plan-of-action-and-milestones . Notice that trestle is a highly opinionated tool and, therefore, the names of the files and directories that are created by any of the trestle commands and subcommands MUST NOT be changed manually. trestle create \u00a4 This command will create a bare-bones sample file for one of the top level OSCAL models, and it can also create new elements within an existing file. For example, trestle create -t catalog -o nist800-53 will create a sample catalog file, catalog.json in the catalog subdirectory, nist800-53 as shown below: . \u251c\u2500\u2500 .trestle \u2514\u2500\u2500 catalogs \u2514\u2500\u2500 nist800-53 \u2514\u2500\u2500 catalog.json ... The -t specifies the type of the model to create, which can be one of catalog, profile, component-definition, system-security-plan, assessment-plan, assessment-results, plan-of-action-and-milestones. Each type will be created in its corresponding directory, such as catalogs, profiles, etc. The following additional options are supported: -o or --output : specifies the name/alias of a model. It is used as the prefix for the output filename under the dist directory and for naming the source subdirectories under catalogs , profiles , component-definitions , system-security-plans , assessment-plans , assessment-results or plan-of-action-and-milestones . The user can edit the parts of the generated OSCAL model by modifying the sample content in those directories. Passing -iof or --include-optional-fields will make trestle create generate a richer model containing all optional fields until finding recursion in the model (e.g controls within control). In addition, trestle create can create new components within an existing file by specifying the existing file name and the corresponding element path to create within that file. For example, $TRESTLE_BASEDIR/catalogs/nist800-53$ trestle create -f ./catalog.json -e catalog.metadata.roles will add the following property under the metadata property for a catalog that will be written to the appropriate file under catalogs/nist800-53 directory: { \"roles\" : [ { \"id\" : \"REPLACE_ME\" , \"title\" : \"REPLACE_ME\" } ] } Default values for mandatory datatypes will be like below. All UUID's will be populated by default whether or not they are mandatory. - DateTime : <Current date-time> - Boolean : false - Integer : 0 - String : REPLACE_ME - Float/Double : 0.00 - Id field : Auto generated UUID Again, passing -iof or --include-optional-fields will make trestle create generate a richer version of the element being created, by including optional fields. trestle import \u00a4 This command allows users to import existing OSCAL files so that they can be managed using trestle. For example trestle import -f /local_dir/existing_catalog.json -o my_existing_catalog will import existing_catalog.json into a new folder under catalogs as shown below: . \u251c\u2500\u2500 .trestle \u2514\u2500\u2500 catalogs \u2514\u2500\u2500 my_existing_catalog \u2514\u2500\u2500 catalog.json ... The following options are supported: -f or --file : specifies the path of an existing OSCAL file or URL to a remote file. -o or --output : specifies the name/alias of a model. It is used as the prefix for the output filename under the dist directory and for naming the source subdirectories under catalogs , profiles , component-definitions , system-security-plans , assessment-plans , assessment-results or plan-of-action-and-milestones . The --file option may be an absolute or relative path, and it may be a URL. For details on allowed formats please see the documentation for the href command. The file must be imported from outside the current trestle directory or an error will result. The import subcommand can determine the type of the model that is to be imported by the contents of the file. But the file name must end with an allowed json or yaml extension: .json, .yaml, .yml During the import process the file must pass the validate test described below for the command, validate . If the file does not pass validation a warning will be given describing the nature of the problem and the import will fail. Once a file has been imported it can be split into a rich tree of sub-components as shown at the top of this document. But the file must be imported first. trestle replicate \u00a4 This command allows users to replicate a certain OSCAL model (file and directory structure). For example trestle replicate catalog -n cat1 -o cat11 will replicate the Catalog cat1 into cat11 directory. It can also regenerate all the UUIDs as required. trestle split \u00a4 This command allows users to further decompose a trestle model into additional subcomponents. The following options are currently supported: -f or --file : this is optional and specifies the file path of the json/yaml file containing the elements that will be split. -e or --elements : specifies the model subcomponent element(s) (JSON/YAML property path) that is/are going to be split. Multiple elements can be specified at once using a comma-separated value, e.g -e 'catalog.metadata,catalog.groups' . Make sure to include the quotes that enclose the comma-separated paths. If the element is of JSON/YAML type array list and you want trestle to create a separate subcomponent file per array item, the element needs to be suffixed with .* , e.g. -e 'catalog.groups.*' . If the suffix is not specified, split will place all array items in only one separate subcomponent file, e.g. 'groups.json' . Again, make sure to include the quotes around the elements. If you just want to split a file into all its constituent parts and the file does not contain a simple list of objects, you can still use * and the file will be split into all its non-trivial elements. Thus if you split a catalog with -e catalog.* the result will be a new directory, catalog , containing files representing the large items, back-matter.json, groups.json and metadata.json , but there will still be a catalog.json file containing just the catalog's uuid . Small items such as strings and dates cannot be split off and will remain in the original model file that is being split. Here are some examples. Starting with a single catalog file, my_catalog/catalog.json , if you do trestle split -f catalog.json -e 'catalog.*' you end up with: catalogs \u2517 my_catalog \u2503 \u2523 catalog \u2503 \u2503 \u2523 back-matter.json \u2503 \u2503 \u2523 groups.json \u2503 \u2503 \u2517 metadata.json \u2503 \u2517 catalog.json If you then split roles out of metadata as a single file containing a list of roles, trestle split -f catalog/metadata.json -e 'metadata.roles' you would end up with: catalogs \u2517 my_catalog \u2503 \u2523 catalog \u2503 \u2503 \u2523 metadata \u2503 \u2503 \u2503 \u2517 roles.json \u2503 \u2503 \u2523 back-matter.json \u2503 \u2503 \u2523 groups.json \u2503 \u2503 \u2517 metadata.json \u2503 \u2517 catalog.json If instead you had specified -e 'metadata.roles.*' you would get: my_catalog \u2523 catalog \u2503 \u2523 metadata \u2503 \u2503 \u2517 roles \u2503 \u2503 \u2503 \u2523 00000__role.json \u2503 \u2503 \u2503 \u2517 00001__role.json \u2503 \u2523 back-matter.json \u2503 \u2523 groups.json \u2503 \u2517 metadata.json \u2517 catalog.json You can see there is no roles.json file anymore and instead there is a subdirectory, roles containing a list of files, one for each role . If the -f or --file option is not specified, the file to split will be determined from the elements specified, in the context of the current working directory. The current directory must be within a specific model (e.g. catalog or profile ), and the element paths must either be absolute (e.g. catalog.metadata.roles ) or relative to the current working directory. For example, if you are in catalogs/mycat/catalog/groups and you want to split the file 00000__group.json , you must use -f to specify the filename, and the element path can either be absolute, as catalog.group.* , or you can set the current working directory to where the file is and use element path group.* . This makes it easier to specify splits when deep in a directory structure. Every subdirectory in a trestle directory model should have a corresponding .json or .yaml file with the same name, except when that subdirectory corresponds to a list of items, such as catalog.groups . When those subcomponents are split/expanded each file or subdirectory under them represents an item of the collection. Because of that, if a corresponding groups.json | groups.yaml file were to exist, its contents would just be an empty representation of that collection and the user would need to be careful never to edit that file. Therefore, we decided not to create that corresponding file in those cases. Following the same logic, another exception is when all the fields from a .json | .yaml file are split, leaving the original file as an empty object. In that case, the file would be deleted as well. To inspect a file to see what elements can be split from it, use the describe command described below. It is also useful for inspection of files created by the split operation. trestle merge \u00a4 The trestle merge command is the reversal of trestle split . This command allows users to reverse the decomposition of a trestle model by aggregating subcomponents scattered across multiple files or directories into the parent JSON/YAML file. To merge a model, you have to first change working directory to the root model component directory that you want to merge a sub-component model into. The following option is required: -e or --elements : specifies the properties (JSON/YAML path) that will be merged, relative to the current working directory. This must contain at least 2 elements, where the last element is the model/sub-component to be merged into the second from last component. For example, in the command trestle merge -e 'catalog.metadata' , executed in the same directory where catalog.json or the split catalog directory exists, the property metadata from metadata.json would be moved/merged into catalog.json . If the metadata model has already been split into smaller sub-component models previously, those smaller sub-components are first recusively merged into metadata , before merging metadata subcomponent into catalog . To specify merging every sub-component split from a component, .* can be used. For example, trestle merge -e 'catalog.*' command, issued from the directory where catalog.json or catalog directory exists, will merge every single sub-component of that catalog back into the catalog.json . trestle describe \u00a4 This command lets users inspect model files to explore contents using an optional element path. The command can work well in concert with split to show what each file contains, and probe within the contents to determine sub-components that can be extracted as separate files. Unlike split, describe only describes the contents of a single item, so the element path may not contain wildcards ( * ) or commas. For example, if a catalog file has been imported to catalogs/my_catalog/catalog.json then the commmand, trestle describe -f catalog.json might yield: #Model file catalog.json is of type catalog.Catalog and contains uuid : 613fca2d-704a-42e7-8e2b-b206fb92b456 metadata : common.Metadata params : None controls : None groups : list of 20 items of type catalog.Group back_matter : common.BackMatter Note that contents are listed even when they are empty (and therefore optional) so the full potential contents can be seen. Also note that if an item corresponds to a list of elements, the number and type of elements is provided. Finally, if an item is a simple string such as id , uuid or title , the string is shown directly up to a maximum of 100 characters. If the string is clipped it will be indicated by [truncated] at the end of the string. An element path can be specified to probe the contents, as in trestle describe -f catalog.json -e 'catalog.metadata.roles' . A possible response is: Model file catalog.json at element path catalog.metadata.roles is a list of 2 items of type common.Role You can also query individual elements, and elements of an element, e.g. trestle describe -f catalog.json -e 'catalog.groups.5.controls.3' # Model file catalog.json at element path catalog.groups.5.controls.3 is of type catalog.Control and contains: id : cp-4 class_ : SP800-53 title : Contingency Plan Testing params : list of 2 items of type common.Parameter props : list of 2 items of type common.Property links : list of 14 items of type common.Link parts : list of 2 items of type common.Part controls : list of 5 items of type catalog.Control (Note that the numbering starts at 0, so the .3 corresponds to the 4th element.) In all output from describe the type of the item shown corresponds to the python file and class of the corresponding OSCAL model in trestle. If you split items off a model so they end up in a subdirectory, the original file is referred to as a \"stripped\" model, with parts of it stripped off and only some elements remaining. For example, if you do trestle split -f catalog.json -e 'catalog.metadata' it will split off metadata from the original catalog.json file and place it in catalog/metadata.json . If you then do trestle describe -f catalog.json on the new file, it will say something like: # Model file catalog.json is of type stripped.Catalog and contains: uuid : 613fca2d-704a-42e7-8e2b-b206fb92b456 params : None controls : None groups : list of 20 items of type catalog.Group back_matter : common.BackMatter Note that the type of the file is now stripped.Catalog and it no longer contains metadata . Even though metadata is no longer in the original .json file, trestle is still aware it is present in the model since it is properly placed as its own file in the subdirectory, catalog . trestle partial-object-validate \u00a4 OSCAL objects may be extremely large. Some systems may only be able to produce partial OSCAL objects. For example, the tanium-result-to-oscal-ar task produces the results attribute of an assessment-results object. trestle partial-object-validate allows the validation of any sub-element/attribute using element path. Using the example above trestle partial-object-validate -f results.json -e assessment-results.results . The file is not required to be in the trestle directory or required to be a specific file name. Example valid element-paths \u00a4 All element paths must be absolute e.g.: catalog.metadata catalog catalog.groups catalog.groups.group.controls.control.controls.control Remembering in the end you only care about the end type. So in this scenario catalog.groups.group.controls.control.controls.control is equivalent to catalog.controls.control . trestle href \u00a4 This command changes the href of an Import in a profile and is needed when generating an SSP (system security plan) with the author tool, ssp-generate . The Imports in a profile are used to load associated catalogs of controls and profiles, and must be available at the corresponding href uri. If an imported catalog is in the trestle directory then the href should be changed with a command of the form: trestle href -n my_profile -hr trestle://catalogs/my_catalog/catalog.json Similarly, if the item imported is a profile, a corresponding href should point to a json file in the profiles directory. Note that catalogs or profiles in the trestle directory are indicated by the trestle:// prefix, followed by the path from the top level models directory to the actual catalog file. The profile itself, which is having its imports modified, is just indicated by its name with the -n option. If the profile has more than one import, you can display the corresponding hrefs with: trestle href -n my_profile This will give a numbered list of the hrefs. You can then change them individually by providing the corresponding item number: trestle href -n my_profile -i 1 -hr trestle://catalogs/my_catalog/catalog.json This will change the href indexed as 1 when the list was displayed. The href's are indexed starting from 0. The trestle href command can also be used to change the value back to the intended one prior to distribution of the profile. The provided href can be of form trestle:// , https:// , sftp:// , or file:/// . If file:/// is used, the path provided must be absolute - and on Windows it must include the drive letter followed by a slash. The only time a relative path is allowed is with the trestle:// heading. A username and password may be embedded in the url for https:// , and a CA certificate path will be searched from environment variables REQUESTS_CA_BUNDLE and CURL_CA_BUNDLE in that order. Authorization for sftp:// access relies on the user's private key being either active via ssh-agent or supplied via the environment variable SSH_KEY . In the latter case it must not require a passphrase prompt. trestle assemble \u00a4 This command assembles all contents (files and directories) representing a specific model into a single OSCAL file located under dist folder. For example, $TRESTLE_BASEDIR$ trestle assemble catalog -n nist800-53 will traverse the catalogs/nist800-53 directory and its children and combine all data into a OSCAL file that will be written to dist/catalogs/nist800-53.json . Note that the parts of catalog nist800-53 can be written in either YAML/JSON (e.g. based on the file extension), however, the output will be generated as YAML/JSON as desired. Trestle will infer the content type from the file extension and create the model representation appropriately in memory and then output in the desired format. Trestle assemble will also validate content as it assembles the files and make sure the contents are syntactically correct. trestle remove \u00a4 The trestle remove command is the reversal of trestle create -f filename.json -e element_path , as it will remove the corresponding element from the specified file. trestle validate \u00a4 Trestle validate checks the integrity of one or more OSCAL files in a number of ways. validate returns a non-zero return code if there is any validation problem detected in a file. The current list of validation modes that get checked internally are: Mode Purpose duplicates Detect whether disallowed duplicate uuid's are present oscal_version Confirm that the oscal version of the file is supported refs Confirm that all references in responsible parties are found in roles You can validate a single model file by specifying its full path: trestle validate -f catalogs/my_cat/catalog.json or by specifying its model name and type: trestle validate -t catalog -n my_cat In addition to validating a single file you can validate all files of a given type with the -t option and no file name: trestle validate -t catalog And you can validate all models with the -a option: trestle validate -a Note that when you Import a file it will perform a full validation on it first, and if it does not pass validation the file cannot be imported. trestle tasks \u00a4 Open Shift Compliance Operator and Tanium are supported as 3rd party tools. trestle task osco-result-to-oscal-ar \u00a4 The trestle task osco-result-to-oscal-ar command facilitates transformation of OpenShift Compliance Operator (OSCO) scan results .yaml files into OSCAL partial results .json files. Specify required config parameters to indicate the location of the input and the output. Specify optional config parameters to indicate the name of the oscal-metadata.yaml file, if any, and whether overwriting of existing output is permitted. Example command invocation: $TRESTLE_BASEDIR$ trestle task osco-result-to-oscal-ar -c /home/user/task.config Example config: /home/user/task.config [task.osco-result-to-oscal-ar] input-dir = /home/user/git/evidence/osco/input output-dir = /home/user/git/evidence/oscal/output oscal-metadata = oscal-metadata.yaml output-overwrite = true input Example input directory contents listing: /home/user/git/evidence/osco/input -rw-rw-r--. 1 user user 3832 Feb 2 09 :36 oscal-metadata.yaml -rw-rw-r--. 1 user user 49132 Feb 2 06 :12 ssg-ocp4-ds-cis-111.222.333.444-pod.yaml -rw-rw-r--. 1 user user 52747 Feb 2 06 :41 ssg-ocp4-ds-cis-111.222.333.555-pod.yaml Example input OSCO scan result file contents (snippet): ssg-ocp4-ds-cis-111.222.333.444-pod.yaml display sample apiVersion : v1 data : exit-code : '2' results : | <?xml version=\"1.0\" encoding=\"UTF-8\"?> <TestResult xmlns=\"https://checklists.nist.gov/xccdf/1.2\" id=\"xccdf_org.open-scap_testresult_xccdf_org.ssgproject.content_profile_cis\" start-time=\"2020-08-03T02:26:26+00:00\" end-time=\"2020-08-03T02:26:26+00:00\" version=\"0.1.52\" test-system=\"cpe:/a:redhat:openscap:1.3.3\"> <benchmark href=\"/content/ssg-ocp4-ds.xml\" id=\"xccdf_org.ssgproject.content_benchmark_OCP-4\"/> <title>OSCAP Scan Result</title> <profile idref=\"xccdf_org.ssgproject.content_profile_cis\"/> <target>kube-br7qsa3d0vceu2so1a90-roksopensca-default-0000026b.iks.mycorp</target> <target-facts> <fact name=\"urn:xccdf:fact:identifier\" type=\"string\">chroot:///host</fact> <fact name=\"urn:xccdf:fact:scanner:name\" type=\"string\">OpenSCAP</fact> <fact name=\"urn:xccdf:fact:scanner:version\" type=\"string\">1.3.3</fact> </target-facts> <target-id-ref system=\"https://scap.nist.gov/schema/asset-identification/1.1\" name=\"asset0\" href=\"\"/> <platform idref=\"cpe:/a:redhat:openshift_container_platform:4.1\"/> <platform idref=\"cpe:/a:machine\"/> <set-value idref=\"xccdf_org.ssgproject.content_value_ocp_data_root\">/kubernetes-api-resources</set-value> <set-value idref=\"xccdf_org.ssgproject.content_value_var_kube_authorization_mode\">Webhook</set-value> <set-value idref=\"xccdf_org.ssgproject.content_value_var_streaming_connection_timeouts\">5m</set-value> <rule-result idref=\"xccdf_org.ssgproject.content_rule_ocp_idp_no_htpasswd\" time=\"2020-08-03T02:26:26+00:00\" severity=\"medium\" weight=\"1.000000\"> <result>notselected</result> <ident system=\"https://nvd.nist.gov/cce/index.cfm\">CCE-84209-6</ident> </rule-result> <rule-result idref=\"xccdf_org.ssgproject.content_rule_accounts_restrict_service_account_tokens\" time=\"2020-08-03T02:26:26+00:00\" severity=\"medium\" weight=\"1.000000\"> <result>notchecked</result> <message severity=\"info\">No candidate or applicable check found.</message> </rule-result> <rule-result idref=\"xccdf_org.ssgproject.content_rule_accounts_unique_service_account\" time=\"2020-08-03T02:26:26+00:00\" severity=\"medium\" weight=\"1.000000\"> <result>notchecked</result> <message severity=\"info\">No candidate or applicable check found.</message> </rule-result> ... </TestResult> kind : ConfigMap metadata : annotations : compliance-remediations/processed : '' compliance.openshift.io/scan-error-msg : '' compliance.openshift.io/scan-result : NON-COMPLIANT openscap-scan-result/node : 111.222.333.444 creationTimestamp : '2020-08-03T02:26:34Z' labels : compliance-scan : ssg-ocp4-ds-cis name : ssg-ocp4-ds-cis-111.222.333.444-pod namespace : openshift-compliance resourceVersion : '22693328' selfLink : /api/v1/namespaces/openshift-compliance/configmaps/ssg-ocp4-ds-cis-111.222.333.444-pod uid : 1da3ea81-0a25-4512-ad86-7ac360246b5d Example input OSCAL metadata file contents: oscal-metadata.yaml display sample ssg-ocp4-ds-cis-111.222.333.444-pod : locker : https://github.mycorp.com/degenaro/evidence-locker namespace : xccdf benchmark : CIS Kubernetes Benchmark subject-references : component : uuid-ref : 56666738-0f9a-4e38-9aac-c0fad00a5821 type : component title : Red Hat OpenShift Kubernetes inventory-item : uuid-ref : 46aADFAC-A1fd-4Cf0-a6aA-d1AfAb3e0d3e type : inventory-item title : Pod properties : target : kube-br7qsa3d0vceu2so1a90-roksopensca-default-0000026b.iks.mycorp target-ip : 111.222.333.444 cluster-name : ROKS-OpenSCAP-1 cluster-type : openshift cluster-region : us-south ssg-rhel7-ds-cis-111.222.333.444-pod : locker : https://github.mycorp.com/degenaro/evidence-locker namespace : xccdf benchmark : CIS Kubernetes Benchmark subject-references : component : uuid-ref : 89cfe7a7-ce6b-4699-aa7b-2f5739c72001 type : component title : RedHat Enterprise Linux 7.8 inventory-item : uuid-ref : 46aADFAC-A1fd-4Cf0-a6aA-d1AfAb3e0d3e type : inventory-item title : VM properties : target : kube-br7qsa3d0vceu2so1a90-roksopensca-default-0000026b.iks.mycorp target-ip : 111.222.333.444 cluster-name : ROKS-OpenSCAP-1 cluster-type : openshift cluster-region : us-south metadata format The oscal-metadata.yaml file comprises one or more mappings. Below is shown the format of a single mapping. The items in angle brackets are to be replaced with desired values for augmenting the produced OSCAL. The mapping whose name matches the [metadata][name] in the evidence for the corresponding embedded XML, if any, will be used for augmenting the produced OSCAL. name : locker : <locker> namespace : <namespace> benchmark : <benchmark> subject-references : component : uuid-ref : <uuid-ref-component> type : <component-type> title : <component-title> inventory-item : uuid-ref : <uuid-ref-inventory-item> type : <inventory-item-type> title : <inventory-item-title> properties : target : <target> cluster-name : <cluster-name> cluster-type : <cluster-type> cluster-region : <cluster-region> output Example output directory contents listing: /home/user/git/evidence/oscal/output -rw-rw-r--. 1 user user 49132 Feb 3 10 :59 ssg-ocp4-ds-cis-111.222.333.444-pod.json -rw-rw-r--. 1 user user 52747 Feb 3 10 :59 ssg-ocp4-ds-cis-111.222.333.555-pod.json Example output OSCAL Observations file contents (snippet): ssg-ocp4-ds-cis-111.222.333.444-pod.json display sample { \"observations\" : [ { \"uuid\" : \"56666738-0f9a-4e38-9aac-c0fad00a5821\" , \"title\" : \"xccdf_org.ssgproject.content_rule_ocp_idp_no_htpasswd\" , \"description\" : \"xccdf_org.ssgproject.content_rule_ocp_idp_no_htpasswd\" , \"props\" : [ { \"name\" : \"benchmark\" , \"ns\" : \"dns://osco\" , \"class\" : \"source\" , \"value\" : \"CIS Kubernetes Benchmark\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"56666738-0f9a-4e38-9aac-c0fad00a5821\" , \"type\" : \"component\" , \"title\" : \"Red Hat OpenShift Kubernetes\" }, { \"uuid-ref\" : \"46aADFAC-A1fd-4Cf0-a6aA-d1AfAb3e0d3e\" , \"type\" : \"inventory-item\" , \"title\" : \"Pod\" , \"props\" : [ { \"name\" : \"target\" , \"ns\" : \"dns://osco\" , \"class\" : \"inventory-item\" , \"value\" : \"kube-br7qsa3d0vceu2so1a90-roksopensca-default-0000026b.iks.mycorp\" }, { \"name\" : \"target-ip\" , \"ns\" : \"dns://osco\" , \"class\" : \"inventory-item\" , \"value\" : \"111.222.333.444\" }, { \"name\" : \"cluster-name\" , \"ns\" : \"dns://osco\" , \"class\" : \"inventory-item\" , \"value\" : \"ROKS-OpenSCAP-1\" }, { \"name\" : \"cluster-type\" , \"ns\" : \"dns://osco\" , \"class\" : \"inventory-item\" , \"value\" : \"openshift\" }, { \"name\" : \"cluster-region\" , \"ns\" : \"dns://osco\" , \"class\" : \"inventory-item\" , \"value\" : \"us-south\" } ] } ], \"relevant-evidence\" : [ { \"href\" : \"https://github.mycorp.com/degenaro/evidence-locker\" , \"description\" : \"Evidence location.\" , \"props\" : [ { \"name\" : \"rule\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"id\" , \"value\" : \"xccdf_org.ssgproject.content_rule_ocp_idp_no_htpasswd\" }, { \"name\" : \"time\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"timestamp\" , \"value\" : \"2020-08-03T02:26:26+00:00\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"result\" , \"value\" : \"notselected\" } ] } ] } ] } trestle task tanium-result-to-oscal-ar \u00a4 The trestle task tanium-result-to-oscal-ar command facilitates transformation of Tanuim reports, each input file comprising individual lines consumable as json , into OSCAL partial results .json files. Specify required config parameters to indicate the location of the input and the output. Specify optional config parameter output-overwrite to indicate whether overwriting of existing output is permitted. Specify optional config parameter timestamp as ISO 8601 formated string (e.g., 2021-02-24T19:31:13+00:00) to override the timestamp attached to each Observation. Example command invocation: $TRESTLE_BASEDIR$ trestle task tanium-result-to-oscal-ar -c /home/user/task.config Example config: /home/user/task.config [task.tanium-result-to-oscal-ar] input-dir = /home/user/git/compliance/tanium/input output-dir = /home/user/git/compliance/oscal/output output-overwrite = true input Example input directory contents listing: /home/user/git/compliance/tanium/input -rw-rw-r--. 1 degenaro degenaro 1830 Mar 7 08 :23 Tanium.comply-nist-results Tanium.comply-nist-results display sample { \"IP Address\" : \"fe80::3cd5:564b:940e:49ab\" , \"Computer Name\" : \"cmp-wn-2106.demo.tanium.local\" , \"Comply - JovalCM Results[c2dc8749]\" : [ { \"Benchmark\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"Benchmark Version\" : \"1.5.0.1\" , \"Profile\" : \"Windows 10 - NIST 800-53\" , \"ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1_L1_Ensure_Enforce_password_history_is_set_to_24_or_more_passwords\" , \"Result\" : \"pass\" , \"Custom ID\" : \"800-53: IA-5\" , \"Version\" : \"version: 1\" } ], \"Count\" : \"1\" , \"Age\" : \"600\" } { \"IP Address\" : \"10.8.69.11\" , \"Computer Name\" : \"\" , \"Comply - JovalCM Results[c2dc8749]\" : [ { \"Benchmark\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"Benchmark Version\" : \"1.5.0.1\" , \"Profile\" : \"Windows 10 - NIST 800-53\" , \"ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.2_L1_Ensure_Maximum_password_age_is_set_to_60_or_fewer_days_but_not_0\" , \"Result\" : \"pass\" , \"Custom ID\" : \"800-53: IA-5\" , \"Version\" : \"version: 1\" } ], \"Count\" : \"1\" , \"Age\" : \"600\" } { \"IP Address\" : \"10.8.69.11\" , \"Computer Name\" : \"cmp-wn-2106.demo.tanium.local\" , \"Comply - JovalCM Results[c2dc8749]\" : [ { \"Benchmark\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"Benchmark Version\" : \"1.5.0.1\" , \"Profile\" : \"Windows 10 - NIST 800-53\" , \"ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.3_L1_Ensure_Minimum_password_age_is_set_to_1_or_more_days\" , \"Result\" : \"fail\" , \"Custom ID\" : \"800-53: IA-5\" , \"Version\" : \"version: 1\" } ], \"Count\" : \"1\" , \"Age\" : \"600\" } { \"IP Address\" : \"10.8.69.11\" , \"Computer Name\" : \"cmp-wn-2106.demo.tanium.local\" , \"Comply - JovalCM Results[c2dc8749]\" : [ { \"Benchmark\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"Benchmark Version\" : \"1.5.0.1\" , \"Profile\" : \"Windows 10 - NIST 800-53\" , \"ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.4_L1_Ensure_Minimum_password_length_is_set_to_14_or_more_characters\" , \"Result\" : \"pass\" , \"Custom ID\" : \"800-53: IA-5\" , \"Version\" : \"version: 1\" } ], \"Count\" : \"1\" , \"Age\" : \"600\" } output Example output directory contents listing: /home/user/git/compliance/oscal/output -rw-rw-r--. 1 degenaro degenaro 6479 Mar 7 08 :25 Tanium.oscal.json Tanium.oscal.json display sample { \"results\" : [ { \"uuid\" : \"0ed0791e-5454-4d07-919f-15a0d806a5a8\" , \"title\" : \"Tanium\" , \"description\" : \"Tanium\" , \"start\" : \"2021-04-13T00:16:20.000+00:00\" , \"local-definitions\" : { \"inventory-items\" : [ { \"uuid\" : \"da8b87f6-2068-415f-94bb-e14e31b4f5c2\" , \"description\" : \"inventory\" , \"props\" : [ { \"name\" : \"computer-name\" , \"ns\" : \"dns://tanium\" , \"value\" : \"cmp-wn-2106.demo.tanium.local\" , \"class\" : \" inventory-item\" }, { \"name\" : \"computer-ip\" , \"ns\" : \"dns://tanium\" , \"value\" : \"fe80::3cd5:564b:940e:49ab\" , \"class\" : \" inventory-item\" }, { \"name\" : \"profile\" , \"ns\" : \"dns://tanium\" , \"value\" : \"Windows 10\" , \"class\" : \" inventory-item\" } ] }, { \"uuid\" : \"f3ab87b2-70c1-4332-991e-c003d4314c0b\" , \"description\" : \"inventory\" , \"props\" : [ { \"name\" : \"computer-name\" , \"ns\" : \"dns://tanium\" , \"value\" : \"\" , \"class\" : \" inventory-item\" }, { \"name\" : \"computer-ip\" , \"ns\" : \"dns://tanium\" , \"value\" : \"10.8.69.11\" , \"class\" : \" inventory-item\" }, { \"name\" : \"profile\" , \"ns\" : \"dns://tanium\" , \"value\" : \"Windows 10\" , \"class\" : \" inventory-item\" } ] } ] }, \"reviewed-controls\" : { \"control-selections\" : [ {} ] }, \"observations\" : [ { \"uuid\" : \"b3250b66-fe6f-4ac0-be99-cb4ff093dc31\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1_L1_Ensure_Enforce_password_history_is_set_to_24_or_more_passwords\" , \"props\" : [ { \"name\" : \"benchmark\" , \"ns\" : \"dns://tanium\" , \"value\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"class\" : \"source\" }, { \"name\" : \"rule\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1_L1_Ensure_Enforce_password_history_is_set_to_24_or_more_passwords\" , \"class\" : \"id\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"pass\" , \"class\" : \"result\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"da8b87f6-2068-415f-94bb-e14e31b4f5c2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-04-13T00:16:20.000+00:00\" }, { \"uuid\" : \"5ae9c133-c32d-44c5-b52e-5af4513cb94a\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.2_L1_Ensure_Maximum_password_age_is_set_to_60_or_fewer_days_but_not_0\" , \"props\" : [ { \"name\" : \"benchmark\" , \"ns\" : \"dns://tanium\" , \"value\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"class\" : \"source\" }, { \"name\" : \"rule\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.2_L1_Ensure_Maximum_password_age_is_set_to_60_or_fewer_days_but_not_0\" , \"class\" : \"id\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"pass\" , \"class\" : \"result\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"f3ab87b2-70c1-4332-991e-c003d4314c0b\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-04-13T00:16:20.000+00:00\" }, { \"uuid\" : \"8d021edc-176e-4373-a3c4-a19e954c1e4d\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.3_L1_Ensure_Minimum_password_age_is_set_to_1_or_more_days\" , \"props\" : [ { \"name\" : \"benchmark\" , \"ns\" : \"dns://tanium\" , \"value\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"class\" : \"source\" }, { \"name\" : \"rule\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.3_L1_Ensure_Minimum_password_age_is_set_to_1_or_more_days\" , \"class\" : \"id\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"fail\" , \"class\" : \"result\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"f3ab87b2-70c1-4332-991e-c003d4314c0b\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-04-13T00:16:20.000+00:00\" }, { \"uuid\" : \"36aa7551-d047-4f4a-9853-6ac63cfc9e48\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.4_L1_Ensure_Minimum_password_length_is_set_to_14_or_more_characters\" , \"props\" : [ { \"name\" : \"benchmark\" , \"ns\" : \"dns://tanium\" , \"value\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"class\" : \"source\" }, { \"name\" : \"rule\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.4_L1_Ensure_Minimum_password_length_is_set_to_14_or_more_characters\" , \"class\" : \"id\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"pass\" , \"class\" : \"result\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"f3ab87b2-70c1-4332-991e-c003d4314c0b\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-04-13T00:16:20.000+00:00\" } ], \"findings\" : [ { \"uuid\" : \"ba4e264f-0aee-4ead-9ee3-6161c5cc4ecb\" , \"title\" : \"800-53: IA-5\" , \"description\" : \"800-53: IA-5\" , \"target\" : { \"type\" : \"objective-id\" , \"id-ref\" : \"800-53: IA-5\" , \"props\" : [ { \"name\" : \"profile\" , \"ns\" : \"dns://tanium\" , \"value\" : \"NIST 800-53\" , \"class\" : \"source\" }, { \"name\" : \"id-ref\" , \"ns\" : \"dns://tanium\" , \"value\" : \"800-53: IA-5\" , \"class\" : \"source\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"FAIL\" , \"class\" : \"STRVALUE\" } ], \"status\" : \"not-satisfied\" }, \"related-observations\" : [ { \"observation-uuid\" : \"b3250b66-fe6f-4ac0-be99-cb4ff093dc31\" }, { \"observation-uuid\" : \"5ae9c133-c32d-44c5-b52e-5af4513cb94a\" }, { \"observation-uuid\" : \"8d021edc-176e-4373-a3c4-a19e954c1e4d\" }, { \"observation-uuid\" : \"36aa7551-d047-4f4a-9853-6ac63cfc9e48\" } ] } ] } ] } trestle task xlsx-to-oscal-cd \u00a4 The trestle task xlsx-to-oscal-cd command facilitates transformation of an excel spreadsheet into an OSCAL component-definition.json file. Specify in the config: location of catalog file location of spreadsheet file work sheet name in the spreadsheet file output directory to write the component-definition.json file whether or not to overwrite an existing component-definition.json file the organization name the organization remarks the namespace comma separated mappings from name to class the catalog URL the catalog title Example command invocation: $TRESTLE_BASEDIR$ trestle task xlsx-to-oscal-cd -c /home/user/task-xlsx-to-oscal-cd.config Example config: /home/user/task-xlsx-to-oscal-cd.config [task.xlsx-to-oscal-cd] catalog-file = nist-content/nist.gov/SP800-53/rev4/json/NIST_SP-800-53_rev4_catalog.json spread-sheet-file = /home/user/compliance/data/spread-sheet/good.xlsx work-sheet-name = example_best_practices_controls output-dir = /home/user/compliance/data/tasks/xlsx/output output-overwrite = true org-name = International Business Machines org-remarks = IBM namespace = https://ibm.github.io/compliance-trestle/schemas/oscal/cd/ibm-cloud property-name-to-class = goal_name_id:scc_goal_name_id, goal_version:scc_goal_version catalog-url = https://github.com/usnistgov/oscal-content/blob/master/nist.gov/SP800-53/rev4/json/NIST_SP-800-53_rev4_catalog.json catalog-title = NIST Special Publication 800-53 Revision 4 catalog-file Example catalog-file: nist-content/nist.gov/SP800-53/rev4/json/NIST_SP-800-53_rev4_catalog.json spread-sheet-file Example spread-sheet-file: /home/user/compliance/data/spread-sheet/good.xlsx output Example component-definition.json: /home/user/compliance/data/tasks/xlsx/output/component-definition.json spreadsheet to component definition mapping \u00a4 display mapping table table, th, td { border: 1px solid black; border-collapse: collapse; } th, td { padding: 5px; } spreadsheet column name component definition path comments ControlId implemented_requirement.property[name='goal_name_id'].value only used if column 'goal_name_id' is empty ControlText implemented_requirement.property[name='goal_name_id'].remarks transformation code replaces \"Check whether\" with \"Ensure\" in text Nist Mappings implemented_requirement.description heading may span multiple columns one value expected per column each entry is separated into control + statements (if any) ResourceTitle component.title component.description component.control-implementation.description + {text} goal_name_id implemented_requirement.property[name='goal_name_id'].value Version implemented_requirement.property[name='goal_version'].value Value from spreadsheet is not currently used. Value '1.0' is hard coded. Parameter [optional parameter] implemented_requirement.set_parameter.param_id The expected text is in two parts separated by '\\n'. The text following the '\\n' is the value used. Values [alternatives] implemented_requirement.set_parameter.values The expected text is of the following format: v0, [v1, v2...] The value v0 is used. trestle task xlsx-to-oscal-profile \u00a4 The trestle task xlsx-to-oscal-profile command facilitates transformation of an excel spreadsheet into an OSCAL profile.json file. Specify in the config: the href URL of the spreadsheet file system location of spreadsheet file work sheet name in the spreadsheet file output directory to write the profile.json file whether or not to overwrite an existing profile.json file the profile title Example command invocation: $TRESTLE_BASEDIR$ trestle task xlsx-to-oscal-profile -c /home/user/task-xlsx-to-oscal-profile.config Example config: /home/user/task-xlsx-to-oscal-profile.config [task.xlsx-to-oscal-profile] spread-sheet-url = https://github.mycorp.com/spread-sheets/good.xlsx spread-sheet-file = /home/user/compliance/data/spread-sheet/good.xlsx work-sheet-name = example_best_practices_controls output-dir = /home/user/compliance/data/tasks/xlsx/output output-overwrite = true profile-title = IBM Best Practices SCC GOALS spread-sheet-file Example spread-sheet-file: /home/user/compliance/data/spread-sheet/good.xlsx output Example profile.json: /home/user/compliance/data/tasks/xlsx/output/profile.json","title":"CLI for OSCAL documents"},{"location":"cli/#trestle-cli-overview-and-oscal-usecases","text":"The trestle CLI has three primary use cases: Serve as tooling to generate and manipulate OSCAL files directly by an end user. The objective is to reduce the complexity of creating and editing workflows. Example commands are: trestle import , trestle create , trestle split , trestle merge . Act as an automation tool that, by design, can be an integral part of a CI/CD pipeline e.g. trestle validate , trestle tasks . Allow governance of markdown documents so they conform to specific style or structure requirements. To support each of these use cases trestle creates an opinionated directory structure to manage governed documents.","title":"trestle CLI Overview and OSCAL Usecases"},{"location":"cli/#opinionated-directory-structure","text":"Trestle relies on an opinionated directory structure (trestle workspace), similar to git , go , or auditree , to manage the workflow. Most trestle commands are restricted to working within an initialized directory tree. The directory structure setup by trestle has three major elements: A .trestle hidden folder. A dist folder. Folders for each of the top level OSCAL models. The outline of the schema is below: . \u251c\u2500\u2500 .trestle \u251c\u2500\u2500 dist \u2502 \u251c\u2500\u2500 catalogs \u2502 \u251c\u2500\u2500 profiles \u2502 \u251c\u2500\u2500 component-definitions \u2502 \u251c\u2500\u2500 system-security-plans \u2502 \u251c\u2500\u2500 assessment-plans \u2502 \u251c\u2500\u2500 assessment-results \u2502 \u2514\u2500\u2500 plan-of-action-and-milestones \u251c\u2500\u2500 catalogs \u251c\u2500\u2500 profiles \u251c\u2500\u2500 component-definitions \u251c\u2500\u2500 system-security-plans \u251c\u2500\u2500 assessment-plans \u251c\u2500\u2500 assessment-results \u2514\u2500\u2500 plan-of-action-and-milestones .trestle directory is a special directory containing various trestle artefacts to help run various other commands. Examples include configuration files, caches and templates. dist directory will contain the assembled version of the top level models located on the source model directories. The bulk of the folder structure is used to represent each of the top level schemas or top level models such as catalogs and profiles . For each of these directories the following root structure is maintained: \u251c\u2500\u2500 .trestle \u2514\u2500\u2500 TOP_LEVEL_MODEL_PLURAL \u2514\u2500\u2500 NAME_OF_MODEL_INSTANCE \u2514\u2500\u2500 TOP_LEVEL_MODEL_NAME.{json,yaml,yml} which appears, for a catalog a user decides is titled nist-800-53, as: \u251c\u2500\u2500 .trestle \u2514\u2500\u2500 catalogs \u2514\u2500\u2500 nist-800-53 \u2514\u2500\u2500 catalog.json In most of the places in the documentation we use json format for specifying model files, but they are equally applicable to yaml format also. The default format is json , and yaml is supported on best effort basis. Within one model directory the two different formats should not be mixed.","title":"Opinionated directory structure"},{"location":"cli/#support-for-subdivided-document-structures","text":"The files constructed by OSCAL can run into tens of thousands of lines of yaml or formatted json. At this size the files become completely unmanageable for users. To combat this, trestle can trestle split a file into many smaller files and later merge those split files together. Directory structures such as the one below can represent OSCAL document structures. Users are strongly encourage to rely on split and merge to code these structures. Users can query the contents of files using trestle describe , and probe the contents more deeply using it in combination with element paths. . \u251c\u2500\u2500 .trestle \u251c\u2500\u2500 dist \u2502 \u2514\u2500\u2500 catalogs \u2502 \u2514\u2500\u2500 nist800-53.json \u2514\u2500\u2500 catalogs \u2514\u2500\u2500 nist800-53 \u251c\u2500\u2500 catalog.json \u2514\u2500\u2500 catalog \u251c\u2500\u2500 metadata.json \u251c\u2500\u2500 metadata \u2502 \u251c\u2500\u2500 revision-history \u2502 \u2502 \u251c\u2500\u2500 00000__revision-history.json \u2502 \u2502 \u251c\u2500\u2500 00001__revision-history.json \u2502 \u2502 \u2514\u2500\u2500 00002__revision-history.json \u2502 \u2514\u2500\u2500 responsible-parties \u2502 \u251c\u2500\u2500 creator__responsible-party.json \u2502 \u2514\u2500\u2500 contact__responsible-party.json \u2514\u2500\u2500 groups \u251c\u2500\u2500 00000__group.json \u251c\u2500\u2500 00000__group \u2502 \u2514\u2500\u2500 controls \u2502 \u251c\u2500\u2500 00000__control.json \u2502 \u2514\u2500\u2500 00001__control.json \u251c\u2500\u2500 00001__group.json \u2514\u2500\u2500 00001__group \u2514\u2500\u2500 controls \u251c\u2500\u2500 00000__control.json \u2514\u2500\u2500 00001__control.json ...","title":"Support for subdivided document structures"},{"location":"cli/#specifying-attributes-elements-within-trestle-commands","text":"OSCAL models are rich and contain multiple nested data structures. Given this, a mechanism is required to address elements / attributes within an oscal object. This accessing method is called 'element path' and is similar to jsonPath . Commands provide element path by a -e argument where available, e.g. trestle split -f catalog.json -e 'catalog.metadata.*'. This path is used whenever specifying an attribute or model, rather than exposing trestle's underlying object model name. Users can refer to NIST's json outline to understand object names in trestle.","title":"Specifying attributes / elements within trestle commands."},{"location":"cli/#rules-for-element-path","text":"Element path is an expression of the attribute names, in json form , concatenated by a period ( . ). E.g. The metadata in a catalog is referred to as catalog.metadata Element paths are relative to the file. e.g. For metadata.json roles would be referred to as metadata.roles , from the catalog file that would be catalog.metadata.roles Arrays can be handled by a wild card * or a numerical index for a specific index. catalog.groups.* to refer to each group in a catalog catalog.groups.*.controls.* to refer to 'for each control under a top level group' For NIST 800-53 catalog.groups.0.controls.0. On *nix platforms if using the wildcard the element path argument should be wrapped in quotes to prevent problems with the shell interpreting the wild card before trestle can When dealing with an array based object, the array syntax may be skipped when passing a model e.g. a control could be catalog.controls.control or catalog.groups.controls.control This syntax is required as OSCAL, across the schema, has conflicting element definitions.","title":"Rules for element path"},{"location":"cli/#a-note-for-software-developers-using-trestle","text":"Trestle provides utilities for converting from element path to trestle's python object model. The (slightly simplified) model is: Class attributes are converted from dash-case to dash_case (aka snake_case) Class names are converted from dash-case to DashCase (aka CamelCase)","title":"A note for software developers using trestle."},{"location":"cli/#trestle-init","text":"This command will create (initialize) a trestle workspace in the current directory with the necessary directory structure and trestle artefacts. For example, if we run trestle init in a directory, it will create the directory structure below for different artefacts: . \u251c\u2500\u2500 .trestle \u251c\u2500\u2500 dist \u2502 \u251c\u2500\u2500 catalogs \u2502 \u251c\u2500\u2500 profiles \u2502 \u251c\u2500\u2500 component-definitions \u2502 \u251c\u2500\u2500 system-security-plans \u2502 \u251c\u2500\u2500 assessment-plans \u2502 \u251c\u2500\u2500 assessment-results \u2502 \u2514\u2500\u2500 plan-of-action-and-milestones \u251c\u2500\u2500 catalogs \u251c\u2500\u2500 profiles \u251c\u2500\u2500 component-definitions \u251c\u2500\u2500 system-security-plans \u251c\u2500\u2500 assessment-plans \u251c\u2500\u2500 assessment-results \u2514\u2500\u2500 plan-of-action-and-milestones .trestle directory is a special directory containing various trestle artefacts to help run various other commands. dist directory will contain the merged or assembled version of the top level models located on the source model directories which are: catalogs , profiles , component-definitions , system-security-plans , assessment-plans , assessment-results and plan-of-action-and-milestones . Notice that trestle is a highly opinionated tool and, therefore, the names of the files and directories that are created by any of the trestle commands and subcommands MUST NOT be changed manually.","title":"trestle init"},{"location":"cli/#trestle-create","text":"This command will create a bare-bones sample file for one of the top level OSCAL models, and it can also create new elements within an existing file. For example, trestle create -t catalog -o nist800-53 will create a sample catalog file, catalog.json in the catalog subdirectory, nist800-53 as shown below: . \u251c\u2500\u2500 .trestle \u2514\u2500\u2500 catalogs \u2514\u2500\u2500 nist800-53 \u2514\u2500\u2500 catalog.json ... The -t specifies the type of the model to create, which can be one of catalog, profile, component-definition, system-security-plan, assessment-plan, assessment-results, plan-of-action-and-milestones. Each type will be created in its corresponding directory, such as catalogs, profiles, etc. The following additional options are supported: -o or --output : specifies the name/alias of a model. It is used as the prefix for the output filename under the dist directory and for naming the source subdirectories under catalogs , profiles , component-definitions , system-security-plans , assessment-plans , assessment-results or plan-of-action-and-milestones . The user can edit the parts of the generated OSCAL model by modifying the sample content in those directories. Passing -iof or --include-optional-fields will make trestle create generate a richer model containing all optional fields until finding recursion in the model (e.g controls within control). In addition, trestle create can create new components within an existing file by specifying the existing file name and the corresponding element path to create within that file. For example, $TRESTLE_BASEDIR/catalogs/nist800-53$ trestle create -f ./catalog.json -e catalog.metadata.roles will add the following property under the metadata property for a catalog that will be written to the appropriate file under catalogs/nist800-53 directory: { \"roles\" : [ { \"id\" : \"REPLACE_ME\" , \"title\" : \"REPLACE_ME\" } ] } Default values for mandatory datatypes will be like below. All UUID's will be populated by default whether or not they are mandatory. - DateTime : <Current date-time> - Boolean : false - Integer : 0 - String : REPLACE_ME - Float/Double : 0.00 - Id field : Auto generated UUID Again, passing -iof or --include-optional-fields will make trestle create generate a richer version of the element being created, by including optional fields.","title":"trestle create"},{"location":"cli/#trestle-import","text":"This command allows users to import existing OSCAL files so that they can be managed using trestle. For example trestle import -f /local_dir/existing_catalog.json -o my_existing_catalog will import existing_catalog.json into a new folder under catalogs as shown below: . \u251c\u2500\u2500 .trestle \u2514\u2500\u2500 catalogs \u2514\u2500\u2500 my_existing_catalog \u2514\u2500\u2500 catalog.json ... The following options are supported: -f or --file : specifies the path of an existing OSCAL file or URL to a remote file. -o or --output : specifies the name/alias of a model. It is used as the prefix for the output filename under the dist directory and for naming the source subdirectories under catalogs , profiles , component-definitions , system-security-plans , assessment-plans , assessment-results or plan-of-action-and-milestones . The --file option may be an absolute or relative path, and it may be a URL. For details on allowed formats please see the documentation for the href command. The file must be imported from outside the current trestle directory or an error will result. The import subcommand can determine the type of the model that is to be imported by the contents of the file. But the file name must end with an allowed json or yaml extension: .json, .yaml, .yml During the import process the file must pass the validate test described below for the command, validate . If the file does not pass validation a warning will be given describing the nature of the problem and the import will fail. Once a file has been imported it can be split into a rich tree of sub-components as shown at the top of this document. But the file must be imported first.","title":"trestle import"},{"location":"cli/#trestle-replicate","text":"This command allows users to replicate a certain OSCAL model (file and directory structure). For example trestle replicate catalog -n cat1 -o cat11 will replicate the Catalog cat1 into cat11 directory. It can also regenerate all the UUIDs as required.","title":"trestle replicate"},{"location":"cli/#trestle-split","text":"This command allows users to further decompose a trestle model into additional subcomponents. The following options are currently supported: -f or --file : this is optional and specifies the file path of the json/yaml file containing the elements that will be split. -e or --elements : specifies the model subcomponent element(s) (JSON/YAML property path) that is/are going to be split. Multiple elements can be specified at once using a comma-separated value, e.g -e 'catalog.metadata,catalog.groups' . Make sure to include the quotes that enclose the comma-separated paths. If the element is of JSON/YAML type array list and you want trestle to create a separate subcomponent file per array item, the element needs to be suffixed with .* , e.g. -e 'catalog.groups.*' . If the suffix is not specified, split will place all array items in only one separate subcomponent file, e.g. 'groups.json' . Again, make sure to include the quotes around the elements. If you just want to split a file into all its constituent parts and the file does not contain a simple list of objects, you can still use * and the file will be split into all its non-trivial elements. Thus if you split a catalog with -e catalog.* the result will be a new directory, catalog , containing files representing the large items, back-matter.json, groups.json and metadata.json , but there will still be a catalog.json file containing just the catalog's uuid . Small items such as strings and dates cannot be split off and will remain in the original model file that is being split. Here are some examples. Starting with a single catalog file, my_catalog/catalog.json , if you do trestle split -f catalog.json -e 'catalog.*' you end up with: catalogs \u2517 my_catalog \u2503 \u2523 catalog \u2503 \u2503 \u2523 back-matter.json \u2503 \u2503 \u2523 groups.json \u2503 \u2503 \u2517 metadata.json \u2503 \u2517 catalog.json If you then split roles out of metadata as a single file containing a list of roles, trestle split -f catalog/metadata.json -e 'metadata.roles' you would end up with: catalogs \u2517 my_catalog \u2503 \u2523 catalog \u2503 \u2503 \u2523 metadata \u2503 \u2503 \u2503 \u2517 roles.json \u2503 \u2503 \u2523 back-matter.json \u2503 \u2503 \u2523 groups.json \u2503 \u2503 \u2517 metadata.json \u2503 \u2517 catalog.json If instead you had specified -e 'metadata.roles.*' you would get: my_catalog \u2523 catalog \u2503 \u2523 metadata \u2503 \u2503 \u2517 roles \u2503 \u2503 \u2503 \u2523 00000__role.json \u2503 \u2503 \u2503 \u2517 00001__role.json \u2503 \u2523 back-matter.json \u2503 \u2523 groups.json \u2503 \u2517 metadata.json \u2517 catalog.json You can see there is no roles.json file anymore and instead there is a subdirectory, roles containing a list of files, one for each role . If the -f or --file option is not specified, the file to split will be determined from the elements specified, in the context of the current working directory. The current directory must be within a specific model (e.g. catalog or profile ), and the element paths must either be absolute (e.g. catalog.metadata.roles ) or relative to the current working directory. For example, if you are in catalogs/mycat/catalog/groups and you want to split the file 00000__group.json , you must use -f to specify the filename, and the element path can either be absolute, as catalog.group.* , or you can set the current working directory to where the file is and use element path group.* . This makes it easier to specify splits when deep in a directory structure. Every subdirectory in a trestle directory model should have a corresponding .json or .yaml file with the same name, except when that subdirectory corresponds to a list of items, such as catalog.groups . When those subcomponents are split/expanded each file or subdirectory under them represents an item of the collection. Because of that, if a corresponding groups.json | groups.yaml file were to exist, its contents would just be an empty representation of that collection and the user would need to be careful never to edit that file. Therefore, we decided not to create that corresponding file in those cases. Following the same logic, another exception is when all the fields from a .json | .yaml file are split, leaving the original file as an empty object. In that case, the file would be deleted as well. To inspect a file to see what elements can be split from it, use the describe command described below. It is also useful for inspection of files created by the split operation.","title":"trestle split"},{"location":"cli/#trestle-merge","text":"The trestle merge command is the reversal of trestle split . This command allows users to reverse the decomposition of a trestle model by aggregating subcomponents scattered across multiple files or directories into the parent JSON/YAML file. To merge a model, you have to first change working directory to the root model component directory that you want to merge a sub-component model into. The following option is required: -e or --elements : specifies the properties (JSON/YAML path) that will be merged, relative to the current working directory. This must contain at least 2 elements, where the last element is the model/sub-component to be merged into the second from last component. For example, in the command trestle merge -e 'catalog.metadata' , executed in the same directory where catalog.json or the split catalog directory exists, the property metadata from metadata.json would be moved/merged into catalog.json . If the metadata model has already been split into smaller sub-component models previously, those smaller sub-components are first recusively merged into metadata , before merging metadata subcomponent into catalog . To specify merging every sub-component split from a component, .* can be used. For example, trestle merge -e 'catalog.*' command, issued from the directory where catalog.json or catalog directory exists, will merge every single sub-component of that catalog back into the catalog.json .","title":"trestle merge"},{"location":"cli/#trestle-describe","text":"This command lets users inspect model files to explore contents using an optional element path. The command can work well in concert with split to show what each file contains, and probe within the contents to determine sub-components that can be extracted as separate files. Unlike split, describe only describes the contents of a single item, so the element path may not contain wildcards ( * ) or commas. For example, if a catalog file has been imported to catalogs/my_catalog/catalog.json then the commmand, trestle describe -f catalog.json might yield: #Model file catalog.json is of type catalog.Catalog and contains uuid : 613fca2d-704a-42e7-8e2b-b206fb92b456 metadata : common.Metadata params : None controls : None groups : list of 20 items of type catalog.Group back_matter : common.BackMatter Note that contents are listed even when they are empty (and therefore optional) so the full potential contents can be seen. Also note that if an item corresponds to a list of elements, the number and type of elements is provided. Finally, if an item is a simple string such as id , uuid or title , the string is shown directly up to a maximum of 100 characters. If the string is clipped it will be indicated by [truncated] at the end of the string. An element path can be specified to probe the contents, as in trestle describe -f catalog.json -e 'catalog.metadata.roles' . A possible response is: Model file catalog.json at element path catalog.metadata.roles is a list of 2 items of type common.Role You can also query individual elements, and elements of an element, e.g. trestle describe -f catalog.json -e 'catalog.groups.5.controls.3' # Model file catalog.json at element path catalog.groups.5.controls.3 is of type catalog.Control and contains: id : cp-4 class_ : SP800-53 title : Contingency Plan Testing params : list of 2 items of type common.Parameter props : list of 2 items of type common.Property links : list of 14 items of type common.Link parts : list of 2 items of type common.Part controls : list of 5 items of type catalog.Control (Note that the numbering starts at 0, so the .3 corresponds to the 4th element.) In all output from describe the type of the item shown corresponds to the python file and class of the corresponding OSCAL model in trestle. If you split items off a model so they end up in a subdirectory, the original file is referred to as a \"stripped\" model, with parts of it stripped off and only some elements remaining. For example, if you do trestle split -f catalog.json -e 'catalog.metadata' it will split off metadata from the original catalog.json file and place it in catalog/metadata.json . If you then do trestle describe -f catalog.json on the new file, it will say something like: # Model file catalog.json is of type stripped.Catalog and contains: uuid : 613fca2d-704a-42e7-8e2b-b206fb92b456 params : None controls : None groups : list of 20 items of type catalog.Group back_matter : common.BackMatter Note that the type of the file is now stripped.Catalog and it no longer contains metadata . Even though metadata is no longer in the original .json file, trestle is still aware it is present in the model since it is properly placed as its own file in the subdirectory, catalog .","title":"trestle describe"},{"location":"cli/#trestle-partial-object-validate","text":"OSCAL objects may be extremely large. Some systems may only be able to produce partial OSCAL objects. For example, the tanium-result-to-oscal-ar task produces the results attribute of an assessment-results object. trestle partial-object-validate allows the validation of any sub-element/attribute using element path. Using the example above trestle partial-object-validate -f results.json -e assessment-results.results . The file is not required to be in the trestle directory or required to be a specific file name.","title":"trestle partial-object-validate"},{"location":"cli/#example-valid-element-paths","text":"All element paths must be absolute e.g.: catalog.metadata catalog catalog.groups catalog.groups.group.controls.control.controls.control Remembering in the end you only care about the end type. So in this scenario catalog.groups.group.controls.control.controls.control is equivalent to catalog.controls.control .","title":"Example valid element-paths"},{"location":"cli/#trestle-href","text":"This command changes the href of an Import in a profile and is needed when generating an SSP (system security plan) with the author tool, ssp-generate . The Imports in a profile are used to load associated catalogs of controls and profiles, and must be available at the corresponding href uri. If an imported catalog is in the trestle directory then the href should be changed with a command of the form: trestle href -n my_profile -hr trestle://catalogs/my_catalog/catalog.json Similarly, if the item imported is a profile, a corresponding href should point to a json file in the profiles directory. Note that catalogs or profiles in the trestle directory are indicated by the trestle:// prefix, followed by the path from the top level models directory to the actual catalog file. The profile itself, which is having its imports modified, is just indicated by its name with the -n option. If the profile has more than one import, you can display the corresponding hrefs with: trestle href -n my_profile This will give a numbered list of the hrefs. You can then change them individually by providing the corresponding item number: trestle href -n my_profile -i 1 -hr trestle://catalogs/my_catalog/catalog.json This will change the href indexed as 1 when the list was displayed. The href's are indexed starting from 0. The trestle href command can also be used to change the value back to the intended one prior to distribution of the profile. The provided href can be of form trestle:// , https:// , sftp:// , or file:/// . If file:/// is used, the path provided must be absolute - and on Windows it must include the drive letter followed by a slash. The only time a relative path is allowed is with the trestle:// heading. A username and password may be embedded in the url for https:// , and a CA certificate path will be searched from environment variables REQUESTS_CA_BUNDLE and CURL_CA_BUNDLE in that order. Authorization for sftp:// access relies on the user's private key being either active via ssh-agent or supplied via the environment variable SSH_KEY . In the latter case it must not require a passphrase prompt.","title":"trestle href"},{"location":"cli/#trestle-assemble","text":"This command assembles all contents (files and directories) representing a specific model into a single OSCAL file located under dist folder. For example, $TRESTLE_BASEDIR$ trestle assemble catalog -n nist800-53 will traverse the catalogs/nist800-53 directory and its children and combine all data into a OSCAL file that will be written to dist/catalogs/nist800-53.json . Note that the parts of catalog nist800-53 can be written in either YAML/JSON (e.g. based on the file extension), however, the output will be generated as YAML/JSON as desired. Trestle will infer the content type from the file extension and create the model representation appropriately in memory and then output in the desired format. Trestle assemble will also validate content as it assembles the files and make sure the contents are syntactically correct.","title":"trestle assemble"},{"location":"cli/#trestle-remove","text":"The trestle remove command is the reversal of trestle create -f filename.json -e element_path , as it will remove the corresponding element from the specified file.","title":"trestle remove"},{"location":"cli/#trestle-validate","text":"Trestle validate checks the integrity of one or more OSCAL files in a number of ways. validate returns a non-zero return code if there is any validation problem detected in a file. The current list of validation modes that get checked internally are: Mode Purpose duplicates Detect whether disallowed duplicate uuid's are present oscal_version Confirm that the oscal version of the file is supported refs Confirm that all references in responsible parties are found in roles You can validate a single model file by specifying its full path: trestle validate -f catalogs/my_cat/catalog.json or by specifying its model name and type: trestle validate -t catalog -n my_cat In addition to validating a single file you can validate all files of a given type with the -t option and no file name: trestle validate -t catalog And you can validate all models with the -a option: trestle validate -a Note that when you Import a file it will perform a full validation on it first, and if it does not pass validation the file cannot be imported.","title":"trestle validate"},{"location":"cli/#trestle-tasks","text":"Open Shift Compliance Operator and Tanium are supported as 3rd party tools.","title":"trestle tasks"},{"location":"cli/#trestle-task-osco-result-to-oscal-ar","text":"The trestle task osco-result-to-oscal-ar command facilitates transformation of OpenShift Compliance Operator (OSCO) scan results .yaml files into OSCAL partial results .json files. Specify required config parameters to indicate the location of the input and the output. Specify optional config parameters to indicate the name of the oscal-metadata.yaml file, if any, and whether overwriting of existing output is permitted. Example command invocation: $TRESTLE_BASEDIR$ trestle task osco-result-to-oscal-ar -c /home/user/task.config Example config: /home/user/task.config [task.osco-result-to-oscal-ar] input-dir = /home/user/git/evidence/osco/input output-dir = /home/user/git/evidence/oscal/output oscal-metadata = oscal-metadata.yaml output-overwrite = true input Example input directory contents listing: /home/user/git/evidence/osco/input -rw-rw-r--. 1 user user 3832 Feb 2 09 :36 oscal-metadata.yaml -rw-rw-r--. 1 user user 49132 Feb 2 06 :12 ssg-ocp4-ds-cis-111.222.333.444-pod.yaml -rw-rw-r--. 1 user user 52747 Feb 2 06 :41 ssg-ocp4-ds-cis-111.222.333.555-pod.yaml Example input OSCO scan result file contents (snippet): ssg-ocp4-ds-cis-111.222.333.444-pod.yaml display sample apiVersion : v1 data : exit-code : '2' results : | <?xml version=\"1.0\" encoding=\"UTF-8\"?> <TestResult xmlns=\"https://checklists.nist.gov/xccdf/1.2\" id=\"xccdf_org.open-scap_testresult_xccdf_org.ssgproject.content_profile_cis\" start-time=\"2020-08-03T02:26:26+00:00\" end-time=\"2020-08-03T02:26:26+00:00\" version=\"0.1.52\" test-system=\"cpe:/a:redhat:openscap:1.3.3\"> <benchmark href=\"/content/ssg-ocp4-ds.xml\" id=\"xccdf_org.ssgproject.content_benchmark_OCP-4\"/> <title>OSCAP Scan Result</title> <profile idref=\"xccdf_org.ssgproject.content_profile_cis\"/> <target>kube-br7qsa3d0vceu2so1a90-roksopensca-default-0000026b.iks.mycorp</target> <target-facts> <fact name=\"urn:xccdf:fact:identifier\" type=\"string\">chroot:///host</fact> <fact name=\"urn:xccdf:fact:scanner:name\" type=\"string\">OpenSCAP</fact> <fact name=\"urn:xccdf:fact:scanner:version\" type=\"string\">1.3.3</fact> </target-facts> <target-id-ref system=\"https://scap.nist.gov/schema/asset-identification/1.1\" name=\"asset0\" href=\"\"/> <platform idref=\"cpe:/a:redhat:openshift_container_platform:4.1\"/> <platform idref=\"cpe:/a:machine\"/> <set-value idref=\"xccdf_org.ssgproject.content_value_ocp_data_root\">/kubernetes-api-resources</set-value> <set-value idref=\"xccdf_org.ssgproject.content_value_var_kube_authorization_mode\">Webhook</set-value> <set-value idref=\"xccdf_org.ssgproject.content_value_var_streaming_connection_timeouts\">5m</set-value> <rule-result idref=\"xccdf_org.ssgproject.content_rule_ocp_idp_no_htpasswd\" time=\"2020-08-03T02:26:26+00:00\" severity=\"medium\" weight=\"1.000000\"> <result>notselected</result> <ident system=\"https://nvd.nist.gov/cce/index.cfm\">CCE-84209-6</ident> </rule-result> <rule-result idref=\"xccdf_org.ssgproject.content_rule_accounts_restrict_service_account_tokens\" time=\"2020-08-03T02:26:26+00:00\" severity=\"medium\" weight=\"1.000000\"> <result>notchecked</result> <message severity=\"info\">No candidate or applicable check found.</message> </rule-result> <rule-result idref=\"xccdf_org.ssgproject.content_rule_accounts_unique_service_account\" time=\"2020-08-03T02:26:26+00:00\" severity=\"medium\" weight=\"1.000000\"> <result>notchecked</result> <message severity=\"info\">No candidate or applicable check found.</message> </rule-result> ... </TestResult> kind : ConfigMap metadata : annotations : compliance-remediations/processed : '' compliance.openshift.io/scan-error-msg : '' compliance.openshift.io/scan-result : NON-COMPLIANT openscap-scan-result/node : 111.222.333.444 creationTimestamp : '2020-08-03T02:26:34Z' labels : compliance-scan : ssg-ocp4-ds-cis name : ssg-ocp4-ds-cis-111.222.333.444-pod namespace : openshift-compliance resourceVersion : '22693328' selfLink : /api/v1/namespaces/openshift-compliance/configmaps/ssg-ocp4-ds-cis-111.222.333.444-pod uid : 1da3ea81-0a25-4512-ad86-7ac360246b5d Example input OSCAL metadata file contents: oscal-metadata.yaml display sample ssg-ocp4-ds-cis-111.222.333.444-pod : locker : https://github.mycorp.com/degenaro/evidence-locker namespace : xccdf benchmark : CIS Kubernetes Benchmark subject-references : component : uuid-ref : 56666738-0f9a-4e38-9aac-c0fad00a5821 type : component title : Red Hat OpenShift Kubernetes inventory-item : uuid-ref : 46aADFAC-A1fd-4Cf0-a6aA-d1AfAb3e0d3e type : inventory-item title : Pod properties : target : kube-br7qsa3d0vceu2so1a90-roksopensca-default-0000026b.iks.mycorp target-ip : 111.222.333.444 cluster-name : ROKS-OpenSCAP-1 cluster-type : openshift cluster-region : us-south ssg-rhel7-ds-cis-111.222.333.444-pod : locker : https://github.mycorp.com/degenaro/evidence-locker namespace : xccdf benchmark : CIS Kubernetes Benchmark subject-references : component : uuid-ref : 89cfe7a7-ce6b-4699-aa7b-2f5739c72001 type : component title : RedHat Enterprise Linux 7.8 inventory-item : uuid-ref : 46aADFAC-A1fd-4Cf0-a6aA-d1AfAb3e0d3e type : inventory-item title : VM properties : target : kube-br7qsa3d0vceu2so1a90-roksopensca-default-0000026b.iks.mycorp target-ip : 111.222.333.444 cluster-name : ROKS-OpenSCAP-1 cluster-type : openshift cluster-region : us-south metadata format The oscal-metadata.yaml file comprises one or more mappings. Below is shown the format of a single mapping. The items in angle brackets are to be replaced with desired values for augmenting the produced OSCAL. The mapping whose name matches the [metadata][name] in the evidence for the corresponding embedded XML, if any, will be used for augmenting the produced OSCAL. name : locker : <locker> namespace : <namespace> benchmark : <benchmark> subject-references : component : uuid-ref : <uuid-ref-component> type : <component-type> title : <component-title> inventory-item : uuid-ref : <uuid-ref-inventory-item> type : <inventory-item-type> title : <inventory-item-title> properties : target : <target> cluster-name : <cluster-name> cluster-type : <cluster-type> cluster-region : <cluster-region> output Example output directory contents listing: /home/user/git/evidence/oscal/output -rw-rw-r--. 1 user user 49132 Feb 3 10 :59 ssg-ocp4-ds-cis-111.222.333.444-pod.json -rw-rw-r--. 1 user user 52747 Feb 3 10 :59 ssg-ocp4-ds-cis-111.222.333.555-pod.json Example output OSCAL Observations file contents (snippet): ssg-ocp4-ds-cis-111.222.333.444-pod.json display sample { \"observations\" : [ { \"uuid\" : \"56666738-0f9a-4e38-9aac-c0fad00a5821\" , \"title\" : \"xccdf_org.ssgproject.content_rule_ocp_idp_no_htpasswd\" , \"description\" : \"xccdf_org.ssgproject.content_rule_ocp_idp_no_htpasswd\" , \"props\" : [ { \"name\" : \"benchmark\" , \"ns\" : \"dns://osco\" , \"class\" : \"source\" , \"value\" : \"CIS Kubernetes Benchmark\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"56666738-0f9a-4e38-9aac-c0fad00a5821\" , \"type\" : \"component\" , \"title\" : \"Red Hat OpenShift Kubernetes\" }, { \"uuid-ref\" : \"46aADFAC-A1fd-4Cf0-a6aA-d1AfAb3e0d3e\" , \"type\" : \"inventory-item\" , \"title\" : \"Pod\" , \"props\" : [ { \"name\" : \"target\" , \"ns\" : \"dns://osco\" , \"class\" : \"inventory-item\" , \"value\" : \"kube-br7qsa3d0vceu2so1a90-roksopensca-default-0000026b.iks.mycorp\" }, { \"name\" : \"target-ip\" , \"ns\" : \"dns://osco\" , \"class\" : \"inventory-item\" , \"value\" : \"111.222.333.444\" }, { \"name\" : \"cluster-name\" , \"ns\" : \"dns://osco\" , \"class\" : \"inventory-item\" , \"value\" : \"ROKS-OpenSCAP-1\" }, { \"name\" : \"cluster-type\" , \"ns\" : \"dns://osco\" , \"class\" : \"inventory-item\" , \"value\" : \"openshift\" }, { \"name\" : \"cluster-region\" , \"ns\" : \"dns://osco\" , \"class\" : \"inventory-item\" , \"value\" : \"us-south\" } ] } ], \"relevant-evidence\" : [ { \"href\" : \"https://github.mycorp.com/degenaro/evidence-locker\" , \"description\" : \"Evidence location.\" , \"props\" : [ { \"name\" : \"rule\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"id\" , \"value\" : \"xccdf_org.ssgproject.content_rule_ocp_idp_no_htpasswd\" }, { \"name\" : \"time\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"timestamp\" , \"value\" : \"2020-08-03T02:26:26+00:00\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"result\" , \"value\" : \"notselected\" } ] } ] } ] }","title":"trestle task osco-result-to-oscal-ar"},{"location":"cli/#trestle-task-tanium-result-to-oscal-ar","text":"The trestle task tanium-result-to-oscal-ar command facilitates transformation of Tanuim reports, each input file comprising individual lines consumable as json , into OSCAL partial results .json files. Specify required config parameters to indicate the location of the input and the output. Specify optional config parameter output-overwrite to indicate whether overwriting of existing output is permitted. Specify optional config parameter timestamp as ISO 8601 formated string (e.g., 2021-02-24T19:31:13+00:00) to override the timestamp attached to each Observation. Example command invocation: $TRESTLE_BASEDIR$ trestle task tanium-result-to-oscal-ar -c /home/user/task.config Example config: /home/user/task.config [task.tanium-result-to-oscal-ar] input-dir = /home/user/git/compliance/tanium/input output-dir = /home/user/git/compliance/oscal/output output-overwrite = true input Example input directory contents listing: /home/user/git/compliance/tanium/input -rw-rw-r--. 1 degenaro degenaro 1830 Mar 7 08 :23 Tanium.comply-nist-results Tanium.comply-nist-results display sample { \"IP Address\" : \"fe80::3cd5:564b:940e:49ab\" , \"Computer Name\" : \"cmp-wn-2106.demo.tanium.local\" , \"Comply - JovalCM Results[c2dc8749]\" : [ { \"Benchmark\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"Benchmark Version\" : \"1.5.0.1\" , \"Profile\" : \"Windows 10 - NIST 800-53\" , \"ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1_L1_Ensure_Enforce_password_history_is_set_to_24_or_more_passwords\" , \"Result\" : \"pass\" , \"Custom ID\" : \"800-53: IA-5\" , \"Version\" : \"version: 1\" } ], \"Count\" : \"1\" , \"Age\" : \"600\" } { \"IP Address\" : \"10.8.69.11\" , \"Computer Name\" : \"\" , \"Comply - JovalCM Results[c2dc8749]\" : [ { \"Benchmark\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"Benchmark Version\" : \"1.5.0.1\" , \"Profile\" : \"Windows 10 - NIST 800-53\" , \"ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.2_L1_Ensure_Maximum_password_age_is_set_to_60_or_fewer_days_but_not_0\" , \"Result\" : \"pass\" , \"Custom ID\" : \"800-53: IA-5\" , \"Version\" : \"version: 1\" } ], \"Count\" : \"1\" , \"Age\" : \"600\" } { \"IP Address\" : \"10.8.69.11\" , \"Computer Name\" : \"cmp-wn-2106.demo.tanium.local\" , \"Comply - JovalCM Results[c2dc8749]\" : [ { \"Benchmark\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"Benchmark Version\" : \"1.5.0.1\" , \"Profile\" : \"Windows 10 - NIST 800-53\" , \"ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.3_L1_Ensure_Minimum_password_age_is_set_to_1_or_more_days\" , \"Result\" : \"fail\" , \"Custom ID\" : \"800-53: IA-5\" , \"Version\" : \"version: 1\" } ], \"Count\" : \"1\" , \"Age\" : \"600\" } { \"IP Address\" : \"10.8.69.11\" , \"Computer Name\" : \"cmp-wn-2106.demo.tanium.local\" , \"Comply - JovalCM Results[c2dc8749]\" : [ { \"Benchmark\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"Benchmark Version\" : \"1.5.0.1\" , \"Profile\" : \"Windows 10 - NIST 800-53\" , \"ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.4_L1_Ensure_Minimum_password_length_is_set_to_14_or_more_characters\" , \"Result\" : \"pass\" , \"Custom ID\" : \"800-53: IA-5\" , \"Version\" : \"version: 1\" } ], \"Count\" : \"1\" , \"Age\" : \"600\" } output Example output directory contents listing: /home/user/git/compliance/oscal/output -rw-rw-r--. 1 degenaro degenaro 6479 Mar 7 08 :25 Tanium.oscal.json Tanium.oscal.json display sample { \"results\" : [ { \"uuid\" : \"0ed0791e-5454-4d07-919f-15a0d806a5a8\" , \"title\" : \"Tanium\" , \"description\" : \"Tanium\" , \"start\" : \"2021-04-13T00:16:20.000+00:00\" , \"local-definitions\" : { \"inventory-items\" : [ { \"uuid\" : \"da8b87f6-2068-415f-94bb-e14e31b4f5c2\" , \"description\" : \"inventory\" , \"props\" : [ { \"name\" : \"computer-name\" , \"ns\" : \"dns://tanium\" , \"value\" : \"cmp-wn-2106.demo.tanium.local\" , \"class\" : \" inventory-item\" }, { \"name\" : \"computer-ip\" , \"ns\" : \"dns://tanium\" , \"value\" : \"fe80::3cd5:564b:940e:49ab\" , \"class\" : \" inventory-item\" }, { \"name\" : \"profile\" , \"ns\" : \"dns://tanium\" , \"value\" : \"Windows 10\" , \"class\" : \" inventory-item\" } ] }, { \"uuid\" : \"f3ab87b2-70c1-4332-991e-c003d4314c0b\" , \"description\" : \"inventory\" , \"props\" : [ { \"name\" : \"computer-name\" , \"ns\" : \"dns://tanium\" , \"value\" : \"\" , \"class\" : \" inventory-item\" }, { \"name\" : \"computer-ip\" , \"ns\" : \"dns://tanium\" , \"value\" : \"10.8.69.11\" , \"class\" : \" inventory-item\" }, { \"name\" : \"profile\" , \"ns\" : \"dns://tanium\" , \"value\" : \"Windows 10\" , \"class\" : \" inventory-item\" } ] } ] }, \"reviewed-controls\" : { \"control-selections\" : [ {} ] }, \"observations\" : [ { \"uuid\" : \"b3250b66-fe6f-4ac0-be99-cb4ff093dc31\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1_L1_Ensure_Enforce_password_history_is_set_to_24_or_more_passwords\" , \"props\" : [ { \"name\" : \"benchmark\" , \"ns\" : \"dns://tanium\" , \"value\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"class\" : \"source\" }, { \"name\" : \"rule\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1_L1_Ensure_Enforce_password_history_is_set_to_24_or_more_passwords\" , \"class\" : \"id\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"pass\" , \"class\" : \"result\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"da8b87f6-2068-415f-94bb-e14e31b4f5c2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-04-13T00:16:20.000+00:00\" }, { \"uuid\" : \"5ae9c133-c32d-44c5-b52e-5af4513cb94a\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.2_L1_Ensure_Maximum_password_age_is_set_to_60_or_fewer_days_but_not_0\" , \"props\" : [ { \"name\" : \"benchmark\" , \"ns\" : \"dns://tanium\" , \"value\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"class\" : \"source\" }, { \"name\" : \"rule\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.2_L1_Ensure_Maximum_password_age_is_set_to_60_or_fewer_days_but_not_0\" , \"class\" : \"id\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"pass\" , \"class\" : \"result\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"f3ab87b2-70c1-4332-991e-c003d4314c0b\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-04-13T00:16:20.000+00:00\" }, { \"uuid\" : \"8d021edc-176e-4373-a3c4-a19e954c1e4d\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.3_L1_Ensure_Minimum_password_age_is_set_to_1_or_more_days\" , \"props\" : [ { \"name\" : \"benchmark\" , \"ns\" : \"dns://tanium\" , \"value\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"class\" : \"source\" }, { \"name\" : \"rule\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.3_L1_Ensure_Minimum_password_age_is_set_to_1_or_more_days\" , \"class\" : \"id\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"fail\" , \"class\" : \"result\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"f3ab87b2-70c1-4332-991e-c003d4314c0b\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-04-13T00:16:20.000+00:00\" }, { \"uuid\" : \"36aa7551-d047-4f4a-9853-6ac63cfc9e48\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.4_L1_Ensure_Minimum_password_length_is_set_to_14_or_more_characters\" , \"props\" : [ { \"name\" : \"benchmark\" , \"ns\" : \"dns://tanium\" , \"value\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"class\" : \"source\" }, { \"name\" : \"rule\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.4_L1_Ensure_Minimum_password_length_is_set_to_14_or_more_characters\" , \"class\" : \"id\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"pass\" , \"class\" : \"result\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"f3ab87b2-70c1-4332-991e-c003d4314c0b\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-04-13T00:16:20.000+00:00\" } ], \"findings\" : [ { \"uuid\" : \"ba4e264f-0aee-4ead-9ee3-6161c5cc4ecb\" , \"title\" : \"800-53: IA-5\" , \"description\" : \"800-53: IA-5\" , \"target\" : { \"type\" : \"objective-id\" , \"id-ref\" : \"800-53: IA-5\" , \"props\" : [ { \"name\" : \"profile\" , \"ns\" : \"dns://tanium\" , \"value\" : \"NIST 800-53\" , \"class\" : \"source\" }, { \"name\" : \"id-ref\" , \"ns\" : \"dns://tanium\" , \"value\" : \"800-53: IA-5\" , \"class\" : \"source\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"value\" : \"FAIL\" , \"class\" : \"STRVALUE\" } ], \"status\" : \"not-satisfied\" }, \"related-observations\" : [ { \"observation-uuid\" : \"b3250b66-fe6f-4ac0-be99-cb4ff093dc31\" }, { \"observation-uuid\" : \"5ae9c133-c32d-44c5-b52e-5af4513cb94a\" }, { \"observation-uuid\" : \"8d021edc-176e-4373-a3c4-a19e954c1e4d\" }, { \"observation-uuid\" : \"36aa7551-d047-4f4a-9853-6ac63cfc9e48\" } ] } ] } ] }","title":"trestle task tanium-result-to-oscal-ar"},{"location":"cli/#trestle-task-xlsx-to-oscal-cd","text":"The trestle task xlsx-to-oscal-cd command facilitates transformation of an excel spreadsheet into an OSCAL component-definition.json file. Specify in the config: location of catalog file location of spreadsheet file work sheet name in the spreadsheet file output directory to write the component-definition.json file whether or not to overwrite an existing component-definition.json file the organization name the organization remarks the namespace comma separated mappings from name to class the catalog URL the catalog title Example command invocation: $TRESTLE_BASEDIR$ trestle task xlsx-to-oscal-cd -c /home/user/task-xlsx-to-oscal-cd.config Example config: /home/user/task-xlsx-to-oscal-cd.config [task.xlsx-to-oscal-cd] catalog-file = nist-content/nist.gov/SP800-53/rev4/json/NIST_SP-800-53_rev4_catalog.json spread-sheet-file = /home/user/compliance/data/spread-sheet/good.xlsx work-sheet-name = example_best_practices_controls output-dir = /home/user/compliance/data/tasks/xlsx/output output-overwrite = true org-name = International Business Machines org-remarks = IBM namespace = https://ibm.github.io/compliance-trestle/schemas/oscal/cd/ibm-cloud property-name-to-class = goal_name_id:scc_goal_name_id, goal_version:scc_goal_version catalog-url = https://github.com/usnistgov/oscal-content/blob/master/nist.gov/SP800-53/rev4/json/NIST_SP-800-53_rev4_catalog.json catalog-title = NIST Special Publication 800-53 Revision 4 catalog-file Example catalog-file: nist-content/nist.gov/SP800-53/rev4/json/NIST_SP-800-53_rev4_catalog.json spread-sheet-file Example spread-sheet-file: /home/user/compliance/data/spread-sheet/good.xlsx output Example component-definition.json: /home/user/compliance/data/tasks/xlsx/output/component-definition.json","title":"trestle task xlsx-to-oscal-cd"},{"location":"cli/#spreadsheet-to-component-definition-mapping","text":"display mapping table table, th, td { border: 1px solid black; border-collapse: collapse; } th, td { padding: 5px; } spreadsheet column name component definition path comments ControlId implemented_requirement.property[name='goal_name_id'].value only used if column 'goal_name_id' is empty ControlText implemented_requirement.property[name='goal_name_id'].remarks transformation code replaces \"Check whether\" with \"Ensure\" in text Nist Mappings implemented_requirement.description heading may span multiple columns one value expected per column each entry is separated into control + statements (if any) ResourceTitle component.title component.description component.control-implementation.description + {text} goal_name_id implemented_requirement.property[name='goal_name_id'].value Version implemented_requirement.property[name='goal_version'].value Value from spreadsheet is not currently used. Value '1.0' is hard coded. Parameter [optional parameter] implemented_requirement.set_parameter.param_id The expected text is in two parts separated by '\\n'. The text following the '\\n' is the value used. Values [alternatives] implemented_requirement.set_parameter.values The expected text is of the following format: v0, [v1, v2...] The value v0 is used.","title":"spreadsheet to component definition mapping"},{"location":"cli/#trestle-task-xlsx-to-oscal-profile","text":"The trestle task xlsx-to-oscal-profile command facilitates transformation of an excel spreadsheet into an OSCAL profile.json file. Specify in the config: the href URL of the spreadsheet file system location of spreadsheet file work sheet name in the spreadsheet file output directory to write the profile.json file whether or not to overwrite an existing profile.json file the profile title Example command invocation: $TRESTLE_BASEDIR$ trestle task xlsx-to-oscal-profile -c /home/user/task-xlsx-to-oscal-profile.config Example config: /home/user/task-xlsx-to-oscal-profile.config [task.xlsx-to-oscal-profile] spread-sheet-url = https://github.mycorp.com/spread-sheets/good.xlsx spread-sheet-file = /home/user/compliance/data/spread-sheet/good.xlsx work-sheet-name = example_best_practices_controls output-dir = /home/user/compliance/data/tasks/xlsx/output output-overwrite = true profile-title = IBM Best Practices SCC GOALS spread-sheet-file Example spread-sheet-file: /home/user/compliance/data/spread-sheet/good.xlsx output Example profile.json: /home/user/compliance/data/tasks/xlsx/output/profile.json","title":"trestle task xlsx-to-oscal-profile"},{"location":"demonstrations-content/","text":"Trestle demonstration projects and content \u00a4 Trestle has a number of demonstrations setup in the IBM/compliance-trestle-demos repository which is intended to be a single point of call for demonstrations and content. If you are interested in contributing a demonstration / content open a PR to the demonstration repo and a PR to this page . Demonstrations, where practical, should include instructions on how they were created. Current demonstrations \u00a4 Simple sdk examples. \u00a4 This folder contains a number of small examples for using the trestle OSCAL sdks. Australian government Information Security Manual (ISM) \u00a4 This demonstration uses trestle as an SDK for generating OSCAL files. This demonstration downloads all currently available versions of the Australian Government ISM from ACSC and converts those documents to a set of OSCAL catalogs and profiles. Read more about the demo here . arc42 architectural template enforcement using trestle author. \u00a4 arc42 have created a set of open-source architecture documentation templates. This demonstration uses trestle author to enforce use of the (modified) arc42 templates. A CICD pipeline (using github actions) is used for this demonstration. The full repository, including working CICD is here . Read more about the demo here . Trestle flask microservice demonstration. \u00a4 trestle uses a python library called pydantic to form the underlying OSCAL object models. flask-pydantic introduces a mechanism which integrates pydantic models into flask, providing automated user input validation in one line of code. This demo accepts a catalog as a POSTed object, throwing errors if the catalog does not meet the schema, and returns the catalog in the response. Find the demonstration here . Creating a CIS controls catalog from an excel spreadsheet. \u00a4 The Centre for Internet Security (CIS) produce a number of cross industry standards for IT security including their platform specific benchmarks and a suite of controls . This demo converts a spreadsheet of those controls into a a catalog and three profiles. Creating an SSP using trestle author. \u00a4 trestle author ssp-generate and trestle author ssp-assemble allow users to generate first a set of markdown documents to allow easy editing of control responses and second to reassemble that information up into an OSCAL ssp document. This is a 'baseline' demonstration with more sophisticated updates expected in the near term. Trestle Repository API ( trestle.core.repository ) \u00a4 trestle.core.repository is an API which abstracts users from the file system of a trestle repository. It provides a way for external developers to access a trestle repository without relying on presumptions (such as cwd being within the repository). Find the demo here . Converting a spreadsheet into a component-definition \u00a4 Plenty of compliance content exists today in spreadsheets. This demonstration show how to use the xlsx-to-oscal-component-definition MVP functionality. Task examples \u00a4 Spreadsheet to component definition \u00a4","title":"Demos"},{"location":"demonstrations-content/#trestle-demonstration-projects-and-content","text":"Trestle has a number of demonstrations setup in the IBM/compliance-trestle-demos repository which is intended to be a single point of call for demonstrations and content. If you are interested in contributing a demonstration / content open a PR to the demonstration repo and a PR to this page . Demonstrations, where practical, should include instructions on how they were created.","title":"Trestle demonstration projects and content"},{"location":"demonstrations-content/#current-demonstrations","text":"","title":"Current demonstrations"},{"location":"demonstrations-content/#simple-sdk-examples","text":"This folder contains a number of small examples for using the trestle OSCAL sdks.","title":"Simple sdk examples."},{"location":"demonstrations-content/#australian-government-information-security-manual-ism","text":"This demonstration uses trestle as an SDK for generating OSCAL files. This demonstration downloads all currently available versions of the Australian Government ISM from ACSC and converts those documents to a set of OSCAL catalogs and profiles. Read more about the demo here .","title":"Australian government Information Security Manual (ISM)"},{"location":"demonstrations-content/#arc42-architectural-template-enforcement-using-trestle-author","text":"arc42 have created a set of open-source architecture documentation templates. This demonstration uses trestle author to enforce use of the (modified) arc42 templates. A CICD pipeline (using github actions) is used for this demonstration. The full repository, including working CICD is here . Read more about the demo here .","title":"arc42 architectural template enforcement using trestle author."},{"location":"demonstrations-content/#trestle-flask-microservice-demonstration","text":"trestle uses a python library called pydantic to form the underlying OSCAL object models. flask-pydantic introduces a mechanism which integrates pydantic models into flask, providing automated user input validation in one line of code. This demo accepts a catalog as a POSTed object, throwing errors if the catalog does not meet the schema, and returns the catalog in the response. Find the demonstration here .","title":"Trestle flask microservice demonstration."},{"location":"demonstrations-content/#creating-a-cis-controls-catalog-from-an-excel-spreadsheet","text":"The Centre for Internet Security (CIS) produce a number of cross industry standards for IT security including their platform specific benchmarks and a suite of controls . This demo converts a spreadsheet of those controls into a a catalog and three profiles.","title":"Creating a CIS controls catalog from an excel spreadsheet."},{"location":"demonstrations-content/#creating-an-ssp-using-trestle-author","text":"trestle author ssp-generate and trestle author ssp-assemble allow users to generate first a set of markdown documents to allow easy editing of control responses and second to reassemble that information up into an OSCAL ssp document. This is a 'baseline' demonstration with more sophisticated updates expected in the near term.","title":"Creating an SSP using trestle author."},{"location":"demonstrations-content/#trestle-repository-api-trestlecorerepository","text":"trestle.core.repository is an API which abstracts users from the file system of a trestle repository. It provides a way for external developers to access a trestle repository without relying on presumptions (such as cwd being within the repository). Find the demo here .","title":"Trestle Repository API (trestle.core.repository)"},{"location":"demonstrations-content/#converting-a-spreadsheet-into-a-component-definition","text":"Plenty of compliance content exists today in spreadsheets. This demonstration show how to use the xlsx-to-oscal-component-definition MVP functionality.","title":"Converting a spreadsheet into a component-definition"},{"location":"demonstrations-content/#task-examples","text":"","title":"Task examples"},{"location":"demonstrations-content/#spreadsheet-to-component-definition","text":"","title":"Spreadsheet to component definition"},{"location":"errors/","text":"Known errors and limitations \u00a4 uft-8 encoding only \u00a4 Trestle supports only utf8 as a file text-encoding. If non-utf8 files are encountered, errors will be reported / thrown. Trestle provides a script that may be used to convert files to utf8 in a destructive manner that may change the file contents. WARNING: This script is potentially destructive and may remove / damage content. Ensure you have a backup before use.","title":"Known limitations"},{"location":"errors/#known-errors-and-limitations","text":"","title":"Known errors and limitations"},{"location":"errors/#uft-8-encoding-only","text":"Trestle supports only utf8 as a file text-encoding. If non-utf8 files are encountered, errors will be reported / thrown. Trestle provides a script that may be used to convert files to utf8 in a destructive manner that may change the file contents. WARNING: This script is potentially destructive and may remove / damage content. Ensure you have a backup before use.","title":"uft-8 encoding only"},{"location":"license/","text":"Apache License Version 2.0, January 2004 https://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright [yyyy] [name of copyright owner] Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"maintainers/","text":"{!MAINTAINERS.md!}","title":"Maintainers"},{"location":"mkdocs_code_of_conduct/","text":"Contributor Covenant Code of Conduct \u00a4 Our Pledge \u00a4 In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards \u00a4 Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Our Responsibilities \u00a4 Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope \u00a4 This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement \u00a4 Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at avikas@in.ibm.com . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution \u00a4 This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Code of Conduct"},{"location":"mkdocs_code_of_conduct/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"mkdocs_code_of_conduct/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"mkdocs_code_of_conduct/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"mkdocs_code_of_conduct/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"mkdocs_code_of_conduct/#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"mkdocs_code_of_conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at avikas@in.ibm.com . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"mkdocs_code_of_conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Attribution"},{"location":"python_trestle_setup/","text":"Install trestle in a python virtual environment \u00a4 There are a few things you need to to start using trestle: Make sure you have a working and recent Python environment Set up a Python virtual environment Download and install trestle Confirm it is working properly Create a trestle workspace Confirm you have python installed \u00a4 Ensure you have a modern Python (3.7, 3.8, 3.9). $ python -V Python 3 .8.3 Setup a virtual environment \u00a4 There are many ways to do this on Windows, Mac and Linux and with different Python installations, so please consult the documentation associated with your platform. Below is how it works on a typical Linux platform. $ cd $ python -m venv venv.trestle $ source venv.trestle/bin/activate ( venv.trestle ) $ Ensure you have a modern pip (19.x or greater). ( venv.trestle ) $ python -m pip --version pip 19 .2.3 from /home... You should probably upgrade your pip to the latest version with: ( venv.trestle ) $ python -m pip install --upgrade pip Details can be found at Installation - pip documentation Install trestle \u00a4 Install compliance-trestle . ( venv.trestle ) $ pip install compliance-trestle Looking in indexes: https://pypi.org/simple,... Confirm trestle is installed properly \u00a4 Check trestle viability (and view help). ( venv.trestle ) $ trestle -h usage: trestle [ -h ] { assemble,author,create,describe,href,import,init,merge,partial-object-validate,remove,replicate,split,task,validate,version } ... Full help text Manage OSCAL files in a human friendly manner. positional arguments: { assemble,author,create,describe,href,import,init,merge,partial-object-validate,remove,replicate,split,task,validate,version } assemble Assemble all subcomponents from a specified trestle model into a single JSON/YAML file under dist. author trestle author, a collection of commands for authoring compliance content outside of OSCAL. create Create a sample OSCAL model in trestle project or create new elements within a given model. describe Describe contents of a model file including optional element path. href Change href of import in profile to point to catalog in trestle project. This command is needed when generating an SSP with a profile that imports a catalog from a temporary location different from the final intended location of the catalog. Omit the href argument to see the list of current imports in the profile. import Import an existing full OSCAL model into the trestle project. init Initialize a trestle working directory. merge Merge subcomponents on a trestle model. partial-object-validate Direct validation any oscal object in a file, including list objects. remove Remove a subcomponent to an existing model. replicate Replicate a top level model within the trestle directory structure. split Split subcomponents on a trestle model. task Run arbitrary trestle tasks in a simple and extensible methodology. validate Validate contents of a trestle model in different modes. version Output version info for trestle and OSCAL. optional arguments: -h, --help show this help message and exit Create a trestle workspace \u00a4 Create trestle workspace. ( venv.trestle ) $ mkdir trestle.workspace ( venv.trestle ) $ cd trestle.workspace ( venv.trestle ) $ trestle init Initialized trestle project successfully in /home/<user>/trestle.workspace Congratulations! You now have a working trestle workspace for safe manipulation of OSCAL documents!","title":"Installation"},{"location":"python_trestle_setup/#install-trestle-in-a-python-virtual-environment","text":"There are a few things you need to to start using trestle: Make sure you have a working and recent Python environment Set up a Python virtual environment Download and install trestle Confirm it is working properly Create a trestle workspace","title":"Install trestle in a python virtual environment"},{"location":"python_trestle_setup/#confirm-you-have-python-installed","text":"Ensure you have a modern Python (3.7, 3.8, 3.9). $ python -V Python 3 .8.3","title":"Confirm you have python installed"},{"location":"python_trestle_setup/#setup-a-virtual-environment","text":"There are many ways to do this on Windows, Mac and Linux and with different Python installations, so please consult the documentation associated with your platform. Below is how it works on a typical Linux platform. $ cd $ python -m venv venv.trestle $ source venv.trestle/bin/activate ( venv.trestle ) $ Ensure you have a modern pip (19.x or greater). ( venv.trestle ) $ python -m pip --version pip 19 .2.3 from /home... You should probably upgrade your pip to the latest version with: ( venv.trestle ) $ python -m pip install --upgrade pip Details can be found at Installation - pip documentation","title":"Setup a virtual environment"},{"location":"python_trestle_setup/#install-trestle","text":"Install compliance-trestle . ( venv.trestle ) $ pip install compliance-trestle Looking in indexes: https://pypi.org/simple,...","title":"Install trestle"},{"location":"python_trestle_setup/#confirm-trestle-is-installed-properly","text":"Check trestle viability (and view help). ( venv.trestle ) $ trestle -h usage: trestle [ -h ] { assemble,author,create,describe,href,import,init,merge,partial-object-validate,remove,replicate,split,task,validate,version } ... Full help text Manage OSCAL files in a human friendly manner. positional arguments: { assemble,author,create,describe,href,import,init,merge,partial-object-validate,remove,replicate,split,task,validate,version } assemble Assemble all subcomponents from a specified trestle model into a single JSON/YAML file under dist. author trestle author, a collection of commands for authoring compliance content outside of OSCAL. create Create a sample OSCAL model in trestle project or create new elements within a given model. describe Describe contents of a model file including optional element path. href Change href of import in profile to point to catalog in trestle project. This command is needed when generating an SSP with a profile that imports a catalog from a temporary location different from the final intended location of the catalog. Omit the href argument to see the list of current imports in the profile. import Import an existing full OSCAL model into the trestle project. init Initialize a trestle working directory. merge Merge subcomponents on a trestle model. partial-object-validate Direct validation any oscal object in a file, including list objects. remove Remove a subcomponent to an existing model. replicate Replicate a top level model within the trestle directory structure. split Split subcomponents on a trestle model. task Run arbitrary trestle tasks in a simple and extensible methodology. validate Validate contents of a trestle model in different modes. version Output version info for trestle and OSCAL. optional arguments: -h, --help show this help message and exit","title":"Confirm trestle is installed properly"},{"location":"python_trestle_setup/#create-a-trestle-workspace","text":"Create trestle workspace. ( venv.trestle ) $ mkdir trestle.workspace ( venv.trestle ) $ cd trestle.workspace ( venv.trestle ) $ trestle init Initialized trestle project successfully in /home/<user>/trestle.workspace Congratulations! You now have a working trestle workspace for safe manipulation of OSCAL documents!","title":"Create a trestle workspace"},{"location":"trestle_author/","text":"trestle CLI for governance of authored documents \u00a4 Overview \u00a4 The premise of trestle is to support managing compliance artifacts as code. When this is considered, many organisations using {github|gitlab|bitbucket} rely on markdown documents for documentary artifacts that may either directly or indirectly support compliance efforts. To support this, trestle has the concept of 'governing' documents that are authored documents: Where structural conditions are enforced on the markdown documents to allow automation and to ensure business processes are met. Living in the GitOps world this capability is anchored with markdown files as the core of the workflows. Currently drawio files are also supported for a subset of enforcement mechanisms. Why is this capability in trestle? \u00a4 While trestle provides editing support for OSCAL there is an unfortunate truth that for some compliance workflows: OSCAL does not cover the lower level operational workflows. Some users will not be comfortable editing in json/yaml/xml formats The markdown centric workflows allow transition path where capability is being developed Governance mechanisms \u00a4 Markdown structural enforcement \u00a4 In order for trestle to enforce structure an approach has been taken for how to template markdown documents. There are two mechanism that are enforced: Enforcing a heading structure within the markdown document: Enforcing a structured header within the markdown document either by using yaml headers or a designated heading. For enforcing the heading structure the mechanism used is the following: Markdown headings As an example are considered to be nested based on the heading level (e.g. heading is below top level heading ). For a document to contain the structural requirements it must contain all the headings provided in the template, however, can contain additional nested templates. Given this template: # Template heading 1 # Template heading 2 ## Template sub heading The following document is acceptable: # Template heading 1 Content for heading one ## Non-required sub header Content for non-required sub header # Template heading 2 Content for heading two ## Template sub heading Content for template sub heading ### non required sub-sub heading This sub-sub heading is okay However, violations such as adding or removing a heading at a level that has been templated is not acceptable e.g.: # Template heading 1 Content for heading one ## Non-required sub header Content for non-required sub header # Template heading 2 Content for heading two ## Template sub heading Content for template sub heading ## sub heading that violates template This sub heading is NOT okay # Top level heading that is not okay For each of the headings - the text of the heading is enforced with one caveat: If the template heading text is wrapped in curly brackets {} then the name is not measured e.g. # {Insert title here} . Strict header / heading conformance mechanisms \u00a4 Two mechanisms are provided to enforce metadata within markdown documents. The first is the yaml header, as used by technologies such as jekyll, the second is a markdown 'governed heading` where templating of the content is enforced. Use of the yaml header is strongly encouraged as a first preference. --- yaml: header: - with some - structure more: information --- # The rest of my document The yaml header is structurally enforced my measuring whether the template key structure is reflected in the measured document. It does not measure values for yaml attributes. For the above markdown document the array value for yaml.header could be replaced with a single value or expanded. Enforcing the yaml header is enabled by -hv where available. For enforcing a governed heading the structural enforcement mechanism assumes that the key:value structure simply takes the form that following that for each line of content under the chosen heading the template content is a subset of the measured document, in the order provided in the template. This is performed after removing formatting (such as bolding), and any HTML comments. Given: # heading for strict enforcement my_key: **my_key_2:** my_other key with strange stuff?? The following heading would be acceptable. # heading for strict enforcement my_key: my value my_key_2: my value my_other key with strange stuff?? my value This capability, where available, is activated by --governed-heading or -gh Drawio enforcement mechanisms \u00a4 Drawio or diagrams.net is a diagramming platform which has significant use for architecture diagrams. In the context of governance of content, trestle is supporting enforcement of metadata. Drawio (or mxgraph ) files have a set of data fields. In a drawio file this is available in the edit menu as edit data . The diagram below shows how to access the (meta)data. The data presents as a set of key-value pairs which can be edited (see below). The data is bound to each tab in a drawio file. The trestle CLI currently expects that metadata (whether from the template or file to be measured) is in the first tab when editing the draw io file. trestle author governed-docs \u00a4 author docs is designed to support enforcing and generating templating markdown files within a single folder based on a task name. Currently author docs supports markdown files only. trestle author docs setup -tn my_task_name Create the necessary directory structures for running governed docs validation. A template file will be created in TRESTLE_ROOT/.trestle/author/my_task_name/template.md and be applied to all markdown files here: TRESTLE_ROOT/my_task_name/*.md . trestle author docs create-sample -tn my_task_name Creates a sample file in TRESTLE_ROOT/my_task_name/ trestle author docs template-validate -tn my_task_name Ensures that the markdown is parseable. If --governed-heading 'heading name' is passed it ensures that the required heading exists. trestle author docs validate -tn my_task_name validates the markdown, optionally with a --governed-heading or -hv yaml header based on this TRESTLE_ROOT/.trestle/author/my_task_name/template.md template to all markdown files here: TRESTLE_ROOT/my_task_name/*.md . trestle author docs validate -tn my_task_name -ig ^_.* will validate all files except folders and files that start with underscore _ . Use option -ig or --ignore when you would like to ignore any folders or files that match given regular expression. Extra options \u00a4 recursive ( -r , --recurse ) \u00a4 By default author docs only indexes a flat directory. The recursive option allows the markdown files to be nested in sub-directories. Header only validation ( -hov , --header-only-validate ) \u00a4 Turns off the validation of the structure of the document and only validates the yaml header structure. Ignore files or folders from validation ( -ig , --ignore ) \u00a4 Provide regular expression after this flag to ignore folders and files which names match this regular expression during validation only . Template version tracking ( -tv , --template-version ) \u00a4 This, along with the use of x-trestle-template-version in the governed header allows for repos using author templates to implement support for multiple versions of templates. The x-trestle-template-version header represents the version of the template used to create an instance document. With this change, the Version header specifically refers to the version of that document (be it an instance or the template itself). This means: For a template, if the x-trestle-template-version header exists, then it and the Version header of that template must always match. Further, the template's path needs to include the value stored in the x-trestle-template-version. For an instance, the Version header should not be compared with the Version header of the template. Rather, the x-trestle-template-version header should be compared with the x-trestle-template-version header of the template. trestle author folders \u00a4 author folders is designed to allow the assembly of groups of templates where the folder assembly is the unique instance. Trestle author folders supports validation of both markdown and drawio files. Note that headers / metadata must be specified in each applicable template. For example given the following template setup using trestle author folders setup -tn my_task_2 trestle_root \u2523 .trestle \u2503 \u2523 author \u2503 \u2503 \u2517 my_task_2 \u2503 \u2503 \u2503 \u2523 a_template.md \u2503 \u2503 \u2503 \u2523 another_template.md \u2503 \u2503 \u2503 \u2517 template.drawio \u2503 \u2517 config.ini Each task folder is required to meet template requirements for both a_template.md , another_template.md , and template.drawio . The names, numbers, and nesting of folders is user specifiable, however, unlike docs the names must be carried over to each instances. Following the similar structure of docs , measurement occurs in the my_task_2 where this structure is enforced for every directory. trestle_root \u2523 .trestle \u2523 my_task_2 \u2503 \u2523 User_chosen_name \u2503 \u2503 \u2523 a_template.md \u2503 \u2503 \u2523 template.drawio \u2503 \u2503 \u2517 another_template.md \u2503 \u2517 Second_user_chosen_name \u2503 \u2503 \u2523 a_template.md \u2503 \u2503 \u2523 template.drawio \u2503 \u2503 \u2517 another_template.md trestle author folders validate -tn my_task_name -ig ^_.* will validate all files except folders and files that start with underscore _ . Use option -ig or --ignore when you would like to ignore any folders or files that match given regular expression. Supported options \u00a4 Header validate ( -hv / --header-validate ) \u00a4 Validate the headers in markdown and metadata in drawio files. Header only validation ( -hov , --header-only-validate ) \u00a4 Turns off the validation of the structure of the document and only validates the yaml header structure and drawio files. Ignore files or folders from validation ( -ig , --ignore ) \u00a4 Provide regular expression after this flag to ignore folders and files which names match this regular expression during validation only . Template version tracking ( -tv , --template-version ) \u00a4 This, along with the use of x-trestle-template-version in the governed header allows for repos using author templates to implement support for multiple versions of templates. The x-trestle-template-version header represents the version of the template used to create an instance document. With this change, the Version header specifically refers to the version of that document (be it an instance or the template itself). This means: For a template, if the x-trestle-template-version header exists, then it and the Version header of that template must always match. Further, the template's path needs to include the value stored in the x-trestle-template-version. For an instance, the Version header should not be compared with the Version header of the template. Rather, the x-trestle-template-version header should be compared with the x-trestle-template-version header of the template. trestle author headers \u00a4 Trestle author headers supports a different usecase than that of docs and folders above: some content is governed, however, the content is non-standardized. The result: metadata but not content needs to be measured. author headers provides this functionality for drawio and markdown files. trestle author headers setup -tn my_task_name Create the necessary directory structures for running header only validation. Per supported file type (e.g. drawio and md) a template file will be generated with the format of template.{extension name} e.g. e.g.: trestle_root \u2523 .trestle \u2503 \u2523 author \u2503 \u2503 \u2517 my_task_2 \u2503 \u2503 \u2503 \u2523 template.md \u2503 \u2503 \u2503 \u2517 template.drawio \u2503 \u2517 config.ini trestle author headers template-validate -tn my_task_name Ensures that the respective template files are parseable. trestle author headers validate -tn my_task_name Will validate all files within the directory against the templates by matching the extensions. trestle author headers validate -tn my_task_name -ig ^_.* will validate all files except folders and files that start with underscore _ . Use option -ig or --ignore when you would like to ignore any folders or files that match given regular expression. Supported options \u00a4 Recursive ( -r , --recurse ) \u00a4 By default author headers only indexes a flat directory. The recursive option allows the discovery of sub directories. Global ( -g , --global ) \u00a4 Allows a single set of templates defined in .trestle/author/__global__ to be applied to mulitple directories in trestle. If --task-name is not provided all folders in the repository will be measured. Exclude ( -ex , --exclude ) \u00a4 Primarily intended for use with global ( -g ), exclude will remove any directory from the search scope of trestle author headers. Must be a relative path to the root of a trestle directory, however, can be multiple levels deep (e.g. --exclude=architecture/drafts ) would allow content in architecture/diagrams to still be indexed to find the header. Ignore files or folders from validation ( -ig , --ignore ) \u00a4 Provide regular expression after this flag to ignore folders and files which names match this regular expression during validation only . Template version tracking ( -tv , --template-version ) \u00a4 This, along with the use of x-trestle-template-version in the governed header allows for repos using author templates to implement support for multiple versions of templates. The x-trestle-template-version header represents the version of the template used to create an instance document. With this change, the Version header specifically refers to the version of that document (be it an instance or the template itself). This means: For a template, if the x-trestle-template-version header exists, then it and the Version header of that template must always match. Further, the template's path needs to include the value stored in the x-trestle-template-version. For an instance, the Version header should not be compared with the Version header of the template. Rather, the x-trestle-template-version header should be compared with the x-trestle-template-version header of the template. trestle author catalog-generate and trestle author catalog-assemble \u00a4 The catalog author commands allow you to convert a control catalog to markdown and edit its control statement, then assemble markdown back into an OSCAL catalog with the modifications to the statement. Items in the statement may be edited or added. For more details on its usage please see the ssp authoring tutorial . trestle author profile-generate and trestle author profile-assemble \u00a4 The profile author commands allow you to edit additions made by a profile to its imported controls that end up in the final resolved profile catalog. Only the additions may be edited or added to the generated markdown control files - and those additions can then be assembled into a new version of the original profile, with those additions. For more details on its usage please see the ssp authoring tutorial . trestle author ssp-generate and trestle author ssp-assemble \u00a4 The ssp-generate sub-command creates a partial SSP (System Security Plan) from a profile and optional yaml header file. ssp-assemble can then assemble the markdown files into a single json SSP file. For more details on its usage please see the ssp authoring tutorial . trestle author ssp-filter \u00a4 The ssp-filter sub-command takes a given SSP and filters its contents based on a given profile. The SSP is assumed to contain a superset of controls needed by the profile, and the filter operation generates a new SSP with just the controls needed by that profile. If the profile references a control not in the SSP, the routine fails with an error. For more details on its usage please see the ssp authoring tutorial .","title":"CLI for authoring governed content"},{"location":"trestle_author/#trestle-cli-for-governance-of-authored-documents","text":"","title":"trestle CLI for governance of authored documents"},{"location":"trestle_author/#overview","text":"The premise of trestle is to support managing compliance artifacts as code. When this is considered, many organisations using {github|gitlab|bitbucket} rely on markdown documents for documentary artifacts that may either directly or indirectly support compliance efforts. To support this, trestle has the concept of 'governing' documents that are authored documents: Where structural conditions are enforced on the markdown documents to allow automation and to ensure business processes are met. Living in the GitOps world this capability is anchored with markdown files as the core of the workflows. Currently drawio files are also supported for a subset of enforcement mechanisms.","title":"Overview"},{"location":"trestle_author/#why-is-this-capability-in-trestle","text":"While trestle provides editing support for OSCAL there is an unfortunate truth that for some compliance workflows: OSCAL does not cover the lower level operational workflows. Some users will not be comfortable editing in json/yaml/xml formats The markdown centric workflows allow transition path where capability is being developed","title":"Why is this capability in trestle?"},{"location":"trestle_author/#governance-mechanisms","text":"","title":"Governance mechanisms"},{"location":"trestle_author/#markdown-structural-enforcement","text":"In order for trestle to enforce structure an approach has been taken for how to template markdown documents. There are two mechanism that are enforced: Enforcing a heading structure within the markdown document: Enforcing a structured header within the markdown document either by using yaml headers or a designated heading. For enforcing the heading structure the mechanism used is the following: Markdown headings As an example are considered to be nested based on the heading level (e.g. heading is below top level heading ). For a document to contain the structural requirements it must contain all the headings provided in the template, however, can contain additional nested templates. Given this template: # Template heading 1 # Template heading 2 ## Template sub heading The following document is acceptable: # Template heading 1 Content for heading one ## Non-required sub header Content for non-required sub header # Template heading 2 Content for heading two ## Template sub heading Content for template sub heading ### non required sub-sub heading This sub-sub heading is okay However, violations such as adding or removing a heading at a level that has been templated is not acceptable e.g.: # Template heading 1 Content for heading one ## Non-required sub header Content for non-required sub header # Template heading 2 Content for heading two ## Template sub heading Content for template sub heading ## sub heading that violates template This sub heading is NOT okay # Top level heading that is not okay For each of the headings - the text of the heading is enforced with one caveat: If the template heading text is wrapped in curly brackets {} then the name is not measured e.g. # {Insert title here} .","title":"Markdown structural enforcement"},{"location":"trestle_author/#strict-header-heading-conformance-mechanisms","text":"Two mechanisms are provided to enforce metadata within markdown documents. The first is the yaml header, as used by technologies such as jekyll, the second is a markdown 'governed heading` where templating of the content is enforced. Use of the yaml header is strongly encouraged as a first preference. --- yaml: header: - with some - structure more: information --- # The rest of my document The yaml header is structurally enforced my measuring whether the template key structure is reflected in the measured document. It does not measure values for yaml attributes. For the above markdown document the array value for yaml.header could be replaced with a single value or expanded. Enforcing the yaml header is enabled by -hv where available. For enforcing a governed heading the structural enforcement mechanism assumes that the key:value structure simply takes the form that following that for each line of content under the chosen heading the template content is a subset of the measured document, in the order provided in the template. This is performed after removing formatting (such as bolding), and any HTML comments. Given: # heading for strict enforcement my_key: **my_key_2:** my_other key with strange stuff?? The following heading would be acceptable. # heading for strict enforcement my_key: my value my_key_2: my value my_other key with strange stuff?? my value This capability, where available, is activated by --governed-heading or -gh","title":"Strict header / heading conformance mechanisms"},{"location":"trestle_author/#drawio-enforcement-mechanisms","text":"Drawio or diagrams.net is a diagramming platform which has significant use for architecture diagrams. In the context of governance of content, trestle is supporting enforcement of metadata. Drawio (or mxgraph ) files have a set of data fields. In a drawio file this is available in the edit menu as edit data . The diagram below shows how to access the (meta)data. The data presents as a set of key-value pairs which can be edited (see below). The data is bound to each tab in a drawio file. The trestle CLI currently expects that metadata (whether from the template or file to be measured) is in the first tab when editing the draw io file.","title":"Drawio enforcement mechanisms"},{"location":"trestle_author/#trestle-author-governed-docs","text":"author docs is designed to support enforcing and generating templating markdown files within a single folder based on a task name. Currently author docs supports markdown files only. trestle author docs setup -tn my_task_name Create the necessary directory structures for running governed docs validation. A template file will be created in TRESTLE_ROOT/.trestle/author/my_task_name/template.md and be applied to all markdown files here: TRESTLE_ROOT/my_task_name/*.md . trestle author docs create-sample -tn my_task_name Creates a sample file in TRESTLE_ROOT/my_task_name/ trestle author docs template-validate -tn my_task_name Ensures that the markdown is parseable. If --governed-heading 'heading name' is passed it ensures that the required heading exists. trestle author docs validate -tn my_task_name validates the markdown, optionally with a --governed-heading or -hv yaml header based on this TRESTLE_ROOT/.trestle/author/my_task_name/template.md template to all markdown files here: TRESTLE_ROOT/my_task_name/*.md . trestle author docs validate -tn my_task_name -ig ^_.* will validate all files except folders and files that start with underscore _ . Use option -ig or --ignore when you would like to ignore any folders or files that match given regular expression.","title":"trestle author governed-docs"},{"location":"trestle_author/#extra-options","text":"","title":"Extra options"},{"location":"trestle_author/#recursive-r-recurse","text":"By default author docs only indexes a flat directory. The recursive option allows the markdown files to be nested in sub-directories.","title":"recursive (-r, --recurse)"},{"location":"trestle_author/#header-only-validation-hov-header-only-validate","text":"Turns off the validation of the structure of the document and only validates the yaml header structure.","title":"Header only validation (-hov, --header-only-validate)"},{"location":"trestle_author/#ignore-files-or-folders-from-validation-ig-ignore","text":"Provide regular expression after this flag to ignore folders and files which names match this regular expression during validation only .","title":"Ignore files or folders from validation (-ig, --ignore)"},{"location":"trestle_author/#template-version-tracking-tv-template-version","text":"This, along with the use of x-trestle-template-version in the governed header allows for repos using author templates to implement support for multiple versions of templates. The x-trestle-template-version header represents the version of the template used to create an instance document. With this change, the Version header specifically refers to the version of that document (be it an instance or the template itself). This means: For a template, if the x-trestle-template-version header exists, then it and the Version header of that template must always match. Further, the template's path needs to include the value stored in the x-trestle-template-version. For an instance, the Version header should not be compared with the Version header of the template. Rather, the x-trestle-template-version header should be compared with the x-trestle-template-version header of the template.","title":"Template version tracking (-tv, --template-version)"},{"location":"trestle_author/#trestle-author-folders","text":"author folders is designed to allow the assembly of groups of templates where the folder assembly is the unique instance. Trestle author folders supports validation of both markdown and drawio files. Note that headers / metadata must be specified in each applicable template. For example given the following template setup using trestle author folders setup -tn my_task_2 trestle_root \u2523 .trestle \u2503 \u2523 author \u2503 \u2503 \u2517 my_task_2 \u2503 \u2503 \u2503 \u2523 a_template.md \u2503 \u2503 \u2503 \u2523 another_template.md \u2503 \u2503 \u2503 \u2517 template.drawio \u2503 \u2517 config.ini Each task folder is required to meet template requirements for both a_template.md , another_template.md , and template.drawio . The names, numbers, and nesting of folders is user specifiable, however, unlike docs the names must be carried over to each instances. Following the similar structure of docs , measurement occurs in the my_task_2 where this structure is enforced for every directory. trestle_root \u2523 .trestle \u2523 my_task_2 \u2503 \u2523 User_chosen_name \u2503 \u2503 \u2523 a_template.md \u2503 \u2503 \u2523 template.drawio \u2503 \u2503 \u2517 another_template.md \u2503 \u2517 Second_user_chosen_name \u2503 \u2503 \u2523 a_template.md \u2503 \u2503 \u2523 template.drawio \u2503 \u2503 \u2517 another_template.md trestle author folders validate -tn my_task_name -ig ^_.* will validate all files except folders and files that start with underscore _ . Use option -ig or --ignore when you would like to ignore any folders or files that match given regular expression.","title":"trestle author folders"},{"location":"trestle_author/#supported-options","text":"","title":"Supported options"},{"location":"trestle_author/#header-validate-hv-header-validate","text":"Validate the headers in markdown and metadata in drawio files.","title":"Header validate (-hv/--header-validate)"},{"location":"trestle_author/#header-only-validation-hov-header-only-validate_1","text":"Turns off the validation of the structure of the document and only validates the yaml header structure and drawio files.","title":"Header only validation (-hov, --header-only-validate)"},{"location":"trestle_author/#ignore-files-or-folders-from-validation-ig-ignore_1","text":"Provide regular expression after this flag to ignore folders and files which names match this regular expression during validation only .","title":"Ignore files or folders from validation (-ig, --ignore)"},{"location":"trestle_author/#template-version-tracking-tv-template-version_1","text":"This, along with the use of x-trestle-template-version in the governed header allows for repos using author templates to implement support for multiple versions of templates. The x-trestle-template-version header represents the version of the template used to create an instance document. With this change, the Version header specifically refers to the version of that document (be it an instance or the template itself). This means: For a template, if the x-trestle-template-version header exists, then it and the Version header of that template must always match. Further, the template's path needs to include the value stored in the x-trestle-template-version. For an instance, the Version header should not be compared with the Version header of the template. Rather, the x-trestle-template-version header should be compared with the x-trestle-template-version header of the template.","title":"Template version tracking (-tv, --template-version)"},{"location":"trestle_author/#trestle-author-headers","text":"Trestle author headers supports a different usecase than that of docs and folders above: some content is governed, however, the content is non-standardized. The result: metadata but not content needs to be measured. author headers provides this functionality for drawio and markdown files. trestle author headers setup -tn my_task_name Create the necessary directory structures for running header only validation. Per supported file type (e.g. drawio and md) a template file will be generated with the format of template.{extension name} e.g. e.g.: trestle_root \u2523 .trestle \u2503 \u2523 author \u2503 \u2503 \u2517 my_task_2 \u2503 \u2503 \u2503 \u2523 template.md \u2503 \u2503 \u2503 \u2517 template.drawio \u2503 \u2517 config.ini trestle author headers template-validate -tn my_task_name Ensures that the respective template files are parseable. trestle author headers validate -tn my_task_name Will validate all files within the directory against the templates by matching the extensions. trestle author headers validate -tn my_task_name -ig ^_.* will validate all files except folders and files that start with underscore _ . Use option -ig or --ignore when you would like to ignore any folders or files that match given regular expression.","title":"trestle author headers"},{"location":"trestle_author/#supported-options_1","text":"","title":"Supported options"},{"location":"trestle_author/#recursive-r-recurse_1","text":"By default author headers only indexes a flat directory. The recursive option allows the discovery of sub directories.","title":"Recursive (-r, --recurse)"},{"location":"trestle_author/#global-g-global","text":"Allows a single set of templates defined in .trestle/author/__global__ to be applied to mulitple directories in trestle. If --task-name is not provided all folders in the repository will be measured.","title":"Global (-g, --global)"},{"location":"trestle_author/#exclude-ex-exclude","text":"Primarily intended for use with global ( -g ), exclude will remove any directory from the search scope of trestle author headers. Must be a relative path to the root of a trestle directory, however, can be multiple levels deep (e.g. --exclude=architecture/drafts ) would allow content in architecture/diagrams to still be indexed to find the header.","title":"Exclude (-ex, --exclude)"},{"location":"trestle_author/#ignore-files-or-folders-from-validation-ig-ignore_2","text":"Provide regular expression after this flag to ignore folders and files which names match this regular expression during validation only .","title":"Ignore files or folders from validation (-ig, --ignore)"},{"location":"trestle_author/#template-version-tracking-tv-template-version_2","text":"This, along with the use of x-trestle-template-version in the governed header allows for repos using author templates to implement support for multiple versions of templates. The x-trestle-template-version header represents the version of the template used to create an instance document. With this change, the Version header specifically refers to the version of that document (be it an instance or the template itself). This means: For a template, if the x-trestle-template-version header exists, then it and the Version header of that template must always match. Further, the template's path needs to include the value stored in the x-trestle-template-version. For an instance, the Version header should not be compared with the Version header of the template. Rather, the x-trestle-template-version header should be compared with the x-trestle-template-version header of the template.","title":"Template version tracking (-tv, --template-version)"},{"location":"trestle_author/#trestle-author-catalog-generate-and-trestle-author-catalog-assemble","text":"The catalog author commands allow you to convert a control catalog to markdown and edit its control statement, then assemble markdown back into an OSCAL catalog with the modifications to the statement. Items in the statement may be edited or added. For more details on its usage please see the ssp authoring tutorial .","title":"trestle author catalog-generate and trestle author catalog-assemble"},{"location":"trestle_author/#trestle-author-profile-generate-and-trestle-author-profile-assemble","text":"The profile author commands allow you to edit additions made by a profile to its imported controls that end up in the final resolved profile catalog. Only the additions may be edited or added to the generated markdown control files - and those additions can then be assembled into a new version of the original profile, with those additions. For more details on its usage please see the ssp authoring tutorial .","title":"trestle author profile-generate and trestle author profile-assemble"},{"location":"trestle_author/#trestle-author-ssp-generate-and-trestle-author-ssp-assemble","text":"The ssp-generate sub-command creates a partial SSP (System Security Plan) from a profile and optional yaml header file. ssp-assemble can then assemble the markdown files into a single json SSP file. For more details on its usage please see the ssp authoring tutorial .","title":"trestle author ssp-generate and trestle author ssp-assemble"},{"location":"trestle_author/#trestle-author-ssp-filter","text":"The ssp-filter sub-command takes a given SSP and filters its contents based on a given profile. The SSP is assumed to contain a superset of controls needed by the profile, and the filter operation generates a new SSP with just the controls needed by that profile. If the profile references a control not in the SSP, the routine fails with an error. For more details on its usage please see the ssp authoring tutorial .","title":"trestle author ssp-filter"},{"location":"trestle_author_jinja/","text":"Trestle author jinja - output templating support for oscal documents. \u00a4 Unfortunately OSCAL documents are not yet universally accepted. Therefore to support various OSCAL and non-OSCAL compliance workflows trestle author jinja is designed to provide end users with the ability to use jinja to produce customized output. This complements the more structured commands trestle author catalog-{assemble|generate} , trestle author profile-{assemble|generate} and trestle author ssp-{assemble|generate} and allows arbitrary use of jinja. Jinja and jinja extensions provided by trestle. \u00a4 Jinja is a powerful templating engine that is both more flexible that pure 'Moustache' approaches, and not coupled to a particular web application server (as an example Django templates). Users are encouraged to review the template designer documentation for jinja as all core functionality is exposed. Trestle's implementation of the Jinja command works in the following way: The template search space, by default, is relative to the current working directory. Trestle can inject a lookup table, into the jinja variables to contain booleans / substitutions required by end users using Moustache style variable substitutions. Trestle can provide a number of interfaces to OSCAL objects, currently a resolved catalog and a SSP, into jinja. Trestle supports custom jinja tags for importing. The jinja templating is recursive, to ensure all jinja tags are resolved as appropriate. More details will be on each of these points below. CLI invocation \u00a4 Note the examples here use markdown, however, jinja can quite easily target xml or html if used w/o specific markdown content. trestle author jinja -i input_template.md.jinja -o output_file.md -ssp SSP_NAME -p PROFILE_NAME -lut lookup_table.yaml -elp lut.prefix -i input file path, relative to cwd. Users are encouraged to use the file_name.target_extension.jinja best practice as it helps mitigate issues, however is not required. -o final output path, relative to cwd. -ssp (optional) ssp name (in the trestle project). When used the jinja template will have a ssp_md_writer variable exposed to use. -p (optional) profile name (in the trestle project). When used the jinja template will have resolved_catalog and catalog_interface variables to use. -lut (optional) loads yaml into a dictionary in python for which each (top level) variable is available in jinja. -elp (optional) a period separated prefix for the variables in the lookup table. E.g. if the lut contained banana: yellow and the prefix was fruit.tropical using {{ fruit.tropical.banana }} would print out yellow in the jinja template. -pf (optional) use to provide a custom formatting of the substituted parameters in the text. Use dot (.) to indicate where the parameter value will be written. E.g. -pf *.* to italicize all substituted parameters, -pf Prefix:. to add Prefix: to all parameters. Sample jinja templates \u00a4 Below is a sample jinja template for SSP. template Description Optional args required Simple SSP template Sample ssp jinja template which prints out all control responses and includes a front-matter section -ssp and -p for the ssp json and corresponding profile, respectively. Also requires a frontmatter.md file Variable availability in the jinja template. \u00a4 LUT \u00a4 The lookup table is primarily used for string substitution and to provide variables for basic logic operations in jinja e.g. The LUT: names : OSCAL : Open Security Compliance Assessment Language trestle_pip : compliance-trestle trestle_module : trestle variables : mac_os : true The Jinja template: Install via pip install {{ names.trestle_pip }} and invoke at the python REPL by import {{ names.trestle_module }} {% if variables.mac_os %} Users are recommended to use homebrew to install the latest python 3 and then install python within a venv. {% endif %} The output: Install via pip install compliance-trestle and invoke at the python REPL by import trestle Users are recommended to use homebrew to install the latest python 3 and then install python within a venv. Users are free to use the LUT to inject more complex variables (arrays of data etc) to use at their own will using standard jinja templating. Resolved catalog interface (profile) \u00a4 Passing -p exposes a catalog, resolved from the profile, at catalog and a trestle.core.catalog_interface.CatalogInterface at catalog_interface . This allows user to perform various task such as iterating ove reach group and printing the group title. {% for group in catalog_interface.get_all_groups_from_catalog () + %} ## {{ group.title }} {{ group.class }} \\( {{ group.id | upper }} \\) SSP interface. \u00a4 If -ssp is passed a variable within the jinja template called ssp_md_writer is made available which is an instance of trestle.core.ssp_io.SSPMarkdownWriter . -ssp requires that -p has also been set. This as allows users, as an example to print out a control response, as markdown #### What is the solution and how is it implemented? {{ ssp_md_writer.get_control_response ( 'my_control_id' , 3 ) }} Custom Jinja tags. \u00a4 Trestle provides custom jinja tags for use specifically with markdown: mdsection_include and md_clean_include . md_clean_include is similar to the native {% include 'sub_template' %} that jinja provides except for the following: md_clean_include will look for yaml headers in the markdown content and exclude it from the template md_clean_include can be used with an optional keyword argument heading_level argument {% md_clean_include 'path_to_file.md' heading_level=2 %} The heading level argument adjusts to (based on the number of hashes) the most significant heading in the document, if headings exist. mdsection_include is similar to the native md_clean_include except that.: mdsection_include requires an second positional argument which is the title of a heading, from a markdown file, which you want the content from. E.g: {% mdsection_include 'test_markdown.md' '# Header we want' %} mdsection_include can be used with an optional keyword argument heading_level argument similar to md_clean_include {% mdsection_include 'test_markdown.md' '# Header we want' %} The heading level argument adjusts to (based on the number of hashes) the most significant heading in the chosen section, if headings exist. md_datestamp inserts a date stamp into the output. By default the date is in the format '%Y-%m-%d', e.g. '2021-12-28' and is followed by a double newline to prevent subsequent headings failing to parse correctly. E.g: {% md_datestamp %} results in a date in the format '2021-12-28' being inserted. md_datestamp can be used with the following optional keyword arguments: format where a python datetime strftime format string is provided to format the output. E.g. {% md_datestamp format='%B %d, %Y' %} results in December 28, 2021 being inserted. newline is a boolean to control the addition of a double newline after the inserted date string. For example {% md_datestamp newline=false %} inserts a date in the default format, without additional newlines. Generate controls as individual markdown pages. \u00a4 Trestle's Jinja functionality allows its users to generate individual markdown pages for each control from a resolved profile catalog. Such functionality can be used later on to pack individual pages into docs of various formats. When --docs-profile or -dp flag is provided as part of the trestle author jinja command, the provided Jinja template will be used to generate a markdown page for each control in each group. For example, suppose we would like to generate the markdown page for each control that would contain Control Objective , Control Statement , Expected Evidence , Implementation Guidance and say Table of Parameters used for this control. To achieve that, we can create a simple Jinja template that would be used to generate each page: # Control Page {{ control_writer.write_control_with_sections( control, group_title, ['statement', 'objective', 'expected_evidence', 'implementation_guidance', 'table_of_parameters'], { 'statement':'Control Statement', 'objective':'Control Objective', 'expected_evidence':'Expected Evidence', 'implementation_guidance':'Implementation Guidance', 'table_of_parameters':'Control Parameters' } ) }} The template above, would call a control writer that would print the required sections (specified in the list) with the provided headers (specified in the dictionary). We can then generate individual markdown pages by executing: trestle author jinja -i profile_to_docs.md.jinja -o controls -p some_profile -dp This will create a folder named controls , that would contain a folder per each group and a markdown file per each control in that group. Each markdown file would be formatted using the Jinja template above. The generated markdown files can then be assembled to the docs of the desired format by adding an indexing page.","title":"CLI for jinja template processing"},{"location":"trestle_author_jinja/#trestle-author-jinja-output-templating-support-for-oscal-documents","text":"Unfortunately OSCAL documents are not yet universally accepted. Therefore to support various OSCAL and non-OSCAL compliance workflows trestle author jinja is designed to provide end users with the ability to use jinja to produce customized output. This complements the more structured commands trestle author catalog-{assemble|generate} , trestle author profile-{assemble|generate} and trestle author ssp-{assemble|generate} and allows arbitrary use of jinja.","title":"Trestle author jinja - output templating support for oscal documents."},{"location":"trestle_author_jinja/#jinja-and-jinja-extensions-provided-by-trestle","text":"Jinja is a powerful templating engine that is both more flexible that pure 'Moustache' approaches, and not coupled to a particular web application server (as an example Django templates). Users are encouraged to review the template designer documentation for jinja as all core functionality is exposed. Trestle's implementation of the Jinja command works in the following way: The template search space, by default, is relative to the current working directory. Trestle can inject a lookup table, into the jinja variables to contain booleans / substitutions required by end users using Moustache style variable substitutions. Trestle can provide a number of interfaces to OSCAL objects, currently a resolved catalog and a SSP, into jinja. Trestle supports custom jinja tags for importing. The jinja templating is recursive, to ensure all jinja tags are resolved as appropriate. More details will be on each of these points below.","title":"Jinja and jinja extensions provided by trestle."},{"location":"trestle_author_jinja/#cli-invocation","text":"Note the examples here use markdown, however, jinja can quite easily target xml or html if used w/o specific markdown content. trestle author jinja -i input_template.md.jinja -o output_file.md -ssp SSP_NAME -p PROFILE_NAME -lut lookup_table.yaml -elp lut.prefix -i input file path, relative to cwd. Users are encouraged to use the file_name.target_extension.jinja best practice as it helps mitigate issues, however is not required. -o final output path, relative to cwd. -ssp (optional) ssp name (in the trestle project). When used the jinja template will have a ssp_md_writer variable exposed to use. -p (optional) profile name (in the trestle project). When used the jinja template will have resolved_catalog and catalog_interface variables to use. -lut (optional) loads yaml into a dictionary in python for which each (top level) variable is available in jinja. -elp (optional) a period separated prefix for the variables in the lookup table. E.g. if the lut contained banana: yellow and the prefix was fruit.tropical using {{ fruit.tropical.banana }} would print out yellow in the jinja template. -pf (optional) use to provide a custom formatting of the substituted parameters in the text. Use dot (.) to indicate where the parameter value will be written. E.g. -pf *.* to italicize all substituted parameters, -pf Prefix:. to add Prefix: to all parameters.","title":"CLI invocation"},{"location":"trestle_author_jinja/#sample-jinja-templates","text":"Below is a sample jinja template for SSP. template Description Optional args required Simple SSP template Sample ssp jinja template which prints out all control responses and includes a front-matter section -ssp and -p for the ssp json and corresponding profile, respectively. Also requires a frontmatter.md file","title":"Sample jinja templates"},{"location":"trestle_author_jinja/#variable-availability-in-the-jinja-template","text":"","title":"Variable availability in the jinja template."},{"location":"trestle_author_jinja/#lut","text":"The lookup table is primarily used for string substitution and to provide variables for basic logic operations in jinja e.g. The LUT: names : OSCAL : Open Security Compliance Assessment Language trestle_pip : compliance-trestle trestle_module : trestle variables : mac_os : true The Jinja template: Install via pip install {{ names.trestle_pip }} and invoke at the python REPL by import {{ names.trestle_module }} {% if variables.mac_os %} Users are recommended to use homebrew to install the latest python 3 and then install python within a venv. {% endif %} The output: Install via pip install compliance-trestle and invoke at the python REPL by import trestle Users are recommended to use homebrew to install the latest python 3 and then install python within a venv. Users are free to use the LUT to inject more complex variables (arrays of data etc) to use at their own will using standard jinja templating.","title":"LUT"},{"location":"trestle_author_jinja/#resolved-catalog-interface-profile","text":"Passing -p exposes a catalog, resolved from the profile, at catalog and a trestle.core.catalog_interface.CatalogInterface at catalog_interface . This allows user to perform various task such as iterating ove reach group and printing the group title. {% for group in catalog_interface.get_all_groups_from_catalog () + %} ## {{ group.title }} {{ group.class }} \\( {{ group.id | upper }} \\)","title":"Resolved catalog interface (profile)"},{"location":"trestle_author_jinja/#ssp-interface","text":"If -ssp is passed a variable within the jinja template called ssp_md_writer is made available which is an instance of trestle.core.ssp_io.SSPMarkdownWriter . -ssp requires that -p has also been set. This as allows users, as an example to print out a control response, as markdown #### What is the solution and how is it implemented? {{ ssp_md_writer.get_control_response ( 'my_control_id' , 3 ) }}","title":"SSP interface."},{"location":"trestle_author_jinja/#custom-jinja-tags","text":"Trestle provides custom jinja tags for use specifically with markdown: mdsection_include and md_clean_include . md_clean_include is similar to the native {% include 'sub_template' %} that jinja provides except for the following: md_clean_include will look for yaml headers in the markdown content and exclude it from the template md_clean_include can be used with an optional keyword argument heading_level argument {% md_clean_include 'path_to_file.md' heading_level=2 %} The heading level argument adjusts to (based on the number of hashes) the most significant heading in the document, if headings exist. mdsection_include is similar to the native md_clean_include except that.: mdsection_include requires an second positional argument which is the title of a heading, from a markdown file, which you want the content from. E.g: {% mdsection_include 'test_markdown.md' '# Header we want' %} mdsection_include can be used with an optional keyword argument heading_level argument similar to md_clean_include {% mdsection_include 'test_markdown.md' '# Header we want' %} The heading level argument adjusts to (based on the number of hashes) the most significant heading in the chosen section, if headings exist. md_datestamp inserts a date stamp into the output. By default the date is in the format '%Y-%m-%d', e.g. '2021-12-28' and is followed by a double newline to prevent subsequent headings failing to parse correctly. E.g: {% md_datestamp %} results in a date in the format '2021-12-28' being inserted. md_datestamp can be used with the following optional keyword arguments: format where a python datetime strftime format string is provided to format the output. E.g. {% md_datestamp format='%B %d, %Y' %} results in December 28, 2021 being inserted. newline is a boolean to control the addition of a double newline after the inserted date string. For example {% md_datestamp newline=false %} inserts a date in the default format, without additional newlines.","title":"Custom Jinja tags."},{"location":"trestle_author_jinja/#generate-controls-as-individual-markdown-pages","text":"Trestle's Jinja functionality allows its users to generate individual markdown pages for each control from a resolved profile catalog. Such functionality can be used later on to pack individual pages into docs of various formats. When --docs-profile or -dp flag is provided as part of the trestle author jinja command, the provided Jinja template will be used to generate a markdown page for each control in each group. For example, suppose we would like to generate the markdown page for each control that would contain Control Objective , Control Statement , Expected Evidence , Implementation Guidance and say Table of Parameters used for this control. To achieve that, we can create a simple Jinja template that would be used to generate each page: # Control Page {{ control_writer.write_control_with_sections( control, group_title, ['statement', 'objective', 'expected_evidence', 'implementation_guidance', 'table_of_parameters'], { 'statement':'Control Statement', 'objective':'Control Objective', 'expected_evidence':'Expected Evidence', 'implementation_guidance':'Implementation Guidance', 'table_of_parameters':'Control Parameters' } ) }} The template above, would call a control writer that would print the required sections (specified in the list) with the provided headers (specified in the dictionary). We can then generate individual markdown pages by executing: trestle author jinja -i profile_to_docs.md.jinja -o controls -p some_profile -dp This will create a folder named controls , that would contain a folder per each group and a markdown file per each control in that group. Each markdown file would be formatted using the Jinja template above. The generated markdown files can then be assembled to the docs of the desired format by adding an indexing page.","title":"Generate controls as individual markdown pages."},{"location":"api_reference/trestle.cli/","text":"trestle.cli \u00a4 Starting point for the Trestle CLI. logger \u00a4 Classes \u00a4 Trestle ( CommandBase ) \u00a4 Manage OSCAL files in a human friendly manner. Source code in trestle/cli.py class Trestle ( CommandBase ): \"\"\"Manage OSCAL files in a human friendly manner.\"\"\" subcommands = [ AssembleCmd , AuthorCmd , CreateCmd , DescribeCmd , HrefCmd , ImportCmd , InitCmd , MergeCmd , PartialObjectValidate , RemoveCmd , ReplicateCmd , SplitCmd , TaskCmd , ValidateCmd , VersionCmd ] discovered_plugins = { name : importlib . import_module ( name ) for finder , name , ispkg in pkgutil . iter_modules () if name . startswith ( 'trestle_' ) } logger . debug ( discovered_plugins ) # This block is uncovered as trestle cannot find plugins in it's unit tests - it is the base module. for plugin , value in discovered_plugins . items (): # pragma: nocover for _ , module , _ in pkgutil . iter_modules ([ pathlib . Path ( value . __path__ [ 0 ], 'commands' )]): logger . debug ( module ) command_module = importlib . import_module ( f ' { plugin } .commands. { module } ' ) clsmembers = inspect . getmembers ( command_module , inspect . isclass ) logger . debug ( clsmembers ) for _ , cmd_cls in clsmembers : # add commands (derived from CommandPlusDocs or CommandBase) to subcommands list if issubclass ( cmd_cls , CommandBase ): # don't add CommandPlusDocs or CommandBase if cmd_cls is not CommandPlusDocs and cmd_cls is not CommandBase : subcommands . append ( cmd_cls ) logger . info ( f ' { cmd_cls } added to subcommands from plugin { plugin } ' ) def _init_arguments ( self ) -> None : self . add_argument ( '-v' , '--verbose' , help = const . DISPLAY_VERBOSE_OUTPUT , action = 'count' , default = 0 ) self . add_argument ( '-tr' , '--trestle-root' , help = 'Path of trestle root dir' , type = pathlib . Path , default = pathlib . Path . cwd () ) discovered_plugins \u00a4 subcommands \u00a4 Functions \u00a4 run () \u00a4 Run the trestle cli. Source code in trestle/cli.py def run () -> None : \"\"\"Run the trestle cli.\"\"\" log . set_global_logging_levels () logger . debug ( 'Main entry point.' ) exit ( Trestle () . run ()) handler: python","title":"cli"},{"location":"api_reference/trestle.cli/#trestle.cli","text":"Starting point for the Trestle CLI.","title":"cli"},{"location":"api_reference/trestle.cli/#trestle.cli.logger","text":"","title":"logger"},{"location":"api_reference/trestle.cli/#trestle.cli-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.cli/#trestle.cli.Trestle","text":"Manage OSCAL files in a human friendly manner. Source code in trestle/cli.py class Trestle ( CommandBase ): \"\"\"Manage OSCAL files in a human friendly manner.\"\"\" subcommands = [ AssembleCmd , AuthorCmd , CreateCmd , DescribeCmd , HrefCmd , ImportCmd , InitCmd , MergeCmd , PartialObjectValidate , RemoveCmd , ReplicateCmd , SplitCmd , TaskCmd , ValidateCmd , VersionCmd ] discovered_plugins = { name : importlib . import_module ( name ) for finder , name , ispkg in pkgutil . iter_modules () if name . startswith ( 'trestle_' ) } logger . debug ( discovered_plugins ) # This block is uncovered as trestle cannot find plugins in it's unit tests - it is the base module. for plugin , value in discovered_plugins . items (): # pragma: nocover for _ , module , _ in pkgutil . iter_modules ([ pathlib . Path ( value . __path__ [ 0 ], 'commands' )]): logger . debug ( module ) command_module = importlib . import_module ( f ' { plugin } .commands. { module } ' ) clsmembers = inspect . getmembers ( command_module , inspect . isclass ) logger . debug ( clsmembers ) for _ , cmd_cls in clsmembers : # add commands (derived from CommandPlusDocs or CommandBase) to subcommands list if issubclass ( cmd_cls , CommandBase ): # don't add CommandPlusDocs or CommandBase if cmd_cls is not CommandPlusDocs and cmd_cls is not CommandBase : subcommands . append ( cmd_cls ) logger . info ( f ' { cmd_cls } added to subcommands from plugin { plugin } ' ) def _init_arguments ( self ) -> None : self . add_argument ( '-v' , '--verbose' , help = const . DISPLAY_VERBOSE_OUTPUT , action = 'count' , default = 0 ) self . add_argument ( '-tr' , '--trestle-root' , help = 'Path of trestle root dir' , type = pathlib . Path , default = pathlib . Path . cwd () )","title":"Trestle"},{"location":"api_reference/trestle.cli/#trestle.cli.Trestle.discovered_plugins","text":"","title":"discovered_plugins"},{"location":"api_reference/trestle.cli/#trestle.cli.Trestle.subcommands","text":"","title":"subcommands"},{"location":"api_reference/trestle.cli/#trestle.cli-functions","text":"","title":"Functions"},{"location":"api_reference/trestle.cli/#trestle.cli.run","text":"Run the trestle cli. Source code in trestle/cli.py def run () -> None : \"\"\"Run the trestle cli.\"\"\" log . set_global_logging_levels () logger . debug ( 'Main entry point.' ) exit ( Trestle () . run ()) handler: python","title":"run()"},{"location":"api_reference/trestle.common.common_types/","text":"trestle.common.common_types \u00a4 Special types are defined here. FixedUuidModel \u00a4 OBT \u00a4 TG \u00a4 TopLevelOscalModel \u00a4 handler: python","title":"common_types"},{"location":"api_reference/trestle.common.common_types/#trestle.common.common_types","text":"Special types are defined here.","title":"common_types"},{"location":"api_reference/trestle.common.common_types/#trestle.common.common_types.FixedUuidModel","text":"","title":"FixedUuidModel"},{"location":"api_reference/trestle.common.common_types/#trestle.common.common_types.OBT","text":"","title":"OBT"},{"location":"api_reference/trestle.common.common_types/#trestle.common.common_types.TG","text":"","title":"TG"},{"location":"api_reference/trestle.common.common_types/#trestle.common.common_types.TopLevelOscalModel","text":"handler: python","title":"TopLevelOscalModel"},{"location":"api_reference/trestle.common.const/","text":"trestle.common.const \u00a4 Core constants module containing all constants. Attributes \u00a4 ALIAS_PATH_SEPARATOR : str \u00a4 ALLOWED_EXTENSIONS_IN_DIRS \u00a4 ARG_DESC_ELEMENT \u00a4 ARG_DESC_FILE \u00a4 ARG_DESC_ITEM \u00a4 ARG_DESC_MODE \u00a4 ARG_ELEMENT \u00a4 ARG_ELEMENT_SHORT \u00a4 ARG_FILE \u00a4 ARG_FILE_SHORT \u00a4 ARG_ITEM \u00a4 ARG_ITEM_SHORT \u00a4 ARG_MODE \u00a4 ARG_MODE_SHORT \u00a4 ARG_VALIDATE \u00a4 ARG_VALIDATE_SHORT \u00a4 BUG_REPORT \u00a4 CACHE_ABS_DIR \u00a4 COMPLETION_DATE \u00a4 CONTROL_ORIGINATION \u00a4 DAY_SECONDS : int \u00a4 DISPLAY_VERBOSE_OUTPUT \u00a4 EDITABLE_CONTENT \u00a4 ELEMENT_WILDCARD \u00a4 FIELDS_SET \u00a4 FILE_DIGIT_PREFIX_LENGTH \u00a4 FILE_ENCODING \u00a4 FILE_URI \u00a4 FILTER_BY_COMPONENTS \u00a4 FILTER_BY_PROFILE \u00a4 FILTER_EXCLUDE_COMPONENTS \u00a4 GENERATE_RESOLVED_CATALOG \u00a4 HELP_ALLOWED_SECTIONS \u00a4 HELP_MARKDOWN_NAME \u00a4 HELP_OVERWRITE_HEADER_VALUES \u00a4 HELP_REGENERATE \u00a4 HELP_REQUIRED_SECTIONS \u00a4 HELP_SECTIONS \u00a4 HELP_SET_PARAMS \u00a4 HELP_VERSION \u00a4 HELP_YAML_PATH \u00a4 HOUR_SECONDS : int \u00a4 HTTPS_URI \u00a4 IDX_SEP \u00a4 IMPLEMENTATION_STATUS \u00a4 INHERITED \u00a4 IOF_HELP \u00a4 IOF_LONG \u00a4 IOF_SHORT \u00a4 LEV_AUTH_UUID \u00a4 MARKDOWN_URL_REGEX \u00a4 MODEL_DIR_A_PLAN \u00a4 MODEL_DIR_A_RESULT \u00a4 MODEL_DIR_CATALOG \u00a4 MODEL_DIR_COMPDEF \u00a4 MODEL_DIR_LIST \u00a4 MODEL_DIR_POAM \u00a4 MODEL_DIR_PROFILE \u00a4 MODEL_DIR_SSP \u00a4 MODEL_DIR_TO_MODEL_MODULE \u00a4 Map of model type to oscal module. MODEL_MODULE_A_PLAN \u00a4 MODEL_MODULE_A_RESULT \u00a4 MODEL_MODULE_CATALOG \u00a4 MODEL_MODULE_COMPDEF \u00a4 MODEL_MODULE_LIST \u00a4 Map of plural form of a model type to the oscal module that contains the classes related to it. MODEL_MODULE_POAM \u00a4 MODEL_MODULE_PROFILE \u00a4 MODEL_MODULE_SSP \u00a4 MODEL_MODULE_TO_MODEL_TYPE \u00a4 Map of model type to model directory. MODEL_TYPE_A_PLAN \u00a4 MODEL_TYPE_A_RESULT \u00a4 MODEL_TYPE_CATALOG \u00a4 MODEL_TYPE_COMPDEF \u00a4 MODEL_TYPE_LIST \u00a4 MODEL_TYPE_POAM \u00a4 MODEL_TYPE_PROFILE \u00a4 MODEL_TYPE_SSP \u00a4 MODEL_TYPE_TO_MODEL_DIR \u00a4 Element path separator MODEL_TYPE_TO_MODEL_MODULE \u00a4 Map of model module to model type. MODULE_NAME_A_PLAN \u00a4 MODULE_NAME_A_RESULT \u00a4 MODULE_NAME_CATALOG \u00a4 MODULE_NAME_COMPDEF \u00a4 MODULE_NAME_POAM \u00a4 MODULE_NAME_PROFILE \u00a4 MODULE_NAME_SSP \u00a4 NAMESPACE_FEDRAMP \u00a4 NCNAME_REGEX \u00a4 NCNAME_UTF8_FIRST_CHAR_OPTIONS \u00a4 NCNAME_UTF8_OTHER_CHAR_OPTIONS \u00a4 PACKAGE_OSCAL \u00a4 PLANNED \u00a4 PLANNED_COMPLETION_DATE \u00a4 PROFILE_ADD_REQUIRED_SECTION_FOR_CONTROL_TEXT \u00a4 PROFILE_VALUES \u00a4 RESPONSIBLE_ROLE \u00a4 RESPONSIBLE_ROLES \u00a4 ROOT \u00a4 SAMPLE_UUID_STR \u00a4 SECTIONS_TAG \u00a4 SET_PARAMS_TAG \u00a4 SFTP_URI \u00a4 SORT_ID \u00a4 SSP_ADD_IMPLEMENTATION_FOR_CONTROL_TEXT \u00a4 SSP_ADD_IMPLEMENTATION_FOR_ITEM_TEXT \u00a4 SSP_ADD_IMPLEMENTATION_FOR_STATEMENT_TEXT \u00a4 SSP_ADD_IMPLEMENTATION_PREFIX \u00a4 SSP_FEDRAMP_TAG \u00a4 SSP_MAIN_COMP_NAME \u00a4 SSP_MD_HRULE_LINE \u00a4 SSP_MD_IMPLEMENTATION_QUESTION \u00a4 SSP_MD_LEAVE_BLANK_TEXT \u00a4 SSP_SYSTEM_CONTROL_IMPLEMENTATION_TEXT \u00a4 TRANSFORM_TYPES \u00a4 TRESTLE_CACHE_DIR \u00a4 TRESTLE_CONFIG_DIR \u00a4 TRESTLE_CONFIG_FILE \u00a4 TRESTLE_DIST_DIR \u00a4 TRESTLE_HREF_HEADING \u00a4 TRESTLE_HREF_REGEX \u00a4 TRESTLE_KEEP_FILE \u00a4 TRESTLE_TAG \u00a4 UNIX_CACHE_ROOT \u00a4 UUID_REGEX \u00a4 VALUES \u00a4 VAL_MODE_ALL \u00a4 VAL_MODE_DUPLICATES \u00a4 VAL_MODE_OSCAL_VERSION \u00a4 VAL_MODE_REFS \u00a4 WEBSITE_ROOT \u00a4 WINDOWS_DRIVE_LETTER_REGEX \u00a4 WINDOWS_DRIVE_URI_REGEX \u00a4 WINDOWS_PLATFORM_STR \u00a4 handler: python","title":"const"},{"location":"api_reference/trestle.common.const/#trestle.common.const","text":"Core constants module containing all constants.","title":"const"},{"location":"api_reference/trestle.common.const/#trestle.common.const-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ALIAS_PATH_SEPARATOR","text":"","title":"ALIAS_PATH_SEPARATOR"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ALLOWED_EXTENSIONS_IN_DIRS","text":"","title":"ALLOWED_EXTENSIONS_IN_DIRS"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ARG_DESC_ELEMENT","text":"","title":"ARG_DESC_ELEMENT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ARG_DESC_FILE","text":"","title":"ARG_DESC_FILE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ARG_DESC_ITEM","text":"","title":"ARG_DESC_ITEM"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ARG_DESC_MODE","text":"","title":"ARG_DESC_MODE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ARG_ELEMENT","text":"","title":"ARG_ELEMENT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ARG_ELEMENT_SHORT","text":"","title":"ARG_ELEMENT_SHORT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ARG_FILE","text":"","title":"ARG_FILE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ARG_FILE_SHORT","text":"","title":"ARG_FILE_SHORT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ARG_ITEM","text":"","title":"ARG_ITEM"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ARG_ITEM_SHORT","text":"","title":"ARG_ITEM_SHORT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ARG_MODE","text":"","title":"ARG_MODE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ARG_MODE_SHORT","text":"","title":"ARG_MODE_SHORT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ARG_VALIDATE","text":"","title":"ARG_VALIDATE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ARG_VALIDATE_SHORT","text":"","title":"ARG_VALIDATE_SHORT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.BUG_REPORT","text":"","title":"BUG_REPORT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.CACHE_ABS_DIR","text":"","title":"CACHE_ABS_DIR"},{"location":"api_reference/trestle.common.const/#trestle.common.const.COMPLETION_DATE","text":"","title":"COMPLETION_DATE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.CONTROL_ORIGINATION","text":"","title":"CONTROL_ORIGINATION"},{"location":"api_reference/trestle.common.const/#trestle.common.const.DAY_SECONDS","text":"","title":"DAY_SECONDS"},{"location":"api_reference/trestle.common.const/#trestle.common.const.DISPLAY_VERBOSE_OUTPUT","text":"","title":"DISPLAY_VERBOSE_OUTPUT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.EDITABLE_CONTENT","text":"","title":"EDITABLE_CONTENT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ELEMENT_WILDCARD","text":"","title":"ELEMENT_WILDCARD"},{"location":"api_reference/trestle.common.const/#trestle.common.const.FIELDS_SET","text":"","title":"FIELDS_SET"},{"location":"api_reference/trestle.common.const/#trestle.common.const.FILE_DIGIT_PREFIX_LENGTH","text":"","title":"FILE_DIGIT_PREFIX_LENGTH"},{"location":"api_reference/trestle.common.const/#trestle.common.const.FILE_ENCODING","text":"","title":"FILE_ENCODING"},{"location":"api_reference/trestle.common.const/#trestle.common.const.FILE_URI","text":"","title":"FILE_URI"},{"location":"api_reference/trestle.common.const/#trestle.common.const.FILTER_BY_COMPONENTS","text":"","title":"FILTER_BY_COMPONENTS"},{"location":"api_reference/trestle.common.const/#trestle.common.const.FILTER_BY_PROFILE","text":"","title":"FILTER_BY_PROFILE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.FILTER_EXCLUDE_COMPONENTS","text":"","title":"FILTER_EXCLUDE_COMPONENTS"},{"location":"api_reference/trestle.common.const/#trestle.common.const.GENERATE_RESOLVED_CATALOG","text":"","title":"GENERATE_RESOLVED_CATALOG"},{"location":"api_reference/trestle.common.const/#trestle.common.const.HELP_ALLOWED_SECTIONS","text":"","title":"HELP_ALLOWED_SECTIONS"},{"location":"api_reference/trestle.common.const/#trestle.common.const.HELP_MARKDOWN_NAME","text":"","title":"HELP_MARKDOWN_NAME"},{"location":"api_reference/trestle.common.const/#trestle.common.const.HELP_OVERWRITE_HEADER_VALUES","text":"","title":"HELP_OVERWRITE_HEADER_VALUES"},{"location":"api_reference/trestle.common.const/#trestle.common.const.HELP_REGENERATE","text":"","title":"HELP_REGENERATE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.HELP_REQUIRED_SECTIONS","text":"","title":"HELP_REQUIRED_SECTIONS"},{"location":"api_reference/trestle.common.const/#trestle.common.const.HELP_SECTIONS","text":"","title":"HELP_SECTIONS"},{"location":"api_reference/trestle.common.const/#trestle.common.const.HELP_SET_PARAMS","text":"","title":"HELP_SET_PARAMS"},{"location":"api_reference/trestle.common.const/#trestle.common.const.HELP_VERSION","text":"","title":"HELP_VERSION"},{"location":"api_reference/trestle.common.const/#trestle.common.const.HELP_YAML_PATH","text":"","title":"HELP_YAML_PATH"},{"location":"api_reference/trestle.common.const/#trestle.common.const.HOUR_SECONDS","text":"","title":"HOUR_SECONDS"},{"location":"api_reference/trestle.common.const/#trestle.common.const.HTTPS_URI","text":"","title":"HTTPS_URI"},{"location":"api_reference/trestle.common.const/#trestle.common.const.IDX_SEP","text":"","title":"IDX_SEP"},{"location":"api_reference/trestle.common.const/#trestle.common.const.IMPLEMENTATION_STATUS","text":"","title":"IMPLEMENTATION_STATUS"},{"location":"api_reference/trestle.common.const/#trestle.common.const.INHERITED","text":"","title":"INHERITED"},{"location":"api_reference/trestle.common.const/#trestle.common.const.IOF_HELP","text":"","title":"IOF_HELP"},{"location":"api_reference/trestle.common.const/#trestle.common.const.IOF_LONG","text":"","title":"IOF_LONG"},{"location":"api_reference/trestle.common.const/#trestle.common.const.IOF_SHORT","text":"","title":"IOF_SHORT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.LEV_AUTH_UUID","text":"","title":"LEV_AUTH_UUID"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MARKDOWN_URL_REGEX","text":"","title":"MARKDOWN_URL_REGEX"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_DIR_A_PLAN","text":"","title":"MODEL_DIR_A_PLAN"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_DIR_A_RESULT","text":"","title":"MODEL_DIR_A_RESULT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_DIR_CATALOG","text":"","title":"MODEL_DIR_CATALOG"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_DIR_COMPDEF","text":"","title":"MODEL_DIR_COMPDEF"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_DIR_LIST","text":"","title":"MODEL_DIR_LIST"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_DIR_POAM","text":"","title":"MODEL_DIR_POAM"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_DIR_PROFILE","text":"","title":"MODEL_DIR_PROFILE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_DIR_SSP","text":"","title":"MODEL_DIR_SSP"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_DIR_TO_MODEL_MODULE","text":"Map of model type to oscal module.","title":"MODEL_DIR_TO_MODEL_MODULE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_MODULE_A_PLAN","text":"","title":"MODEL_MODULE_A_PLAN"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_MODULE_A_RESULT","text":"","title":"MODEL_MODULE_A_RESULT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_MODULE_CATALOG","text":"","title":"MODEL_MODULE_CATALOG"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_MODULE_COMPDEF","text":"","title":"MODEL_MODULE_COMPDEF"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_MODULE_LIST","text":"Map of plural form of a model type to the oscal module that contains the classes related to it.","title":"MODEL_MODULE_LIST"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_MODULE_POAM","text":"","title":"MODEL_MODULE_POAM"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_MODULE_PROFILE","text":"","title":"MODEL_MODULE_PROFILE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_MODULE_SSP","text":"","title":"MODEL_MODULE_SSP"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_MODULE_TO_MODEL_TYPE","text":"Map of model type to model directory.","title":"MODEL_MODULE_TO_MODEL_TYPE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_TYPE_A_PLAN","text":"","title":"MODEL_TYPE_A_PLAN"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_TYPE_A_RESULT","text":"","title":"MODEL_TYPE_A_RESULT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_TYPE_CATALOG","text":"","title":"MODEL_TYPE_CATALOG"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_TYPE_COMPDEF","text":"","title":"MODEL_TYPE_COMPDEF"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_TYPE_LIST","text":"","title":"MODEL_TYPE_LIST"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_TYPE_POAM","text":"","title":"MODEL_TYPE_POAM"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_TYPE_PROFILE","text":"","title":"MODEL_TYPE_PROFILE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_TYPE_SSP","text":"","title":"MODEL_TYPE_SSP"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_TYPE_TO_MODEL_DIR","text":"Element path separator","title":"MODEL_TYPE_TO_MODEL_DIR"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODEL_TYPE_TO_MODEL_MODULE","text":"Map of model module to model type.","title":"MODEL_TYPE_TO_MODEL_MODULE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODULE_NAME_A_PLAN","text":"","title":"MODULE_NAME_A_PLAN"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODULE_NAME_A_RESULT","text":"","title":"MODULE_NAME_A_RESULT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODULE_NAME_CATALOG","text":"","title":"MODULE_NAME_CATALOG"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODULE_NAME_COMPDEF","text":"","title":"MODULE_NAME_COMPDEF"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODULE_NAME_POAM","text":"","title":"MODULE_NAME_POAM"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODULE_NAME_PROFILE","text":"","title":"MODULE_NAME_PROFILE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.MODULE_NAME_SSP","text":"","title":"MODULE_NAME_SSP"},{"location":"api_reference/trestle.common.const/#trestle.common.const.NAMESPACE_FEDRAMP","text":"","title":"NAMESPACE_FEDRAMP"},{"location":"api_reference/trestle.common.const/#trestle.common.const.NCNAME_REGEX","text":"","title":"NCNAME_REGEX"},{"location":"api_reference/trestle.common.const/#trestle.common.const.NCNAME_UTF8_FIRST_CHAR_OPTIONS","text":"","title":"NCNAME_UTF8_FIRST_CHAR_OPTIONS"},{"location":"api_reference/trestle.common.const/#trestle.common.const.NCNAME_UTF8_OTHER_CHAR_OPTIONS","text":"","title":"NCNAME_UTF8_OTHER_CHAR_OPTIONS"},{"location":"api_reference/trestle.common.const/#trestle.common.const.PACKAGE_OSCAL","text":"","title":"PACKAGE_OSCAL"},{"location":"api_reference/trestle.common.const/#trestle.common.const.PLANNED","text":"","title":"PLANNED"},{"location":"api_reference/trestle.common.const/#trestle.common.const.PLANNED_COMPLETION_DATE","text":"","title":"PLANNED_COMPLETION_DATE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.PROFILE_ADD_REQUIRED_SECTION_FOR_CONTROL_TEXT","text":"","title":"PROFILE_ADD_REQUIRED_SECTION_FOR_CONTROL_TEXT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.PROFILE_VALUES","text":"","title":"PROFILE_VALUES"},{"location":"api_reference/trestle.common.const/#trestle.common.const.RESPONSIBLE_ROLE","text":"","title":"RESPONSIBLE_ROLE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.RESPONSIBLE_ROLES","text":"","title":"RESPONSIBLE_ROLES"},{"location":"api_reference/trestle.common.const/#trestle.common.const.ROOT","text":"","title":"ROOT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.SAMPLE_UUID_STR","text":"","title":"SAMPLE_UUID_STR"},{"location":"api_reference/trestle.common.const/#trestle.common.const.SECTIONS_TAG","text":"","title":"SECTIONS_TAG"},{"location":"api_reference/trestle.common.const/#trestle.common.const.SET_PARAMS_TAG","text":"","title":"SET_PARAMS_TAG"},{"location":"api_reference/trestle.common.const/#trestle.common.const.SFTP_URI","text":"","title":"SFTP_URI"},{"location":"api_reference/trestle.common.const/#trestle.common.const.SORT_ID","text":"","title":"SORT_ID"},{"location":"api_reference/trestle.common.const/#trestle.common.const.SSP_ADD_IMPLEMENTATION_FOR_CONTROL_TEXT","text":"","title":"SSP_ADD_IMPLEMENTATION_FOR_CONTROL_TEXT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.SSP_ADD_IMPLEMENTATION_FOR_ITEM_TEXT","text":"","title":"SSP_ADD_IMPLEMENTATION_FOR_ITEM_TEXT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.SSP_ADD_IMPLEMENTATION_FOR_STATEMENT_TEXT","text":"","title":"SSP_ADD_IMPLEMENTATION_FOR_STATEMENT_TEXT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.SSP_ADD_IMPLEMENTATION_PREFIX","text":"","title":"SSP_ADD_IMPLEMENTATION_PREFIX"},{"location":"api_reference/trestle.common.const/#trestle.common.const.SSP_FEDRAMP_TAG","text":"","title":"SSP_FEDRAMP_TAG"},{"location":"api_reference/trestle.common.const/#trestle.common.const.SSP_MAIN_COMP_NAME","text":"","title":"SSP_MAIN_COMP_NAME"},{"location":"api_reference/trestle.common.const/#trestle.common.const.SSP_MD_HRULE_LINE","text":"","title":"SSP_MD_HRULE_LINE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.SSP_MD_IMPLEMENTATION_QUESTION","text":"","title":"SSP_MD_IMPLEMENTATION_QUESTION"},{"location":"api_reference/trestle.common.const/#trestle.common.const.SSP_MD_LEAVE_BLANK_TEXT","text":"","title":"SSP_MD_LEAVE_BLANK_TEXT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.SSP_SYSTEM_CONTROL_IMPLEMENTATION_TEXT","text":"","title":"SSP_SYSTEM_CONTROL_IMPLEMENTATION_TEXT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.TRANSFORM_TYPES","text":"","title":"TRANSFORM_TYPES"},{"location":"api_reference/trestle.common.const/#trestle.common.const.TRESTLE_CACHE_DIR","text":"","title":"TRESTLE_CACHE_DIR"},{"location":"api_reference/trestle.common.const/#trestle.common.const.TRESTLE_CONFIG_DIR","text":"","title":"TRESTLE_CONFIG_DIR"},{"location":"api_reference/trestle.common.const/#trestle.common.const.TRESTLE_CONFIG_FILE","text":"","title":"TRESTLE_CONFIG_FILE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.TRESTLE_DIST_DIR","text":"","title":"TRESTLE_DIST_DIR"},{"location":"api_reference/trestle.common.const/#trestle.common.const.TRESTLE_HREF_HEADING","text":"","title":"TRESTLE_HREF_HEADING"},{"location":"api_reference/trestle.common.const/#trestle.common.const.TRESTLE_HREF_REGEX","text":"","title":"TRESTLE_HREF_REGEX"},{"location":"api_reference/trestle.common.const/#trestle.common.const.TRESTLE_KEEP_FILE","text":"","title":"TRESTLE_KEEP_FILE"},{"location":"api_reference/trestle.common.const/#trestle.common.const.TRESTLE_TAG","text":"","title":"TRESTLE_TAG"},{"location":"api_reference/trestle.common.const/#trestle.common.const.UNIX_CACHE_ROOT","text":"","title":"UNIX_CACHE_ROOT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.UUID_REGEX","text":"","title":"UUID_REGEX"},{"location":"api_reference/trestle.common.const/#trestle.common.const.VALUES","text":"","title":"VALUES"},{"location":"api_reference/trestle.common.const/#trestle.common.const.VAL_MODE_ALL","text":"","title":"VAL_MODE_ALL"},{"location":"api_reference/trestle.common.const/#trestle.common.const.VAL_MODE_DUPLICATES","text":"","title":"VAL_MODE_DUPLICATES"},{"location":"api_reference/trestle.common.const/#trestle.common.const.VAL_MODE_OSCAL_VERSION","text":"","title":"VAL_MODE_OSCAL_VERSION"},{"location":"api_reference/trestle.common.const/#trestle.common.const.VAL_MODE_REFS","text":"","title":"VAL_MODE_REFS"},{"location":"api_reference/trestle.common.const/#trestle.common.const.WEBSITE_ROOT","text":"","title":"WEBSITE_ROOT"},{"location":"api_reference/trestle.common.const/#trestle.common.const.WINDOWS_DRIVE_LETTER_REGEX","text":"","title":"WINDOWS_DRIVE_LETTER_REGEX"},{"location":"api_reference/trestle.common.const/#trestle.common.const.WINDOWS_DRIVE_URI_REGEX","text":"","title":"WINDOWS_DRIVE_URI_REGEX"},{"location":"api_reference/trestle.common.const/#trestle.common.const.WINDOWS_PLATFORM_STR","text":"handler: python","title":"WINDOWS_PLATFORM_STR"},{"location":"api_reference/trestle.common.err/","text":"trestle.common.err \u00a4 Trestle core errors module. Classes \u00a4 TrestleError ( RuntimeError ) \u00a4 General framework (non-application) related errors. Attributes: Name Type Description msg str Human readable string describing the exception. Source code in trestle/common/err.py class TrestleError ( RuntimeError ): \"\"\" General framework (non-application) related errors. Attributes: msg (str): Human readable string describing the exception. \"\"\" def __init__ ( self , msg : str ): \"\"\"Intialization for TresleError. Args: msg (str): The error message \"\"\" RuntimeError . __init__ ( self ) self . msg = msg def __str__ ( self ) -> str : \"\"\"Return Trestle error message if asked for a string.\"\"\" return self . msg Methods \u00a4 __init__ ( self , msg ) special \u00a4 Intialization for TresleError. Parameters: Name Type Description Default msg str The error message required Source code in trestle/common/err.py def __init__ ( self , msg : str ): \"\"\"Intialization for TresleError. Args: msg (str): The error message \"\"\" RuntimeError . __init__ ( self ) self . msg = msg __str__ ( self ) special \u00a4 Return Trestle error message if asked for a string. Source code in trestle/common/err.py def __str__ ( self ) -> str : \"\"\"Return Trestle error message if asked for a string.\"\"\" return self . msg TrestleIncorrectArgsError ( TrestleError ) \u00a4 General error for incorrect args passed to Trestle command. Source code in trestle/common/err.py class TrestleIncorrectArgsError ( TrestleError ): \"\"\"General error for incorrect args passed to Trestle command.\"\"\" def __init__ ( self , msg : str ): \"\"\" Initialize TrestleIncorrectArgsError. Args: msg (str): The error message \"\"\" super () . __init__ ( msg ) Methods \u00a4 __init__ ( self , msg ) special \u00a4 Initialize TrestleIncorrectArgsError. Parameters: Name Type Description Default msg str The error message required Source code in trestle/common/err.py def __init__ ( self , msg : str ): \"\"\" Initialize TrestleIncorrectArgsError. Args: msg (str): The error message \"\"\" super () . __init__ ( msg ) TrestleNotFoundError ( TrestleError ) \u00a4 General framework related not found error. Attributes: Name Type Description msg str Human readable string describing the exception. Source code in trestle/common/err.py class TrestleNotFoundError ( TrestleError ): \"\"\" General framework related not found error. Attributes: msg (str): Human readable string describing the exception. \"\"\" def __init__ ( self , msg : str ): \"\"\" Intialize TresleNotFoundError. Args: msg: The error message \"\"\" super () . __init__ ( msg ) Methods \u00a4 __init__ ( self , msg ) special \u00a4 Intialize TresleNotFoundError. Parameters: Name Type Description Default msg str The error message required Source code in trestle/common/err.py def __init__ ( self , msg : str ): \"\"\" Intialize TresleNotFoundError. Args: msg: The error message \"\"\" super () . __init__ ( msg ) TrestleRootError ( TrestleError ) \u00a4 General error for Trestle project root/setup errors. Source code in trestle/common/err.py class TrestleRootError ( TrestleError ): \"\"\"General error for Trestle project root/setup errors.\"\"\" def __init__ ( self , msg : str ): \"\"\" Initialize TrestleRootError. Args: msg (str): The error message \"\"\" super () . __init__ ( msg ) Methods \u00a4 __init__ ( self , msg ) special \u00a4 Initialize TrestleRootError. Parameters: Name Type Description Default msg str The error message required Source code in trestle/common/err.py def __init__ ( self , msg : str ): \"\"\" Initialize TrestleRootError. Args: msg (str): The error message \"\"\" super () . __init__ ( msg ) Functions \u00a4 handle_generic_command_exception ( exception , logger , msg = 'Exception occured during execution' ) \u00a4 Print out error message based on the verbosity and return appropriate status code. Source code in trestle/common/err.py def handle_generic_command_exception ( exception : Exception , logger : Logger , msg : str = 'Exception occured during execution' ) -> int : \"\"\"Print out error message based on the verbosity and return appropriate status code.\"\"\" if get_current_verbosity_level ( logger ) == 0 : logger . error ( msg + f ': { exception } ' ) else : logger . exception ( msg + f ': { exception } ' ) return _exception_to_error_code ( exception ) handler: python","title":"err"},{"location":"api_reference/trestle.common.err/#trestle.common.err","text":"Trestle core errors module.","title":"err"},{"location":"api_reference/trestle.common.err/#trestle.common.err-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.common.err/#trestle.common.err.TrestleError","text":"General framework (non-application) related errors. Attributes: Name Type Description msg str Human readable string describing the exception. Source code in trestle/common/err.py class TrestleError ( RuntimeError ): \"\"\" General framework (non-application) related errors. Attributes: msg (str): Human readable string describing the exception. \"\"\" def __init__ ( self , msg : str ): \"\"\"Intialization for TresleError. Args: msg (str): The error message \"\"\" RuntimeError . __init__ ( self ) self . msg = msg def __str__ ( self ) -> str : \"\"\"Return Trestle error message if asked for a string.\"\"\" return self . msg","title":"TrestleError"},{"location":"api_reference/trestle.common.err/#trestle.common.err.TrestleError-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.common.err/#trestle.common.err.TrestleError.__init__","text":"Intialization for TresleError. Parameters: Name Type Description Default msg str The error message required Source code in trestle/common/err.py def __init__ ( self , msg : str ): \"\"\"Intialization for TresleError. Args: msg (str): The error message \"\"\" RuntimeError . __init__ ( self ) self . msg = msg","title":"__init__()"},{"location":"api_reference/trestle.common.err/#trestle.common.err.TrestleError.__str__","text":"Return Trestle error message if asked for a string. Source code in trestle/common/err.py def __str__ ( self ) -> str : \"\"\"Return Trestle error message if asked for a string.\"\"\" return self . msg","title":"__str__()"},{"location":"api_reference/trestle.common.err/#trestle.common.err.TrestleIncorrectArgsError","text":"General error for incorrect args passed to Trestle command. Source code in trestle/common/err.py class TrestleIncorrectArgsError ( TrestleError ): \"\"\"General error for incorrect args passed to Trestle command.\"\"\" def __init__ ( self , msg : str ): \"\"\" Initialize TrestleIncorrectArgsError. Args: msg (str): The error message \"\"\" super () . __init__ ( msg )","title":"TrestleIncorrectArgsError"},{"location":"api_reference/trestle.common.err/#trestle.common.err.TrestleIncorrectArgsError-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.common.err/#trestle.common.err.TrestleIncorrectArgsError.__init__","text":"Initialize TrestleIncorrectArgsError. Parameters: Name Type Description Default msg str The error message required Source code in trestle/common/err.py def __init__ ( self , msg : str ): \"\"\" Initialize TrestleIncorrectArgsError. Args: msg (str): The error message \"\"\" super () . __init__ ( msg )","title":"__init__()"},{"location":"api_reference/trestle.common.err/#trestle.common.err.TrestleNotFoundError","text":"General framework related not found error. Attributes: Name Type Description msg str Human readable string describing the exception. Source code in trestle/common/err.py class TrestleNotFoundError ( TrestleError ): \"\"\" General framework related not found error. Attributes: msg (str): Human readable string describing the exception. \"\"\" def __init__ ( self , msg : str ): \"\"\" Intialize TresleNotFoundError. Args: msg: The error message \"\"\" super () . __init__ ( msg )","title":"TrestleNotFoundError"},{"location":"api_reference/trestle.common.err/#trestle.common.err.TrestleNotFoundError-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.common.err/#trestle.common.err.TrestleNotFoundError.__init__","text":"Intialize TresleNotFoundError. Parameters: Name Type Description Default msg str The error message required Source code in trestle/common/err.py def __init__ ( self , msg : str ): \"\"\" Intialize TresleNotFoundError. Args: msg: The error message \"\"\" super () . __init__ ( msg )","title":"__init__()"},{"location":"api_reference/trestle.common.err/#trestle.common.err.TrestleRootError","text":"General error for Trestle project root/setup errors. Source code in trestle/common/err.py class TrestleRootError ( TrestleError ): \"\"\"General error for Trestle project root/setup errors.\"\"\" def __init__ ( self , msg : str ): \"\"\" Initialize TrestleRootError. Args: msg (str): The error message \"\"\" super () . __init__ ( msg )","title":"TrestleRootError"},{"location":"api_reference/trestle.common.err/#trestle.common.err.TrestleRootError-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.common.err/#trestle.common.err.TrestleRootError.__init__","text":"Initialize TrestleRootError. Parameters: Name Type Description Default msg str The error message required Source code in trestle/common/err.py def __init__ ( self , msg : str ): \"\"\" Initialize TrestleRootError. Args: msg (str): The error message \"\"\" super () . __init__ ( msg )","title":"__init__()"},{"location":"api_reference/trestle.common.err/#trestle.common.err-functions","text":"","title":"Functions"},{"location":"api_reference/trestle.common.err/#trestle.common.err.handle_generic_command_exception","text":"Print out error message based on the verbosity and return appropriate status code. Source code in trestle/common/err.py def handle_generic_command_exception ( exception : Exception , logger : Logger , msg : str = 'Exception occured during execution' ) -> int : \"\"\"Print out error message based on the verbosity and return appropriate status code.\"\"\" if get_current_verbosity_level ( logger ) == 0 : logger . error ( msg + f ': { exception } ' ) else : logger . exception ( msg + f ': { exception } ' ) return _exception_to_error_code ( exception ) handler: python","title":"handle_generic_command_exception()"},{"location":"api_reference/trestle.common.file_utils/","text":"trestle.common.file_utils \u00a4 Trestle file system utils. logger \u00a4 Functions \u00a4 check_oscal_directories ( root_path ) \u00a4 Identify the state of the Trestle workspace. Traverses Trestle workspace and looks for unexpected files or directories. Additional files are allowed in the Trestle root but not inside the model folders. Source code in trestle/common/file_utils.py def check_oscal_directories ( root_path : pathlib . Path ) -> bool : \"\"\" Identify the state of the Trestle workspace. Traverses Trestle workspace and looks for unexpected files or directories. Additional files are allowed in the Trestle root but not inside the model folders. \"\"\" trestle_dir_walk = os . walk ( root_path ) is_valid = True for _ , dirs , _ in trestle_dir_walk : for d in dirs : if d in MODEL_DIR_LIST : is_valid = _verify_oscal_folder ( root_path / d ) if not is_valid : break return is_valid extract_project_model_path ( path ) \u00a4 Get the base path of the trestle model project. Source code in trestle/common/file_utils.py def extract_project_model_path ( path : pathlib . Path ) -> Optional [ pathlib . Path ]: \"\"\"Get the base path of the trestle model project.\"\"\" if len ( path . parts ) > 2 : for i in range ( 2 , len ( path . parts )): current = pathlib . Path ( path . parts [ 0 ]) . joinpath ( * path . parts [ 1 : i + 1 ]) if _is_valid_project_model_path ( current ): return current return None extract_trestle_project_root ( path ) \u00a4 Get the trestle project root folder in the path. Source code in trestle/common/file_utils.py def extract_trestle_project_root ( path : pathlib . Path ) -> Optional [ pathlib . Path ]: \"\"\"Get the trestle project root folder in the path.\"\"\" while len ( path . parts ) > 1 : # it must not be the system root directory if is_valid_project_root ( path ): return path path = path . parent return None get_contextual_file_type ( path ) \u00a4 Return the file content type for files in the given directory, if it's a trestle project. Source code in trestle/common/file_utils.py def get_contextual_file_type ( path : pathlib . Path ) -> FileContentType : \"\"\"Return the file content type for files in the given directory, if it's a trestle project.\"\"\" if not _is_valid_project_model_path ( path ): raise err . TrestleError ( f 'Trestle project not found at path { path } ' ) for file_or_directory in iterdir_without_hidden_files ( path ): if file_or_directory . is_file (): return FileContentType . to_content_type ( file_or_directory . suffix ) for file_or_directory in path . iterdir (): if file_or_directory . is_dir (): return get_contextual_file_type ( file_or_directory ) raise err . TrestleError ( 'No files found in the project.' ) is_directory_name_allowed ( name ) \u00a4 Determine whether a directory name, which is a 'non-core-OSCAL activity/directory is allowed. Parameters: Name Type Description Default name str the name which is assumed may take the form of a relative path for task/subtasks. required Returns: Type Description bool Whether the name is allowed or not allowed (interferes with assumed project directories such as catalogs). Source code in trestle/common/file_utils.py def is_directory_name_allowed ( name : str ) -> bool : \"\"\"Determine whether a directory name, which is a 'non-core-OSCAL activity/directory is allowed. args: name: the name which is assumed may take the form of a relative path for task/subtasks. Returns: Whether the name is allowed or not allowed (interferes with assumed project directories such as catalogs). \"\"\" # Task must not use an OSCAL directory # Task must not self-interfere with a project pathed_name = pathlib . Path ( name ) root_path = pathed_name . parts [ 0 ] if root_path in const . MODEL_TYPE_TO_MODEL_DIR . values (): logger . warning ( 'Task name is the same as an OSCAL schema name.' ) return False if root_path [ 0 ] == '.' : logger . warning ( 'Task name must not start with \".\"' ) return False if pathed_name . suffix != '' : # Does it look like a file logger . warning ( 'Task name must not look like a file path (e.g. contain a suffix' ) return False if '__global__' in pathed_name . parts : logger . warning ( 'Task name cannot contain __global__' ) return False return True is_hidden ( file_path ) \u00a4 Determine whether a file is hidden based on the appropriate os attributes. This function will only work for the current file path only (e.g. not if a parent is hidden). Parameters: Name Type Description Default file_path Path The file path for which we are testing whether the file / directory is hidden. required Returns: Type Description bool Whether or not the file is file/directory is hidden. Source code in trestle/common/file_utils.py def is_hidden ( file_path : pathlib . Path ) -> bool : \"\"\" Determine whether a file is hidden based on the appropriate os attributes. This function will only work for the current file path only (e.g. not if a parent is hidden). Args: file_path: The file path for which we are testing whether the file / directory is hidden. Returns: Whether or not the file is file/directory is hidden. \"\"\" # as far as trestle is concerned all .* files are hidden even on windows, regardless of attributes if file_path . stem . startswith ( '.' ): return True # Handle windows if is_windows (): # pragma: no cover attribute = win32api . GetFileAttributes ( str ( file_path )) return attribute & ( win32con . FILE_ATTRIBUTE_HIDDEN | win32con . FILE_ATTRIBUTE_SYSTEM ) return False is_local_and_visible ( file_path ) \u00a4 Is the file or dir local (not a symlink) and not hidden. Source code in trestle/common/file_utils.py def is_local_and_visible ( file_path : pathlib . Path ) -> bool : \"\"\"Is the file or dir local (not a symlink) and not hidden.\"\"\" return not ( is_hidden ( file_path ) or is_symlink ( file_path )) is_symlink ( file_path ) \u00a4 Is the file path a symlink. Source code in trestle/common/file_utils.py def is_symlink ( file_path : pathlib . Path ) -> bool : \"\"\"Is the file path a symlink.\"\"\" if is_windows (): return file_path . suffix == '.lnk' return file_path . is_symlink () is_valid_project_root ( path ) \u00a4 Check if the path is a valid trestle project root. Source code in trestle/common/file_utils.py def is_valid_project_root ( path : pathlib . Path ) -> bool : \"\"\"Check if the path is a valid trestle project root.\"\"\" trestle_dir = path / const . TRESTLE_CONFIG_DIR return trestle_dir . exists () and trestle_dir . is_dir () is_windows () \u00a4 Check if current operating system is Windows. Source code in trestle/common/file_utils.py def is_windows () -> bool : \"\"\"Check if current operating system is Windows.\"\"\" return platform . system () == const . WINDOWS_PLATFORM_STR iterdir_without_hidden_files ( directory_path ) \u00a4 Get iterator over all paths in the given directory_path excluding hidden files. Parameters: Name Type Description Default directory_path Path The directory to iterate through. required Returns: Type Description Iterable[pathlib.Path] Iterator over the files in the directory excluding hidden files. Source code in trestle/common/file_utils.py def iterdir_without_hidden_files ( directory_path : pathlib . Path ) -> Iterable [ pathlib . Path ]: \"\"\" Get iterator over all paths in the given directory_path excluding hidden files. Args: directory_path: The directory to iterate through. Returns: Iterator over the files in the directory excluding hidden files. \"\"\" filtered_paths = list ( filter ( lambda p : not is_hidden ( p ) or p . is_dir (), pathlib . Path . iterdir ( directory_path ))) return filtered_paths . __iter__ () load_file ( file_path ) \u00a4 Load JSON or YAML file content into a dict. This is not intended to be the default load mechanism. It should only be used if a OSCAL object type is unknown but the context a user is in. Source code in trestle/common/file_utils.py def load_file ( file_path : pathlib . Path ) -> Dict [ str , Any ]: \"\"\" Load JSON or YAML file content into a dict. This is not intended to be the default load mechanism. It should only be used if a OSCAL object type is unknown but the context a user is in. \"\"\" content_type = FileContentType . to_content_type ( file_path . suffix ) with file_path . open ( 'r' , encoding = const . FILE_ENCODING ) as f : if content_type == FileContentType . YAML : yaml = YAML ( typ = 'safe' ) return yaml . load ( f ) if content_type == FileContentType . JSON : return json . load ( f ) make_hidden_file ( file_path ) \u00a4 Make hidden file. Source code in trestle/common/file_utils.py def make_hidden_file ( file_path : pathlib . Path ) -> None : \"\"\"Make hidden file.\"\"\" if not file_path . name . startswith ( '.' ) and not is_windows (): file_path = file_path . parent / ( '.' + file_path . name ) file_path . touch () if is_windows (): atts = win32api . GetFileAttributes ( str ( file_path )) win32api . SetFileAttributes ( str ( file_path ), win32con . FILE_ATTRIBUTE_HIDDEN | atts ) relative_resolve ( candidate , cwd ) \u00a4 Resolve a candidate file path relative to a provided cwd. This is to circumvent bad behaviour for resolve on windows platforms where the path must exist. If a relative dir is passed it presumes the directory is relative to the PROVIDED cwd. If relative expansions exist (e.g. ../) the final result must still be within the cwd. If an absolute path is provided it tests whether the path is within the cwd or not. Source code in trestle/common/file_utils.py def relative_resolve ( candidate : pathlib . Path , cwd : pathlib . Path ) -> pathlib . Path : \"\"\"Resolve a candidate file path relative to a provided cwd. This is to circumvent bad behaviour for resolve on windows platforms where the path must exist. If a relative dir is passed it presumes the directory is relative to the PROVIDED cwd. If relative expansions exist (e.g. ../) the final result must still be within the cwd. If an absolute path is provided it tests whether the path is within the cwd or not. \"\"\" # Expand user first if applicable. candidate = candidate . expanduser () if not cwd . is_absolute (): raise TrestleError ( 'Error handling current working directory. CWD is expected to be absolute.' ) if not candidate . is_absolute (): new = pathlib . Path ( cwd / candidate ) . resolve () else : new = candidate . resolve () try : new . relative_to ( cwd ) except ValueError : raise TrestleError ( f 'Provided dir { candidate } is not relative to { cwd } ' ) return new handler: python","title":"file_utils"},{"location":"api_reference/trestle.common.file_utils/#trestle.common.file_utils","text":"Trestle file system utils.","title":"file_utils"},{"location":"api_reference/trestle.common.file_utils/#trestle.common.file_utils.logger","text":"","title":"logger"},{"location":"api_reference/trestle.common.file_utils/#trestle.common.file_utils-functions","text":"","title":"Functions"},{"location":"api_reference/trestle.common.file_utils/#trestle.common.file_utils.check_oscal_directories","text":"Identify the state of the Trestle workspace. Traverses Trestle workspace and looks for unexpected files or directories. Additional files are allowed in the Trestle root but not inside the model folders. Source code in trestle/common/file_utils.py def check_oscal_directories ( root_path : pathlib . Path ) -> bool : \"\"\" Identify the state of the Trestle workspace. Traverses Trestle workspace and looks for unexpected files or directories. Additional files are allowed in the Trestle root but not inside the model folders. \"\"\" trestle_dir_walk = os . walk ( root_path ) is_valid = True for _ , dirs , _ in trestle_dir_walk : for d in dirs : if d in MODEL_DIR_LIST : is_valid = _verify_oscal_folder ( root_path / d ) if not is_valid : break return is_valid","title":"check_oscal_directories()"},{"location":"api_reference/trestle.common.file_utils/#trestle.common.file_utils.extract_project_model_path","text":"Get the base path of the trestle model project. Source code in trestle/common/file_utils.py def extract_project_model_path ( path : pathlib . Path ) -> Optional [ pathlib . Path ]: \"\"\"Get the base path of the trestle model project.\"\"\" if len ( path . parts ) > 2 : for i in range ( 2 , len ( path . parts )): current = pathlib . Path ( path . parts [ 0 ]) . joinpath ( * path . parts [ 1 : i + 1 ]) if _is_valid_project_model_path ( current ): return current return None","title":"extract_project_model_path()"},{"location":"api_reference/trestle.common.file_utils/#trestle.common.file_utils.extract_trestle_project_root","text":"Get the trestle project root folder in the path. Source code in trestle/common/file_utils.py def extract_trestle_project_root ( path : pathlib . Path ) -> Optional [ pathlib . Path ]: \"\"\"Get the trestle project root folder in the path.\"\"\" while len ( path . parts ) > 1 : # it must not be the system root directory if is_valid_project_root ( path ): return path path = path . parent return None","title":"extract_trestle_project_root()"},{"location":"api_reference/trestle.common.file_utils/#trestle.common.file_utils.get_contextual_file_type","text":"Return the file content type for files in the given directory, if it's a trestle project. Source code in trestle/common/file_utils.py def get_contextual_file_type ( path : pathlib . Path ) -> FileContentType : \"\"\"Return the file content type for files in the given directory, if it's a trestle project.\"\"\" if not _is_valid_project_model_path ( path ): raise err . TrestleError ( f 'Trestle project not found at path { path } ' ) for file_or_directory in iterdir_without_hidden_files ( path ): if file_or_directory . is_file (): return FileContentType . to_content_type ( file_or_directory . suffix ) for file_or_directory in path . iterdir (): if file_or_directory . is_dir (): return get_contextual_file_type ( file_or_directory ) raise err . TrestleError ( 'No files found in the project.' )","title":"get_contextual_file_type()"},{"location":"api_reference/trestle.common.file_utils/#trestle.common.file_utils.is_directory_name_allowed","text":"Determine whether a directory name, which is a 'non-core-OSCAL activity/directory is allowed. Parameters: Name Type Description Default name str the name which is assumed may take the form of a relative path for task/subtasks. required Returns: Type Description bool Whether the name is allowed or not allowed (interferes with assumed project directories such as catalogs). Source code in trestle/common/file_utils.py def is_directory_name_allowed ( name : str ) -> bool : \"\"\"Determine whether a directory name, which is a 'non-core-OSCAL activity/directory is allowed. args: name: the name which is assumed may take the form of a relative path for task/subtasks. Returns: Whether the name is allowed or not allowed (interferes with assumed project directories such as catalogs). \"\"\" # Task must not use an OSCAL directory # Task must not self-interfere with a project pathed_name = pathlib . Path ( name ) root_path = pathed_name . parts [ 0 ] if root_path in const . MODEL_TYPE_TO_MODEL_DIR . values (): logger . warning ( 'Task name is the same as an OSCAL schema name.' ) return False if root_path [ 0 ] == '.' : logger . warning ( 'Task name must not start with \".\"' ) return False if pathed_name . suffix != '' : # Does it look like a file logger . warning ( 'Task name must not look like a file path (e.g. contain a suffix' ) return False if '__global__' in pathed_name . parts : logger . warning ( 'Task name cannot contain __global__' ) return False return True","title":"is_directory_name_allowed()"},{"location":"api_reference/trestle.common.file_utils/#trestle.common.file_utils.is_hidden","text":"Determine whether a file is hidden based on the appropriate os attributes. This function will only work for the current file path only (e.g. not if a parent is hidden). Parameters: Name Type Description Default file_path Path The file path for which we are testing whether the file / directory is hidden. required Returns: Type Description bool Whether or not the file is file/directory is hidden. Source code in trestle/common/file_utils.py def is_hidden ( file_path : pathlib . Path ) -> bool : \"\"\" Determine whether a file is hidden based on the appropriate os attributes. This function will only work for the current file path only (e.g. not if a parent is hidden). Args: file_path: The file path for which we are testing whether the file / directory is hidden. Returns: Whether or not the file is file/directory is hidden. \"\"\" # as far as trestle is concerned all .* files are hidden even on windows, regardless of attributes if file_path . stem . startswith ( '.' ): return True # Handle windows if is_windows (): # pragma: no cover attribute = win32api . GetFileAttributes ( str ( file_path )) return attribute & ( win32con . FILE_ATTRIBUTE_HIDDEN | win32con . FILE_ATTRIBUTE_SYSTEM ) return False","title":"is_hidden()"},{"location":"api_reference/trestle.common.file_utils/#trestle.common.file_utils.is_local_and_visible","text":"Is the file or dir local (not a symlink) and not hidden. Source code in trestle/common/file_utils.py def is_local_and_visible ( file_path : pathlib . Path ) -> bool : \"\"\"Is the file or dir local (not a symlink) and not hidden.\"\"\" return not ( is_hidden ( file_path ) or is_symlink ( file_path ))","title":"is_local_and_visible()"},{"location":"api_reference/trestle.common.file_utils/#trestle.common.file_utils.is_symlink","text":"Is the file path a symlink. Source code in trestle/common/file_utils.py def is_symlink ( file_path : pathlib . Path ) -> bool : \"\"\"Is the file path a symlink.\"\"\" if is_windows (): return file_path . suffix == '.lnk' return file_path . is_symlink ()","title":"is_symlink()"},{"location":"api_reference/trestle.common.file_utils/#trestle.common.file_utils.is_valid_project_root","text":"Check if the path is a valid trestle project root. Source code in trestle/common/file_utils.py def is_valid_project_root ( path : pathlib . Path ) -> bool : \"\"\"Check if the path is a valid trestle project root.\"\"\" trestle_dir = path / const . TRESTLE_CONFIG_DIR return trestle_dir . exists () and trestle_dir . is_dir ()","title":"is_valid_project_root()"},{"location":"api_reference/trestle.common.file_utils/#trestle.common.file_utils.is_windows","text":"Check if current operating system is Windows. Source code in trestle/common/file_utils.py def is_windows () -> bool : \"\"\"Check if current operating system is Windows.\"\"\" return platform . system () == const . WINDOWS_PLATFORM_STR","title":"is_windows()"},{"location":"api_reference/trestle.common.file_utils/#trestle.common.file_utils.iterdir_without_hidden_files","text":"Get iterator over all paths in the given directory_path excluding hidden files. Parameters: Name Type Description Default directory_path Path The directory to iterate through. required Returns: Type Description Iterable[pathlib.Path] Iterator over the files in the directory excluding hidden files. Source code in trestle/common/file_utils.py def iterdir_without_hidden_files ( directory_path : pathlib . Path ) -> Iterable [ pathlib . Path ]: \"\"\" Get iterator over all paths in the given directory_path excluding hidden files. Args: directory_path: The directory to iterate through. Returns: Iterator over the files in the directory excluding hidden files. \"\"\" filtered_paths = list ( filter ( lambda p : not is_hidden ( p ) or p . is_dir (), pathlib . Path . iterdir ( directory_path ))) return filtered_paths . __iter__ ()","title":"iterdir_without_hidden_files()"},{"location":"api_reference/trestle.common.file_utils/#trestle.common.file_utils.load_file","text":"Load JSON or YAML file content into a dict. This is not intended to be the default load mechanism. It should only be used if a OSCAL object type is unknown but the context a user is in. Source code in trestle/common/file_utils.py def load_file ( file_path : pathlib . Path ) -> Dict [ str , Any ]: \"\"\" Load JSON or YAML file content into a dict. This is not intended to be the default load mechanism. It should only be used if a OSCAL object type is unknown but the context a user is in. \"\"\" content_type = FileContentType . to_content_type ( file_path . suffix ) with file_path . open ( 'r' , encoding = const . FILE_ENCODING ) as f : if content_type == FileContentType . YAML : yaml = YAML ( typ = 'safe' ) return yaml . load ( f ) if content_type == FileContentType . JSON : return json . load ( f )","title":"load_file()"},{"location":"api_reference/trestle.common.file_utils/#trestle.common.file_utils.make_hidden_file","text":"Make hidden file. Source code in trestle/common/file_utils.py def make_hidden_file ( file_path : pathlib . Path ) -> None : \"\"\"Make hidden file.\"\"\" if not file_path . name . startswith ( '.' ) and not is_windows (): file_path = file_path . parent / ( '.' + file_path . name ) file_path . touch () if is_windows (): atts = win32api . GetFileAttributes ( str ( file_path )) win32api . SetFileAttributes ( str ( file_path ), win32con . FILE_ATTRIBUTE_HIDDEN | atts )","title":"make_hidden_file()"},{"location":"api_reference/trestle.common.file_utils/#trestle.common.file_utils.relative_resolve","text":"Resolve a candidate file path relative to a provided cwd. This is to circumvent bad behaviour for resolve on windows platforms where the path must exist. If a relative dir is passed it presumes the directory is relative to the PROVIDED cwd. If relative expansions exist (e.g. ../) the final result must still be within the cwd. If an absolute path is provided it tests whether the path is within the cwd or not. Source code in trestle/common/file_utils.py def relative_resolve ( candidate : pathlib . Path , cwd : pathlib . Path ) -> pathlib . Path : \"\"\"Resolve a candidate file path relative to a provided cwd. This is to circumvent bad behaviour for resolve on windows platforms where the path must exist. If a relative dir is passed it presumes the directory is relative to the PROVIDED cwd. If relative expansions exist (e.g. ../) the final result must still be within the cwd. If an absolute path is provided it tests whether the path is within the cwd or not. \"\"\" # Expand user first if applicable. candidate = candidate . expanduser () if not cwd . is_absolute (): raise TrestleError ( 'Error handling current working directory. CWD is expected to be absolute.' ) if not candidate . is_absolute (): new = pathlib . Path ( cwd / candidate ) . resolve () else : new = candidate . resolve () try : new . relative_to ( cwd ) except ValueError : raise TrestleError ( f 'Provided dir { candidate } is not relative to { cwd } ' ) return new handler: python","title":"relative_resolve()"},{"location":"api_reference/trestle.common.list_utils/","text":"trestle.common.list_utils \u00a4 Trestle List Utils. Functions \u00a4 as_list ( list_or_none ) \u00a4 Convert list or None object to itself or an empty list if none. Source code in trestle/common/list_utils.py def as_list ( list_or_none : Optional [ List [ TG ]]) -> List [ TG ]: \"\"\"Convert list or None object to itself or an empty list if none.\"\"\" return list_or_none if list_or_none else [] is_ordered_sublist ( needle , haystack ) \u00a4 Determine if needle is exactly contained in haystack. The needle list comprises an ordered list of strings. The haystack list comprises an ordered list of strings that is to be searched. If the strings in the needle appear in the haystack in that exact order then return true, else false. Examples: needle=['a','b','c'], haystack=['x','y','a','b','c','z'], result = True needle=['a','b','c'], haystack=['x','y','a','b','z','c'], result = False Source code in trestle/common/list_utils.py def is_ordered_sublist ( needle : List [ str ], haystack : List [ str ]) -> bool : \"\"\"Determine if needle is exactly contained in haystack. The needle list comprises an ordered list of strings. The haystack list comprises an ordered list of strings that is to be searched. If the strings in the needle appear in the haystack in that exact order then return true, else false. Examples: needle=['a','b','c'], haystack=['x','y','a','b','c','z'], result = True needle=['a','b','c'], haystack=['x','y','a','b','z','c'], result = False \"\"\" return ' ' . join ( needle ) in ' ' . join ( haystack ) join_key_to_list_dicts ( dict1 , dict2 ) \u00a4 Join two dicts of str to List. Source code in trestle/common/list_utils.py def join_key_to_list_dicts ( dict1 : Dict , dict2 : Dict ) -> Dict : \"\"\"Join two dicts of str to List.\"\"\" # merge like keys dict3 = { key : dict1 [ key ] + dict2 . get ( key , []) for key in dict1 } # merge unlike keys dict3 . update ({ key : dict2 [ key ] for key in dict2 if key not in dict3 }) return dict3 none_if_empty ( list_ ) \u00a4 Convert to None if empty list. Source code in trestle/common/list_utils.py def none_if_empty ( list_ : List [ TG ]) -> Optional [ List [ TG ]]: \"\"\"Convert to None if empty list.\"\"\" return list_ if list_ else None handler: python","title":"list_utils"},{"location":"api_reference/trestle.common.list_utils/#trestle.common.list_utils","text":"Trestle List Utils.","title":"list_utils"},{"location":"api_reference/trestle.common.list_utils/#trestle.common.list_utils-functions","text":"","title":"Functions"},{"location":"api_reference/trestle.common.list_utils/#trestle.common.list_utils.as_list","text":"Convert list or None object to itself or an empty list if none. Source code in trestle/common/list_utils.py def as_list ( list_or_none : Optional [ List [ TG ]]) -> List [ TG ]: \"\"\"Convert list or None object to itself or an empty list if none.\"\"\" return list_or_none if list_or_none else []","title":"as_list()"},{"location":"api_reference/trestle.common.list_utils/#trestle.common.list_utils.is_ordered_sublist","text":"Determine if needle is exactly contained in haystack. The needle list comprises an ordered list of strings. The haystack list comprises an ordered list of strings that is to be searched. If the strings in the needle appear in the haystack in that exact order then return true, else false. Examples: needle=['a','b','c'], haystack=['x','y','a','b','c','z'], result = True needle=['a','b','c'], haystack=['x','y','a','b','z','c'], result = False Source code in trestle/common/list_utils.py def is_ordered_sublist ( needle : List [ str ], haystack : List [ str ]) -> bool : \"\"\"Determine if needle is exactly contained in haystack. The needle list comprises an ordered list of strings. The haystack list comprises an ordered list of strings that is to be searched. If the strings in the needle appear in the haystack in that exact order then return true, else false. Examples: needle=['a','b','c'], haystack=['x','y','a','b','c','z'], result = True needle=['a','b','c'], haystack=['x','y','a','b','z','c'], result = False \"\"\" return ' ' . join ( needle ) in ' ' . join ( haystack )","title":"is_ordered_sublist()"},{"location":"api_reference/trestle.common.list_utils/#trestle.common.list_utils.join_key_to_list_dicts","text":"Join two dicts of str to List. Source code in trestle/common/list_utils.py def join_key_to_list_dicts ( dict1 : Dict , dict2 : Dict ) -> Dict : \"\"\"Join two dicts of str to List.\"\"\" # merge like keys dict3 = { key : dict1 [ key ] + dict2 . get ( key , []) for key in dict1 } # merge unlike keys dict3 . update ({ key : dict2 [ key ] for key in dict2 if key not in dict3 }) return dict3","title":"join_key_to_list_dicts()"},{"location":"api_reference/trestle.common.list_utils/#trestle.common.list_utils.none_if_empty","text":"Convert to None if empty list. Source code in trestle/common/list_utils.py def none_if_empty ( list_ : List [ TG ]) -> Optional [ List [ TG ]]: \"\"\"Convert to None if empty list.\"\"\" return list_ if list_ else None handler: python","title":"none_if_empty()"},{"location":"api_reference/trestle.common.log/","text":"trestle.common.log \u00a4 Common logging utilities. Classes \u00a4 SpecificLevelFilter ( Filter ) \u00a4 Filter for the same level as provided by setLevel for a log handler. Python by default logs all levels above to a given destination. This makes it easy to split levels where you might log all levels to file and only errors to std.err, however, does not allow logging a specific level elsewhere. Source code in trestle/common/log.py class SpecificLevelFilter ( logging . Filter ): \"\"\" Filter for the same level as provided by setLevel for a log handler. Python by default logs all levels above to a given destination. This makes it easy to split levels where you might log all levels to file and only errors to std.err, however, does not allow logging a specific level elsewhere. \"\"\" def __init__ ( self , level : int ) -> None : \"\"\"Initialize providing maximum level to be pushed through the filter.\"\"\" self . _level = level def filter ( self , log_record : logging . LogRecord ) -> bool : # noqa: A003 \"\"\"Filter log messages.\"\"\" return log_record . levelno == self . _level Methods \u00a4 __init__ ( self , level ) special \u00a4 Initialize providing maximum level to be pushed through the filter. Source code in trestle/common/log.py def __init__ ( self , level : int ) -> None : \"\"\"Initialize providing maximum level to be pushed through the filter.\"\"\" self . _level = level filter ( self , log_record ) \u00a4 Filter log messages. Source code in trestle/common/log.py def filter ( self , log_record : logging . LogRecord ) -> bool : # noqa: A003 \"\"\"Filter log messages.\"\"\" return log_record . levelno == self . _level Trace \u00a4 Class allowing low priority trace message when verbose > 1 and log level below DEBUG. Source code in trestle/common/log.py class Trace (): \"\"\"Class allowing low priority trace message when verbose > 1 and log level below DEBUG.\"\"\" def __init__ ( self , logger : logging . Logger ) -> None : \"\"\"Store the main logger with its module name.\"\"\" self . _logger = logger def log ( self , msg : str ) -> None : \"\"\"Output the trace msg if log level is below DEBUG.\"\"\" level = self . _logger . getEffectiveLevel () if level < logging . DEBUG : self . _logger . debug ( msg ) Methods \u00a4 __init__ ( self , logger ) special \u00a4 Store the main logger with its module name. Source code in trestle/common/log.py def __init__ ( self , logger : logging . Logger ) -> None : \"\"\"Store the main logger with its module name.\"\"\" self . _logger = logger log ( self , msg ) \u00a4 Output the trace msg if log level is below DEBUG. Source code in trestle/common/log.py def log ( self , msg : str ) -> None : \"\"\"Output the trace msg if log level is below DEBUG.\"\"\" level = self . _logger . getEffectiveLevel () if level < logging . DEBUG : self . _logger . debug ( msg ) Functions \u00a4 get_current_verbosity_level ( logger ) \u00a4 Get the current verbosity level based on logging level. Source code in trestle/common/log.py def get_current_verbosity_level ( logger : logging . Logger ) -> int : \"\"\"Get the current verbosity level based on logging level.\"\"\" level = logger . getEffectiveLevel () if level < logging . DEBUG : return 2 elif level == logging . DEBUG : return 1 return 0 set_global_logging_levels ( level = 20 ) \u00a4 Initialise logging. Should only be invoked by the CLI classes or similar. Source code in trestle/common/log.py def set_global_logging_levels ( level : int = logging . INFO ) -> None : \"\"\"Initialise logging. Should only be invoked by the CLI classes or similar. \"\"\" # This line stops default root loggers setup for a python context from logging extra messages. # DO NOT USE THIS COMMAND directly from an SDK. Handle logs levels based on your own application _logger . propagate = False # Remove handlers _logger . handlers . clear () # set global level _logger . setLevel ( level ) # Create standard out console_out_handler = logging . StreamHandler ( sys . stdout ) console_out_handler . setLevel ( logging . INFO ) console_out_handler . addFilter ( SpecificLevelFilter ( logging . INFO )) console_debug_handler = logging . StreamHandler ( sys . stdout ) console_debug_handler . setLevel ( logging . DEBUG ) console_debug_handler . addFilter ( SpecificLevelFilter ( logging . DEBUG )) console_error_handler = logging . StreamHandler ( sys . stderr ) console_error_handler . setLevel ( logging . WARNING ) # create formatters error_formatter = logging . Formatter ( ' %(name)s : %(lineno)d %(levelname)s : %(message)s ' ) debug_formatter = logging . Formatter ( ' %(name)s : %(lineno)d %(levelname)s : %(message)s ' ) console_debug_handler . setFormatter ( debug_formatter ) console_error_handler . setFormatter ( error_formatter ) # add ch to logger _logger . addHandler ( console_out_handler ) _logger . addHandler ( console_error_handler ) _logger . addHandler ( console_debug_handler ) set_log_level_from_args ( args ) \u00a4 Vanity function to automatically set log levels based on verbosity flags. Source code in trestle/common/log.py def set_log_level_from_args ( args : argparse . Namespace ) -> None : \"\"\"Vanity function to automatically set log levels based on verbosity flags.\"\"\" if args . verbose > 1 : # these msgs only output by trace calls set_global_logging_levels ( _get_trace_level ()) elif args . verbose == 1 : set_global_logging_levels ( logging . DEBUG ) else : set_global_logging_levels ( logging . INFO ) sys . excepthook = _exception_handler handler: python","title":"log"},{"location":"api_reference/trestle.common.log/#trestle.common.log","text":"Common logging utilities.","title":"log"},{"location":"api_reference/trestle.common.log/#trestle.common.log-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.common.log/#trestle.common.log.SpecificLevelFilter","text":"Filter for the same level as provided by setLevel for a log handler. Python by default logs all levels above to a given destination. This makes it easy to split levels where you might log all levels to file and only errors to std.err, however, does not allow logging a specific level elsewhere. Source code in trestle/common/log.py class SpecificLevelFilter ( logging . Filter ): \"\"\" Filter for the same level as provided by setLevel for a log handler. Python by default logs all levels above to a given destination. This makes it easy to split levels where you might log all levels to file and only errors to std.err, however, does not allow logging a specific level elsewhere. \"\"\" def __init__ ( self , level : int ) -> None : \"\"\"Initialize providing maximum level to be pushed through the filter.\"\"\" self . _level = level def filter ( self , log_record : logging . LogRecord ) -> bool : # noqa: A003 \"\"\"Filter log messages.\"\"\" return log_record . levelno == self . _level","title":"SpecificLevelFilter"},{"location":"api_reference/trestle.common.log/#trestle.common.log.SpecificLevelFilter-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.common.log/#trestle.common.log.SpecificLevelFilter.__init__","text":"Initialize providing maximum level to be pushed through the filter. Source code in trestle/common/log.py def __init__ ( self , level : int ) -> None : \"\"\"Initialize providing maximum level to be pushed through the filter.\"\"\" self . _level = level","title":"__init__()"},{"location":"api_reference/trestle.common.log/#trestle.common.log.SpecificLevelFilter.filter","text":"Filter log messages. Source code in trestle/common/log.py def filter ( self , log_record : logging . LogRecord ) -> bool : # noqa: A003 \"\"\"Filter log messages.\"\"\" return log_record . levelno == self . _level","title":"filter()"},{"location":"api_reference/trestle.common.log/#trestle.common.log.Trace","text":"Class allowing low priority trace message when verbose > 1 and log level below DEBUG. Source code in trestle/common/log.py class Trace (): \"\"\"Class allowing low priority trace message when verbose > 1 and log level below DEBUG.\"\"\" def __init__ ( self , logger : logging . Logger ) -> None : \"\"\"Store the main logger with its module name.\"\"\" self . _logger = logger def log ( self , msg : str ) -> None : \"\"\"Output the trace msg if log level is below DEBUG.\"\"\" level = self . _logger . getEffectiveLevel () if level < logging . DEBUG : self . _logger . debug ( msg )","title":"Trace"},{"location":"api_reference/trestle.common.log/#trestle.common.log.Trace-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.common.log/#trestle.common.log.Trace.__init__","text":"Store the main logger with its module name. Source code in trestle/common/log.py def __init__ ( self , logger : logging . Logger ) -> None : \"\"\"Store the main logger with its module name.\"\"\" self . _logger = logger","title":"__init__()"},{"location":"api_reference/trestle.common.log/#trestle.common.log.Trace.log","text":"Output the trace msg if log level is below DEBUG. Source code in trestle/common/log.py def log ( self , msg : str ) -> None : \"\"\"Output the trace msg if log level is below DEBUG.\"\"\" level = self . _logger . getEffectiveLevel () if level < logging . DEBUG : self . _logger . debug ( msg )","title":"log()"},{"location":"api_reference/trestle.common.log/#trestle.common.log-functions","text":"","title":"Functions"},{"location":"api_reference/trestle.common.log/#trestle.common.log.get_current_verbosity_level","text":"Get the current verbosity level based on logging level. Source code in trestle/common/log.py def get_current_verbosity_level ( logger : logging . Logger ) -> int : \"\"\"Get the current verbosity level based on logging level.\"\"\" level = logger . getEffectiveLevel () if level < logging . DEBUG : return 2 elif level == logging . DEBUG : return 1 return 0","title":"get_current_verbosity_level()"},{"location":"api_reference/trestle.common.log/#trestle.common.log.set_global_logging_levels","text":"Initialise logging. Should only be invoked by the CLI classes or similar. Source code in trestle/common/log.py def set_global_logging_levels ( level : int = logging . INFO ) -> None : \"\"\"Initialise logging. Should only be invoked by the CLI classes or similar. \"\"\" # This line stops default root loggers setup for a python context from logging extra messages. # DO NOT USE THIS COMMAND directly from an SDK. Handle logs levels based on your own application _logger . propagate = False # Remove handlers _logger . handlers . clear () # set global level _logger . setLevel ( level ) # Create standard out console_out_handler = logging . StreamHandler ( sys . stdout ) console_out_handler . setLevel ( logging . INFO ) console_out_handler . addFilter ( SpecificLevelFilter ( logging . INFO )) console_debug_handler = logging . StreamHandler ( sys . stdout ) console_debug_handler . setLevel ( logging . DEBUG ) console_debug_handler . addFilter ( SpecificLevelFilter ( logging . DEBUG )) console_error_handler = logging . StreamHandler ( sys . stderr ) console_error_handler . setLevel ( logging . WARNING ) # create formatters error_formatter = logging . Formatter ( ' %(name)s : %(lineno)d %(levelname)s : %(message)s ' ) debug_formatter = logging . Formatter ( ' %(name)s : %(lineno)d %(levelname)s : %(message)s ' ) console_debug_handler . setFormatter ( debug_formatter ) console_error_handler . setFormatter ( error_formatter ) # add ch to logger _logger . addHandler ( console_out_handler ) _logger . addHandler ( console_error_handler ) _logger . addHandler ( console_debug_handler )","title":"set_global_logging_levels()"},{"location":"api_reference/trestle.common.log/#trestle.common.log.set_log_level_from_args","text":"Vanity function to automatically set log levels based on verbosity flags. Source code in trestle/common/log.py def set_log_level_from_args ( args : argparse . Namespace ) -> None : \"\"\"Vanity function to automatically set log levels based on verbosity flags.\"\"\" if args . verbose > 1 : # these msgs only output by trace calls set_global_logging_levels ( _get_trace_level ()) elif args . verbose == 1 : set_global_logging_levels ( logging . DEBUG ) else : set_global_logging_levels ( logging . INFO ) sys . excepthook = _exception_handler handler: python","title":"set_log_level_from_args()"},{"location":"api_reference/trestle.common.model_utils/","text":"trestle.common.model_utils \u00a4 Common utilities for the OSCAL models and directories. logger \u00a4 Classes \u00a4 ModelUtils \u00a4 Utilities for the OSCAL models input and output. Source code in trestle/common/model_utils.py class ModelUtils : \"\"\"Utilities for the OSCAL models input and output.\"\"\" @staticmethod def load_distributed ( abs_path : Path , abs_trestle_root : Path , collection_type : Optional [ Type [ Any ]] = None ) -> Tuple [ Type [ OscalBaseModel ], str , Union [ OscalBaseModel , List [ OscalBaseModel ], Dict [ str , OscalBaseModel ]]]: \"\"\" Given path to a model, load the model. If the model is decomposed/split/distributed,the decomposed models are loaded recursively. Args: abs_path: The path to the file/directory to be loaded. abs_trestle_root: The trestle project root directory. collection_type: The type of collection model, if it is a collection model. typing.List is the only collection type handled or expected. Defaults to None. Returns: Return a tuple of Model Type (e.g. class 'trestle.oscal.catalog.Catalog'), Model Alias (e.g. 'catalog.metadata') and Instance of the Model. If the model is decomposed/split/distributed, the instance of the model contains the decomposed models loaded recursively. \"\"\" # if trying to load file that does not exist, load path instead if not abs_path . exists (): abs_path = abs_path . with_name ( abs_path . stem ) if not abs_path . exists (): raise TrestleNotFoundError ( f 'File { abs_path } not found for load.' ) if collection_type : # If the path contains a list type model if collection_type is list : return ModelUtils . _load_list ( abs_path , abs_trestle_root ) # the only other collection type in OSCAL is dict, and it only applies to include_all, # which is too granular ever to be loaded by this routine else : raise TrestleError ( f 'Collection type { collection_type } not recognized for distributed load.' ) # Get current model primary_model_type , primary_model_alias = ModelUtils . get_stripped_model_type ( abs_path , abs_trestle_root ) primary_model_instance : Optional [ OscalBaseModel ] = None # is this an attempt to load an actual json or yaml file? content_type = FileContentType . path_to_content_type ( abs_path ) # if file is sought but it doesn't exist, ignore and load as decomposed model if FileContentType . is_readable_file ( content_type ) and abs_path . exists (): primary_model_instance = primary_model_type . oscal_read ( abs_path ) # Is model decomposed? decomposed_dir = abs_path . with_name ( abs_path . stem ) if decomposed_dir . exists (): aliases_not_to_be_stripped = [] instances_to_be_merged : List [ OscalBaseModel ] = [] for local_path in sorted ( trestle . common . file_utils . iterdir_without_hidden_files ( decomposed_dir )): if local_path . is_file (): model_type , model_alias , model_instance = ModelUtils . load_distributed ( local_path , abs_trestle_root ) aliases_not_to_be_stripped . append ( model_alias . split ( '.' )[ - 1 ]) instances_to_be_merged . append ( model_instance ) elif local_path . is_dir (): model_type , model_alias = ModelUtils . get_stripped_model_type ( local_path , abs_trestle_root ) # Only load the directory if it is a collection model. Otherwise do nothing - it gets loaded when # iterating over the model file # If a model is just a container for a list e.g. # class Foo(OscalBaseModel): noqa: E800 # __root__: List[Bar] noqa: E800 # You need to test whether first a root key exists # then whether the outer_type of root is a collection. # Alternative is to do a try except to avoid the error for an unknown key. if model_type . is_collection_container (): # This directory is a decomposed List or Dict collection_type = model_type . get_collection_type () model_type , model_alias , model_instance = ModelUtils . load_distributed ( local_path , abs_trestle_root , collection_type ) aliases_not_to_be_stripped . append ( model_alias . split ( '.' )[ - 1 ]) instances_to_be_merged . append ( model_instance ) primary_model_dict = {} if primary_model_instance is not None : primary_model_dict = primary_model_instance . __dict__ merged_model_type , merged_model_alias = ModelUtils . get_stripped_model_type ( abs_path , abs_trestle_root , aliases_not_to_be_stripped ) # The following use of top_level is to allow loading of a top level model by name only, e.g. MyCatalog # There may be a better overall way to approach this. top_level = len ( merged_model_alias . split ( '.' )) == 1 for i in range ( len ( aliases_not_to_be_stripped )): alias = aliases_not_to_be_stripped [ i ] instance = instances_to_be_merged [ i ] if hasattr ( instance , '__dict__' ) and '__root__' in instance . __dict__ and isinstance ( instance , OscalBaseModel ): instance = instance . __dict__ [ '__root__' ] if top_level and not primary_model_dict : primary_model_dict = instance . __dict__ else : primary_model_dict [ alias ] = instance merged_model_instance = merged_model_type ( ** primary_model_dict ) # type: ignore return merged_model_type , merged_model_alias , merged_model_instance return primary_model_type , primary_model_alias , primary_model_instance @staticmethod def load_top_level_model ( trestle_root : pathlib . Path , model_name : str , model_class : Type [ TopLevelOscalModel ], file_content_type : Optional [ FileContentType ] = None ) -> Tuple [ Union [ OscalBaseModel , List [ OscalBaseModel ], Dict [ str , OscalBaseModel ]], pathlib . Path ]: \"\"\"Load a model by name and model class and infer file content type if not specified. If you need to load an existing model but its content type may not be known, use this method. But the file content type should be specified if it is somehow known. \"\"\" root_model_path = ModelUtils . _root_path_for_top_level_model ( trestle_root , model_name , model_class ) if file_content_type is None : file_content_type = FileContentType . path_to_content_type ( root_model_path ) if not FileContentType . is_readable_file ( file_content_type ): raise TrestleError ( f 'Unable to load model { model_name } without specifying json or yaml.' ) full_model_path = root_model_path . with_suffix ( FileContentType . to_file_extension ( file_content_type )) _ , _ , model = ModelUtils . load_distributed ( full_model_path , trestle_root ) return model , full_model_path @staticmethod def save_top_level_model ( model : TopLevelOscalModel , trestle_root : pathlib . Path , model_name : str , file_content_type : FileContentType ) -> None : \"\"\"Save a model by name and infer model type by inspection. You don't need to specify the model type (catalog, profile, etc.) but you must specify the file content type. If the model directory does not exist, it is created. \"\"\" root_model_path = ModelUtils . _root_path_for_top_level_model ( trestle_root , model_name , model ) full_model_path = root_model_path . with_suffix ( FileContentType . to_file_extension ( file_content_type )) if not full_model_path . parent . exists (): full_model_path . parent . mkdir ( parents = True , exist_ok = True ) model . oscal_write ( full_model_path ) @staticmethod def get_relative_model_type ( relative_path : pathlib . Path ) -> Tuple [ Type [ OscalBaseModel ], str ]: \"\"\" Given the relative path of a file with respect to 'trestle_root' return the oscal model type. Args: relative_path: Relative path of the model with respect to the root directory of the trestle project. Returns: Type of Oscal Model for the provided model Alias of that oscal model. \"\"\" if len ( relative_path . parts ) < 2 : raise TrestleError ( 'Insufficient path length to be a valid relative path w.r.t Trestle project root directory.' ) model_dir = relative_path . parts [ 0 ] model_relative_path = pathlib . Path ( * relative_path . parts [ 2 :]) # catalogs, profiles, etc if model_dir in const . MODEL_DIR_LIST : module_name = const . MODEL_DIR_TO_MODEL_MODULE [ model_dir ] else : raise TrestleError ( f 'No valid trestle model type directory (e.g. catalogs) found for { model_dir } .' ) model_type , model_alias = ModelUtils . get_root_model ( module_name ) full_alias = model_alias for index , part in enumerate ( model_relative_path . parts ): alias = ModelUtils . _extract_alias ( part ) if index > 0 or model_alias != alias : model_alias = alias full_alias = f ' { full_alias } . { model_alias } ' if utils . is_collection_field_type ( model_type ): model_type = utils . get_inner_type ( model_type ) else : model_type = model_type . alias_to_field_map ()[ alias ] . outer_type_ return model_type , full_alias @staticmethod def get_stripped_model_type ( absolute_path : pathlib . Path , absolute_trestle_root : pathlib . Path , aliases_not_to_be_stripped : List [ str ] = None ) -> Tuple [ Type [ OscalBaseModel ], str ]: \"\"\" Get the stripped contextual model class and alias based on the contextual path. This function relies on the directory structure of the trestle model being edited to determine, based on the existing files and folder, which fields should be stripped from the model type represented by the path passed in as a parameter. \"\"\" if aliases_not_to_be_stripped is None : aliases_not_to_be_stripped = [] singular_model_type , model_alias = ModelUtils . get_relative_model_type ( absolute_path . relative_to ( absolute_trestle_root )) logger . debug ( f 'singular model type { singular_model_type } model alias { model_alias } ' ) # Stripped models do not apply to collection types such as List[] and Dict{} # if model type is a list or dict, generate a new wrapping model for it if utils . is_collection_field_type ( singular_model_type ): malias = model_alias . split ( '.' )[ - 1 ] class_name = alias_to_classname ( malias , AliasMode . JSON ) logger . debug ( f 'collection field type class name { class_name } and alias { malias } ' ) model_type = create_model ( class_name , __base__ = OscalBaseModel , __root__ = ( singular_model_type , ... )) logger . debug ( f 'model_type created: { model_type } ' ) model_type = cast ( Type [ OscalBaseModel ], model_type ) return model_type , model_alias malias = model_alias . split ( '.' )[ - 1 ] logger . debug ( f 'not collection field type, malias: { malias } ' ) if absolute_path . is_dir () and malias != ModelUtils . _extract_alias ( absolute_path . name ): split_subdir = absolute_path / malias else : split_subdir = absolute_path . parent / absolute_path . with_suffix ( '' ) . name aliases_to_be_stripped = set () if split_subdir . exists (): for f in iterdir_without_hidden_files ( split_subdir ): alias = ModelUtils . _extract_alias ( f . name ) if alias not in aliases_not_to_be_stripped : aliases_to_be_stripped . add ( alias ) logger . debug ( f 'aliases to be stripped: { aliases_to_be_stripped } ' ) if len ( aliases_to_be_stripped ) > 0 : model_type = singular_model_type . create_stripped_model_type ( stripped_fields_aliases = list ( aliases_to_be_stripped ) ) logger . debug ( f 'model_type: { model_type } ' ) return model_type , model_alias return singular_model_type , model_alias @staticmethod def model_type_to_model_dir ( model_type : str ) -> str : \"\"\"Get plural model directory from model type.\"\"\" if model_type not in const . MODEL_TYPE_LIST : raise err . TrestleError ( f 'Not a valid model type: { model_type } .' ) return const . MODEL_TYPE_TO_MODEL_DIR [ model_type ] @staticmethod def get_models_of_type ( model_type : str , root : pathlib . Path ) -> List [ str ]: \"\"\"Get list of model names for requested type in trestle directory.\"\"\" if model_type not in const . MODEL_TYPE_LIST : raise err . TrestleError ( f 'Model type { model_type } is not supported' ) # search relative to project root trestle_root = extract_trestle_project_root ( root ) if not trestle_root : logger . error ( f 'Given directory { root } is not within a trestle project.' ) raise err . TrestleError ( 'Given directory is not within a trestle project.' ) # contruct path to the model file name model_dir_name = ModelUtils . model_type_to_model_dir ( model_type ) root_model_dir = trestle_root / model_dir_name model_list = [] for f in root_model_dir . glob ( '*/' ): # only look for proper json and yaml files if not ModelUtils . _should_ignore ( f . stem ): if not f . is_dir (): logger . warning ( f 'Ignoring validation of misplaced file { f . name } ' + f 'found in the model directory, { model_dir_name } .' ) else : model_list . append ( f . stem ) return model_list @staticmethod def get_all_models ( root : pathlib . Path ) -> List [ Tuple [ str , str ]]: \"\"\"Get list of all models in trestle directory as tuples (model_type, model_name).\"\"\" full_list = [] for model_type in const . MODEL_TYPE_LIST : models = ModelUtils . get_models_of_type ( model_type , root ) for m in models : full_list . append (( model_type , m )) return full_list @staticmethod def path_for_top_level_model ( trestle_root : pathlib . Path , model_name : str , model_class : Type [ TopLevelOscalModel ], file_content_type : FileContentType ) -> pathlib . Path : \"\"\" Find the full path of a model given its name, model type and file content type. This does not inspect the file system or confirm the needed path and file exists. \"\"\" root_path = ModelUtils . _root_path_for_top_level_model ( trestle_root , model_name , model_class ) return root_path . with_suffix ( FileContentType . to_file_extension ( file_content_type )) @staticmethod def full_path_for_top_level_model ( trestle_root : pathlib . Path , model_name : str , model_class : Type [ TopLevelOscalModel ], ) -> Optional [ pathlib . Path ]: \"\"\" Find the full path of an existing model given its name and model type but no file content type. Use this method when you need the path of a model but you don't know the file content type. Returns None if neither json nor yaml file can be found. If you do know the file content type, use path_for_top_level_model instead. \"\"\" root_model_path = ModelUtils . _root_path_for_top_level_model ( trestle_root , model_name , model_class ) file_content_type = FileContentType . path_to_content_type ( root_model_path ) if not FileContentType . is_readable_file ( file_content_type ): return None return root_model_path . with_suffix ( FileContentType . to_file_extension ( file_content_type )) @staticmethod def get_singular_alias ( alias_path : str , relative_path : Optional [ pathlib . Path ] = None ) -> str : \"\"\" Get the alias in the singular form from a jsonpath. If contextual_mode is True and contextual_path is None, it assumes alias_path is relative to the directory the user is running trestle from. Args: alias_path: The current alias element path as a string relative_path: Optional relative path (w.r.t. trestle_root) to cater for relative element paths. Returns: Alias as a string \"\"\" if len ( alias_path . strip ()) == 0 : raise err . TrestleError ( f 'Invalid jsonpath { alias_path } ' ) singular_alias : str = '' full_alias_path = alias_path if relative_path : logger . debug ( f 'get_singular_alias contextual mode: { str } ' ) _ , full_model_alias = ModelUtils . get_relative_model_type ( relative_path ) first_alias_a = full_model_alias . split ( '.' )[ - 1 ] first_alias_b = alias_path . split ( '.' )[ 0 ] if first_alias_a == first_alias_b : full_model_alias = '.' . join ( full_model_alias . split ( '.' )[: - 1 ]) full_alias_path = '.' . join ([ full_model_alias , alias_path ]) . strip ( '.' ) path_parts = full_alias_path . split ( const . ALIAS_PATH_SEPARATOR ) logger . debug ( f 'path parts: { path_parts } ' ) model_types = [] root_model_alias = path_parts [ 0 ] found = False for module_name in const . MODEL_TYPE_TO_MODEL_MODULE . values (): model_type , model_alias = ModelUtils . get_root_model ( module_name ) if root_model_alias == model_alias : found = True model_types . append ( model_type ) break if not found : raise err . TrestleError ( f ' { root_model_alias } is an invalid root model alias.' ) if len ( path_parts ) == 1 : return root_model_alias model_type = model_types [ 0 ] # go through path parts skipping first one for i in range ( 1 , len ( path_parts )): if utils . is_collection_field_type ( model_type ): # if it is a collection type and last part is * then break if i == len ( path_parts ) - 1 and path_parts [ i ] == '*' : break # otherwise get the inner type of items in the collection model_type = utils . get_inner_type ( model_type ) # and bump i i = i + 1 else : path_part = path_parts [ i ] field_map = model_type . alias_to_field_map () if path_part not in field_map : continue field = field_map [ path_part ] model_type = field . outer_type_ model_types . append ( model_type ) last_alias = path_parts [ - 1 ] if last_alias == '*' : last_alias = path_parts [ - 2 ] # generic model and not list, so return itself fixme doc if not utils . is_collection_field_type ( model_type ): return last_alias parent_model_type = model_types [ - 2 ] try : field_map = parent_model_type . alias_to_field_map () field = field_map [ last_alias ] outer_type = field . outer_type_ inner_type = utils . get_inner_type ( outer_type ) inner_type_name = inner_type . __name__ singular_alias = str_utils . classname_to_alias ( inner_type_name , AliasMode . JSON ) except Exception as e : raise err . TrestleError ( f 'Error in json path { alias_path } : { e } ' ) return singular_alias @staticmethod def get_root_model ( module_name : str ) -> Tuple [ Type [ Any ], str ]: \"\"\"Get the root model class and alias based on the module.\"\"\" try : module = importlib . import_module ( module_name ) except ModuleNotFoundError as e : raise err . TrestleError ( str ( e )) if hasattr ( module , 'Model' ): model_metadata = next ( iter ( module . Model . __fields__ . values ())) return model_metadata . type_ , model_metadata . alias raise err . TrestleError ( 'Invalid module' ) @staticmethod def _root_path_for_top_level_model ( trestle_root : pathlib . Path , model_name : str , model_class : Union [ TopLevelOscalModel , Type [ TopLevelOscalModel ]] ) -> pathlib . Path : \"\"\" Find the root path to a model given its name and class - with no suffix. This is a private method used only to construct the root filepath based on model name and type. It does not check for existence or content type and it does not create the directory if it does not exist. \"\"\" if not hasattr ( model_class , '__module__' ) or model_class . __module__ not in const . MODEL_MODULE_LIST : raise TrestleError ( f 'Unable to determine model type for model { model_name } with class { model_class } ' ) model_alias = const . MODEL_MODULE_TO_MODEL_TYPE [ model_class . __module__ ] model_dir = trestle_root / f ' { const . MODEL_TYPE_TO_MODEL_DIR [ model_alias ] } / { model_name } ' return model_dir / model_alias @staticmethod def _extract_alias ( string_dir : str ) -> str : \"\"\" Extract alias from filename or directory name removing extensions and prefixes related to dict and list. As we need to do this for multiple parts of a path operating on strings is easier. \"\"\" alias = string_dir . split ( '.' )[ 0 ] . split ( const . IDX_SEP )[ - 1 ] # get suffix of file or directory name representing list or dict item return alias @staticmethod def _should_ignore ( name : str ) -> bool : \"\"\"Check if the file or directory should be ignored or not.\"\"\" return name [ 0 ] == '.' or name [ 0 ] == '_' @staticmethod def _load_list ( abs_path : Path , abs_trestle_root : Path ) -> Tuple [ Type [ OscalBaseModel ], str , List [ OscalBaseModel ]]: \"\"\"Given path to a directory of list(array) models, load the distributed models.\"\"\" aliases_not_to_be_stripped = [] instances_to_be_merged : List [ OscalBaseModel ] = [] collection_model_type , collection_model_alias = ModelUtils . get_stripped_model_type ( abs_path , abs_trestle_root ) for path in sorted ( trestle . common . file_utils . iterdir_without_hidden_files ( abs_path )): # ASSUMPTION HERE: if it is a directory, there's a file that can not be decomposed further. if path . is_dir (): continue _ , model_alias , model_instance = ModelUtils . load_distributed ( path , abs_trestle_root ) instances_to_be_merged . append ( model_instance ) aliases_not_to_be_stripped . append ( model_alias . split ( '.' )[ - 1 ]) return collection_model_type , collection_model_alias , instances_to_be_merged @staticmethod def parameter_to_dict ( obj : Union [ OscalBaseModel , str ], partial : bool ) -> Union [ str , Dict [ str , Any ]]: \"\"\" Convert obj to dict containing only string values, storing only the fields that have values set. Args: obj: The parameter or its consituent parts in recursive calls partial: Whether to convert the entire param or just the parts needed for markdown header Returns: The converted parameter as dictionary \"\"\" main_fields = [ 'id' , 'label' , 'values' , 'select' , 'choice' , 'how_many' ] if isinstance ( obj , common . HowMany ): return obj . name if isinstance ( obj , common . Remarks ) or isinstance ( obj , common . ParameterValue ): return obj . __root__ # it is either a string already or we cast it to string if not hasattr ( obj , '__fields_set__' ): return str ( obj ) # it is an oscal object and we need to recurse within its attributes res = {} for field in obj . __fields_set__ : if partial and field not in main_fields : continue attr = getattr ( obj , field ) if not attr : continue if isinstance ( attr , list ): # special handling when only one value present - convert to single string if field == 'values' and len ( attr ) == 1 : res [ field ] = str ( attr [ 0 ] . __root__ ) continue new_list = [] for item in attr : new_list . append ( ModelUtils . parameter_to_dict ( item , partial )) res [ field ] = new_list elif isinstance ( attr , str ): res [ field ] = attr else : res [ field ] = ModelUtils . parameter_to_dict ( attr , partial ) return res @staticmethod def _string_to_howmany ( count_str : str ) -> Optional [ common . HowMany ]: clean_str = count_str . lower () . strip () . replace ( '-' , ' ' ) . replace ( '_' , ' ' ) if clean_str == 'one or more' : return common . HowMany . one_or_more elif clean_str == 'one' : return common . HowMany . one return None @staticmethod def dict_to_parameter ( param_dict : Dict [ str , Any ]) -> common . Parameter : \"\"\" Convert dict with only string values to Parameter with handling for HowMany and with validity checks. Args: param_dict: Dictionary of pure string values representing Parameter contents Returns: A valid OSCAL Parameter Notes: This handles both partial and full parameter dictionaries It checks for validity of the values if a select and HowMany is specified There is special handling for values: If it is a single string it is converted to list of one ParameterValue But if it is a list of strings is regarded as a list of values and is converted to a list of ParameterValues \"\"\" values = param_dict . get ( 'values' , []) # special handling when only one value present - convert to list of 1 if isinstance ( values , str ): values = [ values ] param_dict [ 'values' ] = values if 'select' in param_dict and 'how_many' in param_dict [ 'select' ]: count_str = param_dict [ 'select' ][ 'how_many' ] how_many = ModelUtils . _string_to_howmany ( count_str ) if how_many is None : raise TrestleError ( f 'Unrecognized HowMany value { how_many } in Parameter: should be one-or-more or one.' ) param_dict [ 'select' ][ 'how_many' ] = how_many if how_many == common . HowMany . one and len ( values ) > 1 : logger . warning ( f 'Parameter specifies HowMany=1 but has { len ( values ) } values given.' ) choices = param_dict [ 'select' ] . get ( 'choice' , []) if choices and values : for value in values : if value not in choices : logger . warning ( f \"Parameter { param_dict [ 'id' ] } has value \\\" { value } \\\" not in choices: { choices } .\" ) return common . Parameter ( ** param_dict ) @staticmethod def update_last_modified ( model : TopLevelOscalModel , timestamp : Optional [ datetime ] = None ) -> None : \"\"\"Update the LastModified timestamp in top level model to now.\"\"\" timestamp = timestamp if timestamp else datetime . now () . astimezone () model . metadata . last_modified = common . LastModified ( __root__ = timestamp ) @staticmethod def model_age ( model : TopLevelOscalModel ) -> int : \"\"\"Find time in seconds since LastModified timestamp.\"\"\" # default to one year if no last_modified age_seconds = const . DAY_SECONDS * 365 if model . metadata . last_modified : dt = datetime . now () . astimezone () - model . metadata . last_modified . __root__ age_seconds = dt . seconds return age_seconds @staticmethod def find_values_by_name ( object_of_interest : Any , name_of_interest : str ) -> List [ Any ]: \"\"\"Traverse object and return list of values of specified name.\"\"\" loe = [] if isinstance ( object_of_interest , BaseModel ): value = getattr ( object_of_interest , name_of_interest , None ) if value is not None : loe . append ( value ) fields = getattr ( object_of_interest , '__fields_set__' , None ) if fields is not None : for field in fields : loe . extend ( ModelUtils . find_values_by_name ( getattr ( object_of_interest , field , None ), name_of_interest ) ) elif type ( object_of_interest ) is list : for item in object_of_interest : loe . extend ( ModelUtils . find_values_by_name ( item , name_of_interest )) elif type ( object_of_interest ) is dict : if name_of_interest in object_of_interest : loe . append ( object_of_interest [ name_of_interest ]) for item in object_of_interest . values (): loe . extend ( ModelUtils . find_values_by_name ( item , name_of_interest )) return loe @staticmethod def has_no_duplicate_values_by_name ( object_of_interest : Any , name_of_interest : str ) -> bool : \"\"\"Determine if duplicate values of type exist in object.\"\"\" loe = ModelUtils . find_values_by_name ( object_of_interest , name_of_interest ) set_loe = set ( loe ) if len ( loe ) == len ( set_loe ): return True items = {} for item in loe : items [ item ] = items . get ( item , 0 ) + 1 # now print items for item , instances in items . items (): if instances > 1 : logger . info ( f 'Duplicate detected of item { item } with { instances } instances.' ) return False @staticmethod def _regenerate_uuids_in_place ( object_of_interest : Any , uuid_lut : Dict [ str , str ]) -> Tuple [ Any , Dict [ str , str ]]: \"\"\"Update all uuids in model that require updating. Go through the model and replace all dicts with key == 'uuid' and replace the value with a new uuid4. Build a lookup table of the updates that were made. This function does not update the corresponding refs to those uuid's. That is done by update_uuid_refs Note that this function needs to be started off with uuid_lut == {}, i.e. an empty dict. After that it recurses and grows the lut. Args: object_of_interest: pydantic.BaseModel, list, dict or str will be updated uuid_lut: dict of the growing lut of old:new uuid's. First call must be made with value {} Returns: The updated object_of_interest with new uuid's (but refs to them are not updated) The final lookup table of old:new uuid's \"\"\" uuid_str = 'uuid' # Certain types are known not to need updating and should not change # Resources are identified by uuid, and the corresponding href will have # in front of the uuid string # Neither of these should change # If other similar types are found they should be added to the FixedUuidModel typevar to prevent updating if isinstance ( object_of_interest , common . Resource ): pass elif isinstance ( object_of_interest , BaseModel ): # fields_set has names of fields set when model was initialized fields = getattr ( object_of_interest , '__fields_set__' , None ) for field in fields : new_object = None if field == uuid_str : new_object = str ( uuid . uuid4 ()) uuid_lut [ object_of_interest . __dict__ [ field ]] = new_object else : new_object , uuid_lut = ModelUtils . _regenerate_uuids_in_place ( object_of_interest . __dict__ [ field ], uuid_lut ) object_of_interest . __dict__ [ field ] = new_object elif type ( object_of_interest ) is list : new_list = [] for item in object_of_interest : new_item , uuid_lut = ModelUtils . _regenerate_uuids_in_place ( item , uuid_lut ) new_list . append ( new_item ) object_of_interest = new_list elif type ( object_of_interest ) is dict : new_dict = {} for key , value in object_of_interest . items (): if key == uuid_str : new_val = str ( uuid . uuid4 ()) new_dict [ uuid_str ] = new_val uuid_lut [ value ] = new_val else : new_value , uuid_lut = ModelUtils . _regenerate_uuids_in_place ( value , uuid_lut ) new_dict [ key ] = new_value object_of_interest = new_dict return object_of_interest , uuid_lut @staticmethod def _update_new_uuid_refs ( object_of_interest : Any , uuid_lut : Dict [ str , str ]) -> Tuple [ Any , int ]: \"\"\"Update all refs to uuids that were changed.\"\"\" n_refs_updated = 0 if isinstance ( object_of_interest , BaseModel ): fields = getattr ( object_of_interest , '__fields_set__' , None ) for field in fields : new_object , n_new_updates = ModelUtils . _update_new_uuid_refs ( object_of_interest . __dict__ [ field ], uuid_lut ) n_refs_updated += n_new_updates object_of_interest . __dict__ [ field ] = new_object elif type ( object_of_interest ) is list : new_list = [] for item in object_of_interest : new_item , n_new_updates = ModelUtils . _update_new_uuid_refs ( item , uuid_lut ) n_refs_updated += n_new_updates new_list . append ( new_item ) object_of_interest = new_list elif type ( object_of_interest ) is dict : new_dict = {} for key , value in object_of_interest . items (): if isinstance ( value , str ): if value in uuid_lut : new_dict [ key ] = uuid_lut [ value ] n_refs_updated += 1 else : new_dict [ key ] = value else : new_value , n_new_updates = ModelUtils . _update_new_uuid_refs ( value , uuid_lut ) n_refs_updated += n_new_updates new_dict [ key ] = new_value object_of_interest = new_dict elif isinstance ( object_of_interest , str ): if object_of_interest in uuid_lut : n_refs_updated += 1 object_of_interest = uuid_lut [ object_of_interest ] return object_of_interest , n_refs_updated @staticmethod def regenerate_uuids ( object_of_interest : Any ) -> Tuple [ Any , Dict [ str , str ], int ]: \"\"\"Regenerate all uuids in object and update corresponding references. Find all dicts with key == 'uuid' and replace the value with a new uuid4. Build a corresponding lookup table as you go, of old:new uuid values. Then make a second pass through the object and replace all string values present in the lookup table with the new value. Args: object_of_interest: pydantic.BaseModel, list, dict or str will be updated Returns: The updated object with new uuid's and refs The final lookup table of old:new uuid's A count of the number of refs that were updated \"\"\" new_object , uuid_lut = ModelUtils . _regenerate_uuids_in_place ( object_of_interest , {}) new_object , n_refs_updated = ModelUtils . _update_new_uuid_refs ( new_object , uuid_lut ) return new_object , uuid_lut , n_refs_updated @staticmethod def models_are_equivalent ( model_a : Optional [ TopLevelOscalModel ], model_b : Optional [ TopLevelOscalModel ]) -> bool : \"\"\"Test if models are equivalent except for last modified and uuid.\"\"\" # set b's extra properties to those of a then later undo so the models are not changed by this routine if ( model_b and not model_a ) or ( model_a and not model_b ): return False b_last_modified = model_b . metadata . last_modified model_b . metadata . last_modified = model_a . metadata . last_modified b_uuid = model_b . uuid model_b . uuid = model_a . uuid equivalent = model_a == model_b model_b . metadata . last_modified = b_last_modified model_b . uuid = b_uuid return equivalent Methods \u00a4 dict_to_parameter ( param_dict ) staticmethod \u00a4 Convert dict with only string values to Parameter with handling for HowMany and with validity checks. Parameters: Name Type Description Default param_dict Dict[str, Any] Dictionary of pure string values representing Parameter contents required Returns: Type Description Parameter A valid OSCAL Parameter Notes This handles both partial and full parameter dictionaries It checks for validity of the values if a select and HowMany is specified There is special handling for values: If it is a single string it is converted to list of one ParameterValue But if it is a list of strings is regarded as a list of values and is converted to a list of ParameterValues Source code in trestle/common/model_utils.py @staticmethod def dict_to_parameter ( param_dict : Dict [ str , Any ]) -> common . Parameter : \"\"\" Convert dict with only string values to Parameter with handling for HowMany and with validity checks. Args: param_dict: Dictionary of pure string values representing Parameter contents Returns: A valid OSCAL Parameter Notes: This handles both partial and full parameter dictionaries It checks for validity of the values if a select and HowMany is specified There is special handling for values: If it is a single string it is converted to list of one ParameterValue But if it is a list of strings is regarded as a list of values and is converted to a list of ParameterValues \"\"\" values = param_dict . get ( 'values' , []) # special handling when only one value present - convert to list of 1 if isinstance ( values , str ): values = [ values ] param_dict [ 'values' ] = values if 'select' in param_dict and 'how_many' in param_dict [ 'select' ]: count_str = param_dict [ 'select' ][ 'how_many' ] how_many = ModelUtils . _string_to_howmany ( count_str ) if how_many is None : raise TrestleError ( f 'Unrecognized HowMany value { how_many } in Parameter: should be one-or-more or one.' ) param_dict [ 'select' ][ 'how_many' ] = how_many if how_many == common . HowMany . one and len ( values ) > 1 : logger . warning ( f 'Parameter specifies HowMany=1 but has { len ( values ) } values given.' ) choices = param_dict [ 'select' ] . get ( 'choice' , []) if choices and values : for value in values : if value not in choices : logger . warning ( f \"Parameter { param_dict [ 'id' ] } has value \\\" { value } \\\" not in choices: { choices } .\" ) return common . Parameter ( ** param_dict ) find_values_by_name ( object_of_interest , name_of_interest ) staticmethod \u00a4 Traverse object and return list of values of specified name. Source code in trestle/common/model_utils.py @staticmethod def find_values_by_name ( object_of_interest : Any , name_of_interest : str ) -> List [ Any ]: \"\"\"Traverse object and return list of values of specified name.\"\"\" loe = [] if isinstance ( object_of_interest , BaseModel ): value = getattr ( object_of_interest , name_of_interest , None ) if value is not None : loe . append ( value ) fields = getattr ( object_of_interest , '__fields_set__' , None ) if fields is not None : for field in fields : loe . extend ( ModelUtils . find_values_by_name ( getattr ( object_of_interest , field , None ), name_of_interest ) ) elif type ( object_of_interest ) is list : for item in object_of_interest : loe . extend ( ModelUtils . find_values_by_name ( item , name_of_interest )) elif type ( object_of_interest ) is dict : if name_of_interest in object_of_interest : loe . append ( object_of_interest [ name_of_interest ]) for item in object_of_interest . values (): loe . extend ( ModelUtils . find_values_by_name ( item , name_of_interest )) return loe full_path_for_top_level_model ( trestle_root , model_name , model_class ) staticmethod \u00a4 Find the full path of an existing model given its name and model type but no file content type. Use this method when you need the path of a model but you don't know the file content type. Returns None if neither json nor yaml file can be found. If you do know the file content type, use path_for_top_level_model instead. Source code in trestle/common/model_utils.py @staticmethod def full_path_for_top_level_model ( trestle_root : pathlib . Path , model_name : str , model_class : Type [ TopLevelOscalModel ], ) -> Optional [ pathlib . Path ]: \"\"\" Find the full path of an existing model given its name and model type but no file content type. Use this method when you need the path of a model but you don't know the file content type. Returns None if neither json nor yaml file can be found. If you do know the file content type, use path_for_top_level_model instead. \"\"\" root_model_path = ModelUtils . _root_path_for_top_level_model ( trestle_root , model_name , model_class ) file_content_type = FileContentType . path_to_content_type ( root_model_path ) if not FileContentType . is_readable_file ( file_content_type ): return None return root_model_path . with_suffix ( FileContentType . to_file_extension ( file_content_type )) get_all_models ( root ) staticmethod \u00a4 Get list of all models in trestle directory as tuples (model_type, model_name). Source code in trestle/common/model_utils.py @staticmethod def get_all_models ( root : pathlib . Path ) -> List [ Tuple [ str , str ]]: \"\"\"Get list of all models in trestle directory as tuples (model_type, model_name).\"\"\" full_list = [] for model_type in const . MODEL_TYPE_LIST : models = ModelUtils . get_models_of_type ( model_type , root ) for m in models : full_list . append (( model_type , m )) return full_list get_models_of_type ( model_type , root ) staticmethod \u00a4 Get list of model names for requested type in trestle directory. Source code in trestle/common/model_utils.py @staticmethod def get_models_of_type ( model_type : str , root : pathlib . Path ) -> List [ str ]: \"\"\"Get list of model names for requested type in trestle directory.\"\"\" if model_type not in const . MODEL_TYPE_LIST : raise err . TrestleError ( f 'Model type { model_type } is not supported' ) # search relative to project root trestle_root = extract_trestle_project_root ( root ) if not trestle_root : logger . error ( f 'Given directory { root } is not within a trestle project.' ) raise err . TrestleError ( 'Given directory is not within a trestle project.' ) # contruct path to the model file name model_dir_name = ModelUtils . model_type_to_model_dir ( model_type ) root_model_dir = trestle_root / model_dir_name model_list = [] for f in root_model_dir . glob ( '*/' ): # only look for proper json and yaml files if not ModelUtils . _should_ignore ( f . stem ): if not f . is_dir (): logger . warning ( f 'Ignoring validation of misplaced file { f . name } ' + f 'found in the model directory, { model_dir_name } .' ) else : model_list . append ( f . stem ) return model_list get_relative_model_type ( relative_path ) staticmethod \u00a4 Given the relative path of a file with respect to 'trestle_root' return the oscal model type. Parameters: Name Type Description Default relative_path Path Relative path of the model with respect to the root directory of the trestle project. required Returns: Type Description Tuple[Type[trestle.core.base_model.OscalBaseModel], str] Type of Oscal Model for the provided model Alias of that oscal model. Source code in trestle/common/model_utils.py @staticmethod def get_relative_model_type ( relative_path : pathlib . Path ) -> Tuple [ Type [ OscalBaseModel ], str ]: \"\"\" Given the relative path of a file with respect to 'trestle_root' return the oscal model type. Args: relative_path: Relative path of the model with respect to the root directory of the trestle project. Returns: Type of Oscal Model for the provided model Alias of that oscal model. \"\"\" if len ( relative_path . parts ) < 2 : raise TrestleError ( 'Insufficient path length to be a valid relative path w.r.t Trestle project root directory.' ) model_dir = relative_path . parts [ 0 ] model_relative_path = pathlib . Path ( * relative_path . parts [ 2 :]) # catalogs, profiles, etc if model_dir in const . MODEL_DIR_LIST : module_name = const . MODEL_DIR_TO_MODEL_MODULE [ model_dir ] else : raise TrestleError ( f 'No valid trestle model type directory (e.g. catalogs) found for { model_dir } .' ) model_type , model_alias = ModelUtils . get_root_model ( module_name ) full_alias = model_alias for index , part in enumerate ( model_relative_path . parts ): alias = ModelUtils . _extract_alias ( part ) if index > 0 or model_alias != alias : model_alias = alias full_alias = f ' { full_alias } . { model_alias } ' if utils . is_collection_field_type ( model_type ): model_type = utils . get_inner_type ( model_type ) else : model_type = model_type . alias_to_field_map ()[ alias ] . outer_type_ return model_type , full_alias get_root_model ( module_name ) staticmethod \u00a4 Get the root model class and alias based on the module. Source code in trestle/common/model_utils.py @staticmethod def get_root_model ( module_name : str ) -> Tuple [ Type [ Any ], str ]: \"\"\"Get the root model class and alias based on the module.\"\"\" try : module = importlib . import_module ( module_name ) except ModuleNotFoundError as e : raise err . TrestleError ( str ( e )) if hasattr ( module , 'Model' ): model_metadata = next ( iter ( module . Model . __fields__ . values ())) return model_metadata . type_ , model_metadata . alias raise err . TrestleError ( 'Invalid module' ) get_singular_alias ( alias_path , relative_path = None ) staticmethod \u00a4 Get the alias in the singular form from a jsonpath. If contextual_mode is True and contextual_path is None, it assumes alias_path is relative to the directory the user is running trestle from. Parameters: Name Type Description Default alias_path str The current alias element path as a string required relative_path Optional[pathlib.Path] Optional relative path (w.r.t. trestle_root) to cater for relative element paths. None Returns: Type Description str Alias as a string Source code in trestle/common/model_utils.py @staticmethod def get_singular_alias ( alias_path : str , relative_path : Optional [ pathlib . Path ] = None ) -> str : \"\"\" Get the alias in the singular form from a jsonpath. If contextual_mode is True and contextual_path is None, it assumes alias_path is relative to the directory the user is running trestle from. Args: alias_path: The current alias element path as a string relative_path: Optional relative path (w.r.t. trestle_root) to cater for relative element paths. Returns: Alias as a string \"\"\" if len ( alias_path . strip ()) == 0 : raise err . TrestleError ( f 'Invalid jsonpath { alias_path } ' ) singular_alias : str = '' full_alias_path = alias_path if relative_path : logger . debug ( f 'get_singular_alias contextual mode: { str } ' ) _ , full_model_alias = ModelUtils . get_relative_model_type ( relative_path ) first_alias_a = full_model_alias . split ( '.' )[ - 1 ] first_alias_b = alias_path . split ( '.' )[ 0 ] if first_alias_a == first_alias_b : full_model_alias = '.' . join ( full_model_alias . split ( '.' )[: - 1 ]) full_alias_path = '.' . join ([ full_model_alias , alias_path ]) . strip ( '.' ) path_parts = full_alias_path . split ( const . ALIAS_PATH_SEPARATOR ) logger . debug ( f 'path parts: { path_parts } ' ) model_types = [] root_model_alias = path_parts [ 0 ] found = False for module_name in const . MODEL_TYPE_TO_MODEL_MODULE . values (): model_type , model_alias = ModelUtils . get_root_model ( module_name ) if root_model_alias == model_alias : found = True model_types . append ( model_type ) break if not found : raise err . TrestleError ( f ' { root_model_alias } is an invalid root model alias.' ) if len ( path_parts ) == 1 : return root_model_alias model_type = model_types [ 0 ] # go through path parts skipping first one for i in range ( 1 , len ( path_parts )): if utils . is_collection_field_type ( model_type ): # if it is a collection type and last part is * then break if i == len ( path_parts ) - 1 and path_parts [ i ] == '*' : break # otherwise get the inner type of items in the collection model_type = utils . get_inner_type ( model_type ) # and bump i i = i + 1 else : path_part = path_parts [ i ] field_map = model_type . alias_to_field_map () if path_part not in field_map : continue field = field_map [ path_part ] model_type = field . outer_type_ model_types . append ( model_type ) last_alias = path_parts [ - 1 ] if last_alias == '*' : last_alias = path_parts [ - 2 ] # generic model and not list, so return itself fixme doc if not utils . is_collection_field_type ( model_type ): return last_alias parent_model_type = model_types [ - 2 ] try : field_map = parent_model_type . alias_to_field_map () field = field_map [ last_alias ] outer_type = field . outer_type_ inner_type = utils . get_inner_type ( outer_type ) inner_type_name = inner_type . __name__ singular_alias = str_utils . classname_to_alias ( inner_type_name , AliasMode . JSON ) except Exception as e : raise err . TrestleError ( f 'Error in json path { alias_path } : { e } ' ) return singular_alias get_stripped_model_type ( absolute_path , absolute_trestle_root , aliases_not_to_be_stripped = None ) staticmethod \u00a4 Get the stripped contextual model class and alias based on the contextual path. This function relies on the directory structure of the trestle model being edited to determine, based on the existing files and folder, which fields should be stripped from the model type represented by the path passed in as a parameter. Source code in trestle/common/model_utils.py @staticmethod def get_stripped_model_type ( absolute_path : pathlib . Path , absolute_trestle_root : pathlib . Path , aliases_not_to_be_stripped : List [ str ] = None ) -> Tuple [ Type [ OscalBaseModel ], str ]: \"\"\" Get the stripped contextual model class and alias based on the contextual path. This function relies on the directory structure of the trestle model being edited to determine, based on the existing files and folder, which fields should be stripped from the model type represented by the path passed in as a parameter. \"\"\" if aliases_not_to_be_stripped is None : aliases_not_to_be_stripped = [] singular_model_type , model_alias = ModelUtils . get_relative_model_type ( absolute_path . relative_to ( absolute_trestle_root )) logger . debug ( f 'singular model type { singular_model_type } model alias { model_alias } ' ) # Stripped models do not apply to collection types such as List[] and Dict{} # if model type is a list or dict, generate a new wrapping model for it if utils . is_collection_field_type ( singular_model_type ): malias = model_alias . split ( '.' )[ - 1 ] class_name = alias_to_classname ( malias , AliasMode . JSON ) logger . debug ( f 'collection field type class name { class_name } and alias { malias } ' ) model_type = create_model ( class_name , __base__ = OscalBaseModel , __root__ = ( singular_model_type , ... )) logger . debug ( f 'model_type created: { model_type } ' ) model_type = cast ( Type [ OscalBaseModel ], model_type ) return model_type , model_alias malias = model_alias . split ( '.' )[ - 1 ] logger . debug ( f 'not collection field type, malias: { malias } ' ) if absolute_path . is_dir () and malias != ModelUtils . _extract_alias ( absolute_path . name ): split_subdir = absolute_path / malias else : split_subdir = absolute_path . parent / absolute_path . with_suffix ( '' ) . name aliases_to_be_stripped = set () if split_subdir . exists (): for f in iterdir_without_hidden_files ( split_subdir ): alias = ModelUtils . _extract_alias ( f . name ) if alias not in aliases_not_to_be_stripped : aliases_to_be_stripped . add ( alias ) logger . debug ( f 'aliases to be stripped: { aliases_to_be_stripped } ' ) if len ( aliases_to_be_stripped ) > 0 : model_type = singular_model_type . create_stripped_model_type ( stripped_fields_aliases = list ( aliases_to_be_stripped ) ) logger . debug ( f 'model_type: { model_type } ' ) return model_type , model_alias return singular_model_type , model_alias has_no_duplicate_values_by_name ( object_of_interest , name_of_interest ) staticmethod \u00a4 Determine if duplicate values of type exist in object. Source code in trestle/common/model_utils.py @staticmethod def has_no_duplicate_values_by_name ( object_of_interest : Any , name_of_interest : str ) -> bool : \"\"\"Determine if duplicate values of type exist in object.\"\"\" loe = ModelUtils . find_values_by_name ( object_of_interest , name_of_interest ) set_loe = set ( loe ) if len ( loe ) == len ( set_loe ): return True items = {} for item in loe : items [ item ] = items . get ( item , 0 ) + 1 # now print items for item , instances in items . items (): if instances > 1 : logger . info ( f 'Duplicate detected of item { item } with { instances } instances.' ) return False load_distributed ( abs_path , abs_trestle_root , collection_type = None ) staticmethod \u00a4 Given path to a model, load the model. If the model is decomposed/split/distributed,the decomposed models are loaded recursively. Parameters: Name Type Description Default abs_path Path The path to the file/directory to be loaded. required abs_trestle_root Path The trestle project root directory. required collection_type Optional[Type[Any]] The type of collection model, if it is a collection model. typing.List is the only collection type handled or expected. Defaults to None. None Returns: Type Description Tuple[Type[trestle.core.base_model.OscalBaseModel], str, Union[trestle.core.base_model.OscalBaseModel, List[trestle.core.base_model.OscalBaseModel], Dict[str, trestle.core.base_model.OscalBaseModel]]] Return a tuple of Model Type (e.g. class 'trestle.oscal.catalog.Catalog'), Model Alias (e.g. 'catalog.metadata') and Instance of the Model. If the model is decomposed/split/distributed, the instance of the model contains the decomposed models loaded recursively. Source code in trestle/common/model_utils.py @staticmethod def load_distributed ( abs_path : Path , abs_trestle_root : Path , collection_type : Optional [ Type [ Any ]] = None ) -> Tuple [ Type [ OscalBaseModel ], str , Union [ OscalBaseModel , List [ OscalBaseModel ], Dict [ str , OscalBaseModel ]]]: \"\"\" Given path to a model, load the model. If the model is decomposed/split/distributed,the decomposed models are loaded recursively. Args: abs_path: The path to the file/directory to be loaded. abs_trestle_root: The trestle project root directory. collection_type: The type of collection model, if it is a collection model. typing.List is the only collection type handled or expected. Defaults to None. Returns: Return a tuple of Model Type (e.g. class 'trestle.oscal.catalog.Catalog'), Model Alias (e.g. 'catalog.metadata') and Instance of the Model. If the model is decomposed/split/distributed, the instance of the model contains the decomposed models loaded recursively. \"\"\" # if trying to load file that does not exist, load path instead if not abs_path . exists (): abs_path = abs_path . with_name ( abs_path . stem ) if not abs_path . exists (): raise TrestleNotFoundError ( f 'File { abs_path } not found for load.' ) if collection_type : # If the path contains a list type model if collection_type is list : return ModelUtils . _load_list ( abs_path , abs_trestle_root ) # the only other collection type in OSCAL is dict, and it only applies to include_all, # which is too granular ever to be loaded by this routine else : raise TrestleError ( f 'Collection type { collection_type } not recognized for distributed load.' ) # Get current model primary_model_type , primary_model_alias = ModelUtils . get_stripped_model_type ( abs_path , abs_trestle_root ) primary_model_instance : Optional [ OscalBaseModel ] = None # is this an attempt to load an actual json or yaml file? content_type = FileContentType . path_to_content_type ( abs_path ) # if file is sought but it doesn't exist, ignore and load as decomposed model if FileContentType . is_readable_file ( content_type ) and abs_path . exists (): primary_model_instance = primary_model_type . oscal_read ( abs_path ) # Is model decomposed? decomposed_dir = abs_path . with_name ( abs_path . stem ) if decomposed_dir . exists (): aliases_not_to_be_stripped = [] instances_to_be_merged : List [ OscalBaseModel ] = [] for local_path in sorted ( trestle . common . file_utils . iterdir_without_hidden_files ( decomposed_dir )): if local_path . is_file (): model_type , model_alias , model_instance = ModelUtils . load_distributed ( local_path , abs_trestle_root ) aliases_not_to_be_stripped . append ( model_alias . split ( '.' )[ - 1 ]) instances_to_be_merged . append ( model_instance ) elif local_path . is_dir (): model_type , model_alias = ModelUtils . get_stripped_model_type ( local_path , abs_trestle_root ) # Only load the directory if it is a collection model. Otherwise do nothing - it gets loaded when # iterating over the model file # If a model is just a container for a list e.g. # class Foo(OscalBaseModel): noqa: E800 # __root__: List[Bar] noqa: E800 # You need to test whether first a root key exists # then whether the outer_type of root is a collection. # Alternative is to do a try except to avoid the error for an unknown key. if model_type . is_collection_container (): # This directory is a decomposed List or Dict collection_type = model_type . get_collection_type () model_type , model_alias , model_instance = ModelUtils . load_distributed ( local_path , abs_trestle_root , collection_type ) aliases_not_to_be_stripped . append ( model_alias . split ( '.' )[ - 1 ]) instances_to_be_merged . append ( model_instance ) primary_model_dict = {} if primary_model_instance is not None : primary_model_dict = primary_model_instance . __dict__ merged_model_type , merged_model_alias = ModelUtils . get_stripped_model_type ( abs_path , abs_trestle_root , aliases_not_to_be_stripped ) # The following use of top_level is to allow loading of a top level model by name only, e.g. MyCatalog # There may be a better overall way to approach this. top_level = len ( merged_model_alias . split ( '.' )) == 1 for i in range ( len ( aliases_not_to_be_stripped )): alias = aliases_not_to_be_stripped [ i ] instance = instances_to_be_merged [ i ] if hasattr ( instance , '__dict__' ) and '__root__' in instance . __dict__ and isinstance ( instance , OscalBaseModel ): instance = instance . __dict__ [ '__root__' ] if top_level and not primary_model_dict : primary_model_dict = instance . __dict__ else : primary_model_dict [ alias ] = instance merged_model_instance = merged_model_type ( ** primary_model_dict ) # type: ignore return merged_model_type , merged_model_alias , merged_model_instance return primary_model_type , primary_model_alias , primary_model_instance load_top_level_model ( trestle_root , model_name , model_class , file_content_type = None ) staticmethod \u00a4 Load a model by name and model class and infer file content type if not specified. If you need to load an existing model but its content type may not be known, use this method. But the file content type should be specified if it is somehow known. Source code in trestle/common/model_utils.py @staticmethod def load_top_level_model ( trestle_root : pathlib . Path , model_name : str , model_class : Type [ TopLevelOscalModel ], file_content_type : Optional [ FileContentType ] = None ) -> Tuple [ Union [ OscalBaseModel , List [ OscalBaseModel ], Dict [ str , OscalBaseModel ]], pathlib . Path ]: \"\"\"Load a model by name and model class and infer file content type if not specified. If you need to load an existing model but its content type may not be known, use this method. But the file content type should be specified if it is somehow known. \"\"\" root_model_path = ModelUtils . _root_path_for_top_level_model ( trestle_root , model_name , model_class ) if file_content_type is None : file_content_type = FileContentType . path_to_content_type ( root_model_path ) if not FileContentType . is_readable_file ( file_content_type ): raise TrestleError ( f 'Unable to load model { model_name } without specifying json or yaml.' ) full_model_path = root_model_path . with_suffix ( FileContentType . to_file_extension ( file_content_type )) _ , _ , model = ModelUtils . load_distributed ( full_model_path , trestle_root ) return model , full_model_path model_age ( model ) staticmethod \u00a4 Find time in seconds since LastModified timestamp. Source code in trestle/common/model_utils.py @staticmethod def model_age ( model : TopLevelOscalModel ) -> int : \"\"\"Find time in seconds since LastModified timestamp.\"\"\" # default to one year if no last_modified age_seconds = const . DAY_SECONDS * 365 if model . metadata . last_modified : dt = datetime . now () . astimezone () - model . metadata . last_modified . __root__ age_seconds = dt . seconds return age_seconds model_type_to_model_dir ( model_type ) staticmethod \u00a4 Get plural model directory from model type. Source code in trestle/common/model_utils.py @staticmethod def model_type_to_model_dir ( model_type : str ) -> str : \"\"\"Get plural model directory from model type.\"\"\" if model_type not in const . MODEL_TYPE_LIST : raise err . TrestleError ( f 'Not a valid model type: { model_type } .' ) return const . MODEL_TYPE_TO_MODEL_DIR [ model_type ] models_are_equivalent ( model_a , model_b ) staticmethod \u00a4 Test if models are equivalent except for last modified and uuid. Source code in trestle/common/model_utils.py @staticmethod def models_are_equivalent ( model_a : Optional [ TopLevelOscalModel ], model_b : Optional [ TopLevelOscalModel ]) -> bool : \"\"\"Test if models are equivalent except for last modified and uuid.\"\"\" # set b's extra properties to those of a then later undo so the models are not changed by this routine if ( model_b and not model_a ) or ( model_a and not model_b ): return False b_last_modified = model_b . metadata . last_modified model_b . metadata . last_modified = model_a . metadata . last_modified b_uuid = model_b . uuid model_b . uuid = model_a . uuid equivalent = model_a == model_b model_b . metadata . last_modified = b_last_modified model_b . uuid = b_uuid return equivalent parameter_to_dict ( obj , partial ) staticmethod \u00a4 Convert obj to dict containing only string values, storing only the fields that have values set. Parameters: Name Type Description Default obj Union[trestle.core.base_model.OscalBaseModel, str] The parameter or its consituent parts in recursive calls required partial bool Whether to convert the entire param or just the parts needed for markdown header required Returns: Type Description Union[str, Dict[str, Any]] The converted parameter as dictionary Source code in trestle/common/model_utils.py @staticmethod def parameter_to_dict ( obj : Union [ OscalBaseModel , str ], partial : bool ) -> Union [ str , Dict [ str , Any ]]: \"\"\" Convert obj to dict containing only string values, storing only the fields that have values set. Args: obj: The parameter or its consituent parts in recursive calls partial: Whether to convert the entire param or just the parts needed for markdown header Returns: The converted parameter as dictionary \"\"\" main_fields = [ 'id' , 'label' , 'values' , 'select' , 'choice' , 'how_many' ] if isinstance ( obj , common . HowMany ): return obj . name if isinstance ( obj , common . Remarks ) or isinstance ( obj , common . ParameterValue ): return obj . __root__ # it is either a string already or we cast it to string if not hasattr ( obj , '__fields_set__' ): return str ( obj ) # it is an oscal object and we need to recurse within its attributes res = {} for field in obj . __fields_set__ : if partial and field not in main_fields : continue attr = getattr ( obj , field ) if not attr : continue if isinstance ( attr , list ): # special handling when only one value present - convert to single string if field == 'values' and len ( attr ) == 1 : res [ field ] = str ( attr [ 0 ] . __root__ ) continue new_list = [] for item in attr : new_list . append ( ModelUtils . parameter_to_dict ( item , partial )) res [ field ] = new_list elif isinstance ( attr , str ): res [ field ] = attr else : res [ field ] = ModelUtils . parameter_to_dict ( attr , partial ) return res path_for_top_level_model ( trestle_root , model_name , model_class , file_content_type ) staticmethod \u00a4 Find the full path of a model given its name, model type and file content type. This does not inspect the file system or confirm the needed path and file exists. Source code in trestle/common/model_utils.py @staticmethod def path_for_top_level_model ( trestle_root : pathlib . Path , model_name : str , model_class : Type [ TopLevelOscalModel ], file_content_type : FileContentType ) -> pathlib . Path : \"\"\" Find the full path of a model given its name, model type and file content type. This does not inspect the file system or confirm the needed path and file exists. \"\"\" root_path = ModelUtils . _root_path_for_top_level_model ( trestle_root , model_name , model_class ) return root_path . with_suffix ( FileContentType . to_file_extension ( file_content_type )) regenerate_uuids ( object_of_interest ) staticmethod \u00a4 Regenerate all uuids in object and update corresponding references. Find all dicts with key == 'uuid' and replace the value with a new uuid4. Build a corresponding lookup table as you go, of old:new uuid values. Then make a second pass through the object and replace all string values present in the lookup table with the new value. Parameters: Name Type Description Default object_of_interest Any pydantic.BaseModel, list, dict or str will be updated required Returns: Type Description The updated object with new uuid's and refs The final lookup table of old new uuid's A count of the number of refs that were updated Source code in trestle/common/model_utils.py @staticmethod def regenerate_uuids ( object_of_interest : Any ) -> Tuple [ Any , Dict [ str , str ], int ]: \"\"\"Regenerate all uuids in object and update corresponding references. Find all dicts with key == 'uuid' and replace the value with a new uuid4. Build a corresponding lookup table as you go, of old:new uuid values. Then make a second pass through the object and replace all string values present in the lookup table with the new value. Args: object_of_interest: pydantic.BaseModel, list, dict or str will be updated Returns: The updated object with new uuid's and refs The final lookup table of old:new uuid's A count of the number of refs that were updated \"\"\" new_object , uuid_lut = ModelUtils . _regenerate_uuids_in_place ( object_of_interest , {}) new_object , n_refs_updated = ModelUtils . _update_new_uuid_refs ( new_object , uuid_lut ) return new_object , uuid_lut , n_refs_updated save_top_level_model ( model , trestle_root , model_name , file_content_type ) staticmethod \u00a4 Save a model by name and infer model type by inspection. You don't need to specify the model type (catalog, profile, etc.) but you must specify the file content type. If the model directory does not exist, it is created. Source code in trestle/common/model_utils.py @staticmethod def save_top_level_model ( model : TopLevelOscalModel , trestle_root : pathlib . Path , model_name : str , file_content_type : FileContentType ) -> None : \"\"\"Save a model by name and infer model type by inspection. You don't need to specify the model type (catalog, profile, etc.) but you must specify the file content type. If the model directory does not exist, it is created. \"\"\" root_model_path = ModelUtils . _root_path_for_top_level_model ( trestle_root , model_name , model ) full_model_path = root_model_path . with_suffix ( FileContentType . to_file_extension ( file_content_type )) if not full_model_path . parent . exists (): full_model_path . parent . mkdir ( parents = True , exist_ok = True ) model . oscal_write ( full_model_path ) update_last_modified ( model , timestamp = None ) staticmethod \u00a4 Update the LastModified timestamp in top level model to now. Source code in trestle/common/model_utils.py @staticmethod def update_last_modified ( model : TopLevelOscalModel , timestamp : Optional [ datetime ] = None ) -> None : \"\"\"Update the LastModified timestamp in top level model to now.\"\"\" timestamp = timestamp if timestamp else datetime . now () . astimezone () model . metadata . last_modified = common . LastModified ( __root__ = timestamp ) handler: python","title":"model_utils"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils","text":"Common utilities for the OSCAL models and directories.","title":"model_utils"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.logger","text":"","title":"logger"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils","text":"Utilities for the OSCAL models input and output. Source code in trestle/common/model_utils.py class ModelUtils : \"\"\"Utilities for the OSCAL models input and output.\"\"\" @staticmethod def load_distributed ( abs_path : Path , abs_trestle_root : Path , collection_type : Optional [ Type [ Any ]] = None ) -> Tuple [ Type [ OscalBaseModel ], str , Union [ OscalBaseModel , List [ OscalBaseModel ], Dict [ str , OscalBaseModel ]]]: \"\"\" Given path to a model, load the model. If the model is decomposed/split/distributed,the decomposed models are loaded recursively. Args: abs_path: The path to the file/directory to be loaded. abs_trestle_root: The trestle project root directory. collection_type: The type of collection model, if it is a collection model. typing.List is the only collection type handled or expected. Defaults to None. Returns: Return a tuple of Model Type (e.g. class 'trestle.oscal.catalog.Catalog'), Model Alias (e.g. 'catalog.metadata') and Instance of the Model. If the model is decomposed/split/distributed, the instance of the model contains the decomposed models loaded recursively. \"\"\" # if trying to load file that does not exist, load path instead if not abs_path . exists (): abs_path = abs_path . with_name ( abs_path . stem ) if not abs_path . exists (): raise TrestleNotFoundError ( f 'File { abs_path } not found for load.' ) if collection_type : # If the path contains a list type model if collection_type is list : return ModelUtils . _load_list ( abs_path , abs_trestle_root ) # the only other collection type in OSCAL is dict, and it only applies to include_all, # which is too granular ever to be loaded by this routine else : raise TrestleError ( f 'Collection type { collection_type } not recognized for distributed load.' ) # Get current model primary_model_type , primary_model_alias = ModelUtils . get_stripped_model_type ( abs_path , abs_trestle_root ) primary_model_instance : Optional [ OscalBaseModel ] = None # is this an attempt to load an actual json or yaml file? content_type = FileContentType . path_to_content_type ( abs_path ) # if file is sought but it doesn't exist, ignore and load as decomposed model if FileContentType . is_readable_file ( content_type ) and abs_path . exists (): primary_model_instance = primary_model_type . oscal_read ( abs_path ) # Is model decomposed? decomposed_dir = abs_path . with_name ( abs_path . stem ) if decomposed_dir . exists (): aliases_not_to_be_stripped = [] instances_to_be_merged : List [ OscalBaseModel ] = [] for local_path in sorted ( trestle . common . file_utils . iterdir_without_hidden_files ( decomposed_dir )): if local_path . is_file (): model_type , model_alias , model_instance = ModelUtils . load_distributed ( local_path , abs_trestle_root ) aliases_not_to_be_stripped . append ( model_alias . split ( '.' )[ - 1 ]) instances_to_be_merged . append ( model_instance ) elif local_path . is_dir (): model_type , model_alias = ModelUtils . get_stripped_model_type ( local_path , abs_trestle_root ) # Only load the directory if it is a collection model. Otherwise do nothing - it gets loaded when # iterating over the model file # If a model is just a container for a list e.g. # class Foo(OscalBaseModel): noqa: E800 # __root__: List[Bar] noqa: E800 # You need to test whether first a root key exists # then whether the outer_type of root is a collection. # Alternative is to do a try except to avoid the error for an unknown key. if model_type . is_collection_container (): # This directory is a decomposed List or Dict collection_type = model_type . get_collection_type () model_type , model_alias , model_instance = ModelUtils . load_distributed ( local_path , abs_trestle_root , collection_type ) aliases_not_to_be_stripped . append ( model_alias . split ( '.' )[ - 1 ]) instances_to_be_merged . append ( model_instance ) primary_model_dict = {} if primary_model_instance is not None : primary_model_dict = primary_model_instance . __dict__ merged_model_type , merged_model_alias = ModelUtils . get_stripped_model_type ( abs_path , abs_trestle_root , aliases_not_to_be_stripped ) # The following use of top_level is to allow loading of a top level model by name only, e.g. MyCatalog # There may be a better overall way to approach this. top_level = len ( merged_model_alias . split ( '.' )) == 1 for i in range ( len ( aliases_not_to_be_stripped )): alias = aliases_not_to_be_stripped [ i ] instance = instances_to_be_merged [ i ] if hasattr ( instance , '__dict__' ) and '__root__' in instance . __dict__ and isinstance ( instance , OscalBaseModel ): instance = instance . __dict__ [ '__root__' ] if top_level and not primary_model_dict : primary_model_dict = instance . __dict__ else : primary_model_dict [ alias ] = instance merged_model_instance = merged_model_type ( ** primary_model_dict ) # type: ignore return merged_model_type , merged_model_alias , merged_model_instance return primary_model_type , primary_model_alias , primary_model_instance @staticmethod def load_top_level_model ( trestle_root : pathlib . Path , model_name : str , model_class : Type [ TopLevelOscalModel ], file_content_type : Optional [ FileContentType ] = None ) -> Tuple [ Union [ OscalBaseModel , List [ OscalBaseModel ], Dict [ str , OscalBaseModel ]], pathlib . Path ]: \"\"\"Load a model by name and model class and infer file content type if not specified. If you need to load an existing model but its content type may not be known, use this method. But the file content type should be specified if it is somehow known. \"\"\" root_model_path = ModelUtils . _root_path_for_top_level_model ( trestle_root , model_name , model_class ) if file_content_type is None : file_content_type = FileContentType . path_to_content_type ( root_model_path ) if not FileContentType . is_readable_file ( file_content_type ): raise TrestleError ( f 'Unable to load model { model_name } without specifying json or yaml.' ) full_model_path = root_model_path . with_suffix ( FileContentType . to_file_extension ( file_content_type )) _ , _ , model = ModelUtils . load_distributed ( full_model_path , trestle_root ) return model , full_model_path @staticmethod def save_top_level_model ( model : TopLevelOscalModel , trestle_root : pathlib . Path , model_name : str , file_content_type : FileContentType ) -> None : \"\"\"Save a model by name and infer model type by inspection. You don't need to specify the model type (catalog, profile, etc.) but you must specify the file content type. If the model directory does not exist, it is created. \"\"\" root_model_path = ModelUtils . _root_path_for_top_level_model ( trestle_root , model_name , model ) full_model_path = root_model_path . with_suffix ( FileContentType . to_file_extension ( file_content_type )) if not full_model_path . parent . exists (): full_model_path . parent . mkdir ( parents = True , exist_ok = True ) model . oscal_write ( full_model_path ) @staticmethod def get_relative_model_type ( relative_path : pathlib . Path ) -> Tuple [ Type [ OscalBaseModel ], str ]: \"\"\" Given the relative path of a file with respect to 'trestle_root' return the oscal model type. Args: relative_path: Relative path of the model with respect to the root directory of the trestle project. Returns: Type of Oscal Model for the provided model Alias of that oscal model. \"\"\" if len ( relative_path . parts ) < 2 : raise TrestleError ( 'Insufficient path length to be a valid relative path w.r.t Trestle project root directory.' ) model_dir = relative_path . parts [ 0 ] model_relative_path = pathlib . Path ( * relative_path . parts [ 2 :]) # catalogs, profiles, etc if model_dir in const . MODEL_DIR_LIST : module_name = const . MODEL_DIR_TO_MODEL_MODULE [ model_dir ] else : raise TrestleError ( f 'No valid trestle model type directory (e.g. catalogs) found for { model_dir } .' ) model_type , model_alias = ModelUtils . get_root_model ( module_name ) full_alias = model_alias for index , part in enumerate ( model_relative_path . parts ): alias = ModelUtils . _extract_alias ( part ) if index > 0 or model_alias != alias : model_alias = alias full_alias = f ' { full_alias } . { model_alias } ' if utils . is_collection_field_type ( model_type ): model_type = utils . get_inner_type ( model_type ) else : model_type = model_type . alias_to_field_map ()[ alias ] . outer_type_ return model_type , full_alias @staticmethod def get_stripped_model_type ( absolute_path : pathlib . Path , absolute_trestle_root : pathlib . Path , aliases_not_to_be_stripped : List [ str ] = None ) -> Tuple [ Type [ OscalBaseModel ], str ]: \"\"\" Get the stripped contextual model class and alias based on the contextual path. This function relies on the directory structure of the trestle model being edited to determine, based on the existing files and folder, which fields should be stripped from the model type represented by the path passed in as a parameter. \"\"\" if aliases_not_to_be_stripped is None : aliases_not_to_be_stripped = [] singular_model_type , model_alias = ModelUtils . get_relative_model_type ( absolute_path . relative_to ( absolute_trestle_root )) logger . debug ( f 'singular model type { singular_model_type } model alias { model_alias } ' ) # Stripped models do not apply to collection types such as List[] and Dict{} # if model type is a list or dict, generate a new wrapping model for it if utils . is_collection_field_type ( singular_model_type ): malias = model_alias . split ( '.' )[ - 1 ] class_name = alias_to_classname ( malias , AliasMode . JSON ) logger . debug ( f 'collection field type class name { class_name } and alias { malias } ' ) model_type = create_model ( class_name , __base__ = OscalBaseModel , __root__ = ( singular_model_type , ... )) logger . debug ( f 'model_type created: { model_type } ' ) model_type = cast ( Type [ OscalBaseModel ], model_type ) return model_type , model_alias malias = model_alias . split ( '.' )[ - 1 ] logger . debug ( f 'not collection field type, malias: { malias } ' ) if absolute_path . is_dir () and malias != ModelUtils . _extract_alias ( absolute_path . name ): split_subdir = absolute_path / malias else : split_subdir = absolute_path . parent / absolute_path . with_suffix ( '' ) . name aliases_to_be_stripped = set () if split_subdir . exists (): for f in iterdir_without_hidden_files ( split_subdir ): alias = ModelUtils . _extract_alias ( f . name ) if alias not in aliases_not_to_be_stripped : aliases_to_be_stripped . add ( alias ) logger . debug ( f 'aliases to be stripped: { aliases_to_be_stripped } ' ) if len ( aliases_to_be_stripped ) > 0 : model_type = singular_model_type . create_stripped_model_type ( stripped_fields_aliases = list ( aliases_to_be_stripped ) ) logger . debug ( f 'model_type: { model_type } ' ) return model_type , model_alias return singular_model_type , model_alias @staticmethod def model_type_to_model_dir ( model_type : str ) -> str : \"\"\"Get plural model directory from model type.\"\"\" if model_type not in const . MODEL_TYPE_LIST : raise err . TrestleError ( f 'Not a valid model type: { model_type } .' ) return const . MODEL_TYPE_TO_MODEL_DIR [ model_type ] @staticmethod def get_models_of_type ( model_type : str , root : pathlib . Path ) -> List [ str ]: \"\"\"Get list of model names for requested type in trestle directory.\"\"\" if model_type not in const . MODEL_TYPE_LIST : raise err . TrestleError ( f 'Model type { model_type } is not supported' ) # search relative to project root trestle_root = extract_trestle_project_root ( root ) if not trestle_root : logger . error ( f 'Given directory { root } is not within a trestle project.' ) raise err . TrestleError ( 'Given directory is not within a trestle project.' ) # contruct path to the model file name model_dir_name = ModelUtils . model_type_to_model_dir ( model_type ) root_model_dir = trestle_root / model_dir_name model_list = [] for f in root_model_dir . glob ( '*/' ): # only look for proper json and yaml files if not ModelUtils . _should_ignore ( f . stem ): if not f . is_dir (): logger . warning ( f 'Ignoring validation of misplaced file { f . name } ' + f 'found in the model directory, { model_dir_name } .' ) else : model_list . append ( f . stem ) return model_list @staticmethod def get_all_models ( root : pathlib . Path ) -> List [ Tuple [ str , str ]]: \"\"\"Get list of all models in trestle directory as tuples (model_type, model_name).\"\"\" full_list = [] for model_type in const . MODEL_TYPE_LIST : models = ModelUtils . get_models_of_type ( model_type , root ) for m in models : full_list . append (( model_type , m )) return full_list @staticmethod def path_for_top_level_model ( trestle_root : pathlib . Path , model_name : str , model_class : Type [ TopLevelOscalModel ], file_content_type : FileContentType ) -> pathlib . Path : \"\"\" Find the full path of a model given its name, model type and file content type. This does not inspect the file system or confirm the needed path and file exists. \"\"\" root_path = ModelUtils . _root_path_for_top_level_model ( trestle_root , model_name , model_class ) return root_path . with_suffix ( FileContentType . to_file_extension ( file_content_type )) @staticmethod def full_path_for_top_level_model ( trestle_root : pathlib . Path , model_name : str , model_class : Type [ TopLevelOscalModel ], ) -> Optional [ pathlib . Path ]: \"\"\" Find the full path of an existing model given its name and model type but no file content type. Use this method when you need the path of a model but you don't know the file content type. Returns None if neither json nor yaml file can be found. If you do know the file content type, use path_for_top_level_model instead. \"\"\" root_model_path = ModelUtils . _root_path_for_top_level_model ( trestle_root , model_name , model_class ) file_content_type = FileContentType . path_to_content_type ( root_model_path ) if not FileContentType . is_readable_file ( file_content_type ): return None return root_model_path . with_suffix ( FileContentType . to_file_extension ( file_content_type )) @staticmethod def get_singular_alias ( alias_path : str , relative_path : Optional [ pathlib . Path ] = None ) -> str : \"\"\" Get the alias in the singular form from a jsonpath. If contextual_mode is True and contextual_path is None, it assumes alias_path is relative to the directory the user is running trestle from. Args: alias_path: The current alias element path as a string relative_path: Optional relative path (w.r.t. trestle_root) to cater for relative element paths. Returns: Alias as a string \"\"\" if len ( alias_path . strip ()) == 0 : raise err . TrestleError ( f 'Invalid jsonpath { alias_path } ' ) singular_alias : str = '' full_alias_path = alias_path if relative_path : logger . debug ( f 'get_singular_alias contextual mode: { str } ' ) _ , full_model_alias = ModelUtils . get_relative_model_type ( relative_path ) first_alias_a = full_model_alias . split ( '.' )[ - 1 ] first_alias_b = alias_path . split ( '.' )[ 0 ] if first_alias_a == first_alias_b : full_model_alias = '.' . join ( full_model_alias . split ( '.' )[: - 1 ]) full_alias_path = '.' . join ([ full_model_alias , alias_path ]) . strip ( '.' ) path_parts = full_alias_path . split ( const . ALIAS_PATH_SEPARATOR ) logger . debug ( f 'path parts: { path_parts } ' ) model_types = [] root_model_alias = path_parts [ 0 ] found = False for module_name in const . MODEL_TYPE_TO_MODEL_MODULE . values (): model_type , model_alias = ModelUtils . get_root_model ( module_name ) if root_model_alias == model_alias : found = True model_types . append ( model_type ) break if not found : raise err . TrestleError ( f ' { root_model_alias } is an invalid root model alias.' ) if len ( path_parts ) == 1 : return root_model_alias model_type = model_types [ 0 ] # go through path parts skipping first one for i in range ( 1 , len ( path_parts )): if utils . is_collection_field_type ( model_type ): # if it is a collection type and last part is * then break if i == len ( path_parts ) - 1 and path_parts [ i ] == '*' : break # otherwise get the inner type of items in the collection model_type = utils . get_inner_type ( model_type ) # and bump i i = i + 1 else : path_part = path_parts [ i ] field_map = model_type . alias_to_field_map () if path_part not in field_map : continue field = field_map [ path_part ] model_type = field . outer_type_ model_types . append ( model_type ) last_alias = path_parts [ - 1 ] if last_alias == '*' : last_alias = path_parts [ - 2 ] # generic model and not list, so return itself fixme doc if not utils . is_collection_field_type ( model_type ): return last_alias parent_model_type = model_types [ - 2 ] try : field_map = parent_model_type . alias_to_field_map () field = field_map [ last_alias ] outer_type = field . outer_type_ inner_type = utils . get_inner_type ( outer_type ) inner_type_name = inner_type . __name__ singular_alias = str_utils . classname_to_alias ( inner_type_name , AliasMode . JSON ) except Exception as e : raise err . TrestleError ( f 'Error in json path { alias_path } : { e } ' ) return singular_alias @staticmethod def get_root_model ( module_name : str ) -> Tuple [ Type [ Any ], str ]: \"\"\"Get the root model class and alias based on the module.\"\"\" try : module = importlib . import_module ( module_name ) except ModuleNotFoundError as e : raise err . TrestleError ( str ( e )) if hasattr ( module , 'Model' ): model_metadata = next ( iter ( module . Model . __fields__ . values ())) return model_metadata . type_ , model_metadata . alias raise err . TrestleError ( 'Invalid module' ) @staticmethod def _root_path_for_top_level_model ( trestle_root : pathlib . Path , model_name : str , model_class : Union [ TopLevelOscalModel , Type [ TopLevelOscalModel ]] ) -> pathlib . Path : \"\"\" Find the root path to a model given its name and class - with no suffix. This is a private method used only to construct the root filepath based on model name and type. It does not check for existence or content type and it does not create the directory if it does not exist. \"\"\" if not hasattr ( model_class , '__module__' ) or model_class . __module__ not in const . MODEL_MODULE_LIST : raise TrestleError ( f 'Unable to determine model type for model { model_name } with class { model_class } ' ) model_alias = const . MODEL_MODULE_TO_MODEL_TYPE [ model_class . __module__ ] model_dir = trestle_root / f ' { const . MODEL_TYPE_TO_MODEL_DIR [ model_alias ] } / { model_name } ' return model_dir / model_alias @staticmethod def _extract_alias ( string_dir : str ) -> str : \"\"\" Extract alias from filename or directory name removing extensions and prefixes related to dict and list. As we need to do this for multiple parts of a path operating on strings is easier. \"\"\" alias = string_dir . split ( '.' )[ 0 ] . split ( const . IDX_SEP )[ - 1 ] # get suffix of file or directory name representing list or dict item return alias @staticmethod def _should_ignore ( name : str ) -> bool : \"\"\"Check if the file or directory should be ignored or not.\"\"\" return name [ 0 ] == '.' or name [ 0 ] == '_' @staticmethod def _load_list ( abs_path : Path , abs_trestle_root : Path ) -> Tuple [ Type [ OscalBaseModel ], str , List [ OscalBaseModel ]]: \"\"\"Given path to a directory of list(array) models, load the distributed models.\"\"\" aliases_not_to_be_stripped = [] instances_to_be_merged : List [ OscalBaseModel ] = [] collection_model_type , collection_model_alias = ModelUtils . get_stripped_model_type ( abs_path , abs_trestle_root ) for path in sorted ( trestle . common . file_utils . iterdir_without_hidden_files ( abs_path )): # ASSUMPTION HERE: if it is a directory, there's a file that can not be decomposed further. if path . is_dir (): continue _ , model_alias , model_instance = ModelUtils . load_distributed ( path , abs_trestle_root ) instances_to_be_merged . append ( model_instance ) aliases_not_to_be_stripped . append ( model_alias . split ( '.' )[ - 1 ]) return collection_model_type , collection_model_alias , instances_to_be_merged @staticmethod def parameter_to_dict ( obj : Union [ OscalBaseModel , str ], partial : bool ) -> Union [ str , Dict [ str , Any ]]: \"\"\" Convert obj to dict containing only string values, storing only the fields that have values set. Args: obj: The parameter or its consituent parts in recursive calls partial: Whether to convert the entire param or just the parts needed for markdown header Returns: The converted parameter as dictionary \"\"\" main_fields = [ 'id' , 'label' , 'values' , 'select' , 'choice' , 'how_many' ] if isinstance ( obj , common . HowMany ): return obj . name if isinstance ( obj , common . Remarks ) or isinstance ( obj , common . ParameterValue ): return obj . __root__ # it is either a string already or we cast it to string if not hasattr ( obj , '__fields_set__' ): return str ( obj ) # it is an oscal object and we need to recurse within its attributes res = {} for field in obj . __fields_set__ : if partial and field not in main_fields : continue attr = getattr ( obj , field ) if not attr : continue if isinstance ( attr , list ): # special handling when only one value present - convert to single string if field == 'values' and len ( attr ) == 1 : res [ field ] = str ( attr [ 0 ] . __root__ ) continue new_list = [] for item in attr : new_list . append ( ModelUtils . parameter_to_dict ( item , partial )) res [ field ] = new_list elif isinstance ( attr , str ): res [ field ] = attr else : res [ field ] = ModelUtils . parameter_to_dict ( attr , partial ) return res @staticmethod def _string_to_howmany ( count_str : str ) -> Optional [ common . HowMany ]: clean_str = count_str . lower () . strip () . replace ( '-' , ' ' ) . replace ( '_' , ' ' ) if clean_str == 'one or more' : return common . HowMany . one_or_more elif clean_str == 'one' : return common . HowMany . one return None @staticmethod def dict_to_parameter ( param_dict : Dict [ str , Any ]) -> common . Parameter : \"\"\" Convert dict with only string values to Parameter with handling for HowMany and with validity checks. Args: param_dict: Dictionary of pure string values representing Parameter contents Returns: A valid OSCAL Parameter Notes: This handles both partial and full parameter dictionaries It checks for validity of the values if a select and HowMany is specified There is special handling for values: If it is a single string it is converted to list of one ParameterValue But if it is a list of strings is regarded as a list of values and is converted to a list of ParameterValues \"\"\" values = param_dict . get ( 'values' , []) # special handling when only one value present - convert to list of 1 if isinstance ( values , str ): values = [ values ] param_dict [ 'values' ] = values if 'select' in param_dict and 'how_many' in param_dict [ 'select' ]: count_str = param_dict [ 'select' ][ 'how_many' ] how_many = ModelUtils . _string_to_howmany ( count_str ) if how_many is None : raise TrestleError ( f 'Unrecognized HowMany value { how_many } in Parameter: should be one-or-more or one.' ) param_dict [ 'select' ][ 'how_many' ] = how_many if how_many == common . HowMany . one and len ( values ) > 1 : logger . warning ( f 'Parameter specifies HowMany=1 but has { len ( values ) } values given.' ) choices = param_dict [ 'select' ] . get ( 'choice' , []) if choices and values : for value in values : if value not in choices : logger . warning ( f \"Parameter { param_dict [ 'id' ] } has value \\\" { value } \\\" not in choices: { choices } .\" ) return common . Parameter ( ** param_dict ) @staticmethod def update_last_modified ( model : TopLevelOscalModel , timestamp : Optional [ datetime ] = None ) -> None : \"\"\"Update the LastModified timestamp in top level model to now.\"\"\" timestamp = timestamp if timestamp else datetime . now () . astimezone () model . metadata . last_modified = common . LastModified ( __root__ = timestamp ) @staticmethod def model_age ( model : TopLevelOscalModel ) -> int : \"\"\"Find time in seconds since LastModified timestamp.\"\"\" # default to one year if no last_modified age_seconds = const . DAY_SECONDS * 365 if model . metadata . last_modified : dt = datetime . now () . astimezone () - model . metadata . last_modified . __root__ age_seconds = dt . seconds return age_seconds @staticmethod def find_values_by_name ( object_of_interest : Any , name_of_interest : str ) -> List [ Any ]: \"\"\"Traverse object and return list of values of specified name.\"\"\" loe = [] if isinstance ( object_of_interest , BaseModel ): value = getattr ( object_of_interest , name_of_interest , None ) if value is not None : loe . append ( value ) fields = getattr ( object_of_interest , '__fields_set__' , None ) if fields is not None : for field in fields : loe . extend ( ModelUtils . find_values_by_name ( getattr ( object_of_interest , field , None ), name_of_interest ) ) elif type ( object_of_interest ) is list : for item in object_of_interest : loe . extend ( ModelUtils . find_values_by_name ( item , name_of_interest )) elif type ( object_of_interest ) is dict : if name_of_interest in object_of_interest : loe . append ( object_of_interest [ name_of_interest ]) for item in object_of_interest . values (): loe . extend ( ModelUtils . find_values_by_name ( item , name_of_interest )) return loe @staticmethod def has_no_duplicate_values_by_name ( object_of_interest : Any , name_of_interest : str ) -> bool : \"\"\"Determine if duplicate values of type exist in object.\"\"\" loe = ModelUtils . find_values_by_name ( object_of_interest , name_of_interest ) set_loe = set ( loe ) if len ( loe ) == len ( set_loe ): return True items = {} for item in loe : items [ item ] = items . get ( item , 0 ) + 1 # now print items for item , instances in items . items (): if instances > 1 : logger . info ( f 'Duplicate detected of item { item } with { instances } instances.' ) return False @staticmethod def _regenerate_uuids_in_place ( object_of_interest : Any , uuid_lut : Dict [ str , str ]) -> Tuple [ Any , Dict [ str , str ]]: \"\"\"Update all uuids in model that require updating. Go through the model and replace all dicts with key == 'uuid' and replace the value with a new uuid4. Build a lookup table of the updates that were made. This function does not update the corresponding refs to those uuid's. That is done by update_uuid_refs Note that this function needs to be started off with uuid_lut == {}, i.e. an empty dict. After that it recurses and grows the lut. Args: object_of_interest: pydantic.BaseModel, list, dict or str will be updated uuid_lut: dict of the growing lut of old:new uuid's. First call must be made with value {} Returns: The updated object_of_interest with new uuid's (but refs to them are not updated) The final lookup table of old:new uuid's \"\"\" uuid_str = 'uuid' # Certain types are known not to need updating and should not change # Resources are identified by uuid, and the corresponding href will have # in front of the uuid string # Neither of these should change # If other similar types are found they should be added to the FixedUuidModel typevar to prevent updating if isinstance ( object_of_interest , common . Resource ): pass elif isinstance ( object_of_interest , BaseModel ): # fields_set has names of fields set when model was initialized fields = getattr ( object_of_interest , '__fields_set__' , None ) for field in fields : new_object = None if field == uuid_str : new_object = str ( uuid . uuid4 ()) uuid_lut [ object_of_interest . __dict__ [ field ]] = new_object else : new_object , uuid_lut = ModelUtils . _regenerate_uuids_in_place ( object_of_interest . __dict__ [ field ], uuid_lut ) object_of_interest . __dict__ [ field ] = new_object elif type ( object_of_interest ) is list : new_list = [] for item in object_of_interest : new_item , uuid_lut = ModelUtils . _regenerate_uuids_in_place ( item , uuid_lut ) new_list . append ( new_item ) object_of_interest = new_list elif type ( object_of_interest ) is dict : new_dict = {} for key , value in object_of_interest . items (): if key == uuid_str : new_val = str ( uuid . uuid4 ()) new_dict [ uuid_str ] = new_val uuid_lut [ value ] = new_val else : new_value , uuid_lut = ModelUtils . _regenerate_uuids_in_place ( value , uuid_lut ) new_dict [ key ] = new_value object_of_interest = new_dict return object_of_interest , uuid_lut @staticmethod def _update_new_uuid_refs ( object_of_interest : Any , uuid_lut : Dict [ str , str ]) -> Tuple [ Any , int ]: \"\"\"Update all refs to uuids that were changed.\"\"\" n_refs_updated = 0 if isinstance ( object_of_interest , BaseModel ): fields = getattr ( object_of_interest , '__fields_set__' , None ) for field in fields : new_object , n_new_updates = ModelUtils . _update_new_uuid_refs ( object_of_interest . __dict__ [ field ], uuid_lut ) n_refs_updated += n_new_updates object_of_interest . __dict__ [ field ] = new_object elif type ( object_of_interest ) is list : new_list = [] for item in object_of_interest : new_item , n_new_updates = ModelUtils . _update_new_uuid_refs ( item , uuid_lut ) n_refs_updated += n_new_updates new_list . append ( new_item ) object_of_interest = new_list elif type ( object_of_interest ) is dict : new_dict = {} for key , value in object_of_interest . items (): if isinstance ( value , str ): if value in uuid_lut : new_dict [ key ] = uuid_lut [ value ] n_refs_updated += 1 else : new_dict [ key ] = value else : new_value , n_new_updates = ModelUtils . _update_new_uuid_refs ( value , uuid_lut ) n_refs_updated += n_new_updates new_dict [ key ] = new_value object_of_interest = new_dict elif isinstance ( object_of_interest , str ): if object_of_interest in uuid_lut : n_refs_updated += 1 object_of_interest = uuid_lut [ object_of_interest ] return object_of_interest , n_refs_updated @staticmethod def regenerate_uuids ( object_of_interest : Any ) -> Tuple [ Any , Dict [ str , str ], int ]: \"\"\"Regenerate all uuids in object and update corresponding references. Find all dicts with key == 'uuid' and replace the value with a new uuid4. Build a corresponding lookup table as you go, of old:new uuid values. Then make a second pass through the object and replace all string values present in the lookup table with the new value. Args: object_of_interest: pydantic.BaseModel, list, dict or str will be updated Returns: The updated object with new uuid's and refs The final lookup table of old:new uuid's A count of the number of refs that were updated \"\"\" new_object , uuid_lut = ModelUtils . _regenerate_uuids_in_place ( object_of_interest , {}) new_object , n_refs_updated = ModelUtils . _update_new_uuid_refs ( new_object , uuid_lut ) return new_object , uuid_lut , n_refs_updated @staticmethod def models_are_equivalent ( model_a : Optional [ TopLevelOscalModel ], model_b : Optional [ TopLevelOscalModel ]) -> bool : \"\"\"Test if models are equivalent except for last modified and uuid.\"\"\" # set b's extra properties to those of a then later undo so the models are not changed by this routine if ( model_b and not model_a ) or ( model_a and not model_b ): return False b_last_modified = model_b . metadata . last_modified model_b . metadata . last_modified = model_a . metadata . last_modified b_uuid = model_b . uuid model_b . uuid = model_a . uuid equivalent = model_a == model_b model_b . metadata . last_modified = b_last_modified model_b . uuid = b_uuid return equivalent","title":"ModelUtils"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.dict_to_parameter","text":"Convert dict with only string values to Parameter with handling for HowMany and with validity checks. Parameters: Name Type Description Default param_dict Dict[str, Any] Dictionary of pure string values representing Parameter contents required Returns: Type Description Parameter A valid OSCAL Parameter Notes This handles both partial and full parameter dictionaries It checks for validity of the values if a select and HowMany is specified There is special handling for values: If it is a single string it is converted to list of one ParameterValue But if it is a list of strings is regarded as a list of values and is converted to a list of ParameterValues Source code in trestle/common/model_utils.py @staticmethod def dict_to_parameter ( param_dict : Dict [ str , Any ]) -> common . Parameter : \"\"\" Convert dict with only string values to Parameter with handling for HowMany and with validity checks. Args: param_dict: Dictionary of pure string values representing Parameter contents Returns: A valid OSCAL Parameter Notes: This handles both partial and full parameter dictionaries It checks for validity of the values if a select and HowMany is specified There is special handling for values: If it is a single string it is converted to list of one ParameterValue But if it is a list of strings is regarded as a list of values and is converted to a list of ParameterValues \"\"\" values = param_dict . get ( 'values' , []) # special handling when only one value present - convert to list of 1 if isinstance ( values , str ): values = [ values ] param_dict [ 'values' ] = values if 'select' in param_dict and 'how_many' in param_dict [ 'select' ]: count_str = param_dict [ 'select' ][ 'how_many' ] how_many = ModelUtils . _string_to_howmany ( count_str ) if how_many is None : raise TrestleError ( f 'Unrecognized HowMany value { how_many } in Parameter: should be one-or-more or one.' ) param_dict [ 'select' ][ 'how_many' ] = how_many if how_many == common . HowMany . one and len ( values ) > 1 : logger . warning ( f 'Parameter specifies HowMany=1 but has { len ( values ) } values given.' ) choices = param_dict [ 'select' ] . get ( 'choice' , []) if choices and values : for value in values : if value not in choices : logger . warning ( f \"Parameter { param_dict [ 'id' ] } has value \\\" { value } \\\" not in choices: { choices } .\" ) return common . Parameter ( ** param_dict )","title":"dict_to_parameter()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.find_values_by_name","text":"Traverse object and return list of values of specified name. Source code in trestle/common/model_utils.py @staticmethod def find_values_by_name ( object_of_interest : Any , name_of_interest : str ) -> List [ Any ]: \"\"\"Traverse object and return list of values of specified name.\"\"\" loe = [] if isinstance ( object_of_interest , BaseModel ): value = getattr ( object_of_interest , name_of_interest , None ) if value is not None : loe . append ( value ) fields = getattr ( object_of_interest , '__fields_set__' , None ) if fields is not None : for field in fields : loe . extend ( ModelUtils . find_values_by_name ( getattr ( object_of_interest , field , None ), name_of_interest ) ) elif type ( object_of_interest ) is list : for item in object_of_interest : loe . extend ( ModelUtils . find_values_by_name ( item , name_of_interest )) elif type ( object_of_interest ) is dict : if name_of_interest in object_of_interest : loe . append ( object_of_interest [ name_of_interest ]) for item in object_of_interest . values (): loe . extend ( ModelUtils . find_values_by_name ( item , name_of_interest )) return loe","title":"find_values_by_name()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.full_path_for_top_level_model","text":"Find the full path of an existing model given its name and model type but no file content type. Use this method when you need the path of a model but you don't know the file content type. Returns None if neither json nor yaml file can be found. If you do know the file content type, use path_for_top_level_model instead. Source code in trestle/common/model_utils.py @staticmethod def full_path_for_top_level_model ( trestle_root : pathlib . Path , model_name : str , model_class : Type [ TopLevelOscalModel ], ) -> Optional [ pathlib . Path ]: \"\"\" Find the full path of an existing model given its name and model type but no file content type. Use this method when you need the path of a model but you don't know the file content type. Returns None if neither json nor yaml file can be found. If you do know the file content type, use path_for_top_level_model instead. \"\"\" root_model_path = ModelUtils . _root_path_for_top_level_model ( trestle_root , model_name , model_class ) file_content_type = FileContentType . path_to_content_type ( root_model_path ) if not FileContentType . is_readable_file ( file_content_type ): return None return root_model_path . with_suffix ( FileContentType . to_file_extension ( file_content_type ))","title":"full_path_for_top_level_model()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.get_all_models","text":"Get list of all models in trestle directory as tuples (model_type, model_name). Source code in trestle/common/model_utils.py @staticmethod def get_all_models ( root : pathlib . Path ) -> List [ Tuple [ str , str ]]: \"\"\"Get list of all models in trestle directory as tuples (model_type, model_name).\"\"\" full_list = [] for model_type in const . MODEL_TYPE_LIST : models = ModelUtils . get_models_of_type ( model_type , root ) for m in models : full_list . append (( model_type , m )) return full_list","title":"get_all_models()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.get_models_of_type","text":"Get list of model names for requested type in trestle directory. Source code in trestle/common/model_utils.py @staticmethod def get_models_of_type ( model_type : str , root : pathlib . Path ) -> List [ str ]: \"\"\"Get list of model names for requested type in trestle directory.\"\"\" if model_type not in const . MODEL_TYPE_LIST : raise err . TrestleError ( f 'Model type { model_type } is not supported' ) # search relative to project root trestle_root = extract_trestle_project_root ( root ) if not trestle_root : logger . error ( f 'Given directory { root } is not within a trestle project.' ) raise err . TrestleError ( 'Given directory is not within a trestle project.' ) # contruct path to the model file name model_dir_name = ModelUtils . model_type_to_model_dir ( model_type ) root_model_dir = trestle_root / model_dir_name model_list = [] for f in root_model_dir . glob ( '*/' ): # only look for proper json and yaml files if not ModelUtils . _should_ignore ( f . stem ): if not f . is_dir (): logger . warning ( f 'Ignoring validation of misplaced file { f . name } ' + f 'found in the model directory, { model_dir_name } .' ) else : model_list . append ( f . stem ) return model_list","title":"get_models_of_type()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.get_relative_model_type","text":"Given the relative path of a file with respect to 'trestle_root' return the oscal model type. Parameters: Name Type Description Default relative_path Path Relative path of the model with respect to the root directory of the trestle project. required Returns: Type Description Tuple[Type[trestle.core.base_model.OscalBaseModel], str] Type of Oscal Model for the provided model Alias of that oscal model. Source code in trestle/common/model_utils.py @staticmethod def get_relative_model_type ( relative_path : pathlib . Path ) -> Tuple [ Type [ OscalBaseModel ], str ]: \"\"\" Given the relative path of a file with respect to 'trestle_root' return the oscal model type. Args: relative_path: Relative path of the model with respect to the root directory of the trestle project. Returns: Type of Oscal Model for the provided model Alias of that oscal model. \"\"\" if len ( relative_path . parts ) < 2 : raise TrestleError ( 'Insufficient path length to be a valid relative path w.r.t Trestle project root directory.' ) model_dir = relative_path . parts [ 0 ] model_relative_path = pathlib . Path ( * relative_path . parts [ 2 :]) # catalogs, profiles, etc if model_dir in const . MODEL_DIR_LIST : module_name = const . MODEL_DIR_TO_MODEL_MODULE [ model_dir ] else : raise TrestleError ( f 'No valid trestle model type directory (e.g. catalogs) found for { model_dir } .' ) model_type , model_alias = ModelUtils . get_root_model ( module_name ) full_alias = model_alias for index , part in enumerate ( model_relative_path . parts ): alias = ModelUtils . _extract_alias ( part ) if index > 0 or model_alias != alias : model_alias = alias full_alias = f ' { full_alias } . { model_alias } ' if utils . is_collection_field_type ( model_type ): model_type = utils . get_inner_type ( model_type ) else : model_type = model_type . alias_to_field_map ()[ alias ] . outer_type_ return model_type , full_alias","title":"get_relative_model_type()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.get_root_model","text":"Get the root model class and alias based on the module. Source code in trestle/common/model_utils.py @staticmethod def get_root_model ( module_name : str ) -> Tuple [ Type [ Any ], str ]: \"\"\"Get the root model class and alias based on the module.\"\"\" try : module = importlib . import_module ( module_name ) except ModuleNotFoundError as e : raise err . TrestleError ( str ( e )) if hasattr ( module , 'Model' ): model_metadata = next ( iter ( module . Model . __fields__ . values ())) return model_metadata . type_ , model_metadata . alias raise err . TrestleError ( 'Invalid module' )","title":"get_root_model()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.get_singular_alias","text":"Get the alias in the singular form from a jsonpath. If contextual_mode is True and contextual_path is None, it assumes alias_path is relative to the directory the user is running trestle from. Parameters: Name Type Description Default alias_path str The current alias element path as a string required relative_path Optional[pathlib.Path] Optional relative path (w.r.t. trestle_root) to cater for relative element paths. None Returns: Type Description str Alias as a string Source code in trestle/common/model_utils.py @staticmethod def get_singular_alias ( alias_path : str , relative_path : Optional [ pathlib . Path ] = None ) -> str : \"\"\" Get the alias in the singular form from a jsonpath. If contextual_mode is True and contextual_path is None, it assumes alias_path is relative to the directory the user is running trestle from. Args: alias_path: The current alias element path as a string relative_path: Optional relative path (w.r.t. trestle_root) to cater for relative element paths. Returns: Alias as a string \"\"\" if len ( alias_path . strip ()) == 0 : raise err . TrestleError ( f 'Invalid jsonpath { alias_path } ' ) singular_alias : str = '' full_alias_path = alias_path if relative_path : logger . debug ( f 'get_singular_alias contextual mode: { str } ' ) _ , full_model_alias = ModelUtils . get_relative_model_type ( relative_path ) first_alias_a = full_model_alias . split ( '.' )[ - 1 ] first_alias_b = alias_path . split ( '.' )[ 0 ] if first_alias_a == first_alias_b : full_model_alias = '.' . join ( full_model_alias . split ( '.' )[: - 1 ]) full_alias_path = '.' . join ([ full_model_alias , alias_path ]) . strip ( '.' ) path_parts = full_alias_path . split ( const . ALIAS_PATH_SEPARATOR ) logger . debug ( f 'path parts: { path_parts } ' ) model_types = [] root_model_alias = path_parts [ 0 ] found = False for module_name in const . MODEL_TYPE_TO_MODEL_MODULE . values (): model_type , model_alias = ModelUtils . get_root_model ( module_name ) if root_model_alias == model_alias : found = True model_types . append ( model_type ) break if not found : raise err . TrestleError ( f ' { root_model_alias } is an invalid root model alias.' ) if len ( path_parts ) == 1 : return root_model_alias model_type = model_types [ 0 ] # go through path parts skipping first one for i in range ( 1 , len ( path_parts )): if utils . is_collection_field_type ( model_type ): # if it is a collection type and last part is * then break if i == len ( path_parts ) - 1 and path_parts [ i ] == '*' : break # otherwise get the inner type of items in the collection model_type = utils . get_inner_type ( model_type ) # and bump i i = i + 1 else : path_part = path_parts [ i ] field_map = model_type . alias_to_field_map () if path_part not in field_map : continue field = field_map [ path_part ] model_type = field . outer_type_ model_types . append ( model_type ) last_alias = path_parts [ - 1 ] if last_alias == '*' : last_alias = path_parts [ - 2 ] # generic model and not list, so return itself fixme doc if not utils . is_collection_field_type ( model_type ): return last_alias parent_model_type = model_types [ - 2 ] try : field_map = parent_model_type . alias_to_field_map () field = field_map [ last_alias ] outer_type = field . outer_type_ inner_type = utils . get_inner_type ( outer_type ) inner_type_name = inner_type . __name__ singular_alias = str_utils . classname_to_alias ( inner_type_name , AliasMode . JSON ) except Exception as e : raise err . TrestleError ( f 'Error in json path { alias_path } : { e } ' ) return singular_alias","title":"get_singular_alias()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.get_stripped_model_type","text":"Get the stripped contextual model class and alias based on the contextual path. This function relies on the directory structure of the trestle model being edited to determine, based on the existing files and folder, which fields should be stripped from the model type represented by the path passed in as a parameter. Source code in trestle/common/model_utils.py @staticmethod def get_stripped_model_type ( absolute_path : pathlib . Path , absolute_trestle_root : pathlib . Path , aliases_not_to_be_stripped : List [ str ] = None ) -> Tuple [ Type [ OscalBaseModel ], str ]: \"\"\" Get the stripped contextual model class and alias based on the contextual path. This function relies on the directory structure of the trestle model being edited to determine, based on the existing files and folder, which fields should be stripped from the model type represented by the path passed in as a parameter. \"\"\" if aliases_not_to_be_stripped is None : aliases_not_to_be_stripped = [] singular_model_type , model_alias = ModelUtils . get_relative_model_type ( absolute_path . relative_to ( absolute_trestle_root )) logger . debug ( f 'singular model type { singular_model_type } model alias { model_alias } ' ) # Stripped models do not apply to collection types such as List[] and Dict{} # if model type is a list or dict, generate a new wrapping model for it if utils . is_collection_field_type ( singular_model_type ): malias = model_alias . split ( '.' )[ - 1 ] class_name = alias_to_classname ( malias , AliasMode . JSON ) logger . debug ( f 'collection field type class name { class_name } and alias { malias } ' ) model_type = create_model ( class_name , __base__ = OscalBaseModel , __root__ = ( singular_model_type , ... )) logger . debug ( f 'model_type created: { model_type } ' ) model_type = cast ( Type [ OscalBaseModel ], model_type ) return model_type , model_alias malias = model_alias . split ( '.' )[ - 1 ] logger . debug ( f 'not collection field type, malias: { malias } ' ) if absolute_path . is_dir () and malias != ModelUtils . _extract_alias ( absolute_path . name ): split_subdir = absolute_path / malias else : split_subdir = absolute_path . parent / absolute_path . with_suffix ( '' ) . name aliases_to_be_stripped = set () if split_subdir . exists (): for f in iterdir_without_hidden_files ( split_subdir ): alias = ModelUtils . _extract_alias ( f . name ) if alias not in aliases_not_to_be_stripped : aliases_to_be_stripped . add ( alias ) logger . debug ( f 'aliases to be stripped: { aliases_to_be_stripped } ' ) if len ( aliases_to_be_stripped ) > 0 : model_type = singular_model_type . create_stripped_model_type ( stripped_fields_aliases = list ( aliases_to_be_stripped ) ) logger . debug ( f 'model_type: { model_type } ' ) return model_type , model_alias return singular_model_type , model_alias","title":"get_stripped_model_type()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.has_no_duplicate_values_by_name","text":"Determine if duplicate values of type exist in object. Source code in trestle/common/model_utils.py @staticmethod def has_no_duplicate_values_by_name ( object_of_interest : Any , name_of_interest : str ) -> bool : \"\"\"Determine if duplicate values of type exist in object.\"\"\" loe = ModelUtils . find_values_by_name ( object_of_interest , name_of_interest ) set_loe = set ( loe ) if len ( loe ) == len ( set_loe ): return True items = {} for item in loe : items [ item ] = items . get ( item , 0 ) + 1 # now print items for item , instances in items . items (): if instances > 1 : logger . info ( f 'Duplicate detected of item { item } with { instances } instances.' ) return False","title":"has_no_duplicate_values_by_name()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.load_distributed","text":"Given path to a model, load the model. If the model is decomposed/split/distributed,the decomposed models are loaded recursively. Parameters: Name Type Description Default abs_path Path The path to the file/directory to be loaded. required abs_trestle_root Path The trestle project root directory. required collection_type Optional[Type[Any]] The type of collection model, if it is a collection model. typing.List is the only collection type handled or expected. Defaults to None. None Returns: Type Description Tuple[Type[trestle.core.base_model.OscalBaseModel], str, Union[trestle.core.base_model.OscalBaseModel, List[trestle.core.base_model.OscalBaseModel], Dict[str, trestle.core.base_model.OscalBaseModel]]] Return a tuple of Model Type (e.g. class 'trestle.oscal.catalog.Catalog'), Model Alias (e.g. 'catalog.metadata') and Instance of the Model. If the model is decomposed/split/distributed, the instance of the model contains the decomposed models loaded recursively. Source code in trestle/common/model_utils.py @staticmethod def load_distributed ( abs_path : Path , abs_trestle_root : Path , collection_type : Optional [ Type [ Any ]] = None ) -> Tuple [ Type [ OscalBaseModel ], str , Union [ OscalBaseModel , List [ OscalBaseModel ], Dict [ str , OscalBaseModel ]]]: \"\"\" Given path to a model, load the model. If the model is decomposed/split/distributed,the decomposed models are loaded recursively. Args: abs_path: The path to the file/directory to be loaded. abs_trestle_root: The trestle project root directory. collection_type: The type of collection model, if it is a collection model. typing.List is the only collection type handled or expected. Defaults to None. Returns: Return a tuple of Model Type (e.g. class 'trestle.oscal.catalog.Catalog'), Model Alias (e.g. 'catalog.metadata') and Instance of the Model. If the model is decomposed/split/distributed, the instance of the model contains the decomposed models loaded recursively. \"\"\" # if trying to load file that does not exist, load path instead if not abs_path . exists (): abs_path = abs_path . with_name ( abs_path . stem ) if not abs_path . exists (): raise TrestleNotFoundError ( f 'File { abs_path } not found for load.' ) if collection_type : # If the path contains a list type model if collection_type is list : return ModelUtils . _load_list ( abs_path , abs_trestle_root ) # the only other collection type in OSCAL is dict, and it only applies to include_all, # which is too granular ever to be loaded by this routine else : raise TrestleError ( f 'Collection type { collection_type } not recognized for distributed load.' ) # Get current model primary_model_type , primary_model_alias = ModelUtils . get_stripped_model_type ( abs_path , abs_trestle_root ) primary_model_instance : Optional [ OscalBaseModel ] = None # is this an attempt to load an actual json or yaml file? content_type = FileContentType . path_to_content_type ( abs_path ) # if file is sought but it doesn't exist, ignore and load as decomposed model if FileContentType . is_readable_file ( content_type ) and abs_path . exists (): primary_model_instance = primary_model_type . oscal_read ( abs_path ) # Is model decomposed? decomposed_dir = abs_path . with_name ( abs_path . stem ) if decomposed_dir . exists (): aliases_not_to_be_stripped = [] instances_to_be_merged : List [ OscalBaseModel ] = [] for local_path in sorted ( trestle . common . file_utils . iterdir_without_hidden_files ( decomposed_dir )): if local_path . is_file (): model_type , model_alias , model_instance = ModelUtils . load_distributed ( local_path , abs_trestle_root ) aliases_not_to_be_stripped . append ( model_alias . split ( '.' )[ - 1 ]) instances_to_be_merged . append ( model_instance ) elif local_path . is_dir (): model_type , model_alias = ModelUtils . get_stripped_model_type ( local_path , abs_trestle_root ) # Only load the directory if it is a collection model. Otherwise do nothing - it gets loaded when # iterating over the model file # If a model is just a container for a list e.g. # class Foo(OscalBaseModel): noqa: E800 # __root__: List[Bar] noqa: E800 # You need to test whether first a root key exists # then whether the outer_type of root is a collection. # Alternative is to do a try except to avoid the error for an unknown key. if model_type . is_collection_container (): # This directory is a decomposed List or Dict collection_type = model_type . get_collection_type () model_type , model_alias , model_instance = ModelUtils . load_distributed ( local_path , abs_trestle_root , collection_type ) aliases_not_to_be_stripped . append ( model_alias . split ( '.' )[ - 1 ]) instances_to_be_merged . append ( model_instance ) primary_model_dict = {} if primary_model_instance is not None : primary_model_dict = primary_model_instance . __dict__ merged_model_type , merged_model_alias = ModelUtils . get_stripped_model_type ( abs_path , abs_trestle_root , aliases_not_to_be_stripped ) # The following use of top_level is to allow loading of a top level model by name only, e.g. MyCatalog # There may be a better overall way to approach this. top_level = len ( merged_model_alias . split ( '.' )) == 1 for i in range ( len ( aliases_not_to_be_stripped )): alias = aliases_not_to_be_stripped [ i ] instance = instances_to_be_merged [ i ] if hasattr ( instance , '__dict__' ) and '__root__' in instance . __dict__ and isinstance ( instance , OscalBaseModel ): instance = instance . __dict__ [ '__root__' ] if top_level and not primary_model_dict : primary_model_dict = instance . __dict__ else : primary_model_dict [ alias ] = instance merged_model_instance = merged_model_type ( ** primary_model_dict ) # type: ignore return merged_model_type , merged_model_alias , merged_model_instance return primary_model_type , primary_model_alias , primary_model_instance","title":"load_distributed()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.load_top_level_model","text":"Load a model by name and model class and infer file content type if not specified. If you need to load an existing model but its content type may not be known, use this method. But the file content type should be specified if it is somehow known. Source code in trestle/common/model_utils.py @staticmethod def load_top_level_model ( trestle_root : pathlib . Path , model_name : str , model_class : Type [ TopLevelOscalModel ], file_content_type : Optional [ FileContentType ] = None ) -> Tuple [ Union [ OscalBaseModel , List [ OscalBaseModel ], Dict [ str , OscalBaseModel ]], pathlib . Path ]: \"\"\"Load a model by name and model class and infer file content type if not specified. If you need to load an existing model but its content type may not be known, use this method. But the file content type should be specified if it is somehow known. \"\"\" root_model_path = ModelUtils . _root_path_for_top_level_model ( trestle_root , model_name , model_class ) if file_content_type is None : file_content_type = FileContentType . path_to_content_type ( root_model_path ) if not FileContentType . is_readable_file ( file_content_type ): raise TrestleError ( f 'Unable to load model { model_name } without specifying json or yaml.' ) full_model_path = root_model_path . with_suffix ( FileContentType . to_file_extension ( file_content_type )) _ , _ , model = ModelUtils . load_distributed ( full_model_path , trestle_root ) return model , full_model_path","title":"load_top_level_model()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.model_age","text":"Find time in seconds since LastModified timestamp. Source code in trestle/common/model_utils.py @staticmethod def model_age ( model : TopLevelOscalModel ) -> int : \"\"\"Find time in seconds since LastModified timestamp.\"\"\" # default to one year if no last_modified age_seconds = const . DAY_SECONDS * 365 if model . metadata . last_modified : dt = datetime . now () . astimezone () - model . metadata . last_modified . __root__ age_seconds = dt . seconds return age_seconds","title":"model_age()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.model_type_to_model_dir","text":"Get plural model directory from model type. Source code in trestle/common/model_utils.py @staticmethod def model_type_to_model_dir ( model_type : str ) -> str : \"\"\"Get plural model directory from model type.\"\"\" if model_type not in const . MODEL_TYPE_LIST : raise err . TrestleError ( f 'Not a valid model type: { model_type } .' ) return const . MODEL_TYPE_TO_MODEL_DIR [ model_type ]","title":"model_type_to_model_dir()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.models_are_equivalent","text":"Test if models are equivalent except for last modified and uuid. Source code in trestle/common/model_utils.py @staticmethod def models_are_equivalent ( model_a : Optional [ TopLevelOscalModel ], model_b : Optional [ TopLevelOscalModel ]) -> bool : \"\"\"Test if models are equivalent except for last modified and uuid.\"\"\" # set b's extra properties to those of a then later undo so the models are not changed by this routine if ( model_b and not model_a ) or ( model_a and not model_b ): return False b_last_modified = model_b . metadata . last_modified model_b . metadata . last_modified = model_a . metadata . last_modified b_uuid = model_b . uuid model_b . uuid = model_a . uuid equivalent = model_a == model_b model_b . metadata . last_modified = b_last_modified model_b . uuid = b_uuid return equivalent","title":"models_are_equivalent()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.parameter_to_dict","text":"Convert obj to dict containing only string values, storing only the fields that have values set. Parameters: Name Type Description Default obj Union[trestle.core.base_model.OscalBaseModel, str] The parameter or its consituent parts in recursive calls required partial bool Whether to convert the entire param or just the parts needed for markdown header required Returns: Type Description Union[str, Dict[str, Any]] The converted parameter as dictionary Source code in trestle/common/model_utils.py @staticmethod def parameter_to_dict ( obj : Union [ OscalBaseModel , str ], partial : bool ) -> Union [ str , Dict [ str , Any ]]: \"\"\" Convert obj to dict containing only string values, storing only the fields that have values set. Args: obj: The parameter or its consituent parts in recursive calls partial: Whether to convert the entire param or just the parts needed for markdown header Returns: The converted parameter as dictionary \"\"\" main_fields = [ 'id' , 'label' , 'values' , 'select' , 'choice' , 'how_many' ] if isinstance ( obj , common . HowMany ): return obj . name if isinstance ( obj , common . Remarks ) or isinstance ( obj , common . ParameterValue ): return obj . __root__ # it is either a string already or we cast it to string if not hasattr ( obj , '__fields_set__' ): return str ( obj ) # it is an oscal object and we need to recurse within its attributes res = {} for field in obj . __fields_set__ : if partial and field not in main_fields : continue attr = getattr ( obj , field ) if not attr : continue if isinstance ( attr , list ): # special handling when only one value present - convert to single string if field == 'values' and len ( attr ) == 1 : res [ field ] = str ( attr [ 0 ] . __root__ ) continue new_list = [] for item in attr : new_list . append ( ModelUtils . parameter_to_dict ( item , partial )) res [ field ] = new_list elif isinstance ( attr , str ): res [ field ] = attr else : res [ field ] = ModelUtils . parameter_to_dict ( attr , partial ) return res","title":"parameter_to_dict()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.path_for_top_level_model","text":"Find the full path of a model given its name, model type and file content type. This does not inspect the file system or confirm the needed path and file exists. Source code in trestle/common/model_utils.py @staticmethod def path_for_top_level_model ( trestle_root : pathlib . Path , model_name : str , model_class : Type [ TopLevelOscalModel ], file_content_type : FileContentType ) -> pathlib . Path : \"\"\" Find the full path of a model given its name, model type and file content type. This does not inspect the file system or confirm the needed path and file exists. \"\"\" root_path = ModelUtils . _root_path_for_top_level_model ( trestle_root , model_name , model_class ) return root_path . with_suffix ( FileContentType . to_file_extension ( file_content_type ))","title":"path_for_top_level_model()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.regenerate_uuids","text":"Regenerate all uuids in object and update corresponding references. Find all dicts with key == 'uuid' and replace the value with a new uuid4. Build a corresponding lookup table as you go, of old:new uuid values. Then make a second pass through the object and replace all string values present in the lookup table with the new value. Parameters: Name Type Description Default object_of_interest Any pydantic.BaseModel, list, dict or str will be updated required Returns: Type Description The updated object with new uuid's and refs The final lookup table of old new uuid's A count of the number of refs that were updated Source code in trestle/common/model_utils.py @staticmethod def regenerate_uuids ( object_of_interest : Any ) -> Tuple [ Any , Dict [ str , str ], int ]: \"\"\"Regenerate all uuids in object and update corresponding references. Find all dicts with key == 'uuid' and replace the value with a new uuid4. Build a corresponding lookup table as you go, of old:new uuid values. Then make a second pass through the object and replace all string values present in the lookup table with the new value. Args: object_of_interest: pydantic.BaseModel, list, dict or str will be updated Returns: The updated object with new uuid's and refs The final lookup table of old:new uuid's A count of the number of refs that were updated \"\"\" new_object , uuid_lut = ModelUtils . _regenerate_uuids_in_place ( object_of_interest , {}) new_object , n_refs_updated = ModelUtils . _update_new_uuid_refs ( new_object , uuid_lut ) return new_object , uuid_lut , n_refs_updated","title":"regenerate_uuids()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.save_top_level_model","text":"Save a model by name and infer model type by inspection. You don't need to specify the model type (catalog, profile, etc.) but you must specify the file content type. If the model directory does not exist, it is created. Source code in trestle/common/model_utils.py @staticmethod def save_top_level_model ( model : TopLevelOscalModel , trestle_root : pathlib . Path , model_name : str , file_content_type : FileContentType ) -> None : \"\"\"Save a model by name and infer model type by inspection. You don't need to specify the model type (catalog, profile, etc.) but you must specify the file content type. If the model directory does not exist, it is created. \"\"\" root_model_path = ModelUtils . _root_path_for_top_level_model ( trestle_root , model_name , model ) full_model_path = root_model_path . with_suffix ( FileContentType . to_file_extension ( file_content_type )) if not full_model_path . parent . exists (): full_model_path . parent . mkdir ( parents = True , exist_ok = True ) model . oscal_write ( full_model_path )","title":"save_top_level_model()"},{"location":"api_reference/trestle.common.model_utils/#trestle.common.model_utils.ModelUtils.update_last_modified","text":"Update the LastModified timestamp in top level model to now. Source code in trestle/common/model_utils.py @staticmethod def update_last_modified ( model : TopLevelOscalModel , timestamp : Optional [ datetime ] = None ) -> None : \"\"\"Update the LastModified timestamp in top level model to now.\"\"\" timestamp = timestamp if timestamp else datetime . now () . astimezone () model . metadata . last_modified = common . LastModified ( __root__ = timestamp ) handler: python","title":"update_last_modified()"},{"location":"api_reference/trestle.common.str_utils/","text":"trestle.common.str_utils \u00a4 Trestle String Utils. Classes \u00a4 AliasMode ( Enum ) \u00a4 Allowed formats for classname alias. Currently there are only two. If others are added, check they get handled properly in the code. Source code in trestle/common/str_utils.py class AliasMode ( enum . Enum ): \"\"\" Allowed formats for classname alias. Currently there are only two. If others are added, check they get handled properly in the code. \"\"\" JSON = 1 FIELD = 2 FIELD \u00a4 JSON \u00a4 Functions \u00a4 alias_to_classname ( alias , mode ) \u00a4 Return class name based dashed or snake alias. This is applicable creating dynamic wrapper model for a list or dict field. Source code in trestle/common/str_utils.py def alias_to_classname ( alias : str , mode : AliasMode ) -> str : \"\"\" Return class name based dashed or snake alias. This is applicable creating dynamic wrapper model for a list or dict field. \"\"\" if mode == AliasMode . JSON : return _snake_to_upper_camel ( alias . replace ( '-' , '_' )) return _snake_to_upper_camel ( alias ) classname_to_alias ( classname , mode ) \u00a4 Return oscal key name or field element name based on class name. This is applicable when asking for a singular element. Source code in trestle/common/str_utils.py def classname_to_alias ( classname : str , mode : AliasMode ) -> str : \"\"\" Return oscal key name or field element name based on class name. This is applicable when asking for a singular element. \"\"\" suffix = classname . split ( '.' )[ - 1 ] # the alias mode is either json or field - yaml doesn't apply here if mode == AliasMode . JSON : # things like class_ should just be class if suffix [ - 1 ] == '_' : suffix = suffix [: - 1 ] return _camel_to_dash ( suffix ) . rstrip ( string . digits ) # else alias mode is field return _camel_to_snake ( suffix ) . rstrip ( string . digits ) dash_to_underscore ( name ) \u00a4 Convert dash to underscore. Source code in trestle/common/str_utils.py def dash_to_underscore ( name : str ) -> str : \"\"\"Convert dash to underscore.\"\"\" return name . replace ( '-' , '_' ) spaces_and_caps_to_snake ( spaced_str ) \u00a4 Convert caps and spaces to snake. Source code in trestle/common/str_utils.py def spaces_and_caps_to_snake ( spaced_str : str ) -> str : \"\"\"Convert caps and spaces to snake.\"\"\" underscored = spaced_str . strip () . replace ( ' ' , '_' ) return underscored . lower () underscore_to_dash ( name ) \u00a4 Convert underscore to dash and drop final dash if present. Source code in trestle/common/str_utils.py def underscore_to_dash ( name : str ) -> str : \"\"\"Convert underscore to dash and drop final dash if present.\"\"\" converted = name . replace ( '_' , '-' ) return converted if converted [ - 1 ] != '-' else converted [: - 1 ] handler: python","title":"str_utils"},{"location":"api_reference/trestle.common.str_utils/#trestle.common.str_utils","text":"Trestle String Utils.","title":"str_utils"},{"location":"api_reference/trestle.common.str_utils/#trestle.common.str_utils-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.common.str_utils/#trestle.common.str_utils.AliasMode","text":"Allowed formats for classname alias. Currently there are only two. If others are added, check they get handled properly in the code. Source code in trestle/common/str_utils.py class AliasMode ( enum . Enum ): \"\"\" Allowed formats for classname alias. Currently there are only two. If others are added, check they get handled properly in the code. \"\"\" JSON = 1 FIELD = 2","title":"AliasMode"},{"location":"api_reference/trestle.common.str_utils/#trestle.common.str_utils.AliasMode.FIELD","text":"","title":"FIELD"},{"location":"api_reference/trestle.common.str_utils/#trestle.common.str_utils.AliasMode.JSON","text":"","title":"JSON"},{"location":"api_reference/trestle.common.str_utils/#trestle.common.str_utils-functions","text":"","title":"Functions"},{"location":"api_reference/trestle.common.str_utils/#trestle.common.str_utils.alias_to_classname","text":"Return class name based dashed or snake alias. This is applicable creating dynamic wrapper model for a list or dict field. Source code in trestle/common/str_utils.py def alias_to_classname ( alias : str , mode : AliasMode ) -> str : \"\"\" Return class name based dashed or snake alias. This is applicable creating dynamic wrapper model for a list or dict field. \"\"\" if mode == AliasMode . JSON : return _snake_to_upper_camel ( alias . replace ( '-' , '_' )) return _snake_to_upper_camel ( alias )","title":"alias_to_classname()"},{"location":"api_reference/trestle.common.str_utils/#trestle.common.str_utils.classname_to_alias","text":"Return oscal key name or field element name based on class name. This is applicable when asking for a singular element. Source code in trestle/common/str_utils.py def classname_to_alias ( classname : str , mode : AliasMode ) -> str : \"\"\" Return oscal key name or field element name based on class name. This is applicable when asking for a singular element. \"\"\" suffix = classname . split ( '.' )[ - 1 ] # the alias mode is either json or field - yaml doesn't apply here if mode == AliasMode . JSON : # things like class_ should just be class if suffix [ - 1 ] == '_' : suffix = suffix [: - 1 ] return _camel_to_dash ( suffix ) . rstrip ( string . digits ) # else alias mode is field return _camel_to_snake ( suffix ) . rstrip ( string . digits )","title":"classname_to_alias()"},{"location":"api_reference/trestle.common.str_utils/#trestle.common.str_utils.dash_to_underscore","text":"Convert dash to underscore. Source code in trestle/common/str_utils.py def dash_to_underscore ( name : str ) -> str : \"\"\"Convert dash to underscore.\"\"\" return name . replace ( '-' , '_' )","title":"dash_to_underscore()"},{"location":"api_reference/trestle.common.str_utils/#trestle.common.str_utils.spaces_and_caps_to_snake","text":"Convert caps and spaces to snake. Source code in trestle/common/str_utils.py def spaces_and_caps_to_snake ( spaced_str : str ) -> str : \"\"\"Convert caps and spaces to snake.\"\"\" underscored = spaced_str . strip () . replace ( ' ' , '_' ) return underscored . lower ()","title":"spaces_and_caps_to_snake()"},{"location":"api_reference/trestle.common.str_utils/#trestle.common.str_utils.underscore_to_dash","text":"Convert underscore to dash and drop final dash if present. Source code in trestle/common/str_utils.py def underscore_to_dash ( name : str ) -> str : \"\"\"Convert underscore to dash and drop final dash if present.\"\"\" converted = name . replace ( '_' , '-' ) return converted if converted [ - 1 ] != '-' else converted [: - 1 ] handler: python","title":"underscore_to_dash()"},{"location":"api_reference/trestle.common.trash/","text":"trestle.common.trash \u00a4 Trestle trash module. TRESTLE_TRASH_DIR \u00a4 TRESTLE_TRASH_DIR_EXT \u00a4 TRESTLE_TRASH_FILE_EXT \u00a4 Functions \u00a4 get_trash_root ( path ) \u00a4 Find the trestle trash root path. Source code in trestle/common/trash.py def get_trash_root ( path : pathlib . Path ) -> Optional [ pathlib . Path ]: \"\"\"Find the trestle trash root path.\"\"\" if path is None or len ( path . parts ) <= 0 : return None current = path while len ( current . parts ) > 1 : # it must not be the system root directory trash_dir = current / TRESTLE_TRASH_DIR if trash_dir . exists () and trash_dir . is_dir (): return trash_dir current = current . parent return None has_parent_path ( sub_path , parent_path ) \u00a4 Check if sub_path has the specified parent_dir path. Source code in trestle/common/trash.py def has_parent_path ( sub_path : pathlib . Path , parent_path : pathlib . Path ) -> bool : \"\"\"Check if sub_path has the specified parent_dir path.\"\"\" # sub_path should be longer than parent path if len ( sub_path . parts ) < len ( parent_path . parts ): return False for i , part in enumerate ( parent_path . parts ): if part != sub_path . parts [ i ]: return False return True recover ( dest_content_path , delete_trash = False ) \u00a4 Recover the specified file or directory from the trash directory. dest_content_path: destination content path that needs to be recovered from trash It recovers the latest path content from trash if exists Source code in trestle/common/trash.py def recover ( dest_content_path : pathlib . Path , delete_trash : bool = False ) -> None : \"\"\"Recover the specified file or directory from the trash directory. dest_content_path: destination content path that needs to be recovered from trash It recovers the latest path content from trash if exists \"\"\" if dest_content_path . suffix != '' : return recover_file ( dest_content_path , delete_trash ) return recover_dir ( dest_content_path , delete_trash ) recover_dir ( dest_dir_path , delete_trash = False ) \u00a4 Move the specified dir from the trash directory. dest_dir_path: destination path of the directory inside a trestle project It recovers the latest directory and contents from trash if exists Source code in trestle/common/trash.py def recover_dir ( dest_dir_path : pathlib . Path , delete_trash : bool = False ) -> None : \"\"\"Move the specified dir from the trash directory. dest_dir_path: destination path of the directory inside a trestle project It recovers the latest directory and contents from trash if exists \"\"\" trash_dir_path = to_trash_dir_path ( dest_dir_path ) if not ( trash_dir_path . exists () and trash_dir_path . is_dir ()): raise AssertionError ( f 'Specified path \" { dest_dir_path } \" could not be found in trash' ) # move all files/directories under sub_path for item_path in pathlib . Path . iterdir ( trash_dir_path ): if item_path . is_file (): recover_file ( to_origin_file_path ( item_path ), delete_trash ) elif item_path . is_dir (): recover_dir ( to_origin_dir_path ( item_path ), delete_trash ) if delete_trash : trash_dir_path . rmdir () recover_file ( file_path , delete_trash = False ) \u00a4 Recover the specified file from the trash directory. It recovers the latest file from trash if exists Source code in trestle/common/trash.py def recover_file ( file_path : pathlib . Path , delete_trash : bool = False ) -> None : \"\"\"Recover the specified file from the trash directory. It recovers the latest file from trash if exists \"\"\" trash_file_path = to_trash_file_path ( file_path ) if not trash_file_path . exists (): raise AssertionError ( f 'Specified path \" { file_path } \" could not be found in trash' ) file_path . parent . mkdir ( exist_ok = True , parents = True ) copyfile ( trash_file_path , file_path ) if delete_trash : trash_file_path . unlink () store ( content_path , delete_content = False ) \u00a4 Move the specified file or directory to the trash directory. It overwrites the previous file or directory if exists Source code in trestle/common/trash.py def store ( content_path : pathlib . Path , delete_content : bool = False ) -> None : \"\"\"Move the specified file or directory to the trash directory. It overwrites the previous file or directory if exists \"\"\" if content_path . is_file (): return store_file ( content_path , delete_content ) if content_path . is_dir (): return store_dir ( content_path , delete_content ) store_dir ( dir_path , delete_source = False ) \u00a4 Move the specified dir to the trash directory. It overwrites the previous directory and contents if exists Source code in trestle/common/trash.py def store_dir ( dir_path : pathlib . Path , delete_source : bool = False ) -> None : \"\"\"Move the specified dir to the trash directory. It overwrites the previous directory and contents if exists \"\"\" if not dir_path . is_dir (): raise AssertionError ( f 'Specified path \" { dir_path } \" is not a dir' ) # move all files/directories under sub_path for item_path in pathlib . Path . iterdir ( dir_path ): if item_path . is_file (): store_file ( item_path , delete_source ) elif item_path . is_dir (): store_dir ( item_path , delete_source ) if delete_source : dir_path . rmdir () store_file ( file_path , delete_source = False ) \u00a4 Move the specified file to the trash directory. It overwrites the previous file if exists Source code in trestle/common/trash.py def store_file ( file_path : pathlib . Path , delete_source : bool = False ) -> None : \"\"\"Move the specified file to the trash directory. It overwrites the previous file if exists \"\"\" if not file_path . is_file (): raise AssertionError ( f 'Specified path \" { file_path } \" is not a file' ) trash_file_path = to_trash_file_path ( file_path ) trash_file_path . parent . mkdir ( exist_ok = True , parents = True ) copyfile ( file_path , trash_file_path ) if delete_source : file_path . unlink () to_origin_dir_path ( trash_dir_path ) \u00a4 Convert trash content path to origin path. Source code in trestle/common/trash.py def to_origin_dir_path ( trash_dir_path : pathlib . Path ) -> pathlib . Path : \"\"\"Convert trash content path to origin path.\"\"\" if trash_dir_path . suffix != '' and trash_dir_path . suffix . endswith ( TRESTLE_TRASH_FILE_EXT ): raise AssertionError ( f 'Given path \" { trash_dir_path } \" is a trash file, not a valid trash directory' ) trestle_root = file_utils . extract_trestle_project_root ( trash_dir_path ) if trestle_root is None : raise AssertionError ( f 'Directory path \" { trash_dir_path } \" is not in a valid trestle project path' ) trash_root = get_trash_root ( trash_dir_path ) if trash_root is None : raise AssertionError ( f 'Directory path \" { trash_dir_path } \" is not in a valid trestle trash path' ) if not has_parent_path ( trash_dir_path , trash_root ): raise AssertionError ( f 'Directory path \" { trash_dir_path } \" is not a valid trash dir path' ) relative_path = trash_dir_path . relative_to ( str ( trash_root )) origin_path_parts : List [ str ] = [] for item in relative_path . parts : parts = item . split ( TRESTLE_TRASH_DIR_EXT ) origin_path_parts . append ( parts [ 0 ]) origin_relative_path = pathlib . Path ( '/' . join ( origin_path_parts )) origin_path = trestle_root / origin_relative_path return origin_path to_origin_file_path ( trash_file_path ) \u00a4 Convert trash file path to origin file path. Source code in trestle/common/trash.py def to_origin_file_path ( trash_file_path : pathlib . Path ) -> pathlib . Path : \"\"\"Convert trash file path to origin file path.\"\"\" if trash_file_path . suffix != TRESTLE_TRASH_FILE_EXT : raise AssertionError ( f 'File path \" { trash_file_path } \" is not a valid trash file path' ) origin_dir = to_origin_dir_path ( trash_file_path . parent ) file_parts = trash_file_path . name . split ( TRESTLE_TRASH_FILE_EXT ) origin_file_path = origin_dir / file_parts [ 0 ] return origin_file_path to_origin_path ( trash_content_path ) \u00a4 Convert the trash path to origin path. Source code in trestle/common/trash.py def to_origin_path ( trash_content_path : pathlib . Path ) -> pathlib . Path : \"\"\"Convert the trash path to origin path.\"\"\" if trash_content_path . suffix == TRESTLE_TRASH_FILE_EXT : return to_origin_file_path ( trash_content_path ) return to_origin_dir_path ( trash_content_path ) to_trash_dir_path ( dir_path ) \u00a4 Construct the path to the trashed file. Source code in trestle/common/trash.py def to_trash_dir_path ( dir_path : pathlib . Path ) -> pathlib . Path : \"\"\"Construct the path to the trashed file.\"\"\" absolute_path = dir_path . resolve () root_path = file_utils . extract_trestle_project_root ( absolute_path ) if root_path is None : raise AssertionError ( f 'Directory path \" { absolute_path } \" is not in a valid trestle project' ) trestle_trash_path = root_path / TRESTLE_TRASH_DIR relative_path = absolute_path . relative_to ( str ( root_path )) if len ( relative_path . parts ) == 0 : trash_dir = trestle_trash_path else : trash_dir = trestle_trash_path / f ' { relative_path }{ TRESTLE_TRASH_DIR_EXT } ' return trash_dir to_trash_file_path ( file_path ) \u00a4 Construct the path to the trashed file. Source code in trestle/common/trash.py def to_trash_file_path ( file_path : pathlib . Path ) -> pathlib . Path : \"\"\"Construct the path to the trashed file.\"\"\" trash_file_dir = to_trash_dir_path ( file_path . parent ) trash_file_path = trash_file_dir / f ' { file_path . name }{ TRESTLE_TRASH_FILE_EXT } ' return trash_file_path to_trash_path ( path ) \u00a4 Convert the dir or file path to apporpriate trash file or dir path. Source code in trestle/common/trash.py def to_trash_path ( path : pathlib . Path ) -> pathlib . Path : \"\"\"Convert the dir or file path to apporpriate trash file or dir path.\"\"\" if path . suffix != '' : return to_trash_file_path ( path ) return to_trash_dir_path ( path ) handler: python","title":"trash"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash","text":"Trestle trash module.","title":"trash"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash.TRESTLE_TRASH_DIR","text":"","title":"TRESTLE_TRASH_DIR"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash.TRESTLE_TRASH_DIR_EXT","text":"","title":"TRESTLE_TRASH_DIR_EXT"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash.TRESTLE_TRASH_FILE_EXT","text":"","title":"TRESTLE_TRASH_FILE_EXT"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash-functions","text":"","title":"Functions"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash.get_trash_root","text":"Find the trestle trash root path. Source code in trestle/common/trash.py def get_trash_root ( path : pathlib . Path ) -> Optional [ pathlib . Path ]: \"\"\"Find the trestle trash root path.\"\"\" if path is None or len ( path . parts ) <= 0 : return None current = path while len ( current . parts ) > 1 : # it must not be the system root directory trash_dir = current / TRESTLE_TRASH_DIR if trash_dir . exists () and trash_dir . is_dir (): return trash_dir current = current . parent return None","title":"get_trash_root()"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash.has_parent_path","text":"Check if sub_path has the specified parent_dir path. Source code in trestle/common/trash.py def has_parent_path ( sub_path : pathlib . Path , parent_path : pathlib . Path ) -> bool : \"\"\"Check if sub_path has the specified parent_dir path.\"\"\" # sub_path should be longer than parent path if len ( sub_path . parts ) < len ( parent_path . parts ): return False for i , part in enumerate ( parent_path . parts ): if part != sub_path . parts [ i ]: return False return True","title":"has_parent_path()"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash.recover","text":"Recover the specified file or directory from the trash directory. dest_content_path: destination content path that needs to be recovered from trash It recovers the latest path content from trash if exists Source code in trestle/common/trash.py def recover ( dest_content_path : pathlib . Path , delete_trash : bool = False ) -> None : \"\"\"Recover the specified file or directory from the trash directory. dest_content_path: destination content path that needs to be recovered from trash It recovers the latest path content from trash if exists \"\"\" if dest_content_path . suffix != '' : return recover_file ( dest_content_path , delete_trash ) return recover_dir ( dest_content_path , delete_trash )","title":"recover()"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash.recover_dir","text":"Move the specified dir from the trash directory. dest_dir_path: destination path of the directory inside a trestle project It recovers the latest directory and contents from trash if exists Source code in trestle/common/trash.py def recover_dir ( dest_dir_path : pathlib . Path , delete_trash : bool = False ) -> None : \"\"\"Move the specified dir from the trash directory. dest_dir_path: destination path of the directory inside a trestle project It recovers the latest directory and contents from trash if exists \"\"\" trash_dir_path = to_trash_dir_path ( dest_dir_path ) if not ( trash_dir_path . exists () and trash_dir_path . is_dir ()): raise AssertionError ( f 'Specified path \" { dest_dir_path } \" could not be found in trash' ) # move all files/directories under sub_path for item_path in pathlib . Path . iterdir ( trash_dir_path ): if item_path . is_file (): recover_file ( to_origin_file_path ( item_path ), delete_trash ) elif item_path . is_dir (): recover_dir ( to_origin_dir_path ( item_path ), delete_trash ) if delete_trash : trash_dir_path . rmdir ()","title":"recover_dir()"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash.recover_file","text":"Recover the specified file from the trash directory. It recovers the latest file from trash if exists Source code in trestle/common/trash.py def recover_file ( file_path : pathlib . Path , delete_trash : bool = False ) -> None : \"\"\"Recover the specified file from the trash directory. It recovers the latest file from trash if exists \"\"\" trash_file_path = to_trash_file_path ( file_path ) if not trash_file_path . exists (): raise AssertionError ( f 'Specified path \" { file_path } \" could not be found in trash' ) file_path . parent . mkdir ( exist_ok = True , parents = True ) copyfile ( trash_file_path , file_path ) if delete_trash : trash_file_path . unlink ()","title":"recover_file()"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash.store","text":"Move the specified file or directory to the trash directory. It overwrites the previous file or directory if exists Source code in trestle/common/trash.py def store ( content_path : pathlib . Path , delete_content : bool = False ) -> None : \"\"\"Move the specified file or directory to the trash directory. It overwrites the previous file or directory if exists \"\"\" if content_path . is_file (): return store_file ( content_path , delete_content ) if content_path . is_dir (): return store_dir ( content_path , delete_content )","title":"store()"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash.store_dir","text":"Move the specified dir to the trash directory. It overwrites the previous directory and contents if exists Source code in trestle/common/trash.py def store_dir ( dir_path : pathlib . Path , delete_source : bool = False ) -> None : \"\"\"Move the specified dir to the trash directory. It overwrites the previous directory and contents if exists \"\"\" if not dir_path . is_dir (): raise AssertionError ( f 'Specified path \" { dir_path } \" is not a dir' ) # move all files/directories under sub_path for item_path in pathlib . Path . iterdir ( dir_path ): if item_path . is_file (): store_file ( item_path , delete_source ) elif item_path . is_dir (): store_dir ( item_path , delete_source ) if delete_source : dir_path . rmdir ()","title":"store_dir()"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash.store_file","text":"Move the specified file to the trash directory. It overwrites the previous file if exists Source code in trestle/common/trash.py def store_file ( file_path : pathlib . Path , delete_source : bool = False ) -> None : \"\"\"Move the specified file to the trash directory. It overwrites the previous file if exists \"\"\" if not file_path . is_file (): raise AssertionError ( f 'Specified path \" { file_path } \" is not a file' ) trash_file_path = to_trash_file_path ( file_path ) trash_file_path . parent . mkdir ( exist_ok = True , parents = True ) copyfile ( file_path , trash_file_path ) if delete_source : file_path . unlink ()","title":"store_file()"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash.to_origin_dir_path","text":"Convert trash content path to origin path. Source code in trestle/common/trash.py def to_origin_dir_path ( trash_dir_path : pathlib . Path ) -> pathlib . Path : \"\"\"Convert trash content path to origin path.\"\"\" if trash_dir_path . suffix != '' and trash_dir_path . suffix . endswith ( TRESTLE_TRASH_FILE_EXT ): raise AssertionError ( f 'Given path \" { trash_dir_path } \" is a trash file, not a valid trash directory' ) trestle_root = file_utils . extract_trestle_project_root ( trash_dir_path ) if trestle_root is None : raise AssertionError ( f 'Directory path \" { trash_dir_path } \" is not in a valid trestle project path' ) trash_root = get_trash_root ( trash_dir_path ) if trash_root is None : raise AssertionError ( f 'Directory path \" { trash_dir_path } \" is not in a valid trestle trash path' ) if not has_parent_path ( trash_dir_path , trash_root ): raise AssertionError ( f 'Directory path \" { trash_dir_path } \" is not a valid trash dir path' ) relative_path = trash_dir_path . relative_to ( str ( trash_root )) origin_path_parts : List [ str ] = [] for item in relative_path . parts : parts = item . split ( TRESTLE_TRASH_DIR_EXT ) origin_path_parts . append ( parts [ 0 ]) origin_relative_path = pathlib . Path ( '/' . join ( origin_path_parts )) origin_path = trestle_root / origin_relative_path return origin_path","title":"to_origin_dir_path()"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash.to_origin_file_path","text":"Convert trash file path to origin file path. Source code in trestle/common/trash.py def to_origin_file_path ( trash_file_path : pathlib . Path ) -> pathlib . Path : \"\"\"Convert trash file path to origin file path.\"\"\" if trash_file_path . suffix != TRESTLE_TRASH_FILE_EXT : raise AssertionError ( f 'File path \" { trash_file_path } \" is not a valid trash file path' ) origin_dir = to_origin_dir_path ( trash_file_path . parent ) file_parts = trash_file_path . name . split ( TRESTLE_TRASH_FILE_EXT ) origin_file_path = origin_dir / file_parts [ 0 ] return origin_file_path","title":"to_origin_file_path()"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash.to_origin_path","text":"Convert the trash path to origin path. Source code in trestle/common/trash.py def to_origin_path ( trash_content_path : pathlib . Path ) -> pathlib . Path : \"\"\"Convert the trash path to origin path.\"\"\" if trash_content_path . suffix == TRESTLE_TRASH_FILE_EXT : return to_origin_file_path ( trash_content_path ) return to_origin_dir_path ( trash_content_path )","title":"to_origin_path()"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash.to_trash_dir_path","text":"Construct the path to the trashed file. Source code in trestle/common/trash.py def to_trash_dir_path ( dir_path : pathlib . Path ) -> pathlib . Path : \"\"\"Construct the path to the trashed file.\"\"\" absolute_path = dir_path . resolve () root_path = file_utils . extract_trestle_project_root ( absolute_path ) if root_path is None : raise AssertionError ( f 'Directory path \" { absolute_path } \" is not in a valid trestle project' ) trestle_trash_path = root_path / TRESTLE_TRASH_DIR relative_path = absolute_path . relative_to ( str ( root_path )) if len ( relative_path . parts ) == 0 : trash_dir = trestle_trash_path else : trash_dir = trestle_trash_path / f ' { relative_path }{ TRESTLE_TRASH_DIR_EXT } ' return trash_dir","title":"to_trash_dir_path()"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash.to_trash_file_path","text":"Construct the path to the trashed file. Source code in trestle/common/trash.py def to_trash_file_path ( file_path : pathlib . Path ) -> pathlib . Path : \"\"\"Construct the path to the trashed file.\"\"\" trash_file_dir = to_trash_dir_path ( file_path . parent ) trash_file_path = trash_file_dir / f ' { file_path . name }{ TRESTLE_TRASH_FILE_EXT } ' return trash_file_path","title":"to_trash_file_path()"},{"location":"api_reference/trestle.common.trash/#trestle.common.trash.to_trash_path","text":"Convert the dir or file path to apporpriate trash file or dir path. Source code in trestle/common/trash.py def to_trash_path ( path : pathlib . Path ) -> pathlib . Path : \"\"\"Convert the dir or file path to apporpriate trash file or dir path.\"\"\" if path . suffix != '' : return to_trash_file_path ( path ) return to_trash_dir_path ( path ) handler: python","title":"to_trash_path()"},{"location":"api_reference/trestle.common.type_utils/","text":"trestle.common.type_utils \u00a4 Utilities for dealing with models. logger \u00a4 Functions \u00a4 get_inner_type ( collection_field_type ) \u00a4 Get the inner model in a generic collection model such as a List or a Dict. For a dict the return type is of the value and not the key. Parameters: Name Type Description Default collection_field_type Union[Type[List[Any]], Type[Dict[str, Any]]] Provided type annotation from a pydantic object required Returns: Type Description Type[Any] The desired type. Source code in trestle/common/type_utils.py def get_inner_type ( collection_field_type : Union [ Type [ List [ Any ]], Type [ Dict [ str , Any ]]]) -> Type [ Any ]: \"\"\"Get the inner model in a generic collection model such as a List or a Dict. For a dict the return type is of the value and not the key. Args: collection_field_type: Provided type annotation from a pydantic object Returns: The desired type. \"\"\" try : # Pydantic special cases must be dealt with here: _ , _ , singular_type = _get_model_field_info ( collection_field_type ) if singular_type is not None : return singular_type return typing_extensions . get_args ( collection_field_type )[ - 1 ] except Exception as e : logger . debug ( e ) raise err . TrestleError ( 'Model type is not a Dict or List' ) from e get_origin ( field_type ) \u00a4 Generalized and robust get_origin function. This function is derived from work by pydantic, however, avoids complications from various python versions. Source code in trestle/common/type_utils.py def get_origin ( field_type : Type [ Any ]) -> Optional [ Type [ Any ]]: \"\"\"Generalized and robust get_origin function. This function is derived from work by pydantic, however, avoids complications from various python versions. \"\"\" # This executes a fallback that allows a list to be generated from a constrained list. return typing_extensions . get_origin ( field_type ) or getattr ( field_type , '__origin__' , None ) is_collection_field_type ( field_type ) \u00a4 Check whether a type hint is a collection type as used by OSCAL. Specifically this is whether the type is a list or not. Parameters: Name Type Description Default field_type Type[Any] A type or a type alias of a field typically as served via pydantic introspection required Returns: Type Description bool True if it is a collection type list. Source code in trestle/common/type_utils.py def is_collection_field_type ( field_type : Type [ Any ]) -> bool : \"\"\"Check whether a type hint is a collection type as used by OSCAL. Specifically this is whether the type is a list or not. Args: field_type: A type or a type alias of a field typically as served via pydantic introspection Returns: True if it is a collection type list. \"\"\" # first check if it is a pydantic __root__ object _ , root_type , _ = _get_model_field_info ( field_type ) if root_type == 'List' : return True # Retrieves type from a type annotation origin_type = get_origin ( field_type ) return origin_type == list handler: python","title":"type_utils"},{"location":"api_reference/trestle.common.type_utils/#trestle.common.type_utils","text":"Utilities for dealing with models.","title":"type_utils"},{"location":"api_reference/trestle.common.type_utils/#trestle.common.type_utils.logger","text":"","title":"logger"},{"location":"api_reference/trestle.common.type_utils/#trestle.common.type_utils-functions","text":"","title":"Functions"},{"location":"api_reference/trestle.common.type_utils/#trestle.common.type_utils.get_inner_type","text":"Get the inner model in a generic collection model such as a List or a Dict. For a dict the return type is of the value and not the key. Parameters: Name Type Description Default collection_field_type Union[Type[List[Any]], Type[Dict[str, Any]]] Provided type annotation from a pydantic object required Returns: Type Description Type[Any] The desired type. Source code in trestle/common/type_utils.py def get_inner_type ( collection_field_type : Union [ Type [ List [ Any ]], Type [ Dict [ str , Any ]]]) -> Type [ Any ]: \"\"\"Get the inner model in a generic collection model such as a List or a Dict. For a dict the return type is of the value and not the key. Args: collection_field_type: Provided type annotation from a pydantic object Returns: The desired type. \"\"\" try : # Pydantic special cases must be dealt with here: _ , _ , singular_type = _get_model_field_info ( collection_field_type ) if singular_type is not None : return singular_type return typing_extensions . get_args ( collection_field_type )[ - 1 ] except Exception as e : logger . debug ( e ) raise err . TrestleError ( 'Model type is not a Dict or List' ) from e","title":"get_inner_type()"},{"location":"api_reference/trestle.common.type_utils/#trestle.common.type_utils.get_origin","text":"Generalized and robust get_origin function. This function is derived from work by pydantic, however, avoids complications from various python versions. Source code in trestle/common/type_utils.py def get_origin ( field_type : Type [ Any ]) -> Optional [ Type [ Any ]]: \"\"\"Generalized and robust get_origin function. This function is derived from work by pydantic, however, avoids complications from various python versions. \"\"\" # This executes a fallback that allows a list to be generated from a constrained list. return typing_extensions . get_origin ( field_type ) or getattr ( field_type , '__origin__' , None )","title":"get_origin()"},{"location":"api_reference/trestle.common.type_utils/#trestle.common.type_utils.is_collection_field_type","text":"Check whether a type hint is a collection type as used by OSCAL. Specifically this is whether the type is a list or not. Parameters: Name Type Description Default field_type Type[Any] A type or a type alias of a field typically as served via pydantic introspection required Returns: Type Description bool True if it is a collection type list. Source code in trestle/common/type_utils.py def is_collection_field_type ( field_type : Type [ Any ]) -> bool : \"\"\"Check whether a type hint is a collection type as used by OSCAL. Specifically this is whether the type is a list or not. Args: field_type: A type or a type alias of a field typically as served via pydantic introspection Returns: True if it is a collection type list. \"\"\" # first check if it is a pydantic __root__ object _ , root_type , _ = _get_model_field_info ( field_type ) if root_type == 'List' : return True # Retrieves type from a type annotation origin_type = get_origin ( field_type ) return origin_type == list handler: python","title":"is_collection_field_type()"},{"location":"api_reference/trestle.core.all_validator/","text":"trestle.core.all_validator \u00a4 Validate based on all registered validators. Classes \u00a4 AllValidator ( Validator ) \u00a4 Validator to confirm the model passes all registered validation tests. Source code in trestle/core/all_validator.py class AllValidator ( Validator ): \"\"\"Validator to confirm the model passes all registered validation tests.\"\"\" last_failure_msg : str def error_msg ( self ) -> str : \"\"\"Return information on which validation failed.\"\"\" return self . last_failure_msg def model_is_valid ( self , model : OscalBaseModel ) -> bool : \"\"\" Validate an oscal model against all available validators in the trestle library. args: model: An Oscal model that can be passed to the validator. returns: True (valid) if the model passed all registered validators. \"\"\" self . last_failure_msg = self . __doc__ for val in vfact . validator_factory . get_all (): if val != self : if not val . model_is_valid ( model ): self . last_failure_msg = val . error_msg () return False return True Methods \u00a4 error_msg ( self ) \u00a4 Return information on which validation failed. Source code in trestle/core/all_validator.py def error_msg ( self ) -> str : \"\"\"Return information on which validation failed.\"\"\" return self . last_failure_msg model_is_valid ( self , model ) \u00a4 Validate an oscal model against all available validators in the trestle library. Parameters: Name Type Description Default model OscalBaseModel An Oscal model that can be passed to the validator. required Returns: Type Description bool True (valid) if the model passed all registered validators. Source code in trestle/core/all_validator.py def model_is_valid ( self , model : OscalBaseModel ) -> bool : \"\"\" Validate an oscal model against all available validators in the trestle library. args: model: An Oscal model that can be passed to the validator. returns: True (valid) if the model passed all registered validators. \"\"\" self . last_failure_msg = self . __doc__ for val in vfact . validator_factory . get_all (): if val != self : if not val . model_is_valid ( model ): self . last_failure_msg = val . error_msg () return False return True handler: python","title":"all_validator"},{"location":"api_reference/trestle.core.all_validator/#trestle.core.all_validator","text":"Validate based on all registered validators.","title":"all_validator"},{"location":"api_reference/trestle.core.all_validator/#trestle.core.all_validator-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.all_validator/#trestle.core.all_validator.AllValidator","text":"Validator to confirm the model passes all registered validation tests. Source code in trestle/core/all_validator.py class AllValidator ( Validator ): \"\"\"Validator to confirm the model passes all registered validation tests.\"\"\" last_failure_msg : str def error_msg ( self ) -> str : \"\"\"Return information on which validation failed.\"\"\" return self . last_failure_msg def model_is_valid ( self , model : OscalBaseModel ) -> bool : \"\"\" Validate an oscal model against all available validators in the trestle library. args: model: An Oscal model that can be passed to the validator. returns: True (valid) if the model passed all registered validators. \"\"\" self . last_failure_msg = self . __doc__ for val in vfact . validator_factory . get_all (): if val != self : if not val . model_is_valid ( model ): self . last_failure_msg = val . error_msg () return False return True","title":"AllValidator"},{"location":"api_reference/trestle.core.all_validator/#trestle.core.all_validator.AllValidator-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.all_validator/#trestle.core.all_validator.AllValidator.error_msg","text":"Return information on which validation failed. Source code in trestle/core/all_validator.py def error_msg ( self ) -> str : \"\"\"Return information on which validation failed.\"\"\" return self . last_failure_msg","title":"error_msg()"},{"location":"api_reference/trestle.core.all_validator/#trestle.core.all_validator.AllValidator.model_is_valid","text":"Validate an oscal model against all available validators in the trestle library. Parameters: Name Type Description Default model OscalBaseModel An Oscal model that can be passed to the validator. required Returns: Type Description bool True (valid) if the model passed all registered validators. Source code in trestle/core/all_validator.py def model_is_valid ( self , model : OscalBaseModel ) -> bool : \"\"\" Validate an oscal model against all available validators in the trestle library. args: model: An Oscal model that can be passed to the validator. returns: True (valid) if the model passed all registered validators. \"\"\" self . last_failure_msg = self . __doc__ for val in vfact . validator_factory . get_all (): if val != self : if not val . model_is_valid ( model ): self . last_failure_msg = val . error_msg () return False return True handler: python","title":"model_is_valid()"},{"location":"api_reference/trestle.core.base_model/","text":"trestle.core.base_model \u00a4 Pydantic base model for use within trestle project and associated configuration. The heart of the current OSCAL model within trestle is based on pydantic ( https://pydantic-docs.helpmanual.io/ ) which itself is a veneer on-top of python data classes. Functionality here defines a base-model which all trestle oscal data models inherit from. This allows additional functionality to be easily inserted. I can write a comment in here and you can even edit on the same line. logger \u00a4 Classes \u00a4 OscalBaseModel ( TrestleBaseModel ) pydantic-model \u00a4 Trestle defined pydantic base model for use with OSCAL pydantic dataclasses. This BaseModel provides two types of functionality: 1. Overrides default configuation of the pydantic library with behaviours required for trestle 2. Provides utility functions for trestle which are specific to OSCAL and the naming schema associated with it. Source code in trestle/core/base_model.py class OscalBaseModel ( TrestleBaseModel ): \"\"\" Trestle defined pydantic base model for use with OSCAL pydantic dataclasses. This BaseModel provides two types of functionality: 1. Overrides default configuation of the pydantic library with behaviours required for trestle 2. Provides utility functions for trestle which are specific to OSCAL and the naming schema associated with it. \"\"\" class Config : \"\"\"Overriding configuration class for pydantic base model, for use with OSCAL data classes.\"\"\" json_loads = orjson . loads # TODO: json_dumps with orjson.dumps see #840 json_encoders = { datetime . datetime : lambda x : robust_datetime_serialization ( x )} allow_population_by_field_name = True # Enforce strict schema extra = Extra . forbid # Validate on assignment of variables to ensure no escapes validate_assignment = True @classmethod def create_stripped_model_type ( cls , stripped_fields : Optional [ List [ str ]] = None , stripped_fields_aliases : Optional [ List [ str ]] = None ) -> Type [ 'OscalBaseModel' ]: \"\"\"Create a pydantic model, which is derived from the current model, but missing certain fields. OSCAL mandates a 'strict' schema (e.g. unless otherwise stated no additional fields), and certain fields are mandatory. Given this the corresponding dataclasses are also strict. Workflows with trestle require missing mandatory fields. This allows creation of derivative models missing certain fields. Args: stripped_fields: The fields to be removed from the current data class. stripped_fields_aliases: The fields to be removed from the current data class provided by alias. Returns: Pydantic data class thta can be used to instanciate a model. Raises: TrestleError: If user provided both stripped_fields and stripped_field_aliases or neither. TrestleError: If incorrect aliases or field names are provided. \"\"\" if stripped_fields is not None and stripped_fields_aliases is not None : raise err . TrestleError ( 'Either \"stripped_fields\" or \"stripped_fields_aliases\" need to be passed, not both.' ) if stripped_fields is None and stripped_fields_aliases is None : raise err . TrestleError ( 'Exactly one of \"stripped_fields\" or \"stripped_fields_aliases\" must be provided' ) # create alias to field_name mapping excluded_fields = [] if stripped_fields is not None : excluded_fields = stripped_fields elif stripped_fields_aliases is not None : alias_to_field = cls . alias_to_field_map () try : excluded_fields = [ alias_to_field [ key ] . name for key in stripped_fields_aliases ] except KeyError as e : raise err . TrestleError ( f 'Field { str ( e ) } does not exist in the model' ) current_fields = cls . __fields__ new_fields_for_model = {} # Build field list for current_mfield in current_fields . values (): if current_mfield . name in excluded_fields : continue # Validate name in the field # Cehcke behaviour with an alias if current_mfield . required : new_fields_for_model [ current_mfield . name ] = ( current_mfield . outer_type_ , Field ( ... , title = current_mfield . name , alias = current_mfield . alias )) else : new_fields_for_model [ current_mfield . name ] = ( Optional [ current_mfield . outer_type_ ], Field ( None , title = current_mfield . name , alias = current_mfield . alias ) ) new_model = create_model ( cls . __name__ , __base__ = OscalBaseModel , ** new_fields_for_model ) # type: ignore # TODO: This typing cast should NOT be necessary. Potentially fixable with a fix to pydantic. Issue #175 new_model = cast ( Type [ OscalBaseModel ], new_model ) return new_model def get_field_by_alias ( self , field_alias : str ) -> Any : \"\"\"Convert field alias to a field.\"\"\" attr_field = self . alias_to_field_map () . get ( field_alias , None ) return attr_field def get_field_value_by_alias ( self , attr_alias : str ) -> Optional [ Any ]: \"\"\"Get attribute value by field alias.\"\"\" # TODO: can this be restricted beyond Any easily. attr_field = self . get_field_by_alias ( attr_alias ) if isinstance ( attr_field , ModelField ): return getattr ( self , attr_field . name , None ) return None def stripped_instance ( self , stripped_fields : List [ str ] = None , stripped_fields_aliases : List [ str ] = None ) -> 'OscalBaseModel' : \"\"\"Return a new model instance with the specified fields being stripped. Args: stripped_fields: The fields to be removed from the current data class. stripped_fields_aliases: The fields to be removed from the current data class provided by alias. Returns: The current datamodel with the fields provided removed in a derivate (run time created) data model. Raises: err.TrestleError: If user provided both stripped_fields and stripped_field_aliases or neither. err.TrestleError: If incorrect aliases or field names are provided. \"\"\" # stripped class type stripped_class : Type [ OscalBaseModel ] = self . create_stripped_model_type ( stripped_fields = stripped_fields , stripped_fields_aliases = stripped_fields_aliases ) # remaining values remaining_values = {} for field in self . __fields__ . values (): if field . name in stripped_class . __fields__ : remaining_values [ field . name ] = self . __dict__ [ field . name ] # create stripped model instance # TODO: Not sure if we can avoid type escapes here stripped_instance = stripped_class ( ** remaining_values ) # type: ignore return stripped_instance def oscal_dict ( self ) -> Dict [ str , Any ]: \"\"\"Return a dictionary including the root wrapping object key.\"\"\" class_name = self . __class__ . __name__ result = {} raw_dict = self . dict ( by_alias = True , exclude_none = True ) # Additional check to avoid root serialization if '__root__' in raw_dict . keys (): result [ classname_to_alias ( class_name , AliasMode . JSON )] = raw_dict [ '__root__' ] else : result [ classname_to_alias ( class_name , AliasMode . JSON )] = raw_dict return result def oscal_serialize_json_bytes ( self , pretty : bool = False , wrapped : bool = True ) -> bytes : \"\"\" Return an 'oscal wrapped' json object serialized in a compressed form as bytes. Args: pretty: Whether or not to pretty-print json output or have in compressed form. Returns: Oscal model serialized to a json object including packaging inside of a single top level key. \"\"\" if wrapped : odict = self . oscal_dict () else : odict = self . dict ( by_alias = True , exclude_none = True ) if pretty : return orjson . dumps ( odict , default = self . __json_encoder__ , option = orjson . OPT_INDENT_2 ) return orjson . dumps ( odict , default = self . __json_encoder__ ) def oscal_serialize_json ( self , pretty : bool = False , wrapped : bool = True ) -> str : \"\"\" Return an 'oscal wrapped' json object serialized in a compressed form as bytes. Args: pretty: Whether or not to pretty-print json output or have in compressed form. Returns: Oscal model serialized to a json object including packaging inside of a single top level key. \"\"\" # This function is provided for backwards compatibility return self . oscal_serialize_json_bytes ( pretty , wrapped ) . decode ( const . FILE_ENCODING ) def oscal_write ( self , path : pathlib . Path ) -> None : \"\"\" Write out a pydantic data model in an oscal friendly way. OSCAL schema mandates that top level elements are wrapped in a singular json/yaml field. This function handles both json and yaml output as well as formatting of the json. Args: path: The output file location for the oscal object. Raises: err.TrestleError: If a unknown file extension is provided. \"\"\" content_type = FileContentType . to_content_type ( path . suffix ) # The output will have \\r\\n newlines on windows and \\n newlines elsewhere if content_type == FileContentType . YAML : write_file = pathlib . Path ( path ) . open ( 'w' , encoding = const . FILE_ENCODING ) yaml = YAML ( typ = 'safe' ) yaml . dump ( yaml . load ( self . oscal_serialize_json ()), write_file ) write_file . flush () write_file . close () elif content_type == FileContentType . JSON : write_file = pathlib . Path ( path ) . open ( 'wb' ) write_file . write ( self . oscal_serialize_json_bytes ( pretty = True )) # Flush / close required (by experience) due to flushing issues in tests. write_file . flush () write_file . close () @classmethod def oscal_read ( cls , path : pathlib . Path ) -> Optional [ 'OscalBaseModel' ]: \"\"\" Read OSCAL objects. Handles the fact OSCAL wraps top level elements and also deals with both yaml and json. Args: path: The path of the oscal object to read. Returns: The oscal object read into trestle oscal models. \"\"\" # Create the wrapper model. alias = classname_to_alias ( cls . __name__ , AliasMode . JSON ) content_type = FileContentType . to_content_type ( path . suffix ) logger . debug ( f 'oscal_read content type { content_type } and alias { alias } from { path } ' ) if not path . exists (): logger . warning ( f 'path does not exist in oscal_read: { path } ' ) return None obj : Dict [ str , Any ] = {} try : if content_type == FileContentType . YAML : yaml = YAML ( typ = 'safe' ) fh = path . open ( 'r' , encoding = const . FILE_ENCODING ) obj = yaml . load ( fh ) fh . close () elif content_type == FileContentType . JSON : obj = load_file ( path , json_loads = cls . __config__ . json_loads , ) except Exception as e : raise err . TrestleError ( f 'Error loading file { path } { str ( e ) } ' ) try : if not len ( obj ) == 1 : raise err . TrestleError ( f 'Invalid OSCAL file structure, oscal file ' f 'does not have a single top level key wrapping it. It has { len ( obj ) } keys.' ) parsed = cls . parse_obj ( obj [ alias ]) except KeyError : raise err . TrestleError ( f 'Provided oscal file does not have top level key key: { alias } ' ) except Exception as e : raise err . TrestleError ( f 'Error parsing file { path } { str ( e ) } ' ) return parsed def copy_to ( self , new_oscal_type : Type [ 'OscalBaseModel' ]) -> 'OscalBaseModel' : \"\"\" Opportunistic copy operation between similar types of data classes. Due to the way in which oscal is constructed we get a set of similar / the same definition across various oscal models. Due to the lack of guarantees that they are the same we cannot easily 'collapse' the mode. Args: new_oscal_type: The desired type of oscal model Returns: Opportunistic copy of the data into the new model type. \"\"\" logger . debug ( 'Copy to started' ) if self . __class__ . __name__ == new_oscal_type . __name__ : logger . debug ( 'Json based copy' ) # Note: Json based oppportunistic copy # Dev notes: Do not change this from json. Due to enums (in particular) json is the closest we can get. return new_oscal_type . parse_raw ( self . oscal_serialize_json ( pretty = False , wrapped = False )) if ( '__root__' in self . __fields__ and len ( self . __fields__ ) == 1 and '__root__' in new_oscal_type . __fields__ and len ( new_oscal_type . __fields__ ) == 1 ): logger . debug ( 'Root element based copy too' ) return new_oscal_type . parse_obj ( self . __root__ ) # bad place here. raise err . TrestleError ( 'Provided inconsistent classes to copy to methodology.' ) def copy_from ( self , existing_oscal_object : 'OscalBaseModel' ) -> None : \"\"\" Copy operation that implicitly does type conversion. Typically would be used to set an attribute, however, does not need to be. Deals with two scenarios: 1) Casting across oscal models of equivalent type. The purpose if this is to cross class spaces. 2) The same as above where the item is an array style object which does not correctly serialize to a dict. 3) if the from and 'to' objects are root schema elements the copy operation will copy the root element to the value. Args: existing_oscal_object: The oscal object where fields are copied from. \"\"\" recast_object = existing_oscal_object . copy_to ( self . __class__ ) for raw_field in self . __dict__ : self . __dict__ [ raw_field ] = recast_object . __dict__ [ raw_field ] @classmethod def alias_to_field_map ( cls ) -> Dict [ str , ModelField ]: \"\"\"Create a map from field alias to field. Returns: A dict which has key's of aliases and Fields as values. \"\"\" alias_to_field : Dict [ str , ModelField ] = {} for field in cls . __fields__ . values (): alias_to_field [ field . alias ] = field return alias_to_field @classmethod def is_collection_container ( cls ) -> bool : \"\"\" Determine whether a pydantic model has being created to wrap a collection primitive (e.g a list or dict). In performing model decomposition it is possible using trestle framework to automatically generate a model which looks like class Foo(OscalBaseModel): __root__: List[Bar] Returns: Boolean on if it meets the above criteria When these cases exist we need special handling of the type information. \"\"\" # Additional sanity check on field length if len ( cls . __fields__ ) == 1 and '__root__' in cls . __fields__ : # This is now a __root__ key only model if is_collection_field_type ( cls . __fields__ [ '__root__' ] . outer_type_ ): return True return False @classmethod def get_collection_type ( cls ) -> Optional [ type ]: \"\"\" If the type wraps an collection, return the collection type. Returns: The collection type. Raises: err.TrestleError: if not a wrapper of the collection type. \"\"\" if not cls . is_collection_container (): raise err . TrestleError ( 'OscalBaseModel is not wrapping a collection type' ) return get_origin ( cls . __fields__ [ '__root__' ] . outer_type_ ) Classes \u00a4 Config \u00a4 Overriding configuration class for pydantic base model, for use with OSCAL data classes. Source code in trestle/core/base_model.py class Config : \"\"\"Overriding configuration class for pydantic base model, for use with OSCAL data classes.\"\"\" json_loads = orjson . loads # TODO: json_dumps with orjson.dumps see #840 json_encoders = { datetime . datetime : lambda x : robust_datetime_serialization ( x )} allow_population_by_field_name = True # Enforce strict schema extra = Extra . forbid # Validate on assignment of variables to ensure no escapes validate_assignment = True allow_population_by_field_name \u00a4 extra \u00a4 json_encoders \u00a4 json_loads \u00a4 validate_assignment \u00a4 Methods \u00a4 alias_to_field_map () classmethod \u00a4 Create a map from field alias to field. Returns: Type Description Dict[str, pydantic.fields.ModelField] A dict which has key's of aliases and Fields as values. Source code in trestle/core/base_model.py @classmethod def alias_to_field_map ( cls ) -> Dict [ str , ModelField ]: \"\"\"Create a map from field alias to field. Returns: A dict which has key's of aliases and Fields as values. \"\"\" alias_to_field : Dict [ str , ModelField ] = {} for field in cls . __fields__ . values (): alias_to_field [ field . alias ] = field return alias_to_field copy_from ( self , existing_oscal_object ) \u00a4 Copy operation that implicitly does type conversion. Typically would be used to set an attribute, however, does not need to be. Deals with two scenarios: 1) Casting across oscal models of equivalent type. The purpose if this is to cross class spaces. 2) The same as above where the item is an array style object which does not correctly serialize to a dict. 3) if the from and 'to' objects are root schema elements the copy operation will copy the root element to the value. Parameters: Name Type Description Default existing_oscal_object OscalBaseModel The oscal object where fields are copied from. required Source code in trestle/core/base_model.py def copy_from ( self , existing_oscal_object : 'OscalBaseModel' ) -> None : \"\"\" Copy operation that implicitly does type conversion. Typically would be used to set an attribute, however, does not need to be. Deals with two scenarios: 1) Casting across oscal models of equivalent type. The purpose if this is to cross class spaces. 2) The same as above where the item is an array style object which does not correctly serialize to a dict. 3) if the from and 'to' objects are root schema elements the copy operation will copy the root element to the value. Args: existing_oscal_object: The oscal object where fields are copied from. \"\"\" recast_object = existing_oscal_object . copy_to ( self . __class__ ) for raw_field in self . __dict__ : self . __dict__ [ raw_field ] = recast_object . __dict__ [ raw_field ] copy_to ( self , new_oscal_type ) \u00a4 Opportunistic copy operation between similar types of data classes. Due to the way in which oscal is constructed we get a set of similar / the same definition across various oscal models. Due to the lack of guarantees that they are the same we cannot easily 'collapse' the mode. Parameters: Name Type Description Default new_oscal_type Type[OscalBaseModel] The desired type of oscal model required Returns: Type Description OscalBaseModel Opportunistic copy of the data into the new model type. Source code in trestle/core/base_model.py def copy_to ( self , new_oscal_type : Type [ 'OscalBaseModel' ]) -> 'OscalBaseModel' : \"\"\" Opportunistic copy operation between similar types of data classes. Due to the way in which oscal is constructed we get a set of similar / the same definition across various oscal models. Due to the lack of guarantees that they are the same we cannot easily 'collapse' the mode. Args: new_oscal_type: The desired type of oscal model Returns: Opportunistic copy of the data into the new model type. \"\"\" logger . debug ( 'Copy to started' ) if self . __class__ . __name__ == new_oscal_type . __name__ : logger . debug ( 'Json based copy' ) # Note: Json based oppportunistic copy # Dev notes: Do not change this from json. Due to enums (in particular) json is the closest we can get. return new_oscal_type . parse_raw ( self . oscal_serialize_json ( pretty = False , wrapped = False )) if ( '__root__' in self . __fields__ and len ( self . __fields__ ) == 1 and '__root__' in new_oscal_type . __fields__ and len ( new_oscal_type . __fields__ ) == 1 ): logger . debug ( 'Root element based copy too' ) return new_oscal_type . parse_obj ( self . __root__ ) # bad place here. raise err . TrestleError ( 'Provided inconsistent classes to copy to methodology.' ) create_stripped_model_type ( stripped_fields = None , stripped_fields_aliases = None ) classmethod \u00a4 Create a pydantic model, which is derived from the current model, but missing certain fields. OSCAL mandates a 'strict' schema (e.g. unless otherwise stated no additional fields), and certain fields are mandatory. Given this the corresponding dataclasses are also strict. Workflows with trestle require missing mandatory fields. This allows creation of derivative models missing certain fields. Parameters: Name Type Description Default stripped_fields Optional[List[str]] The fields to be removed from the current data class. None stripped_fields_aliases Optional[List[str]] The fields to be removed from the current data class provided by alias. None Returns: Type Description Type[OscalBaseModel] Pydantic data class thta can be used to instanciate a model. Exceptions: Type Description TrestleError If user provided both stripped_fields and stripped_field_aliases or neither. TrestleError If incorrect aliases or field names are provided. Source code in trestle/core/base_model.py @classmethod def create_stripped_model_type ( cls , stripped_fields : Optional [ List [ str ]] = None , stripped_fields_aliases : Optional [ List [ str ]] = None ) -> Type [ 'OscalBaseModel' ]: \"\"\"Create a pydantic model, which is derived from the current model, but missing certain fields. OSCAL mandates a 'strict' schema (e.g. unless otherwise stated no additional fields), and certain fields are mandatory. Given this the corresponding dataclasses are also strict. Workflows with trestle require missing mandatory fields. This allows creation of derivative models missing certain fields. Args: stripped_fields: The fields to be removed from the current data class. stripped_fields_aliases: The fields to be removed from the current data class provided by alias. Returns: Pydantic data class thta can be used to instanciate a model. Raises: TrestleError: If user provided both stripped_fields and stripped_field_aliases or neither. TrestleError: If incorrect aliases or field names are provided. \"\"\" if stripped_fields is not None and stripped_fields_aliases is not None : raise err . TrestleError ( 'Either \"stripped_fields\" or \"stripped_fields_aliases\" need to be passed, not both.' ) if stripped_fields is None and stripped_fields_aliases is None : raise err . TrestleError ( 'Exactly one of \"stripped_fields\" or \"stripped_fields_aliases\" must be provided' ) # create alias to field_name mapping excluded_fields = [] if stripped_fields is not None : excluded_fields = stripped_fields elif stripped_fields_aliases is not None : alias_to_field = cls . alias_to_field_map () try : excluded_fields = [ alias_to_field [ key ] . name for key in stripped_fields_aliases ] except KeyError as e : raise err . TrestleError ( f 'Field { str ( e ) } does not exist in the model' ) current_fields = cls . __fields__ new_fields_for_model = {} # Build field list for current_mfield in current_fields . values (): if current_mfield . name in excluded_fields : continue # Validate name in the field # Cehcke behaviour with an alias if current_mfield . required : new_fields_for_model [ current_mfield . name ] = ( current_mfield . outer_type_ , Field ( ... , title = current_mfield . name , alias = current_mfield . alias )) else : new_fields_for_model [ current_mfield . name ] = ( Optional [ current_mfield . outer_type_ ], Field ( None , title = current_mfield . name , alias = current_mfield . alias ) ) new_model = create_model ( cls . __name__ , __base__ = OscalBaseModel , ** new_fields_for_model ) # type: ignore # TODO: This typing cast should NOT be necessary. Potentially fixable with a fix to pydantic. Issue #175 new_model = cast ( Type [ OscalBaseModel ], new_model ) return new_model get_collection_type () classmethod \u00a4 If the type wraps an collection, return the collection type. Returns: Type Description Optional[type] The collection type. Exceptions: Type Description err.TrestleError if not a wrapper of the collection type. Source code in trestle/core/base_model.py @classmethod def get_collection_type ( cls ) -> Optional [ type ]: \"\"\" If the type wraps an collection, return the collection type. Returns: The collection type. Raises: err.TrestleError: if not a wrapper of the collection type. \"\"\" if not cls . is_collection_container (): raise err . TrestleError ( 'OscalBaseModel is not wrapping a collection type' ) return get_origin ( cls . __fields__ [ '__root__' ] . outer_type_ ) get_field_by_alias ( self , field_alias ) \u00a4 Convert field alias to a field. Source code in trestle/core/base_model.py def get_field_by_alias ( self , field_alias : str ) -> Any : \"\"\"Convert field alias to a field.\"\"\" attr_field = self . alias_to_field_map () . get ( field_alias , None ) return attr_field get_field_value_by_alias ( self , attr_alias ) \u00a4 Get attribute value by field alias. Source code in trestle/core/base_model.py def get_field_value_by_alias ( self , attr_alias : str ) -> Optional [ Any ]: \"\"\"Get attribute value by field alias.\"\"\" # TODO: can this be restricted beyond Any easily. attr_field = self . get_field_by_alias ( attr_alias ) if isinstance ( attr_field , ModelField ): return getattr ( self , attr_field . name , None ) return None is_collection_container () classmethod \u00a4 Determine whether a pydantic model has being created to wrap a collection primitive (e.g a list or dict). In performing model decomposition it is possible using trestle framework to automatically generate a model which looks like class Foo(OscalBaseModel): root : List[Bar] Returns: Type Description bool Boolean on if it meets the above criteria When these cases exist we need special handling of the type information. Source code in trestle/core/base_model.py @classmethod def is_collection_container ( cls ) -> bool : \"\"\" Determine whether a pydantic model has being created to wrap a collection primitive (e.g a list or dict). In performing model decomposition it is possible using trestle framework to automatically generate a model which looks like class Foo(OscalBaseModel): __root__: List[Bar] Returns: Boolean on if it meets the above criteria When these cases exist we need special handling of the type information. \"\"\" # Additional sanity check on field length if len ( cls . __fields__ ) == 1 and '__root__' in cls . __fields__ : # This is now a __root__ key only model if is_collection_field_type ( cls . __fields__ [ '__root__' ] . outer_type_ ): return True return False oscal_dict ( self ) \u00a4 Return a dictionary including the root wrapping object key. Source code in trestle/core/base_model.py def oscal_dict ( self ) -> Dict [ str , Any ]: \"\"\"Return a dictionary including the root wrapping object key.\"\"\" class_name = self . __class__ . __name__ result = {} raw_dict = self . dict ( by_alias = True , exclude_none = True ) # Additional check to avoid root serialization if '__root__' in raw_dict . keys (): result [ classname_to_alias ( class_name , AliasMode . JSON )] = raw_dict [ '__root__' ] else : result [ classname_to_alias ( class_name , AliasMode . JSON )] = raw_dict return result oscal_read ( path ) classmethod \u00a4 Read OSCAL objects. Handles the fact OSCAL wraps top level elements and also deals with both yaml and json. Parameters: Name Type Description Default path Path The path of the oscal object to read. required Returns: Type Description Optional[OscalBaseModel] The oscal object read into trestle oscal models. Source code in trestle/core/base_model.py @classmethod def oscal_read ( cls , path : pathlib . Path ) -> Optional [ 'OscalBaseModel' ]: \"\"\" Read OSCAL objects. Handles the fact OSCAL wraps top level elements and also deals with both yaml and json. Args: path: The path of the oscal object to read. Returns: The oscal object read into trestle oscal models. \"\"\" # Create the wrapper model. alias = classname_to_alias ( cls . __name__ , AliasMode . JSON ) content_type = FileContentType . to_content_type ( path . suffix ) logger . debug ( f 'oscal_read content type { content_type } and alias { alias } from { path } ' ) if not path . exists (): logger . warning ( f 'path does not exist in oscal_read: { path } ' ) return None obj : Dict [ str , Any ] = {} try : if content_type == FileContentType . YAML : yaml = YAML ( typ = 'safe' ) fh = path . open ( 'r' , encoding = const . FILE_ENCODING ) obj = yaml . load ( fh ) fh . close () elif content_type == FileContentType . JSON : obj = load_file ( path , json_loads = cls . __config__ . json_loads , ) except Exception as e : raise err . TrestleError ( f 'Error loading file { path } { str ( e ) } ' ) try : if not len ( obj ) == 1 : raise err . TrestleError ( f 'Invalid OSCAL file structure, oscal file ' f 'does not have a single top level key wrapping it. It has { len ( obj ) } keys.' ) parsed = cls . parse_obj ( obj [ alias ]) except KeyError : raise err . TrestleError ( f 'Provided oscal file does not have top level key key: { alias } ' ) except Exception as e : raise err . TrestleError ( f 'Error parsing file { path } { str ( e ) } ' ) return parsed oscal_serialize_json ( self , pretty = False , wrapped = True ) \u00a4 Return an 'oscal wrapped' json object serialized in a compressed form as bytes. Parameters: Name Type Description Default pretty bool Whether or not to pretty-print json output or have in compressed form. False Returns: Type Description str Oscal model serialized to a json object including packaging inside of a single top level key. Source code in trestle/core/base_model.py def oscal_serialize_json ( self , pretty : bool = False , wrapped : bool = True ) -> str : \"\"\" Return an 'oscal wrapped' json object serialized in a compressed form as bytes. Args: pretty: Whether or not to pretty-print json output or have in compressed form. Returns: Oscal model serialized to a json object including packaging inside of a single top level key. \"\"\" # This function is provided for backwards compatibility return self . oscal_serialize_json_bytes ( pretty , wrapped ) . decode ( const . FILE_ENCODING ) oscal_serialize_json_bytes ( self , pretty = False , wrapped = True ) \u00a4 Return an 'oscal wrapped' json object serialized in a compressed form as bytes. Parameters: Name Type Description Default pretty bool Whether or not to pretty-print json output or have in compressed form. False Returns: Type Description bytes Oscal model serialized to a json object including packaging inside of a single top level key. Source code in trestle/core/base_model.py def oscal_serialize_json_bytes ( self , pretty : bool = False , wrapped : bool = True ) -> bytes : \"\"\" Return an 'oscal wrapped' json object serialized in a compressed form as bytes. Args: pretty: Whether or not to pretty-print json output or have in compressed form. Returns: Oscal model serialized to a json object including packaging inside of a single top level key. \"\"\" if wrapped : odict = self . oscal_dict () else : odict = self . dict ( by_alias = True , exclude_none = True ) if pretty : return orjson . dumps ( odict , default = self . __json_encoder__ , option = orjson . OPT_INDENT_2 ) return orjson . dumps ( odict , default = self . __json_encoder__ ) oscal_write ( self , path ) \u00a4 Write out a pydantic data model in an oscal friendly way. OSCAL schema mandates that top level elements are wrapped in a singular json/yaml field. This function handles both json and yaml output as well as formatting of the json. Parameters: Name Type Description Default path Path The output file location for the oscal object. required Exceptions: Type Description err.TrestleError If a unknown file extension is provided. Source code in trestle/core/base_model.py def oscal_write ( self , path : pathlib . Path ) -> None : \"\"\" Write out a pydantic data model in an oscal friendly way. OSCAL schema mandates that top level elements are wrapped in a singular json/yaml field. This function handles both json and yaml output as well as formatting of the json. Args: path: The output file location for the oscal object. Raises: err.TrestleError: If a unknown file extension is provided. \"\"\" content_type = FileContentType . to_content_type ( path . suffix ) # The output will have \\r\\n newlines on windows and \\n newlines elsewhere if content_type == FileContentType . YAML : write_file = pathlib . Path ( path ) . open ( 'w' , encoding = const . FILE_ENCODING ) yaml = YAML ( typ = 'safe' ) yaml . dump ( yaml . load ( self . oscal_serialize_json ()), write_file ) write_file . flush () write_file . close () elif content_type == FileContentType . JSON : write_file = pathlib . Path ( path ) . open ( 'wb' ) write_file . write ( self . oscal_serialize_json_bytes ( pretty = True )) # Flush / close required (by experience) due to flushing issues in tests. write_file . flush () write_file . close () stripped_instance ( self , stripped_fields = None , stripped_fields_aliases = None ) \u00a4 Return a new model instance with the specified fields being stripped. Parameters: Name Type Description Default stripped_fields List[str] The fields to be removed from the current data class. None stripped_fields_aliases List[str] The fields to be removed from the current data class provided by alias. None Returns: Type Description OscalBaseModel The current datamodel with the fields provided removed in a derivate (run time created) data model. Exceptions: Type Description err.TrestleError If user provided both stripped_fields and stripped_field_aliases or neither. err.TrestleError If incorrect aliases or field names are provided. Source code in trestle/core/base_model.py def stripped_instance ( self , stripped_fields : List [ str ] = None , stripped_fields_aliases : List [ str ] = None ) -> 'OscalBaseModel' : \"\"\"Return a new model instance with the specified fields being stripped. Args: stripped_fields: The fields to be removed from the current data class. stripped_fields_aliases: The fields to be removed from the current data class provided by alias. Returns: The current datamodel with the fields provided removed in a derivate (run time created) data model. Raises: err.TrestleError: If user provided both stripped_fields and stripped_field_aliases or neither. err.TrestleError: If incorrect aliases or field names are provided. \"\"\" # stripped class type stripped_class : Type [ OscalBaseModel ] = self . create_stripped_model_type ( stripped_fields = stripped_fields , stripped_fields_aliases = stripped_fields_aliases ) # remaining values remaining_values = {} for field in self . __fields__ . values (): if field . name in stripped_class . __fields__ : remaining_values [ field . name ] = self . __dict__ [ field . name ] # create stripped model instance # TODO: Not sure if we can avoid type escapes here stripped_instance = stripped_class ( ** remaining_values ) # type: ignore return stripped_instance Functions \u00a4 robust_datetime_serialization ( input_dt ) \u00a4 Return a nicely formatted string for in a format compatible with OSCAL specifications. Parameters: Name Type Description Default input_dt datetime Input datetime to convert to a string. required Returns: Type Description str String in isoformat to the millisecond enforcing that timezone offset is provided. Exceptions: Type Description TrestleError Error is raised if datetime object does not contain sufficient timezone information. Source code in trestle/core/base_model.py def robust_datetime_serialization ( input_dt : datetime . datetime ) -> str : \"\"\"Return a nicely formatted string for in a format compatible with OSCAL specifications. Args: input_dt: Input datetime to convert to a string. Returns: String in isoformat to the millisecond enforcing that timezone offset is provided. Raises: TrestleError: Error is raised if datetime object does not contain sufficient timezone information. \"\"\" # fail if the input datetime is not aware - ie it has no associated timezone if input_dt . tzinfo is None : raise err . TrestleError ( 'Missing timezone in datetime' ) if input_dt . tzinfo . utcoffset ( input_dt ) is None : raise err . TrestleError ( 'Missing utcoffset in datetime' ) # use this leave in original timezone rather than utc # return input_dt.astimezone().isoformat(timespec='milliseconds') noqa: E800 # force it to be utc return input_dt . astimezone ( datetime . timezone . utc ) . isoformat ( timespec = 'milliseconds' ) handler: python","title":"base_model"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model","text":"Pydantic base model for use within trestle project and associated configuration. The heart of the current OSCAL model within trestle is based on pydantic ( https://pydantic-docs.helpmanual.io/ ) which itself is a veneer on-top of python data classes. Functionality here defines a base-model which all trestle oscal data models inherit from. This allows additional functionality to be easily inserted. I can write a comment in here and you can even edit on the same line.","title":"base_model"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel","text":"Trestle defined pydantic base model for use with OSCAL pydantic dataclasses. This BaseModel provides two types of functionality: 1. Overrides default configuation of the pydantic library with behaviours required for trestle 2. Provides utility functions for trestle which are specific to OSCAL and the naming schema associated with it. Source code in trestle/core/base_model.py class OscalBaseModel ( TrestleBaseModel ): \"\"\" Trestle defined pydantic base model for use with OSCAL pydantic dataclasses. This BaseModel provides two types of functionality: 1. Overrides default configuation of the pydantic library with behaviours required for trestle 2. Provides utility functions for trestle which are specific to OSCAL and the naming schema associated with it. \"\"\" class Config : \"\"\"Overriding configuration class for pydantic base model, for use with OSCAL data classes.\"\"\" json_loads = orjson . loads # TODO: json_dumps with orjson.dumps see #840 json_encoders = { datetime . datetime : lambda x : robust_datetime_serialization ( x )} allow_population_by_field_name = True # Enforce strict schema extra = Extra . forbid # Validate on assignment of variables to ensure no escapes validate_assignment = True @classmethod def create_stripped_model_type ( cls , stripped_fields : Optional [ List [ str ]] = None , stripped_fields_aliases : Optional [ List [ str ]] = None ) -> Type [ 'OscalBaseModel' ]: \"\"\"Create a pydantic model, which is derived from the current model, but missing certain fields. OSCAL mandates a 'strict' schema (e.g. unless otherwise stated no additional fields), and certain fields are mandatory. Given this the corresponding dataclasses are also strict. Workflows with trestle require missing mandatory fields. This allows creation of derivative models missing certain fields. Args: stripped_fields: The fields to be removed from the current data class. stripped_fields_aliases: The fields to be removed from the current data class provided by alias. Returns: Pydantic data class thta can be used to instanciate a model. Raises: TrestleError: If user provided both stripped_fields and stripped_field_aliases or neither. TrestleError: If incorrect aliases or field names are provided. \"\"\" if stripped_fields is not None and stripped_fields_aliases is not None : raise err . TrestleError ( 'Either \"stripped_fields\" or \"stripped_fields_aliases\" need to be passed, not both.' ) if stripped_fields is None and stripped_fields_aliases is None : raise err . TrestleError ( 'Exactly one of \"stripped_fields\" or \"stripped_fields_aliases\" must be provided' ) # create alias to field_name mapping excluded_fields = [] if stripped_fields is not None : excluded_fields = stripped_fields elif stripped_fields_aliases is not None : alias_to_field = cls . alias_to_field_map () try : excluded_fields = [ alias_to_field [ key ] . name for key in stripped_fields_aliases ] except KeyError as e : raise err . TrestleError ( f 'Field { str ( e ) } does not exist in the model' ) current_fields = cls . __fields__ new_fields_for_model = {} # Build field list for current_mfield in current_fields . values (): if current_mfield . name in excluded_fields : continue # Validate name in the field # Cehcke behaviour with an alias if current_mfield . required : new_fields_for_model [ current_mfield . name ] = ( current_mfield . outer_type_ , Field ( ... , title = current_mfield . name , alias = current_mfield . alias )) else : new_fields_for_model [ current_mfield . name ] = ( Optional [ current_mfield . outer_type_ ], Field ( None , title = current_mfield . name , alias = current_mfield . alias ) ) new_model = create_model ( cls . __name__ , __base__ = OscalBaseModel , ** new_fields_for_model ) # type: ignore # TODO: This typing cast should NOT be necessary. Potentially fixable with a fix to pydantic. Issue #175 new_model = cast ( Type [ OscalBaseModel ], new_model ) return new_model def get_field_by_alias ( self , field_alias : str ) -> Any : \"\"\"Convert field alias to a field.\"\"\" attr_field = self . alias_to_field_map () . get ( field_alias , None ) return attr_field def get_field_value_by_alias ( self , attr_alias : str ) -> Optional [ Any ]: \"\"\"Get attribute value by field alias.\"\"\" # TODO: can this be restricted beyond Any easily. attr_field = self . get_field_by_alias ( attr_alias ) if isinstance ( attr_field , ModelField ): return getattr ( self , attr_field . name , None ) return None def stripped_instance ( self , stripped_fields : List [ str ] = None , stripped_fields_aliases : List [ str ] = None ) -> 'OscalBaseModel' : \"\"\"Return a new model instance with the specified fields being stripped. Args: stripped_fields: The fields to be removed from the current data class. stripped_fields_aliases: The fields to be removed from the current data class provided by alias. Returns: The current datamodel with the fields provided removed in a derivate (run time created) data model. Raises: err.TrestleError: If user provided both stripped_fields and stripped_field_aliases or neither. err.TrestleError: If incorrect aliases or field names are provided. \"\"\" # stripped class type stripped_class : Type [ OscalBaseModel ] = self . create_stripped_model_type ( stripped_fields = stripped_fields , stripped_fields_aliases = stripped_fields_aliases ) # remaining values remaining_values = {} for field in self . __fields__ . values (): if field . name in stripped_class . __fields__ : remaining_values [ field . name ] = self . __dict__ [ field . name ] # create stripped model instance # TODO: Not sure if we can avoid type escapes here stripped_instance = stripped_class ( ** remaining_values ) # type: ignore return stripped_instance def oscal_dict ( self ) -> Dict [ str , Any ]: \"\"\"Return a dictionary including the root wrapping object key.\"\"\" class_name = self . __class__ . __name__ result = {} raw_dict = self . dict ( by_alias = True , exclude_none = True ) # Additional check to avoid root serialization if '__root__' in raw_dict . keys (): result [ classname_to_alias ( class_name , AliasMode . JSON )] = raw_dict [ '__root__' ] else : result [ classname_to_alias ( class_name , AliasMode . JSON )] = raw_dict return result def oscal_serialize_json_bytes ( self , pretty : bool = False , wrapped : bool = True ) -> bytes : \"\"\" Return an 'oscal wrapped' json object serialized in a compressed form as bytes. Args: pretty: Whether or not to pretty-print json output or have in compressed form. Returns: Oscal model serialized to a json object including packaging inside of a single top level key. \"\"\" if wrapped : odict = self . oscal_dict () else : odict = self . dict ( by_alias = True , exclude_none = True ) if pretty : return orjson . dumps ( odict , default = self . __json_encoder__ , option = orjson . OPT_INDENT_2 ) return orjson . dumps ( odict , default = self . __json_encoder__ ) def oscal_serialize_json ( self , pretty : bool = False , wrapped : bool = True ) -> str : \"\"\" Return an 'oscal wrapped' json object serialized in a compressed form as bytes. Args: pretty: Whether or not to pretty-print json output or have in compressed form. Returns: Oscal model serialized to a json object including packaging inside of a single top level key. \"\"\" # This function is provided for backwards compatibility return self . oscal_serialize_json_bytes ( pretty , wrapped ) . decode ( const . FILE_ENCODING ) def oscal_write ( self , path : pathlib . Path ) -> None : \"\"\" Write out a pydantic data model in an oscal friendly way. OSCAL schema mandates that top level elements are wrapped in a singular json/yaml field. This function handles both json and yaml output as well as formatting of the json. Args: path: The output file location for the oscal object. Raises: err.TrestleError: If a unknown file extension is provided. \"\"\" content_type = FileContentType . to_content_type ( path . suffix ) # The output will have \\r\\n newlines on windows and \\n newlines elsewhere if content_type == FileContentType . YAML : write_file = pathlib . Path ( path ) . open ( 'w' , encoding = const . FILE_ENCODING ) yaml = YAML ( typ = 'safe' ) yaml . dump ( yaml . load ( self . oscal_serialize_json ()), write_file ) write_file . flush () write_file . close () elif content_type == FileContentType . JSON : write_file = pathlib . Path ( path ) . open ( 'wb' ) write_file . write ( self . oscal_serialize_json_bytes ( pretty = True )) # Flush / close required (by experience) due to flushing issues in tests. write_file . flush () write_file . close () @classmethod def oscal_read ( cls , path : pathlib . Path ) -> Optional [ 'OscalBaseModel' ]: \"\"\" Read OSCAL objects. Handles the fact OSCAL wraps top level elements and also deals with both yaml and json. Args: path: The path of the oscal object to read. Returns: The oscal object read into trestle oscal models. \"\"\" # Create the wrapper model. alias = classname_to_alias ( cls . __name__ , AliasMode . JSON ) content_type = FileContentType . to_content_type ( path . suffix ) logger . debug ( f 'oscal_read content type { content_type } and alias { alias } from { path } ' ) if not path . exists (): logger . warning ( f 'path does not exist in oscal_read: { path } ' ) return None obj : Dict [ str , Any ] = {} try : if content_type == FileContentType . YAML : yaml = YAML ( typ = 'safe' ) fh = path . open ( 'r' , encoding = const . FILE_ENCODING ) obj = yaml . load ( fh ) fh . close () elif content_type == FileContentType . JSON : obj = load_file ( path , json_loads = cls . __config__ . json_loads , ) except Exception as e : raise err . TrestleError ( f 'Error loading file { path } { str ( e ) } ' ) try : if not len ( obj ) == 1 : raise err . TrestleError ( f 'Invalid OSCAL file structure, oscal file ' f 'does not have a single top level key wrapping it. It has { len ( obj ) } keys.' ) parsed = cls . parse_obj ( obj [ alias ]) except KeyError : raise err . TrestleError ( f 'Provided oscal file does not have top level key key: { alias } ' ) except Exception as e : raise err . TrestleError ( f 'Error parsing file { path } { str ( e ) } ' ) return parsed def copy_to ( self , new_oscal_type : Type [ 'OscalBaseModel' ]) -> 'OscalBaseModel' : \"\"\" Opportunistic copy operation between similar types of data classes. Due to the way in which oscal is constructed we get a set of similar / the same definition across various oscal models. Due to the lack of guarantees that they are the same we cannot easily 'collapse' the mode. Args: new_oscal_type: The desired type of oscal model Returns: Opportunistic copy of the data into the new model type. \"\"\" logger . debug ( 'Copy to started' ) if self . __class__ . __name__ == new_oscal_type . __name__ : logger . debug ( 'Json based copy' ) # Note: Json based oppportunistic copy # Dev notes: Do not change this from json. Due to enums (in particular) json is the closest we can get. return new_oscal_type . parse_raw ( self . oscal_serialize_json ( pretty = False , wrapped = False )) if ( '__root__' in self . __fields__ and len ( self . __fields__ ) == 1 and '__root__' in new_oscal_type . __fields__ and len ( new_oscal_type . __fields__ ) == 1 ): logger . debug ( 'Root element based copy too' ) return new_oscal_type . parse_obj ( self . __root__ ) # bad place here. raise err . TrestleError ( 'Provided inconsistent classes to copy to methodology.' ) def copy_from ( self , existing_oscal_object : 'OscalBaseModel' ) -> None : \"\"\" Copy operation that implicitly does type conversion. Typically would be used to set an attribute, however, does not need to be. Deals with two scenarios: 1) Casting across oscal models of equivalent type. The purpose if this is to cross class spaces. 2) The same as above where the item is an array style object which does not correctly serialize to a dict. 3) if the from and 'to' objects are root schema elements the copy operation will copy the root element to the value. Args: existing_oscal_object: The oscal object where fields are copied from. \"\"\" recast_object = existing_oscal_object . copy_to ( self . __class__ ) for raw_field in self . __dict__ : self . __dict__ [ raw_field ] = recast_object . __dict__ [ raw_field ] @classmethod def alias_to_field_map ( cls ) -> Dict [ str , ModelField ]: \"\"\"Create a map from field alias to field. Returns: A dict which has key's of aliases and Fields as values. \"\"\" alias_to_field : Dict [ str , ModelField ] = {} for field in cls . __fields__ . values (): alias_to_field [ field . alias ] = field return alias_to_field @classmethod def is_collection_container ( cls ) -> bool : \"\"\" Determine whether a pydantic model has being created to wrap a collection primitive (e.g a list or dict). In performing model decomposition it is possible using trestle framework to automatically generate a model which looks like class Foo(OscalBaseModel): __root__: List[Bar] Returns: Boolean on if it meets the above criteria When these cases exist we need special handling of the type information. \"\"\" # Additional sanity check on field length if len ( cls . __fields__ ) == 1 and '__root__' in cls . __fields__ : # This is now a __root__ key only model if is_collection_field_type ( cls . __fields__ [ '__root__' ] . outer_type_ ): return True return False @classmethod def get_collection_type ( cls ) -> Optional [ type ]: \"\"\" If the type wraps an collection, return the collection type. Returns: The collection type. Raises: err.TrestleError: if not a wrapper of the collection type. \"\"\" if not cls . is_collection_container (): raise err . TrestleError ( 'OscalBaseModel is not wrapping a collection type' ) return get_origin ( cls . __fields__ [ '__root__' ] . outer_type_ )","title":"OscalBaseModel"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel.Config","text":"Overriding configuration class for pydantic base model, for use with OSCAL data classes. Source code in trestle/core/base_model.py class Config : \"\"\"Overriding configuration class for pydantic base model, for use with OSCAL data classes.\"\"\" json_loads = orjson . loads # TODO: json_dumps with orjson.dumps see #840 json_encoders = { datetime . datetime : lambda x : robust_datetime_serialization ( x )} allow_population_by_field_name = True # Enforce strict schema extra = Extra . forbid # Validate on assignment of variables to ensure no escapes validate_assignment = True allow_population_by_field_name \u00a4 extra \u00a4 json_encoders \u00a4 json_loads \u00a4 validate_assignment \u00a4","title":"Config"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel.alias_to_field_map","text":"Create a map from field alias to field. Returns: Type Description Dict[str, pydantic.fields.ModelField] A dict which has key's of aliases and Fields as values. Source code in trestle/core/base_model.py @classmethod def alias_to_field_map ( cls ) -> Dict [ str , ModelField ]: \"\"\"Create a map from field alias to field. Returns: A dict which has key's of aliases and Fields as values. \"\"\" alias_to_field : Dict [ str , ModelField ] = {} for field in cls . __fields__ . values (): alias_to_field [ field . alias ] = field return alias_to_field","title":"alias_to_field_map()"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel.copy_from","text":"Copy operation that implicitly does type conversion. Typically would be used to set an attribute, however, does not need to be. Deals with two scenarios: 1) Casting across oscal models of equivalent type. The purpose if this is to cross class spaces. 2) The same as above where the item is an array style object which does not correctly serialize to a dict. 3) if the from and 'to' objects are root schema elements the copy operation will copy the root element to the value. Parameters: Name Type Description Default existing_oscal_object OscalBaseModel The oscal object where fields are copied from. required Source code in trestle/core/base_model.py def copy_from ( self , existing_oscal_object : 'OscalBaseModel' ) -> None : \"\"\" Copy operation that implicitly does type conversion. Typically would be used to set an attribute, however, does not need to be. Deals with two scenarios: 1) Casting across oscal models of equivalent type. The purpose if this is to cross class spaces. 2) The same as above where the item is an array style object which does not correctly serialize to a dict. 3) if the from and 'to' objects are root schema elements the copy operation will copy the root element to the value. Args: existing_oscal_object: The oscal object where fields are copied from. \"\"\" recast_object = existing_oscal_object . copy_to ( self . __class__ ) for raw_field in self . __dict__ : self . __dict__ [ raw_field ] = recast_object . __dict__ [ raw_field ]","title":"copy_from()"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel.copy_to","text":"Opportunistic copy operation between similar types of data classes. Due to the way in which oscal is constructed we get a set of similar / the same definition across various oscal models. Due to the lack of guarantees that they are the same we cannot easily 'collapse' the mode. Parameters: Name Type Description Default new_oscal_type Type[OscalBaseModel] The desired type of oscal model required Returns: Type Description OscalBaseModel Opportunistic copy of the data into the new model type. Source code in trestle/core/base_model.py def copy_to ( self , new_oscal_type : Type [ 'OscalBaseModel' ]) -> 'OscalBaseModel' : \"\"\" Opportunistic copy operation between similar types of data classes. Due to the way in which oscal is constructed we get a set of similar / the same definition across various oscal models. Due to the lack of guarantees that they are the same we cannot easily 'collapse' the mode. Args: new_oscal_type: The desired type of oscal model Returns: Opportunistic copy of the data into the new model type. \"\"\" logger . debug ( 'Copy to started' ) if self . __class__ . __name__ == new_oscal_type . __name__ : logger . debug ( 'Json based copy' ) # Note: Json based oppportunistic copy # Dev notes: Do not change this from json. Due to enums (in particular) json is the closest we can get. return new_oscal_type . parse_raw ( self . oscal_serialize_json ( pretty = False , wrapped = False )) if ( '__root__' in self . __fields__ and len ( self . __fields__ ) == 1 and '__root__' in new_oscal_type . __fields__ and len ( new_oscal_type . __fields__ ) == 1 ): logger . debug ( 'Root element based copy too' ) return new_oscal_type . parse_obj ( self . __root__ ) # bad place here. raise err . TrestleError ( 'Provided inconsistent classes to copy to methodology.' )","title":"copy_to()"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel.create_stripped_model_type","text":"Create a pydantic model, which is derived from the current model, but missing certain fields. OSCAL mandates a 'strict' schema (e.g. unless otherwise stated no additional fields), and certain fields are mandatory. Given this the corresponding dataclasses are also strict. Workflows with trestle require missing mandatory fields. This allows creation of derivative models missing certain fields. Parameters: Name Type Description Default stripped_fields Optional[List[str]] The fields to be removed from the current data class. None stripped_fields_aliases Optional[List[str]] The fields to be removed from the current data class provided by alias. None Returns: Type Description Type[OscalBaseModel] Pydantic data class thta can be used to instanciate a model. Exceptions: Type Description TrestleError If user provided both stripped_fields and stripped_field_aliases or neither. TrestleError If incorrect aliases or field names are provided. Source code in trestle/core/base_model.py @classmethod def create_stripped_model_type ( cls , stripped_fields : Optional [ List [ str ]] = None , stripped_fields_aliases : Optional [ List [ str ]] = None ) -> Type [ 'OscalBaseModel' ]: \"\"\"Create a pydantic model, which is derived from the current model, but missing certain fields. OSCAL mandates a 'strict' schema (e.g. unless otherwise stated no additional fields), and certain fields are mandatory. Given this the corresponding dataclasses are also strict. Workflows with trestle require missing mandatory fields. This allows creation of derivative models missing certain fields. Args: stripped_fields: The fields to be removed from the current data class. stripped_fields_aliases: The fields to be removed from the current data class provided by alias. Returns: Pydantic data class thta can be used to instanciate a model. Raises: TrestleError: If user provided both stripped_fields and stripped_field_aliases or neither. TrestleError: If incorrect aliases or field names are provided. \"\"\" if stripped_fields is not None and stripped_fields_aliases is not None : raise err . TrestleError ( 'Either \"stripped_fields\" or \"stripped_fields_aliases\" need to be passed, not both.' ) if stripped_fields is None and stripped_fields_aliases is None : raise err . TrestleError ( 'Exactly one of \"stripped_fields\" or \"stripped_fields_aliases\" must be provided' ) # create alias to field_name mapping excluded_fields = [] if stripped_fields is not None : excluded_fields = stripped_fields elif stripped_fields_aliases is not None : alias_to_field = cls . alias_to_field_map () try : excluded_fields = [ alias_to_field [ key ] . name for key in stripped_fields_aliases ] except KeyError as e : raise err . TrestleError ( f 'Field { str ( e ) } does not exist in the model' ) current_fields = cls . __fields__ new_fields_for_model = {} # Build field list for current_mfield in current_fields . values (): if current_mfield . name in excluded_fields : continue # Validate name in the field # Cehcke behaviour with an alias if current_mfield . required : new_fields_for_model [ current_mfield . name ] = ( current_mfield . outer_type_ , Field ( ... , title = current_mfield . name , alias = current_mfield . alias )) else : new_fields_for_model [ current_mfield . name ] = ( Optional [ current_mfield . outer_type_ ], Field ( None , title = current_mfield . name , alias = current_mfield . alias ) ) new_model = create_model ( cls . __name__ , __base__ = OscalBaseModel , ** new_fields_for_model ) # type: ignore # TODO: This typing cast should NOT be necessary. Potentially fixable with a fix to pydantic. Issue #175 new_model = cast ( Type [ OscalBaseModel ], new_model ) return new_model","title":"create_stripped_model_type()"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel.get_collection_type","text":"If the type wraps an collection, return the collection type. Returns: Type Description Optional[type] The collection type. Exceptions: Type Description err.TrestleError if not a wrapper of the collection type. Source code in trestle/core/base_model.py @classmethod def get_collection_type ( cls ) -> Optional [ type ]: \"\"\" If the type wraps an collection, return the collection type. Returns: The collection type. Raises: err.TrestleError: if not a wrapper of the collection type. \"\"\" if not cls . is_collection_container (): raise err . TrestleError ( 'OscalBaseModel is not wrapping a collection type' ) return get_origin ( cls . __fields__ [ '__root__' ] . outer_type_ )","title":"get_collection_type()"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel.get_field_by_alias","text":"Convert field alias to a field. Source code in trestle/core/base_model.py def get_field_by_alias ( self , field_alias : str ) -> Any : \"\"\"Convert field alias to a field.\"\"\" attr_field = self . alias_to_field_map () . get ( field_alias , None ) return attr_field","title":"get_field_by_alias()"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel.get_field_value_by_alias","text":"Get attribute value by field alias. Source code in trestle/core/base_model.py def get_field_value_by_alias ( self , attr_alias : str ) -> Optional [ Any ]: \"\"\"Get attribute value by field alias.\"\"\" # TODO: can this be restricted beyond Any easily. attr_field = self . get_field_by_alias ( attr_alias ) if isinstance ( attr_field , ModelField ): return getattr ( self , attr_field . name , None ) return None","title":"get_field_value_by_alias()"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel.is_collection_container","text":"Determine whether a pydantic model has being created to wrap a collection primitive (e.g a list or dict). In performing model decomposition it is possible using trestle framework to automatically generate a model which looks like class Foo(OscalBaseModel): root : List[Bar] Returns: Type Description bool Boolean on if it meets the above criteria When these cases exist we need special handling of the type information. Source code in trestle/core/base_model.py @classmethod def is_collection_container ( cls ) -> bool : \"\"\" Determine whether a pydantic model has being created to wrap a collection primitive (e.g a list or dict). In performing model decomposition it is possible using trestle framework to automatically generate a model which looks like class Foo(OscalBaseModel): __root__: List[Bar] Returns: Boolean on if it meets the above criteria When these cases exist we need special handling of the type information. \"\"\" # Additional sanity check on field length if len ( cls . __fields__ ) == 1 and '__root__' in cls . __fields__ : # This is now a __root__ key only model if is_collection_field_type ( cls . __fields__ [ '__root__' ] . outer_type_ ): return True return False","title":"is_collection_container()"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel.oscal_dict","text":"Return a dictionary including the root wrapping object key. Source code in trestle/core/base_model.py def oscal_dict ( self ) -> Dict [ str , Any ]: \"\"\"Return a dictionary including the root wrapping object key.\"\"\" class_name = self . __class__ . __name__ result = {} raw_dict = self . dict ( by_alias = True , exclude_none = True ) # Additional check to avoid root serialization if '__root__' in raw_dict . keys (): result [ classname_to_alias ( class_name , AliasMode . JSON )] = raw_dict [ '__root__' ] else : result [ classname_to_alias ( class_name , AliasMode . JSON )] = raw_dict return result","title":"oscal_dict()"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel.oscal_read","text":"Read OSCAL objects. Handles the fact OSCAL wraps top level elements and also deals with both yaml and json. Parameters: Name Type Description Default path Path The path of the oscal object to read. required Returns: Type Description Optional[OscalBaseModel] The oscal object read into trestle oscal models. Source code in trestle/core/base_model.py @classmethod def oscal_read ( cls , path : pathlib . Path ) -> Optional [ 'OscalBaseModel' ]: \"\"\" Read OSCAL objects. Handles the fact OSCAL wraps top level elements and also deals with both yaml and json. Args: path: The path of the oscal object to read. Returns: The oscal object read into trestle oscal models. \"\"\" # Create the wrapper model. alias = classname_to_alias ( cls . __name__ , AliasMode . JSON ) content_type = FileContentType . to_content_type ( path . suffix ) logger . debug ( f 'oscal_read content type { content_type } and alias { alias } from { path } ' ) if not path . exists (): logger . warning ( f 'path does not exist in oscal_read: { path } ' ) return None obj : Dict [ str , Any ] = {} try : if content_type == FileContentType . YAML : yaml = YAML ( typ = 'safe' ) fh = path . open ( 'r' , encoding = const . FILE_ENCODING ) obj = yaml . load ( fh ) fh . close () elif content_type == FileContentType . JSON : obj = load_file ( path , json_loads = cls . __config__ . json_loads , ) except Exception as e : raise err . TrestleError ( f 'Error loading file { path } { str ( e ) } ' ) try : if not len ( obj ) == 1 : raise err . TrestleError ( f 'Invalid OSCAL file structure, oscal file ' f 'does not have a single top level key wrapping it. It has { len ( obj ) } keys.' ) parsed = cls . parse_obj ( obj [ alias ]) except KeyError : raise err . TrestleError ( f 'Provided oscal file does not have top level key key: { alias } ' ) except Exception as e : raise err . TrestleError ( f 'Error parsing file { path } { str ( e ) } ' ) return parsed","title":"oscal_read()"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel.oscal_serialize_json","text":"Return an 'oscal wrapped' json object serialized in a compressed form as bytes. Parameters: Name Type Description Default pretty bool Whether or not to pretty-print json output or have in compressed form. False Returns: Type Description str Oscal model serialized to a json object including packaging inside of a single top level key. Source code in trestle/core/base_model.py def oscal_serialize_json ( self , pretty : bool = False , wrapped : bool = True ) -> str : \"\"\" Return an 'oscal wrapped' json object serialized in a compressed form as bytes. Args: pretty: Whether or not to pretty-print json output or have in compressed form. Returns: Oscal model serialized to a json object including packaging inside of a single top level key. \"\"\" # This function is provided for backwards compatibility return self . oscal_serialize_json_bytes ( pretty , wrapped ) . decode ( const . FILE_ENCODING )","title":"oscal_serialize_json()"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel.oscal_serialize_json_bytes","text":"Return an 'oscal wrapped' json object serialized in a compressed form as bytes. Parameters: Name Type Description Default pretty bool Whether or not to pretty-print json output or have in compressed form. False Returns: Type Description bytes Oscal model serialized to a json object including packaging inside of a single top level key. Source code in trestle/core/base_model.py def oscal_serialize_json_bytes ( self , pretty : bool = False , wrapped : bool = True ) -> bytes : \"\"\" Return an 'oscal wrapped' json object serialized in a compressed form as bytes. Args: pretty: Whether or not to pretty-print json output or have in compressed form. Returns: Oscal model serialized to a json object including packaging inside of a single top level key. \"\"\" if wrapped : odict = self . oscal_dict () else : odict = self . dict ( by_alias = True , exclude_none = True ) if pretty : return orjson . dumps ( odict , default = self . __json_encoder__ , option = orjson . OPT_INDENT_2 ) return orjson . dumps ( odict , default = self . __json_encoder__ )","title":"oscal_serialize_json_bytes()"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel.oscal_write","text":"Write out a pydantic data model in an oscal friendly way. OSCAL schema mandates that top level elements are wrapped in a singular json/yaml field. This function handles both json and yaml output as well as formatting of the json. Parameters: Name Type Description Default path Path The output file location for the oscal object. required Exceptions: Type Description err.TrestleError If a unknown file extension is provided. Source code in trestle/core/base_model.py def oscal_write ( self , path : pathlib . Path ) -> None : \"\"\" Write out a pydantic data model in an oscal friendly way. OSCAL schema mandates that top level elements are wrapped in a singular json/yaml field. This function handles both json and yaml output as well as formatting of the json. Args: path: The output file location for the oscal object. Raises: err.TrestleError: If a unknown file extension is provided. \"\"\" content_type = FileContentType . to_content_type ( path . suffix ) # The output will have \\r\\n newlines on windows and \\n newlines elsewhere if content_type == FileContentType . YAML : write_file = pathlib . Path ( path ) . open ( 'w' , encoding = const . FILE_ENCODING ) yaml = YAML ( typ = 'safe' ) yaml . dump ( yaml . load ( self . oscal_serialize_json ()), write_file ) write_file . flush () write_file . close () elif content_type == FileContentType . JSON : write_file = pathlib . Path ( path ) . open ( 'wb' ) write_file . write ( self . oscal_serialize_json_bytes ( pretty = True )) # Flush / close required (by experience) due to flushing issues in tests. write_file . flush () write_file . close ()","title":"oscal_write()"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.OscalBaseModel.stripped_instance","text":"Return a new model instance with the specified fields being stripped. Parameters: Name Type Description Default stripped_fields List[str] The fields to be removed from the current data class. None stripped_fields_aliases List[str] The fields to be removed from the current data class provided by alias. None Returns: Type Description OscalBaseModel The current datamodel with the fields provided removed in a derivate (run time created) data model. Exceptions: Type Description err.TrestleError If user provided both stripped_fields and stripped_field_aliases or neither. err.TrestleError If incorrect aliases or field names are provided. Source code in trestle/core/base_model.py def stripped_instance ( self , stripped_fields : List [ str ] = None , stripped_fields_aliases : List [ str ] = None ) -> 'OscalBaseModel' : \"\"\"Return a new model instance with the specified fields being stripped. Args: stripped_fields: The fields to be removed from the current data class. stripped_fields_aliases: The fields to be removed from the current data class provided by alias. Returns: The current datamodel with the fields provided removed in a derivate (run time created) data model. Raises: err.TrestleError: If user provided both stripped_fields and stripped_field_aliases or neither. err.TrestleError: If incorrect aliases or field names are provided. \"\"\" # stripped class type stripped_class : Type [ OscalBaseModel ] = self . create_stripped_model_type ( stripped_fields = stripped_fields , stripped_fields_aliases = stripped_fields_aliases ) # remaining values remaining_values = {} for field in self . __fields__ . values (): if field . name in stripped_class . __fields__ : remaining_values [ field . name ] = self . __dict__ [ field . name ] # create stripped model instance # TODO: Not sure if we can avoid type escapes here stripped_instance = stripped_class ( ** remaining_values ) # type: ignore return stripped_instance","title":"stripped_instance()"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model-functions","text":"","title":"Functions"},{"location":"api_reference/trestle.core.base_model/#trestle.core.base_model.robust_datetime_serialization","text":"Return a nicely formatted string for in a format compatible with OSCAL specifications. Parameters: Name Type Description Default input_dt datetime Input datetime to convert to a string. required Returns: Type Description str String in isoformat to the millisecond enforcing that timezone offset is provided. Exceptions: Type Description TrestleError Error is raised if datetime object does not contain sufficient timezone information. Source code in trestle/core/base_model.py def robust_datetime_serialization ( input_dt : datetime . datetime ) -> str : \"\"\"Return a nicely formatted string for in a format compatible with OSCAL specifications. Args: input_dt: Input datetime to convert to a string. Returns: String in isoformat to the millisecond enforcing that timezone offset is provided. Raises: TrestleError: Error is raised if datetime object does not contain sufficient timezone information. \"\"\" # fail if the input datetime is not aware - ie it has no associated timezone if input_dt . tzinfo is None : raise err . TrestleError ( 'Missing timezone in datetime' ) if input_dt . tzinfo . utcoffset ( input_dt ) is None : raise err . TrestleError ( 'Missing utcoffset in datetime' ) # use this leave in original timezone rather than utc # return input_dt.astimezone().isoformat(timespec='milliseconds') noqa: E800 # force it to be utc return input_dt . astimezone ( datetime . timezone . utc ) . isoformat ( timespec = 'milliseconds' ) handler: python","title":"robust_datetime_serialization()"},{"location":"api_reference/trestle.core.catalog_interface/","text":"trestle.core.catalog_interface \u00a4 Provide interface to catalog allowing queries and operations at control level. logger \u00a4 Classes \u00a4 CatalogInterface \u00a4 Interface to query and modify catalog contents. The catalog is contained in two separate forms: As an actual OSCAL catalog, and as a separate dict providing direct lookup of a control by id. The two representations should be converted as needed using provided routines: dict -> cat: update_catalog_controls cat -> dict: _create_control_dict In normal use the dict is created by the CatalogInterface constructor, changes are then made to controls in the dict, then the catalog controls are updated by pulling from the dict back into the catalog. This class does no direct file i/o. i/o is performed via ControlIO. Source code in trestle/core/catalog_interface.py class CatalogInterface (): \"\"\" Interface to query and modify catalog contents. The catalog is contained in two separate forms: As an actual OSCAL catalog, and as a separate dict providing direct lookup of a control by id. The two representations should be converted as needed using provided routines: dict -> cat: update_catalog_controls cat -> dict: _create_control_dict In normal use the dict is created by the CatalogInterface constructor, changes are then made to controls in the dict, then the catalog controls are updated by pulling from the dict back into the catalog. This class does no direct file i/o. i/o is performed via ControlIO. \"\"\" class ControlHandle ( TrestleBaseModel ): \"\"\"Convenience class for handling controls as members of a group. group_id: id of parent group or '' if not in a group group_title: title of the group group_class: class of the group path: path of parent groups leading to this control - without the final control_id, or [''] if in cat list control: the control itself \"\"\" group_id : str group_title : Optional [ str ] group_class : Optional [ str ] path : List [ str ] control : cat . Control def __init__ ( self , catalog : Optional [ cat . Catalog ] = None ) -> None : \"\"\"Initialize the interface with the catalog.\"\"\" self . _catalog = catalog self . _param_control_map : Dict [ str , str ] = {} self . _control_dict = self . _create_control_dict () if catalog else None self . loose_param_dict : Dict [ str , common . Parameter ] = { param . id : param for param in as_list ( catalog . params )} if catalog else {} def _add_params_to_map ( self , control : cat . Control ) -> None : # this does not need to recurse because it is called for each control in the catalog for param in as_list ( control . params ): if param . id in self . _param_control_map : logger . warning ( f 'Duplicate param id { param . id } in control { control . id } and { self . _param_control_map [ param . id ] } .' ) self . _param_control_map [ param . id ] = control . id def _add_sub_controls ( self , control_handle : ControlHandle , control_dict : Dict [ str , ControlHandle ], path : List [ str ] ) -> None : \"\"\" Get all controls contained in this control and add it to the growing dict. Add all its sub-controls to the dict recursively. The path does not change because only groups are in the path, and controls cannot contain groups. \"\"\" if control_handle . control . controls : group_id = control_handle . group_id group_title = control_handle . group_title group_class = control_handle . group_class for sub_control in control_handle . control . controls : control_handle = CatalogInterface . ControlHandle ( group_id = group_id , group_title = group_title , group_class = group_class , path = path , control = sub_control ) control_dict [ sub_control . id ] = control_handle self . _add_sub_controls ( control_handle , control_dict , path ) def _add_group_controls ( self , group : cat . Group , control_dict : Dict [ str , ControlHandle ], path : List [ str ]) -> None : if group . controls is not None : group_path = path [:] if not group_path or group_path [ - 1 ] != group . id : group_path . append ( group . id ) for control in group . controls : control_handle = CatalogInterface . ControlHandle ( group_id = group . id , group_title = group . title , group_class = group . class_ , control = control , path = group_path ) control_dict [ control . id ] = control_handle self . _add_sub_controls ( control_handle , control_dict , group_path ) if group . groups is not None : group_path = path [:] group_path . append ( group . id ) for sub_group in group . groups : new_path = group_path [:] new_path . append ( sub_group . id ) self . _add_group_controls ( sub_group , control_dict , new_path ) def _create_control_dict ( self ) -> Dict [ str , ControlHandle ]: control_dict : Dict [ str , CatalogInterface . ControlHandle ] = {} # add controls by group if self . _catalog . groups is not None : for group in self . _catalog . groups : self . _add_group_controls ( group , control_dict , []) # now add controls not in a group, if any if self . _catalog . controls is not None : group_path = [ '' ] for control in self . _catalog . controls : control_handle = CatalogInterface . ControlHandle ( group_id = '' , group_title = '' , group_class = const . MODEL_TYPE_CATALOG , control = control , path = group_path ) control_dict [ control . id ] = control_handle self . _add_sub_controls ( control_handle , control_dict , group_path ) for handle in control_dict . values (): self . _add_params_to_map ( handle . control ) return control_dict def _get_all_controls_in_list ( self , controls : List [ cat . Control ], recurse : bool ) -> List [ cat . Control ]: new_list : List [ cat . Control ] = [] for control in controls : new_list . append ( control ) if recurse and control . controls : new_list . extend ( self . _get_all_controls_in_list ( control . controls , recurse )) return new_list def _get_all_controls_in_group ( self , group : cat . Group , recurse : bool ) -> List [ cat . Control ]: \"\"\" Create a list of all controls in this group. recurse specifies to recurse within controls, but groups are always recursed \"\"\" controls : List [ cat . Control ] = [] if group . controls : controls . extend ( self . _get_all_controls_in_list ( group . controls , recurse )) for sub_group in as_list ( group . groups ): if sub_group . controls : controls . extend ( self . _get_all_controls_in_group ( sub_group , recurse )) return controls def get_sorted_controls_in_group ( self , group_id : str ) -> List [ cat . Control ]: \"\"\"Get the list of controls in a group sorted by the control sort-id.\"\"\" controls : List [ cat . Control ] = [] for control in self . get_all_controls_from_dict (): grp_id , _ , _ = self . get_group_info_by_control ( control . id ) if grp_id == group_id : controls . append ( control ) return sorted ( controls , key = lambda control : ControlIOWriter . get_sort_id ( control )) def get_dependent_control_ids ( self , control_id : str ) -> List [ str ]: \"\"\"Find all children of this control.\"\"\" children : List [ str ] = [] control = self . get_control ( control_id ) if control . controls : new_controls = self . _get_all_controls_in_list ( control . controls , True ) children . extend ([ con . id for con in new_controls ]) return children def get_control_ids ( self ) -> List [ str ]: \"\"\"Get all control ids in catalog using the dict.\"\"\" return self . _control_dict . keys () def get_control ( self , control_id : str ) -> Optional [ cat . Control ]: \"\"\"Get control from catalog with this id using the dict.\"\"\" return None if control_id not in self . _control_dict else self . _control_dict [ control_id ] . control def get_control_by_param_id ( self , param_id : str ) -> Optional [ cat . Control ]: \"\"\"Get control from catalog that has this param id using the dict.\"\"\" if param_id in self . _param_control_map : return self . get_control ( self . _param_control_map [ param_id ]) return None def get_control_id_and_status ( self , control_name : str ) -> Tuple [ str , str ]: \"\"\"Get the control id and status using the control name.\"\"\" for control in self . get_all_controls_from_dict (): if ControlIOWriter . get_label ( control ) . strip () . lower () == control_name . strip () . lower (): status = ControlIOWriter . get_prop ( control , 'status' ) return control . id , status return '' , '' def get_control_part_prose ( self , control_id : str , part_name : str ) -> str : \"\"\" Get the prose for a named part in the control. Args: control_id: id of the control part_name: name of the part Returns: Single string concatenating prose from all parts and sub-parts in control with that name. \"\"\" control = self . get_control ( control_id ) return ControlIOWriter . get_part_prose ( control , part_name ) def get_all_controls_from_catalog ( self , recurse : bool ) -> Iterator [ cat . Control ]: \"\"\" Yield all deep and individual controls from the actual catalog by group. Args: recurse: Whether to recurse within controls, but groups are always recursed Returns: iterator of the controls in the catalog Notes: This follows the actual structure of the catalog and groups \"\"\" if self . _catalog . groups : for group in self . _catalog . groups : controls = self . _get_all_controls_in_group ( group , recurse ) for control in controls : yield control if self . _catalog . controls : cat_controls = self . _get_all_controls_in_list ( self . _catalog . controls , recurse ) for control in cat_controls : yield control def get_all_controls_from_dict ( self ) -> Iterator [ cat . Control ]: \"\"\"Yield individual controls from the dict.\"\"\" return [ handle . control for handle in self . _control_dict . values ()] def get_count_of_controls_in_dict ( self ) -> int : \"\"\"Find number of controls in the dict.\"\"\" return len ( self . _control_dict . keys ()) def get_count_of_controls_in_catalog ( self , recurse : bool ) -> int : \"\"\"Get count of controls from the actual catalog.\"\"\" return len ( list ( self . get_all_controls_from_catalog ( recurse ))) def get_group_ids ( self ) -> List [ str ]: \"\"\"Get all the group id's as a list of sorted strings.\"\"\" return sorted ( filter ( lambda id : id , list ({ control . group_id for control in self . _control_dict . values ()}))) def get_all_groups_from_catalog ( self ) -> List [ cat . Group ]: \"\"\"Retrieve all groups in the catalog sorted by group_id.\"\"\" groups : List [ cat . Group ] = [] if self . _catalog . groups : for my_group in self . _catalog . groups : for res in CatalogInterface . _get_groups_from_group ( my_group ): groups . append ( res ) return sorted ( groups , key = lambda group : group . id ) def get_statement_label_if_exists ( self , control_id : str , statement_id : str ) -> Tuple [ Optional [ str ], Optional [ common . Part ]]: \"\"\"Get statement label if given.\"\"\" def does_part_exists ( part : common . Part ) -> bool : does_match = False if part . name and part . name in { 'statement' , 'item' } and part . id == statement_id : does_match = True return does_match control = self . get_control ( control_id ) if not control : return '' , None label = None found_part = None if control . parts : for part in as_list ( control . parts ): # Performance OSCAL assumption, ids are nested so recurse only if prefix if part . id and statement_id . startswith ( part . id ): part = self . find_part_with_condition ( part , does_part_exists ) if part : label = ControlIOWriter . get_label ( part ) found_part = part break return label , found_part def find_part_with_condition ( self , part : common . Part , condition : Callable ) -> Optional [ common . Part ]: \"\"\"Traverse part and find subpart that satisfies given condition.\"\"\" if condition ( part ): # Part that satisfies the condition is found. return part else : if part . parts : for subpart in part . parts : found_part = self . find_part_with_condition ( subpart , condition ) if found_part : return found_part return None def delete_withdrawn_controls ( self ) -> None : \"\"\"Delete all withdrawn controls from the catalog.\"\"\" delete_list = [] for control in self . get_all_controls_from_dict (): if ControlIOWriter . is_withdrawn ( control ): delete_list . append ( control . id ) for id_ in delete_list : self . delete_control ( id_ ) @staticmethod def _get_groups_from_group ( group : cat . Group ) -> Iterator [ cat . Group ]: yield group if group . groups : for new_group in group . groups : for res in CatalogInterface . _get_groups_from_group ( new_group ): yield res def get_group_info_by_control ( self , control_id : str ) -> Tuple [ str , str , str ]: \"\"\"Get the group_id, title, class for this control from the dict.\"\"\" return ( self . _control_dict [ control_id ] . group_id , self . _control_dict [ control_id ] . group_title , self . _control_dict [ control_id ] . group_class ) def get_control_path ( self , control_id : str ) -> List [ str ]: \"\"\"Return the path into the catalog for this control.\"\"\" return self . _control_dict [ control_id ] . path def replace_control ( self , control : cat . Control ) -> None : \"\"\"Replace the control in the control_dict after modifying it.\"\"\" self . _control_dict [ control . id ] . control = control def delete_control ( self , control_id : str ) -> None : \"\"\"Delete the control from the control_dict based on id.\"\"\" self . _control_dict . pop ( control_id , None ) def get_catalog ( self , update = True ) -> cat . Catalog : \"\"\"Safe method to get catalog after forced update from catalog dict.\"\"\" if update : self . update_catalog_controls () return self . _catalog def _update_all_controls_in_list ( self , controls : List [ cat . Control ]) -> List [ cat . Control ]: \"\"\" Given a list of controls, create fresh list pulled from the control dict. Args: controls: a list of controls in the original catalog Returns: The new list of updated controls, possibly with some missing if they have been removed from the dict \"\"\" new_list : List [ cat . Control ] = [] for control in controls : # first update the control itself by getting it from the dict control = self . get_control ( control . id ) # no warning given if control not found in dict. it is assumed to have been removed from the catalog. if control is not None : # then update any controls it contains from the dict if control . controls : control . controls = self . _update_all_controls_in_list ( control . controls ) new_list . append ( control ) return new_list def _update_all_controls_in_group ( self , group : cat . Group ) -> None : \"\"\"Given a group of controls, create fresh version pulled from the control dict.\"\"\" if group . controls : group . controls = self . _update_all_controls_in_list ( group . controls ) if group . groups : new_groups : List [ cat . Group ] = [] for sub_group in group . groups : self . _update_all_controls_in_group ( sub_group ) new_groups . append ( sub_group ) group . groups = new_groups def update_catalog_controls ( self ) -> None : \"\"\"Update the actual catalog by pulling fresh controls from the dict.\"\"\" if self . _catalog . groups : for group in self . _catalog . groups : self . _update_all_controls_in_group ( group ) if self . _catalog . controls : self . _catalog . controls = self . _update_all_controls_in_list ( self . _catalog . controls ) self . _catalog . params = list ( self . loose_param_dict . values ()) def _find_string_in_part ( self , control_id : str , part : common . Part , seek_str : str ) -> List [ str ]: hits : List [ str ] = [] if part . prose : if part . prose . find ( seek_str ) >= 0 : hits . append (( control_id , part . prose )) if part . parts : for sub_part in part . parts : hits . extend ( self . _find_string_in_part ( control_id , sub_part , seek_str )) return hits def find_string_in_control ( self , control : cat . Control , seek_str : str ) -> List [ Tuple [ str , str ]]: \"\"\"Find all instances of this string in prose of control.\"\"\" hits : List [ Tuple [ str , str ]] = [] if control . parts : for part in control . parts : hits . extend ( self . _find_string_in_part ( control . id , part , seek_str )) return hits @staticmethod def setparam_to_param ( param_id : str , set_param : prof . SetParameter ) -> common . Parameter : \"\"\" Convert setparameter to parameter. Args: param_id: the id of the parameter set_param: the set_parameter from a profile Returns: a Parameter with param_id and content from the SetParameter \"\"\" return common . Parameter ( id = param_id , values = set_param . values , select = set_param . select , label = set_param . label ) @staticmethod def _get_full_profile_param_dict ( profile : prof . Profile ) -> Dict [ str , common . Parameter ]: \"\"\"Get the full mapping of param_id to modified value for this profiles set_params.\"\"\" set_param_dict : Dict [ str , common . Parameter ] = {} if not profile . modify : return set_param_dict for set_param in as_list ( profile . modify . set_parameters ): param = CatalogInterface . setparam_to_param ( set_param . param_id , set_param ) set_param_dict [ set_param . param_id ] = param return set_param_dict @staticmethod def _get_profile_param_dict ( control : cat . Control , profile_param_dict : Dict [ str , common . Parameter ], values_only : bool ) -> Dict [ str , common . Parameter ]: \"\"\" Get the dict of params for this control including possible overrides made by the profile modifications. Args: control: The control being queried profile_param_dict: The full dict of params and modified values made by the profile Returns: mapping of param ids to their final parameter states after possible modify by the profile setparameters \"\"\" # get the mapping of param_id's to params for this control, excluding those with no value set param_dict = ControlIOReader . get_control_param_dict ( control , values_only ) for key in param_dict . keys (): if key in profile_param_dict : param_dict [ key ] = profile_param_dict [ key ] return param_dict def write_catalog_as_markdown ( self , md_path : pathlib . Path , yaml_header : dict , sections_dict : Optional [ Dict [ str , str ]], prompt_responses : bool , additional_content : bool = False , profile : Optional [ prof . Profile ] = None , overwrite_header_values : bool = False , set_parameters : bool = False , required_sections : Optional [ str ] = None , allowed_sections : Optional [ str ] = None ) -> None : \"\"\" Write out the catalog controls from dict as markdown files to the specified directory. Args: md_path: Path to directory in which to write the markdown yaml_header: Dictionary to write into the yaml header of the controls sections_dict: Optional dict mapping section short names to long prompt_responses: Whether to prompt for responses in the control markdown additional_content: Should the additional content be printed corresponding to profile adds profile: Optional profile containing the adds making up additional content overwrite_header_values: Overwrite existing values in markdown header content but add new content set_parameters: Set header values based on params in the control and in the profile required_sections: Optional string containing list of sections that should be prompted for prose allowed_sections: Optional string containing list of sections that should be included in markdown Returns: None Notes: The header should capture current values for parameters. Special handling is needed if a profile is provided, in which case the header should only have details captured in the set_params of the profile. label, select, choice, how-many should only appear if they are specified explicitly in the profile's set_parameters. \"\"\" writer = ControlIOWriter () required_section_list = required_sections . split ( ',' ) if required_sections else [] allowed_section_list = allowed_sections . split ( ',' ) if allowed_sections else [] # create the directory in which to write the control markdown files md_path . mkdir ( exist_ok = True , parents = True ) catalog_interface = CatalogInterface ( self . _catalog ) # get the list of params for this profile from its set_params # this is just from the set_params full_profile_param_dict = CatalogInterface . _get_full_profile_param_dict ( profile ) if profile else {} # write out the controls for control in catalog_interface . get_all_controls_from_catalog ( True ): # make copy of incoming yaml header new_header = copy . deepcopy ( yaml_header ) # here we do special handling of how set-parameters merge with the yaml header if set_parameters : # get all params for this control control_param_dict = ControlIOReader . get_control_param_dict ( control , False ) set_param_dict : Dict [ str , str ] = {} for param_id , param_dict in control_param_dict . items (): # if the param is in the profile set_params, load its contents first and mark as profile-values if param_id in full_profile_param_dict : # get the param from the profile set_param param = full_profile_param_dict [ param_id ] # assign its contents to the dict new_dict = ModelUtils . parameter_to_dict ( param , True ) profile_values = new_dict . get ( const . VALUES , None ) if profile_values : new_dict [ const . PROFILE_VALUES ] = profile_values new_dict . pop ( const . VALUES ) # then insert the original, incoming values as values if param_id in control_param_dict : orig_param = control_param_dict [ param_id ] orig_dict = ModelUtils . parameter_to_dict ( orig_param , True ) # pull only the values from the actual control dict # all the other elements are from the profile set_param new_dict [ const . VALUES ] = orig_dict . get ( const . VALUES , None ) else : new_dict = ModelUtils . parameter_to_dict ( param_dict , True ) new_dict . pop ( 'id' ) set_param_dict [ param_id ] = new_dict if set_param_dict : if const . SET_PARAMS_TAG not in new_header : new_header [ const . SET_PARAMS_TAG ] = {} if overwrite_header_values : # update the control params with new values for key , value in new_header [ const . SET_PARAMS_TAG ] . items (): if key in control_param_dict : set_param_dict [ key ] = value else : # update the control params with any values in yaml header not set in control # need to maintain order in the set_param_dict for key , value in new_header [ const . SET_PARAMS_TAG ] . items (): if key in control_param_dict and key not in set_param_dict : set_param_dict [ key ] = value new_header [ const . SET_PARAMS_TAG ] = set_param_dict elif const . SET_PARAMS_TAG in new_header : # need to cull any params that are not in control pop_list : List [ str ] = [] for key in new_header [ const . SET_PARAMS_TAG ] . keys (): if key not in control_param_dict : pop_list . append ( key ) for pop in pop_list : new_header [ const . SET_PARAMS_TAG ] . pop ( pop ) _ , group_title , _ = catalog_interface . get_group_info_by_control ( control . id ) # control could be in sub-group of group so build path to it group_dir = md_path control_path = catalog_interface . get_control_path ( control . id ) for sub_dir in control_path : group_dir = group_dir / sub_dir if not group_dir . exists (): group_dir . mkdir ( parents = True , exist_ok = True ) writer . write_control_for_editing ( group_dir , control , group_title , new_header , sections_dict , additional_content , prompt_responses , profile , overwrite_header_values , required_section_list , allowed_section_list ) @staticmethod def _get_group_ids_and_dirs ( md_path : pathlib . Path ) -> Dict [ str , pathlib . Path ]: \"\"\" Create a sorted map of group id to group dir that is ordered by group id. This includes '' as the root group id. \"\"\" # manually insert the top dir as group '' id_map : Dict [ str , pathlib . Path ] = { '' : md_path } for gdir in md_path . glob ( '*/' ): if gdir . is_dir (): id_map [ gdir . stem ] = gdir # rebuild the dict by inserting items in manner sorted by key sorted_id_map : Dict [ str , pathlib . Path ] = {} for key in sorted ( id_map ): sorted_id_map [ key ] = id_map [ key ] return sorted_id_map def read_catalog_from_markdown ( self , md_path : pathlib . Path , set_parameters : bool ) -> cat . Catalog : \"\"\" Read the groups and catalog controls from the given directory. This will overwrite the existing groups and controls in the catalog. \"\"\" if not self . _catalog : self . _catalog = gens . generate_sample_model ( cat . Catalog ) id_map = CatalogInterface . _get_group_ids_and_dirs ( md_path ) groups : List [ cat . Group ] = [] # read each group dir for group_id , group_dir in id_map . items (): control_list_raw = [] group_title = '' # Need to get group title from at least one control in this directory # All controls in dir should have same group title # Set group title to the first one found and warn if different non-empty title appears # Controls with empty group titles are tolerated but at least one title must be present or warning given # The special group with no name that has the catalog as parent is just a list and has no title for control_path in group_dir . glob ( '*.md' ): control , control_group_title = ControlIOReader . read_control ( control_path , set_parameters ) if control_group_title : if group_title : if control_group_title != group_title : logger . warning ( f 'Control { control . id } group title { control_group_title } differs from { group_title } ' ) else : group_title = control_group_title control_list_raw . append ( control ) control_list = sorted ( control_list_raw , key = lambda control : ControlIOWriter . get_sort_id ( control )) if group_id : if not group_title : logger . warning ( f 'No group title found in controls for group { group_id } ' ) new_group = cat . Group ( id = group_id , title = group_title ) new_group . controls = control_list groups . append ( new_group ) else : # if the list of controls has no group id it also has no title and is just the controls of the catalog self . _catalog . controls = control_list self . _catalog . groups = groups if groups else None self . _create_control_dict () return self . _catalog @staticmethod def read_catalog_imp_reqs ( md_path : pathlib . Path , avail_comps : Dict [ str , ossp . SystemComponent ]) -> List [ ossp . ImplementedRequirement ]: \"\"\"Read the full set of control implemented requirements from markdown. Args: md_path: Path to the markdown control files, with directories for each group avail_comps: Dict mapping component names to known components Returns: List of implemented requirements gathered from each control Notes: As the controls are read into the catalog the needed components are added if not already available. avail_comps provides the mapping of component name to the actual component. \"\"\" imp_req_map : Dict [ str , ossp . ImplementRequirement ] = {} for group_path in CatalogInterface . _get_group_ids_and_dirs ( md_path ) . values (): for control_file in group_path . glob ( '*.md' ): sort_id , imp_req = ControlIOReader . read_implemented_requirement ( control_file , avail_comps ) imp_req_map [ sort_id ] = imp_req return [ imp_req_map [ key ] for key in sorted ( imp_req_map . keys ())] @staticmethod def read_additional_content ( md_path : pathlib . Path , required_sections_list : List [ str ] ) -> Tuple [ List [ prof . Alter ], Dict [ str , Any ], Dict [ str , str ]]: \"\"\"Read all markdown controls and return list of alters plus control param dict and param sort map.\"\"\" alters_map : Dict [ str , prof . Alter ] = {} final_param_dict : Dict [ str , Any ] = {} param_sort_map : Dict [ str , str ] = {} for group_path in CatalogInterface . _get_group_ids_and_dirs ( md_path ) . values (): for control_file in group_path . glob ( '*.md' ): sort_id , control_alters , control_param_dict = ControlIOReader . read_new_alters_and_params ( control_file , required_sections_list ) alters_map [ sort_id ] = control_alters for param_id , param_dict in control_param_dict . items (): # if profile_values are present, overwrite values with them if const . PROFILE_VALUES in param_dict : param_dict [ const . VALUES ] = param_dict . pop ( const . PROFILE_VALUES ) final_param_dict [ param_id ] = param_dict param_sort_map [ param_id ] = sort_id new_alters : List [ prof . Alter ] = [] # fill the alters according to the control sorting order for key in sorted ( alters_map . keys ()): new_alters . extend ( alters_map [ key ]) return new_alters , final_param_dict , param_sort_map def get_sections ( self ) -> List [ str ]: \"\"\"Get the available sections by a full index of all controls.\"\"\" sections : List [ str ] = [] for control in self . _control_dict . values (): if not control . control . parts : continue for part in control . control . parts : if part . name not in sections and part . name != 'statement' : sections . append ( part . name ) return sections @staticmethod def merge_controls ( dest : cat . Control , src : cat . Control , replace_params : bool ) -> None : \"\"\" Merge the src control into dest. Args: dest: destination control into which content will be added src: source control with new content replace_params: replace the control params with the new ones \"\"\" dest . parts = src . parts if replace_params : dest . params = src . params def _find_control_in_group ( self , group_id : str ) -> Tuple [ str , ControlHandle ]: \"\"\" Find a representative control for this group and its control handle. This is a simple way to get group info (title etc.) given only group id. It is not intended for high performance loops. Use only as needed. \"\"\" for control_id , control_handle in self . _control_dict . items (): if control_handle . group_id == group_id : return control_id , control_handle raise TrestleError ( f 'No controls found for group { group_id } ' ) def merge_catalog ( self , catalog : cat . Catalog , replace_params : bool ) -> None : \"\"\" Merge the provided new catalog controls into the original catalog in this catalog interface. Args: catalog: catalog containing controls that are merged into the current catalog of the interface replace_params: replace all params in the control with the new ones Notes: This is mainly to support the reading of a catalog from markdown. It allows retention of content such as metadata and backmatter, along with labels and other parameter attributes that aren't in markdown. The list of controls and group structure is specified by the markdown structure - but this doesn't allow controls to contain controls. Group lists are specified per directory. Reading the markdown tells you groups and controls in them - and groups in groups. Controls cannot change groups. If the control was in the original json, its parts are replaced, including its parameters. Only values may be specified. If no value specified, the value is unset in json. \"\"\" cat_interface = CatalogInterface ( catalog ) for src in cat_interface . get_all_controls_from_dict (): group_id , _ , _ = cat_interface . get_group_info_by_control ( src . id ) dest = self . get_control ( src . id ) if dest : dest_group , _ , _ = self . get_group_info_by_control ( dest . id ) if dest_group != group_id : raise TrestleError ( f 'Markdown for control { src . id } has different group id.' ) CatalogInterface . merge_controls ( dest , src , replace_params ) self . replace_control ( dest ) else : # need to add the control knowing its group must already exist # get group info from an arbitrary control already present in group _ , control_handle = self . _find_control_in_group ( group_id ) # add the control and its handle to the param_dict self . _control_dict [ src . id ] = control_handle # now need to cull any controls that are not in the src catalog handled_ids = set ( cat_interface . _control_dict . keys ()) orig_ids = set ( self . _control_dict . keys ()) extra_ids = orig_ids . difference ( handled_ids ) for extra_id in extra_ids : self . _control_dict . pop ( extra_id ) self . update_catalog_controls () Classes \u00a4 ControlHandle ( TrestleBaseModel ) pydantic-model \u00a4 Convenience class for handling controls as members of a group. group_id: id of parent group or '' if not in a group group_title: title of the group group_class: class of the group path: path of parent groups leading to this control - without the final control_id, or [''] if in cat list control: the control itself Source code in trestle/core/catalog_interface.py class ControlHandle ( TrestleBaseModel ): \"\"\"Convenience class for handling controls as members of a group. group_id: id of parent group or '' if not in a group group_title: title of the group group_class: class of the group path: path of parent groups leading to this control - without the final control_id, or [''] if in cat list control: the control itself \"\"\" group_id : str group_title : Optional [ str ] group_class : Optional [ str ] path : List [ str ] control : cat . Control control : Control pydantic-field required \u00a4 group_class : str pydantic-field \u00a4 group_id : str pydantic-field required \u00a4 group_title : str pydantic-field \u00a4 path : List [ str ] pydantic-field required \u00a4 Methods \u00a4 __init__ ( self , catalog = None ) special \u00a4 Initialize the interface with the catalog. Source code in trestle/core/catalog_interface.py def __init__ ( self , catalog : Optional [ cat . Catalog ] = None ) -> None : \"\"\"Initialize the interface with the catalog.\"\"\" self . _catalog = catalog self . _param_control_map : Dict [ str , str ] = {} self . _control_dict = self . _create_control_dict () if catalog else None self . loose_param_dict : Dict [ str , common . Parameter ] = { param . id : param for param in as_list ( catalog . params )} if catalog else {} delete_control ( self , control_id ) \u00a4 Delete the control from the control_dict based on id. Source code in trestle/core/catalog_interface.py def delete_control ( self , control_id : str ) -> None : \"\"\"Delete the control from the control_dict based on id.\"\"\" self . _control_dict . pop ( control_id , None ) delete_withdrawn_controls ( self ) \u00a4 Delete all withdrawn controls from the catalog. Source code in trestle/core/catalog_interface.py def delete_withdrawn_controls ( self ) -> None : \"\"\"Delete all withdrawn controls from the catalog.\"\"\" delete_list = [] for control in self . get_all_controls_from_dict (): if ControlIOWriter . is_withdrawn ( control ): delete_list . append ( control . id ) for id_ in delete_list : self . delete_control ( id_ ) find_part_with_condition ( self , part , condition ) \u00a4 Traverse part and find subpart that satisfies given condition. Source code in trestle/core/catalog_interface.py def find_part_with_condition ( self , part : common . Part , condition : Callable ) -> Optional [ common . Part ]: \"\"\"Traverse part and find subpart that satisfies given condition.\"\"\" if condition ( part ): # Part that satisfies the condition is found. return part else : if part . parts : for subpart in part . parts : found_part = self . find_part_with_condition ( subpart , condition ) if found_part : return found_part return None find_string_in_control ( self , control , seek_str ) \u00a4 Find all instances of this string in prose of control. Source code in trestle/core/catalog_interface.py def find_string_in_control ( self , control : cat . Control , seek_str : str ) -> List [ Tuple [ str , str ]]: \"\"\"Find all instances of this string in prose of control.\"\"\" hits : List [ Tuple [ str , str ]] = [] if control . parts : for part in control . parts : hits . extend ( self . _find_string_in_part ( control . id , part , seek_str )) return hits get_all_controls_from_catalog ( self , recurse ) \u00a4 Yield all deep and individual controls from the actual catalog by group. Parameters: Name Type Description Default recurse bool Whether to recurse within controls, but groups are always recursed required Returns: Type Description Iterator[trestle.oscal.catalog.Control] iterator of the controls in the catalog Notes This follows the actual structure of the catalog and groups Source code in trestle/core/catalog_interface.py def get_all_controls_from_catalog ( self , recurse : bool ) -> Iterator [ cat . Control ]: \"\"\" Yield all deep and individual controls from the actual catalog by group. Args: recurse: Whether to recurse within controls, but groups are always recursed Returns: iterator of the controls in the catalog Notes: This follows the actual structure of the catalog and groups \"\"\" if self . _catalog . groups : for group in self . _catalog . groups : controls = self . _get_all_controls_in_group ( group , recurse ) for control in controls : yield control if self . _catalog . controls : cat_controls = self . _get_all_controls_in_list ( self . _catalog . controls , recurse ) for control in cat_controls : yield control get_all_controls_from_dict ( self ) \u00a4 Yield individual controls from the dict. Source code in trestle/core/catalog_interface.py def get_all_controls_from_dict ( self ) -> Iterator [ cat . Control ]: \"\"\"Yield individual controls from the dict.\"\"\" return [ handle . control for handle in self . _control_dict . values ()] get_all_groups_from_catalog ( self ) \u00a4 Retrieve all groups in the catalog sorted by group_id. Source code in trestle/core/catalog_interface.py def get_all_groups_from_catalog ( self ) -> List [ cat . Group ]: \"\"\"Retrieve all groups in the catalog sorted by group_id.\"\"\" groups : List [ cat . Group ] = [] if self . _catalog . groups : for my_group in self . _catalog . groups : for res in CatalogInterface . _get_groups_from_group ( my_group ): groups . append ( res ) return sorted ( groups , key = lambda group : group . id ) get_catalog ( self , update = True ) \u00a4 Safe method to get catalog after forced update from catalog dict. Source code in trestle/core/catalog_interface.py def get_catalog ( self , update = True ) -> cat . Catalog : \"\"\"Safe method to get catalog after forced update from catalog dict.\"\"\" if update : self . update_catalog_controls () return self . _catalog get_control ( self , control_id ) \u00a4 Get control from catalog with this id using the dict. Source code in trestle/core/catalog_interface.py def get_control ( self , control_id : str ) -> Optional [ cat . Control ]: \"\"\"Get control from catalog with this id using the dict.\"\"\" return None if control_id not in self . _control_dict else self . _control_dict [ control_id ] . control get_control_by_param_id ( self , param_id ) \u00a4 Get control from catalog that has this param id using the dict. Source code in trestle/core/catalog_interface.py def get_control_by_param_id ( self , param_id : str ) -> Optional [ cat . Control ]: \"\"\"Get control from catalog that has this param id using the dict.\"\"\" if param_id in self . _param_control_map : return self . get_control ( self . _param_control_map [ param_id ]) return None get_control_id_and_status ( self , control_name ) \u00a4 Get the control id and status using the control name. Source code in trestle/core/catalog_interface.py def get_control_id_and_status ( self , control_name : str ) -> Tuple [ str , str ]: \"\"\"Get the control id and status using the control name.\"\"\" for control in self . get_all_controls_from_dict (): if ControlIOWriter . get_label ( control ) . strip () . lower () == control_name . strip () . lower (): status = ControlIOWriter . get_prop ( control , 'status' ) return control . id , status return '' , '' get_control_ids ( self ) \u00a4 Get all control ids in catalog using the dict. Source code in trestle/core/catalog_interface.py def get_control_ids ( self ) -> List [ str ]: \"\"\"Get all control ids in catalog using the dict.\"\"\" return self . _control_dict . keys () get_control_part_prose ( self , control_id , part_name ) \u00a4 Get the prose for a named part in the control. Parameters: Name Type Description Default control_id str id of the control required part_name str name of the part required Returns: Type Description str Single string concatenating prose from all parts and sub-parts in control with that name. Source code in trestle/core/catalog_interface.py def get_control_part_prose ( self , control_id : str , part_name : str ) -> str : \"\"\" Get the prose for a named part in the control. Args: control_id: id of the control part_name: name of the part Returns: Single string concatenating prose from all parts and sub-parts in control with that name. \"\"\" control = self . get_control ( control_id ) return ControlIOWriter . get_part_prose ( control , part_name ) get_control_path ( self , control_id ) \u00a4 Return the path into the catalog for this control. Source code in trestle/core/catalog_interface.py def get_control_path ( self , control_id : str ) -> List [ str ]: \"\"\"Return the path into the catalog for this control.\"\"\" return self . _control_dict [ control_id ] . path get_count_of_controls_in_catalog ( self , recurse ) \u00a4 Get count of controls from the actual catalog. Source code in trestle/core/catalog_interface.py def get_count_of_controls_in_catalog ( self , recurse : bool ) -> int : \"\"\"Get count of controls from the actual catalog.\"\"\" return len ( list ( self . get_all_controls_from_catalog ( recurse ))) get_count_of_controls_in_dict ( self ) \u00a4 Find number of controls in the dict. Source code in trestle/core/catalog_interface.py def get_count_of_controls_in_dict ( self ) -> int : \"\"\"Find number of controls in the dict.\"\"\" return len ( self . _control_dict . keys ()) get_dependent_control_ids ( self , control_id ) \u00a4 Find all children of this control. Source code in trestle/core/catalog_interface.py def get_dependent_control_ids ( self , control_id : str ) -> List [ str ]: \"\"\"Find all children of this control.\"\"\" children : List [ str ] = [] control = self . get_control ( control_id ) if control . controls : new_controls = self . _get_all_controls_in_list ( control . controls , True ) children . extend ([ con . id for con in new_controls ]) return children get_group_ids ( self ) \u00a4 Get all the group id's as a list of sorted strings. Source code in trestle/core/catalog_interface.py def get_group_ids ( self ) -> List [ str ]: \"\"\"Get all the group id's as a list of sorted strings.\"\"\" return sorted ( filter ( lambda id : id , list ({ control . group_id for control in self . _control_dict . values ()}))) get_group_info_by_control ( self , control_id ) \u00a4 Get the group_id, title, class for this control from the dict. Source code in trestle/core/catalog_interface.py def get_group_info_by_control ( self , control_id : str ) -> Tuple [ str , str , str ]: \"\"\"Get the group_id, title, class for this control from the dict.\"\"\" return ( self . _control_dict [ control_id ] . group_id , self . _control_dict [ control_id ] . group_title , self . _control_dict [ control_id ] . group_class ) get_sections ( self ) \u00a4 Get the available sections by a full index of all controls. Source code in trestle/core/catalog_interface.py def get_sections ( self ) -> List [ str ]: \"\"\"Get the available sections by a full index of all controls.\"\"\" sections : List [ str ] = [] for control in self . _control_dict . values (): if not control . control . parts : continue for part in control . control . parts : if part . name not in sections and part . name != 'statement' : sections . append ( part . name ) return sections get_sorted_controls_in_group ( self , group_id ) \u00a4 Get the list of controls in a group sorted by the control sort-id. Source code in trestle/core/catalog_interface.py def get_sorted_controls_in_group ( self , group_id : str ) -> List [ cat . Control ]: \"\"\"Get the list of controls in a group sorted by the control sort-id.\"\"\" controls : List [ cat . Control ] = [] for control in self . get_all_controls_from_dict (): grp_id , _ , _ = self . get_group_info_by_control ( control . id ) if grp_id == group_id : controls . append ( control ) return sorted ( controls , key = lambda control : ControlIOWriter . get_sort_id ( control )) get_statement_label_if_exists ( self , control_id , statement_id ) \u00a4 Get statement label if given. Source code in trestle/core/catalog_interface.py def get_statement_label_if_exists ( self , control_id : str , statement_id : str ) -> Tuple [ Optional [ str ], Optional [ common . Part ]]: \"\"\"Get statement label if given.\"\"\" def does_part_exists ( part : common . Part ) -> bool : does_match = False if part . name and part . name in { 'statement' , 'item' } and part . id == statement_id : does_match = True return does_match control = self . get_control ( control_id ) if not control : return '' , None label = None found_part = None if control . parts : for part in as_list ( control . parts ): # Performance OSCAL assumption, ids are nested so recurse only if prefix if part . id and statement_id . startswith ( part . id ): part = self . find_part_with_condition ( part , does_part_exists ) if part : label = ControlIOWriter . get_label ( part ) found_part = part break return label , found_part merge_catalog ( self , catalog , replace_params ) \u00a4 Merge the provided new catalog controls into the original catalog in this catalog interface. Parameters: Name Type Description Default catalog Catalog catalog containing controls that are merged into the current catalog of the interface required replace_params bool replace all params in the control with the new ones required Notes This is mainly to support the reading of a catalog from markdown. It allows retention of content such as metadata and backmatter, along with labels and other parameter attributes that aren't in markdown. The list of controls and group structure is specified by the markdown structure - but this doesn't allow controls to contain controls. Group lists are specified per directory. Reading the markdown tells you groups and controls in them - and groups in groups. Controls cannot change groups. If the control was in the original json, its parts are replaced, including its parameters. Only values may be specified. If no value specified, the value is unset in json. Source code in trestle/core/catalog_interface.py def merge_catalog ( self , catalog : cat . Catalog , replace_params : bool ) -> None : \"\"\" Merge the provided new catalog controls into the original catalog in this catalog interface. Args: catalog: catalog containing controls that are merged into the current catalog of the interface replace_params: replace all params in the control with the new ones Notes: This is mainly to support the reading of a catalog from markdown. It allows retention of content such as metadata and backmatter, along with labels and other parameter attributes that aren't in markdown. The list of controls and group structure is specified by the markdown structure - but this doesn't allow controls to contain controls. Group lists are specified per directory. Reading the markdown tells you groups and controls in them - and groups in groups. Controls cannot change groups. If the control was in the original json, its parts are replaced, including its parameters. Only values may be specified. If no value specified, the value is unset in json. \"\"\" cat_interface = CatalogInterface ( catalog ) for src in cat_interface . get_all_controls_from_dict (): group_id , _ , _ = cat_interface . get_group_info_by_control ( src . id ) dest = self . get_control ( src . id ) if dest : dest_group , _ , _ = self . get_group_info_by_control ( dest . id ) if dest_group != group_id : raise TrestleError ( f 'Markdown for control { src . id } has different group id.' ) CatalogInterface . merge_controls ( dest , src , replace_params ) self . replace_control ( dest ) else : # need to add the control knowing its group must already exist # get group info from an arbitrary control already present in group _ , control_handle = self . _find_control_in_group ( group_id ) # add the control and its handle to the param_dict self . _control_dict [ src . id ] = control_handle # now need to cull any controls that are not in the src catalog handled_ids = set ( cat_interface . _control_dict . keys ()) orig_ids = set ( self . _control_dict . keys ()) extra_ids = orig_ids . difference ( handled_ids ) for extra_id in extra_ids : self . _control_dict . pop ( extra_id ) self . update_catalog_controls () merge_controls ( dest , src , replace_params ) staticmethod \u00a4 Merge the src control into dest. Parameters: Name Type Description Default dest Control destination control into which content will be added required src Control source control with new content required replace_params bool replace the control params with the new ones required Source code in trestle/core/catalog_interface.py @staticmethod def merge_controls ( dest : cat . Control , src : cat . Control , replace_params : bool ) -> None : \"\"\" Merge the src control into dest. Args: dest: destination control into which content will be added src: source control with new content replace_params: replace the control params with the new ones \"\"\" dest . parts = src . parts if replace_params : dest . params = src . params read_additional_content ( md_path , required_sections_list ) staticmethod \u00a4 Read all markdown controls and return list of alters plus control param dict and param sort map. Source code in trestle/core/catalog_interface.py @staticmethod def read_additional_content ( md_path : pathlib . Path , required_sections_list : List [ str ] ) -> Tuple [ List [ prof . Alter ], Dict [ str , Any ], Dict [ str , str ]]: \"\"\"Read all markdown controls and return list of alters plus control param dict and param sort map.\"\"\" alters_map : Dict [ str , prof . Alter ] = {} final_param_dict : Dict [ str , Any ] = {} param_sort_map : Dict [ str , str ] = {} for group_path in CatalogInterface . _get_group_ids_and_dirs ( md_path ) . values (): for control_file in group_path . glob ( '*.md' ): sort_id , control_alters , control_param_dict = ControlIOReader . read_new_alters_and_params ( control_file , required_sections_list ) alters_map [ sort_id ] = control_alters for param_id , param_dict in control_param_dict . items (): # if profile_values are present, overwrite values with them if const . PROFILE_VALUES in param_dict : param_dict [ const . VALUES ] = param_dict . pop ( const . PROFILE_VALUES ) final_param_dict [ param_id ] = param_dict param_sort_map [ param_id ] = sort_id new_alters : List [ prof . Alter ] = [] # fill the alters according to the control sorting order for key in sorted ( alters_map . keys ()): new_alters . extend ( alters_map [ key ]) return new_alters , final_param_dict , param_sort_map read_catalog_from_markdown ( self , md_path , set_parameters ) \u00a4 Read the groups and catalog controls from the given directory. This will overwrite the existing groups and controls in the catalog. Source code in trestle/core/catalog_interface.py def read_catalog_from_markdown ( self , md_path : pathlib . Path , set_parameters : bool ) -> cat . Catalog : \"\"\" Read the groups and catalog controls from the given directory. This will overwrite the existing groups and controls in the catalog. \"\"\" if not self . _catalog : self . _catalog = gens . generate_sample_model ( cat . Catalog ) id_map = CatalogInterface . _get_group_ids_and_dirs ( md_path ) groups : List [ cat . Group ] = [] # read each group dir for group_id , group_dir in id_map . items (): control_list_raw = [] group_title = '' # Need to get group title from at least one control in this directory # All controls in dir should have same group title # Set group title to the first one found and warn if different non-empty title appears # Controls with empty group titles are tolerated but at least one title must be present or warning given # The special group with no name that has the catalog as parent is just a list and has no title for control_path in group_dir . glob ( '*.md' ): control , control_group_title = ControlIOReader . read_control ( control_path , set_parameters ) if control_group_title : if group_title : if control_group_title != group_title : logger . warning ( f 'Control { control . id } group title { control_group_title } differs from { group_title } ' ) else : group_title = control_group_title control_list_raw . append ( control ) control_list = sorted ( control_list_raw , key = lambda control : ControlIOWriter . get_sort_id ( control )) if group_id : if not group_title : logger . warning ( f 'No group title found in controls for group { group_id } ' ) new_group = cat . Group ( id = group_id , title = group_title ) new_group . controls = control_list groups . append ( new_group ) else : # if the list of controls has no group id it also has no title and is just the controls of the catalog self . _catalog . controls = control_list self . _catalog . groups = groups if groups else None self . _create_control_dict () return self . _catalog read_catalog_imp_reqs ( md_path , avail_comps ) staticmethod \u00a4 Read the full set of control implemented requirements from markdown. Parameters: Name Type Description Default md_path Path Path to the markdown control files, with directories for each group required avail_comps Dict[str, trestle.oscal.ssp.SystemComponent] Dict mapping component names to known components required Returns: Type Description List[trestle.oscal.ssp.ImplementedRequirement] List of implemented requirements gathered from each control Notes As the controls are read into the catalog the needed components are added if not already available. avail_comps provides the mapping of component name to the actual component. Source code in trestle/core/catalog_interface.py @staticmethod def read_catalog_imp_reqs ( md_path : pathlib . Path , avail_comps : Dict [ str , ossp . SystemComponent ]) -> List [ ossp . ImplementedRequirement ]: \"\"\"Read the full set of control implemented requirements from markdown. Args: md_path: Path to the markdown control files, with directories for each group avail_comps: Dict mapping component names to known components Returns: List of implemented requirements gathered from each control Notes: As the controls are read into the catalog the needed components are added if not already available. avail_comps provides the mapping of component name to the actual component. \"\"\" imp_req_map : Dict [ str , ossp . ImplementRequirement ] = {} for group_path in CatalogInterface . _get_group_ids_and_dirs ( md_path ) . values (): for control_file in group_path . glob ( '*.md' ): sort_id , imp_req = ControlIOReader . read_implemented_requirement ( control_file , avail_comps ) imp_req_map [ sort_id ] = imp_req return [ imp_req_map [ key ] for key in sorted ( imp_req_map . keys ())] replace_control ( self , control ) \u00a4 Replace the control in the control_dict after modifying it. Source code in trestle/core/catalog_interface.py def replace_control ( self , control : cat . Control ) -> None : \"\"\"Replace the control in the control_dict after modifying it.\"\"\" self . _control_dict [ control . id ] . control = control setparam_to_param ( param_id , set_param ) staticmethod \u00a4 Convert setparameter to parameter. Parameters: Name Type Description Default param_id str the id of the parameter required set_param SetParameter the set_parameter from a profile required Returns: Type Description Parameter a Parameter with param_id and content from the SetParameter Source code in trestle/core/catalog_interface.py @staticmethod def setparam_to_param ( param_id : str , set_param : prof . SetParameter ) -> common . Parameter : \"\"\" Convert setparameter to parameter. Args: param_id: the id of the parameter set_param: the set_parameter from a profile Returns: a Parameter with param_id and content from the SetParameter \"\"\" return common . Parameter ( id = param_id , values = set_param . values , select = set_param . select , label = set_param . label ) update_catalog_controls ( self ) \u00a4 Update the actual catalog by pulling fresh controls from the dict. Source code in trestle/core/catalog_interface.py def update_catalog_controls ( self ) -> None : \"\"\"Update the actual catalog by pulling fresh controls from the dict.\"\"\" if self . _catalog . groups : for group in self . _catalog . groups : self . _update_all_controls_in_group ( group ) if self . _catalog . controls : self . _catalog . controls = self . _update_all_controls_in_list ( self . _catalog . controls ) self . _catalog . params = list ( self . loose_param_dict . values ()) write_catalog_as_markdown ( self , md_path , yaml_header , sections_dict , prompt_responses , additional_content = False , profile = None , overwrite_header_values = False , set_parameters = False , required_sections = None , allowed_sections = None ) \u00a4 Write out the catalog controls from dict as markdown files to the specified directory. Parameters: Name Type Description Default md_path Path Path to directory in which to write the markdown required yaml_header dict Dictionary to write into the yaml header of the controls required sections_dict Optional[Dict[str, str]] Optional dict mapping section short names to long required prompt_responses bool Whether to prompt for responses in the control markdown required additional_content bool Should the additional content be printed corresponding to profile adds False profile Optional[trestle.oscal.profile.Profile] Optional profile containing the adds making up additional content None overwrite_header_values bool Overwrite existing values in markdown header content but add new content False set_parameters bool Set header values based on params in the control and in the profile False required_sections Optional[str] Optional string containing list of sections that should be prompted for prose None allowed_sections Optional[str] Optional string containing list of sections that should be included in markdown None Returns: Type Description None None Notes The header should capture current values for parameters. Special handling is needed if a profile is provided, in which case the header should only have details captured in the set_params of the profile. label, select, choice, how-many should only appear if they are specified explicitly in the profile's set_parameters. Source code in trestle/core/catalog_interface.py def write_catalog_as_markdown ( self , md_path : pathlib . Path , yaml_header : dict , sections_dict : Optional [ Dict [ str , str ]], prompt_responses : bool , additional_content : bool = False , profile : Optional [ prof . Profile ] = None , overwrite_header_values : bool = False , set_parameters : bool = False , required_sections : Optional [ str ] = None , allowed_sections : Optional [ str ] = None ) -> None : \"\"\" Write out the catalog controls from dict as markdown files to the specified directory. Args: md_path: Path to directory in which to write the markdown yaml_header: Dictionary to write into the yaml header of the controls sections_dict: Optional dict mapping section short names to long prompt_responses: Whether to prompt for responses in the control markdown additional_content: Should the additional content be printed corresponding to profile adds profile: Optional profile containing the adds making up additional content overwrite_header_values: Overwrite existing values in markdown header content but add new content set_parameters: Set header values based on params in the control and in the profile required_sections: Optional string containing list of sections that should be prompted for prose allowed_sections: Optional string containing list of sections that should be included in markdown Returns: None Notes: The header should capture current values for parameters. Special handling is needed if a profile is provided, in which case the header should only have details captured in the set_params of the profile. label, select, choice, how-many should only appear if they are specified explicitly in the profile's set_parameters. \"\"\" writer = ControlIOWriter () required_section_list = required_sections . split ( ',' ) if required_sections else [] allowed_section_list = allowed_sections . split ( ',' ) if allowed_sections else [] # create the directory in which to write the control markdown files md_path . mkdir ( exist_ok = True , parents = True ) catalog_interface = CatalogInterface ( self . _catalog ) # get the list of params for this profile from its set_params # this is just from the set_params full_profile_param_dict = CatalogInterface . _get_full_profile_param_dict ( profile ) if profile else {} # write out the controls for control in catalog_interface . get_all_controls_from_catalog ( True ): # make copy of incoming yaml header new_header = copy . deepcopy ( yaml_header ) # here we do special handling of how set-parameters merge with the yaml header if set_parameters : # get all params for this control control_param_dict = ControlIOReader . get_control_param_dict ( control , False ) set_param_dict : Dict [ str , str ] = {} for param_id , param_dict in control_param_dict . items (): # if the param is in the profile set_params, load its contents first and mark as profile-values if param_id in full_profile_param_dict : # get the param from the profile set_param param = full_profile_param_dict [ param_id ] # assign its contents to the dict new_dict = ModelUtils . parameter_to_dict ( param , True ) profile_values = new_dict . get ( const . VALUES , None ) if profile_values : new_dict [ const . PROFILE_VALUES ] = profile_values new_dict . pop ( const . VALUES ) # then insert the original, incoming values as values if param_id in control_param_dict : orig_param = control_param_dict [ param_id ] orig_dict = ModelUtils . parameter_to_dict ( orig_param , True ) # pull only the values from the actual control dict # all the other elements are from the profile set_param new_dict [ const . VALUES ] = orig_dict . get ( const . VALUES , None ) else : new_dict = ModelUtils . parameter_to_dict ( param_dict , True ) new_dict . pop ( 'id' ) set_param_dict [ param_id ] = new_dict if set_param_dict : if const . SET_PARAMS_TAG not in new_header : new_header [ const . SET_PARAMS_TAG ] = {} if overwrite_header_values : # update the control params with new values for key , value in new_header [ const . SET_PARAMS_TAG ] . items (): if key in control_param_dict : set_param_dict [ key ] = value else : # update the control params with any values in yaml header not set in control # need to maintain order in the set_param_dict for key , value in new_header [ const . SET_PARAMS_TAG ] . items (): if key in control_param_dict and key not in set_param_dict : set_param_dict [ key ] = value new_header [ const . SET_PARAMS_TAG ] = set_param_dict elif const . SET_PARAMS_TAG in new_header : # need to cull any params that are not in control pop_list : List [ str ] = [] for key in new_header [ const . SET_PARAMS_TAG ] . keys (): if key not in control_param_dict : pop_list . append ( key ) for pop in pop_list : new_header [ const . SET_PARAMS_TAG ] . pop ( pop ) _ , group_title , _ = catalog_interface . get_group_info_by_control ( control . id ) # control could be in sub-group of group so build path to it group_dir = md_path control_path = catalog_interface . get_control_path ( control . id ) for sub_dir in control_path : group_dir = group_dir / sub_dir if not group_dir . exists (): group_dir . mkdir ( parents = True , exist_ok = True ) writer . write_control_for_editing ( group_dir , control , group_title , new_header , sections_dict , additional_content , prompt_responses , profile , overwrite_header_values , required_section_list , allowed_section_list ) handler: python","title":"catalog_interface"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface","text":"Provide interface to catalog allowing queries and operations at control level.","title":"catalog_interface"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface","text":"Interface to query and modify catalog contents. The catalog is contained in two separate forms: As an actual OSCAL catalog, and as a separate dict providing direct lookup of a control by id. The two representations should be converted as needed using provided routines: dict -> cat: update_catalog_controls cat -> dict: _create_control_dict In normal use the dict is created by the CatalogInterface constructor, changes are then made to controls in the dict, then the catalog controls are updated by pulling from the dict back into the catalog. This class does no direct file i/o. i/o is performed via ControlIO. Source code in trestle/core/catalog_interface.py class CatalogInterface (): \"\"\" Interface to query and modify catalog contents. The catalog is contained in two separate forms: As an actual OSCAL catalog, and as a separate dict providing direct lookup of a control by id. The two representations should be converted as needed using provided routines: dict -> cat: update_catalog_controls cat -> dict: _create_control_dict In normal use the dict is created by the CatalogInterface constructor, changes are then made to controls in the dict, then the catalog controls are updated by pulling from the dict back into the catalog. This class does no direct file i/o. i/o is performed via ControlIO. \"\"\" class ControlHandle ( TrestleBaseModel ): \"\"\"Convenience class for handling controls as members of a group. group_id: id of parent group or '' if not in a group group_title: title of the group group_class: class of the group path: path of parent groups leading to this control - without the final control_id, or [''] if in cat list control: the control itself \"\"\" group_id : str group_title : Optional [ str ] group_class : Optional [ str ] path : List [ str ] control : cat . Control def __init__ ( self , catalog : Optional [ cat . Catalog ] = None ) -> None : \"\"\"Initialize the interface with the catalog.\"\"\" self . _catalog = catalog self . _param_control_map : Dict [ str , str ] = {} self . _control_dict = self . _create_control_dict () if catalog else None self . loose_param_dict : Dict [ str , common . Parameter ] = { param . id : param for param in as_list ( catalog . params )} if catalog else {} def _add_params_to_map ( self , control : cat . Control ) -> None : # this does not need to recurse because it is called for each control in the catalog for param in as_list ( control . params ): if param . id in self . _param_control_map : logger . warning ( f 'Duplicate param id { param . id } in control { control . id } and { self . _param_control_map [ param . id ] } .' ) self . _param_control_map [ param . id ] = control . id def _add_sub_controls ( self , control_handle : ControlHandle , control_dict : Dict [ str , ControlHandle ], path : List [ str ] ) -> None : \"\"\" Get all controls contained in this control and add it to the growing dict. Add all its sub-controls to the dict recursively. The path does not change because only groups are in the path, and controls cannot contain groups. \"\"\" if control_handle . control . controls : group_id = control_handle . group_id group_title = control_handle . group_title group_class = control_handle . group_class for sub_control in control_handle . control . controls : control_handle = CatalogInterface . ControlHandle ( group_id = group_id , group_title = group_title , group_class = group_class , path = path , control = sub_control ) control_dict [ sub_control . id ] = control_handle self . _add_sub_controls ( control_handle , control_dict , path ) def _add_group_controls ( self , group : cat . Group , control_dict : Dict [ str , ControlHandle ], path : List [ str ]) -> None : if group . controls is not None : group_path = path [:] if not group_path or group_path [ - 1 ] != group . id : group_path . append ( group . id ) for control in group . controls : control_handle = CatalogInterface . ControlHandle ( group_id = group . id , group_title = group . title , group_class = group . class_ , control = control , path = group_path ) control_dict [ control . id ] = control_handle self . _add_sub_controls ( control_handle , control_dict , group_path ) if group . groups is not None : group_path = path [:] group_path . append ( group . id ) for sub_group in group . groups : new_path = group_path [:] new_path . append ( sub_group . id ) self . _add_group_controls ( sub_group , control_dict , new_path ) def _create_control_dict ( self ) -> Dict [ str , ControlHandle ]: control_dict : Dict [ str , CatalogInterface . ControlHandle ] = {} # add controls by group if self . _catalog . groups is not None : for group in self . _catalog . groups : self . _add_group_controls ( group , control_dict , []) # now add controls not in a group, if any if self . _catalog . controls is not None : group_path = [ '' ] for control in self . _catalog . controls : control_handle = CatalogInterface . ControlHandle ( group_id = '' , group_title = '' , group_class = const . MODEL_TYPE_CATALOG , control = control , path = group_path ) control_dict [ control . id ] = control_handle self . _add_sub_controls ( control_handle , control_dict , group_path ) for handle in control_dict . values (): self . _add_params_to_map ( handle . control ) return control_dict def _get_all_controls_in_list ( self , controls : List [ cat . Control ], recurse : bool ) -> List [ cat . Control ]: new_list : List [ cat . Control ] = [] for control in controls : new_list . append ( control ) if recurse and control . controls : new_list . extend ( self . _get_all_controls_in_list ( control . controls , recurse )) return new_list def _get_all_controls_in_group ( self , group : cat . Group , recurse : bool ) -> List [ cat . Control ]: \"\"\" Create a list of all controls in this group. recurse specifies to recurse within controls, but groups are always recursed \"\"\" controls : List [ cat . Control ] = [] if group . controls : controls . extend ( self . _get_all_controls_in_list ( group . controls , recurse )) for sub_group in as_list ( group . groups ): if sub_group . controls : controls . extend ( self . _get_all_controls_in_group ( sub_group , recurse )) return controls def get_sorted_controls_in_group ( self , group_id : str ) -> List [ cat . Control ]: \"\"\"Get the list of controls in a group sorted by the control sort-id.\"\"\" controls : List [ cat . Control ] = [] for control in self . get_all_controls_from_dict (): grp_id , _ , _ = self . get_group_info_by_control ( control . id ) if grp_id == group_id : controls . append ( control ) return sorted ( controls , key = lambda control : ControlIOWriter . get_sort_id ( control )) def get_dependent_control_ids ( self , control_id : str ) -> List [ str ]: \"\"\"Find all children of this control.\"\"\" children : List [ str ] = [] control = self . get_control ( control_id ) if control . controls : new_controls = self . _get_all_controls_in_list ( control . controls , True ) children . extend ([ con . id for con in new_controls ]) return children def get_control_ids ( self ) -> List [ str ]: \"\"\"Get all control ids in catalog using the dict.\"\"\" return self . _control_dict . keys () def get_control ( self , control_id : str ) -> Optional [ cat . Control ]: \"\"\"Get control from catalog with this id using the dict.\"\"\" return None if control_id not in self . _control_dict else self . _control_dict [ control_id ] . control def get_control_by_param_id ( self , param_id : str ) -> Optional [ cat . Control ]: \"\"\"Get control from catalog that has this param id using the dict.\"\"\" if param_id in self . _param_control_map : return self . get_control ( self . _param_control_map [ param_id ]) return None def get_control_id_and_status ( self , control_name : str ) -> Tuple [ str , str ]: \"\"\"Get the control id and status using the control name.\"\"\" for control in self . get_all_controls_from_dict (): if ControlIOWriter . get_label ( control ) . strip () . lower () == control_name . strip () . lower (): status = ControlIOWriter . get_prop ( control , 'status' ) return control . id , status return '' , '' def get_control_part_prose ( self , control_id : str , part_name : str ) -> str : \"\"\" Get the prose for a named part in the control. Args: control_id: id of the control part_name: name of the part Returns: Single string concatenating prose from all parts and sub-parts in control with that name. \"\"\" control = self . get_control ( control_id ) return ControlIOWriter . get_part_prose ( control , part_name ) def get_all_controls_from_catalog ( self , recurse : bool ) -> Iterator [ cat . Control ]: \"\"\" Yield all deep and individual controls from the actual catalog by group. Args: recurse: Whether to recurse within controls, but groups are always recursed Returns: iterator of the controls in the catalog Notes: This follows the actual structure of the catalog and groups \"\"\" if self . _catalog . groups : for group in self . _catalog . groups : controls = self . _get_all_controls_in_group ( group , recurse ) for control in controls : yield control if self . _catalog . controls : cat_controls = self . _get_all_controls_in_list ( self . _catalog . controls , recurse ) for control in cat_controls : yield control def get_all_controls_from_dict ( self ) -> Iterator [ cat . Control ]: \"\"\"Yield individual controls from the dict.\"\"\" return [ handle . control for handle in self . _control_dict . values ()] def get_count_of_controls_in_dict ( self ) -> int : \"\"\"Find number of controls in the dict.\"\"\" return len ( self . _control_dict . keys ()) def get_count_of_controls_in_catalog ( self , recurse : bool ) -> int : \"\"\"Get count of controls from the actual catalog.\"\"\" return len ( list ( self . get_all_controls_from_catalog ( recurse ))) def get_group_ids ( self ) -> List [ str ]: \"\"\"Get all the group id's as a list of sorted strings.\"\"\" return sorted ( filter ( lambda id : id , list ({ control . group_id for control in self . _control_dict . values ()}))) def get_all_groups_from_catalog ( self ) -> List [ cat . Group ]: \"\"\"Retrieve all groups in the catalog sorted by group_id.\"\"\" groups : List [ cat . Group ] = [] if self . _catalog . groups : for my_group in self . _catalog . groups : for res in CatalogInterface . _get_groups_from_group ( my_group ): groups . append ( res ) return sorted ( groups , key = lambda group : group . id ) def get_statement_label_if_exists ( self , control_id : str , statement_id : str ) -> Tuple [ Optional [ str ], Optional [ common . Part ]]: \"\"\"Get statement label if given.\"\"\" def does_part_exists ( part : common . Part ) -> bool : does_match = False if part . name and part . name in { 'statement' , 'item' } and part . id == statement_id : does_match = True return does_match control = self . get_control ( control_id ) if not control : return '' , None label = None found_part = None if control . parts : for part in as_list ( control . parts ): # Performance OSCAL assumption, ids are nested so recurse only if prefix if part . id and statement_id . startswith ( part . id ): part = self . find_part_with_condition ( part , does_part_exists ) if part : label = ControlIOWriter . get_label ( part ) found_part = part break return label , found_part def find_part_with_condition ( self , part : common . Part , condition : Callable ) -> Optional [ common . Part ]: \"\"\"Traverse part and find subpart that satisfies given condition.\"\"\" if condition ( part ): # Part that satisfies the condition is found. return part else : if part . parts : for subpart in part . parts : found_part = self . find_part_with_condition ( subpart , condition ) if found_part : return found_part return None def delete_withdrawn_controls ( self ) -> None : \"\"\"Delete all withdrawn controls from the catalog.\"\"\" delete_list = [] for control in self . get_all_controls_from_dict (): if ControlIOWriter . is_withdrawn ( control ): delete_list . append ( control . id ) for id_ in delete_list : self . delete_control ( id_ ) @staticmethod def _get_groups_from_group ( group : cat . Group ) -> Iterator [ cat . Group ]: yield group if group . groups : for new_group in group . groups : for res in CatalogInterface . _get_groups_from_group ( new_group ): yield res def get_group_info_by_control ( self , control_id : str ) -> Tuple [ str , str , str ]: \"\"\"Get the group_id, title, class for this control from the dict.\"\"\" return ( self . _control_dict [ control_id ] . group_id , self . _control_dict [ control_id ] . group_title , self . _control_dict [ control_id ] . group_class ) def get_control_path ( self , control_id : str ) -> List [ str ]: \"\"\"Return the path into the catalog for this control.\"\"\" return self . _control_dict [ control_id ] . path def replace_control ( self , control : cat . Control ) -> None : \"\"\"Replace the control in the control_dict after modifying it.\"\"\" self . _control_dict [ control . id ] . control = control def delete_control ( self , control_id : str ) -> None : \"\"\"Delete the control from the control_dict based on id.\"\"\" self . _control_dict . pop ( control_id , None ) def get_catalog ( self , update = True ) -> cat . Catalog : \"\"\"Safe method to get catalog after forced update from catalog dict.\"\"\" if update : self . update_catalog_controls () return self . _catalog def _update_all_controls_in_list ( self , controls : List [ cat . Control ]) -> List [ cat . Control ]: \"\"\" Given a list of controls, create fresh list pulled from the control dict. Args: controls: a list of controls in the original catalog Returns: The new list of updated controls, possibly with some missing if they have been removed from the dict \"\"\" new_list : List [ cat . Control ] = [] for control in controls : # first update the control itself by getting it from the dict control = self . get_control ( control . id ) # no warning given if control not found in dict. it is assumed to have been removed from the catalog. if control is not None : # then update any controls it contains from the dict if control . controls : control . controls = self . _update_all_controls_in_list ( control . controls ) new_list . append ( control ) return new_list def _update_all_controls_in_group ( self , group : cat . Group ) -> None : \"\"\"Given a group of controls, create fresh version pulled from the control dict.\"\"\" if group . controls : group . controls = self . _update_all_controls_in_list ( group . controls ) if group . groups : new_groups : List [ cat . Group ] = [] for sub_group in group . groups : self . _update_all_controls_in_group ( sub_group ) new_groups . append ( sub_group ) group . groups = new_groups def update_catalog_controls ( self ) -> None : \"\"\"Update the actual catalog by pulling fresh controls from the dict.\"\"\" if self . _catalog . groups : for group in self . _catalog . groups : self . _update_all_controls_in_group ( group ) if self . _catalog . controls : self . _catalog . controls = self . _update_all_controls_in_list ( self . _catalog . controls ) self . _catalog . params = list ( self . loose_param_dict . values ()) def _find_string_in_part ( self , control_id : str , part : common . Part , seek_str : str ) -> List [ str ]: hits : List [ str ] = [] if part . prose : if part . prose . find ( seek_str ) >= 0 : hits . append (( control_id , part . prose )) if part . parts : for sub_part in part . parts : hits . extend ( self . _find_string_in_part ( control_id , sub_part , seek_str )) return hits def find_string_in_control ( self , control : cat . Control , seek_str : str ) -> List [ Tuple [ str , str ]]: \"\"\"Find all instances of this string in prose of control.\"\"\" hits : List [ Tuple [ str , str ]] = [] if control . parts : for part in control . parts : hits . extend ( self . _find_string_in_part ( control . id , part , seek_str )) return hits @staticmethod def setparam_to_param ( param_id : str , set_param : prof . SetParameter ) -> common . Parameter : \"\"\" Convert setparameter to parameter. Args: param_id: the id of the parameter set_param: the set_parameter from a profile Returns: a Parameter with param_id and content from the SetParameter \"\"\" return common . Parameter ( id = param_id , values = set_param . values , select = set_param . select , label = set_param . label ) @staticmethod def _get_full_profile_param_dict ( profile : prof . Profile ) -> Dict [ str , common . Parameter ]: \"\"\"Get the full mapping of param_id to modified value for this profiles set_params.\"\"\" set_param_dict : Dict [ str , common . Parameter ] = {} if not profile . modify : return set_param_dict for set_param in as_list ( profile . modify . set_parameters ): param = CatalogInterface . setparam_to_param ( set_param . param_id , set_param ) set_param_dict [ set_param . param_id ] = param return set_param_dict @staticmethod def _get_profile_param_dict ( control : cat . Control , profile_param_dict : Dict [ str , common . Parameter ], values_only : bool ) -> Dict [ str , common . Parameter ]: \"\"\" Get the dict of params for this control including possible overrides made by the profile modifications. Args: control: The control being queried profile_param_dict: The full dict of params and modified values made by the profile Returns: mapping of param ids to their final parameter states after possible modify by the profile setparameters \"\"\" # get the mapping of param_id's to params for this control, excluding those with no value set param_dict = ControlIOReader . get_control_param_dict ( control , values_only ) for key in param_dict . keys (): if key in profile_param_dict : param_dict [ key ] = profile_param_dict [ key ] return param_dict def write_catalog_as_markdown ( self , md_path : pathlib . Path , yaml_header : dict , sections_dict : Optional [ Dict [ str , str ]], prompt_responses : bool , additional_content : bool = False , profile : Optional [ prof . Profile ] = None , overwrite_header_values : bool = False , set_parameters : bool = False , required_sections : Optional [ str ] = None , allowed_sections : Optional [ str ] = None ) -> None : \"\"\" Write out the catalog controls from dict as markdown files to the specified directory. Args: md_path: Path to directory in which to write the markdown yaml_header: Dictionary to write into the yaml header of the controls sections_dict: Optional dict mapping section short names to long prompt_responses: Whether to prompt for responses in the control markdown additional_content: Should the additional content be printed corresponding to profile adds profile: Optional profile containing the adds making up additional content overwrite_header_values: Overwrite existing values in markdown header content but add new content set_parameters: Set header values based on params in the control and in the profile required_sections: Optional string containing list of sections that should be prompted for prose allowed_sections: Optional string containing list of sections that should be included in markdown Returns: None Notes: The header should capture current values for parameters. Special handling is needed if a profile is provided, in which case the header should only have details captured in the set_params of the profile. label, select, choice, how-many should only appear if they are specified explicitly in the profile's set_parameters. \"\"\" writer = ControlIOWriter () required_section_list = required_sections . split ( ',' ) if required_sections else [] allowed_section_list = allowed_sections . split ( ',' ) if allowed_sections else [] # create the directory in which to write the control markdown files md_path . mkdir ( exist_ok = True , parents = True ) catalog_interface = CatalogInterface ( self . _catalog ) # get the list of params for this profile from its set_params # this is just from the set_params full_profile_param_dict = CatalogInterface . _get_full_profile_param_dict ( profile ) if profile else {} # write out the controls for control in catalog_interface . get_all_controls_from_catalog ( True ): # make copy of incoming yaml header new_header = copy . deepcopy ( yaml_header ) # here we do special handling of how set-parameters merge with the yaml header if set_parameters : # get all params for this control control_param_dict = ControlIOReader . get_control_param_dict ( control , False ) set_param_dict : Dict [ str , str ] = {} for param_id , param_dict in control_param_dict . items (): # if the param is in the profile set_params, load its contents first and mark as profile-values if param_id in full_profile_param_dict : # get the param from the profile set_param param = full_profile_param_dict [ param_id ] # assign its contents to the dict new_dict = ModelUtils . parameter_to_dict ( param , True ) profile_values = new_dict . get ( const . VALUES , None ) if profile_values : new_dict [ const . PROFILE_VALUES ] = profile_values new_dict . pop ( const . VALUES ) # then insert the original, incoming values as values if param_id in control_param_dict : orig_param = control_param_dict [ param_id ] orig_dict = ModelUtils . parameter_to_dict ( orig_param , True ) # pull only the values from the actual control dict # all the other elements are from the profile set_param new_dict [ const . VALUES ] = orig_dict . get ( const . VALUES , None ) else : new_dict = ModelUtils . parameter_to_dict ( param_dict , True ) new_dict . pop ( 'id' ) set_param_dict [ param_id ] = new_dict if set_param_dict : if const . SET_PARAMS_TAG not in new_header : new_header [ const . SET_PARAMS_TAG ] = {} if overwrite_header_values : # update the control params with new values for key , value in new_header [ const . SET_PARAMS_TAG ] . items (): if key in control_param_dict : set_param_dict [ key ] = value else : # update the control params with any values in yaml header not set in control # need to maintain order in the set_param_dict for key , value in new_header [ const . SET_PARAMS_TAG ] . items (): if key in control_param_dict and key not in set_param_dict : set_param_dict [ key ] = value new_header [ const . SET_PARAMS_TAG ] = set_param_dict elif const . SET_PARAMS_TAG in new_header : # need to cull any params that are not in control pop_list : List [ str ] = [] for key in new_header [ const . SET_PARAMS_TAG ] . keys (): if key not in control_param_dict : pop_list . append ( key ) for pop in pop_list : new_header [ const . SET_PARAMS_TAG ] . pop ( pop ) _ , group_title , _ = catalog_interface . get_group_info_by_control ( control . id ) # control could be in sub-group of group so build path to it group_dir = md_path control_path = catalog_interface . get_control_path ( control . id ) for sub_dir in control_path : group_dir = group_dir / sub_dir if not group_dir . exists (): group_dir . mkdir ( parents = True , exist_ok = True ) writer . write_control_for_editing ( group_dir , control , group_title , new_header , sections_dict , additional_content , prompt_responses , profile , overwrite_header_values , required_section_list , allowed_section_list ) @staticmethod def _get_group_ids_and_dirs ( md_path : pathlib . Path ) -> Dict [ str , pathlib . Path ]: \"\"\" Create a sorted map of group id to group dir that is ordered by group id. This includes '' as the root group id. \"\"\" # manually insert the top dir as group '' id_map : Dict [ str , pathlib . Path ] = { '' : md_path } for gdir in md_path . glob ( '*/' ): if gdir . is_dir (): id_map [ gdir . stem ] = gdir # rebuild the dict by inserting items in manner sorted by key sorted_id_map : Dict [ str , pathlib . Path ] = {} for key in sorted ( id_map ): sorted_id_map [ key ] = id_map [ key ] return sorted_id_map def read_catalog_from_markdown ( self , md_path : pathlib . Path , set_parameters : bool ) -> cat . Catalog : \"\"\" Read the groups and catalog controls from the given directory. This will overwrite the existing groups and controls in the catalog. \"\"\" if not self . _catalog : self . _catalog = gens . generate_sample_model ( cat . Catalog ) id_map = CatalogInterface . _get_group_ids_and_dirs ( md_path ) groups : List [ cat . Group ] = [] # read each group dir for group_id , group_dir in id_map . items (): control_list_raw = [] group_title = '' # Need to get group title from at least one control in this directory # All controls in dir should have same group title # Set group title to the first one found and warn if different non-empty title appears # Controls with empty group titles are tolerated but at least one title must be present or warning given # The special group with no name that has the catalog as parent is just a list and has no title for control_path in group_dir . glob ( '*.md' ): control , control_group_title = ControlIOReader . read_control ( control_path , set_parameters ) if control_group_title : if group_title : if control_group_title != group_title : logger . warning ( f 'Control { control . id } group title { control_group_title } differs from { group_title } ' ) else : group_title = control_group_title control_list_raw . append ( control ) control_list = sorted ( control_list_raw , key = lambda control : ControlIOWriter . get_sort_id ( control )) if group_id : if not group_title : logger . warning ( f 'No group title found in controls for group { group_id } ' ) new_group = cat . Group ( id = group_id , title = group_title ) new_group . controls = control_list groups . append ( new_group ) else : # if the list of controls has no group id it also has no title and is just the controls of the catalog self . _catalog . controls = control_list self . _catalog . groups = groups if groups else None self . _create_control_dict () return self . _catalog @staticmethod def read_catalog_imp_reqs ( md_path : pathlib . Path , avail_comps : Dict [ str , ossp . SystemComponent ]) -> List [ ossp . ImplementedRequirement ]: \"\"\"Read the full set of control implemented requirements from markdown. Args: md_path: Path to the markdown control files, with directories for each group avail_comps: Dict mapping component names to known components Returns: List of implemented requirements gathered from each control Notes: As the controls are read into the catalog the needed components are added if not already available. avail_comps provides the mapping of component name to the actual component. \"\"\" imp_req_map : Dict [ str , ossp . ImplementRequirement ] = {} for group_path in CatalogInterface . _get_group_ids_and_dirs ( md_path ) . values (): for control_file in group_path . glob ( '*.md' ): sort_id , imp_req = ControlIOReader . read_implemented_requirement ( control_file , avail_comps ) imp_req_map [ sort_id ] = imp_req return [ imp_req_map [ key ] for key in sorted ( imp_req_map . keys ())] @staticmethod def read_additional_content ( md_path : pathlib . Path , required_sections_list : List [ str ] ) -> Tuple [ List [ prof . Alter ], Dict [ str , Any ], Dict [ str , str ]]: \"\"\"Read all markdown controls and return list of alters plus control param dict and param sort map.\"\"\" alters_map : Dict [ str , prof . Alter ] = {} final_param_dict : Dict [ str , Any ] = {} param_sort_map : Dict [ str , str ] = {} for group_path in CatalogInterface . _get_group_ids_and_dirs ( md_path ) . values (): for control_file in group_path . glob ( '*.md' ): sort_id , control_alters , control_param_dict = ControlIOReader . read_new_alters_and_params ( control_file , required_sections_list ) alters_map [ sort_id ] = control_alters for param_id , param_dict in control_param_dict . items (): # if profile_values are present, overwrite values with them if const . PROFILE_VALUES in param_dict : param_dict [ const . VALUES ] = param_dict . pop ( const . PROFILE_VALUES ) final_param_dict [ param_id ] = param_dict param_sort_map [ param_id ] = sort_id new_alters : List [ prof . Alter ] = [] # fill the alters according to the control sorting order for key in sorted ( alters_map . keys ()): new_alters . extend ( alters_map [ key ]) return new_alters , final_param_dict , param_sort_map def get_sections ( self ) -> List [ str ]: \"\"\"Get the available sections by a full index of all controls.\"\"\" sections : List [ str ] = [] for control in self . _control_dict . values (): if not control . control . parts : continue for part in control . control . parts : if part . name not in sections and part . name != 'statement' : sections . append ( part . name ) return sections @staticmethod def merge_controls ( dest : cat . Control , src : cat . Control , replace_params : bool ) -> None : \"\"\" Merge the src control into dest. Args: dest: destination control into which content will be added src: source control with new content replace_params: replace the control params with the new ones \"\"\" dest . parts = src . parts if replace_params : dest . params = src . params def _find_control_in_group ( self , group_id : str ) -> Tuple [ str , ControlHandle ]: \"\"\" Find a representative control for this group and its control handle. This is a simple way to get group info (title etc.) given only group id. It is not intended for high performance loops. Use only as needed. \"\"\" for control_id , control_handle in self . _control_dict . items (): if control_handle . group_id == group_id : return control_id , control_handle raise TrestleError ( f 'No controls found for group { group_id } ' ) def merge_catalog ( self , catalog : cat . Catalog , replace_params : bool ) -> None : \"\"\" Merge the provided new catalog controls into the original catalog in this catalog interface. Args: catalog: catalog containing controls that are merged into the current catalog of the interface replace_params: replace all params in the control with the new ones Notes: This is mainly to support the reading of a catalog from markdown. It allows retention of content such as metadata and backmatter, along with labels and other parameter attributes that aren't in markdown. The list of controls and group structure is specified by the markdown structure - but this doesn't allow controls to contain controls. Group lists are specified per directory. Reading the markdown tells you groups and controls in them - and groups in groups. Controls cannot change groups. If the control was in the original json, its parts are replaced, including its parameters. Only values may be specified. If no value specified, the value is unset in json. \"\"\" cat_interface = CatalogInterface ( catalog ) for src in cat_interface . get_all_controls_from_dict (): group_id , _ , _ = cat_interface . get_group_info_by_control ( src . id ) dest = self . get_control ( src . id ) if dest : dest_group , _ , _ = self . get_group_info_by_control ( dest . id ) if dest_group != group_id : raise TrestleError ( f 'Markdown for control { src . id } has different group id.' ) CatalogInterface . merge_controls ( dest , src , replace_params ) self . replace_control ( dest ) else : # need to add the control knowing its group must already exist # get group info from an arbitrary control already present in group _ , control_handle = self . _find_control_in_group ( group_id ) # add the control and its handle to the param_dict self . _control_dict [ src . id ] = control_handle # now need to cull any controls that are not in the src catalog handled_ids = set ( cat_interface . _control_dict . keys ()) orig_ids = set ( self . _control_dict . keys ()) extra_ids = orig_ids . difference ( handled_ids ) for extra_id in extra_ids : self . _control_dict . pop ( extra_id ) self . update_catalog_controls ()","title":"CatalogInterface"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.ControlHandle","text":"Convenience class for handling controls as members of a group. group_id: id of parent group or '' if not in a group group_title: title of the group group_class: class of the group path: path of parent groups leading to this control - without the final control_id, or [''] if in cat list control: the control itself Source code in trestle/core/catalog_interface.py class ControlHandle ( TrestleBaseModel ): \"\"\"Convenience class for handling controls as members of a group. group_id: id of parent group or '' if not in a group group_title: title of the group group_class: class of the group path: path of parent groups leading to this control - without the final control_id, or [''] if in cat list control: the control itself \"\"\" group_id : str group_title : Optional [ str ] group_class : Optional [ str ] path : List [ str ] control : cat . Control control : Control pydantic-field required \u00a4 group_class : str pydantic-field \u00a4 group_id : str pydantic-field required \u00a4 group_title : str pydantic-field \u00a4 path : List [ str ] pydantic-field required \u00a4","title":"ControlHandle"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.__init__","text":"Initialize the interface with the catalog. Source code in trestle/core/catalog_interface.py def __init__ ( self , catalog : Optional [ cat . Catalog ] = None ) -> None : \"\"\"Initialize the interface with the catalog.\"\"\" self . _catalog = catalog self . _param_control_map : Dict [ str , str ] = {} self . _control_dict = self . _create_control_dict () if catalog else None self . loose_param_dict : Dict [ str , common . Parameter ] = { param . id : param for param in as_list ( catalog . params )} if catalog else {}","title":"__init__()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.delete_control","text":"Delete the control from the control_dict based on id. Source code in trestle/core/catalog_interface.py def delete_control ( self , control_id : str ) -> None : \"\"\"Delete the control from the control_dict based on id.\"\"\" self . _control_dict . pop ( control_id , None )","title":"delete_control()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.delete_withdrawn_controls","text":"Delete all withdrawn controls from the catalog. Source code in trestle/core/catalog_interface.py def delete_withdrawn_controls ( self ) -> None : \"\"\"Delete all withdrawn controls from the catalog.\"\"\" delete_list = [] for control in self . get_all_controls_from_dict (): if ControlIOWriter . is_withdrawn ( control ): delete_list . append ( control . id ) for id_ in delete_list : self . delete_control ( id_ )","title":"delete_withdrawn_controls()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.find_part_with_condition","text":"Traverse part and find subpart that satisfies given condition. Source code in trestle/core/catalog_interface.py def find_part_with_condition ( self , part : common . Part , condition : Callable ) -> Optional [ common . Part ]: \"\"\"Traverse part and find subpart that satisfies given condition.\"\"\" if condition ( part ): # Part that satisfies the condition is found. return part else : if part . parts : for subpart in part . parts : found_part = self . find_part_with_condition ( subpart , condition ) if found_part : return found_part return None","title":"find_part_with_condition()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.find_string_in_control","text":"Find all instances of this string in prose of control. Source code in trestle/core/catalog_interface.py def find_string_in_control ( self , control : cat . Control , seek_str : str ) -> List [ Tuple [ str , str ]]: \"\"\"Find all instances of this string in prose of control.\"\"\" hits : List [ Tuple [ str , str ]] = [] if control . parts : for part in control . parts : hits . extend ( self . _find_string_in_part ( control . id , part , seek_str )) return hits","title":"find_string_in_control()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_all_controls_from_catalog","text":"Yield all deep and individual controls from the actual catalog by group. Parameters: Name Type Description Default recurse bool Whether to recurse within controls, but groups are always recursed required Returns: Type Description Iterator[trestle.oscal.catalog.Control] iterator of the controls in the catalog Notes This follows the actual structure of the catalog and groups Source code in trestle/core/catalog_interface.py def get_all_controls_from_catalog ( self , recurse : bool ) -> Iterator [ cat . Control ]: \"\"\" Yield all deep and individual controls from the actual catalog by group. Args: recurse: Whether to recurse within controls, but groups are always recursed Returns: iterator of the controls in the catalog Notes: This follows the actual structure of the catalog and groups \"\"\" if self . _catalog . groups : for group in self . _catalog . groups : controls = self . _get_all_controls_in_group ( group , recurse ) for control in controls : yield control if self . _catalog . controls : cat_controls = self . _get_all_controls_in_list ( self . _catalog . controls , recurse ) for control in cat_controls : yield control","title":"get_all_controls_from_catalog()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_all_controls_from_dict","text":"Yield individual controls from the dict. Source code in trestle/core/catalog_interface.py def get_all_controls_from_dict ( self ) -> Iterator [ cat . Control ]: \"\"\"Yield individual controls from the dict.\"\"\" return [ handle . control for handle in self . _control_dict . values ()]","title":"get_all_controls_from_dict()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_all_groups_from_catalog","text":"Retrieve all groups in the catalog sorted by group_id. Source code in trestle/core/catalog_interface.py def get_all_groups_from_catalog ( self ) -> List [ cat . Group ]: \"\"\"Retrieve all groups in the catalog sorted by group_id.\"\"\" groups : List [ cat . Group ] = [] if self . _catalog . groups : for my_group in self . _catalog . groups : for res in CatalogInterface . _get_groups_from_group ( my_group ): groups . append ( res ) return sorted ( groups , key = lambda group : group . id )","title":"get_all_groups_from_catalog()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_catalog","text":"Safe method to get catalog after forced update from catalog dict. Source code in trestle/core/catalog_interface.py def get_catalog ( self , update = True ) -> cat . Catalog : \"\"\"Safe method to get catalog after forced update from catalog dict.\"\"\" if update : self . update_catalog_controls () return self . _catalog","title":"get_catalog()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_control","text":"Get control from catalog with this id using the dict. Source code in trestle/core/catalog_interface.py def get_control ( self , control_id : str ) -> Optional [ cat . Control ]: \"\"\"Get control from catalog with this id using the dict.\"\"\" return None if control_id not in self . _control_dict else self . _control_dict [ control_id ] . control","title":"get_control()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_control_by_param_id","text":"Get control from catalog that has this param id using the dict. Source code in trestle/core/catalog_interface.py def get_control_by_param_id ( self , param_id : str ) -> Optional [ cat . Control ]: \"\"\"Get control from catalog that has this param id using the dict.\"\"\" if param_id in self . _param_control_map : return self . get_control ( self . _param_control_map [ param_id ]) return None","title":"get_control_by_param_id()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_control_id_and_status","text":"Get the control id and status using the control name. Source code in trestle/core/catalog_interface.py def get_control_id_and_status ( self , control_name : str ) -> Tuple [ str , str ]: \"\"\"Get the control id and status using the control name.\"\"\" for control in self . get_all_controls_from_dict (): if ControlIOWriter . get_label ( control ) . strip () . lower () == control_name . strip () . lower (): status = ControlIOWriter . get_prop ( control , 'status' ) return control . id , status return '' , ''","title":"get_control_id_and_status()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_control_ids","text":"Get all control ids in catalog using the dict. Source code in trestle/core/catalog_interface.py def get_control_ids ( self ) -> List [ str ]: \"\"\"Get all control ids in catalog using the dict.\"\"\" return self . _control_dict . keys ()","title":"get_control_ids()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_control_part_prose","text":"Get the prose for a named part in the control. Parameters: Name Type Description Default control_id str id of the control required part_name str name of the part required Returns: Type Description str Single string concatenating prose from all parts and sub-parts in control with that name. Source code in trestle/core/catalog_interface.py def get_control_part_prose ( self , control_id : str , part_name : str ) -> str : \"\"\" Get the prose for a named part in the control. Args: control_id: id of the control part_name: name of the part Returns: Single string concatenating prose from all parts and sub-parts in control with that name. \"\"\" control = self . get_control ( control_id ) return ControlIOWriter . get_part_prose ( control , part_name )","title":"get_control_part_prose()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_control_path","text":"Return the path into the catalog for this control. Source code in trestle/core/catalog_interface.py def get_control_path ( self , control_id : str ) -> List [ str ]: \"\"\"Return the path into the catalog for this control.\"\"\" return self . _control_dict [ control_id ] . path","title":"get_control_path()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_count_of_controls_in_catalog","text":"Get count of controls from the actual catalog. Source code in trestle/core/catalog_interface.py def get_count_of_controls_in_catalog ( self , recurse : bool ) -> int : \"\"\"Get count of controls from the actual catalog.\"\"\" return len ( list ( self . get_all_controls_from_catalog ( recurse )))","title":"get_count_of_controls_in_catalog()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_count_of_controls_in_dict","text":"Find number of controls in the dict. Source code in trestle/core/catalog_interface.py def get_count_of_controls_in_dict ( self ) -> int : \"\"\"Find number of controls in the dict.\"\"\" return len ( self . _control_dict . keys ())","title":"get_count_of_controls_in_dict()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_dependent_control_ids","text":"Find all children of this control. Source code in trestle/core/catalog_interface.py def get_dependent_control_ids ( self , control_id : str ) -> List [ str ]: \"\"\"Find all children of this control.\"\"\" children : List [ str ] = [] control = self . get_control ( control_id ) if control . controls : new_controls = self . _get_all_controls_in_list ( control . controls , True ) children . extend ([ con . id for con in new_controls ]) return children","title":"get_dependent_control_ids()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_group_ids","text":"Get all the group id's as a list of sorted strings. Source code in trestle/core/catalog_interface.py def get_group_ids ( self ) -> List [ str ]: \"\"\"Get all the group id's as a list of sorted strings.\"\"\" return sorted ( filter ( lambda id : id , list ({ control . group_id for control in self . _control_dict . values ()})))","title":"get_group_ids()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_group_info_by_control","text":"Get the group_id, title, class for this control from the dict. Source code in trestle/core/catalog_interface.py def get_group_info_by_control ( self , control_id : str ) -> Tuple [ str , str , str ]: \"\"\"Get the group_id, title, class for this control from the dict.\"\"\" return ( self . _control_dict [ control_id ] . group_id , self . _control_dict [ control_id ] . group_title , self . _control_dict [ control_id ] . group_class )","title":"get_group_info_by_control()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_sections","text":"Get the available sections by a full index of all controls. Source code in trestle/core/catalog_interface.py def get_sections ( self ) -> List [ str ]: \"\"\"Get the available sections by a full index of all controls.\"\"\" sections : List [ str ] = [] for control in self . _control_dict . values (): if not control . control . parts : continue for part in control . control . parts : if part . name not in sections and part . name != 'statement' : sections . append ( part . name ) return sections","title":"get_sections()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_sorted_controls_in_group","text":"Get the list of controls in a group sorted by the control sort-id. Source code in trestle/core/catalog_interface.py def get_sorted_controls_in_group ( self , group_id : str ) -> List [ cat . Control ]: \"\"\"Get the list of controls in a group sorted by the control sort-id.\"\"\" controls : List [ cat . Control ] = [] for control in self . get_all_controls_from_dict (): grp_id , _ , _ = self . get_group_info_by_control ( control . id ) if grp_id == group_id : controls . append ( control ) return sorted ( controls , key = lambda control : ControlIOWriter . get_sort_id ( control ))","title":"get_sorted_controls_in_group()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.get_statement_label_if_exists","text":"Get statement label if given. Source code in trestle/core/catalog_interface.py def get_statement_label_if_exists ( self , control_id : str , statement_id : str ) -> Tuple [ Optional [ str ], Optional [ common . Part ]]: \"\"\"Get statement label if given.\"\"\" def does_part_exists ( part : common . Part ) -> bool : does_match = False if part . name and part . name in { 'statement' , 'item' } and part . id == statement_id : does_match = True return does_match control = self . get_control ( control_id ) if not control : return '' , None label = None found_part = None if control . parts : for part in as_list ( control . parts ): # Performance OSCAL assumption, ids are nested so recurse only if prefix if part . id and statement_id . startswith ( part . id ): part = self . find_part_with_condition ( part , does_part_exists ) if part : label = ControlIOWriter . get_label ( part ) found_part = part break return label , found_part","title":"get_statement_label_if_exists()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.merge_catalog","text":"Merge the provided new catalog controls into the original catalog in this catalog interface. Parameters: Name Type Description Default catalog Catalog catalog containing controls that are merged into the current catalog of the interface required replace_params bool replace all params in the control with the new ones required Notes This is mainly to support the reading of a catalog from markdown. It allows retention of content such as metadata and backmatter, along with labels and other parameter attributes that aren't in markdown. The list of controls and group structure is specified by the markdown structure - but this doesn't allow controls to contain controls. Group lists are specified per directory. Reading the markdown tells you groups and controls in them - and groups in groups. Controls cannot change groups. If the control was in the original json, its parts are replaced, including its parameters. Only values may be specified. If no value specified, the value is unset in json. Source code in trestle/core/catalog_interface.py def merge_catalog ( self , catalog : cat . Catalog , replace_params : bool ) -> None : \"\"\" Merge the provided new catalog controls into the original catalog in this catalog interface. Args: catalog: catalog containing controls that are merged into the current catalog of the interface replace_params: replace all params in the control with the new ones Notes: This is mainly to support the reading of a catalog from markdown. It allows retention of content such as metadata and backmatter, along with labels and other parameter attributes that aren't in markdown. The list of controls and group structure is specified by the markdown structure - but this doesn't allow controls to contain controls. Group lists are specified per directory. Reading the markdown tells you groups and controls in them - and groups in groups. Controls cannot change groups. If the control was in the original json, its parts are replaced, including its parameters. Only values may be specified. If no value specified, the value is unset in json. \"\"\" cat_interface = CatalogInterface ( catalog ) for src in cat_interface . get_all_controls_from_dict (): group_id , _ , _ = cat_interface . get_group_info_by_control ( src . id ) dest = self . get_control ( src . id ) if dest : dest_group , _ , _ = self . get_group_info_by_control ( dest . id ) if dest_group != group_id : raise TrestleError ( f 'Markdown for control { src . id } has different group id.' ) CatalogInterface . merge_controls ( dest , src , replace_params ) self . replace_control ( dest ) else : # need to add the control knowing its group must already exist # get group info from an arbitrary control already present in group _ , control_handle = self . _find_control_in_group ( group_id ) # add the control and its handle to the param_dict self . _control_dict [ src . id ] = control_handle # now need to cull any controls that are not in the src catalog handled_ids = set ( cat_interface . _control_dict . keys ()) orig_ids = set ( self . _control_dict . keys ()) extra_ids = orig_ids . difference ( handled_ids ) for extra_id in extra_ids : self . _control_dict . pop ( extra_id ) self . update_catalog_controls ()","title":"merge_catalog()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.merge_controls","text":"Merge the src control into dest. Parameters: Name Type Description Default dest Control destination control into which content will be added required src Control source control with new content required replace_params bool replace the control params with the new ones required Source code in trestle/core/catalog_interface.py @staticmethod def merge_controls ( dest : cat . Control , src : cat . Control , replace_params : bool ) -> None : \"\"\" Merge the src control into dest. Args: dest: destination control into which content will be added src: source control with new content replace_params: replace the control params with the new ones \"\"\" dest . parts = src . parts if replace_params : dest . params = src . params","title":"merge_controls()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.read_additional_content","text":"Read all markdown controls and return list of alters plus control param dict and param sort map. Source code in trestle/core/catalog_interface.py @staticmethod def read_additional_content ( md_path : pathlib . Path , required_sections_list : List [ str ] ) -> Tuple [ List [ prof . Alter ], Dict [ str , Any ], Dict [ str , str ]]: \"\"\"Read all markdown controls and return list of alters plus control param dict and param sort map.\"\"\" alters_map : Dict [ str , prof . Alter ] = {} final_param_dict : Dict [ str , Any ] = {} param_sort_map : Dict [ str , str ] = {} for group_path in CatalogInterface . _get_group_ids_and_dirs ( md_path ) . values (): for control_file in group_path . glob ( '*.md' ): sort_id , control_alters , control_param_dict = ControlIOReader . read_new_alters_and_params ( control_file , required_sections_list ) alters_map [ sort_id ] = control_alters for param_id , param_dict in control_param_dict . items (): # if profile_values are present, overwrite values with them if const . PROFILE_VALUES in param_dict : param_dict [ const . VALUES ] = param_dict . pop ( const . PROFILE_VALUES ) final_param_dict [ param_id ] = param_dict param_sort_map [ param_id ] = sort_id new_alters : List [ prof . Alter ] = [] # fill the alters according to the control sorting order for key in sorted ( alters_map . keys ()): new_alters . extend ( alters_map [ key ]) return new_alters , final_param_dict , param_sort_map","title":"read_additional_content()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.read_catalog_from_markdown","text":"Read the groups and catalog controls from the given directory. This will overwrite the existing groups and controls in the catalog. Source code in trestle/core/catalog_interface.py def read_catalog_from_markdown ( self , md_path : pathlib . Path , set_parameters : bool ) -> cat . Catalog : \"\"\" Read the groups and catalog controls from the given directory. This will overwrite the existing groups and controls in the catalog. \"\"\" if not self . _catalog : self . _catalog = gens . generate_sample_model ( cat . Catalog ) id_map = CatalogInterface . _get_group_ids_and_dirs ( md_path ) groups : List [ cat . Group ] = [] # read each group dir for group_id , group_dir in id_map . items (): control_list_raw = [] group_title = '' # Need to get group title from at least one control in this directory # All controls in dir should have same group title # Set group title to the first one found and warn if different non-empty title appears # Controls with empty group titles are tolerated but at least one title must be present or warning given # The special group with no name that has the catalog as parent is just a list and has no title for control_path in group_dir . glob ( '*.md' ): control , control_group_title = ControlIOReader . read_control ( control_path , set_parameters ) if control_group_title : if group_title : if control_group_title != group_title : logger . warning ( f 'Control { control . id } group title { control_group_title } differs from { group_title } ' ) else : group_title = control_group_title control_list_raw . append ( control ) control_list = sorted ( control_list_raw , key = lambda control : ControlIOWriter . get_sort_id ( control )) if group_id : if not group_title : logger . warning ( f 'No group title found in controls for group { group_id } ' ) new_group = cat . Group ( id = group_id , title = group_title ) new_group . controls = control_list groups . append ( new_group ) else : # if the list of controls has no group id it also has no title and is just the controls of the catalog self . _catalog . controls = control_list self . _catalog . groups = groups if groups else None self . _create_control_dict () return self . _catalog","title":"read_catalog_from_markdown()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.read_catalog_imp_reqs","text":"Read the full set of control implemented requirements from markdown. Parameters: Name Type Description Default md_path Path Path to the markdown control files, with directories for each group required avail_comps Dict[str, trestle.oscal.ssp.SystemComponent] Dict mapping component names to known components required Returns: Type Description List[trestle.oscal.ssp.ImplementedRequirement] List of implemented requirements gathered from each control Notes As the controls are read into the catalog the needed components are added if not already available. avail_comps provides the mapping of component name to the actual component. Source code in trestle/core/catalog_interface.py @staticmethod def read_catalog_imp_reqs ( md_path : pathlib . Path , avail_comps : Dict [ str , ossp . SystemComponent ]) -> List [ ossp . ImplementedRequirement ]: \"\"\"Read the full set of control implemented requirements from markdown. Args: md_path: Path to the markdown control files, with directories for each group avail_comps: Dict mapping component names to known components Returns: List of implemented requirements gathered from each control Notes: As the controls are read into the catalog the needed components are added if not already available. avail_comps provides the mapping of component name to the actual component. \"\"\" imp_req_map : Dict [ str , ossp . ImplementRequirement ] = {} for group_path in CatalogInterface . _get_group_ids_and_dirs ( md_path ) . values (): for control_file in group_path . glob ( '*.md' ): sort_id , imp_req = ControlIOReader . read_implemented_requirement ( control_file , avail_comps ) imp_req_map [ sort_id ] = imp_req return [ imp_req_map [ key ] for key in sorted ( imp_req_map . keys ())]","title":"read_catalog_imp_reqs()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.replace_control","text":"Replace the control in the control_dict after modifying it. Source code in trestle/core/catalog_interface.py def replace_control ( self , control : cat . Control ) -> None : \"\"\"Replace the control in the control_dict after modifying it.\"\"\" self . _control_dict [ control . id ] . control = control","title":"replace_control()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.setparam_to_param","text":"Convert setparameter to parameter. Parameters: Name Type Description Default param_id str the id of the parameter required set_param SetParameter the set_parameter from a profile required Returns: Type Description Parameter a Parameter with param_id and content from the SetParameter Source code in trestle/core/catalog_interface.py @staticmethod def setparam_to_param ( param_id : str , set_param : prof . SetParameter ) -> common . Parameter : \"\"\" Convert setparameter to parameter. Args: param_id: the id of the parameter set_param: the set_parameter from a profile Returns: a Parameter with param_id and content from the SetParameter \"\"\" return common . Parameter ( id = param_id , values = set_param . values , select = set_param . select , label = set_param . label )","title":"setparam_to_param()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.update_catalog_controls","text":"Update the actual catalog by pulling fresh controls from the dict. Source code in trestle/core/catalog_interface.py def update_catalog_controls ( self ) -> None : \"\"\"Update the actual catalog by pulling fresh controls from the dict.\"\"\" if self . _catalog . groups : for group in self . _catalog . groups : self . _update_all_controls_in_group ( group ) if self . _catalog . controls : self . _catalog . controls = self . _update_all_controls_in_list ( self . _catalog . controls ) self . _catalog . params = list ( self . loose_param_dict . values ())","title":"update_catalog_controls()"},{"location":"api_reference/trestle.core.catalog_interface/#trestle.core.catalog_interface.CatalogInterface.write_catalog_as_markdown","text":"Write out the catalog controls from dict as markdown files to the specified directory. Parameters: Name Type Description Default md_path Path Path to directory in which to write the markdown required yaml_header dict Dictionary to write into the yaml header of the controls required sections_dict Optional[Dict[str, str]] Optional dict mapping section short names to long required prompt_responses bool Whether to prompt for responses in the control markdown required additional_content bool Should the additional content be printed corresponding to profile adds False profile Optional[trestle.oscal.profile.Profile] Optional profile containing the adds making up additional content None overwrite_header_values bool Overwrite existing values in markdown header content but add new content False set_parameters bool Set header values based on params in the control and in the profile False required_sections Optional[str] Optional string containing list of sections that should be prompted for prose None allowed_sections Optional[str] Optional string containing list of sections that should be included in markdown None Returns: Type Description None None Notes The header should capture current values for parameters. Special handling is needed if a profile is provided, in which case the header should only have details captured in the set_params of the profile. label, select, choice, how-many should only appear if they are specified explicitly in the profile's set_parameters. Source code in trestle/core/catalog_interface.py def write_catalog_as_markdown ( self , md_path : pathlib . Path , yaml_header : dict , sections_dict : Optional [ Dict [ str , str ]], prompt_responses : bool , additional_content : bool = False , profile : Optional [ prof . Profile ] = None , overwrite_header_values : bool = False , set_parameters : bool = False , required_sections : Optional [ str ] = None , allowed_sections : Optional [ str ] = None ) -> None : \"\"\" Write out the catalog controls from dict as markdown files to the specified directory. Args: md_path: Path to directory in which to write the markdown yaml_header: Dictionary to write into the yaml header of the controls sections_dict: Optional dict mapping section short names to long prompt_responses: Whether to prompt for responses in the control markdown additional_content: Should the additional content be printed corresponding to profile adds profile: Optional profile containing the adds making up additional content overwrite_header_values: Overwrite existing values in markdown header content but add new content set_parameters: Set header values based on params in the control and in the profile required_sections: Optional string containing list of sections that should be prompted for prose allowed_sections: Optional string containing list of sections that should be included in markdown Returns: None Notes: The header should capture current values for parameters. Special handling is needed if a profile is provided, in which case the header should only have details captured in the set_params of the profile. label, select, choice, how-many should only appear if they are specified explicitly in the profile's set_parameters. \"\"\" writer = ControlIOWriter () required_section_list = required_sections . split ( ',' ) if required_sections else [] allowed_section_list = allowed_sections . split ( ',' ) if allowed_sections else [] # create the directory in which to write the control markdown files md_path . mkdir ( exist_ok = True , parents = True ) catalog_interface = CatalogInterface ( self . _catalog ) # get the list of params for this profile from its set_params # this is just from the set_params full_profile_param_dict = CatalogInterface . _get_full_profile_param_dict ( profile ) if profile else {} # write out the controls for control in catalog_interface . get_all_controls_from_catalog ( True ): # make copy of incoming yaml header new_header = copy . deepcopy ( yaml_header ) # here we do special handling of how set-parameters merge with the yaml header if set_parameters : # get all params for this control control_param_dict = ControlIOReader . get_control_param_dict ( control , False ) set_param_dict : Dict [ str , str ] = {} for param_id , param_dict in control_param_dict . items (): # if the param is in the profile set_params, load its contents first and mark as profile-values if param_id in full_profile_param_dict : # get the param from the profile set_param param = full_profile_param_dict [ param_id ] # assign its contents to the dict new_dict = ModelUtils . parameter_to_dict ( param , True ) profile_values = new_dict . get ( const . VALUES , None ) if profile_values : new_dict [ const . PROFILE_VALUES ] = profile_values new_dict . pop ( const . VALUES ) # then insert the original, incoming values as values if param_id in control_param_dict : orig_param = control_param_dict [ param_id ] orig_dict = ModelUtils . parameter_to_dict ( orig_param , True ) # pull only the values from the actual control dict # all the other elements are from the profile set_param new_dict [ const . VALUES ] = orig_dict . get ( const . VALUES , None ) else : new_dict = ModelUtils . parameter_to_dict ( param_dict , True ) new_dict . pop ( 'id' ) set_param_dict [ param_id ] = new_dict if set_param_dict : if const . SET_PARAMS_TAG not in new_header : new_header [ const . SET_PARAMS_TAG ] = {} if overwrite_header_values : # update the control params with new values for key , value in new_header [ const . SET_PARAMS_TAG ] . items (): if key in control_param_dict : set_param_dict [ key ] = value else : # update the control params with any values in yaml header not set in control # need to maintain order in the set_param_dict for key , value in new_header [ const . SET_PARAMS_TAG ] . items (): if key in control_param_dict and key not in set_param_dict : set_param_dict [ key ] = value new_header [ const . SET_PARAMS_TAG ] = set_param_dict elif const . SET_PARAMS_TAG in new_header : # need to cull any params that are not in control pop_list : List [ str ] = [] for key in new_header [ const . SET_PARAMS_TAG ] . keys (): if key not in control_param_dict : pop_list . append ( key ) for pop in pop_list : new_header [ const . SET_PARAMS_TAG ] . pop ( pop ) _ , group_title , _ = catalog_interface . get_group_info_by_control ( control . id ) # control could be in sub-group of group so build path to it group_dir = md_path control_path = catalog_interface . get_control_path ( control . id ) for sub_dir in control_path : group_dir = group_dir / sub_dir if not group_dir . exists (): group_dir . mkdir ( parents = True , exist_ok = True ) writer . write_control_for_editing ( group_dir , control , group_title , new_header , sections_dict , additional_content , prompt_responses , profile , overwrite_header_values , required_section_list , allowed_section_list ) handler: python","title":"write_catalog_as_markdown()"},{"location":"api_reference/trestle.core.commands.add/","text":"trestle.core.commands.add \u00a4 Trestle Add Command. logger \u00a4 Classes \u00a4 Add \u00a4 Class supporting Add of an OSCAL object to a provided file based on element path. Examples of element paths: catalog.metadata catalog.controls.control assessment-results.results. The method first finds the parent model from the file and loads the file into the model. Then the method executes 'add' for each of the element paths specified. Add was originally its own command but has been incorporated into the Create command. Source code in trestle/core/commands/add.py class Add (): \"\"\" Class supporting Add of an OSCAL object to a provided file based on element path. Examples of element paths: catalog.metadata catalog.controls.control assessment-results.results. The method first finds the parent model from the file and loads the file into the model. Then the method executes 'add' for each of the element paths specified. Add was originally its own command but has been incorporated into the Create command. \"\"\" def add_from_args ( self , args : argparse . Namespace ) -> int : \"\"\"Parse args for add element to file.\"\"\" file_path = pathlib . Path ( args . file ) . resolve () # Get parent model and then load json into parent model parent_model , _ = ModelUtils . get_stripped_model_type ( file_path , args . trestle_root ) parent_object = parent_model . oscal_read ( file_path ) parent_element = Element ( parent_object , classname_to_alias ( parent_model . __name__ , AliasMode . JSON )) add_plan = Plan () # Do _add for each element_path specified in args element_paths : List [ str ] = args . element . split ( ',' ) for elm_path_str in element_paths : element_path = ElementPath ( elm_path_str ) update_action , parent_element = self . add ( element_path , parent_element , args . include_optional_fields ) add_plan . add_action ( update_action ) create_action = CreatePathAction ( file_path , True ) # this will output json or yaml based on type of input file write_action = WriteFileAction ( file_path , parent_element , FileContentType . to_content_type ( file_path . suffix )) add_plan . add_action ( create_action ) add_plan . add_action ( write_action ) add_plan . execute () return CmdReturnCodes . SUCCESS . value @staticmethod def add ( element_path : ElementPath , parent_element : Element , include_optional : bool ) -> None : \"\"\"For a element_path, add a child model to the parent_element of a given parent_model. Args: element_path: element path of the item to create within the model parent_element: the parent element that will host the created element include_optional: whether to create optional attributes in the created element Notes: First we find the child model at the specified element path and instantiate it with default values. Then we check if there's already existing element at that path, in which case we append the child model to the existing list of dict. Then we set up an action plan to update the model (specified by file_path) in memory, create a file at the same location and write the file. We update the parent_element to prepare for next adds in the chain \"\"\" if '*' in element_path . get_full_path_parts (): raise err . TrestleError ( 'trestle add does not support Wildcard element path.' ) # Get child model try : child_model = element_path . get_type ( type ( parent_element . get ())) # Create child element with sample values child_object = gens . generate_sample_model ( child_model , include_optional = include_optional ) if parent_element . get_at ( element_path ) is not None : # The element already exists if type ( parent_element . get_at ( element_path )) is list : child_object = parent_element . get_at ( element_path ) + child_object elif type ( parent_element . get_at ( element_path )) is dict : child_object = { ** parent_element . get_at ( element_path ), ** child_object } else : raise err . TrestleError ( 'Already exists and is not a list or dictionary.' ) except Exception as e : raise err . TrestleError ( f 'Bad element path. { str ( e ) } ' ) update_action = UpdateAction ( sub_element = child_object , dest_element = parent_element , sub_element_path = element_path ) parent_element = parent_element . set_at ( element_path , child_object ) return update_action , parent_element Methods \u00a4 add ( element_path , parent_element , include_optional ) staticmethod \u00a4 For a element_path, add a child model to the parent_element of a given parent_model. Parameters: Name Type Description Default element_path ElementPath element path of the item to create within the model required parent_element Element the parent element that will host the created element required include_optional bool whether to create optional attributes in the created element required Notes First we find the child model at the specified element path and instantiate it with default values. Then we check if there's already existing element at that path, in which case we append the child model to the existing list of dict. Then we set up an action plan to update the model (specified by file_path) in memory, create a file at the same location and write the file. We update the parent_element to prepare for next adds in the chain Source code in trestle/core/commands/add.py @staticmethod def add ( element_path : ElementPath , parent_element : Element , include_optional : bool ) -> None : \"\"\"For a element_path, add a child model to the parent_element of a given parent_model. Args: element_path: element path of the item to create within the model parent_element: the parent element that will host the created element include_optional: whether to create optional attributes in the created element Notes: First we find the child model at the specified element path and instantiate it with default values. Then we check if there's already existing element at that path, in which case we append the child model to the existing list of dict. Then we set up an action plan to update the model (specified by file_path) in memory, create a file at the same location and write the file. We update the parent_element to prepare for next adds in the chain \"\"\" if '*' in element_path . get_full_path_parts (): raise err . TrestleError ( 'trestle add does not support Wildcard element path.' ) # Get child model try : child_model = element_path . get_type ( type ( parent_element . get ())) # Create child element with sample values child_object = gens . generate_sample_model ( child_model , include_optional = include_optional ) if parent_element . get_at ( element_path ) is not None : # The element already exists if type ( parent_element . get_at ( element_path )) is list : child_object = parent_element . get_at ( element_path ) + child_object elif type ( parent_element . get_at ( element_path )) is dict : child_object = { ** parent_element . get_at ( element_path ), ** child_object } else : raise err . TrestleError ( 'Already exists and is not a list or dictionary.' ) except Exception as e : raise err . TrestleError ( f 'Bad element path. { str ( e ) } ' ) update_action = UpdateAction ( sub_element = child_object , dest_element = parent_element , sub_element_path = element_path ) parent_element = parent_element . set_at ( element_path , child_object ) return update_action , parent_element add_from_args ( self , args ) \u00a4 Parse args for add element to file. Source code in trestle/core/commands/add.py def add_from_args ( self , args : argparse . Namespace ) -> int : \"\"\"Parse args for add element to file.\"\"\" file_path = pathlib . Path ( args . file ) . resolve () # Get parent model and then load json into parent model parent_model , _ = ModelUtils . get_stripped_model_type ( file_path , args . trestle_root ) parent_object = parent_model . oscal_read ( file_path ) parent_element = Element ( parent_object , classname_to_alias ( parent_model . __name__ , AliasMode . JSON )) add_plan = Plan () # Do _add for each element_path specified in args element_paths : List [ str ] = args . element . split ( ',' ) for elm_path_str in element_paths : element_path = ElementPath ( elm_path_str ) update_action , parent_element = self . add ( element_path , parent_element , args . include_optional_fields ) add_plan . add_action ( update_action ) create_action = CreatePathAction ( file_path , True ) # this will output json or yaml based on type of input file write_action = WriteFileAction ( file_path , parent_element , FileContentType . to_content_type ( file_path . suffix )) add_plan . add_action ( create_action ) add_plan . add_action ( write_action ) add_plan . execute () return CmdReturnCodes . SUCCESS . value handler: python","title":"add"},{"location":"api_reference/trestle.core.commands.add/#trestle.core.commands.add","text":"Trestle Add Command.","title":"add"},{"location":"api_reference/trestle.core.commands.add/#trestle.core.commands.add.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.add/#trestle.core.commands.add-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.add/#trestle.core.commands.add.Add","text":"Class supporting Add of an OSCAL object to a provided file based on element path. Examples of element paths: catalog.metadata catalog.controls.control assessment-results.results. The method first finds the parent model from the file and loads the file into the model. Then the method executes 'add' for each of the element paths specified. Add was originally its own command but has been incorporated into the Create command. Source code in trestle/core/commands/add.py class Add (): \"\"\" Class supporting Add of an OSCAL object to a provided file based on element path. Examples of element paths: catalog.metadata catalog.controls.control assessment-results.results. The method first finds the parent model from the file and loads the file into the model. Then the method executes 'add' for each of the element paths specified. Add was originally its own command but has been incorporated into the Create command. \"\"\" def add_from_args ( self , args : argparse . Namespace ) -> int : \"\"\"Parse args for add element to file.\"\"\" file_path = pathlib . Path ( args . file ) . resolve () # Get parent model and then load json into parent model parent_model , _ = ModelUtils . get_stripped_model_type ( file_path , args . trestle_root ) parent_object = parent_model . oscal_read ( file_path ) parent_element = Element ( parent_object , classname_to_alias ( parent_model . __name__ , AliasMode . JSON )) add_plan = Plan () # Do _add for each element_path specified in args element_paths : List [ str ] = args . element . split ( ',' ) for elm_path_str in element_paths : element_path = ElementPath ( elm_path_str ) update_action , parent_element = self . add ( element_path , parent_element , args . include_optional_fields ) add_plan . add_action ( update_action ) create_action = CreatePathAction ( file_path , True ) # this will output json or yaml based on type of input file write_action = WriteFileAction ( file_path , parent_element , FileContentType . to_content_type ( file_path . suffix )) add_plan . add_action ( create_action ) add_plan . add_action ( write_action ) add_plan . execute () return CmdReturnCodes . SUCCESS . value @staticmethod def add ( element_path : ElementPath , parent_element : Element , include_optional : bool ) -> None : \"\"\"For a element_path, add a child model to the parent_element of a given parent_model. Args: element_path: element path of the item to create within the model parent_element: the parent element that will host the created element include_optional: whether to create optional attributes in the created element Notes: First we find the child model at the specified element path and instantiate it with default values. Then we check if there's already existing element at that path, in which case we append the child model to the existing list of dict. Then we set up an action plan to update the model (specified by file_path) in memory, create a file at the same location and write the file. We update the parent_element to prepare for next adds in the chain \"\"\" if '*' in element_path . get_full_path_parts (): raise err . TrestleError ( 'trestle add does not support Wildcard element path.' ) # Get child model try : child_model = element_path . get_type ( type ( parent_element . get ())) # Create child element with sample values child_object = gens . generate_sample_model ( child_model , include_optional = include_optional ) if parent_element . get_at ( element_path ) is not None : # The element already exists if type ( parent_element . get_at ( element_path )) is list : child_object = parent_element . get_at ( element_path ) + child_object elif type ( parent_element . get_at ( element_path )) is dict : child_object = { ** parent_element . get_at ( element_path ), ** child_object } else : raise err . TrestleError ( 'Already exists and is not a list or dictionary.' ) except Exception as e : raise err . TrestleError ( f 'Bad element path. { str ( e ) } ' ) update_action = UpdateAction ( sub_element = child_object , dest_element = parent_element , sub_element_path = element_path ) parent_element = parent_element . set_at ( element_path , child_object ) return update_action , parent_element","title":"Add"},{"location":"api_reference/trestle.core.commands.add/#trestle.core.commands.add.Add-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.add/#trestle.core.commands.add.Add.add","text":"For a element_path, add a child model to the parent_element of a given parent_model. Parameters: Name Type Description Default element_path ElementPath element path of the item to create within the model required parent_element Element the parent element that will host the created element required include_optional bool whether to create optional attributes in the created element required Notes First we find the child model at the specified element path and instantiate it with default values. Then we check if there's already existing element at that path, in which case we append the child model to the existing list of dict. Then we set up an action plan to update the model (specified by file_path) in memory, create a file at the same location and write the file. We update the parent_element to prepare for next adds in the chain Source code in trestle/core/commands/add.py @staticmethod def add ( element_path : ElementPath , parent_element : Element , include_optional : bool ) -> None : \"\"\"For a element_path, add a child model to the parent_element of a given parent_model. Args: element_path: element path of the item to create within the model parent_element: the parent element that will host the created element include_optional: whether to create optional attributes in the created element Notes: First we find the child model at the specified element path and instantiate it with default values. Then we check if there's already existing element at that path, in which case we append the child model to the existing list of dict. Then we set up an action plan to update the model (specified by file_path) in memory, create a file at the same location and write the file. We update the parent_element to prepare for next adds in the chain \"\"\" if '*' in element_path . get_full_path_parts (): raise err . TrestleError ( 'trestle add does not support Wildcard element path.' ) # Get child model try : child_model = element_path . get_type ( type ( parent_element . get ())) # Create child element with sample values child_object = gens . generate_sample_model ( child_model , include_optional = include_optional ) if parent_element . get_at ( element_path ) is not None : # The element already exists if type ( parent_element . get_at ( element_path )) is list : child_object = parent_element . get_at ( element_path ) + child_object elif type ( parent_element . get_at ( element_path )) is dict : child_object = { ** parent_element . get_at ( element_path ), ** child_object } else : raise err . TrestleError ( 'Already exists and is not a list or dictionary.' ) except Exception as e : raise err . TrestleError ( f 'Bad element path. { str ( e ) } ' ) update_action = UpdateAction ( sub_element = child_object , dest_element = parent_element , sub_element_path = element_path ) parent_element = parent_element . set_at ( element_path , child_object ) return update_action , parent_element","title":"add()"},{"location":"api_reference/trestle.core.commands.add/#trestle.core.commands.add.Add.add_from_args","text":"Parse args for add element to file. Source code in trestle/core/commands/add.py def add_from_args ( self , args : argparse . Namespace ) -> int : \"\"\"Parse args for add element to file.\"\"\" file_path = pathlib . Path ( args . file ) . resolve () # Get parent model and then load json into parent model parent_model , _ = ModelUtils . get_stripped_model_type ( file_path , args . trestle_root ) parent_object = parent_model . oscal_read ( file_path ) parent_element = Element ( parent_object , classname_to_alias ( parent_model . __name__ , AliasMode . JSON )) add_plan = Plan () # Do _add for each element_path specified in args element_paths : List [ str ] = args . element . split ( ',' ) for elm_path_str in element_paths : element_path = ElementPath ( elm_path_str ) update_action , parent_element = self . add ( element_path , parent_element , args . include_optional_fields ) add_plan . add_action ( update_action ) create_action = CreatePathAction ( file_path , True ) # this will output json or yaml based on type of input file write_action = WriteFileAction ( file_path , parent_element , FileContentType . to_content_type ( file_path . suffix )) add_plan . add_action ( create_action ) add_plan . add_action ( write_action ) add_plan . execute () return CmdReturnCodes . SUCCESS . value handler: python","title":"add_from_args()"},{"location":"api_reference/trestle.core.commands.assemble/","text":"trestle.core.commands.assemble \u00a4 Trestle Assemble Command. logger \u00a4 Classes \u00a4 AssembleCmd ( CommandPlusDocs ) \u00a4 Assemble all subcomponents from a specified trestle model into a single JSON/YAML file under dist. Source code in trestle/core/commands/assemble.py class AssembleCmd ( CommandPlusDocs ): \"\"\"Assemble all subcomponents from a specified trestle model into a single JSON/YAML file under dist.\"\"\" name = 'assemble' def _init_arguments ( self ) -> None : self . add_argument ( 'model' , help = '' , choices = const . MODEL_TYPE_LIST ) self . add_argument ( '-n' , '--name' , help = 'Name of a single model to assemble.' ) self . add_argument ( '-t' , '--type' , action = 'store_true' , help = 'Assemble all models of the given type.' ) self . add_argument ( '-x' , '--extension' , help = 'Type of file output.' , choices = [ 'json' , 'yaml' , 'yml' ], default = 'json' ) def _run ( self , args : argparse . Namespace ) -> int : try : return self . assemble_model ( args . model , args ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while assembling OSCAL model' ) @classmethod def assemble_model ( cls , model_alias : str , args : argparse . Namespace ) -> int : \"\"\"Assemble a top level OSCAL model within the trestle dist directory.\"\"\" log . set_log_level_from_args ( args ) logger . info ( f 'Assembling models of type { model_alias } .' ) trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. if not trestle_root or not file_utils . is_valid_project_root ( args . trestle_root ): raise TrestleRootError ( f 'Given directory { trestle_root } is not a trestle project.' ) model_names = [] if args . name : model_names = [ args . name ] logger . info ( f 'Assembling single model of type { model_alias } : { args . name } .' ) else : model_names = ModelUtils . get_models_of_type ( model_alias , trestle_root ) nmodels = len ( model_names ) logger . info ( f 'Assembling { nmodels } found models of type { model_alias } .' ) if len ( model_names ) == 0 : logger . info ( f 'No models found to assemble of type { model_alias } .' ) return CmdReturnCodes . SUCCESS . value for model_name in model_names : # contruct path to the model file name root_model_dir = trestle_root / ModelUtils . model_type_to_model_dir ( model_alias ) model_file_type = file_utils . get_contextual_file_type ( root_model_dir / model_name ) model_file_name = f ' { model_alias }{ FileContentType . to_file_extension ( model_file_type ) } ' root_model_filepath = root_model_dir / model_name / model_file_name if not root_model_filepath . exists (): raise TrestleError ( f 'No top level model file at { root_model_dir } ' ) # distributed load _ , _ , assembled_model = ModelUtils . load_distributed ( root_model_filepath , args . trestle_root ) plural_alias = ModelUtils . model_type_to_model_dir ( model_alias ) assembled_model_dir = trestle_root / const . TRESTLE_DIST_DIR / plural_alias assembled_model_filepath = assembled_model_dir / f ' { model_name } . { args . extension } ' plan = Plan () plan . add_action ( CreatePathAction ( assembled_model_filepath , True )) plan . add_action ( WriteFileAction ( assembled_model_filepath , Element ( assembled_model ), FileContentType . to_content_type ( f '. { args . extension } ' ) ) ) plan . execute () return CmdReturnCodes . SUCCESS . value name \u00a4 Methods \u00a4 assemble_model ( model_alias , args ) classmethod \u00a4 Assemble a top level OSCAL model within the trestle dist directory. Source code in trestle/core/commands/assemble.py @classmethod def assemble_model ( cls , model_alias : str , args : argparse . Namespace ) -> int : \"\"\"Assemble a top level OSCAL model within the trestle dist directory.\"\"\" log . set_log_level_from_args ( args ) logger . info ( f 'Assembling models of type { model_alias } .' ) trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. if not trestle_root or not file_utils . is_valid_project_root ( args . trestle_root ): raise TrestleRootError ( f 'Given directory { trestle_root } is not a trestle project.' ) model_names = [] if args . name : model_names = [ args . name ] logger . info ( f 'Assembling single model of type { model_alias } : { args . name } .' ) else : model_names = ModelUtils . get_models_of_type ( model_alias , trestle_root ) nmodels = len ( model_names ) logger . info ( f 'Assembling { nmodels } found models of type { model_alias } .' ) if len ( model_names ) == 0 : logger . info ( f 'No models found to assemble of type { model_alias } .' ) return CmdReturnCodes . SUCCESS . value for model_name in model_names : # contruct path to the model file name root_model_dir = trestle_root / ModelUtils . model_type_to_model_dir ( model_alias ) model_file_type = file_utils . get_contextual_file_type ( root_model_dir / model_name ) model_file_name = f ' { model_alias }{ FileContentType . to_file_extension ( model_file_type ) } ' root_model_filepath = root_model_dir / model_name / model_file_name if not root_model_filepath . exists (): raise TrestleError ( f 'No top level model file at { root_model_dir } ' ) # distributed load _ , _ , assembled_model = ModelUtils . load_distributed ( root_model_filepath , args . trestle_root ) plural_alias = ModelUtils . model_type_to_model_dir ( model_alias ) assembled_model_dir = trestle_root / const . TRESTLE_DIST_DIR / plural_alias assembled_model_filepath = assembled_model_dir / f ' { model_name } . { args . extension } ' plan = Plan () plan . add_action ( CreatePathAction ( assembled_model_filepath , True )) plan . add_action ( WriteFileAction ( assembled_model_filepath , Element ( assembled_model ), FileContentType . to_content_type ( f '. { args . extension } ' ) ) ) plan . execute () return CmdReturnCodes . SUCCESS . value handler: python","title":"assemble"},{"location":"api_reference/trestle.core.commands.assemble/#trestle.core.commands.assemble","text":"Trestle Assemble Command.","title":"assemble"},{"location":"api_reference/trestle.core.commands.assemble/#trestle.core.commands.assemble.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.assemble/#trestle.core.commands.assemble-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.assemble/#trestle.core.commands.assemble.AssembleCmd","text":"Assemble all subcomponents from a specified trestle model into a single JSON/YAML file under dist. Source code in trestle/core/commands/assemble.py class AssembleCmd ( CommandPlusDocs ): \"\"\"Assemble all subcomponents from a specified trestle model into a single JSON/YAML file under dist.\"\"\" name = 'assemble' def _init_arguments ( self ) -> None : self . add_argument ( 'model' , help = '' , choices = const . MODEL_TYPE_LIST ) self . add_argument ( '-n' , '--name' , help = 'Name of a single model to assemble.' ) self . add_argument ( '-t' , '--type' , action = 'store_true' , help = 'Assemble all models of the given type.' ) self . add_argument ( '-x' , '--extension' , help = 'Type of file output.' , choices = [ 'json' , 'yaml' , 'yml' ], default = 'json' ) def _run ( self , args : argparse . Namespace ) -> int : try : return self . assemble_model ( args . model , args ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while assembling OSCAL model' ) @classmethod def assemble_model ( cls , model_alias : str , args : argparse . Namespace ) -> int : \"\"\"Assemble a top level OSCAL model within the trestle dist directory.\"\"\" log . set_log_level_from_args ( args ) logger . info ( f 'Assembling models of type { model_alias } .' ) trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. if not trestle_root or not file_utils . is_valid_project_root ( args . trestle_root ): raise TrestleRootError ( f 'Given directory { trestle_root } is not a trestle project.' ) model_names = [] if args . name : model_names = [ args . name ] logger . info ( f 'Assembling single model of type { model_alias } : { args . name } .' ) else : model_names = ModelUtils . get_models_of_type ( model_alias , trestle_root ) nmodels = len ( model_names ) logger . info ( f 'Assembling { nmodels } found models of type { model_alias } .' ) if len ( model_names ) == 0 : logger . info ( f 'No models found to assemble of type { model_alias } .' ) return CmdReturnCodes . SUCCESS . value for model_name in model_names : # contruct path to the model file name root_model_dir = trestle_root / ModelUtils . model_type_to_model_dir ( model_alias ) model_file_type = file_utils . get_contextual_file_type ( root_model_dir / model_name ) model_file_name = f ' { model_alias }{ FileContentType . to_file_extension ( model_file_type ) } ' root_model_filepath = root_model_dir / model_name / model_file_name if not root_model_filepath . exists (): raise TrestleError ( f 'No top level model file at { root_model_dir } ' ) # distributed load _ , _ , assembled_model = ModelUtils . load_distributed ( root_model_filepath , args . trestle_root ) plural_alias = ModelUtils . model_type_to_model_dir ( model_alias ) assembled_model_dir = trestle_root / const . TRESTLE_DIST_DIR / plural_alias assembled_model_filepath = assembled_model_dir / f ' { model_name } . { args . extension } ' plan = Plan () plan . add_action ( CreatePathAction ( assembled_model_filepath , True )) plan . add_action ( WriteFileAction ( assembled_model_filepath , Element ( assembled_model ), FileContentType . to_content_type ( f '. { args . extension } ' ) ) ) plan . execute () return CmdReturnCodes . SUCCESS . value","title":"AssembleCmd"},{"location":"api_reference/trestle.core.commands.assemble/#trestle.core.commands.assemble.AssembleCmd.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.assemble/#trestle.core.commands.assemble.AssembleCmd-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.assemble/#trestle.core.commands.assemble.AssembleCmd.assemble_model","text":"Assemble a top level OSCAL model within the trestle dist directory. Source code in trestle/core/commands/assemble.py @classmethod def assemble_model ( cls , model_alias : str , args : argparse . Namespace ) -> int : \"\"\"Assemble a top level OSCAL model within the trestle dist directory.\"\"\" log . set_log_level_from_args ( args ) logger . info ( f 'Assembling models of type { model_alias } .' ) trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. if not trestle_root or not file_utils . is_valid_project_root ( args . trestle_root ): raise TrestleRootError ( f 'Given directory { trestle_root } is not a trestle project.' ) model_names = [] if args . name : model_names = [ args . name ] logger . info ( f 'Assembling single model of type { model_alias } : { args . name } .' ) else : model_names = ModelUtils . get_models_of_type ( model_alias , trestle_root ) nmodels = len ( model_names ) logger . info ( f 'Assembling { nmodels } found models of type { model_alias } .' ) if len ( model_names ) == 0 : logger . info ( f 'No models found to assemble of type { model_alias } .' ) return CmdReturnCodes . SUCCESS . value for model_name in model_names : # contruct path to the model file name root_model_dir = trestle_root / ModelUtils . model_type_to_model_dir ( model_alias ) model_file_type = file_utils . get_contextual_file_type ( root_model_dir / model_name ) model_file_name = f ' { model_alias }{ FileContentType . to_file_extension ( model_file_type ) } ' root_model_filepath = root_model_dir / model_name / model_file_name if not root_model_filepath . exists (): raise TrestleError ( f 'No top level model file at { root_model_dir } ' ) # distributed load _ , _ , assembled_model = ModelUtils . load_distributed ( root_model_filepath , args . trestle_root ) plural_alias = ModelUtils . model_type_to_model_dir ( model_alias ) assembled_model_dir = trestle_root / const . TRESTLE_DIST_DIR / plural_alias assembled_model_filepath = assembled_model_dir / f ' { model_name } . { args . extension } ' plan = Plan () plan . add_action ( CreatePathAction ( assembled_model_filepath , True )) plan . add_action ( WriteFileAction ( assembled_model_filepath , Element ( assembled_model ), FileContentType . to_content_type ( f '. { args . extension } ' ) ) ) plan . execute () return CmdReturnCodes . SUCCESS . value handler: python","title":"assemble_model()"},{"location":"api_reference/trestle.core.commands.author.catalog/","text":"trestle.core.commands.author.catalog \u00a4 Author commands to generate catalog controls as markdown and assemble them back to json. logger \u00a4 Classes \u00a4 CatalogAssemble ( AuthorCommonCommand ) \u00a4 Assemble markdown files of controls into a Catalog json file. Source code in trestle/core/commands/author/catalog.py class CatalogAssemble ( AuthorCommonCommand ): \"\"\"Assemble markdown files of controls into a Catalog json file.\"\"\" name = 'catalog-assemble' def _init_arguments ( self ) -> None : name_help_str = ( 'Optional name of the catalog model in the trestle workspace that is being modified. ' 'If not provided the output name is used.' ) self . add_argument ( '-n' , '--name' , help = name_help_str , required = False , type = str ) file_help_str = 'Name of the input markdown file directory' self . add_argument ( '-m' , '--markdown' , help = file_help_str , required = True , type = str ) output_help_str = 'Name of the output generated json Catalog' self . add_argument ( '-o' , '--output' , help = output_help_str , required = True , type = str ) self . add_argument ( '-sp' , '--set-parameters' , action = 'store_true' , help = const . HELP_SET_PARAMS , required = False ) self . add_argument ( '-r' , '--regenerate' , action = 'store_true' , help = const . HELP_REGENERATE ) self . add_argument ( '-vn' , '--version' , help = const . HELP_VERSION , required = False , type = str ) def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) trestle_root = pathlib . Path ( args . trestle_root ) return CatalogAssemble . assemble_catalog ( trestle_root = trestle_root , md_name = args . markdown , assem_cat_name = args . output , parent_cat_name = args . name , set_parameters = args . set_parameters , regenerate = args . regenerate , version = args . version ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error occurred while assembling catalog' ) @staticmethod def assemble_catalog ( trestle_root : pathlib . Path , md_name : str , assem_cat_name : str , parent_cat_name : Optional [ str ], set_parameters : bool , regenerate : bool , version : Optional [ str ] ) -> int : \"\"\" Assemble the markdown directory into a json catalog model file. Args: trestle_root: The trestle root directory md_name: The name of the directory containing the markdown control files for the ssp assem_cat_name: The output name of the catalog model to be created from the assembly parent_cat_name: Optional name of the parent catalog that the markdown controls will replace set_parameters: set the parameters in the control to the values in the markdown yaml header regenerate: whether to regenerate the uuid's in the catalog version: version for the assembled catalog Returns: 0 on success, 1 otherwise Notes: If the destination catalog_name model already exists in the trestle project, it is overwritten. If a parent catalog is not specified, the assembled catalog will be used as the parent if it exists. If no parent catalog name is available, the catalog is created anew using only the markdown content. \"\"\" md_dir = trestle_root / md_name if not md_dir . exists (): raise TrestleError ( f 'Markdown directory { md_name } does not exist.' ) # assemble the markdown controls into md_catalog md_catalog_interface = CatalogInterface () try : md_catalog = md_catalog_interface . read_catalog_from_markdown ( md_dir , set_parameters ) except Exception as e : raise TrestleError ( f 'Error reading catalog from markdown { md_dir } : { e } ' ) if md_catalog_interface . get_count_of_controls_in_catalog ( True ) == 0 : raise TrestleError ( f 'No controls were loaded from markdown { md_dir } . No catalog created.' ) # this is None if it doesn't exist yet assem_cat_path = ModelUtils . full_path_for_top_level_model ( trestle_root , assem_cat_name , Catalog ) # if original cat is not specified, use the assembled cat but only if it already exists if not parent_cat_name and assem_cat_path : parent_cat_name = assem_cat_name # default to JSON but allow override later if other file type found new_content_type = FileContentType . JSON # if we have parent catalog then merge the markdown controls into it # the parent can be a separate catalog or the destination assembled catalog if it exists # but this is the catalog that the markdown is merged into in memory if parent_cat_name : parent_cat , parent_cat_path = ModelUtils . load_top_level_model ( trestle_root , parent_cat_name , Catalog ) parent_cat_interface = CatalogInterface ( parent_cat ) # merge the just-read md catalog into the original json parent_cat_interface . merge_catalog ( md_catalog , set_parameters ) md_catalog = parent_cat_interface . get_catalog () new_content_type = FileContentType . path_to_content_type ( parent_cat_path ) if version : md_catalog . metadata . version = com . Version ( __root__ = version ) # now check the destination catalog to see if the in-memory catalog matches it if assem_cat_path : new_content_type = FileContentType . path_to_content_type ( assem_cat_path ) _ , _ , existing_cat = ModelUtils . load_distributed ( assem_cat_path , trestle_root ) if ModelUtils . models_are_equivalent ( existing_cat , md_catalog ): logger . info ( 'Assembled catalog is not different from existing version, so no update.' ) return CmdReturnCodes . SUCCESS . value if regenerate : md_catalog , _ , _ = ModelUtils . regenerate_uuids ( md_catalog ) ModelUtils . update_last_modified ( md_catalog ) # we still may not know the assem_cat_path but can now create it with file content type assem_cat_path = ModelUtils . path_for_top_level_model ( trestle_root , assem_cat_name , Catalog , new_content_type ) if assem_cat_path . parent . exists (): logger . info ( 'Creating catalog from markdown and destination catalog exists, so updating.' ) shutil . rmtree ( str ( assem_cat_path . parent )) assem_cat_path . parent . mkdir ( parents = True , exist_ok = True ) md_catalog . oscal_write ( assem_cat_path . parent / 'catalog.json' ) return CmdReturnCodes . SUCCESS . value name \u00a4 Methods \u00a4 assemble_catalog ( trestle_root , md_name , assem_cat_name , parent_cat_name , set_parameters , regenerate , version ) staticmethod \u00a4 Assemble the markdown directory into a json catalog model file. Parameters: Name Type Description Default trestle_root Path The trestle root directory required md_name str The name of the directory containing the markdown control files for the ssp required assem_cat_name str The output name of the catalog model to be created from the assembly required parent_cat_name Optional[str] Optional name of the parent catalog that the markdown controls will replace required set_parameters bool set the parameters in the control to the values in the markdown yaml header required regenerate bool whether to regenerate the uuid's in the catalog required version Optional[str] version for the assembled catalog required Returns: Type Description int 0 on success, 1 otherwise Notes If the destination catalog_name model already exists in the trestle project, it is overwritten. If a parent catalog is not specified, the assembled catalog will be used as the parent if it exists. If no parent catalog name is available, the catalog is created anew using only the markdown content. Source code in trestle/core/commands/author/catalog.py @staticmethod def assemble_catalog ( trestle_root : pathlib . Path , md_name : str , assem_cat_name : str , parent_cat_name : Optional [ str ], set_parameters : bool , regenerate : bool , version : Optional [ str ] ) -> int : \"\"\" Assemble the markdown directory into a json catalog model file. Args: trestle_root: The trestle root directory md_name: The name of the directory containing the markdown control files for the ssp assem_cat_name: The output name of the catalog model to be created from the assembly parent_cat_name: Optional name of the parent catalog that the markdown controls will replace set_parameters: set the parameters in the control to the values in the markdown yaml header regenerate: whether to regenerate the uuid's in the catalog version: version for the assembled catalog Returns: 0 on success, 1 otherwise Notes: If the destination catalog_name model already exists in the trestle project, it is overwritten. If a parent catalog is not specified, the assembled catalog will be used as the parent if it exists. If no parent catalog name is available, the catalog is created anew using only the markdown content. \"\"\" md_dir = trestle_root / md_name if not md_dir . exists (): raise TrestleError ( f 'Markdown directory { md_name } does not exist.' ) # assemble the markdown controls into md_catalog md_catalog_interface = CatalogInterface () try : md_catalog = md_catalog_interface . read_catalog_from_markdown ( md_dir , set_parameters ) except Exception as e : raise TrestleError ( f 'Error reading catalog from markdown { md_dir } : { e } ' ) if md_catalog_interface . get_count_of_controls_in_catalog ( True ) == 0 : raise TrestleError ( f 'No controls were loaded from markdown { md_dir } . No catalog created.' ) # this is None if it doesn't exist yet assem_cat_path = ModelUtils . full_path_for_top_level_model ( trestle_root , assem_cat_name , Catalog ) # if original cat is not specified, use the assembled cat but only if it already exists if not parent_cat_name and assem_cat_path : parent_cat_name = assem_cat_name # default to JSON but allow override later if other file type found new_content_type = FileContentType . JSON # if we have parent catalog then merge the markdown controls into it # the parent can be a separate catalog or the destination assembled catalog if it exists # but this is the catalog that the markdown is merged into in memory if parent_cat_name : parent_cat , parent_cat_path = ModelUtils . load_top_level_model ( trestle_root , parent_cat_name , Catalog ) parent_cat_interface = CatalogInterface ( parent_cat ) # merge the just-read md catalog into the original json parent_cat_interface . merge_catalog ( md_catalog , set_parameters ) md_catalog = parent_cat_interface . get_catalog () new_content_type = FileContentType . path_to_content_type ( parent_cat_path ) if version : md_catalog . metadata . version = com . Version ( __root__ = version ) # now check the destination catalog to see if the in-memory catalog matches it if assem_cat_path : new_content_type = FileContentType . path_to_content_type ( assem_cat_path ) _ , _ , existing_cat = ModelUtils . load_distributed ( assem_cat_path , trestle_root ) if ModelUtils . models_are_equivalent ( existing_cat , md_catalog ): logger . info ( 'Assembled catalog is not different from existing version, so no update.' ) return CmdReturnCodes . SUCCESS . value if regenerate : md_catalog , _ , _ = ModelUtils . regenerate_uuids ( md_catalog ) ModelUtils . update_last_modified ( md_catalog ) # we still may not know the assem_cat_path but can now create it with file content type assem_cat_path = ModelUtils . path_for_top_level_model ( trestle_root , assem_cat_name , Catalog , new_content_type ) if assem_cat_path . parent . exists (): logger . info ( 'Creating catalog from markdown and destination catalog exists, so updating.' ) shutil . rmtree ( str ( assem_cat_path . parent )) assem_cat_path . parent . mkdir ( parents = True , exist_ok = True ) md_catalog . oscal_write ( assem_cat_path . parent / 'catalog.json' ) return CmdReturnCodes . SUCCESS . value CatalogGenerate ( AuthorCommonCommand ) \u00a4 Generate Catalog controls in markdown form from a catalog in the trestle workspace. Source code in trestle/core/commands/author/catalog.py class CatalogGenerate ( AuthorCommonCommand ): \"\"\"Generate Catalog controls in markdown form from a catalog in the trestle workspace.\"\"\" name = 'catalog-generate' def _init_arguments ( self ) -> None : name_help_str = 'Name of the catalog model in the trestle workspace' self . add_argument ( '-n' , '--name' , help = name_help_str , required = True , type = str ) self . add_argument ( '-o' , '--output' , help = const . HELP_MARKDOWN_NAME , required = True , type = str ) self . add_argument ( '-y' , '--yaml-header' , help = const . HELP_YAML_PATH , required = False , type = str ) self . add_argument ( '-ohv' , '--overwrite-header-values' , help = const . HELP_OVERWRITE_HEADER_VALUES , required = False , action = 'store_true' , default = False ) def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) trestle_root = args . trestle_root if not file_utils . is_directory_name_allowed ( args . output ): raise TrestleError ( f ' { args . output } is not an allowed directory name' ) yaml_header : dict = {} if args . yaml_header : try : logging . debug ( f 'Loading yaml header file { args . yaml_header } ' ) yaml = YAML ( typ = 'safe' ) yaml_header = yaml . load ( pathlib . Path ( args . yaml_header ) . open ( 'r' )) except YAMLError as e : raise TrestleError ( f 'YAML error loading yaml header { args . yaml_header } for ssp generation: { e } ' ) catalog_path = trestle_root / f 'catalogs/ { args . name } /catalog.json' markdown_path = trestle_root / args . output return self . generate_markdown ( trestle_root , catalog_path , markdown_path , yaml_header , args . overwrite_header_values ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error occurred when generating markdown for catalog' ) def generate_markdown ( self , trestle_root : pathlib . Path , catalog_path : pathlib . Path , markdown_path : pathlib . Path , yaml_header : dict , overwrite_header_values : bool ) -> int : \"\"\"Generate markdown for the controls in the catalog.\"\"\" try : _ , _ , catalog = ModelUtils . load_distributed ( catalog_path , trestle_root ) catalog_interface = CatalogInterface ( catalog ) catalog_interface . write_catalog_as_markdown ( md_path = markdown_path , yaml_header = yaml_header , sections_dict = None , prompt_responses = False , additional_content = False , profile = None , overwrite_header_values = overwrite_header_values , set_parameters = True , required_sections = None ) except TrestleNotFoundError as e : raise TrestleError ( f 'Catalog { catalog_path } not found for load: { e } ' ) except Exception as e : raise TrestleError ( f 'Error generating markdown for controls in { catalog_path } : { e } ' ) return CmdReturnCodes . SUCCESS . value name \u00a4 Methods \u00a4 generate_markdown ( self , trestle_root , catalog_path , markdown_path , yaml_header , overwrite_header_values ) \u00a4 Generate markdown for the controls in the catalog. Source code in trestle/core/commands/author/catalog.py def generate_markdown ( self , trestle_root : pathlib . Path , catalog_path : pathlib . Path , markdown_path : pathlib . Path , yaml_header : dict , overwrite_header_values : bool ) -> int : \"\"\"Generate markdown for the controls in the catalog.\"\"\" try : _ , _ , catalog = ModelUtils . load_distributed ( catalog_path , trestle_root ) catalog_interface = CatalogInterface ( catalog ) catalog_interface . write_catalog_as_markdown ( md_path = markdown_path , yaml_header = yaml_header , sections_dict = None , prompt_responses = False , additional_content = False , profile = None , overwrite_header_values = overwrite_header_values , set_parameters = True , required_sections = None ) except TrestleNotFoundError as e : raise TrestleError ( f 'Catalog { catalog_path } not found for load: { e } ' ) except Exception as e : raise TrestleError ( f 'Error generating markdown for controls in { catalog_path } : { e } ' ) return CmdReturnCodes . SUCCESS . value handler: python","title":"catalog"},{"location":"api_reference/trestle.core.commands.author.catalog/#trestle.core.commands.author.catalog","text":"Author commands to generate catalog controls as markdown and assemble them back to json.","title":"catalog"},{"location":"api_reference/trestle.core.commands.author.catalog/#trestle.core.commands.author.catalog.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.author.catalog/#trestle.core.commands.author.catalog-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.author.catalog/#trestle.core.commands.author.catalog.CatalogAssemble","text":"Assemble markdown files of controls into a Catalog json file. Source code in trestle/core/commands/author/catalog.py class CatalogAssemble ( AuthorCommonCommand ): \"\"\"Assemble markdown files of controls into a Catalog json file.\"\"\" name = 'catalog-assemble' def _init_arguments ( self ) -> None : name_help_str = ( 'Optional name of the catalog model in the trestle workspace that is being modified. ' 'If not provided the output name is used.' ) self . add_argument ( '-n' , '--name' , help = name_help_str , required = False , type = str ) file_help_str = 'Name of the input markdown file directory' self . add_argument ( '-m' , '--markdown' , help = file_help_str , required = True , type = str ) output_help_str = 'Name of the output generated json Catalog' self . add_argument ( '-o' , '--output' , help = output_help_str , required = True , type = str ) self . add_argument ( '-sp' , '--set-parameters' , action = 'store_true' , help = const . HELP_SET_PARAMS , required = False ) self . add_argument ( '-r' , '--regenerate' , action = 'store_true' , help = const . HELP_REGENERATE ) self . add_argument ( '-vn' , '--version' , help = const . HELP_VERSION , required = False , type = str ) def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) trestle_root = pathlib . Path ( args . trestle_root ) return CatalogAssemble . assemble_catalog ( trestle_root = trestle_root , md_name = args . markdown , assem_cat_name = args . output , parent_cat_name = args . name , set_parameters = args . set_parameters , regenerate = args . regenerate , version = args . version ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error occurred while assembling catalog' ) @staticmethod def assemble_catalog ( trestle_root : pathlib . Path , md_name : str , assem_cat_name : str , parent_cat_name : Optional [ str ], set_parameters : bool , regenerate : bool , version : Optional [ str ] ) -> int : \"\"\" Assemble the markdown directory into a json catalog model file. Args: trestle_root: The trestle root directory md_name: The name of the directory containing the markdown control files for the ssp assem_cat_name: The output name of the catalog model to be created from the assembly parent_cat_name: Optional name of the parent catalog that the markdown controls will replace set_parameters: set the parameters in the control to the values in the markdown yaml header regenerate: whether to regenerate the uuid's in the catalog version: version for the assembled catalog Returns: 0 on success, 1 otherwise Notes: If the destination catalog_name model already exists in the trestle project, it is overwritten. If a parent catalog is not specified, the assembled catalog will be used as the parent if it exists. If no parent catalog name is available, the catalog is created anew using only the markdown content. \"\"\" md_dir = trestle_root / md_name if not md_dir . exists (): raise TrestleError ( f 'Markdown directory { md_name } does not exist.' ) # assemble the markdown controls into md_catalog md_catalog_interface = CatalogInterface () try : md_catalog = md_catalog_interface . read_catalog_from_markdown ( md_dir , set_parameters ) except Exception as e : raise TrestleError ( f 'Error reading catalog from markdown { md_dir } : { e } ' ) if md_catalog_interface . get_count_of_controls_in_catalog ( True ) == 0 : raise TrestleError ( f 'No controls were loaded from markdown { md_dir } . No catalog created.' ) # this is None if it doesn't exist yet assem_cat_path = ModelUtils . full_path_for_top_level_model ( trestle_root , assem_cat_name , Catalog ) # if original cat is not specified, use the assembled cat but only if it already exists if not parent_cat_name and assem_cat_path : parent_cat_name = assem_cat_name # default to JSON but allow override later if other file type found new_content_type = FileContentType . JSON # if we have parent catalog then merge the markdown controls into it # the parent can be a separate catalog or the destination assembled catalog if it exists # but this is the catalog that the markdown is merged into in memory if parent_cat_name : parent_cat , parent_cat_path = ModelUtils . load_top_level_model ( trestle_root , parent_cat_name , Catalog ) parent_cat_interface = CatalogInterface ( parent_cat ) # merge the just-read md catalog into the original json parent_cat_interface . merge_catalog ( md_catalog , set_parameters ) md_catalog = parent_cat_interface . get_catalog () new_content_type = FileContentType . path_to_content_type ( parent_cat_path ) if version : md_catalog . metadata . version = com . Version ( __root__ = version ) # now check the destination catalog to see if the in-memory catalog matches it if assem_cat_path : new_content_type = FileContentType . path_to_content_type ( assem_cat_path ) _ , _ , existing_cat = ModelUtils . load_distributed ( assem_cat_path , trestle_root ) if ModelUtils . models_are_equivalent ( existing_cat , md_catalog ): logger . info ( 'Assembled catalog is not different from existing version, so no update.' ) return CmdReturnCodes . SUCCESS . value if regenerate : md_catalog , _ , _ = ModelUtils . regenerate_uuids ( md_catalog ) ModelUtils . update_last_modified ( md_catalog ) # we still may not know the assem_cat_path but can now create it with file content type assem_cat_path = ModelUtils . path_for_top_level_model ( trestle_root , assem_cat_name , Catalog , new_content_type ) if assem_cat_path . parent . exists (): logger . info ( 'Creating catalog from markdown and destination catalog exists, so updating.' ) shutil . rmtree ( str ( assem_cat_path . parent )) assem_cat_path . parent . mkdir ( parents = True , exist_ok = True ) md_catalog . oscal_write ( assem_cat_path . parent / 'catalog.json' ) return CmdReturnCodes . SUCCESS . value","title":"CatalogAssemble"},{"location":"api_reference/trestle.core.commands.author.catalog/#trestle.core.commands.author.catalog.CatalogAssemble.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.author.catalog/#trestle.core.commands.author.catalog.CatalogAssemble-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.author.catalog/#trestle.core.commands.author.catalog.CatalogAssemble.assemble_catalog","text":"Assemble the markdown directory into a json catalog model file. Parameters: Name Type Description Default trestle_root Path The trestle root directory required md_name str The name of the directory containing the markdown control files for the ssp required assem_cat_name str The output name of the catalog model to be created from the assembly required parent_cat_name Optional[str] Optional name of the parent catalog that the markdown controls will replace required set_parameters bool set the parameters in the control to the values in the markdown yaml header required regenerate bool whether to regenerate the uuid's in the catalog required version Optional[str] version for the assembled catalog required Returns: Type Description int 0 on success, 1 otherwise Notes If the destination catalog_name model already exists in the trestle project, it is overwritten. If a parent catalog is not specified, the assembled catalog will be used as the parent if it exists. If no parent catalog name is available, the catalog is created anew using only the markdown content. Source code in trestle/core/commands/author/catalog.py @staticmethod def assemble_catalog ( trestle_root : pathlib . Path , md_name : str , assem_cat_name : str , parent_cat_name : Optional [ str ], set_parameters : bool , regenerate : bool , version : Optional [ str ] ) -> int : \"\"\" Assemble the markdown directory into a json catalog model file. Args: trestle_root: The trestle root directory md_name: The name of the directory containing the markdown control files for the ssp assem_cat_name: The output name of the catalog model to be created from the assembly parent_cat_name: Optional name of the parent catalog that the markdown controls will replace set_parameters: set the parameters in the control to the values in the markdown yaml header regenerate: whether to regenerate the uuid's in the catalog version: version for the assembled catalog Returns: 0 on success, 1 otherwise Notes: If the destination catalog_name model already exists in the trestle project, it is overwritten. If a parent catalog is not specified, the assembled catalog will be used as the parent if it exists. If no parent catalog name is available, the catalog is created anew using only the markdown content. \"\"\" md_dir = trestle_root / md_name if not md_dir . exists (): raise TrestleError ( f 'Markdown directory { md_name } does not exist.' ) # assemble the markdown controls into md_catalog md_catalog_interface = CatalogInterface () try : md_catalog = md_catalog_interface . read_catalog_from_markdown ( md_dir , set_parameters ) except Exception as e : raise TrestleError ( f 'Error reading catalog from markdown { md_dir } : { e } ' ) if md_catalog_interface . get_count_of_controls_in_catalog ( True ) == 0 : raise TrestleError ( f 'No controls were loaded from markdown { md_dir } . No catalog created.' ) # this is None if it doesn't exist yet assem_cat_path = ModelUtils . full_path_for_top_level_model ( trestle_root , assem_cat_name , Catalog ) # if original cat is not specified, use the assembled cat but only if it already exists if not parent_cat_name and assem_cat_path : parent_cat_name = assem_cat_name # default to JSON but allow override later if other file type found new_content_type = FileContentType . JSON # if we have parent catalog then merge the markdown controls into it # the parent can be a separate catalog or the destination assembled catalog if it exists # but this is the catalog that the markdown is merged into in memory if parent_cat_name : parent_cat , parent_cat_path = ModelUtils . load_top_level_model ( trestle_root , parent_cat_name , Catalog ) parent_cat_interface = CatalogInterface ( parent_cat ) # merge the just-read md catalog into the original json parent_cat_interface . merge_catalog ( md_catalog , set_parameters ) md_catalog = parent_cat_interface . get_catalog () new_content_type = FileContentType . path_to_content_type ( parent_cat_path ) if version : md_catalog . metadata . version = com . Version ( __root__ = version ) # now check the destination catalog to see if the in-memory catalog matches it if assem_cat_path : new_content_type = FileContentType . path_to_content_type ( assem_cat_path ) _ , _ , existing_cat = ModelUtils . load_distributed ( assem_cat_path , trestle_root ) if ModelUtils . models_are_equivalent ( existing_cat , md_catalog ): logger . info ( 'Assembled catalog is not different from existing version, so no update.' ) return CmdReturnCodes . SUCCESS . value if regenerate : md_catalog , _ , _ = ModelUtils . regenerate_uuids ( md_catalog ) ModelUtils . update_last_modified ( md_catalog ) # we still may not know the assem_cat_path but can now create it with file content type assem_cat_path = ModelUtils . path_for_top_level_model ( trestle_root , assem_cat_name , Catalog , new_content_type ) if assem_cat_path . parent . exists (): logger . info ( 'Creating catalog from markdown and destination catalog exists, so updating.' ) shutil . rmtree ( str ( assem_cat_path . parent )) assem_cat_path . parent . mkdir ( parents = True , exist_ok = True ) md_catalog . oscal_write ( assem_cat_path . parent / 'catalog.json' ) return CmdReturnCodes . SUCCESS . value","title":"assemble_catalog()"},{"location":"api_reference/trestle.core.commands.author.catalog/#trestle.core.commands.author.catalog.CatalogGenerate","text":"Generate Catalog controls in markdown form from a catalog in the trestle workspace. Source code in trestle/core/commands/author/catalog.py class CatalogGenerate ( AuthorCommonCommand ): \"\"\"Generate Catalog controls in markdown form from a catalog in the trestle workspace.\"\"\" name = 'catalog-generate' def _init_arguments ( self ) -> None : name_help_str = 'Name of the catalog model in the trestle workspace' self . add_argument ( '-n' , '--name' , help = name_help_str , required = True , type = str ) self . add_argument ( '-o' , '--output' , help = const . HELP_MARKDOWN_NAME , required = True , type = str ) self . add_argument ( '-y' , '--yaml-header' , help = const . HELP_YAML_PATH , required = False , type = str ) self . add_argument ( '-ohv' , '--overwrite-header-values' , help = const . HELP_OVERWRITE_HEADER_VALUES , required = False , action = 'store_true' , default = False ) def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) trestle_root = args . trestle_root if not file_utils . is_directory_name_allowed ( args . output ): raise TrestleError ( f ' { args . output } is not an allowed directory name' ) yaml_header : dict = {} if args . yaml_header : try : logging . debug ( f 'Loading yaml header file { args . yaml_header } ' ) yaml = YAML ( typ = 'safe' ) yaml_header = yaml . load ( pathlib . Path ( args . yaml_header ) . open ( 'r' )) except YAMLError as e : raise TrestleError ( f 'YAML error loading yaml header { args . yaml_header } for ssp generation: { e } ' ) catalog_path = trestle_root / f 'catalogs/ { args . name } /catalog.json' markdown_path = trestle_root / args . output return self . generate_markdown ( trestle_root , catalog_path , markdown_path , yaml_header , args . overwrite_header_values ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error occurred when generating markdown for catalog' ) def generate_markdown ( self , trestle_root : pathlib . Path , catalog_path : pathlib . Path , markdown_path : pathlib . Path , yaml_header : dict , overwrite_header_values : bool ) -> int : \"\"\"Generate markdown for the controls in the catalog.\"\"\" try : _ , _ , catalog = ModelUtils . load_distributed ( catalog_path , trestle_root ) catalog_interface = CatalogInterface ( catalog ) catalog_interface . write_catalog_as_markdown ( md_path = markdown_path , yaml_header = yaml_header , sections_dict = None , prompt_responses = False , additional_content = False , profile = None , overwrite_header_values = overwrite_header_values , set_parameters = True , required_sections = None ) except TrestleNotFoundError as e : raise TrestleError ( f 'Catalog { catalog_path } not found for load: { e } ' ) except Exception as e : raise TrestleError ( f 'Error generating markdown for controls in { catalog_path } : { e } ' ) return CmdReturnCodes . SUCCESS . value","title":"CatalogGenerate"},{"location":"api_reference/trestle.core.commands.author.catalog/#trestle.core.commands.author.catalog.CatalogGenerate.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.author.catalog/#trestle.core.commands.author.catalog.CatalogGenerate-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.author.catalog/#trestle.core.commands.author.catalog.CatalogGenerate.generate_markdown","text":"Generate markdown for the controls in the catalog. Source code in trestle/core/commands/author/catalog.py def generate_markdown ( self , trestle_root : pathlib . Path , catalog_path : pathlib . Path , markdown_path : pathlib . Path , yaml_header : dict , overwrite_header_values : bool ) -> int : \"\"\"Generate markdown for the controls in the catalog.\"\"\" try : _ , _ , catalog = ModelUtils . load_distributed ( catalog_path , trestle_root ) catalog_interface = CatalogInterface ( catalog ) catalog_interface . write_catalog_as_markdown ( md_path = markdown_path , yaml_header = yaml_header , sections_dict = None , prompt_responses = False , additional_content = False , profile = None , overwrite_header_values = overwrite_header_values , set_parameters = True , required_sections = None ) except TrestleNotFoundError as e : raise TrestleError ( f 'Catalog { catalog_path } not found for load: { e } ' ) except Exception as e : raise TrestleError ( f 'Error generating markdown for controls in { catalog_path } : { e } ' ) return CmdReturnCodes . SUCCESS . value handler: python","title":"generate_markdown()"},{"location":"api_reference/trestle.core.commands.author.command/","text":"trestle.core.commands.author.command \u00a4 Trestle author command. Umbrella command for all markdown related transformations logger \u00a4 Classes \u00a4 AuthorCmd ( CommandPlusDocs ) \u00a4 trestle author, a collection of commands for authoring compliance content outside of OSCAL. Source code in trestle/core/commands/author/command.py class AuthorCmd ( CommandPlusDocs ): \"\"\"trestle author, a collection of commands for authoring compliance content outside of OSCAL.\"\"\" name = 'author' subcommands = [ CatalogAssemble , CatalogGenerate , Docs , Folders , Headers , JinjaCmd , ProfileAssemble , ProfileGenerate , SSPAssemble , SSPFilter , SSPGenerate ] name \u00a4 subcommands \u00a4 handler: python","title":"command"},{"location":"api_reference/trestle.core.commands.author.command/#trestle.core.commands.author.command","text":"Trestle author command. Umbrella command for all markdown related transformations","title":"command"},{"location":"api_reference/trestle.core.commands.author.command/#trestle.core.commands.author.command.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.author.command/#trestle.core.commands.author.command-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.author.command/#trestle.core.commands.author.command.AuthorCmd","text":"trestle author, a collection of commands for authoring compliance content outside of OSCAL. Source code in trestle/core/commands/author/command.py class AuthorCmd ( CommandPlusDocs ): \"\"\"trestle author, a collection of commands for authoring compliance content outside of OSCAL.\"\"\" name = 'author' subcommands = [ CatalogAssemble , CatalogGenerate , Docs , Folders , Headers , JinjaCmd , ProfileAssemble , ProfileGenerate , SSPAssemble , SSPFilter , SSPGenerate ]","title":"AuthorCmd"},{"location":"api_reference/trestle.core.commands.author.command/#trestle.core.commands.author.command.AuthorCmd.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.author.command/#trestle.core.commands.author.command.AuthorCmd.subcommands","text":"handler: python","title":"subcommands"},{"location":"api_reference/trestle.core.commands.author.common/","text":"trestle.core.commands.author.common \u00a4 AuthorCommonCommands - reusable utilities to increase code base abstraction for author command. logger \u00a4 Classes \u00a4 AuthorCommonCommand ( CommandPlusDocs ) \u00a4 Extension for the subset of commands that operate using the common mode structure. Source code in trestle/core/commands/author/common.py class AuthorCommonCommand ( CommandPlusDocs ): \"\"\"Extension for the subset of commands that operate using the common mode structure.\"\"\" trestle_root : pathlib . Path task_name : str def _initialize ( self , args : argparse . Namespace ) -> int : log . set_log_level_from_args ( args ) # Externalize self . trestle_root = args . trestle_root self . task_name = args . task_name try : self . global_ = args . __getattribute__ ( 'global' ) except AttributeError : self . global_ = None if self . task_name : self . task_path = self . trestle_root / self . task_name if not file_utils . is_directory_name_allowed ( self . task_name ): logger . error ( f 'Task name { self . task_name } is invalid as it interferes with OSCAL and trestle reserved names.' ) return CmdReturnCodes . COMMAND_ERROR . value rc = self . _setup_template_dir ( args ) return rc def rel_dir ( self , path : pathlib . Path ) -> str : \"\"\"Stringify a directory relative to trestle root.\"\"\" return str ( path . relative_to ( self . trestle_root )) def _setup_template_dir ( self , args : argparse . Namespace ) -> int : \"\"\"Set template directory and update to new format.\"\"\" if not self . global_ and self . task_name is None : logger . error ( 'At least a global flag or a task name should be provided.' ) return CmdReturnCodes . INCORRECT_ARGS . value if self . global_ : old_template_dir = self . trestle_root / TRESTLE_CONFIG_DIR / 'author' / '__global__' self . _set_template_version_to_latest ( args , old_template_dir ) self . template_dir = old_template_dir / args . template_version elif self . task_name and not self . global_ : old_template_dir = self . trestle_root / TRESTLE_CONFIG_DIR / 'author' / self . task_name self . _set_template_version_to_latest ( args , old_template_dir ) self . template_dir = old_template_dir / args . template_version if old_template_dir . exists (): TemplateVersioning . validate_template_folder ( old_template_dir ) TemplateVersioning . update_template_folder_structure ( old_template_dir ) return CmdReturnCodes . SUCCESS . value def _set_template_version_to_latest ( self , args : argparse . Namespace , template_dir : pathlib . Path ): \"\"\"Set template version argument to the latest version if none was given.\"\"\" if not TemplateVersioning . is_valid_version ( args . template_version ): raise TrestleError ( f 'Version { args . template_version } is invalid, version format should be: 0.0.1' ) if args . template_version is None and args . mode == ARG_VALIDATE : # in validate mode no version will validate instances based on header version args . template_version = '' if args . template_version is None : args . template_version = START_TEMPLATE_VERSION if template_dir . exists (): all_versions = TemplateVersioning . get_all_versions_for_task ( template_dir ) if all_versions : args . template_version = max ( all_versions ) if args . template_version == '' : logger . info ( 'Instances will be validated against template version specified in their headers.' ) else : logger . info ( f 'Set template version to { args . template_version } .' ) Methods \u00a4 rel_dir ( self , path ) \u00a4 Stringify a directory relative to trestle root. Source code in trestle/core/commands/author/common.py def rel_dir ( self , path : pathlib . Path ) -> str : \"\"\"Stringify a directory relative to trestle root.\"\"\" return str ( path . relative_to ( self . trestle_root )) handler: python","title":"common"},{"location":"api_reference/trestle.core.commands.author.common/#trestle.core.commands.author.common","text":"AuthorCommonCommands - reusable utilities to increase code base abstraction for author command.","title":"common"},{"location":"api_reference/trestle.core.commands.author.common/#trestle.core.commands.author.common.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.author.common/#trestle.core.commands.author.common-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.author.common/#trestle.core.commands.author.common.AuthorCommonCommand","text":"Extension for the subset of commands that operate using the common mode structure. Source code in trestle/core/commands/author/common.py class AuthorCommonCommand ( CommandPlusDocs ): \"\"\"Extension for the subset of commands that operate using the common mode structure.\"\"\" trestle_root : pathlib . Path task_name : str def _initialize ( self , args : argparse . Namespace ) -> int : log . set_log_level_from_args ( args ) # Externalize self . trestle_root = args . trestle_root self . task_name = args . task_name try : self . global_ = args . __getattribute__ ( 'global' ) except AttributeError : self . global_ = None if self . task_name : self . task_path = self . trestle_root / self . task_name if not file_utils . is_directory_name_allowed ( self . task_name ): logger . error ( f 'Task name { self . task_name } is invalid as it interferes with OSCAL and trestle reserved names.' ) return CmdReturnCodes . COMMAND_ERROR . value rc = self . _setup_template_dir ( args ) return rc def rel_dir ( self , path : pathlib . Path ) -> str : \"\"\"Stringify a directory relative to trestle root.\"\"\" return str ( path . relative_to ( self . trestle_root )) def _setup_template_dir ( self , args : argparse . Namespace ) -> int : \"\"\"Set template directory and update to new format.\"\"\" if not self . global_ and self . task_name is None : logger . error ( 'At least a global flag or a task name should be provided.' ) return CmdReturnCodes . INCORRECT_ARGS . value if self . global_ : old_template_dir = self . trestle_root / TRESTLE_CONFIG_DIR / 'author' / '__global__' self . _set_template_version_to_latest ( args , old_template_dir ) self . template_dir = old_template_dir / args . template_version elif self . task_name and not self . global_ : old_template_dir = self . trestle_root / TRESTLE_CONFIG_DIR / 'author' / self . task_name self . _set_template_version_to_latest ( args , old_template_dir ) self . template_dir = old_template_dir / args . template_version if old_template_dir . exists (): TemplateVersioning . validate_template_folder ( old_template_dir ) TemplateVersioning . update_template_folder_structure ( old_template_dir ) return CmdReturnCodes . SUCCESS . value def _set_template_version_to_latest ( self , args : argparse . Namespace , template_dir : pathlib . Path ): \"\"\"Set template version argument to the latest version if none was given.\"\"\" if not TemplateVersioning . is_valid_version ( args . template_version ): raise TrestleError ( f 'Version { args . template_version } is invalid, version format should be: 0.0.1' ) if args . template_version is None and args . mode == ARG_VALIDATE : # in validate mode no version will validate instances based on header version args . template_version = '' if args . template_version is None : args . template_version = START_TEMPLATE_VERSION if template_dir . exists (): all_versions = TemplateVersioning . get_all_versions_for_task ( template_dir ) if all_versions : args . template_version = max ( all_versions ) if args . template_version == '' : logger . info ( 'Instances will be validated against template version specified in their headers.' ) else : logger . info ( f 'Set template version to { args . template_version } .' )","title":"AuthorCommonCommand"},{"location":"api_reference/trestle.core.commands.author.common/#trestle.core.commands.author.common.AuthorCommonCommand-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.author.common/#trestle.core.commands.author.common.AuthorCommonCommand.rel_dir","text":"Stringify a directory relative to trestle root. Source code in trestle/core/commands/author/common.py def rel_dir ( self , path : pathlib . Path ) -> str : \"\"\"Stringify a directory relative to trestle root.\"\"\" return str ( path . relative_to ( self . trestle_root )) handler: python","title":"rel_dir()"},{"location":"api_reference/trestle.core.commands.author.consts/","text":"trestle.core.commands.author.consts \u00a4 Constants associated with trestle author commands to decrease duplication. EXCLUDE_HELP \u00a4 EXCLUDE_LONG \u00a4 EXCLUDE_SHORT \u00a4 GH_HELP \u00a4 GH_LONG \u00a4 GH_SHORT \u00a4 GLOBAL_HELP \u00a4 GLOBAL_LONG \u00a4 GLOBAL_SHORT \u00a4 HEADER_VALIDATE_HELP \u00a4 HOV_HELP \u00a4 HOV_LONG \u00a4 HOV_SHORT \u00a4 IGNORE_HELP \u00a4 LONG_HEADER_VALIDATE \u00a4 LONG_IGNORE \u00a4 LONG_README_VALIDATE \u00a4 LONG_TEMPLATE_VERSION \u00a4 MODE_ARG_NAME \u00a4 MODE_CHOICES \u00a4 README_VALIDATE_FOLDERS_HELP \u00a4 README_VALIDATE_HELP \u00a4 RECURSE_HELP \u00a4 RECURSE_LONG \u00a4 RECURSE_SHORT \u00a4 REFERENCE_TEMPLATES \u00a4 SHORT_HEADER_VALIDATE \u00a4 SHORT_IGNORE \u00a4 SHORT_README_VALIDATE \u00a4 SHORT_TEMPLATE_VERSION \u00a4 START_TEMPLATE_VERSION \u00a4 TASK_NAME_LONG \u00a4 TASK_NAME_SHORT \u00a4 TEMPLATE_VERSION_HEADER \u00a4 TEMPLATE_VERSION_HELP \u00a4 TRESTLE_RESOURCES \u00a4 handler: python","title":"consts"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts","text":"Constants associated with trestle author commands to decrease duplication.","title":"consts"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.EXCLUDE_HELP","text":"","title":"EXCLUDE_HELP"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.EXCLUDE_LONG","text":"","title":"EXCLUDE_LONG"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.EXCLUDE_SHORT","text":"","title":"EXCLUDE_SHORT"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.GH_HELP","text":"","title":"GH_HELP"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.GH_LONG","text":"","title":"GH_LONG"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.GH_SHORT","text":"","title":"GH_SHORT"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.GLOBAL_HELP","text":"","title":"GLOBAL_HELP"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.GLOBAL_LONG","text":"","title":"GLOBAL_LONG"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.GLOBAL_SHORT","text":"","title":"GLOBAL_SHORT"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.HEADER_VALIDATE_HELP","text":"","title":"HEADER_VALIDATE_HELP"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.HOV_HELP","text":"","title":"HOV_HELP"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.HOV_LONG","text":"","title":"HOV_LONG"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.HOV_SHORT","text":"","title":"HOV_SHORT"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.IGNORE_HELP","text":"","title":"IGNORE_HELP"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.LONG_HEADER_VALIDATE","text":"","title":"LONG_HEADER_VALIDATE"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.LONG_IGNORE","text":"","title":"LONG_IGNORE"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.LONG_README_VALIDATE","text":"","title":"LONG_README_VALIDATE"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.LONG_TEMPLATE_VERSION","text":"","title":"LONG_TEMPLATE_VERSION"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.MODE_ARG_NAME","text":"","title":"MODE_ARG_NAME"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.MODE_CHOICES","text":"","title":"MODE_CHOICES"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.README_VALIDATE_FOLDERS_HELP","text":"","title":"README_VALIDATE_FOLDERS_HELP"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.README_VALIDATE_HELP","text":"","title":"README_VALIDATE_HELP"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.RECURSE_HELP","text":"","title":"RECURSE_HELP"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.RECURSE_LONG","text":"","title":"RECURSE_LONG"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.RECURSE_SHORT","text":"","title":"RECURSE_SHORT"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.REFERENCE_TEMPLATES","text":"","title":"REFERENCE_TEMPLATES"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.SHORT_HEADER_VALIDATE","text":"","title":"SHORT_HEADER_VALIDATE"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.SHORT_IGNORE","text":"","title":"SHORT_IGNORE"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.SHORT_README_VALIDATE","text":"","title":"SHORT_README_VALIDATE"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.SHORT_TEMPLATE_VERSION","text":"","title":"SHORT_TEMPLATE_VERSION"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.START_TEMPLATE_VERSION","text":"","title":"START_TEMPLATE_VERSION"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.TASK_NAME_LONG","text":"","title":"TASK_NAME_LONG"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.TASK_NAME_SHORT","text":"","title":"TASK_NAME_SHORT"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.TEMPLATE_VERSION_HEADER","text":"","title":"TEMPLATE_VERSION_HEADER"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.TEMPLATE_VERSION_HELP","text":"","title":"TEMPLATE_VERSION_HELP"},{"location":"api_reference/trestle.core.commands.author.consts/#trestle.core.commands.author.consts.TRESTLE_RESOURCES","text":"handler: python","title":"TRESTLE_RESOURCES"},{"location":"api_reference/trestle.core.commands.author.docs/","text":"trestle.core.commands.author.docs \u00a4 Trestle author docs sub-command. logger \u00a4 Classes \u00a4 Docs ( AuthorCommonCommand ) \u00a4 Markdown governed documents - enforcing consistent markdown across a set of files. Source code in trestle/core/commands/author/docs.py class Docs ( AuthorCommonCommand ): \"\"\"Markdown governed documents - enforcing consistent markdown across a set of files.\"\"\" name = 'docs' template_name = 'template.md' def _init_arguments ( self ) -> None : self . add_argument ( author_const . GH_SHORT , author_const . GH_LONG , help = author_const . GH_HELP , default = None , type = str ) self . add_argument ( author_const . SHORT_HEADER_VALIDATE , author_const . LONG_HEADER_VALIDATE , help = author_const . HEADER_VALIDATE_HELP , action = 'store_true' ) self . add_argument ( author_const . SHORT_TEMPLATE_VERSION , author_const . LONG_TEMPLATE_VERSION , help = author_const . TEMPLATE_VERSION_HELP , action = 'store' ) self . add_argument ( author_const . HOV_SHORT , author_const . HOV_LONG , help = author_const . HOV_HELP , action = 'store_true' ) self . add_argument ( author_const . SHORT_IGNORE , author_const . LONG_IGNORE , help = author_const . IGNORE_HELP , default = None , type = str ) self . add_argument ( author_const . RECURSE_SHORT , author_const . RECURSE_LONG , help = author_const . RECURSE_HELP , action = 'store_true' ) self . add_argument ( author_const . MODE_ARG_NAME , choices = author_const . MODE_CHOICES ) tn_help_str = ' \\n ' . join ( [ 'The name of the the task to be governed.' , '' 'The template file is at .trestle/author/[task-name]/template.md' , 'Note that by default this will automatically enforce the task.' ] ) self . add_argument ( author_const . TASK_NAME_SHORT , author_const . TASK_NAME_LONG , help = tn_help_str , required = True , type = str ) self . add_argument ( author_const . SHORT_README_VALIDATE , author_const . LONG_README_VALIDATE , help = author_const . README_VALIDATE_HELP , action = 'store_true' ) def _run ( self , args : argparse . Namespace ) -> int : try : status = 1 if self . _initialize ( args ): return status if args . mode == 'create-sample' : status = self . create_sample () elif args . mode == 'template-validate' : status = self . template_validate ( args . governed_heading , args . header_validate , args . header_only_validate , ) elif args . mode == 'setup' : status = self . setup_template_governed_docs ( args . template_version ) elif args . mode == 'validate' : # mode is validate status = self . validate ( args . governed_heading , args . header_validate , args . header_only_validate , args . recurse , args . readme_validate , args . template_version , args . ignore ) return status except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error occurred when running trestle author docs' ) def setup_template_governed_docs ( self , template_version : str ) -> int : \"\"\"Create structure to allow markdown template enforcement. Returns: Unix return code. \"\"\" if not self . task_path . exists (): self . task_path . mkdir ( exist_ok = True , parents = True ) elif self . task_path . is_file (): raise TrestleError ( f 'Task path: { self . rel_dir ( self . task_path ) } is a file not a directory.' ) if not self . template_dir . exists (): self . template_dir . mkdir ( exist_ok = True , parents = True ) elif self . template_dir . is_file (): raise TrestleError ( f 'Template path: { self . rel_dir ( self . template_dir ) } is a file not a directory.' ) logger . debug ( self . template_dir ) if not self . _validate_template_dir (): raise TrestleError ( 'Aborting setup' ) template_file = self . template_dir / self . template_name if template_file . is_file (): return CmdReturnCodes . SUCCESS . value TemplateVersioning . write_versioned_template ( 'template.md' , self . template_dir , template_file , template_version ) logger . info ( f 'Template file setup for task { self . task_name } at { self . rel_dir ( template_file ) } ' ) logger . info ( f 'Task directory is { self . rel_dir ( self . task_path ) } ' ) return CmdReturnCodes . SUCCESS . value def create_sample ( self ) -> int : \"\"\"Presuming the template exists, copy into a sample markdown file with an index.\"\"\" template_file = self . template_dir / self . template_name if not self . _validate_template_dir (): raise TrestleError ( 'Aborting setup' ) if not template_file . is_file (): raise TrestleError ( 'No template file ... exiting.' ) index = 0 while True : candidate_task = self . task_path / f ' { self . task_name } _ { index : 03d } .md' if candidate_task . is_file (): index = index + 1 else : shutil . copy ( str ( template_file ), str ( candidate_task )) break return CmdReturnCodes . SUCCESS . value def template_validate ( self , heading : str , validate_header : bool , validate_only_header : bool ) -> int : \"\"\"Validate that the template is acceptable markdown.\"\"\" template_file = self . template_dir / self . template_name if not self . _validate_template_dir (): raise TrestleError ( 'Aborting setup' ) if not template_file . is_file (): raise TrestleError ( f 'Required template file: { self . rel_dir ( template_file ) } does not exist. Exiting.' ) try : md_api = MarkdownAPI () md_api . load_validator_with_template ( template_file , validate_header , validate_only_header , heading ) except Exception as ex : raise TrestleError ( f 'Template for task { self . task_name } failed to validate due to { ex } ' ) logger . info ( f 'TEMPLATES VALID: { self . task_name } ' ) return CmdReturnCodes . SUCCESS . value def _validate_template_dir ( self ) -> bool : \"\"\"Template directory should only have template file.\"\"\" for child in file_utils . iterdir_without_hidden_files ( self . template_dir ): # Only allowable template file in the directory is the template directory. if child . name != self . template_name and child . name . lower () != 'readme.md' : logger . warning ( f 'Unknown file: { child . name } in template directory { self . rel_dir ( self . template_dir ) } ' ) return False return True def _validate_dir ( self , governed_heading : str , md_dir : pathlib . Path , validate_header : bool , validate_only_header : bool , recurse : bool , readme_validate : bool , template_version : Optional [ str ] = None , ignore : Optional [ str ] = None ) -> int : \"\"\" Validate md files in a directory with option to recurse. Template version will be fetched from the instance header. \"\"\" # status is a linux returncode status = 0 for item_path in md_dir . iterdir (): if file_utils . is_local_and_visible ( item_path ): if item_path . is_file (): if not item_path . suffix == '.md' : logger . info ( f 'Unexpected file { self . rel_dir ( item_path ) } in folder { self . rel_dir ( md_dir ) } , skipping.' ) continue if not readme_validate and item_path . name . lower () == 'readme.md' : continue if ignore : p = re . compile ( ignore ) matched = p . match ( item_path . parts [ - 1 ]) if matched is not None : logger . info ( f 'Ignoring file { item_path } from validation.' ) continue md_api = MarkdownAPI () if template_version != '' : template_file = self . template_dir / self . template_name else : instance_version = md_api . processor . fetch_value_from_header ( item_path , author_const . TEMPLATE_VERSION_HEADER ) if instance_version is None : instance_version = '0.0.1' versione_template_dir = TemplateVersioning . get_versioned_template_dir ( self . template_dir , instance_version ) template_file = versione_template_dir / self . template_name if not template_file . is_file (): raise TrestleError ( f 'Required template file: { self . rel_dir ( template_file ) } does not exist. Exiting.' ) md_api . load_validator_with_template ( template_file , validate_header , not validate_only_header , governed_heading ) if not md_api . validate_instance ( item_path ): logger . info ( f 'INVALID: { self . rel_dir ( item_path ) } ' ) status = 1 else : logger . info ( f 'VALID: { self . rel_dir ( item_path ) } ' ) elif recurse : if ignore : p = re . compile ( ignore ) if len ( list ( filter ( p . match , str ( item_path . relative_to ( md_dir )) . split ( '/' )))) > 0 : logger . info ( f 'Ignoring directory { item_path } from validation.' ) continue rc = self . _validate_dir ( governed_heading , item_path , validate_header , validate_only_header , recurse , readme_validate , template_version , ignore ) if rc != 0 : status = rc return status def validate ( self , governed_heading : str , validate_header : bool , validate_only_header : bool , recurse : bool , readme_validate : bool , template_version : str , ignore : str ) -> int : \"\"\" Validate task. Args: governed_heading: A heading for which structural enforcement (see online docs). validate_header: Whether or not to validate the key structure of the yaml header to the markdown document. validate_only_header: Whether to validate just the yaml header. recurse: Whether to allow validated files to be in a directory tree. readme_validate: Whether to validate readme files, otherwise they will be ignored. Returns: Return code to be used for the command. \"\"\" if not self . task_path . is_dir (): raise TrestleError ( f 'Task directory { self . rel_dir ( self . task_path ) } does not exist. Exiting validate.' ) return self . _validate_dir ( governed_heading , self . task_path , validate_header , validate_only_header , recurse , readme_validate , template_version , ignore ) name \u00a4 template_name \u00a4 Methods \u00a4 create_sample ( self ) \u00a4 Presuming the template exists, copy into a sample markdown file with an index. Source code in trestle/core/commands/author/docs.py def create_sample ( self ) -> int : \"\"\"Presuming the template exists, copy into a sample markdown file with an index.\"\"\" template_file = self . template_dir / self . template_name if not self . _validate_template_dir (): raise TrestleError ( 'Aborting setup' ) if not template_file . is_file (): raise TrestleError ( 'No template file ... exiting.' ) index = 0 while True : candidate_task = self . task_path / f ' { self . task_name } _ { index : 03d } .md' if candidate_task . is_file (): index = index + 1 else : shutil . copy ( str ( template_file ), str ( candidate_task )) break return CmdReturnCodes . SUCCESS . value setup_template_governed_docs ( self , template_version ) \u00a4 Create structure to allow markdown template enforcement. Returns: Type Description int Unix return code. Source code in trestle/core/commands/author/docs.py def setup_template_governed_docs ( self , template_version : str ) -> int : \"\"\"Create structure to allow markdown template enforcement. Returns: Unix return code. \"\"\" if not self . task_path . exists (): self . task_path . mkdir ( exist_ok = True , parents = True ) elif self . task_path . is_file (): raise TrestleError ( f 'Task path: { self . rel_dir ( self . task_path ) } is a file not a directory.' ) if not self . template_dir . exists (): self . template_dir . mkdir ( exist_ok = True , parents = True ) elif self . template_dir . is_file (): raise TrestleError ( f 'Template path: { self . rel_dir ( self . template_dir ) } is a file not a directory.' ) logger . debug ( self . template_dir ) if not self . _validate_template_dir (): raise TrestleError ( 'Aborting setup' ) template_file = self . template_dir / self . template_name if template_file . is_file (): return CmdReturnCodes . SUCCESS . value TemplateVersioning . write_versioned_template ( 'template.md' , self . template_dir , template_file , template_version ) logger . info ( f 'Template file setup for task { self . task_name } at { self . rel_dir ( template_file ) } ' ) logger . info ( f 'Task directory is { self . rel_dir ( self . task_path ) } ' ) return CmdReturnCodes . SUCCESS . value template_validate ( self , heading , validate_header , validate_only_header ) \u00a4 Validate that the template is acceptable markdown. Source code in trestle/core/commands/author/docs.py def template_validate ( self , heading : str , validate_header : bool , validate_only_header : bool ) -> int : \"\"\"Validate that the template is acceptable markdown.\"\"\" template_file = self . template_dir / self . template_name if not self . _validate_template_dir (): raise TrestleError ( 'Aborting setup' ) if not template_file . is_file (): raise TrestleError ( f 'Required template file: { self . rel_dir ( template_file ) } does not exist. Exiting.' ) try : md_api = MarkdownAPI () md_api . load_validator_with_template ( template_file , validate_header , validate_only_header , heading ) except Exception as ex : raise TrestleError ( f 'Template for task { self . task_name } failed to validate due to { ex } ' ) logger . info ( f 'TEMPLATES VALID: { self . task_name } ' ) return CmdReturnCodes . SUCCESS . value validate ( self , governed_heading , validate_header , validate_only_header , recurse , readme_validate , template_version , ignore ) \u00a4 Validate task. Parameters: Name Type Description Default governed_heading str A heading for which structural enforcement (see online docs). required validate_header bool Whether or not to validate the key structure of the yaml header to the markdown document. required validate_only_header bool Whether to validate just the yaml header. required recurse bool Whether to allow validated files to be in a directory tree. required readme_validate bool Whether to validate readme files, otherwise they will be ignored. required Returns: Type Description int Return code to be used for the command. Source code in trestle/core/commands/author/docs.py def validate ( self , governed_heading : str , validate_header : bool , validate_only_header : bool , recurse : bool , readme_validate : bool , template_version : str , ignore : str ) -> int : \"\"\" Validate task. Args: governed_heading: A heading for which structural enforcement (see online docs). validate_header: Whether or not to validate the key structure of the yaml header to the markdown document. validate_only_header: Whether to validate just the yaml header. recurse: Whether to allow validated files to be in a directory tree. readme_validate: Whether to validate readme files, otherwise they will be ignored. Returns: Return code to be used for the command. \"\"\" if not self . task_path . is_dir (): raise TrestleError ( f 'Task directory { self . rel_dir ( self . task_path ) } does not exist. Exiting validate.' ) return self . _validate_dir ( governed_heading , self . task_path , validate_header , validate_only_header , recurse , readme_validate , template_version , ignore ) handler: python","title":"docs"},{"location":"api_reference/trestle.core.commands.author.docs/#trestle.core.commands.author.docs","text":"Trestle author docs sub-command.","title":"docs"},{"location":"api_reference/trestle.core.commands.author.docs/#trestle.core.commands.author.docs.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.author.docs/#trestle.core.commands.author.docs-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.author.docs/#trestle.core.commands.author.docs.Docs","text":"Markdown governed documents - enforcing consistent markdown across a set of files. Source code in trestle/core/commands/author/docs.py class Docs ( AuthorCommonCommand ): \"\"\"Markdown governed documents - enforcing consistent markdown across a set of files.\"\"\" name = 'docs' template_name = 'template.md' def _init_arguments ( self ) -> None : self . add_argument ( author_const . GH_SHORT , author_const . GH_LONG , help = author_const . GH_HELP , default = None , type = str ) self . add_argument ( author_const . SHORT_HEADER_VALIDATE , author_const . LONG_HEADER_VALIDATE , help = author_const . HEADER_VALIDATE_HELP , action = 'store_true' ) self . add_argument ( author_const . SHORT_TEMPLATE_VERSION , author_const . LONG_TEMPLATE_VERSION , help = author_const . TEMPLATE_VERSION_HELP , action = 'store' ) self . add_argument ( author_const . HOV_SHORT , author_const . HOV_LONG , help = author_const . HOV_HELP , action = 'store_true' ) self . add_argument ( author_const . SHORT_IGNORE , author_const . LONG_IGNORE , help = author_const . IGNORE_HELP , default = None , type = str ) self . add_argument ( author_const . RECURSE_SHORT , author_const . RECURSE_LONG , help = author_const . RECURSE_HELP , action = 'store_true' ) self . add_argument ( author_const . MODE_ARG_NAME , choices = author_const . MODE_CHOICES ) tn_help_str = ' \\n ' . join ( [ 'The name of the the task to be governed.' , '' 'The template file is at .trestle/author/[task-name]/template.md' , 'Note that by default this will automatically enforce the task.' ] ) self . add_argument ( author_const . TASK_NAME_SHORT , author_const . TASK_NAME_LONG , help = tn_help_str , required = True , type = str ) self . add_argument ( author_const . SHORT_README_VALIDATE , author_const . LONG_README_VALIDATE , help = author_const . README_VALIDATE_HELP , action = 'store_true' ) def _run ( self , args : argparse . Namespace ) -> int : try : status = 1 if self . _initialize ( args ): return status if args . mode == 'create-sample' : status = self . create_sample () elif args . mode == 'template-validate' : status = self . template_validate ( args . governed_heading , args . header_validate , args . header_only_validate , ) elif args . mode == 'setup' : status = self . setup_template_governed_docs ( args . template_version ) elif args . mode == 'validate' : # mode is validate status = self . validate ( args . governed_heading , args . header_validate , args . header_only_validate , args . recurse , args . readme_validate , args . template_version , args . ignore ) return status except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error occurred when running trestle author docs' ) def setup_template_governed_docs ( self , template_version : str ) -> int : \"\"\"Create structure to allow markdown template enforcement. Returns: Unix return code. \"\"\" if not self . task_path . exists (): self . task_path . mkdir ( exist_ok = True , parents = True ) elif self . task_path . is_file (): raise TrestleError ( f 'Task path: { self . rel_dir ( self . task_path ) } is a file not a directory.' ) if not self . template_dir . exists (): self . template_dir . mkdir ( exist_ok = True , parents = True ) elif self . template_dir . is_file (): raise TrestleError ( f 'Template path: { self . rel_dir ( self . template_dir ) } is a file not a directory.' ) logger . debug ( self . template_dir ) if not self . _validate_template_dir (): raise TrestleError ( 'Aborting setup' ) template_file = self . template_dir / self . template_name if template_file . is_file (): return CmdReturnCodes . SUCCESS . value TemplateVersioning . write_versioned_template ( 'template.md' , self . template_dir , template_file , template_version ) logger . info ( f 'Template file setup for task { self . task_name } at { self . rel_dir ( template_file ) } ' ) logger . info ( f 'Task directory is { self . rel_dir ( self . task_path ) } ' ) return CmdReturnCodes . SUCCESS . value def create_sample ( self ) -> int : \"\"\"Presuming the template exists, copy into a sample markdown file with an index.\"\"\" template_file = self . template_dir / self . template_name if not self . _validate_template_dir (): raise TrestleError ( 'Aborting setup' ) if not template_file . is_file (): raise TrestleError ( 'No template file ... exiting.' ) index = 0 while True : candidate_task = self . task_path / f ' { self . task_name } _ { index : 03d } .md' if candidate_task . is_file (): index = index + 1 else : shutil . copy ( str ( template_file ), str ( candidate_task )) break return CmdReturnCodes . SUCCESS . value def template_validate ( self , heading : str , validate_header : bool , validate_only_header : bool ) -> int : \"\"\"Validate that the template is acceptable markdown.\"\"\" template_file = self . template_dir / self . template_name if not self . _validate_template_dir (): raise TrestleError ( 'Aborting setup' ) if not template_file . is_file (): raise TrestleError ( f 'Required template file: { self . rel_dir ( template_file ) } does not exist. Exiting.' ) try : md_api = MarkdownAPI () md_api . load_validator_with_template ( template_file , validate_header , validate_only_header , heading ) except Exception as ex : raise TrestleError ( f 'Template for task { self . task_name } failed to validate due to { ex } ' ) logger . info ( f 'TEMPLATES VALID: { self . task_name } ' ) return CmdReturnCodes . SUCCESS . value def _validate_template_dir ( self ) -> bool : \"\"\"Template directory should only have template file.\"\"\" for child in file_utils . iterdir_without_hidden_files ( self . template_dir ): # Only allowable template file in the directory is the template directory. if child . name != self . template_name and child . name . lower () != 'readme.md' : logger . warning ( f 'Unknown file: { child . name } in template directory { self . rel_dir ( self . template_dir ) } ' ) return False return True def _validate_dir ( self , governed_heading : str , md_dir : pathlib . Path , validate_header : bool , validate_only_header : bool , recurse : bool , readme_validate : bool , template_version : Optional [ str ] = None , ignore : Optional [ str ] = None ) -> int : \"\"\" Validate md files in a directory with option to recurse. Template version will be fetched from the instance header. \"\"\" # status is a linux returncode status = 0 for item_path in md_dir . iterdir (): if file_utils . is_local_and_visible ( item_path ): if item_path . is_file (): if not item_path . suffix == '.md' : logger . info ( f 'Unexpected file { self . rel_dir ( item_path ) } in folder { self . rel_dir ( md_dir ) } , skipping.' ) continue if not readme_validate and item_path . name . lower () == 'readme.md' : continue if ignore : p = re . compile ( ignore ) matched = p . match ( item_path . parts [ - 1 ]) if matched is not None : logger . info ( f 'Ignoring file { item_path } from validation.' ) continue md_api = MarkdownAPI () if template_version != '' : template_file = self . template_dir / self . template_name else : instance_version = md_api . processor . fetch_value_from_header ( item_path , author_const . TEMPLATE_VERSION_HEADER ) if instance_version is None : instance_version = '0.0.1' versione_template_dir = TemplateVersioning . get_versioned_template_dir ( self . template_dir , instance_version ) template_file = versione_template_dir / self . template_name if not template_file . is_file (): raise TrestleError ( f 'Required template file: { self . rel_dir ( template_file ) } does not exist. Exiting.' ) md_api . load_validator_with_template ( template_file , validate_header , not validate_only_header , governed_heading ) if not md_api . validate_instance ( item_path ): logger . info ( f 'INVALID: { self . rel_dir ( item_path ) } ' ) status = 1 else : logger . info ( f 'VALID: { self . rel_dir ( item_path ) } ' ) elif recurse : if ignore : p = re . compile ( ignore ) if len ( list ( filter ( p . match , str ( item_path . relative_to ( md_dir )) . split ( '/' )))) > 0 : logger . info ( f 'Ignoring directory { item_path } from validation.' ) continue rc = self . _validate_dir ( governed_heading , item_path , validate_header , validate_only_header , recurse , readme_validate , template_version , ignore ) if rc != 0 : status = rc return status def validate ( self , governed_heading : str , validate_header : bool , validate_only_header : bool , recurse : bool , readme_validate : bool , template_version : str , ignore : str ) -> int : \"\"\" Validate task. Args: governed_heading: A heading for which structural enforcement (see online docs). validate_header: Whether or not to validate the key structure of the yaml header to the markdown document. validate_only_header: Whether to validate just the yaml header. recurse: Whether to allow validated files to be in a directory tree. readme_validate: Whether to validate readme files, otherwise they will be ignored. Returns: Return code to be used for the command. \"\"\" if not self . task_path . is_dir (): raise TrestleError ( f 'Task directory { self . rel_dir ( self . task_path ) } does not exist. Exiting validate.' ) return self . _validate_dir ( governed_heading , self . task_path , validate_header , validate_only_header , recurse , readme_validate , template_version , ignore )","title":"Docs"},{"location":"api_reference/trestle.core.commands.author.docs/#trestle.core.commands.author.docs.Docs.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.author.docs/#trestle.core.commands.author.docs.Docs.template_name","text":"","title":"template_name"},{"location":"api_reference/trestle.core.commands.author.docs/#trestle.core.commands.author.docs.Docs-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.author.docs/#trestle.core.commands.author.docs.Docs.create_sample","text":"Presuming the template exists, copy into a sample markdown file with an index. Source code in trestle/core/commands/author/docs.py def create_sample ( self ) -> int : \"\"\"Presuming the template exists, copy into a sample markdown file with an index.\"\"\" template_file = self . template_dir / self . template_name if not self . _validate_template_dir (): raise TrestleError ( 'Aborting setup' ) if not template_file . is_file (): raise TrestleError ( 'No template file ... exiting.' ) index = 0 while True : candidate_task = self . task_path / f ' { self . task_name } _ { index : 03d } .md' if candidate_task . is_file (): index = index + 1 else : shutil . copy ( str ( template_file ), str ( candidate_task )) break return CmdReturnCodes . SUCCESS . value","title":"create_sample()"},{"location":"api_reference/trestle.core.commands.author.docs/#trestle.core.commands.author.docs.Docs.setup_template_governed_docs","text":"Create structure to allow markdown template enforcement. Returns: Type Description int Unix return code. Source code in trestle/core/commands/author/docs.py def setup_template_governed_docs ( self , template_version : str ) -> int : \"\"\"Create structure to allow markdown template enforcement. Returns: Unix return code. \"\"\" if not self . task_path . exists (): self . task_path . mkdir ( exist_ok = True , parents = True ) elif self . task_path . is_file (): raise TrestleError ( f 'Task path: { self . rel_dir ( self . task_path ) } is a file not a directory.' ) if not self . template_dir . exists (): self . template_dir . mkdir ( exist_ok = True , parents = True ) elif self . template_dir . is_file (): raise TrestleError ( f 'Template path: { self . rel_dir ( self . template_dir ) } is a file not a directory.' ) logger . debug ( self . template_dir ) if not self . _validate_template_dir (): raise TrestleError ( 'Aborting setup' ) template_file = self . template_dir / self . template_name if template_file . is_file (): return CmdReturnCodes . SUCCESS . value TemplateVersioning . write_versioned_template ( 'template.md' , self . template_dir , template_file , template_version ) logger . info ( f 'Template file setup for task { self . task_name } at { self . rel_dir ( template_file ) } ' ) logger . info ( f 'Task directory is { self . rel_dir ( self . task_path ) } ' ) return CmdReturnCodes . SUCCESS . value","title":"setup_template_governed_docs()"},{"location":"api_reference/trestle.core.commands.author.docs/#trestle.core.commands.author.docs.Docs.template_validate","text":"Validate that the template is acceptable markdown. Source code in trestle/core/commands/author/docs.py def template_validate ( self , heading : str , validate_header : bool , validate_only_header : bool ) -> int : \"\"\"Validate that the template is acceptable markdown.\"\"\" template_file = self . template_dir / self . template_name if not self . _validate_template_dir (): raise TrestleError ( 'Aborting setup' ) if not template_file . is_file (): raise TrestleError ( f 'Required template file: { self . rel_dir ( template_file ) } does not exist. Exiting.' ) try : md_api = MarkdownAPI () md_api . load_validator_with_template ( template_file , validate_header , validate_only_header , heading ) except Exception as ex : raise TrestleError ( f 'Template for task { self . task_name } failed to validate due to { ex } ' ) logger . info ( f 'TEMPLATES VALID: { self . task_name } ' ) return CmdReturnCodes . SUCCESS . value","title":"template_validate()"},{"location":"api_reference/trestle.core.commands.author.docs/#trestle.core.commands.author.docs.Docs.validate","text":"Validate task. Parameters: Name Type Description Default governed_heading str A heading for which structural enforcement (see online docs). required validate_header bool Whether or not to validate the key structure of the yaml header to the markdown document. required validate_only_header bool Whether to validate just the yaml header. required recurse bool Whether to allow validated files to be in a directory tree. required readme_validate bool Whether to validate readme files, otherwise they will be ignored. required Returns: Type Description int Return code to be used for the command. Source code in trestle/core/commands/author/docs.py def validate ( self , governed_heading : str , validate_header : bool , validate_only_header : bool , recurse : bool , readme_validate : bool , template_version : str , ignore : str ) -> int : \"\"\" Validate task. Args: governed_heading: A heading for which structural enforcement (see online docs). validate_header: Whether or not to validate the key structure of the yaml header to the markdown document. validate_only_header: Whether to validate just the yaml header. recurse: Whether to allow validated files to be in a directory tree. readme_validate: Whether to validate readme files, otherwise they will be ignored. Returns: Return code to be used for the command. \"\"\" if not self . task_path . is_dir (): raise TrestleError ( f 'Task directory { self . rel_dir ( self . task_path ) } does not exist. Exiting validate.' ) return self . _validate_dir ( governed_heading , self . task_path , validate_header , validate_only_header , recurse , readme_validate , template_version , ignore ) handler: python","title":"validate()"},{"location":"api_reference/trestle.core.commands.author.folders/","text":"trestle.core.commands.author.folders \u00a4 Trestle author docs sub-command. logger \u00a4 Classes \u00a4 Folders ( AuthorCommonCommand ) \u00a4 Markdown governed folders - enforcing consistent files and templates across directories. Source code in trestle/core/commands/author/folders.py class Folders ( AuthorCommonCommand ): \"\"\"Markdown governed folders - enforcing consistent files and templates across directories.\"\"\" name = 'folders' def _init_arguments ( self ) -> None : self . add_argument ( author_const . GH_SHORT , author_const . GH_LONG , help = author_const . GH_HELP , default = None , type = str ) self . add_argument ( author_const . SHORT_HEADER_VALIDATE , author_const . LONG_HEADER_VALIDATE , help = author_const . HEADER_VALIDATE_HELP , action = 'store_true' ) self . add_argument ( author_const . HOV_SHORT , author_const . HOV_LONG , help = author_const . HOV_HELP , action = 'store_true' ) self . add_argument ( author_const . SHORT_TEMPLATE_VERSION , author_const . LONG_TEMPLATE_VERSION , help = author_const . TEMPLATE_VERSION_HELP , action = 'store' ) self . add_argument ( author_const . SHORT_IGNORE , author_const . LONG_IGNORE , help = author_const . IGNORE_HELP , default = None , type = str ) self . add_argument ( author_const . MODE_ARG_NAME , choices = author_const . MODE_CHOICES ) tn_help_str = ' \\n ' . join ( [ 'The name of the the task to be governed.' , '' , 'The template files are at .trestle/author/[task-name],' , 'where the directory tree established and the markdown files within that directory' + 'tree are enforced.' ] ) self . add_argument ( author_const . TASK_NAME_SHORT , author_const . TASK_NAME_LONG , help = tn_help_str , required = True , type = str ) self . add_argument ( author_const . SHORT_README_VALIDATE , author_const . LONG_README_VALIDATE , help = author_const . README_VALIDATE_FOLDERS_HELP , action = 'store_true' ) def _run ( self , args : argparse . Namespace ) -> int : try : if self . _initialize ( args ): raise TrestleError ( f 'Error when initializing trestle folders command with args: { args } ' ) if args . mode == 'create-sample' : status = self . create_sample () elif args . mode == 'template-validate' : status = self . template_validate ( args . header_validate , args . header_only_validate , args . governed_heading , args . readme_validate ) elif args . mode == 'setup' : status = self . setup_template ( args . template_version ) elif args . mode == 'validate' : # mode is validate status = self . validate ( args . header_validate , args . header_only_validate , args . governed_heading , args . readme_validate , args . template_version , args . ignore ) else : raise TrestleIncorrectArgsError ( f 'Unsupported mode: { args . mode } for folders command.' ) return status except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error occurred when running trestle author folders' ) def setup_template ( self , template_version : str ) -> int : \"\"\"Create structure to allow markdown template enforcement.\"\"\" if not self . task_path . exists (): self . task_path . mkdir ( exist_ok = True , parents = True ) elif self . task_path . is_file (): raise TrestleError ( f 'Task path: { self . rel_dir ( self . task_path ) } is a file not a directory.' ) if not self . template_dir . exists (): self . template_dir . mkdir ( exist_ok = True , parents = True ) elif self . template_dir . is_file (): raise TrestleError ( f 'Template path: { self . rel_dir ( self . template_dir ) } is a file not a directory.' ) template_file_a_md = self . template_dir / 'a_template.md' template_file_another_md = self . template_dir / 'another_template.md' template_file_drawio = self . template_dir / 'architecture.drawio' TemplateVersioning . write_versioned_template ( 'template.md' , self . template_dir , template_file_a_md , template_version ) TemplateVersioning . write_versioned_template ( 'template.md' , self . template_dir , template_file_another_md , template_version ) TemplateVersioning . write_versioned_template ( 'template.drawio' , self . template_dir , template_file_drawio , template_version ) return CmdReturnCodes . SUCCESS . value def template_validate ( self , validate_header : bool , validate_only_header : bool , heading : str , readme_validate : bool ) -> int : \"\"\"Validate that the template is acceptable markdown.\"\"\" if not self . template_dir . is_dir (): raise TrestleError ( f 'Template directory { self . rel_dir ( self . template_dir ) } for task { self . task_name } does not exist.' ) # get list of files: template_files = self . template_dir . rglob ( '*' ) for template_file in template_files : try : if not file_utils . is_local_and_visible ( template_file ): continue elif template_file . is_dir (): continue elif template_file . suffix . lower () == '.md' : if not readme_validate and template_file . name == 'readme.md' : raise TrestleError ( 'Template directory contains a readme.md file and readme validation is off.' ) md_api = MarkdownAPI () md_api . load_validator_with_template ( template_file , validate_header , not validate_only_header , heading ) elif template_file . suffix . lower () . lstrip ( '.' ) == 'drawio' : _ = draw_io . DrawIOMetadataValidator ( template_file ) else : logger . info ( f 'File: { self . rel_dir ( template_file ) } within the template directory was ignored' + 'as it is not markdown.' ) except Exception as ex : raise TrestleError ( f 'Template file { self . rel_dir ( template_file ) } for task { self . task_name } ' + f ' failed to validate due to { ex } ' ) logger . info ( f 'TEMPLATES VALID: { self . task_name } .' ) return CmdReturnCodes . SUCCESS . value def _measure_template_folder ( self , instance_dir : pathlib . Path , validate_header : bool , validate_only_header : bool , governed_heading : str , readme_validate : bool , template_version : str , ignore : str ) -> bool : \"\"\" Validate instances against templates. Validation will succeed iff: 1. All template files from the specified version are present in the task 2. All of the instances are valid \"\"\" all_versioned_templates = {} instance_version = template_version instance_file_names : List [ pathlib . Path ] = [] # Fetch all instances versions and build dictionary of required template files for instance_file in instance_dir . iterdir (): if not file_utils . is_local_and_visible ( instance_file ): continue if not instance_file . is_file (): continue if instance_file . name . lower () == 'readme.md' and not readme_validate : continue if ignore : p = re . compile ( ignore ) matched = p . match ( instance_file . parts [ - 1 ]) if matched is not None : logger . info ( f 'Ignoring file { instance_file } from validation.' ) continue instance_file_name = instance_file . relative_to ( instance_dir ) instance_file_names . append ( instance_file_name ) if instance_file . suffix == '.md' : md_api = MarkdownAPI () versioned_template_dir = None if template_version != '' : template_file = self . template_dir / instance_file_name versioned_template_dir = self . template_dir else : instance_version = md_api . processor . fetch_value_from_header ( instance_file , author_const . TEMPLATE_VERSION_HEADER ) if instance_version is None : instance_version = '0.0.1' # backward compatibility versioned_template_dir = TemplateVersioning . get_versioned_template_dir ( self . template_dir , instance_version ) template_file = versioned_template_dir / instance_file_name if instance_version not in all_versioned_templates . keys (): templates = list ( filter ( lambda p : file_utils . is_local_and_visible ( p ), versioned_template_dir . iterdir ()) ) if not readme_validate : templates = list ( filter ( lambda p : p . name . lower () != 'readme.md' , templates )) all_versioned_templates [ instance_version ] = dict . fromkeys ( [ t . relative_to ( versioned_template_dir ) for t in templates ], False ) if instance_file_name in all_versioned_templates [ instance_version ]: # validate md_api . load_validator_with_template ( template_file , validate_header , not validate_only_header , governed_heading ) status = md_api . validate_instance ( instance_file ) if not status : logger . warning ( f 'INVALID: Markdown file { instance_file } failed validation against' + f ' { template_file } ' ) return False else : logger . info ( f 'VALID: { instance_file } ' ) # mark template as present all_versioned_templates [ instance_version ][ instance_file_name ] = True elif instance_file . suffix == '.drawio' : drawio = draw_io . DrawIO ( instance_file ) metadata = drawio . get_metadata ()[ 0 ] versioned_template_dir = None if template_version != '' : template_file = self . template_dir / instance_file_name versioned_template_dir = self . template_dir else : if author_const . TEMPLATE_VERSION_HEADER in metadata . keys (): instance_version = metadata [ author_const . TEMPLATE_VERSION_HEADER ] else : instance_version = '0.0.1' # backward compatibility versioned_template_dir = TemplateVersioning . get_versioned_template_dir ( self . template_dir , instance_version ) template_file = versioned_template_dir / instance_file_name if instance_version not in all_versioned_templates . keys (): templates = list ( filter ( lambda p : file_utils . is_local_and_visible ( p ), versioned_template_dir . iterdir ()) ) if not readme_validate : templates = list ( filter ( lambda p : p . name . lower () != 'readme.md' , templates )) all_versioned_templates [ instance_version ] = dict . fromkeys ( [ t . relative_to ( versioned_template_dir ) for t in templates ], False ) if instance_file_name in all_versioned_templates [ instance_version ]: # validate drawio_validator = draw_io . DrawIOMetadataValidator ( template_file ) status = drawio_validator . validate ( instance_file ) if not status : logger . warning ( f 'INVALID: Drawio file { instance_file } failed validation against' + f ' { template_file } ' ) return False else : logger . info ( f 'VALID: { instance_file } ' ) # mark template as present all_versioned_templates [ instance_version ][ instance_file_name ] = True else : logger . debug ( f 'Unsupported extension of the instance file: { instance_file } , will not be validated.' ) # Check that all template files are present for version in all_versioned_templates . keys (): for template in all_versioned_templates [ version ]: if not all_versioned_templates [ version ][ template ]: logger . warning ( f 'Required template file { template } does not exist in measured instance' + f ' { instance_dir } ' ) return False return True def create_sample ( self ) -> int : \"\"\" Create a sample folder within the task and populate with template content. Returns: Unix return code for running sample as a command. \"\"\" ii = 0 while True : sample_path = self . task_path / f 'sample_folder_ { ii } ' if sample_path . exists (): ii = ii + 1 continue shutil . copytree ( str ( self . template_dir ), str ( sample_path )) return CmdReturnCodes . SUCCESS . value def validate ( self , validate_header : bool , validate_only_header : bool , governed_heading : str , readme_validate : bool , template_version : str , ignore : str ) -> int : \"\"\"Validate task.\"\"\" if not self . task_path . is_dir (): raise TrestleError ( f 'Task directory { self . task_path } does not exist. Exiting validate.' ) for task_instance in self . task_path . iterdir (): if task_instance . is_dir (): if file_utils . is_symlink ( task_instance ): continue result = self . _measure_template_folder ( task_instance , validate_header , validate_only_header , governed_heading , readme_validate , template_version , ignore ) if not result : raise TrestleError ( 'Governed-folder validation failed for task' + f ' { self . task_name } on directory { self . rel_dir ( task_instance ) } ' ) else : logger . warning ( f 'Unexpected file { self . rel_dir ( task_instance ) } identified in { self . task_name } ' + ' directory, ignoring.' ) return CmdReturnCodes . SUCCESS . value name \u00a4 Methods \u00a4 create_sample ( self ) \u00a4 Create a sample folder within the task and populate with template content. Returns: Type Description int Unix return code for running sample as a command. Source code in trestle/core/commands/author/folders.py def create_sample ( self ) -> int : \"\"\" Create a sample folder within the task and populate with template content. Returns: Unix return code for running sample as a command. \"\"\" ii = 0 while True : sample_path = self . task_path / f 'sample_folder_ { ii } ' if sample_path . exists (): ii = ii + 1 continue shutil . copytree ( str ( self . template_dir ), str ( sample_path )) return CmdReturnCodes . SUCCESS . value setup_template ( self , template_version ) \u00a4 Create structure to allow markdown template enforcement. Source code in trestle/core/commands/author/folders.py def setup_template ( self , template_version : str ) -> int : \"\"\"Create structure to allow markdown template enforcement.\"\"\" if not self . task_path . exists (): self . task_path . mkdir ( exist_ok = True , parents = True ) elif self . task_path . is_file (): raise TrestleError ( f 'Task path: { self . rel_dir ( self . task_path ) } is a file not a directory.' ) if not self . template_dir . exists (): self . template_dir . mkdir ( exist_ok = True , parents = True ) elif self . template_dir . is_file (): raise TrestleError ( f 'Template path: { self . rel_dir ( self . template_dir ) } is a file not a directory.' ) template_file_a_md = self . template_dir / 'a_template.md' template_file_another_md = self . template_dir / 'another_template.md' template_file_drawio = self . template_dir / 'architecture.drawio' TemplateVersioning . write_versioned_template ( 'template.md' , self . template_dir , template_file_a_md , template_version ) TemplateVersioning . write_versioned_template ( 'template.md' , self . template_dir , template_file_another_md , template_version ) TemplateVersioning . write_versioned_template ( 'template.drawio' , self . template_dir , template_file_drawio , template_version ) return CmdReturnCodes . SUCCESS . value template_validate ( self , validate_header , validate_only_header , heading , readme_validate ) \u00a4 Validate that the template is acceptable markdown. Source code in trestle/core/commands/author/folders.py def template_validate ( self , validate_header : bool , validate_only_header : bool , heading : str , readme_validate : bool ) -> int : \"\"\"Validate that the template is acceptable markdown.\"\"\" if not self . template_dir . is_dir (): raise TrestleError ( f 'Template directory { self . rel_dir ( self . template_dir ) } for task { self . task_name } does not exist.' ) # get list of files: template_files = self . template_dir . rglob ( '*' ) for template_file in template_files : try : if not file_utils . is_local_and_visible ( template_file ): continue elif template_file . is_dir (): continue elif template_file . suffix . lower () == '.md' : if not readme_validate and template_file . name == 'readme.md' : raise TrestleError ( 'Template directory contains a readme.md file and readme validation is off.' ) md_api = MarkdownAPI () md_api . load_validator_with_template ( template_file , validate_header , not validate_only_header , heading ) elif template_file . suffix . lower () . lstrip ( '.' ) == 'drawio' : _ = draw_io . DrawIOMetadataValidator ( template_file ) else : logger . info ( f 'File: { self . rel_dir ( template_file ) } within the template directory was ignored' + 'as it is not markdown.' ) except Exception as ex : raise TrestleError ( f 'Template file { self . rel_dir ( template_file ) } for task { self . task_name } ' + f ' failed to validate due to { ex } ' ) logger . info ( f 'TEMPLATES VALID: { self . task_name } .' ) return CmdReturnCodes . SUCCESS . value validate ( self , validate_header , validate_only_header , governed_heading , readme_validate , template_version , ignore ) \u00a4 Validate task. Source code in trestle/core/commands/author/folders.py def validate ( self , validate_header : bool , validate_only_header : bool , governed_heading : str , readme_validate : bool , template_version : str , ignore : str ) -> int : \"\"\"Validate task.\"\"\" if not self . task_path . is_dir (): raise TrestleError ( f 'Task directory { self . task_path } does not exist. Exiting validate.' ) for task_instance in self . task_path . iterdir (): if task_instance . is_dir (): if file_utils . is_symlink ( task_instance ): continue result = self . _measure_template_folder ( task_instance , validate_header , validate_only_header , governed_heading , readme_validate , template_version , ignore ) if not result : raise TrestleError ( 'Governed-folder validation failed for task' + f ' { self . task_name } on directory { self . rel_dir ( task_instance ) } ' ) else : logger . warning ( f 'Unexpected file { self . rel_dir ( task_instance ) } identified in { self . task_name } ' + ' directory, ignoring.' ) return CmdReturnCodes . SUCCESS . value handler: python","title":"folders"},{"location":"api_reference/trestle.core.commands.author.folders/#trestle.core.commands.author.folders","text":"Trestle author docs sub-command.","title":"folders"},{"location":"api_reference/trestle.core.commands.author.folders/#trestle.core.commands.author.folders.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.author.folders/#trestle.core.commands.author.folders-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.author.folders/#trestle.core.commands.author.folders.Folders","text":"Markdown governed folders - enforcing consistent files and templates across directories. Source code in trestle/core/commands/author/folders.py class Folders ( AuthorCommonCommand ): \"\"\"Markdown governed folders - enforcing consistent files and templates across directories.\"\"\" name = 'folders' def _init_arguments ( self ) -> None : self . add_argument ( author_const . GH_SHORT , author_const . GH_LONG , help = author_const . GH_HELP , default = None , type = str ) self . add_argument ( author_const . SHORT_HEADER_VALIDATE , author_const . LONG_HEADER_VALIDATE , help = author_const . HEADER_VALIDATE_HELP , action = 'store_true' ) self . add_argument ( author_const . HOV_SHORT , author_const . HOV_LONG , help = author_const . HOV_HELP , action = 'store_true' ) self . add_argument ( author_const . SHORT_TEMPLATE_VERSION , author_const . LONG_TEMPLATE_VERSION , help = author_const . TEMPLATE_VERSION_HELP , action = 'store' ) self . add_argument ( author_const . SHORT_IGNORE , author_const . LONG_IGNORE , help = author_const . IGNORE_HELP , default = None , type = str ) self . add_argument ( author_const . MODE_ARG_NAME , choices = author_const . MODE_CHOICES ) tn_help_str = ' \\n ' . join ( [ 'The name of the the task to be governed.' , '' , 'The template files are at .trestle/author/[task-name],' , 'where the directory tree established and the markdown files within that directory' + 'tree are enforced.' ] ) self . add_argument ( author_const . TASK_NAME_SHORT , author_const . TASK_NAME_LONG , help = tn_help_str , required = True , type = str ) self . add_argument ( author_const . SHORT_README_VALIDATE , author_const . LONG_README_VALIDATE , help = author_const . README_VALIDATE_FOLDERS_HELP , action = 'store_true' ) def _run ( self , args : argparse . Namespace ) -> int : try : if self . _initialize ( args ): raise TrestleError ( f 'Error when initializing trestle folders command with args: { args } ' ) if args . mode == 'create-sample' : status = self . create_sample () elif args . mode == 'template-validate' : status = self . template_validate ( args . header_validate , args . header_only_validate , args . governed_heading , args . readme_validate ) elif args . mode == 'setup' : status = self . setup_template ( args . template_version ) elif args . mode == 'validate' : # mode is validate status = self . validate ( args . header_validate , args . header_only_validate , args . governed_heading , args . readme_validate , args . template_version , args . ignore ) else : raise TrestleIncorrectArgsError ( f 'Unsupported mode: { args . mode } for folders command.' ) return status except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error occurred when running trestle author folders' ) def setup_template ( self , template_version : str ) -> int : \"\"\"Create structure to allow markdown template enforcement.\"\"\" if not self . task_path . exists (): self . task_path . mkdir ( exist_ok = True , parents = True ) elif self . task_path . is_file (): raise TrestleError ( f 'Task path: { self . rel_dir ( self . task_path ) } is a file not a directory.' ) if not self . template_dir . exists (): self . template_dir . mkdir ( exist_ok = True , parents = True ) elif self . template_dir . is_file (): raise TrestleError ( f 'Template path: { self . rel_dir ( self . template_dir ) } is a file not a directory.' ) template_file_a_md = self . template_dir / 'a_template.md' template_file_another_md = self . template_dir / 'another_template.md' template_file_drawio = self . template_dir / 'architecture.drawio' TemplateVersioning . write_versioned_template ( 'template.md' , self . template_dir , template_file_a_md , template_version ) TemplateVersioning . write_versioned_template ( 'template.md' , self . template_dir , template_file_another_md , template_version ) TemplateVersioning . write_versioned_template ( 'template.drawio' , self . template_dir , template_file_drawio , template_version ) return CmdReturnCodes . SUCCESS . value def template_validate ( self , validate_header : bool , validate_only_header : bool , heading : str , readme_validate : bool ) -> int : \"\"\"Validate that the template is acceptable markdown.\"\"\" if not self . template_dir . is_dir (): raise TrestleError ( f 'Template directory { self . rel_dir ( self . template_dir ) } for task { self . task_name } does not exist.' ) # get list of files: template_files = self . template_dir . rglob ( '*' ) for template_file in template_files : try : if not file_utils . is_local_and_visible ( template_file ): continue elif template_file . is_dir (): continue elif template_file . suffix . lower () == '.md' : if not readme_validate and template_file . name == 'readme.md' : raise TrestleError ( 'Template directory contains a readme.md file and readme validation is off.' ) md_api = MarkdownAPI () md_api . load_validator_with_template ( template_file , validate_header , not validate_only_header , heading ) elif template_file . suffix . lower () . lstrip ( '.' ) == 'drawio' : _ = draw_io . DrawIOMetadataValidator ( template_file ) else : logger . info ( f 'File: { self . rel_dir ( template_file ) } within the template directory was ignored' + 'as it is not markdown.' ) except Exception as ex : raise TrestleError ( f 'Template file { self . rel_dir ( template_file ) } for task { self . task_name } ' + f ' failed to validate due to { ex } ' ) logger . info ( f 'TEMPLATES VALID: { self . task_name } .' ) return CmdReturnCodes . SUCCESS . value def _measure_template_folder ( self , instance_dir : pathlib . Path , validate_header : bool , validate_only_header : bool , governed_heading : str , readme_validate : bool , template_version : str , ignore : str ) -> bool : \"\"\" Validate instances against templates. Validation will succeed iff: 1. All template files from the specified version are present in the task 2. All of the instances are valid \"\"\" all_versioned_templates = {} instance_version = template_version instance_file_names : List [ pathlib . Path ] = [] # Fetch all instances versions and build dictionary of required template files for instance_file in instance_dir . iterdir (): if not file_utils . is_local_and_visible ( instance_file ): continue if not instance_file . is_file (): continue if instance_file . name . lower () == 'readme.md' and not readme_validate : continue if ignore : p = re . compile ( ignore ) matched = p . match ( instance_file . parts [ - 1 ]) if matched is not None : logger . info ( f 'Ignoring file { instance_file } from validation.' ) continue instance_file_name = instance_file . relative_to ( instance_dir ) instance_file_names . append ( instance_file_name ) if instance_file . suffix == '.md' : md_api = MarkdownAPI () versioned_template_dir = None if template_version != '' : template_file = self . template_dir / instance_file_name versioned_template_dir = self . template_dir else : instance_version = md_api . processor . fetch_value_from_header ( instance_file , author_const . TEMPLATE_VERSION_HEADER ) if instance_version is None : instance_version = '0.0.1' # backward compatibility versioned_template_dir = TemplateVersioning . get_versioned_template_dir ( self . template_dir , instance_version ) template_file = versioned_template_dir / instance_file_name if instance_version not in all_versioned_templates . keys (): templates = list ( filter ( lambda p : file_utils . is_local_and_visible ( p ), versioned_template_dir . iterdir ()) ) if not readme_validate : templates = list ( filter ( lambda p : p . name . lower () != 'readme.md' , templates )) all_versioned_templates [ instance_version ] = dict . fromkeys ( [ t . relative_to ( versioned_template_dir ) for t in templates ], False ) if instance_file_name in all_versioned_templates [ instance_version ]: # validate md_api . load_validator_with_template ( template_file , validate_header , not validate_only_header , governed_heading ) status = md_api . validate_instance ( instance_file ) if not status : logger . warning ( f 'INVALID: Markdown file { instance_file } failed validation against' + f ' { template_file } ' ) return False else : logger . info ( f 'VALID: { instance_file } ' ) # mark template as present all_versioned_templates [ instance_version ][ instance_file_name ] = True elif instance_file . suffix == '.drawio' : drawio = draw_io . DrawIO ( instance_file ) metadata = drawio . get_metadata ()[ 0 ] versioned_template_dir = None if template_version != '' : template_file = self . template_dir / instance_file_name versioned_template_dir = self . template_dir else : if author_const . TEMPLATE_VERSION_HEADER in metadata . keys (): instance_version = metadata [ author_const . TEMPLATE_VERSION_HEADER ] else : instance_version = '0.0.1' # backward compatibility versioned_template_dir = TemplateVersioning . get_versioned_template_dir ( self . template_dir , instance_version ) template_file = versioned_template_dir / instance_file_name if instance_version not in all_versioned_templates . keys (): templates = list ( filter ( lambda p : file_utils . is_local_and_visible ( p ), versioned_template_dir . iterdir ()) ) if not readme_validate : templates = list ( filter ( lambda p : p . name . lower () != 'readme.md' , templates )) all_versioned_templates [ instance_version ] = dict . fromkeys ( [ t . relative_to ( versioned_template_dir ) for t in templates ], False ) if instance_file_name in all_versioned_templates [ instance_version ]: # validate drawio_validator = draw_io . DrawIOMetadataValidator ( template_file ) status = drawio_validator . validate ( instance_file ) if not status : logger . warning ( f 'INVALID: Drawio file { instance_file } failed validation against' + f ' { template_file } ' ) return False else : logger . info ( f 'VALID: { instance_file } ' ) # mark template as present all_versioned_templates [ instance_version ][ instance_file_name ] = True else : logger . debug ( f 'Unsupported extension of the instance file: { instance_file } , will not be validated.' ) # Check that all template files are present for version in all_versioned_templates . keys (): for template in all_versioned_templates [ version ]: if not all_versioned_templates [ version ][ template ]: logger . warning ( f 'Required template file { template } does not exist in measured instance' + f ' { instance_dir } ' ) return False return True def create_sample ( self ) -> int : \"\"\" Create a sample folder within the task and populate with template content. Returns: Unix return code for running sample as a command. \"\"\" ii = 0 while True : sample_path = self . task_path / f 'sample_folder_ { ii } ' if sample_path . exists (): ii = ii + 1 continue shutil . copytree ( str ( self . template_dir ), str ( sample_path )) return CmdReturnCodes . SUCCESS . value def validate ( self , validate_header : bool , validate_only_header : bool , governed_heading : str , readme_validate : bool , template_version : str , ignore : str ) -> int : \"\"\"Validate task.\"\"\" if not self . task_path . is_dir (): raise TrestleError ( f 'Task directory { self . task_path } does not exist. Exiting validate.' ) for task_instance in self . task_path . iterdir (): if task_instance . is_dir (): if file_utils . is_symlink ( task_instance ): continue result = self . _measure_template_folder ( task_instance , validate_header , validate_only_header , governed_heading , readme_validate , template_version , ignore ) if not result : raise TrestleError ( 'Governed-folder validation failed for task' + f ' { self . task_name } on directory { self . rel_dir ( task_instance ) } ' ) else : logger . warning ( f 'Unexpected file { self . rel_dir ( task_instance ) } identified in { self . task_name } ' + ' directory, ignoring.' ) return CmdReturnCodes . SUCCESS . value","title":"Folders"},{"location":"api_reference/trestle.core.commands.author.folders/#trestle.core.commands.author.folders.Folders.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.author.folders/#trestle.core.commands.author.folders.Folders-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.author.folders/#trestle.core.commands.author.folders.Folders.create_sample","text":"Create a sample folder within the task and populate with template content. Returns: Type Description int Unix return code for running sample as a command. Source code in trestle/core/commands/author/folders.py def create_sample ( self ) -> int : \"\"\" Create a sample folder within the task and populate with template content. Returns: Unix return code for running sample as a command. \"\"\" ii = 0 while True : sample_path = self . task_path / f 'sample_folder_ { ii } ' if sample_path . exists (): ii = ii + 1 continue shutil . copytree ( str ( self . template_dir ), str ( sample_path )) return CmdReturnCodes . SUCCESS . value","title":"create_sample()"},{"location":"api_reference/trestle.core.commands.author.folders/#trestle.core.commands.author.folders.Folders.setup_template","text":"Create structure to allow markdown template enforcement. Source code in trestle/core/commands/author/folders.py def setup_template ( self , template_version : str ) -> int : \"\"\"Create structure to allow markdown template enforcement.\"\"\" if not self . task_path . exists (): self . task_path . mkdir ( exist_ok = True , parents = True ) elif self . task_path . is_file (): raise TrestleError ( f 'Task path: { self . rel_dir ( self . task_path ) } is a file not a directory.' ) if not self . template_dir . exists (): self . template_dir . mkdir ( exist_ok = True , parents = True ) elif self . template_dir . is_file (): raise TrestleError ( f 'Template path: { self . rel_dir ( self . template_dir ) } is a file not a directory.' ) template_file_a_md = self . template_dir / 'a_template.md' template_file_another_md = self . template_dir / 'another_template.md' template_file_drawio = self . template_dir / 'architecture.drawio' TemplateVersioning . write_versioned_template ( 'template.md' , self . template_dir , template_file_a_md , template_version ) TemplateVersioning . write_versioned_template ( 'template.md' , self . template_dir , template_file_another_md , template_version ) TemplateVersioning . write_versioned_template ( 'template.drawio' , self . template_dir , template_file_drawio , template_version ) return CmdReturnCodes . SUCCESS . value","title":"setup_template()"},{"location":"api_reference/trestle.core.commands.author.folders/#trestle.core.commands.author.folders.Folders.template_validate","text":"Validate that the template is acceptable markdown. Source code in trestle/core/commands/author/folders.py def template_validate ( self , validate_header : bool , validate_only_header : bool , heading : str , readme_validate : bool ) -> int : \"\"\"Validate that the template is acceptable markdown.\"\"\" if not self . template_dir . is_dir (): raise TrestleError ( f 'Template directory { self . rel_dir ( self . template_dir ) } for task { self . task_name } does not exist.' ) # get list of files: template_files = self . template_dir . rglob ( '*' ) for template_file in template_files : try : if not file_utils . is_local_and_visible ( template_file ): continue elif template_file . is_dir (): continue elif template_file . suffix . lower () == '.md' : if not readme_validate and template_file . name == 'readme.md' : raise TrestleError ( 'Template directory contains a readme.md file and readme validation is off.' ) md_api = MarkdownAPI () md_api . load_validator_with_template ( template_file , validate_header , not validate_only_header , heading ) elif template_file . suffix . lower () . lstrip ( '.' ) == 'drawio' : _ = draw_io . DrawIOMetadataValidator ( template_file ) else : logger . info ( f 'File: { self . rel_dir ( template_file ) } within the template directory was ignored' + 'as it is not markdown.' ) except Exception as ex : raise TrestleError ( f 'Template file { self . rel_dir ( template_file ) } for task { self . task_name } ' + f ' failed to validate due to { ex } ' ) logger . info ( f 'TEMPLATES VALID: { self . task_name } .' ) return CmdReturnCodes . SUCCESS . value","title":"template_validate()"},{"location":"api_reference/trestle.core.commands.author.folders/#trestle.core.commands.author.folders.Folders.validate","text":"Validate task. Source code in trestle/core/commands/author/folders.py def validate ( self , validate_header : bool , validate_only_header : bool , governed_heading : str , readme_validate : bool , template_version : str , ignore : str ) -> int : \"\"\"Validate task.\"\"\" if not self . task_path . is_dir (): raise TrestleError ( f 'Task directory { self . task_path } does not exist. Exiting validate.' ) for task_instance in self . task_path . iterdir (): if task_instance . is_dir (): if file_utils . is_symlink ( task_instance ): continue result = self . _measure_template_folder ( task_instance , validate_header , validate_only_header , governed_heading , readme_validate , template_version , ignore ) if not result : raise TrestleError ( 'Governed-folder validation failed for task' + f ' { self . task_name } on directory { self . rel_dir ( task_instance ) } ' ) else : logger . warning ( f 'Unexpected file { self . rel_dir ( task_instance ) } identified in { self . task_name } ' + ' directory, ignoring.' ) return CmdReturnCodes . SUCCESS . value handler: python","title":"validate()"},{"location":"api_reference/trestle.core.commands.author.headers/","text":"trestle.core.commands.author.headers \u00a4 Trestle author headers command. logger \u00a4 Classes \u00a4 Headers ( AuthorCommonCommand ) \u00a4 Enforce header / metadata across file types supported by author (markdown and drawio). Source code in trestle/core/commands/author/headers.py class Headers ( AuthorCommonCommand ): \"\"\"Enforce header / metadata across file types supported by author (markdown and drawio).\"\"\" name = 'headers' def _init_arguments ( self ) -> None : self . add_argument ( author_const . RECURSE_SHORT , author_const . RECURSE_LONG , help = author_const . RECURSE_HELP , action = 'store_true' ) self . add_argument ( author_const . MODE_ARG_NAME , choices = author_const . MODE_CHOICES ) tn_help_str = ' \\n ' . join ( [ 'The name of the the task to be governed.' , '' , 'The template files for header metadata governance are located at .trestle/author/[task name]' , 'Currently supported types are:' , 'Markdown: .trestle/author/[task name]/template.md' , 'Drawio: .trestle/author/[task name]/template.drawio' , '' , 'Note that by default this will automatically enforce the task.' ] ) self . add_argument ( author_const . TASK_NAME_SHORT , author_const . TASK_NAME_LONG , help = tn_help_str , type = str , default = None ) self . add_argument ( author_const . SHORT_README_VALIDATE , author_const . LONG_README_VALIDATE , help = author_const . README_VALIDATE_HELP , action = 'store_true' ) self . add_argument ( author_const . SHORT_TEMPLATE_VERSION , author_const . LONG_TEMPLATE_VERSION , help = author_const . TEMPLATE_VERSION_HELP , action = 'store' ) self . add_argument ( author_const . SHORT_IGNORE , author_const . LONG_IGNORE , help = author_const . IGNORE_HELP , default = None , type = str ) self . add_argument ( author_const . GLOBAL_SHORT , author_const . GLOBAL_LONG , help = author_const . GLOBAL_HELP , action = 'store_true' ) self . add_argument ( author_const . EXCLUDE_SHORT , author_const . EXCLUDE_LONG , help = author_const . EXCLUDE_HELP , type = pathlib . Path , nargs = '*' , default = None ) def _run ( self , args : argparse . Namespace ) -> int : try : status = 1 if self . _initialize ( args ): return status # Handle conditional requirement of args.task_name # global is special so we need to use get attribute. if not self . global_ and not self . task_name : logger . warning ( 'Task name (-tn) argument is required when global is not specified' ) return status if args . exclude : logger . warning ( '--exclude or -e is deprecated, use --ignore instead.' ) if args . mode == 'create-sample' : status = self . create_sample () elif args . mode == 'template-validate' : status = self . template_validate () elif args . mode == 'setup' : status = self . setup ( args . template_version ) elif args . mode == 'validate' : exclusions = [] if args . exclude : exclusions = args . exclude # mode is validate status = self . validate ( args . recurse , args . readme_validate , exclusions , args . template_version , args . ignore ) return status except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error occurred when running trestle author headers' ) def create_sample ( self ) -> int : \"\"\"Create sample object, this always defaults to markdown.\"\"\" logger . info ( 'Header only validation does not support sample creation.' ) logger . info ( 'Exiting' ) return CmdReturnCodes . SUCCESS . value def setup ( self , template_version : str ) -> int : \"\"\"Create template directory and templates.\"\"\" # Step 1 - validation if self . task_name and not self . task_path . exists (): self . task_path . mkdir ( exist_ok = True , parents = True ) elif self . task_name and self . task_path . is_file (): raise TrestleError ( f 'Task path: { self . rel_dir ( self . task_path ) } is a file not a directory.' ) if not self . template_dir . exists (): self . template_dir . mkdir ( exist_ok = True , parents = True ) logger . info ( f 'Populating template files to { self . rel_dir ( self . template_dir ) } ' ) for template in author_const . REFERENCE_TEMPLATES . values (): destination_path = self . template_dir / template TemplateVersioning . write_versioned_template ( template , self . template_dir , destination_path , template_version ) logger . info ( f 'Template directory populated { self . rel_dir ( destination_path ) } ' ) return CmdReturnCodes . SUCCESS . value def template_validate ( self ) -> int : \"\"\"Validate the integrity of the template files.\"\"\" logger . info ( 'Checking template file integrity' ) for template_file in self . template_dir . iterdir (): if ( template_file . name not in author_const . REFERENCE_TEMPLATES . values () and template_file . name . lower () != 'readme.md' ): raise TrestleError ( f 'Unexpected template file { self . rel_dir ( template_file ) } ' ) if template_file . suffix == '.md' : try : md_api = MarkdownAPI () md_api . load_validator_with_template ( template_file , True , False ) except Exception as ex : raise TrestleError ( f 'Template for task { self . task_name } failed to validate due to { ex } ' ) elif template_file . suffix == '.drawio' : try : _ = DrawIOMetadataValidator ( template_file ) except Exception as ex : raise TrestleError ( f 'Template for task { self . task_name } failed to validate due to { ex } ' ) logger . info ( 'Templates validated' ) return CmdReturnCodes . SUCCESS . value def _validate_dir ( self , candidate_dir : pathlib . Path , recurse : bool , readme_validate : bool , relative_exclusions : List [ pathlib . Path ], template_version : str , ignore : str ) -> bool : \"\"\"Validate a directory within the trestle project.\"\"\" all_versioned_templates = {} instance_version = template_version instance_file_names : List [ pathlib . Path ] = [] # Fetch all instances versions and build dictionary of required template files instances = list ( candidate_dir . iterdir ()) if recurse : instances = candidate_dir . rglob ( '*' ) if ignore : p = re . compile ( ignore ) instances = list ( filter ( lambda f : len ( list ( filter ( p . match , str ( f . relative_to ( candidate_dir )) . split ( '/' )))) == 0 , instances ) ) for instance_file in instances : if not file_utils . is_local_and_visible ( instance_file ): continue if instance_file . name . lower () == 'readme.md' and not readme_validate : continue if instance_file . is_dir () and not recurse : continue if any ( str ( ex ) in str ( instance_file ) for ex in relative_exclusions ): continue if ignore : p = re . compile ( ignore ) matched = p . match ( instance_file . parts [ - 1 ]) if matched is not None : logger . info ( f 'Ignoring file { instance_file } from validation.' ) continue instance_file_name = instance_file . relative_to ( candidate_dir ) instance_file_names . append ( instance_file_name ) if instance_file . suffix == '.md' : md_api = MarkdownAPI () versioned_template_dir = None if template_version != '' : versioned_template_dir = self . template_dir else : instance_version = md_api . processor . fetch_value_from_header ( instance_file , author_const . TEMPLATE_VERSION_HEADER ) if instance_version is None : instance_version = '0.0.1' # backward compatibility versioned_template_dir = TemplateVersioning . get_versioned_template_dir ( self . template_dir , instance_version ) if instance_version not in all_versioned_templates . keys (): templates = list ( filter ( lambda p : file_utils . is_local_and_visible ( p ), versioned_template_dir . iterdir ()) ) if not readme_validate : templates = list ( filter ( lambda p : p . name . lower () != 'readme.md' , templates )) all_versioned_templates [ instance_version ] = {} all_versioned_templates [ instance_version ][ 'drawio' ] = list ( filter ( lambda p : p . suffix == '.drawio' , templates ) )[ 0 ] all_versioned_templates [ instance_version ][ 'md' ] = list ( filter ( lambda p : p . suffix == '.md' , templates ) )[ 0 ] # validate md_api . load_validator_with_template ( all_versioned_templates [ instance_version ][ 'md' ], True , False ) status = md_api . validate_instance ( instance_file ) if not status : logger . info ( f 'INVALID: { self . rel_dir ( instance_file ) } ' ) return False else : logger . info ( f 'VALID: { self . rel_dir ( instance_file ) } ' ) elif instance_file . suffix == '.drawio' : drawio = DrawIO ( instance_file ) metadata = drawio . get_metadata ()[ 0 ] versioned_template_dir = None if template_version != '' : versioned_template_dir = self . template_dir else : if author_const . TEMPLATE_VERSION_HEADER in metadata . keys (): instance_version = metadata [ author_const . TEMPLATE_VERSION_HEADER ] else : instance_version = '0.0.1' # backward compatibility versioned_template_dir = TemplateVersioning . get_versioned_template_dir ( self . template_dir , instance_version ) if instance_version not in all_versioned_templates . keys (): templates = list ( filter ( lambda p : file_utils . is_local_and_visible ( p ), versioned_template_dir . iterdir ()) ) if not readme_validate : templates = list ( filter ( lambda p : p . name . lower () != 'readme.md' , templates )) all_versioned_templates [ instance_version ] = {} all_versioned_templates [ instance_version ][ 'drawio' ] = list ( filter ( lambda p : p . suffix == '.drawio' , templates ) )[ 0 ] all_versioned_templates [ instance_version ][ 'md' ] = list ( filter ( lambda p : p . suffix == '.md' , templates ) )[ 0 ] # validate drawio_validator = DrawIOMetadataValidator ( all_versioned_templates [ instance_version ][ 'drawio' ]) status = drawio_validator . validate ( instance_file ) if not status : logger . info ( f 'INVALID: { self . rel_dir ( instance_file ) } ' ) return False else : logger . info ( f 'VALID: { self . rel_dir ( instance_file ) } ' ) else : logger . debug ( f 'Unsupported extension of the instance file: { instance_file } , will not be validated.' ) return True def validate ( self , recurse : bool , readme_validate : bool , relative_excludes : List [ pathlib . Path ], template_version : str , ignore : str ) -> int : \"\"\"Run validation based on available templates.\"\"\" paths = [] if self . task_name : if not self . task_path . is_dir (): raise TrestleError ( f 'Task directory { self . rel_dir ( self . task_path ) } does not exist. Exiting validate.' ) paths = [ self . task_path ] else : for path in self . trestle_root . iterdir (): relative_path = path . relative_to ( self . trestle_root ) # Files in the root directory must be exclused if path . is_file (): continue if not file_utils . is_directory_name_allowed ( path ): continue if str ( relative_path ) . rstrip ( '/' ) in const . MODEL_DIR_LIST : continue if ( relative_path in relative_excludes ): continue if not file_utils . is_hidden ( path ): paths . append ( path ) for path in paths : try : valid = self . _validate_dir ( path , recurse , readme_validate , relative_excludes , template_version , ignore ) if not valid : logger . info ( f 'validation failed on { path } ' ) return CmdReturnCodes . DOCUMENTS_VALIDATION_ERROR . value except Exception as e : raise TrestleError ( f 'Error during header validation on { path } { e } ' ) return CmdReturnCodes . SUCCESS . value name \u00a4 Methods \u00a4 create_sample ( self ) \u00a4 Create sample object, this always defaults to markdown. Source code in trestle/core/commands/author/headers.py def create_sample ( self ) -> int : \"\"\"Create sample object, this always defaults to markdown.\"\"\" logger . info ( 'Header only validation does not support sample creation.' ) logger . info ( 'Exiting' ) return CmdReturnCodes . SUCCESS . value setup ( self , template_version ) \u00a4 Create template directory and templates. Source code in trestle/core/commands/author/headers.py def setup ( self , template_version : str ) -> int : \"\"\"Create template directory and templates.\"\"\" # Step 1 - validation if self . task_name and not self . task_path . exists (): self . task_path . mkdir ( exist_ok = True , parents = True ) elif self . task_name and self . task_path . is_file (): raise TrestleError ( f 'Task path: { self . rel_dir ( self . task_path ) } is a file not a directory.' ) if not self . template_dir . exists (): self . template_dir . mkdir ( exist_ok = True , parents = True ) logger . info ( f 'Populating template files to { self . rel_dir ( self . template_dir ) } ' ) for template in author_const . REFERENCE_TEMPLATES . values (): destination_path = self . template_dir / template TemplateVersioning . write_versioned_template ( template , self . template_dir , destination_path , template_version ) logger . info ( f 'Template directory populated { self . rel_dir ( destination_path ) } ' ) return CmdReturnCodes . SUCCESS . value template_validate ( self ) \u00a4 Validate the integrity of the template files. Source code in trestle/core/commands/author/headers.py def template_validate ( self ) -> int : \"\"\"Validate the integrity of the template files.\"\"\" logger . info ( 'Checking template file integrity' ) for template_file in self . template_dir . iterdir (): if ( template_file . name not in author_const . REFERENCE_TEMPLATES . values () and template_file . name . lower () != 'readme.md' ): raise TrestleError ( f 'Unexpected template file { self . rel_dir ( template_file ) } ' ) if template_file . suffix == '.md' : try : md_api = MarkdownAPI () md_api . load_validator_with_template ( template_file , True , False ) except Exception as ex : raise TrestleError ( f 'Template for task { self . task_name } failed to validate due to { ex } ' ) elif template_file . suffix == '.drawio' : try : _ = DrawIOMetadataValidator ( template_file ) except Exception as ex : raise TrestleError ( f 'Template for task { self . task_name } failed to validate due to { ex } ' ) logger . info ( 'Templates validated' ) return CmdReturnCodes . SUCCESS . value validate ( self , recurse , readme_validate , relative_excludes , template_version , ignore ) \u00a4 Run validation based on available templates. Source code in trestle/core/commands/author/headers.py def validate ( self , recurse : bool , readme_validate : bool , relative_excludes : List [ pathlib . Path ], template_version : str , ignore : str ) -> int : \"\"\"Run validation based on available templates.\"\"\" paths = [] if self . task_name : if not self . task_path . is_dir (): raise TrestleError ( f 'Task directory { self . rel_dir ( self . task_path ) } does not exist. Exiting validate.' ) paths = [ self . task_path ] else : for path in self . trestle_root . iterdir (): relative_path = path . relative_to ( self . trestle_root ) # Files in the root directory must be exclused if path . is_file (): continue if not file_utils . is_directory_name_allowed ( path ): continue if str ( relative_path ) . rstrip ( '/' ) in const . MODEL_DIR_LIST : continue if ( relative_path in relative_excludes ): continue if not file_utils . is_hidden ( path ): paths . append ( path ) for path in paths : try : valid = self . _validate_dir ( path , recurse , readme_validate , relative_excludes , template_version , ignore ) if not valid : logger . info ( f 'validation failed on { path } ' ) return CmdReturnCodes . DOCUMENTS_VALIDATION_ERROR . value except Exception as e : raise TrestleError ( f 'Error during header validation on { path } { e } ' ) return CmdReturnCodes . SUCCESS . value handler: python","title":"headers"},{"location":"api_reference/trestle.core.commands.author.headers/#trestle.core.commands.author.headers","text":"Trestle author headers command.","title":"headers"},{"location":"api_reference/trestle.core.commands.author.headers/#trestle.core.commands.author.headers.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.author.headers/#trestle.core.commands.author.headers-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.author.headers/#trestle.core.commands.author.headers.Headers","text":"Enforce header / metadata across file types supported by author (markdown and drawio). Source code in trestle/core/commands/author/headers.py class Headers ( AuthorCommonCommand ): \"\"\"Enforce header / metadata across file types supported by author (markdown and drawio).\"\"\" name = 'headers' def _init_arguments ( self ) -> None : self . add_argument ( author_const . RECURSE_SHORT , author_const . RECURSE_LONG , help = author_const . RECURSE_HELP , action = 'store_true' ) self . add_argument ( author_const . MODE_ARG_NAME , choices = author_const . MODE_CHOICES ) tn_help_str = ' \\n ' . join ( [ 'The name of the the task to be governed.' , '' , 'The template files for header metadata governance are located at .trestle/author/[task name]' , 'Currently supported types are:' , 'Markdown: .trestle/author/[task name]/template.md' , 'Drawio: .trestle/author/[task name]/template.drawio' , '' , 'Note that by default this will automatically enforce the task.' ] ) self . add_argument ( author_const . TASK_NAME_SHORT , author_const . TASK_NAME_LONG , help = tn_help_str , type = str , default = None ) self . add_argument ( author_const . SHORT_README_VALIDATE , author_const . LONG_README_VALIDATE , help = author_const . README_VALIDATE_HELP , action = 'store_true' ) self . add_argument ( author_const . SHORT_TEMPLATE_VERSION , author_const . LONG_TEMPLATE_VERSION , help = author_const . TEMPLATE_VERSION_HELP , action = 'store' ) self . add_argument ( author_const . SHORT_IGNORE , author_const . LONG_IGNORE , help = author_const . IGNORE_HELP , default = None , type = str ) self . add_argument ( author_const . GLOBAL_SHORT , author_const . GLOBAL_LONG , help = author_const . GLOBAL_HELP , action = 'store_true' ) self . add_argument ( author_const . EXCLUDE_SHORT , author_const . EXCLUDE_LONG , help = author_const . EXCLUDE_HELP , type = pathlib . Path , nargs = '*' , default = None ) def _run ( self , args : argparse . Namespace ) -> int : try : status = 1 if self . _initialize ( args ): return status # Handle conditional requirement of args.task_name # global is special so we need to use get attribute. if not self . global_ and not self . task_name : logger . warning ( 'Task name (-tn) argument is required when global is not specified' ) return status if args . exclude : logger . warning ( '--exclude or -e is deprecated, use --ignore instead.' ) if args . mode == 'create-sample' : status = self . create_sample () elif args . mode == 'template-validate' : status = self . template_validate () elif args . mode == 'setup' : status = self . setup ( args . template_version ) elif args . mode == 'validate' : exclusions = [] if args . exclude : exclusions = args . exclude # mode is validate status = self . validate ( args . recurse , args . readme_validate , exclusions , args . template_version , args . ignore ) return status except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error occurred when running trestle author headers' ) def create_sample ( self ) -> int : \"\"\"Create sample object, this always defaults to markdown.\"\"\" logger . info ( 'Header only validation does not support sample creation.' ) logger . info ( 'Exiting' ) return CmdReturnCodes . SUCCESS . value def setup ( self , template_version : str ) -> int : \"\"\"Create template directory and templates.\"\"\" # Step 1 - validation if self . task_name and not self . task_path . exists (): self . task_path . mkdir ( exist_ok = True , parents = True ) elif self . task_name and self . task_path . is_file (): raise TrestleError ( f 'Task path: { self . rel_dir ( self . task_path ) } is a file not a directory.' ) if not self . template_dir . exists (): self . template_dir . mkdir ( exist_ok = True , parents = True ) logger . info ( f 'Populating template files to { self . rel_dir ( self . template_dir ) } ' ) for template in author_const . REFERENCE_TEMPLATES . values (): destination_path = self . template_dir / template TemplateVersioning . write_versioned_template ( template , self . template_dir , destination_path , template_version ) logger . info ( f 'Template directory populated { self . rel_dir ( destination_path ) } ' ) return CmdReturnCodes . SUCCESS . value def template_validate ( self ) -> int : \"\"\"Validate the integrity of the template files.\"\"\" logger . info ( 'Checking template file integrity' ) for template_file in self . template_dir . iterdir (): if ( template_file . name not in author_const . REFERENCE_TEMPLATES . values () and template_file . name . lower () != 'readme.md' ): raise TrestleError ( f 'Unexpected template file { self . rel_dir ( template_file ) } ' ) if template_file . suffix == '.md' : try : md_api = MarkdownAPI () md_api . load_validator_with_template ( template_file , True , False ) except Exception as ex : raise TrestleError ( f 'Template for task { self . task_name } failed to validate due to { ex } ' ) elif template_file . suffix == '.drawio' : try : _ = DrawIOMetadataValidator ( template_file ) except Exception as ex : raise TrestleError ( f 'Template for task { self . task_name } failed to validate due to { ex } ' ) logger . info ( 'Templates validated' ) return CmdReturnCodes . SUCCESS . value def _validate_dir ( self , candidate_dir : pathlib . Path , recurse : bool , readme_validate : bool , relative_exclusions : List [ pathlib . Path ], template_version : str , ignore : str ) -> bool : \"\"\"Validate a directory within the trestle project.\"\"\" all_versioned_templates = {} instance_version = template_version instance_file_names : List [ pathlib . Path ] = [] # Fetch all instances versions and build dictionary of required template files instances = list ( candidate_dir . iterdir ()) if recurse : instances = candidate_dir . rglob ( '*' ) if ignore : p = re . compile ( ignore ) instances = list ( filter ( lambda f : len ( list ( filter ( p . match , str ( f . relative_to ( candidate_dir )) . split ( '/' )))) == 0 , instances ) ) for instance_file in instances : if not file_utils . is_local_and_visible ( instance_file ): continue if instance_file . name . lower () == 'readme.md' and not readme_validate : continue if instance_file . is_dir () and not recurse : continue if any ( str ( ex ) in str ( instance_file ) for ex in relative_exclusions ): continue if ignore : p = re . compile ( ignore ) matched = p . match ( instance_file . parts [ - 1 ]) if matched is not None : logger . info ( f 'Ignoring file { instance_file } from validation.' ) continue instance_file_name = instance_file . relative_to ( candidate_dir ) instance_file_names . append ( instance_file_name ) if instance_file . suffix == '.md' : md_api = MarkdownAPI () versioned_template_dir = None if template_version != '' : versioned_template_dir = self . template_dir else : instance_version = md_api . processor . fetch_value_from_header ( instance_file , author_const . TEMPLATE_VERSION_HEADER ) if instance_version is None : instance_version = '0.0.1' # backward compatibility versioned_template_dir = TemplateVersioning . get_versioned_template_dir ( self . template_dir , instance_version ) if instance_version not in all_versioned_templates . keys (): templates = list ( filter ( lambda p : file_utils . is_local_and_visible ( p ), versioned_template_dir . iterdir ()) ) if not readme_validate : templates = list ( filter ( lambda p : p . name . lower () != 'readme.md' , templates )) all_versioned_templates [ instance_version ] = {} all_versioned_templates [ instance_version ][ 'drawio' ] = list ( filter ( lambda p : p . suffix == '.drawio' , templates ) )[ 0 ] all_versioned_templates [ instance_version ][ 'md' ] = list ( filter ( lambda p : p . suffix == '.md' , templates ) )[ 0 ] # validate md_api . load_validator_with_template ( all_versioned_templates [ instance_version ][ 'md' ], True , False ) status = md_api . validate_instance ( instance_file ) if not status : logger . info ( f 'INVALID: { self . rel_dir ( instance_file ) } ' ) return False else : logger . info ( f 'VALID: { self . rel_dir ( instance_file ) } ' ) elif instance_file . suffix == '.drawio' : drawio = DrawIO ( instance_file ) metadata = drawio . get_metadata ()[ 0 ] versioned_template_dir = None if template_version != '' : versioned_template_dir = self . template_dir else : if author_const . TEMPLATE_VERSION_HEADER in metadata . keys (): instance_version = metadata [ author_const . TEMPLATE_VERSION_HEADER ] else : instance_version = '0.0.1' # backward compatibility versioned_template_dir = TemplateVersioning . get_versioned_template_dir ( self . template_dir , instance_version ) if instance_version not in all_versioned_templates . keys (): templates = list ( filter ( lambda p : file_utils . is_local_and_visible ( p ), versioned_template_dir . iterdir ()) ) if not readme_validate : templates = list ( filter ( lambda p : p . name . lower () != 'readme.md' , templates )) all_versioned_templates [ instance_version ] = {} all_versioned_templates [ instance_version ][ 'drawio' ] = list ( filter ( lambda p : p . suffix == '.drawio' , templates ) )[ 0 ] all_versioned_templates [ instance_version ][ 'md' ] = list ( filter ( lambda p : p . suffix == '.md' , templates ) )[ 0 ] # validate drawio_validator = DrawIOMetadataValidator ( all_versioned_templates [ instance_version ][ 'drawio' ]) status = drawio_validator . validate ( instance_file ) if not status : logger . info ( f 'INVALID: { self . rel_dir ( instance_file ) } ' ) return False else : logger . info ( f 'VALID: { self . rel_dir ( instance_file ) } ' ) else : logger . debug ( f 'Unsupported extension of the instance file: { instance_file } , will not be validated.' ) return True def validate ( self , recurse : bool , readme_validate : bool , relative_excludes : List [ pathlib . Path ], template_version : str , ignore : str ) -> int : \"\"\"Run validation based on available templates.\"\"\" paths = [] if self . task_name : if not self . task_path . is_dir (): raise TrestleError ( f 'Task directory { self . rel_dir ( self . task_path ) } does not exist. Exiting validate.' ) paths = [ self . task_path ] else : for path in self . trestle_root . iterdir (): relative_path = path . relative_to ( self . trestle_root ) # Files in the root directory must be exclused if path . is_file (): continue if not file_utils . is_directory_name_allowed ( path ): continue if str ( relative_path ) . rstrip ( '/' ) in const . MODEL_DIR_LIST : continue if ( relative_path in relative_excludes ): continue if not file_utils . is_hidden ( path ): paths . append ( path ) for path in paths : try : valid = self . _validate_dir ( path , recurse , readme_validate , relative_excludes , template_version , ignore ) if not valid : logger . info ( f 'validation failed on { path } ' ) return CmdReturnCodes . DOCUMENTS_VALIDATION_ERROR . value except Exception as e : raise TrestleError ( f 'Error during header validation on { path } { e } ' ) return CmdReturnCodes . SUCCESS . value","title":"Headers"},{"location":"api_reference/trestle.core.commands.author.headers/#trestle.core.commands.author.headers.Headers.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.author.headers/#trestle.core.commands.author.headers.Headers-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.author.headers/#trestle.core.commands.author.headers.Headers.create_sample","text":"Create sample object, this always defaults to markdown. Source code in trestle/core/commands/author/headers.py def create_sample ( self ) -> int : \"\"\"Create sample object, this always defaults to markdown.\"\"\" logger . info ( 'Header only validation does not support sample creation.' ) logger . info ( 'Exiting' ) return CmdReturnCodes . SUCCESS . value","title":"create_sample()"},{"location":"api_reference/trestle.core.commands.author.headers/#trestle.core.commands.author.headers.Headers.setup","text":"Create template directory and templates. Source code in trestle/core/commands/author/headers.py def setup ( self , template_version : str ) -> int : \"\"\"Create template directory and templates.\"\"\" # Step 1 - validation if self . task_name and not self . task_path . exists (): self . task_path . mkdir ( exist_ok = True , parents = True ) elif self . task_name and self . task_path . is_file (): raise TrestleError ( f 'Task path: { self . rel_dir ( self . task_path ) } is a file not a directory.' ) if not self . template_dir . exists (): self . template_dir . mkdir ( exist_ok = True , parents = True ) logger . info ( f 'Populating template files to { self . rel_dir ( self . template_dir ) } ' ) for template in author_const . REFERENCE_TEMPLATES . values (): destination_path = self . template_dir / template TemplateVersioning . write_versioned_template ( template , self . template_dir , destination_path , template_version ) logger . info ( f 'Template directory populated { self . rel_dir ( destination_path ) } ' ) return CmdReturnCodes . SUCCESS . value","title":"setup()"},{"location":"api_reference/trestle.core.commands.author.headers/#trestle.core.commands.author.headers.Headers.template_validate","text":"Validate the integrity of the template files. Source code in trestle/core/commands/author/headers.py def template_validate ( self ) -> int : \"\"\"Validate the integrity of the template files.\"\"\" logger . info ( 'Checking template file integrity' ) for template_file in self . template_dir . iterdir (): if ( template_file . name not in author_const . REFERENCE_TEMPLATES . values () and template_file . name . lower () != 'readme.md' ): raise TrestleError ( f 'Unexpected template file { self . rel_dir ( template_file ) } ' ) if template_file . suffix == '.md' : try : md_api = MarkdownAPI () md_api . load_validator_with_template ( template_file , True , False ) except Exception as ex : raise TrestleError ( f 'Template for task { self . task_name } failed to validate due to { ex } ' ) elif template_file . suffix == '.drawio' : try : _ = DrawIOMetadataValidator ( template_file ) except Exception as ex : raise TrestleError ( f 'Template for task { self . task_name } failed to validate due to { ex } ' ) logger . info ( 'Templates validated' ) return CmdReturnCodes . SUCCESS . value","title":"template_validate()"},{"location":"api_reference/trestle.core.commands.author.headers/#trestle.core.commands.author.headers.Headers.validate","text":"Run validation based on available templates. Source code in trestle/core/commands/author/headers.py def validate ( self , recurse : bool , readme_validate : bool , relative_excludes : List [ pathlib . Path ], template_version : str , ignore : str ) -> int : \"\"\"Run validation based on available templates.\"\"\" paths = [] if self . task_name : if not self . task_path . is_dir (): raise TrestleError ( f 'Task directory { self . rel_dir ( self . task_path ) } does not exist. Exiting validate.' ) paths = [ self . task_path ] else : for path in self . trestle_root . iterdir (): relative_path = path . relative_to ( self . trestle_root ) # Files in the root directory must be exclused if path . is_file (): continue if not file_utils . is_directory_name_allowed ( path ): continue if str ( relative_path ) . rstrip ( '/' ) in const . MODEL_DIR_LIST : continue if ( relative_path in relative_excludes ): continue if not file_utils . is_hidden ( path ): paths . append ( path ) for path in paths : try : valid = self . _validate_dir ( path , recurse , readme_validate , relative_excludes , template_version , ignore ) if not valid : logger . info ( f 'validation failed on { path } ' ) return CmdReturnCodes . DOCUMENTS_VALIDATION_ERROR . value except Exception as e : raise TrestleError ( f 'Error during header validation on { path } { e } ' ) return CmdReturnCodes . SUCCESS . value handler: python","title":"validate()"},{"location":"api_reference/trestle.core.commands.author.jinja/","text":"trestle.core.commands.author.jinja \u00a4 Trestle Commands. logger \u00a4 Classes \u00a4 JinjaCmd ( CommandPlusDocs ) \u00a4 Transform an input template to an output document using jinja templating. Source code in trestle/core/commands/author/jinja.py class JinjaCmd ( CommandPlusDocs ): \"\"\"Transform an input template to an output document using jinja templating.\"\"\" max_recursion_depth = 2 name = 'jinja' def _init_arguments ( self ): self . add_argument ( '-i' , '--input' , help = 'Input jinja template, relative to trestle root' , required = True ) self . add_argument ( '-o' , '--output' , help = 'Output template, relative to trestle root.' , required = True ) self . add_argument ( '-lut' , '--look-up-table' , help = 'Key-value pair table, stored as yaml, to be passed to jinja as variables' , required = False ) self . add_argument ( '-elp' , '--external-lut-prefix' , help = 'Prefix paths for LUT, to maintain compatibility with other templating systems' , required = False ) self . add_argument ( '-nc' , '--number-captions' , help = 'Add incremental numbering to table and image captions, in the form Table n - ... and Figure n - ...' , action = 'store_true' ) self . add_argument ( '-pf' , '--param-formatting' , help = 'Add given text to each parameter, ' 'use dot to specify location of parameter (i.e. foo.bar will wrap param with foo and bar)' , required = False ) self . add_argument ( '-ssp' , '--system-security-plan' , help = 'An optional SSP to be passed' , default = None , required = False ) self . add_argument ( '-p' , '--profile' , help = 'An optional profile to be passed' , default = None , required = False ) self . add_argument ( '-dp' , '--docs-profile' , help = 'Output profile controls to separate markdown files' , action = 'store_true' , required = False ) def _run ( self , args : argparse . Namespace ): try : log . set_log_level_from_args ( args ) logger . debug ( f 'Starting { self . name } command' ) input_path = pathlib . Path ( args . input ) output_path = pathlib . Path ( args . output ) if args . system_security_plan and args . docs_profile : raise TrestleIncorrectArgsError ( 'Output to multiple files is possible with profile only.' ) if args . docs_profile and not args . profile : raise TrestleIncorrectArgsError ( 'Profile must be provided to output to multiple files.' ) lut = {} if args . look_up_table : lut_table = pathlib . Path ( args . look_up_table ) lookup_table_path = pathlib . Path . cwd () / lut_table lut = JinjaCmd . load_LUT ( lookup_table_path , args . external_lut_prefix ) if args . system_security_plan : return JinjaCmd . jinja_ify ( pathlib . Path ( args . trestle_root ), input_path , output_path , args . system_security_plan , args . profile , lut , number_captions = args . number_captions , parameters_formatting = args . param_formatting ) elif args . profile and args . docs_profile : return JinjaCmd . jinja_multiple_md ( pathlib . Path ( args . trestle_root ), input_path , output_path , args . profile , lut , parameters_formatting = args . param_formatting ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while generating markdown via Jinja template' ) @staticmethod def load_LUT ( path : pathlib . Path , prefix : Optional [ str ]) -> Dict [ str , Any ]: # noqa: N802 \"\"\"Load a Yaml lookup table from file.\"\"\" yaml = YAML () lut = yaml . load ( path . open ( 'r' , encoding = const . FILE_ENCODING )) if prefix : prefixes = prefix . split ( '.' ) while prefixes : old_lut = lut lut [ prefixes . pop ( - 1 )] = old_lut return lut @staticmethod def jinja_ify ( trestle_root : pathlib . Path , r_input_file : pathlib . Path , r_output_file : pathlib . Path , ssp : Optional [ str ], profile : Optional [ str ], lut : Dict [ str , Any ], number_captions : Optional [ bool ] = False , parameters_formatting : Optional [ str ] = None ) -> int : \"\"\"Run jinja over an input file with additional booleans.\"\"\" template_folder = pathlib . Path . cwd () jinja_env = Environment ( loader = FileSystemLoader ( template_folder ), extensions = [ MDSectionInclude , MDCleanInclude , MDDatestamp ], trim_blocks = True , autoescape = True ) template = jinja_env . get_template ( str ( r_input_file )) # create boolean dict if operator . xor ( bool ( ssp ), bool ( profile )): raise TrestleIncorrectArgsError ( 'Both SSP and profile should be provided or not at all' ) if ssp : # name lookup ssp_data , _ = ModelUtils . load_top_level_model ( trestle_root , ssp , SystemSecurityPlan ) lut [ 'ssp' ] = ssp_data _ , profile_path = ModelUtils . load_top_level_model ( trestle_root , profile , Profile ) profile_resolver = ProfileResolver () resolved_catalog = profile_resolver . get_resolved_profile_catalog ( trestle_root , profile_path , False , False , parameters_formatting ) ssp_writer = SSPMarkdownWriter ( trestle_root ) ssp_writer . set_ssp ( ssp_data ) ssp_writer . set_catalog ( resolved_catalog ) lut [ 'catalog' ] = resolved_catalog lut [ 'catalog_interface' ] = CatalogInterface ( resolved_catalog ) lut [ 'control_io_writer' ] = ControlIOWriter () lut [ 'ssp_md_writer' ] = ssp_writer output = JinjaCmd . render_template ( template , lut , template_folder ) output_file = trestle_root / r_output_file if number_captions : output_file . open ( 'w' , encoding = const . FILE_ENCODING ) . write ( _number_captions ( output )) else : output_file . open ( 'w' , encoding = const . FILE_ENCODING ) . write ( output ) return CmdReturnCodes . SUCCESS . value @staticmethod def jinja_multiple_md ( trestle_root : pathlib . Path , r_input_file : pathlib . Path , r_output_file : pathlib . Path , profile : Optional [ str ], lut : Dict [ str , Any ], parameters_formatting : Optional [ str ] = None ) -> int : \"\"\"Output profile as multiple markdown files using Jinja.\"\"\" template_folder = pathlib . Path . cwd () # Output to multiple markdown files _ , profile_path = ModelUtils . load_top_level_model ( trestle_root , profile , Profile ) profile_resolver = ProfileResolver () resolved_catalog = profile_resolver . get_resolved_profile_catalog ( trestle_root , profile_path , False , False , parameters_formatting ) catalog_interface = CatalogInterface ( resolved_catalog ) # Generate a single markdown page for each control per each group for group in catalog_interface . get_all_groups_from_catalog (): for control in catalog_interface . get_sorted_controls_in_group ( group . id ): _ , group_title , _ = catalog_interface . get_group_info_by_control ( control . id ) group_dir = r_output_file control_path = catalog_interface . get_control_path ( control . id ) for sub_dir in control_path : group_dir = group_dir / sub_dir if not group_dir . exists (): group_dir . mkdir ( parents = True , exist_ok = True ) control_writer = ControlIOWriter () jinja_env = Environment ( loader = FileSystemLoader ( template_folder ), extensions = [ MDSectionInclude , MDCleanInclude , MDDatestamp ], trim_blocks = True , autoescape = True ) template = jinja_env . get_template ( str ( r_input_file )) lut [ 'catalog_interface' ] = catalog_interface lut [ 'control_writer' ] = control_writer lut [ 'control' ] = control lut [ 'profile' ] = profile lut [ 'group_title' ] = group_title output = JinjaCmd . render_template ( template , lut , template_folder ) output_file = trestle_root / group_dir / pathlib . Path ( control . id + '.md' ) output_file . open ( 'w' , encoding = const . FILE_ENCODING ) . write ( output ) return CmdReturnCodes . SUCCESS . value @staticmethod def render_template ( template : Template , lut : Dict [ str , Any ], template_folder : pathlib . Path ) -> str : \"\"\"Render template.\"\"\" new_output = template . render ( ** lut ) output = '' # This recursion allows nesting within expressions (e.g. an expression can contain jinja templates). error_countdown = JinjaCmd . max_recursion_depth while new_output != output and error_countdown > 0 : error_countdown = error_countdown - 1 output = new_output random_name = uuid . uuid4 () # Should be random and not used. dict_loader = DictLoader ({ str ( random_name ): new_output }) jinja_env = Environment ( loader = ChoiceLoader ([ dict_loader , FileSystemLoader ( template_folder )]), extensions = [ MDCleanInclude , MDSectionInclude , MDDatestamp ], autoescape = True , trim_blocks = True ) template = jinja_env . get_template ( str ( random_name )) new_output = template . render ( ** lut ) return output max_recursion_depth \u00a4 name \u00a4 Methods \u00a4 jinja_ify ( trestle_root , r_input_file , r_output_file , ssp , profile , lut , number_captions = False , parameters_formatting = None ) staticmethod \u00a4 Run jinja over an input file with additional booleans. Source code in trestle/core/commands/author/jinja.py @staticmethod def jinja_ify ( trestle_root : pathlib . Path , r_input_file : pathlib . Path , r_output_file : pathlib . Path , ssp : Optional [ str ], profile : Optional [ str ], lut : Dict [ str , Any ], number_captions : Optional [ bool ] = False , parameters_formatting : Optional [ str ] = None ) -> int : \"\"\"Run jinja over an input file with additional booleans.\"\"\" template_folder = pathlib . Path . cwd () jinja_env = Environment ( loader = FileSystemLoader ( template_folder ), extensions = [ MDSectionInclude , MDCleanInclude , MDDatestamp ], trim_blocks = True , autoescape = True ) template = jinja_env . get_template ( str ( r_input_file )) # create boolean dict if operator . xor ( bool ( ssp ), bool ( profile )): raise TrestleIncorrectArgsError ( 'Both SSP and profile should be provided or not at all' ) if ssp : # name lookup ssp_data , _ = ModelUtils . load_top_level_model ( trestle_root , ssp , SystemSecurityPlan ) lut [ 'ssp' ] = ssp_data _ , profile_path = ModelUtils . load_top_level_model ( trestle_root , profile , Profile ) profile_resolver = ProfileResolver () resolved_catalog = profile_resolver . get_resolved_profile_catalog ( trestle_root , profile_path , False , False , parameters_formatting ) ssp_writer = SSPMarkdownWriter ( trestle_root ) ssp_writer . set_ssp ( ssp_data ) ssp_writer . set_catalog ( resolved_catalog ) lut [ 'catalog' ] = resolved_catalog lut [ 'catalog_interface' ] = CatalogInterface ( resolved_catalog ) lut [ 'control_io_writer' ] = ControlIOWriter () lut [ 'ssp_md_writer' ] = ssp_writer output = JinjaCmd . render_template ( template , lut , template_folder ) output_file = trestle_root / r_output_file if number_captions : output_file . open ( 'w' , encoding = const . FILE_ENCODING ) . write ( _number_captions ( output )) else : output_file . open ( 'w' , encoding = const . FILE_ENCODING ) . write ( output ) return CmdReturnCodes . SUCCESS . value jinja_multiple_md ( trestle_root , r_input_file , r_output_file , profile , lut , parameters_formatting = None ) staticmethod \u00a4 Output profile as multiple markdown files using Jinja. Source code in trestle/core/commands/author/jinja.py @staticmethod def jinja_multiple_md ( trestle_root : pathlib . Path , r_input_file : pathlib . Path , r_output_file : pathlib . Path , profile : Optional [ str ], lut : Dict [ str , Any ], parameters_formatting : Optional [ str ] = None ) -> int : \"\"\"Output profile as multiple markdown files using Jinja.\"\"\" template_folder = pathlib . Path . cwd () # Output to multiple markdown files _ , profile_path = ModelUtils . load_top_level_model ( trestle_root , profile , Profile ) profile_resolver = ProfileResolver () resolved_catalog = profile_resolver . get_resolved_profile_catalog ( trestle_root , profile_path , False , False , parameters_formatting ) catalog_interface = CatalogInterface ( resolved_catalog ) # Generate a single markdown page for each control per each group for group in catalog_interface . get_all_groups_from_catalog (): for control in catalog_interface . get_sorted_controls_in_group ( group . id ): _ , group_title , _ = catalog_interface . get_group_info_by_control ( control . id ) group_dir = r_output_file control_path = catalog_interface . get_control_path ( control . id ) for sub_dir in control_path : group_dir = group_dir / sub_dir if not group_dir . exists (): group_dir . mkdir ( parents = True , exist_ok = True ) control_writer = ControlIOWriter () jinja_env = Environment ( loader = FileSystemLoader ( template_folder ), extensions = [ MDSectionInclude , MDCleanInclude , MDDatestamp ], trim_blocks = True , autoescape = True ) template = jinja_env . get_template ( str ( r_input_file )) lut [ 'catalog_interface' ] = catalog_interface lut [ 'control_writer' ] = control_writer lut [ 'control' ] = control lut [ 'profile' ] = profile lut [ 'group_title' ] = group_title output = JinjaCmd . render_template ( template , lut , template_folder ) output_file = trestle_root / group_dir / pathlib . Path ( control . id + '.md' ) output_file . open ( 'w' , encoding = const . FILE_ENCODING ) . write ( output ) return CmdReturnCodes . SUCCESS . value load_LUT ( path , prefix ) staticmethod \u00a4 Load a Yaml lookup table from file. Source code in trestle/core/commands/author/jinja.py @staticmethod def load_LUT ( path : pathlib . Path , prefix : Optional [ str ]) -> Dict [ str , Any ]: # noqa: N802 \"\"\"Load a Yaml lookup table from file.\"\"\" yaml = YAML () lut = yaml . load ( path . open ( 'r' , encoding = const . FILE_ENCODING )) if prefix : prefixes = prefix . split ( '.' ) while prefixes : old_lut = lut lut [ prefixes . pop ( - 1 )] = old_lut return lut render_template ( template , lut , template_folder ) staticmethod \u00a4 Render template. Source code in trestle/core/commands/author/jinja.py @staticmethod def render_template ( template : Template , lut : Dict [ str , Any ], template_folder : pathlib . Path ) -> str : \"\"\"Render template.\"\"\" new_output = template . render ( ** lut ) output = '' # This recursion allows nesting within expressions (e.g. an expression can contain jinja templates). error_countdown = JinjaCmd . max_recursion_depth while new_output != output and error_countdown > 0 : error_countdown = error_countdown - 1 output = new_output random_name = uuid . uuid4 () # Should be random and not used. dict_loader = DictLoader ({ str ( random_name ): new_output }) jinja_env = Environment ( loader = ChoiceLoader ([ dict_loader , FileSystemLoader ( template_folder )]), extensions = [ MDCleanInclude , MDSectionInclude , MDDatestamp ], autoescape = True , trim_blocks = True ) template = jinja_env . get_template ( str ( random_name )) new_output = template . render ( ** lut ) return output handler: python","title":"jinja"},{"location":"api_reference/trestle.core.commands.author.jinja/#trestle.core.commands.author.jinja","text":"Trestle Commands.","title":"jinja"},{"location":"api_reference/trestle.core.commands.author.jinja/#trestle.core.commands.author.jinja.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.author.jinja/#trestle.core.commands.author.jinja-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.author.jinja/#trestle.core.commands.author.jinja.JinjaCmd","text":"Transform an input template to an output document using jinja templating. Source code in trestle/core/commands/author/jinja.py class JinjaCmd ( CommandPlusDocs ): \"\"\"Transform an input template to an output document using jinja templating.\"\"\" max_recursion_depth = 2 name = 'jinja' def _init_arguments ( self ): self . add_argument ( '-i' , '--input' , help = 'Input jinja template, relative to trestle root' , required = True ) self . add_argument ( '-o' , '--output' , help = 'Output template, relative to trestle root.' , required = True ) self . add_argument ( '-lut' , '--look-up-table' , help = 'Key-value pair table, stored as yaml, to be passed to jinja as variables' , required = False ) self . add_argument ( '-elp' , '--external-lut-prefix' , help = 'Prefix paths for LUT, to maintain compatibility with other templating systems' , required = False ) self . add_argument ( '-nc' , '--number-captions' , help = 'Add incremental numbering to table and image captions, in the form Table n - ... and Figure n - ...' , action = 'store_true' ) self . add_argument ( '-pf' , '--param-formatting' , help = 'Add given text to each parameter, ' 'use dot to specify location of parameter (i.e. foo.bar will wrap param with foo and bar)' , required = False ) self . add_argument ( '-ssp' , '--system-security-plan' , help = 'An optional SSP to be passed' , default = None , required = False ) self . add_argument ( '-p' , '--profile' , help = 'An optional profile to be passed' , default = None , required = False ) self . add_argument ( '-dp' , '--docs-profile' , help = 'Output profile controls to separate markdown files' , action = 'store_true' , required = False ) def _run ( self , args : argparse . Namespace ): try : log . set_log_level_from_args ( args ) logger . debug ( f 'Starting { self . name } command' ) input_path = pathlib . Path ( args . input ) output_path = pathlib . Path ( args . output ) if args . system_security_plan and args . docs_profile : raise TrestleIncorrectArgsError ( 'Output to multiple files is possible with profile only.' ) if args . docs_profile and not args . profile : raise TrestleIncorrectArgsError ( 'Profile must be provided to output to multiple files.' ) lut = {} if args . look_up_table : lut_table = pathlib . Path ( args . look_up_table ) lookup_table_path = pathlib . Path . cwd () / lut_table lut = JinjaCmd . load_LUT ( lookup_table_path , args . external_lut_prefix ) if args . system_security_plan : return JinjaCmd . jinja_ify ( pathlib . Path ( args . trestle_root ), input_path , output_path , args . system_security_plan , args . profile , lut , number_captions = args . number_captions , parameters_formatting = args . param_formatting ) elif args . profile and args . docs_profile : return JinjaCmd . jinja_multiple_md ( pathlib . Path ( args . trestle_root ), input_path , output_path , args . profile , lut , parameters_formatting = args . param_formatting ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while generating markdown via Jinja template' ) @staticmethod def load_LUT ( path : pathlib . Path , prefix : Optional [ str ]) -> Dict [ str , Any ]: # noqa: N802 \"\"\"Load a Yaml lookup table from file.\"\"\" yaml = YAML () lut = yaml . load ( path . open ( 'r' , encoding = const . FILE_ENCODING )) if prefix : prefixes = prefix . split ( '.' ) while prefixes : old_lut = lut lut [ prefixes . pop ( - 1 )] = old_lut return lut @staticmethod def jinja_ify ( trestle_root : pathlib . Path , r_input_file : pathlib . Path , r_output_file : pathlib . Path , ssp : Optional [ str ], profile : Optional [ str ], lut : Dict [ str , Any ], number_captions : Optional [ bool ] = False , parameters_formatting : Optional [ str ] = None ) -> int : \"\"\"Run jinja over an input file with additional booleans.\"\"\" template_folder = pathlib . Path . cwd () jinja_env = Environment ( loader = FileSystemLoader ( template_folder ), extensions = [ MDSectionInclude , MDCleanInclude , MDDatestamp ], trim_blocks = True , autoescape = True ) template = jinja_env . get_template ( str ( r_input_file )) # create boolean dict if operator . xor ( bool ( ssp ), bool ( profile )): raise TrestleIncorrectArgsError ( 'Both SSP and profile should be provided or not at all' ) if ssp : # name lookup ssp_data , _ = ModelUtils . load_top_level_model ( trestle_root , ssp , SystemSecurityPlan ) lut [ 'ssp' ] = ssp_data _ , profile_path = ModelUtils . load_top_level_model ( trestle_root , profile , Profile ) profile_resolver = ProfileResolver () resolved_catalog = profile_resolver . get_resolved_profile_catalog ( trestle_root , profile_path , False , False , parameters_formatting ) ssp_writer = SSPMarkdownWriter ( trestle_root ) ssp_writer . set_ssp ( ssp_data ) ssp_writer . set_catalog ( resolved_catalog ) lut [ 'catalog' ] = resolved_catalog lut [ 'catalog_interface' ] = CatalogInterface ( resolved_catalog ) lut [ 'control_io_writer' ] = ControlIOWriter () lut [ 'ssp_md_writer' ] = ssp_writer output = JinjaCmd . render_template ( template , lut , template_folder ) output_file = trestle_root / r_output_file if number_captions : output_file . open ( 'w' , encoding = const . FILE_ENCODING ) . write ( _number_captions ( output )) else : output_file . open ( 'w' , encoding = const . FILE_ENCODING ) . write ( output ) return CmdReturnCodes . SUCCESS . value @staticmethod def jinja_multiple_md ( trestle_root : pathlib . Path , r_input_file : pathlib . Path , r_output_file : pathlib . Path , profile : Optional [ str ], lut : Dict [ str , Any ], parameters_formatting : Optional [ str ] = None ) -> int : \"\"\"Output profile as multiple markdown files using Jinja.\"\"\" template_folder = pathlib . Path . cwd () # Output to multiple markdown files _ , profile_path = ModelUtils . load_top_level_model ( trestle_root , profile , Profile ) profile_resolver = ProfileResolver () resolved_catalog = profile_resolver . get_resolved_profile_catalog ( trestle_root , profile_path , False , False , parameters_formatting ) catalog_interface = CatalogInterface ( resolved_catalog ) # Generate a single markdown page for each control per each group for group in catalog_interface . get_all_groups_from_catalog (): for control in catalog_interface . get_sorted_controls_in_group ( group . id ): _ , group_title , _ = catalog_interface . get_group_info_by_control ( control . id ) group_dir = r_output_file control_path = catalog_interface . get_control_path ( control . id ) for sub_dir in control_path : group_dir = group_dir / sub_dir if not group_dir . exists (): group_dir . mkdir ( parents = True , exist_ok = True ) control_writer = ControlIOWriter () jinja_env = Environment ( loader = FileSystemLoader ( template_folder ), extensions = [ MDSectionInclude , MDCleanInclude , MDDatestamp ], trim_blocks = True , autoescape = True ) template = jinja_env . get_template ( str ( r_input_file )) lut [ 'catalog_interface' ] = catalog_interface lut [ 'control_writer' ] = control_writer lut [ 'control' ] = control lut [ 'profile' ] = profile lut [ 'group_title' ] = group_title output = JinjaCmd . render_template ( template , lut , template_folder ) output_file = trestle_root / group_dir / pathlib . Path ( control . id + '.md' ) output_file . open ( 'w' , encoding = const . FILE_ENCODING ) . write ( output ) return CmdReturnCodes . SUCCESS . value @staticmethod def render_template ( template : Template , lut : Dict [ str , Any ], template_folder : pathlib . Path ) -> str : \"\"\"Render template.\"\"\" new_output = template . render ( ** lut ) output = '' # This recursion allows nesting within expressions (e.g. an expression can contain jinja templates). error_countdown = JinjaCmd . max_recursion_depth while new_output != output and error_countdown > 0 : error_countdown = error_countdown - 1 output = new_output random_name = uuid . uuid4 () # Should be random and not used. dict_loader = DictLoader ({ str ( random_name ): new_output }) jinja_env = Environment ( loader = ChoiceLoader ([ dict_loader , FileSystemLoader ( template_folder )]), extensions = [ MDCleanInclude , MDSectionInclude , MDDatestamp ], autoescape = True , trim_blocks = True ) template = jinja_env . get_template ( str ( random_name )) new_output = template . render ( ** lut ) return output","title":"JinjaCmd"},{"location":"api_reference/trestle.core.commands.author.jinja/#trestle.core.commands.author.jinja.JinjaCmd.max_recursion_depth","text":"","title":"max_recursion_depth"},{"location":"api_reference/trestle.core.commands.author.jinja/#trestle.core.commands.author.jinja.JinjaCmd.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.author.jinja/#trestle.core.commands.author.jinja.JinjaCmd-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.author.jinja/#trestle.core.commands.author.jinja.JinjaCmd.jinja_ify","text":"Run jinja over an input file with additional booleans. Source code in trestle/core/commands/author/jinja.py @staticmethod def jinja_ify ( trestle_root : pathlib . Path , r_input_file : pathlib . Path , r_output_file : pathlib . Path , ssp : Optional [ str ], profile : Optional [ str ], lut : Dict [ str , Any ], number_captions : Optional [ bool ] = False , parameters_formatting : Optional [ str ] = None ) -> int : \"\"\"Run jinja over an input file with additional booleans.\"\"\" template_folder = pathlib . Path . cwd () jinja_env = Environment ( loader = FileSystemLoader ( template_folder ), extensions = [ MDSectionInclude , MDCleanInclude , MDDatestamp ], trim_blocks = True , autoescape = True ) template = jinja_env . get_template ( str ( r_input_file )) # create boolean dict if operator . xor ( bool ( ssp ), bool ( profile )): raise TrestleIncorrectArgsError ( 'Both SSP and profile should be provided or not at all' ) if ssp : # name lookup ssp_data , _ = ModelUtils . load_top_level_model ( trestle_root , ssp , SystemSecurityPlan ) lut [ 'ssp' ] = ssp_data _ , profile_path = ModelUtils . load_top_level_model ( trestle_root , profile , Profile ) profile_resolver = ProfileResolver () resolved_catalog = profile_resolver . get_resolved_profile_catalog ( trestle_root , profile_path , False , False , parameters_formatting ) ssp_writer = SSPMarkdownWriter ( trestle_root ) ssp_writer . set_ssp ( ssp_data ) ssp_writer . set_catalog ( resolved_catalog ) lut [ 'catalog' ] = resolved_catalog lut [ 'catalog_interface' ] = CatalogInterface ( resolved_catalog ) lut [ 'control_io_writer' ] = ControlIOWriter () lut [ 'ssp_md_writer' ] = ssp_writer output = JinjaCmd . render_template ( template , lut , template_folder ) output_file = trestle_root / r_output_file if number_captions : output_file . open ( 'w' , encoding = const . FILE_ENCODING ) . write ( _number_captions ( output )) else : output_file . open ( 'w' , encoding = const . FILE_ENCODING ) . write ( output ) return CmdReturnCodes . SUCCESS . value","title":"jinja_ify()"},{"location":"api_reference/trestle.core.commands.author.jinja/#trestle.core.commands.author.jinja.JinjaCmd.jinja_multiple_md","text":"Output profile as multiple markdown files using Jinja. Source code in trestle/core/commands/author/jinja.py @staticmethod def jinja_multiple_md ( trestle_root : pathlib . Path , r_input_file : pathlib . Path , r_output_file : pathlib . Path , profile : Optional [ str ], lut : Dict [ str , Any ], parameters_formatting : Optional [ str ] = None ) -> int : \"\"\"Output profile as multiple markdown files using Jinja.\"\"\" template_folder = pathlib . Path . cwd () # Output to multiple markdown files _ , profile_path = ModelUtils . load_top_level_model ( trestle_root , profile , Profile ) profile_resolver = ProfileResolver () resolved_catalog = profile_resolver . get_resolved_profile_catalog ( trestle_root , profile_path , False , False , parameters_formatting ) catalog_interface = CatalogInterface ( resolved_catalog ) # Generate a single markdown page for each control per each group for group in catalog_interface . get_all_groups_from_catalog (): for control in catalog_interface . get_sorted_controls_in_group ( group . id ): _ , group_title , _ = catalog_interface . get_group_info_by_control ( control . id ) group_dir = r_output_file control_path = catalog_interface . get_control_path ( control . id ) for sub_dir in control_path : group_dir = group_dir / sub_dir if not group_dir . exists (): group_dir . mkdir ( parents = True , exist_ok = True ) control_writer = ControlIOWriter () jinja_env = Environment ( loader = FileSystemLoader ( template_folder ), extensions = [ MDSectionInclude , MDCleanInclude , MDDatestamp ], trim_blocks = True , autoescape = True ) template = jinja_env . get_template ( str ( r_input_file )) lut [ 'catalog_interface' ] = catalog_interface lut [ 'control_writer' ] = control_writer lut [ 'control' ] = control lut [ 'profile' ] = profile lut [ 'group_title' ] = group_title output = JinjaCmd . render_template ( template , lut , template_folder ) output_file = trestle_root / group_dir / pathlib . Path ( control . id + '.md' ) output_file . open ( 'w' , encoding = const . FILE_ENCODING ) . write ( output ) return CmdReturnCodes . SUCCESS . value","title":"jinja_multiple_md()"},{"location":"api_reference/trestle.core.commands.author.jinja/#trestle.core.commands.author.jinja.JinjaCmd.load_LUT","text":"Load a Yaml lookup table from file. Source code in trestle/core/commands/author/jinja.py @staticmethod def load_LUT ( path : pathlib . Path , prefix : Optional [ str ]) -> Dict [ str , Any ]: # noqa: N802 \"\"\"Load a Yaml lookup table from file.\"\"\" yaml = YAML () lut = yaml . load ( path . open ( 'r' , encoding = const . FILE_ENCODING )) if prefix : prefixes = prefix . split ( '.' ) while prefixes : old_lut = lut lut [ prefixes . pop ( - 1 )] = old_lut return lut","title":"load_LUT()"},{"location":"api_reference/trestle.core.commands.author.jinja/#trestle.core.commands.author.jinja.JinjaCmd.render_template","text":"Render template. Source code in trestle/core/commands/author/jinja.py @staticmethod def render_template ( template : Template , lut : Dict [ str , Any ], template_folder : pathlib . Path ) -> str : \"\"\"Render template.\"\"\" new_output = template . render ( ** lut ) output = '' # This recursion allows nesting within expressions (e.g. an expression can contain jinja templates). error_countdown = JinjaCmd . max_recursion_depth while new_output != output and error_countdown > 0 : error_countdown = error_countdown - 1 output = new_output random_name = uuid . uuid4 () # Should be random and not used. dict_loader = DictLoader ({ str ( random_name ): new_output }) jinja_env = Environment ( loader = ChoiceLoader ([ dict_loader , FileSystemLoader ( template_folder )]), extensions = [ MDCleanInclude , MDSectionInclude , MDDatestamp ], autoescape = True , trim_blocks = True ) template = jinja_env . get_template ( str ( random_name )) new_output = template . render ( ** lut ) return output handler: python","title":"render_template()"},{"location":"api_reference/trestle.core.commands.author.profile/","text":"trestle.core.commands.author.profile \u00a4 Author commands to generate profile as markdown and assemble to json after edit. logger \u00a4 Classes \u00a4 ProfileAssemble ( AuthorCommonCommand ) \u00a4 Assemble markdown files of controls into a Profile json file. Source code in trestle/core/commands/author/profile.py class ProfileAssemble ( AuthorCommonCommand ): \"\"\"Assemble markdown files of controls into a Profile json file.\"\"\" name = 'profile-assemble' def _init_arguments ( self ) -> None : name_help_str = ( 'Optional name of the profile model in the trestle workspace that is being modified. ' 'If not provided the output name is used.' ) self . add_argument ( '-n' , '--name' , help = name_help_str , required = False , type = str ) file_help_str = 'Name of the source markdown file directory' self . add_argument ( '-m' , '--markdown' , help = file_help_str , required = True , type = str ) output_help_str = 'Name of the output generated json Profile (ok to overwrite original)' self . add_argument ( '-o' , '--output' , help = output_help_str , required = True , type = str ) self . add_argument ( '-sp' , '--set-parameters' , action = 'store_true' , help = const . HELP_SET_PARAMS , required = False ) self . add_argument ( '-r' , '--regenerate' , action = 'store_true' , help = const . HELP_REGENERATE ) self . add_argument ( '-vn' , '--version' , help = const . HELP_VERSION , required = False , type = str ) self . add_argument ( '-rs' , '--required-sections' , help = const . HELP_REQUIRED_SECTIONS , required = False , type = str ) self . add_argument ( '-as' , '--allowed-sections' , help = const . HELP_ALLOWED_SECTIONS , required = False , type = str ) def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) trestle_root = pathlib . Path ( args . trestle_root ) return self . assemble_profile ( trestle_root = trestle_root , parent_prof_name = args . name , md_name = args . markdown , assem_prof_name = args . output , set_parameters = args . set_parameters , regenerate = args . regenerate , version = args . version , required_sections = args . required_sections , allowed_sections = args . allowed_sections ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Assembly of markdown to profile failed' ) @staticmethod def _replace_alter_adds ( profile : prof . Profile , alters : List [ prof . Alter ]) -> bool : \"\"\"Replace the alter adds in the orig_profile with the new ones and return True if changed.\"\"\" changed = False if not profile . modify : profile . modify = prof . Modify ( alters = alters ) if alters : changed = True elif not profile . modify . alters : profile . modify . alters = alters if alters : changed = True else : alter_dict = {} # if an alter has adds - remove them up front and build dict of alters by control id for alter in profile . modify . alters : alter . adds = None alter_dict [ alter . control_id ] = alter # now go through new alters and add them to each control in dict by control id for new_alter in alters : alter = alter_dict . get ( new_alter . control_id , None ) if alter : # even though we removed adds at start, we may have added one already if alter . adds : alter . adds . extend ( new_alter . adds ) else : alter . adds = new_alter . adds # update the dict with the new alter with its added adds alter_dict [ new_alter . control_id ] = alter # get the new list of alters from the dict and update profile new_alters = list ( alter_dict . values ()) if profile . modify . alters != new_alters : changed = True profile . modify . alters = new_alters return changed @staticmethod def _replace_modify_set_params ( profile : prof . Profile , param_dict : Dict [ str , Any ], param_map : Dict [ str , str ] ) -> bool : \"\"\" Replace the set_params in the profile with list and values from markdown. Notes: Returns whether or not change was made. \"\"\" changed = False if param_dict : if not profile . modify : profile . modify = prof . Modify () new_set_params : List [ prof . SetParameter ] = [] for key , sub_param_dict in param_dict . items (): if sub_param_dict : sub_param_dict [ 'id' ] = key param = ModelUtils . dict_to_parameter ( sub_param_dict ) new_set_params . append ( prof . SetParameter ( param_id = key , label = param . label , values = param . values , select = param . select ) ) if profile . modify . set_parameters != new_set_params : changed = True # sort the params first by control sorting then by param_id profile . modify . set_parameters = sorted ( new_set_params , key = lambda param : ( param_map [ param . param_id ], param . param_id ) ) return changed @staticmethod def assemble_profile ( trestle_root : pathlib . Path , parent_prof_name : str , md_name : str , assem_prof_name : str , set_parameters : bool , regenerate : bool , version : Optional [ str ], required_sections : Optional [ str ], allowed_sections : Optional [ List [ str ]] ) -> int : \"\"\" Assemble the markdown directory into a json profile model file. Args: trestle_root: The trestle root directory parent_prof_name: Optional name of profile used to generate the markdown (default is assem_prof_name) md_name: The name of the directory containing the markdown control files for the profile assem_prof_name: The name of the assembled profile. It can be the same as the parent to overwrite set_parameters: Use the parameters in the yaml header to specify values for setparameters in the profile regenerate: Whether to regenerate the uuid's in the profile version: Optional version for the assembled profile required_sections: Optional List of required sections in assembled profile, as comma-separated short names allowed_sections: Optional list of section short names that are allowed, as comma-separated short names Returns: 0 on success, 1 otherwise Notes: There must already be a profile model and it will either be updated or a new json profile created. The generated markdown has the current values for parameters of controls being imported, as set by the original catalog and any intermediate profiles. It also shows the current SetParameters being applied by this profile. That list of SetParameters can be edited by changing the assigned values and adding or removing SetParameters from that list. During assembly that list will be used to create the SetParameters in the assembled profile if the --set-parameters option is specified. \"\"\" md_dir = trestle_root / md_name if not md_dir . exists (): raise TrestleError ( f 'Markdown directory { md_name } does not exist.' ) if not parent_prof_name : parent_prof_name = assem_prof_name parent_prof , parent_prof_path = ModelUtils . load_top_level_model ( trestle_root , parent_prof_name , prof . Profile ) new_content_type = FileContentType . path_to_content_type ( parent_prof_path ) required_sections_list = required_sections . split ( ',' ) if required_sections else [] # load the editable sections of the markdown and create Adds for them # then overwrite the Adds in the existing profile with the new ones # keep track if any changes were made md_dir = trestle_root / md_name found_alters , param_dict , param_map = CatalogInterface . read_additional_content ( md_dir , required_sections_list ) if allowed_sections : for alter in found_alters : for add in alter . adds : for part in add . parts : if part . name not in allowed_sections : raise TrestleError ( f 'Profile has alter with name { part . name } not in allowed sections.' ) ProfileAssemble . _replace_alter_adds ( parent_prof , found_alters ) if set_parameters : ProfileAssemble . _replace_modify_set_params ( parent_prof , param_dict , param_map ) if version : parent_prof . metadata . version = com . Version ( __root__ = version ) assem_prof_path = ModelUtils . path_for_top_level_model ( trestle_root , assem_prof_name , prof . Profile , new_content_type ) if assem_prof_path . exists (): _ , _ , existing_prof = ModelUtils . load_distributed ( assem_prof_path , trestle_root ) if ModelUtils . models_are_equivalent ( existing_prof , parent_prof ): logger . info ( 'Assembled profile is no different from existing version, so no update.' ) return CmdReturnCodes . SUCCESS . value if regenerate : parent_prof , _ , _ = ModelUtils . regenerate_uuids ( parent_prof ) ModelUtils . update_last_modified ( parent_prof ) if assem_prof_path . parent . exists (): logger . info ( 'Creating profile from markdown and destination profile exists, so updating.' ) shutil . rmtree ( str ( assem_prof_path . parent )) assem_prof_path . parent . mkdir ( parents = True , exist_ok = True ) parent_prof . oscal_write ( assem_prof_path ) return CmdReturnCodes . SUCCESS . value name \u00a4 Methods \u00a4 assemble_profile ( trestle_root , parent_prof_name , md_name , assem_prof_name , set_parameters , regenerate , version , required_sections , allowed_sections ) staticmethod \u00a4 Assemble the markdown directory into a json profile model file. Parameters: Name Type Description Default trestle_root Path The trestle root directory required parent_prof_name str Optional name of profile used to generate the markdown (default is assem_prof_name) required md_name str The name of the directory containing the markdown control files for the profile required assem_prof_name str The name of the assembled profile. It can be the same as the parent to overwrite required set_parameters bool Use the parameters in the yaml header to specify values for setparameters in the profile required regenerate bool Whether to regenerate the uuid's in the profile required version Optional[str] Optional version for the assembled profile required required_sections Optional[str] Optional List of required sections in assembled profile, as comma-separated short names required allowed_sections Optional[List[str]] Optional list of section short names that are allowed, as comma-separated short names required Returns: Type Description int 0 on success, 1 otherwise Notes There must already be a profile model and it will either be updated or a new json profile created. The generated markdown has the current values for parameters of controls being imported, as set by the original catalog and any intermediate profiles. It also shows the current SetParameters being applied by this profile. That list of SetParameters can be edited by changing the assigned values and adding or removing SetParameters from that list. During assembly that list will be used to create the SetParameters in the assembled profile if the --set-parameters option is specified. Source code in trestle/core/commands/author/profile.py @staticmethod def assemble_profile ( trestle_root : pathlib . Path , parent_prof_name : str , md_name : str , assem_prof_name : str , set_parameters : bool , regenerate : bool , version : Optional [ str ], required_sections : Optional [ str ], allowed_sections : Optional [ List [ str ]] ) -> int : \"\"\" Assemble the markdown directory into a json profile model file. Args: trestle_root: The trestle root directory parent_prof_name: Optional name of profile used to generate the markdown (default is assem_prof_name) md_name: The name of the directory containing the markdown control files for the profile assem_prof_name: The name of the assembled profile. It can be the same as the parent to overwrite set_parameters: Use the parameters in the yaml header to specify values for setparameters in the profile regenerate: Whether to regenerate the uuid's in the profile version: Optional version for the assembled profile required_sections: Optional List of required sections in assembled profile, as comma-separated short names allowed_sections: Optional list of section short names that are allowed, as comma-separated short names Returns: 0 on success, 1 otherwise Notes: There must already be a profile model and it will either be updated or a new json profile created. The generated markdown has the current values for parameters of controls being imported, as set by the original catalog and any intermediate profiles. It also shows the current SetParameters being applied by this profile. That list of SetParameters can be edited by changing the assigned values and adding or removing SetParameters from that list. During assembly that list will be used to create the SetParameters in the assembled profile if the --set-parameters option is specified. \"\"\" md_dir = trestle_root / md_name if not md_dir . exists (): raise TrestleError ( f 'Markdown directory { md_name } does not exist.' ) if not parent_prof_name : parent_prof_name = assem_prof_name parent_prof , parent_prof_path = ModelUtils . load_top_level_model ( trestle_root , parent_prof_name , prof . Profile ) new_content_type = FileContentType . path_to_content_type ( parent_prof_path ) required_sections_list = required_sections . split ( ',' ) if required_sections else [] # load the editable sections of the markdown and create Adds for them # then overwrite the Adds in the existing profile with the new ones # keep track if any changes were made md_dir = trestle_root / md_name found_alters , param_dict , param_map = CatalogInterface . read_additional_content ( md_dir , required_sections_list ) if allowed_sections : for alter in found_alters : for add in alter . adds : for part in add . parts : if part . name not in allowed_sections : raise TrestleError ( f 'Profile has alter with name { part . name } not in allowed sections.' ) ProfileAssemble . _replace_alter_adds ( parent_prof , found_alters ) if set_parameters : ProfileAssemble . _replace_modify_set_params ( parent_prof , param_dict , param_map ) if version : parent_prof . metadata . version = com . Version ( __root__ = version ) assem_prof_path = ModelUtils . path_for_top_level_model ( trestle_root , assem_prof_name , prof . Profile , new_content_type ) if assem_prof_path . exists (): _ , _ , existing_prof = ModelUtils . load_distributed ( assem_prof_path , trestle_root ) if ModelUtils . models_are_equivalent ( existing_prof , parent_prof ): logger . info ( 'Assembled profile is no different from existing version, so no update.' ) return CmdReturnCodes . SUCCESS . value if regenerate : parent_prof , _ , _ = ModelUtils . regenerate_uuids ( parent_prof ) ModelUtils . update_last_modified ( parent_prof ) if assem_prof_path . parent . exists (): logger . info ( 'Creating profile from markdown and destination profile exists, so updating.' ) shutil . rmtree ( str ( assem_prof_path . parent )) assem_prof_path . parent . mkdir ( parents = True , exist_ok = True ) parent_prof . oscal_write ( assem_prof_path ) return CmdReturnCodes . SUCCESS . value ProfileGenerate ( AuthorCommonCommand ) \u00a4 Generate profile in markdown form from a profile in the trestle workspace. Source code in trestle/core/commands/author/profile.py class ProfileGenerate ( AuthorCommonCommand ): \"\"\"Generate profile in markdown form from a profile in the trestle workspace.\"\"\" name = 'profile-generate' def _init_arguments ( self ) -> None : name_help_str = 'Name of the source profile model in the trestle workspace' self . add_argument ( '-n' , '--name' , help = name_help_str , required = True , type = str ) self . add_argument ( '-o' , '--output' , help = const . HELP_MARKDOWN_NAME , required = True , type = str ) self . add_argument ( '-y' , '--yaml-header' , help = const . HELP_YAML_PATH , required = False , type = str ) self . add_argument ( '-ohv' , '--overwrite-header-values' , help = const . HELP_OVERWRITE_HEADER_VALUES , required = False , action = 'store_true' , default = False ) self . add_argument ( '-s' , '--sections' , help = const . HELP_SECTIONS , required = False , type = str ) self . add_argument ( '-rs' , '--required-sections' , help = const . HELP_REQUIRED_SECTIONS , required = False , type = str ) def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) trestle_root : pathlib . Path = args . trestle_root if not file_utils . is_directory_name_allowed ( args . output ): raise TrestleError ( f ' { args . output } is not an allowed directory name' ) yaml_header : dict = {} if args . yaml_header : try : logging . debug ( f 'Loading yaml header file { args . yaml_header } ' ) yaml = YAML () yaml_header = yaml . load ( pathlib . Path ( args . yaml_header ) . open ( 'r' )) except YAMLError as e : raise TrestleError ( f 'YAML error loading yaml header for ssp generation: { e } ' ) # combine command line sections with any in the yaml header, with priority to command line sections_dict : Optional [ Dict [ str , str ]] = None if args . sections : sections_dict = sections_to_dict ( args . sections ) profile_path = trestle_root / f 'profiles/ { args . name } /profile.json' markdown_path = trestle_root / args . output return self . generate_markdown ( trestle_root , profile_path , markdown_path , yaml_header , args . overwrite_header_values , sections_dict , args . required_sections ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Generation of the profile markdown failed' ) def generate_markdown ( self , trestle_root : pathlib . Path , profile_path : pathlib . Path , markdown_path : pathlib . Path , yaml_header : dict , overwrite_header_values : bool , sections_dict : Optional [ Dict [ str , str ]], required_sections : Optional [ str ] ) -> int : \"\"\"Generate markdown for the controls in the profile. Args: trestle_root: Root directory of the trestle workspace profile_path: Path of the profile json file markdown_path: Path to the directory into which the markdown will be written yaml_header: Dict to merge into the yaml header of the control markdown overwrite_header_values: Overwrite values in the markdown header but allow new items to be added sections_dict: Optional dict mapping section short names to long required_sections: Optional comma-sep list of sections that get prompted for prose if not in the profile Returns: 0 on success, 1 on error \"\"\" try : if sections_dict and 'statement' in sections_dict : logger . warning ( 'statement is not allowed as a section name.' ) return CmdReturnCodes . COMMAND_ERROR . value _ , _ , profile = ModelUtils . load_distributed ( profile_path , trestle_root ) catalog = ProfileResolver () . get_resolved_profile_catalog ( trestle_root , profile_path , True , True , None , ParameterRep . LEAVE_MOUSTACHE ) catalog_interface = CatalogInterface ( catalog ) catalog_interface . write_catalog_as_markdown ( md_path = markdown_path , yaml_header = yaml_header , sections_dict = sections_dict , prompt_responses = False , additional_content = True , profile = profile , overwrite_header_values = overwrite_header_values , set_parameters = True , required_sections = required_sections , allowed_sections = None ) except TrestleNotFoundError as e : raise TrestleError ( f 'Profile { profile_path } not found, error { e } ' ) except TrestleError as e : raise TrestleError ( f 'Error generating the catalog as markdown: { e } ' ) return CmdReturnCodes . SUCCESS . value name \u00a4 Methods \u00a4 generate_markdown ( self , trestle_root , profile_path , markdown_path , yaml_header , overwrite_header_values , sections_dict , required_sections ) \u00a4 Generate markdown for the controls in the profile. Parameters: Name Type Description Default trestle_root Path Root directory of the trestle workspace required profile_path Path Path of the profile json file required markdown_path Path Path to the directory into which the markdown will be written required yaml_header dict Dict to merge into the yaml header of the control markdown required overwrite_header_values bool Overwrite values in the markdown header but allow new items to be added required sections_dict Optional[Dict[str, str]] Optional dict mapping section short names to long required required_sections Optional[str] Optional comma-sep list of sections that get prompted for prose if not in the profile required Returns: Type Description int 0 on success, 1 on error Source code in trestle/core/commands/author/profile.py def generate_markdown ( self , trestle_root : pathlib . Path , profile_path : pathlib . Path , markdown_path : pathlib . Path , yaml_header : dict , overwrite_header_values : bool , sections_dict : Optional [ Dict [ str , str ]], required_sections : Optional [ str ] ) -> int : \"\"\"Generate markdown for the controls in the profile. Args: trestle_root: Root directory of the trestle workspace profile_path: Path of the profile json file markdown_path: Path to the directory into which the markdown will be written yaml_header: Dict to merge into the yaml header of the control markdown overwrite_header_values: Overwrite values in the markdown header but allow new items to be added sections_dict: Optional dict mapping section short names to long required_sections: Optional comma-sep list of sections that get prompted for prose if not in the profile Returns: 0 on success, 1 on error \"\"\" try : if sections_dict and 'statement' in sections_dict : logger . warning ( 'statement is not allowed as a section name.' ) return CmdReturnCodes . COMMAND_ERROR . value _ , _ , profile = ModelUtils . load_distributed ( profile_path , trestle_root ) catalog = ProfileResolver () . get_resolved_profile_catalog ( trestle_root , profile_path , True , True , None , ParameterRep . LEAVE_MOUSTACHE ) catalog_interface = CatalogInterface ( catalog ) catalog_interface . write_catalog_as_markdown ( md_path = markdown_path , yaml_header = yaml_header , sections_dict = sections_dict , prompt_responses = False , additional_content = True , profile = profile , overwrite_header_values = overwrite_header_values , set_parameters = True , required_sections = required_sections , allowed_sections = None ) except TrestleNotFoundError as e : raise TrestleError ( f 'Profile { profile_path } not found, error { e } ' ) except TrestleError as e : raise TrestleError ( f 'Error generating the catalog as markdown: { e } ' ) return CmdReturnCodes . SUCCESS . value Functions \u00a4 sections_to_dict ( sections ) \u00a4 Convert sections string to dict mapping short to long names. Parameters: Name Type Description Default sections Optional[str] String containing comma-sep pars of short_name:long_name for sections required Returns: Type Description Dict[str, str] Dict mapping short names to long names Notes If the long name is not provided (single string and no :) the long name is same as short name. This is needed to map the internal part name for a guidance section to its long name in the formatted markdown. Source code in trestle/core/commands/author/profile.py def sections_to_dict ( sections : Optional [ str ]) -> Dict [ str , str ]: \"\"\" Convert sections string to dict mapping short to long names. Args: sections: String containing comma-sep pars of short_name:long_name for sections Returns: Dict mapping short names to long names Notes: If the long name is not provided (single string and no :) the long name is same as short name. This is needed to map the internal part name for a guidance section to its long name in the formatted markdown. \"\"\" sections_dict : Dict [ str , str ] = {} if sections : section_pairs = sections . strip ( \"'\" ) . split ( ',' ) # section pair is a single string possibly containing : and is either short_name:long_name or just short_name for section_pair in section_pairs : if ':' in section_pair : section_tuple = section_pair . split ( ':' ) sections_dict [ section_tuple [ 0 ] . strip ()] = section_tuple [ 1 ] . strip () else : sections_dict [ section_pair ] = section_pair return sections_dict handler: python","title":"profile"},{"location":"api_reference/trestle.core.commands.author.profile/#trestle.core.commands.author.profile","text":"Author commands to generate profile as markdown and assemble to json after edit.","title":"profile"},{"location":"api_reference/trestle.core.commands.author.profile/#trestle.core.commands.author.profile.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.author.profile/#trestle.core.commands.author.profile-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.author.profile/#trestle.core.commands.author.profile.ProfileAssemble","text":"Assemble markdown files of controls into a Profile json file. Source code in trestle/core/commands/author/profile.py class ProfileAssemble ( AuthorCommonCommand ): \"\"\"Assemble markdown files of controls into a Profile json file.\"\"\" name = 'profile-assemble' def _init_arguments ( self ) -> None : name_help_str = ( 'Optional name of the profile model in the trestle workspace that is being modified. ' 'If not provided the output name is used.' ) self . add_argument ( '-n' , '--name' , help = name_help_str , required = False , type = str ) file_help_str = 'Name of the source markdown file directory' self . add_argument ( '-m' , '--markdown' , help = file_help_str , required = True , type = str ) output_help_str = 'Name of the output generated json Profile (ok to overwrite original)' self . add_argument ( '-o' , '--output' , help = output_help_str , required = True , type = str ) self . add_argument ( '-sp' , '--set-parameters' , action = 'store_true' , help = const . HELP_SET_PARAMS , required = False ) self . add_argument ( '-r' , '--regenerate' , action = 'store_true' , help = const . HELP_REGENERATE ) self . add_argument ( '-vn' , '--version' , help = const . HELP_VERSION , required = False , type = str ) self . add_argument ( '-rs' , '--required-sections' , help = const . HELP_REQUIRED_SECTIONS , required = False , type = str ) self . add_argument ( '-as' , '--allowed-sections' , help = const . HELP_ALLOWED_SECTIONS , required = False , type = str ) def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) trestle_root = pathlib . Path ( args . trestle_root ) return self . assemble_profile ( trestle_root = trestle_root , parent_prof_name = args . name , md_name = args . markdown , assem_prof_name = args . output , set_parameters = args . set_parameters , regenerate = args . regenerate , version = args . version , required_sections = args . required_sections , allowed_sections = args . allowed_sections ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Assembly of markdown to profile failed' ) @staticmethod def _replace_alter_adds ( profile : prof . Profile , alters : List [ prof . Alter ]) -> bool : \"\"\"Replace the alter adds in the orig_profile with the new ones and return True if changed.\"\"\" changed = False if not profile . modify : profile . modify = prof . Modify ( alters = alters ) if alters : changed = True elif not profile . modify . alters : profile . modify . alters = alters if alters : changed = True else : alter_dict = {} # if an alter has adds - remove them up front and build dict of alters by control id for alter in profile . modify . alters : alter . adds = None alter_dict [ alter . control_id ] = alter # now go through new alters and add them to each control in dict by control id for new_alter in alters : alter = alter_dict . get ( new_alter . control_id , None ) if alter : # even though we removed adds at start, we may have added one already if alter . adds : alter . adds . extend ( new_alter . adds ) else : alter . adds = new_alter . adds # update the dict with the new alter with its added adds alter_dict [ new_alter . control_id ] = alter # get the new list of alters from the dict and update profile new_alters = list ( alter_dict . values ()) if profile . modify . alters != new_alters : changed = True profile . modify . alters = new_alters return changed @staticmethod def _replace_modify_set_params ( profile : prof . Profile , param_dict : Dict [ str , Any ], param_map : Dict [ str , str ] ) -> bool : \"\"\" Replace the set_params in the profile with list and values from markdown. Notes: Returns whether or not change was made. \"\"\" changed = False if param_dict : if not profile . modify : profile . modify = prof . Modify () new_set_params : List [ prof . SetParameter ] = [] for key , sub_param_dict in param_dict . items (): if sub_param_dict : sub_param_dict [ 'id' ] = key param = ModelUtils . dict_to_parameter ( sub_param_dict ) new_set_params . append ( prof . SetParameter ( param_id = key , label = param . label , values = param . values , select = param . select ) ) if profile . modify . set_parameters != new_set_params : changed = True # sort the params first by control sorting then by param_id profile . modify . set_parameters = sorted ( new_set_params , key = lambda param : ( param_map [ param . param_id ], param . param_id ) ) return changed @staticmethod def assemble_profile ( trestle_root : pathlib . Path , parent_prof_name : str , md_name : str , assem_prof_name : str , set_parameters : bool , regenerate : bool , version : Optional [ str ], required_sections : Optional [ str ], allowed_sections : Optional [ List [ str ]] ) -> int : \"\"\" Assemble the markdown directory into a json profile model file. Args: trestle_root: The trestle root directory parent_prof_name: Optional name of profile used to generate the markdown (default is assem_prof_name) md_name: The name of the directory containing the markdown control files for the profile assem_prof_name: The name of the assembled profile. It can be the same as the parent to overwrite set_parameters: Use the parameters in the yaml header to specify values for setparameters in the profile regenerate: Whether to regenerate the uuid's in the profile version: Optional version for the assembled profile required_sections: Optional List of required sections in assembled profile, as comma-separated short names allowed_sections: Optional list of section short names that are allowed, as comma-separated short names Returns: 0 on success, 1 otherwise Notes: There must already be a profile model and it will either be updated or a new json profile created. The generated markdown has the current values for parameters of controls being imported, as set by the original catalog and any intermediate profiles. It also shows the current SetParameters being applied by this profile. That list of SetParameters can be edited by changing the assigned values and adding or removing SetParameters from that list. During assembly that list will be used to create the SetParameters in the assembled profile if the --set-parameters option is specified. \"\"\" md_dir = trestle_root / md_name if not md_dir . exists (): raise TrestleError ( f 'Markdown directory { md_name } does not exist.' ) if not parent_prof_name : parent_prof_name = assem_prof_name parent_prof , parent_prof_path = ModelUtils . load_top_level_model ( trestle_root , parent_prof_name , prof . Profile ) new_content_type = FileContentType . path_to_content_type ( parent_prof_path ) required_sections_list = required_sections . split ( ',' ) if required_sections else [] # load the editable sections of the markdown and create Adds for them # then overwrite the Adds in the existing profile with the new ones # keep track if any changes were made md_dir = trestle_root / md_name found_alters , param_dict , param_map = CatalogInterface . read_additional_content ( md_dir , required_sections_list ) if allowed_sections : for alter in found_alters : for add in alter . adds : for part in add . parts : if part . name not in allowed_sections : raise TrestleError ( f 'Profile has alter with name { part . name } not in allowed sections.' ) ProfileAssemble . _replace_alter_adds ( parent_prof , found_alters ) if set_parameters : ProfileAssemble . _replace_modify_set_params ( parent_prof , param_dict , param_map ) if version : parent_prof . metadata . version = com . Version ( __root__ = version ) assem_prof_path = ModelUtils . path_for_top_level_model ( trestle_root , assem_prof_name , prof . Profile , new_content_type ) if assem_prof_path . exists (): _ , _ , existing_prof = ModelUtils . load_distributed ( assem_prof_path , trestle_root ) if ModelUtils . models_are_equivalent ( existing_prof , parent_prof ): logger . info ( 'Assembled profile is no different from existing version, so no update.' ) return CmdReturnCodes . SUCCESS . value if regenerate : parent_prof , _ , _ = ModelUtils . regenerate_uuids ( parent_prof ) ModelUtils . update_last_modified ( parent_prof ) if assem_prof_path . parent . exists (): logger . info ( 'Creating profile from markdown and destination profile exists, so updating.' ) shutil . rmtree ( str ( assem_prof_path . parent )) assem_prof_path . parent . mkdir ( parents = True , exist_ok = True ) parent_prof . oscal_write ( assem_prof_path ) return CmdReturnCodes . SUCCESS . value","title":"ProfileAssemble"},{"location":"api_reference/trestle.core.commands.author.profile/#trestle.core.commands.author.profile.ProfileAssemble.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.author.profile/#trestle.core.commands.author.profile.ProfileAssemble-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.author.profile/#trestle.core.commands.author.profile.ProfileAssemble.assemble_profile","text":"Assemble the markdown directory into a json profile model file. Parameters: Name Type Description Default trestle_root Path The trestle root directory required parent_prof_name str Optional name of profile used to generate the markdown (default is assem_prof_name) required md_name str The name of the directory containing the markdown control files for the profile required assem_prof_name str The name of the assembled profile. It can be the same as the parent to overwrite required set_parameters bool Use the parameters in the yaml header to specify values for setparameters in the profile required regenerate bool Whether to regenerate the uuid's in the profile required version Optional[str] Optional version for the assembled profile required required_sections Optional[str] Optional List of required sections in assembled profile, as comma-separated short names required allowed_sections Optional[List[str]] Optional list of section short names that are allowed, as comma-separated short names required Returns: Type Description int 0 on success, 1 otherwise Notes There must already be a profile model and it will either be updated or a new json profile created. The generated markdown has the current values for parameters of controls being imported, as set by the original catalog and any intermediate profiles. It also shows the current SetParameters being applied by this profile. That list of SetParameters can be edited by changing the assigned values and adding or removing SetParameters from that list. During assembly that list will be used to create the SetParameters in the assembled profile if the --set-parameters option is specified. Source code in trestle/core/commands/author/profile.py @staticmethod def assemble_profile ( trestle_root : pathlib . Path , parent_prof_name : str , md_name : str , assem_prof_name : str , set_parameters : bool , regenerate : bool , version : Optional [ str ], required_sections : Optional [ str ], allowed_sections : Optional [ List [ str ]] ) -> int : \"\"\" Assemble the markdown directory into a json profile model file. Args: trestle_root: The trestle root directory parent_prof_name: Optional name of profile used to generate the markdown (default is assem_prof_name) md_name: The name of the directory containing the markdown control files for the profile assem_prof_name: The name of the assembled profile. It can be the same as the parent to overwrite set_parameters: Use the parameters in the yaml header to specify values for setparameters in the profile regenerate: Whether to regenerate the uuid's in the profile version: Optional version for the assembled profile required_sections: Optional List of required sections in assembled profile, as comma-separated short names allowed_sections: Optional list of section short names that are allowed, as comma-separated short names Returns: 0 on success, 1 otherwise Notes: There must already be a profile model and it will either be updated or a new json profile created. The generated markdown has the current values for parameters of controls being imported, as set by the original catalog and any intermediate profiles. It also shows the current SetParameters being applied by this profile. That list of SetParameters can be edited by changing the assigned values and adding or removing SetParameters from that list. During assembly that list will be used to create the SetParameters in the assembled profile if the --set-parameters option is specified. \"\"\" md_dir = trestle_root / md_name if not md_dir . exists (): raise TrestleError ( f 'Markdown directory { md_name } does not exist.' ) if not parent_prof_name : parent_prof_name = assem_prof_name parent_prof , parent_prof_path = ModelUtils . load_top_level_model ( trestle_root , parent_prof_name , prof . Profile ) new_content_type = FileContentType . path_to_content_type ( parent_prof_path ) required_sections_list = required_sections . split ( ',' ) if required_sections else [] # load the editable sections of the markdown and create Adds for them # then overwrite the Adds in the existing profile with the new ones # keep track if any changes were made md_dir = trestle_root / md_name found_alters , param_dict , param_map = CatalogInterface . read_additional_content ( md_dir , required_sections_list ) if allowed_sections : for alter in found_alters : for add in alter . adds : for part in add . parts : if part . name not in allowed_sections : raise TrestleError ( f 'Profile has alter with name { part . name } not in allowed sections.' ) ProfileAssemble . _replace_alter_adds ( parent_prof , found_alters ) if set_parameters : ProfileAssemble . _replace_modify_set_params ( parent_prof , param_dict , param_map ) if version : parent_prof . metadata . version = com . Version ( __root__ = version ) assem_prof_path = ModelUtils . path_for_top_level_model ( trestle_root , assem_prof_name , prof . Profile , new_content_type ) if assem_prof_path . exists (): _ , _ , existing_prof = ModelUtils . load_distributed ( assem_prof_path , trestle_root ) if ModelUtils . models_are_equivalent ( existing_prof , parent_prof ): logger . info ( 'Assembled profile is no different from existing version, so no update.' ) return CmdReturnCodes . SUCCESS . value if regenerate : parent_prof , _ , _ = ModelUtils . regenerate_uuids ( parent_prof ) ModelUtils . update_last_modified ( parent_prof ) if assem_prof_path . parent . exists (): logger . info ( 'Creating profile from markdown and destination profile exists, so updating.' ) shutil . rmtree ( str ( assem_prof_path . parent )) assem_prof_path . parent . mkdir ( parents = True , exist_ok = True ) parent_prof . oscal_write ( assem_prof_path ) return CmdReturnCodes . SUCCESS . value","title":"assemble_profile()"},{"location":"api_reference/trestle.core.commands.author.profile/#trestle.core.commands.author.profile.ProfileGenerate","text":"Generate profile in markdown form from a profile in the trestle workspace. Source code in trestle/core/commands/author/profile.py class ProfileGenerate ( AuthorCommonCommand ): \"\"\"Generate profile in markdown form from a profile in the trestle workspace.\"\"\" name = 'profile-generate' def _init_arguments ( self ) -> None : name_help_str = 'Name of the source profile model in the trestle workspace' self . add_argument ( '-n' , '--name' , help = name_help_str , required = True , type = str ) self . add_argument ( '-o' , '--output' , help = const . HELP_MARKDOWN_NAME , required = True , type = str ) self . add_argument ( '-y' , '--yaml-header' , help = const . HELP_YAML_PATH , required = False , type = str ) self . add_argument ( '-ohv' , '--overwrite-header-values' , help = const . HELP_OVERWRITE_HEADER_VALUES , required = False , action = 'store_true' , default = False ) self . add_argument ( '-s' , '--sections' , help = const . HELP_SECTIONS , required = False , type = str ) self . add_argument ( '-rs' , '--required-sections' , help = const . HELP_REQUIRED_SECTIONS , required = False , type = str ) def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) trestle_root : pathlib . Path = args . trestle_root if not file_utils . is_directory_name_allowed ( args . output ): raise TrestleError ( f ' { args . output } is not an allowed directory name' ) yaml_header : dict = {} if args . yaml_header : try : logging . debug ( f 'Loading yaml header file { args . yaml_header } ' ) yaml = YAML () yaml_header = yaml . load ( pathlib . Path ( args . yaml_header ) . open ( 'r' )) except YAMLError as e : raise TrestleError ( f 'YAML error loading yaml header for ssp generation: { e } ' ) # combine command line sections with any in the yaml header, with priority to command line sections_dict : Optional [ Dict [ str , str ]] = None if args . sections : sections_dict = sections_to_dict ( args . sections ) profile_path = trestle_root / f 'profiles/ { args . name } /profile.json' markdown_path = trestle_root / args . output return self . generate_markdown ( trestle_root , profile_path , markdown_path , yaml_header , args . overwrite_header_values , sections_dict , args . required_sections ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Generation of the profile markdown failed' ) def generate_markdown ( self , trestle_root : pathlib . Path , profile_path : pathlib . Path , markdown_path : pathlib . Path , yaml_header : dict , overwrite_header_values : bool , sections_dict : Optional [ Dict [ str , str ]], required_sections : Optional [ str ] ) -> int : \"\"\"Generate markdown for the controls in the profile. Args: trestle_root: Root directory of the trestle workspace profile_path: Path of the profile json file markdown_path: Path to the directory into which the markdown will be written yaml_header: Dict to merge into the yaml header of the control markdown overwrite_header_values: Overwrite values in the markdown header but allow new items to be added sections_dict: Optional dict mapping section short names to long required_sections: Optional comma-sep list of sections that get prompted for prose if not in the profile Returns: 0 on success, 1 on error \"\"\" try : if sections_dict and 'statement' in sections_dict : logger . warning ( 'statement is not allowed as a section name.' ) return CmdReturnCodes . COMMAND_ERROR . value _ , _ , profile = ModelUtils . load_distributed ( profile_path , trestle_root ) catalog = ProfileResolver () . get_resolved_profile_catalog ( trestle_root , profile_path , True , True , None , ParameterRep . LEAVE_MOUSTACHE ) catalog_interface = CatalogInterface ( catalog ) catalog_interface . write_catalog_as_markdown ( md_path = markdown_path , yaml_header = yaml_header , sections_dict = sections_dict , prompt_responses = False , additional_content = True , profile = profile , overwrite_header_values = overwrite_header_values , set_parameters = True , required_sections = required_sections , allowed_sections = None ) except TrestleNotFoundError as e : raise TrestleError ( f 'Profile { profile_path } not found, error { e } ' ) except TrestleError as e : raise TrestleError ( f 'Error generating the catalog as markdown: { e } ' ) return CmdReturnCodes . SUCCESS . value","title":"ProfileGenerate"},{"location":"api_reference/trestle.core.commands.author.profile/#trestle.core.commands.author.profile.ProfileGenerate.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.author.profile/#trestle.core.commands.author.profile.ProfileGenerate-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.author.profile/#trestle.core.commands.author.profile.ProfileGenerate.generate_markdown","text":"Generate markdown for the controls in the profile. Parameters: Name Type Description Default trestle_root Path Root directory of the trestle workspace required profile_path Path Path of the profile json file required markdown_path Path Path to the directory into which the markdown will be written required yaml_header dict Dict to merge into the yaml header of the control markdown required overwrite_header_values bool Overwrite values in the markdown header but allow new items to be added required sections_dict Optional[Dict[str, str]] Optional dict mapping section short names to long required required_sections Optional[str] Optional comma-sep list of sections that get prompted for prose if not in the profile required Returns: Type Description int 0 on success, 1 on error Source code in trestle/core/commands/author/profile.py def generate_markdown ( self , trestle_root : pathlib . Path , profile_path : pathlib . Path , markdown_path : pathlib . Path , yaml_header : dict , overwrite_header_values : bool , sections_dict : Optional [ Dict [ str , str ]], required_sections : Optional [ str ] ) -> int : \"\"\"Generate markdown for the controls in the profile. Args: trestle_root: Root directory of the trestle workspace profile_path: Path of the profile json file markdown_path: Path to the directory into which the markdown will be written yaml_header: Dict to merge into the yaml header of the control markdown overwrite_header_values: Overwrite values in the markdown header but allow new items to be added sections_dict: Optional dict mapping section short names to long required_sections: Optional comma-sep list of sections that get prompted for prose if not in the profile Returns: 0 on success, 1 on error \"\"\" try : if sections_dict and 'statement' in sections_dict : logger . warning ( 'statement is not allowed as a section name.' ) return CmdReturnCodes . COMMAND_ERROR . value _ , _ , profile = ModelUtils . load_distributed ( profile_path , trestle_root ) catalog = ProfileResolver () . get_resolved_profile_catalog ( trestle_root , profile_path , True , True , None , ParameterRep . LEAVE_MOUSTACHE ) catalog_interface = CatalogInterface ( catalog ) catalog_interface . write_catalog_as_markdown ( md_path = markdown_path , yaml_header = yaml_header , sections_dict = sections_dict , prompt_responses = False , additional_content = True , profile = profile , overwrite_header_values = overwrite_header_values , set_parameters = True , required_sections = required_sections , allowed_sections = None ) except TrestleNotFoundError as e : raise TrestleError ( f 'Profile { profile_path } not found, error { e } ' ) except TrestleError as e : raise TrestleError ( f 'Error generating the catalog as markdown: { e } ' ) return CmdReturnCodes . SUCCESS . value","title":"generate_markdown()"},{"location":"api_reference/trestle.core.commands.author.profile/#trestle.core.commands.author.profile-functions","text":"","title":"Functions"},{"location":"api_reference/trestle.core.commands.author.profile/#trestle.core.commands.author.profile.sections_to_dict","text":"Convert sections string to dict mapping short to long names. Parameters: Name Type Description Default sections Optional[str] String containing comma-sep pars of short_name:long_name for sections required Returns: Type Description Dict[str, str] Dict mapping short names to long names Notes If the long name is not provided (single string and no :) the long name is same as short name. This is needed to map the internal part name for a guidance section to its long name in the formatted markdown. Source code in trestle/core/commands/author/profile.py def sections_to_dict ( sections : Optional [ str ]) -> Dict [ str , str ]: \"\"\" Convert sections string to dict mapping short to long names. Args: sections: String containing comma-sep pars of short_name:long_name for sections Returns: Dict mapping short names to long names Notes: If the long name is not provided (single string and no :) the long name is same as short name. This is needed to map the internal part name for a guidance section to its long name in the formatted markdown. \"\"\" sections_dict : Dict [ str , str ] = {} if sections : section_pairs = sections . strip ( \"'\" ) . split ( ',' ) # section pair is a single string possibly containing : and is either short_name:long_name or just short_name for section_pair in section_pairs : if ':' in section_pair : section_tuple = section_pair . split ( ':' ) sections_dict [ section_tuple [ 0 ] . strip ()] = section_tuple [ 1 ] . strip () else : sections_dict [ section_pair ] = section_pair return sections_dict handler: python","title":"sections_to_dict()"},{"location":"api_reference/trestle.core.commands.author.ssp/","text":"trestle.core.commands.author.ssp \u00a4 Create ssp from catalog and profile. logger \u00a4 Classes \u00a4 SSPAssemble ( AuthorCommonCommand ) \u00a4 Assemble markdown files of controls into an SSP json file. Source code in trestle/core/commands/author/ssp.py class SSPAssemble ( AuthorCommonCommand ): \"\"\"Assemble markdown files of controls into an SSP json file.\"\"\" name = 'ssp-assemble' def _init_arguments ( self ) -> None : name_help_str = ( 'Optional name of the ssp model in the trestle workspace that is being modified. ' 'If not provided the output name is used.' ) self . add_argument ( '-n' , '--name' , help = name_help_str , required = False , type = str ) file_help_str = 'Name of the input markdown file directory' self . add_argument ( '-m' , '--markdown' , help = file_help_str , required = True , type = str ) output_help_str = 'Name of the output generated json SSP' self . add_argument ( '-o' , '--output' , help = output_help_str , required = True , type = str ) self . add_argument ( '-r' , '--regenerate' , action = 'store_true' , help = const . HELP_REGENERATE ) self . add_argument ( '-vn' , '--version' , help = const . HELP_VERSION , required = False , type = str ) def _merge_imp_reqs ( self , ssp : ossp . SystemSecurityPlan , imp_reqs : List [ ossp . ImplementedRequirement ]) -> None : \"\"\" Merge the new imp_reqs into the ssp and optionally regenerate uuids. If a statement has same id and same by_comp uuid as ssp, use the ssp version with new description. Otherwise just insert the statement. When the statement was loaded it had access to the current components so the uuids should match. \"\"\" id_map : Dict [ str , Dict [ str , ossp . Statement ]] = {} control_map : Dict [ str , ossp . ImplementedRequirement ] = {} for imp_req in ssp . control_implementation . implemented_requirements : control_map [ imp_req . control_id ] = imp_req for statement in imp_req . statements : for by_comp in statement . by_components : id_ = statement . statement_id if id_ not in id_map : id_map [ id_ ] = {} id_map [ id_ ][ by_comp . component_uuid ] = statement for imp_req in imp_reqs : if imp_req . control_id in control_map : imp_req . uuid = control_map [ imp_req . control_id ] . uuid for statement in as_list ( imp_req . statements ): id_ = statement . statement_id # for each statement id match the statement per component to the original if id_ in id_map : comp_dict = id_map [ id_ ] for by_comp in as_list ( statement . by_components ): if by_comp . component_uuid in comp_dict : statement . uuid = comp_dict [ by_comp . component_uuid ] . uuid for orig_by_comp in as_list ( comp_dict [ by_comp . component_uuid ] . by_components ): if orig_by_comp . component_uuid == by_comp . component_uuid : by_comp . uuid = orig_by_comp . uuid break changed = ssp . control_implementation . implemented_requirements != imp_reqs ssp . control_implementation . implemented_requirements = imp_reqs return changed def _generate_roles_in_metadata ( self , ssp : ossp . SystemSecurityPlan ) -> bool : \"\"\"Find all roles referenced by imp reqs and create role in metadata as needed.\"\"\" metadata = ssp . metadata metadata . roles = as_list ( metadata . roles ) known_role_ids = [ role . id for role in metadata . roles ] changed = False for imp_req in ssp . control_implementation . implemented_requirements : role_ids = [ resp_role . role_id for resp_role in as_list ( imp_req . responsible_roles )] for role_id in role_ids : if role_id not in known_role_ids : role = com . Role ( id = role_id , title = role_id ) metadata . roles . append ( role ) known_role_ids . append ( role_id ) changed = True metadata . roles = none_if_empty ( metadata . roles ) return changed def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) trestle_root = pathlib . Path ( args . trestle_root ) md_path = trestle_root / args . markdown # the original, reference ssp name defaults to same as output if name not specified # thus in cyclic editing you are reading and writing same json ssp orig_ssp_name = args . output if args . name : orig_ssp_name = args . name new_ssp_name = args . output new_file_content_type = FileContentType . JSON # if output ssp already exists, load it to see if new one is different existing_ssp : Optional [ ossp . SystemSecurityPlan ] = None new_ssp_path = ModelUtils . full_path_for_top_level_model ( trestle_root , new_ssp_name , ossp . SystemSecurityPlan ) if new_ssp_path : _ , _ , existing_ssp = ModelUtils . load_distributed ( new_ssp_path , trestle_root ) new_file_content_type = FileContentType . path_to_content_type ( new_ssp_path ) ssp : ossp . SystemSecurityPlan comp_dict : Dict [ str , ossp . SystemComponent ] = {} # if orig ssp exists - need to load it rather than instantiate new one orig_ssp_path = ModelUtils . full_path_for_top_level_model ( trestle_root , orig_ssp_name , ossp . SystemSecurityPlan ) # need to load imp_reqs from markdown but need component first if orig_ssp_path : # load the existing json ssp _ , _ , ssp = ModelUtils . load_distributed ( orig_ssp_path , trestle_root ) for component in ssp . system_implementation . components : comp_dict [ component . title ] = component # read the new imp reqs from markdown and have them reference existing components imp_reqs = CatalogInterface . read_catalog_imp_reqs ( md_path , comp_dict ) self . _merge_imp_reqs ( ssp , imp_reqs ) new_file_content_type = FileContentType . path_to_content_type ( orig_ssp_path ) else : # create a sample ssp to hold all the parts ssp = gens . generate_sample_model ( ossp . SystemSecurityPlan ) # load the imp_reqs from markdown and create components as needed, referenced by ### headers imp_reqs = CatalogInterface . read_catalog_imp_reqs ( md_path , comp_dict ) # create system implementation system_imp : ossp . SystemImplementation = gens . generate_sample_model ( ossp . SystemImplementation ) ssp . system_implementation = system_imp # create a control implementation to hold the implementated requirements control_imp : ossp . ControlImplementation = gens . generate_sample_model ( ossp . ControlImplementation ) control_imp . implemented_requirements = imp_reqs control_imp . description = const . SSP_SYSTEM_CONTROL_IMPLEMENTATION_TEXT # insert the parts into the ssp ssp . control_implementation = control_imp ssp . system_implementation = system_imp # we don't have access to the original profile so we don't know the href import_profile : ossp . ImportProfile = gens . generate_sample_model ( ossp . ImportProfile ) import_profile . href = 'REPLACE_ME' ssp . import_profile = import_profile # now that we know the complete list of needed components, add them to the sys_imp # TODO if the ssp already existed then components may need to be removed if not ref'd by imp_reqs component_list : List [ ossp . SystemComponent ] = [] for comp in comp_dict . values (): component_list . append ( comp ) if ssp . system_implementation . components : # reconstruct list with same order as existing, but add/remove components as needed new_list : List [ ossp . SystemComponent ] = [] for comp in ssp . system_implementation . components : if comp in component_list : new_list . append ( comp ) for comp in component_list : if comp not in new_list : new_list . append ( comp ) ssp . system_implementation . components = new_list elif component_list : ssp . system_implementation . components = component_list self . _generate_roles_in_metadata ( ssp ) if args . version : ssp . metadata . version = com . Version ( __root__ = args . version ) if ModelUtils . models_are_equivalent ( existing_ssp , ssp ): logger . info ( 'No changes to assembled ssp so ssp not written out.' ) return CmdReturnCodes . SUCCESS . value if args . regenerate : ssp , _ , _ = ModelUtils . regenerate_uuids ( ssp ) ModelUtils . update_last_modified ( ssp ) # write out the ssp as json ModelUtils . save_top_level_model ( ssp , trestle_root , new_ssp_name , new_file_content_type ) return CmdReturnCodes . SUCCESS . value except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while assembling SSP' ) name \u00a4 SSPFilter ( AuthorCommonCommand ) \u00a4 Filter the controls in an ssp based on files included by profile. Source code in trestle/core/commands/author/ssp.py class SSPFilter ( AuthorCommonCommand ): \"\"\"Filter the controls in an ssp based on files included by profile.\"\"\" name = 'ssp-filter' def _init_arguments ( self ) -> None : file_help_str = 'Name of the input ssp' self . add_argument ( '-n' , '--name' , help = file_help_str , required = True , type = str ) file_help_str = 'Name of the input profile that defines set of controls in output ssp' self . add_argument ( '-p' , '--profile' , help = file_help_str , required = True , type = str ) output_help_str = 'Name of the output generated SSP' self . add_argument ( '-o' , '--output' , help = output_help_str , required = True , type = str ) self . add_argument ( '-r' , '--regenerate' , action = 'store_true' , help = const . HELP_REGENERATE ) self . add_argument ( '-vn' , '--version' , help = const . HELP_VERSION , required = False , type = str ) def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) trestle_root = pathlib . Path ( args . trestle_root ) return self . filter_ssp ( trestle_root , args . name , args . profile , args . output , args . regenerate , args . version ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error generating the filtered ssp' ) def filter_ssp ( self , trestle_root : pathlib . Path , ssp_name : str , profile_name : str , out_name : str , regenerate : bool , version : Optional [ str ] ) -> int : \"\"\" Filter the ssp based on controls included by the profile and output new ssp. Args: trestle_root: root directory of the trestle project ssp_name: name of the ssp model profile_name: name of the profile model used for filtering out_name: name of the output ssp model with filtered controls regenerate: whether to regenerate the uuid's in the ssp version: new version for the model Returns: 0 on success, 1 otherwise \"\"\" ssp : ossp . SystemSecurityPlan ssp , _ = ModelUtils . load_top_level_model ( trestle_root , ssp_name , ossp . SystemSecurityPlan , FileContentType . JSON ) profile_path = ModelUtils . path_for_top_level_model ( trestle_root , profile_name , prof . Profile , FileContentType . JSON ) prof_resolver = ProfileResolver () catalog = prof_resolver . get_resolved_profile_catalog ( trestle_root , profile_path ) catalog_interface = CatalogInterface ( catalog ) # The input ssp should reference a superset of the controls referenced by the profile # Need to cull references in the ssp to controls not in the profile # Also make sure the output ssp contains imp reqs for all controls in the profile control_imp = ssp . control_implementation ssp_control_ids : Set [ str ] = set () new_set_params : List [ ossp . SetParameter ] = [] for set_param in as_list ( control_imp . set_parameters ): control = catalog_interface . get_control_by_param_id ( set_param . param_id ) if control is not None : new_set_params . append ( set_param ) ssp_control_ids . add ( control . id ) control_imp . set_parameters = new_set_params if new_set_params else None new_imp_requirements : List [ ossp . ImplementedRequirement ] = [] for imp_requirement in as_list ( control_imp . implemented_requirements ): control = catalog_interface . get_control ( imp_requirement . control_id ) if control is not None : new_imp_requirements . append ( imp_requirement ) ssp_control_ids . add ( control . id ) control_imp . implemented_requirements = new_imp_requirements # make sure all controls in the profile have implemented reqs in the final ssp if not ssp_control_ids . issuperset ( catalog_interface . get_control_ids ()): raise TrestleError ( 'Unable to filter the ssp because the profile references controls not in it.' ) ssp . control_implementation = control_imp if regenerate : ssp , _ , _ = ModelUtils . regenerate_uuids ( ssp ) if version : ssp . metadata . version = com . Version ( __root__ = version ) ModelUtils . update_last_modified ( ssp ) ModelUtils . save_top_level_model ( ssp , trestle_root , out_name , FileContentType . JSON ) return CmdReturnCodes . SUCCESS . value name \u00a4 Methods \u00a4 filter_ssp ( self , trestle_root , ssp_name , profile_name , out_name , regenerate , version ) \u00a4 Filter the ssp based on controls included by the profile and output new ssp. Parameters: Name Type Description Default trestle_root Path root directory of the trestle project required ssp_name str name of the ssp model required profile_name str name of the profile model used for filtering required out_name str name of the output ssp model with filtered controls required regenerate bool whether to regenerate the uuid's in the ssp required version Optional[str] new version for the model required Returns: Type Description int 0 on success, 1 otherwise Source code in trestle/core/commands/author/ssp.py def filter_ssp ( self , trestle_root : pathlib . Path , ssp_name : str , profile_name : str , out_name : str , regenerate : bool , version : Optional [ str ] ) -> int : \"\"\" Filter the ssp based on controls included by the profile and output new ssp. Args: trestle_root: root directory of the trestle project ssp_name: name of the ssp model profile_name: name of the profile model used for filtering out_name: name of the output ssp model with filtered controls regenerate: whether to regenerate the uuid's in the ssp version: new version for the model Returns: 0 on success, 1 otherwise \"\"\" ssp : ossp . SystemSecurityPlan ssp , _ = ModelUtils . load_top_level_model ( trestle_root , ssp_name , ossp . SystemSecurityPlan , FileContentType . JSON ) profile_path = ModelUtils . path_for_top_level_model ( trestle_root , profile_name , prof . Profile , FileContentType . JSON ) prof_resolver = ProfileResolver () catalog = prof_resolver . get_resolved_profile_catalog ( trestle_root , profile_path ) catalog_interface = CatalogInterface ( catalog ) # The input ssp should reference a superset of the controls referenced by the profile # Need to cull references in the ssp to controls not in the profile # Also make sure the output ssp contains imp reqs for all controls in the profile control_imp = ssp . control_implementation ssp_control_ids : Set [ str ] = set () new_set_params : List [ ossp . SetParameter ] = [] for set_param in as_list ( control_imp . set_parameters ): control = catalog_interface . get_control_by_param_id ( set_param . param_id ) if control is not None : new_set_params . append ( set_param ) ssp_control_ids . add ( control . id ) control_imp . set_parameters = new_set_params if new_set_params else None new_imp_requirements : List [ ossp . ImplementedRequirement ] = [] for imp_requirement in as_list ( control_imp . implemented_requirements ): control = catalog_interface . get_control ( imp_requirement . control_id ) if control is not None : new_imp_requirements . append ( imp_requirement ) ssp_control_ids . add ( control . id ) control_imp . implemented_requirements = new_imp_requirements # make sure all controls in the profile have implemented reqs in the final ssp if not ssp_control_ids . issuperset ( catalog_interface . get_control_ids ()): raise TrestleError ( 'Unable to filter the ssp because the profile references controls not in it.' ) ssp . control_implementation = control_imp if regenerate : ssp , _ , _ = ModelUtils . regenerate_uuids ( ssp ) if version : ssp . metadata . version = com . Version ( __root__ = version ) ModelUtils . update_last_modified ( ssp ) ModelUtils . save_top_level_model ( ssp , trestle_root , out_name , FileContentType . JSON ) return CmdReturnCodes . SUCCESS . value SSPGenerate ( AuthorCommonCommand ) \u00a4 Generate SSP in markdown form from a Profile. Source code in trestle/core/commands/author/ssp.py class SSPGenerate ( AuthorCommonCommand ): \"\"\"Generate SSP in markdown form from a Profile.\"\"\" name = 'ssp-generate' def _init_arguments ( self ) -> None : file_help_str = 'Name of the profile model in the trestle workspace' self . add_argument ( '-p' , '--profile' , help = file_help_str , required = True , type = str ) self . add_argument ( '-o' , '--output' , help = const . HELP_MARKDOWN_NAME , required = True , type = str ) self . add_argument ( '-y' , '--yaml-header' , help = const . HELP_YAML_PATH , required = False , type = str ) self . add_argument ( '-ohv' , '--overwrite-header-values' , help = const . HELP_OVERWRITE_HEADER_VALUES , required = False , action = 'store_true' , default = False ) sections_help_str = ( 'Comma separated list of section:alias pairs. Provides mapping of short names to long for markdown.' ) self . add_argument ( '-s' , '--sections' , help = sections_help_str , required = False , type = str ) allowed_sections_help_str = ( 'Comma separated list of section short names to include in the markdown. Others will not appear.' ) self . add_argument ( '-as' , '--allowed-sections' , help = allowed_sections_help_str , required = False , type = str ) def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) trestle_root = args . trestle_root if not file_utils . is_directory_name_allowed ( args . output ): raise TrestleError ( f ' { args . output } is not an allowed directory name' ) profile_path = trestle_root / f 'profiles/ { args . profile } /profile.json' yaml_header : dict = {} if args . yaml_header : try : logging . debug ( f 'Loading yaml header file { args . yaml_header } ' ) yaml = YAML () yaml_header = yaml . load ( pathlib . Path ( args . yaml_header ) . open ( 'r' )) except YAMLError as e : raise TrestleError ( f 'YAML error loading yaml header for ssp generation: { e } ' ) markdown_path = trestle_root / args . output profile_resolver = ProfileResolver () resolved_catalog = profile_resolver . get_resolved_profile_catalog ( trestle_root , profile_path ) catalog_interface = CatalogInterface ( resolved_catalog ) sections_dict : Dict [ str , str ] = {} if args . sections : sections_dict = sections_to_dict ( args . sections ) if 'statement' in sections_dict : raise TrestleError ( 'Statement is not allowed as a section name.' ) # add any existing sections from the controls but only have short names control_section_short_names = catalog_interface . get_sections () for short_name in control_section_short_names : if short_name not in sections_dict : sections_dict [ short_name ] = short_name logger . debug ( f 'ssp sections dict: { sections_dict } ' ) catalog_interface . write_catalog_as_markdown ( md_path = markdown_path , yaml_header = yaml_header , sections_dict = sections_dict , prompt_responses = True , additional_content = False , profile = None , overwrite_header_values = args . overwrite_header_values , set_parameters = False , required_sections = None , allowed_sections = args . allowed_sections ) return CmdReturnCodes . SUCCESS . value except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while writing markdown from catalog' ) name \u00a4 handler: python","title":"ssp"},{"location":"api_reference/trestle.core.commands.author.ssp/#trestle.core.commands.author.ssp","text":"Create ssp from catalog and profile.","title":"ssp"},{"location":"api_reference/trestle.core.commands.author.ssp/#trestle.core.commands.author.ssp.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.author.ssp/#trestle.core.commands.author.ssp-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.author.ssp/#trestle.core.commands.author.ssp.SSPAssemble","text":"Assemble markdown files of controls into an SSP json file. Source code in trestle/core/commands/author/ssp.py class SSPAssemble ( AuthorCommonCommand ): \"\"\"Assemble markdown files of controls into an SSP json file.\"\"\" name = 'ssp-assemble' def _init_arguments ( self ) -> None : name_help_str = ( 'Optional name of the ssp model in the trestle workspace that is being modified. ' 'If not provided the output name is used.' ) self . add_argument ( '-n' , '--name' , help = name_help_str , required = False , type = str ) file_help_str = 'Name of the input markdown file directory' self . add_argument ( '-m' , '--markdown' , help = file_help_str , required = True , type = str ) output_help_str = 'Name of the output generated json SSP' self . add_argument ( '-o' , '--output' , help = output_help_str , required = True , type = str ) self . add_argument ( '-r' , '--regenerate' , action = 'store_true' , help = const . HELP_REGENERATE ) self . add_argument ( '-vn' , '--version' , help = const . HELP_VERSION , required = False , type = str ) def _merge_imp_reqs ( self , ssp : ossp . SystemSecurityPlan , imp_reqs : List [ ossp . ImplementedRequirement ]) -> None : \"\"\" Merge the new imp_reqs into the ssp and optionally regenerate uuids. If a statement has same id and same by_comp uuid as ssp, use the ssp version with new description. Otherwise just insert the statement. When the statement was loaded it had access to the current components so the uuids should match. \"\"\" id_map : Dict [ str , Dict [ str , ossp . Statement ]] = {} control_map : Dict [ str , ossp . ImplementedRequirement ] = {} for imp_req in ssp . control_implementation . implemented_requirements : control_map [ imp_req . control_id ] = imp_req for statement in imp_req . statements : for by_comp in statement . by_components : id_ = statement . statement_id if id_ not in id_map : id_map [ id_ ] = {} id_map [ id_ ][ by_comp . component_uuid ] = statement for imp_req in imp_reqs : if imp_req . control_id in control_map : imp_req . uuid = control_map [ imp_req . control_id ] . uuid for statement in as_list ( imp_req . statements ): id_ = statement . statement_id # for each statement id match the statement per component to the original if id_ in id_map : comp_dict = id_map [ id_ ] for by_comp in as_list ( statement . by_components ): if by_comp . component_uuid in comp_dict : statement . uuid = comp_dict [ by_comp . component_uuid ] . uuid for orig_by_comp in as_list ( comp_dict [ by_comp . component_uuid ] . by_components ): if orig_by_comp . component_uuid == by_comp . component_uuid : by_comp . uuid = orig_by_comp . uuid break changed = ssp . control_implementation . implemented_requirements != imp_reqs ssp . control_implementation . implemented_requirements = imp_reqs return changed def _generate_roles_in_metadata ( self , ssp : ossp . SystemSecurityPlan ) -> bool : \"\"\"Find all roles referenced by imp reqs and create role in metadata as needed.\"\"\" metadata = ssp . metadata metadata . roles = as_list ( metadata . roles ) known_role_ids = [ role . id for role in metadata . roles ] changed = False for imp_req in ssp . control_implementation . implemented_requirements : role_ids = [ resp_role . role_id for resp_role in as_list ( imp_req . responsible_roles )] for role_id in role_ids : if role_id not in known_role_ids : role = com . Role ( id = role_id , title = role_id ) metadata . roles . append ( role ) known_role_ids . append ( role_id ) changed = True metadata . roles = none_if_empty ( metadata . roles ) return changed def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) trestle_root = pathlib . Path ( args . trestle_root ) md_path = trestle_root / args . markdown # the original, reference ssp name defaults to same as output if name not specified # thus in cyclic editing you are reading and writing same json ssp orig_ssp_name = args . output if args . name : orig_ssp_name = args . name new_ssp_name = args . output new_file_content_type = FileContentType . JSON # if output ssp already exists, load it to see if new one is different existing_ssp : Optional [ ossp . SystemSecurityPlan ] = None new_ssp_path = ModelUtils . full_path_for_top_level_model ( trestle_root , new_ssp_name , ossp . SystemSecurityPlan ) if new_ssp_path : _ , _ , existing_ssp = ModelUtils . load_distributed ( new_ssp_path , trestle_root ) new_file_content_type = FileContentType . path_to_content_type ( new_ssp_path ) ssp : ossp . SystemSecurityPlan comp_dict : Dict [ str , ossp . SystemComponent ] = {} # if orig ssp exists - need to load it rather than instantiate new one orig_ssp_path = ModelUtils . full_path_for_top_level_model ( trestle_root , orig_ssp_name , ossp . SystemSecurityPlan ) # need to load imp_reqs from markdown but need component first if orig_ssp_path : # load the existing json ssp _ , _ , ssp = ModelUtils . load_distributed ( orig_ssp_path , trestle_root ) for component in ssp . system_implementation . components : comp_dict [ component . title ] = component # read the new imp reqs from markdown and have them reference existing components imp_reqs = CatalogInterface . read_catalog_imp_reqs ( md_path , comp_dict ) self . _merge_imp_reqs ( ssp , imp_reqs ) new_file_content_type = FileContentType . path_to_content_type ( orig_ssp_path ) else : # create a sample ssp to hold all the parts ssp = gens . generate_sample_model ( ossp . SystemSecurityPlan ) # load the imp_reqs from markdown and create components as needed, referenced by ### headers imp_reqs = CatalogInterface . read_catalog_imp_reqs ( md_path , comp_dict ) # create system implementation system_imp : ossp . SystemImplementation = gens . generate_sample_model ( ossp . SystemImplementation ) ssp . system_implementation = system_imp # create a control implementation to hold the implementated requirements control_imp : ossp . ControlImplementation = gens . generate_sample_model ( ossp . ControlImplementation ) control_imp . implemented_requirements = imp_reqs control_imp . description = const . SSP_SYSTEM_CONTROL_IMPLEMENTATION_TEXT # insert the parts into the ssp ssp . control_implementation = control_imp ssp . system_implementation = system_imp # we don't have access to the original profile so we don't know the href import_profile : ossp . ImportProfile = gens . generate_sample_model ( ossp . ImportProfile ) import_profile . href = 'REPLACE_ME' ssp . import_profile = import_profile # now that we know the complete list of needed components, add them to the sys_imp # TODO if the ssp already existed then components may need to be removed if not ref'd by imp_reqs component_list : List [ ossp . SystemComponent ] = [] for comp in comp_dict . values (): component_list . append ( comp ) if ssp . system_implementation . components : # reconstruct list with same order as existing, but add/remove components as needed new_list : List [ ossp . SystemComponent ] = [] for comp in ssp . system_implementation . components : if comp in component_list : new_list . append ( comp ) for comp in component_list : if comp not in new_list : new_list . append ( comp ) ssp . system_implementation . components = new_list elif component_list : ssp . system_implementation . components = component_list self . _generate_roles_in_metadata ( ssp ) if args . version : ssp . metadata . version = com . Version ( __root__ = args . version ) if ModelUtils . models_are_equivalent ( existing_ssp , ssp ): logger . info ( 'No changes to assembled ssp so ssp not written out.' ) return CmdReturnCodes . SUCCESS . value if args . regenerate : ssp , _ , _ = ModelUtils . regenerate_uuids ( ssp ) ModelUtils . update_last_modified ( ssp ) # write out the ssp as json ModelUtils . save_top_level_model ( ssp , trestle_root , new_ssp_name , new_file_content_type ) return CmdReturnCodes . SUCCESS . value except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while assembling SSP' )","title":"SSPAssemble"},{"location":"api_reference/trestle.core.commands.author.ssp/#trestle.core.commands.author.ssp.SSPAssemble.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.author.ssp/#trestle.core.commands.author.ssp.SSPFilter","text":"Filter the controls in an ssp based on files included by profile. Source code in trestle/core/commands/author/ssp.py class SSPFilter ( AuthorCommonCommand ): \"\"\"Filter the controls in an ssp based on files included by profile.\"\"\" name = 'ssp-filter' def _init_arguments ( self ) -> None : file_help_str = 'Name of the input ssp' self . add_argument ( '-n' , '--name' , help = file_help_str , required = True , type = str ) file_help_str = 'Name of the input profile that defines set of controls in output ssp' self . add_argument ( '-p' , '--profile' , help = file_help_str , required = True , type = str ) output_help_str = 'Name of the output generated SSP' self . add_argument ( '-o' , '--output' , help = output_help_str , required = True , type = str ) self . add_argument ( '-r' , '--regenerate' , action = 'store_true' , help = const . HELP_REGENERATE ) self . add_argument ( '-vn' , '--version' , help = const . HELP_VERSION , required = False , type = str ) def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) trestle_root = pathlib . Path ( args . trestle_root ) return self . filter_ssp ( trestle_root , args . name , args . profile , args . output , args . regenerate , args . version ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error generating the filtered ssp' ) def filter_ssp ( self , trestle_root : pathlib . Path , ssp_name : str , profile_name : str , out_name : str , regenerate : bool , version : Optional [ str ] ) -> int : \"\"\" Filter the ssp based on controls included by the profile and output new ssp. Args: trestle_root: root directory of the trestle project ssp_name: name of the ssp model profile_name: name of the profile model used for filtering out_name: name of the output ssp model with filtered controls regenerate: whether to regenerate the uuid's in the ssp version: new version for the model Returns: 0 on success, 1 otherwise \"\"\" ssp : ossp . SystemSecurityPlan ssp , _ = ModelUtils . load_top_level_model ( trestle_root , ssp_name , ossp . SystemSecurityPlan , FileContentType . JSON ) profile_path = ModelUtils . path_for_top_level_model ( trestle_root , profile_name , prof . Profile , FileContentType . JSON ) prof_resolver = ProfileResolver () catalog = prof_resolver . get_resolved_profile_catalog ( trestle_root , profile_path ) catalog_interface = CatalogInterface ( catalog ) # The input ssp should reference a superset of the controls referenced by the profile # Need to cull references in the ssp to controls not in the profile # Also make sure the output ssp contains imp reqs for all controls in the profile control_imp = ssp . control_implementation ssp_control_ids : Set [ str ] = set () new_set_params : List [ ossp . SetParameter ] = [] for set_param in as_list ( control_imp . set_parameters ): control = catalog_interface . get_control_by_param_id ( set_param . param_id ) if control is not None : new_set_params . append ( set_param ) ssp_control_ids . add ( control . id ) control_imp . set_parameters = new_set_params if new_set_params else None new_imp_requirements : List [ ossp . ImplementedRequirement ] = [] for imp_requirement in as_list ( control_imp . implemented_requirements ): control = catalog_interface . get_control ( imp_requirement . control_id ) if control is not None : new_imp_requirements . append ( imp_requirement ) ssp_control_ids . add ( control . id ) control_imp . implemented_requirements = new_imp_requirements # make sure all controls in the profile have implemented reqs in the final ssp if not ssp_control_ids . issuperset ( catalog_interface . get_control_ids ()): raise TrestleError ( 'Unable to filter the ssp because the profile references controls not in it.' ) ssp . control_implementation = control_imp if regenerate : ssp , _ , _ = ModelUtils . regenerate_uuids ( ssp ) if version : ssp . metadata . version = com . Version ( __root__ = version ) ModelUtils . update_last_modified ( ssp ) ModelUtils . save_top_level_model ( ssp , trestle_root , out_name , FileContentType . JSON ) return CmdReturnCodes . SUCCESS . value","title":"SSPFilter"},{"location":"api_reference/trestle.core.commands.author.ssp/#trestle.core.commands.author.ssp.SSPFilter.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.author.ssp/#trestle.core.commands.author.ssp.SSPFilter-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.author.ssp/#trestle.core.commands.author.ssp.SSPFilter.filter_ssp","text":"Filter the ssp based on controls included by the profile and output new ssp. Parameters: Name Type Description Default trestle_root Path root directory of the trestle project required ssp_name str name of the ssp model required profile_name str name of the profile model used for filtering required out_name str name of the output ssp model with filtered controls required regenerate bool whether to regenerate the uuid's in the ssp required version Optional[str] new version for the model required Returns: Type Description int 0 on success, 1 otherwise Source code in trestle/core/commands/author/ssp.py def filter_ssp ( self , trestle_root : pathlib . Path , ssp_name : str , profile_name : str , out_name : str , regenerate : bool , version : Optional [ str ] ) -> int : \"\"\" Filter the ssp based on controls included by the profile and output new ssp. Args: trestle_root: root directory of the trestle project ssp_name: name of the ssp model profile_name: name of the profile model used for filtering out_name: name of the output ssp model with filtered controls regenerate: whether to regenerate the uuid's in the ssp version: new version for the model Returns: 0 on success, 1 otherwise \"\"\" ssp : ossp . SystemSecurityPlan ssp , _ = ModelUtils . load_top_level_model ( trestle_root , ssp_name , ossp . SystemSecurityPlan , FileContentType . JSON ) profile_path = ModelUtils . path_for_top_level_model ( trestle_root , profile_name , prof . Profile , FileContentType . JSON ) prof_resolver = ProfileResolver () catalog = prof_resolver . get_resolved_profile_catalog ( trestle_root , profile_path ) catalog_interface = CatalogInterface ( catalog ) # The input ssp should reference a superset of the controls referenced by the profile # Need to cull references in the ssp to controls not in the profile # Also make sure the output ssp contains imp reqs for all controls in the profile control_imp = ssp . control_implementation ssp_control_ids : Set [ str ] = set () new_set_params : List [ ossp . SetParameter ] = [] for set_param in as_list ( control_imp . set_parameters ): control = catalog_interface . get_control_by_param_id ( set_param . param_id ) if control is not None : new_set_params . append ( set_param ) ssp_control_ids . add ( control . id ) control_imp . set_parameters = new_set_params if new_set_params else None new_imp_requirements : List [ ossp . ImplementedRequirement ] = [] for imp_requirement in as_list ( control_imp . implemented_requirements ): control = catalog_interface . get_control ( imp_requirement . control_id ) if control is not None : new_imp_requirements . append ( imp_requirement ) ssp_control_ids . add ( control . id ) control_imp . implemented_requirements = new_imp_requirements # make sure all controls in the profile have implemented reqs in the final ssp if not ssp_control_ids . issuperset ( catalog_interface . get_control_ids ()): raise TrestleError ( 'Unable to filter the ssp because the profile references controls not in it.' ) ssp . control_implementation = control_imp if regenerate : ssp , _ , _ = ModelUtils . regenerate_uuids ( ssp ) if version : ssp . metadata . version = com . Version ( __root__ = version ) ModelUtils . update_last_modified ( ssp ) ModelUtils . save_top_level_model ( ssp , trestle_root , out_name , FileContentType . JSON ) return CmdReturnCodes . SUCCESS . value","title":"filter_ssp()"},{"location":"api_reference/trestle.core.commands.author.ssp/#trestle.core.commands.author.ssp.SSPGenerate","text":"Generate SSP in markdown form from a Profile. Source code in trestle/core/commands/author/ssp.py class SSPGenerate ( AuthorCommonCommand ): \"\"\"Generate SSP in markdown form from a Profile.\"\"\" name = 'ssp-generate' def _init_arguments ( self ) -> None : file_help_str = 'Name of the profile model in the trestle workspace' self . add_argument ( '-p' , '--profile' , help = file_help_str , required = True , type = str ) self . add_argument ( '-o' , '--output' , help = const . HELP_MARKDOWN_NAME , required = True , type = str ) self . add_argument ( '-y' , '--yaml-header' , help = const . HELP_YAML_PATH , required = False , type = str ) self . add_argument ( '-ohv' , '--overwrite-header-values' , help = const . HELP_OVERWRITE_HEADER_VALUES , required = False , action = 'store_true' , default = False ) sections_help_str = ( 'Comma separated list of section:alias pairs. Provides mapping of short names to long for markdown.' ) self . add_argument ( '-s' , '--sections' , help = sections_help_str , required = False , type = str ) allowed_sections_help_str = ( 'Comma separated list of section short names to include in the markdown. Others will not appear.' ) self . add_argument ( '-as' , '--allowed-sections' , help = allowed_sections_help_str , required = False , type = str ) def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) trestle_root = args . trestle_root if not file_utils . is_directory_name_allowed ( args . output ): raise TrestleError ( f ' { args . output } is not an allowed directory name' ) profile_path = trestle_root / f 'profiles/ { args . profile } /profile.json' yaml_header : dict = {} if args . yaml_header : try : logging . debug ( f 'Loading yaml header file { args . yaml_header } ' ) yaml = YAML () yaml_header = yaml . load ( pathlib . Path ( args . yaml_header ) . open ( 'r' )) except YAMLError as e : raise TrestleError ( f 'YAML error loading yaml header for ssp generation: { e } ' ) markdown_path = trestle_root / args . output profile_resolver = ProfileResolver () resolved_catalog = profile_resolver . get_resolved_profile_catalog ( trestle_root , profile_path ) catalog_interface = CatalogInterface ( resolved_catalog ) sections_dict : Dict [ str , str ] = {} if args . sections : sections_dict = sections_to_dict ( args . sections ) if 'statement' in sections_dict : raise TrestleError ( 'Statement is not allowed as a section name.' ) # add any existing sections from the controls but only have short names control_section_short_names = catalog_interface . get_sections () for short_name in control_section_short_names : if short_name not in sections_dict : sections_dict [ short_name ] = short_name logger . debug ( f 'ssp sections dict: { sections_dict } ' ) catalog_interface . write_catalog_as_markdown ( md_path = markdown_path , yaml_header = yaml_header , sections_dict = sections_dict , prompt_responses = True , additional_content = False , profile = None , overwrite_header_values = args . overwrite_header_values , set_parameters = False , required_sections = None , allowed_sections = args . allowed_sections ) return CmdReturnCodes . SUCCESS . value except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while writing markdown from catalog' )","title":"SSPGenerate"},{"location":"api_reference/trestle.core.commands.author.ssp/#trestle.core.commands.author.ssp.SSPGenerate.name","text":"handler: python","title":"name"},{"location":"api_reference/trestle.core.commands.author.versioning.template_versioning/","text":"trestle.core.commands.author.versioning.template_versioning \u00a4 A Template Versioning. logger \u00a4 Classes \u00a4 TemplateVersioning \u00a4 Template versioning solution. Load template with a specified version. Template version can be specified via -tv flag If no version specified the latest version will be used by default. Otherwise use the templates from the specified version. Backward compatibility. Version 0.0.1 will be reserved for the template versions prior to this change. If the old template path is detected (i.e. without the template version). then the filesystem will be updated to the new path with the version. Upon first run, old template versions prior to this change will be placed to the folder 0.0.1. If templates have no headers then 0.0.1 version will be used. Versioning organization. Template and instance version is added both: in the file system (via path) and in the headers or metadata. Instance version validation. Markdown: When validating the instance the header will be used to validate the version. Drawio: When validating the instance the metadata will be used to validate the version. Source code in trestle/core/commands/author/versioning/template_versioning.py class TemplateVersioning : \"\"\" Template versioning solution. 1. Load template with a specified version. 1. Template version can be specified via -tv flag 2. If no version specified the latest version will be used by default. 3. Otherwise use the templates from the specified version. 2. Backward compatibility. 1. Version 0.0.1 will be reserved for the template versions prior to this change. 2. If the old template path is detected (i.e. without the template version). then the filesystem will be updated to the new path with the version. 3. Upon first run, old template versions prior to this change will be placed to the folder 0.0.1. 4. If templates have no headers then 0.0.1 version will be used. 3. Versioning organization. 1. Template and instance version is added both: in the file system (via path) and in the headers or metadata. 4. Instance version validation. 1. Markdown: 1. When validating the instance the header will be used to validate the version. 2. Drawio: 1. When validating the instance the metadata will be used to validate the version. \"\"\" @staticmethod def update_template_folder_structure ( task_path : Path ) -> None : \"\"\" Automatically detect whether the path is an old style and update it. An old-style path is a path of the form: root_folder/.trestle/author/{template_name}/{template_objects} The new version path is a path of the form: root_folder/.trestle/author/{template_name}/{version}/{template_objects} By default all old-style templates will be updated to version 0.0.1 \"\"\" TemplateVersioning . _check_if_exists_and_dir ( task_path ) try : all_files_wo_version = list ( filter ( lambda p : p . is_file (), file_utils . iterdir_without_hidden_files ( task_path )) ) new_dir = Path ( f ' { task_path } / { START_TEMPLATE_VERSION } ' ) new_dir . mkdir ( parents = True , exist_ok = True ) if len ( all_files_wo_version ) == 0 : logger . debug ( 'No templates outside of the version folders.' ) for f in all_files_wo_version : shutil . copy ( f , new_dir ) for p in all_files_wo_version : if p . is_dir (): shutil . rmtree ( p ) else : p . unlink () except OSError as e : raise TrestleError ( f 'Error while updating template folder: { e } ' ) except Exception as e : raise TrestleError ( f 'Unexpected error while updating template folder: { e } ' ) @staticmethod def validate_template_folder ( template_dir : Path ): \"\"\"Validate template folder confirms to the versioned path style and has no other subdirectories.\"\"\" TemplateVersioning . _check_if_exists_and_dir ( template_dir ) version_regex = r '[0-9]+.[0-9]+.[0-9]+' pattern = re . compile ( version_regex ) subdirectories = list ( filter ( lambda p : p . is_dir () and pattern . search ( p . parts [ - 1 ]) is None , template_dir . iterdir ()) ) if len ( subdirectories ) > 0 : raise TrestleError ( f 'Subdirectories are not allowed in template folders: { subdirectories } ' ) @staticmethod def get_versioned_template_dir ( task_path : Path , version : Optional [ str ] = None ) -> Path : \"\"\" Get a template folder of the specified version. If no version is given, the latest version of template will be returned \"\"\" TemplateVersioning . _check_if_exists_and_dir ( task_path ) latest_path = None if version is None : latest_path , _ = TemplateVersioning . get_latest_version_for_task ( task_path ) else : latest_path = Path ( f ' { task_path } / { version } /' ) if not latest_path . exists (): raise TrestleError ( f 'The task: { task_path } with version: { version } does not exists.' ) return latest_path @staticmethod def get_latest_version_for_task ( task_path : Path ) -> Tuple [ Path , str ]: \"\"\"Get latest version of the template for the given task.\"\"\" TemplateVersioning . _check_if_exists_and_dir ( task_path ) all_versions = TemplateVersioning . get_all_versions_for_task ( task_path ) max_version = START_TEMPLATE_VERSION if len ( all_versions ) == 0 : logger . debug ( f 'No template versions were found for task: { task_path } , defaulting to 0.0.1' ) max_version = START_TEMPLATE_VERSION else : max_version = max ( all_versions ) latest_path = Path ( f ' { task_path } / { max_version } ' ) return latest_path , max_version @staticmethod def get_all_versions_for_task ( task_path : Path ) -> List [ str ]: \"\"\"Get all versions for the task.\"\"\" version_regex = r '[0-9]+.[0-9]+.[0-9]+' pattern = re . compile ( version_regex ) all_versions = [] max_version = START_TEMPLATE_VERSION for p in task_path . iterdir (): if p . is_dir () and pattern . search ( p . parts [ - 1 ]) is not None : match = pattern . search ( p . parts [ - 1 ]) . string all_versions . append ( match ) if match > max_version : max_version = match return all_versions @staticmethod def write_versioned_template ( resource_name : str , task_path : Path , target_file : Path , version : Optional [ str ] = None ) -> None : \"\"\" Write a template with the header or metadata of a specified version. If no version was given the latest version for the task will be used. Args: resource_name: Template resource name task_path: Task path target_file: File path where template will be written version: return a resource of a specific version Returns: A dotted path of a versioned template, list of all available versions \"\"\" TemplateVersioning . _check_if_exists_and_dir ( task_path ) try : templates_resource_path = TRESTLE_RESOURCES + '.templates' generic_template = Path ( resource_filename ( templates_resource_path , resource_name )) . resolve () if version is None : _ , version = TemplateVersioning . get_latest_version_for_task ( task_path ) # modify header/metadata in the template if generic_template . suffix == '.md' : md_api = MarkdownAPI () header , md_body = md_api . processor . read_markdown_wo_processing ( generic_template ) header [ TEMPLATE_VERSION_HEADER ] = version md_api . write_markdown_with_header ( target_file , header , md_body ) logger . debug ( f 'Successfully written template markdown to { target_file } ' ) elif generic_template . suffix == '.drawio' : drawio = DrawIO ( generic_template ) metadata = drawio . get_metadata ()[ 0 ] metadata [ TEMPLATE_VERSION_HEADER ] = version drawio . write_drawio_with_metadata ( generic_template , metadata , 0 , target_file ) logger . debug ( f 'Successfully written template drawio to { target_file } ' ) else : raise TrestleError ( f 'Unsupported template file extension { generic_template . suffix } ' ) except OSError as e : raise TrestleError ( f 'Error while updating template folder: { e } ' ) @staticmethod def is_valid_version ( template_version : str ) -> bool : \"\"\"Check if the version format is correct.\"\"\" if template_version is None : return True # we can have empty version if template_version == '0.0.0' : return False version_regex = r '^[0-9]+.[0-9]+.[0-9]+$' pattern = re . compile ( version_regex ) if pattern . search ( template_version ): return True else : return False @staticmethod def _check_if_exists_and_dir ( task_path : Path ) -> None : if not task_path . exists (): raise TrestleError ( f 'Path: { task_path } does not exists.' ) if not task_path . is_dir (): raise TrestleError ( f 'File { task_path } passed, however template directory is expected.' ) Methods \u00a4 get_all_versions_for_task ( task_path ) staticmethod \u00a4 Get all versions for the task. Source code in trestle/core/commands/author/versioning/template_versioning.py @staticmethod def get_all_versions_for_task ( task_path : Path ) -> List [ str ]: \"\"\"Get all versions for the task.\"\"\" version_regex = r '[0-9]+.[0-9]+.[0-9]+' pattern = re . compile ( version_regex ) all_versions = [] max_version = START_TEMPLATE_VERSION for p in task_path . iterdir (): if p . is_dir () and pattern . search ( p . parts [ - 1 ]) is not None : match = pattern . search ( p . parts [ - 1 ]) . string all_versions . append ( match ) if match > max_version : max_version = match return all_versions get_latest_version_for_task ( task_path ) staticmethod \u00a4 Get latest version of the template for the given task. Source code in trestle/core/commands/author/versioning/template_versioning.py @staticmethod def get_latest_version_for_task ( task_path : Path ) -> Tuple [ Path , str ]: \"\"\"Get latest version of the template for the given task.\"\"\" TemplateVersioning . _check_if_exists_and_dir ( task_path ) all_versions = TemplateVersioning . get_all_versions_for_task ( task_path ) max_version = START_TEMPLATE_VERSION if len ( all_versions ) == 0 : logger . debug ( f 'No template versions were found for task: { task_path } , defaulting to 0.0.1' ) max_version = START_TEMPLATE_VERSION else : max_version = max ( all_versions ) latest_path = Path ( f ' { task_path } / { max_version } ' ) return latest_path , max_version get_versioned_template_dir ( task_path , version = None ) staticmethod \u00a4 Get a template folder of the specified version. If no version is given, the latest version of template will be returned Source code in trestle/core/commands/author/versioning/template_versioning.py @staticmethod def get_versioned_template_dir ( task_path : Path , version : Optional [ str ] = None ) -> Path : \"\"\" Get a template folder of the specified version. If no version is given, the latest version of template will be returned \"\"\" TemplateVersioning . _check_if_exists_and_dir ( task_path ) latest_path = None if version is None : latest_path , _ = TemplateVersioning . get_latest_version_for_task ( task_path ) else : latest_path = Path ( f ' { task_path } / { version } /' ) if not latest_path . exists (): raise TrestleError ( f 'The task: { task_path } with version: { version } does not exists.' ) return latest_path is_valid_version ( template_version ) staticmethod \u00a4 Check if the version format is correct. Source code in trestle/core/commands/author/versioning/template_versioning.py @staticmethod def is_valid_version ( template_version : str ) -> bool : \"\"\"Check if the version format is correct.\"\"\" if template_version is None : return True # we can have empty version if template_version == '0.0.0' : return False version_regex = r '^[0-9]+.[0-9]+.[0-9]+$' pattern = re . compile ( version_regex ) if pattern . search ( template_version ): return True else : return False update_template_folder_structure ( task_path ) staticmethod \u00a4 Automatically detect whether the path is an old style and update it. An old-style path is a path of the form: root_folder/.trestle/author/{template_name}/{template_objects} The new version path is a path of the form: root_folder/.trestle/author/{template_name}/{version}/{template_objects} By default all old-style templates will be updated to version 0.0.1 Source code in trestle/core/commands/author/versioning/template_versioning.py @staticmethod def update_template_folder_structure ( task_path : Path ) -> None : \"\"\" Automatically detect whether the path is an old style and update it. An old-style path is a path of the form: root_folder/.trestle/author/{template_name}/{template_objects} The new version path is a path of the form: root_folder/.trestle/author/{template_name}/{version}/{template_objects} By default all old-style templates will be updated to version 0.0.1 \"\"\" TemplateVersioning . _check_if_exists_and_dir ( task_path ) try : all_files_wo_version = list ( filter ( lambda p : p . is_file (), file_utils . iterdir_without_hidden_files ( task_path )) ) new_dir = Path ( f ' { task_path } / { START_TEMPLATE_VERSION } ' ) new_dir . mkdir ( parents = True , exist_ok = True ) if len ( all_files_wo_version ) == 0 : logger . debug ( 'No templates outside of the version folders.' ) for f in all_files_wo_version : shutil . copy ( f , new_dir ) for p in all_files_wo_version : if p . is_dir (): shutil . rmtree ( p ) else : p . unlink () except OSError as e : raise TrestleError ( f 'Error while updating template folder: { e } ' ) except Exception as e : raise TrestleError ( f 'Unexpected error while updating template folder: { e } ' ) validate_template_folder ( template_dir ) staticmethod \u00a4 Validate template folder confirms to the versioned path style and has no other subdirectories. Source code in trestle/core/commands/author/versioning/template_versioning.py @staticmethod def validate_template_folder ( template_dir : Path ): \"\"\"Validate template folder confirms to the versioned path style and has no other subdirectories.\"\"\" TemplateVersioning . _check_if_exists_and_dir ( template_dir ) version_regex = r '[0-9]+.[0-9]+.[0-9]+' pattern = re . compile ( version_regex ) subdirectories = list ( filter ( lambda p : p . is_dir () and pattern . search ( p . parts [ - 1 ]) is None , template_dir . iterdir ()) ) if len ( subdirectories ) > 0 : raise TrestleError ( f 'Subdirectories are not allowed in template folders: { subdirectories } ' ) write_versioned_template ( resource_name , task_path , target_file , version = None ) staticmethod \u00a4 Write a template with the header or metadata of a specified version. If no version was given the latest version for the task will be used. Parameters: Name Type Description Default resource_name str Template resource name required task_path Path Task path required target_file Path File path where template will be written required version Optional[str] return a resource of a specific version None Returns: Type Description None A dotted path of a versioned template, list of all available versions Source code in trestle/core/commands/author/versioning/template_versioning.py @staticmethod def write_versioned_template ( resource_name : str , task_path : Path , target_file : Path , version : Optional [ str ] = None ) -> None : \"\"\" Write a template with the header or metadata of a specified version. If no version was given the latest version for the task will be used. Args: resource_name: Template resource name task_path: Task path target_file: File path where template will be written version: return a resource of a specific version Returns: A dotted path of a versioned template, list of all available versions \"\"\" TemplateVersioning . _check_if_exists_and_dir ( task_path ) try : templates_resource_path = TRESTLE_RESOURCES + '.templates' generic_template = Path ( resource_filename ( templates_resource_path , resource_name )) . resolve () if version is None : _ , version = TemplateVersioning . get_latest_version_for_task ( task_path ) # modify header/metadata in the template if generic_template . suffix == '.md' : md_api = MarkdownAPI () header , md_body = md_api . processor . read_markdown_wo_processing ( generic_template ) header [ TEMPLATE_VERSION_HEADER ] = version md_api . write_markdown_with_header ( target_file , header , md_body ) logger . debug ( f 'Successfully written template markdown to { target_file } ' ) elif generic_template . suffix == '.drawio' : drawio = DrawIO ( generic_template ) metadata = drawio . get_metadata ()[ 0 ] metadata [ TEMPLATE_VERSION_HEADER ] = version drawio . write_drawio_with_metadata ( generic_template , metadata , 0 , target_file ) logger . debug ( f 'Successfully written template drawio to { target_file } ' ) else : raise TrestleError ( f 'Unsupported template file extension { generic_template . suffix } ' ) except OSError as e : raise TrestleError ( f 'Error while updating template folder: { e } ' ) handler: python","title":"template_versioning"},{"location":"api_reference/trestle.core.commands.author.versioning.template_versioning/#trestle.core.commands.author.versioning.template_versioning","text":"A Template Versioning.","title":"template_versioning"},{"location":"api_reference/trestle.core.commands.author.versioning.template_versioning/#trestle.core.commands.author.versioning.template_versioning.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.author.versioning.template_versioning/#trestle.core.commands.author.versioning.template_versioning-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.author.versioning.template_versioning/#trestle.core.commands.author.versioning.template_versioning.TemplateVersioning","text":"Template versioning solution. Load template with a specified version. Template version can be specified via -tv flag If no version specified the latest version will be used by default. Otherwise use the templates from the specified version. Backward compatibility. Version 0.0.1 will be reserved for the template versions prior to this change. If the old template path is detected (i.e. without the template version). then the filesystem will be updated to the new path with the version. Upon first run, old template versions prior to this change will be placed to the folder 0.0.1. If templates have no headers then 0.0.1 version will be used. Versioning organization. Template and instance version is added both: in the file system (via path) and in the headers or metadata. Instance version validation. Markdown: When validating the instance the header will be used to validate the version. Drawio: When validating the instance the metadata will be used to validate the version. Source code in trestle/core/commands/author/versioning/template_versioning.py class TemplateVersioning : \"\"\" Template versioning solution. 1. Load template with a specified version. 1. Template version can be specified via -tv flag 2. If no version specified the latest version will be used by default. 3. Otherwise use the templates from the specified version. 2. Backward compatibility. 1. Version 0.0.1 will be reserved for the template versions prior to this change. 2. If the old template path is detected (i.e. without the template version). then the filesystem will be updated to the new path with the version. 3. Upon first run, old template versions prior to this change will be placed to the folder 0.0.1. 4. If templates have no headers then 0.0.1 version will be used. 3. Versioning organization. 1. Template and instance version is added both: in the file system (via path) and in the headers or metadata. 4. Instance version validation. 1. Markdown: 1. When validating the instance the header will be used to validate the version. 2. Drawio: 1. When validating the instance the metadata will be used to validate the version. \"\"\" @staticmethod def update_template_folder_structure ( task_path : Path ) -> None : \"\"\" Automatically detect whether the path is an old style and update it. An old-style path is a path of the form: root_folder/.trestle/author/{template_name}/{template_objects} The new version path is a path of the form: root_folder/.trestle/author/{template_name}/{version}/{template_objects} By default all old-style templates will be updated to version 0.0.1 \"\"\" TemplateVersioning . _check_if_exists_and_dir ( task_path ) try : all_files_wo_version = list ( filter ( lambda p : p . is_file (), file_utils . iterdir_without_hidden_files ( task_path )) ) new_dir = Path ( f ' { task_path } / { START_TEMPLATE_VERSION } ' ) new_dir . mkdir ( parents = True , exist_ok = True ) if len ( all_files_wo_version ) == 0 : logger . debug ( 'No templates outside of the version folders.' ) for f in all_files_wo_version : shutil . copy ( f , new_dir ) for p in all_files_wo_version : if p . is_dir (): shutil . rmtree ( p ) else : p . unlink () except OSError as e : raise TrestleError ( f 'Error while updating template folder: { e } ' ) except Exception as e : raise TrestleError ( f 'Unexpected error while updating template folder: { e } ' ) @staticmethod def validate_template_folder ( template_dir : Path ): \"\"\"Validate template folder confirms to the versioned path style and has no other subdirectories.\"\"\" TemplateVersioning . _check_if_exists_and_dir ( template_dir ) version_regex = r '[0-9]+.[0-9]+.[0-9]+' pattern = re . compile ( version_regex ) subdirectories = list ( filter ( lambda p : p . is_dir () and pattern . search ( p . parts [ - 1 ]) is None , template_dir . iterdir ()) ) if len ( subdirectories ) > 0 : raise TrestleError ( f 'Subdirectories are not allowed in template folders: { subdirectories } ' ) @staticmethod def get_versioned_template_dir ( task_path : Path , version : Optional [ str ] = None ) -> Path : \"\"\" Get a template folder of the specified version. If no version is given, the latest version of template will be returned \"\"\" TemplateVersioning . _check_if_exists_and_dir ( task_path ) latest_path = None if version is None : latest_path , _ = TemplateVersioning . get_latest_version_for_task ( task_path ) else : latest_path = Path ( f ' { task_path } / { version } /' ) if not latest_path . exists (): raise TrestleError ( f 'The task: { task_path } with version: { version } does not exists.' ) return latest_path @staticmethod def get_latest_version_for_task ( task_path : Path ) -> Tuple [ Path , str ]: \"\"\"Get latest version of the template for the given task.\"\"\" TemplateVersioning . _check_if_exists_and_dir ( task_path ) all_versions = TemplateVersioning . get_all_versions_for_task ( task_path ) max_version = START_TEMPLATE_VERSION if len ( all_versions ) == 0 : logger . debug ( f 'No template versions were found for task: { task_path } , defaulting to 0.0.1' ) max_version = START_TEMPLATE_VERSION else : max_version = max ( all_versions ) latest_path = Path ( f ' { task_path } / { max_version } ' ) return latest_path , max_version @staticmethod def get_all_versions_for_task ( task_path : Path ) -> List [ str ]: \"\"\"Get all versions for the task.\"\"\" version_regex = r '[0-9]+.[0-9]+.[0-9]+' pattern = re . compile ( version_regex ) all_versions = [] max_version = START_TEMPLATE_VERSION for p in task_path . iterdir (): if p . is_dir () and pattern . search ( p . parts [ - 1 ]) is not None : match = pattern . search ( p . parts [ - 1 ]) . string all_versions . append ( match ) if match > max_version : max_version = match return all_versions @staticmethod def write_versioned_template ( resource_name : str , task_path : Path , target_file : Path , version : Optional [ str ] = None ) -> None : \"\"\" Write a template with the header or metadata of a specified version. If no version was given the latest version for the task will be used. Args: resource_name: Template resource name task_path: Task path target_file: File path where template will be written version: return a resource of a specific version Returns: A dotted path of a versioned template, list of all available versions \"\"\" TemplateVersioning . _check_if_exists_and_dir ( task_path ) try : templates_resource_path = TRESTLE_RESOURCES + '.templates' generic_template = Path ( resource_filename ( templates_resource_path , resource_name )) . resolve () if version is None : _ , version = TemplateVersioning . get_latest_version_for_task ( task_path ) # modify header/metadata in the template if generic_template . suffix == '.md' : md_api = MarkdownAPI () header , md_body = md_api . processor . read_markdown_wo_processing ( generic_template ) header [ TEMPLATE_VERSION_HEADER ] = version md_api . write_markdown_with_header ( target_file , header , md_body ) logger . debug ( f 'Successfully written template markdown to { target_file } ' ) elif generic_template . suffix == '.drawio' : drawio = DrawIO ( generic_template ) metadata = drawio . get_metadata ()[ 0 ] metadata [ TEMPLATE_VERSION_HEADER ] = version drawio . write_drawio_with_metadata ( generic_template , metadata , 0 , target_file ) logger . debug ( f 'Successfully written template drawio to { target_file } ' ) else : raise TrestleError ( f 'Unsupported template file extension { generic_template . suffix } ' ) except OSError as e : raise TrestleError ( f 'Error while updating template folder: { e } ' ) @staticmethod def is_valid_version ( template_version : str ) -> bool : \"\"\"Check if the version format is correct.\"\"\" if template_version is None : return True # we can have empty version if template_version == '0.0.0' : return False version_regex = r '^[0-9]+.[0-9]+.[0-9]+$' pattern = re . compile ( version_regex ) if pattern . search ( template_version ): return True else : return False @staticmethod def _check_if_exists_and_dir ( task_path : Path ) -> None : if not task_path . exists (): raise TrestleError ( f 'Path: { task_path } does not exists.' ) if not task_path . is_dir (): raise TrestleError ( f 'File { task_path } passed, however template directory is expected.' )","title":"TemplateVersioning"},{"location":"api_reference/trestle.core.commands.author.versioning.template_versioning/#trestle.core.commands.author.versioning.template_versioning.TemplateVersioning-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.author.versioning.template_versioning/#trestle.core.commands.author.versioning.template_versioning.TemplateVersioning.get_all_versions_for_task","text":"Get all versions for the task. Source code in trestle/core/commands/author/versioning/template_versioning.py @staticmethod def get_all_versions_for_task ( task_path : Path ) -> List [ str ]: \"\"\"Get all versions for the task.\"\"\" version_regex = r '[0-9]+.[0-9]+.[0-9]+' pattern = re . compile ( version_regex ) all_versions = [] max_version = START_TEMPLATE_VERSION for p in task_path . iterdir (): if p . is_dir () and pattern . search ( p . parts [ - 1 ]) is not None : match = pattern . search ( p . parts [ - 1 ]) . string all_versions . append ( match ) if match > max_version : max_version = match return all_versions","title":"get_all_versions_for_task()"},{"location":"api_reference/trestle.core.commands.author.versioning.template_versioning/#trestle.core.commands.author.versioning.template_versioning.TemplateVersioning.get_latest_version_for_task","text":"Get latest version of the template for the given task. Source code in trestle/core/commands/author/versioning/template_versioning.py @staticmethod def get_latest_version_for_task ( task_path : Path ) -> Tuple [ Path , str ]: \"\"\"Get latest version of the template for the given task.\"\"\" TemplateVersioning . _check_if_exists_and_dir ( task_path ) all_versions = TemplateVersioning . get_all_versions_for_task ( task_path ) max_version = START_TEMPLATE_VERSION if len ( all_versions ) == 0 : logger . debug ( f 'No template versions were found for task: { task_path } , defaulting to 0.0.1' ) max_version = START_TEMPLATE_VERSION else : max_version = max ( all_versions ) latest_path = Path ( f ' { task_path } / { max_version } ' ) return latest_path , max_version","title":"get_latest_version_for_task()"},{"location":"api_reference/trestle.core.commands.author.versioning.template_versioning/#trestle.core.commands.author.versioning.template_versioning.TemplateVersioning.get_versioned_template_dir","text":"Get a template folder of the specified version. If no version is given, the latest version of template will be returned Source code in trestle/core/commands/author/versioning/template_versioning.py @staticmethod def get_versioned_template_dir ( task_path : Path , version : Optional [ str ] = None ) -> Path : \"\"\" Get a template folder of the specified version. If no version is given, the latest version of template will be returned \"\"\" TemplateVersioning . _check_if_exists_and_dir ( task_path ) latest_path = None if version is None : latest_path , _ = TemplateVersioning . get_latest_version_for_task ( task_path ) else : latest_path = Path ( f ' { task_path } / { version } /' ) if not latest_path . exists (): raise TrestleError ( f 'The task: { task_path } with version: { version } does not exists.' ) return latest_path","title":"get_versioned_template_dir()"},{"location":"api_reference/trestle.core.commands.author.versioning.template_versioning/#trestle.core.commands.author.versioning.template_versioning.TemplateVersioning.is_valid_version","text":"Check if the version format is correct. Source code in trestle/core/commands/author/versioning/template_versioning.py @staticmethod def is_valid_version ( template_version : str ) -> bool : \"\"\"Check if the version format is correct.\"\"\" if template_version is None : return True # we can have empty version if template_version == '0.0.0' : return False version_regex = r '^[0-9]+.[0-9]+.[0-9]+$' pattern = re . compile ( version_regex ) if pattern . search ( template_version ): return True else : return False","title":"is_valid_version()"},{"location":"api_reference/trestle.core.commands.author.versioning.template_versioning/#trestle.core.commands.author.versioning.template_versioning.TemplateVersioning.update_template_folder_structure","text":"Automatically detect whether the path is an old style and update it. An old-style path is a path of the form: root_folder/.trestle/author/{template_name}/{template_objects} The new version path is a path of the form: root_folder/.trestle/author/{template_name}/{version}/{template_objects} By default all old-style templates will be updated to version 0.0.1 Source code in trestle/core/commands/author/versioning/template_versioning.py @staticmethod def update_template_folder_structure ( task_path : Path ) -> None : \"\"\" Automatically detect whether the path is an old style and update it. An old-style path is a path of the form: root_folder/.trestle/author/{template_name}/{template_objects} The new version path is a path of the form: root_folder/.trestle/author/{template_name}/{version}/{template_objects} By default all old-style templates will be updated to version 0.0.1 \"\"\" TemplateVersioning . _check_if_exists_and_dir ( task_path ) try : all_files_wo_version = list ( filter ( lambda p : p . is_file (), file_utils . iterdir_without_hidden_files ( task_path )) ) new_dir = Path ( f ' { task_path } / { START_TEMPLATE_VERSION } ' ) new_dir . mkdir ( parents = True , exist_ok = True ) if len ( all_files_wo_version ) == 0 : logger . debug ( 'No templates outside of the version folders.' ) for f in all_files_wo_version : shutil . copy ( f , new_dir ) for p in all_files_wo_version : if p . is_dir (): shutil . rmtree ( p ) else : p . unlink () except OSError as e : raise TrestleError ( f 'Error while updating template folder: { e } ' ) except Exception as e : raise TrestleError ( f 'Unexpected error while updating template folder: { e } ' )","title":"update_template_folder_structure()"},{"location":"api_reference/trestle.core.commands.author.versioning.template_versioning/#trestle.core.commands.author.versioning.template_versioning.TemplateVersioning.validate_template_folder","text":"Validate template folder confirms to the versioned path style and has no other subdirectories. Source code in trestle/core/commands/author/versioning/template_versioning.py @staticmethod def validate_template_folder ( template_dir : Path ): \"\"\"Validate template folder confirms to the versioned path style and has no other subdirectories.\"\"\" TemplateVersioning . _check_if_exists_and_dir ( template_dir ) version_regex = r '[0-9]+.[0-9]+.[0-9]+' pattern = re . compile ( version_regex ) subdirectories = list ( filter ( lambda p : p . is_dir () and pattern . search ( p . parts [ - 1 ]) is None , template_dir . iterdir ()) ) if len ( subdirectories ) > 0 : raise TrestleError ( f 'Subdirectories are not allowed in template folders: { subdirectories } ' )","title":"validate_template_folder()"},{"location":"api_reference/trestle.core.commands.author.versioning.template_versioning/#trestle.core.commands.author.versioning.template_versioning.TemplateVersioning.write_versioned_template","text":"Write a template with the header or metadata of a specified version. If no version was given the latest version for the task will be used. Parameters: Name Type Description Default resource_name str Template resource name required task_path Path Task path required target_file Path File path where template will be written required version Optional[str] return a resource of a specific version None Returns: Type Description None A dotted path of a versioned template, list of all available versions Source code in trestle/core/commands/author/versioning/template_versioning.py @staticmethod def write_versioned_template ( resource_name : str , task_path : Path , target_file : Path , version : Optional [ str ] = None ) -> None : \"\"\" Write a template with the header or metadata of a specified version. If no version was given the latest version for the task will be used. Args: resource_name: Template resource name task_path: Task path target_file: File path where template will be written version: return a resource of a specific version Returns: A dotted path of a versioned template, list of all available versions \"\"\" TemplateVersioning . _check_if_exists_and_dir ( task_path ) try : templates_resource_path = TRESTLE_RESOURCES + '.templates' generic_template = Path ( resource_filename ( templates_resource_path , resource_name )) . resolve () if version is None : _ , version = TemplateVersioning . get_latest_version_for_task ( task_path ) # modify header/metadata in the template if generic_template . suffix == '.md' : md_api = MarkdownAPI () header , md_body = md_api . processor . read_markdown_wo_processing ( generic_template ) header [ TEMPLATE_VERSION_HEADER ] = version md_api . write_markdown_with_header ( target_file , header , md_body ) logger . debug ( f 'Successfully written template markdown to { target_file } ' ) elif generic_template . suffix == '.drawio' : drawio = DrawIO ( generic_template ) metadata = drawio . get_metadata ()[ 0 ] metadata [ TEMPLATE_VERSION_HEADER ] = version drawio . write_drawio_with_metadata ( generic_template , metadata , 0 , target_file ) logger . debug ( f 'Successfully written template drawio to { target_file } ' ) else : raise TrestleError ( f 'Unsupported template file extension { generic_template . suffix } ' ) except OSError as e : raise TrestleError ( f 'Error while updating template folder: { e } ' ) handler: python","title":"write_versioned_template()"},{"location":"api_reference/trestle.core.commands.command_docs/","text":"trestle.core.commands.command_docs \u00a4 Trestle command abstraction. Improves parsing until such a point as ILCLI is fixed. logger \u00a4 Classes \u00a4 CommandBase ( Command ) \u00a4 Linear extension to the ILCLI interface to use documentation string more. Trestle commands not requiring trestle-root should extend from this class. Source code in trestle/core/commands/command_docs.py class CommandBase ( Command ): \"\"\"Linear extension to the ILCLI interface to use documentation string more. Trestle commands not requiring trestle-root should extend from this class. \"\"\" # Example commands extedning from this class - init', 'trestle', 'version', 'partial-object-validate' def __init__ ( self , parser = None , parent = None , name = None , out = None , err = None ) -> None : \"\"\"Override default ILCLI behaviour to include class documentation in command help description.\"\"\" super ( CommandBase , self ) . __init__ ( parser , parent , name , out , err ) self . parser . description = self . __doc__ Methods \u00a4 __init__ ( self , parser = None , parent = None , name = None , out = None , err = None ) special \u00a4 Override default ILCLI behaviour to include class documentation in command help description. Source code in trestle/core/commands/command_docs.py def __init__ ( self , parser = None , parent = None , name = None , out = None , err = None ) -> None : \"\"\"Override default ILCLI behaviour to include class documentation in command help description.\"\"\" super ( CommandBase , self ) . __init__ ( parser , parent , name , out , err ) self . parser . description = self . __doc__ CommandPlusDocs ( CommandBase ) \u00a4 This class validates trestle-root argument. Trestle commands requiring trestle-root should extend from this class. All commands that extend this class will validate the state of Trestle workspace. Source code in trestle/core/commands/command_docs.py class CommandPlusDocs ( CommandBase ): \"\"\"This class validates trestle-root argument. Trestle commands requiring trestle-root should extend from this class. All commands that extend this class will validate the state of Trestle workspace. \"\"\" def _validate_arguments ( self , args ): \"\"\"Check trestle-root argument is a valid trestle root directory.\"\"\" root = file_utils . extract_trestle_project_root ( args . trestle_root ) if root is None : logger . error ( f 'Given directory { args . trestle_root } is not in a valid trestle root directory' ) return CmdReturnCodes . TRESTLE_ROOT_ERROR . value is_oscal_dir_valid = file_utils . check_oscal_directories ( args . trestle_root ) if not is_oscal_dir_valid : return CmdReturnCodes . TRESTLE_ROOT_ERROR . value args . trestle_root = root return CmdReturnCodes . SUCCESS . value handler: python","title":"command_docs"},{"location":"api_reference/trestle.core.commands.command_docs/#trestle.core.commands.command_docs","text":"Trestle command abstraction. Improves parsing until such a point as ILCLI is fixed.","title":"command_docs"},{"location":"api_reference/trestle.core.commands.command_docs/#trestle.core.commands.command_docs.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.command_docs/#trestle.core.commands.command_docs-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.command_docs/#trestle.core.commands.command_docs.CommandBase","text":"Linear extension to the ILCLI interface to use documentation string more. Trestle commands not requiring trestle-root should extend from this class. Source code in trestle/core/commands/command_docs.py class CommandBase ( Command ): \"\"\"Linear extension to the ILCLI interface to use documentation string more. Trestle commands not requiring trestle-root should extend from this class. \"\"\" # Example commands extedning from this class - init', 'trestle', 'version', 'partial-object-validate' def __init__ ( self , parser = None , parent = None , name = None , out = None , err = None ) -> None : \"\"\"Override default ILCLI behaviour to include class documentation in command help description.\"\"\" super ( CommandBase , self ) . __init__ ( parser , parent , name , out , err ) self . parser . description = self . __doc__","title":"CommandBase"},{"location":"api_reference/trestle.core.commands.command_docs/#trestle.core.commands.command_docs.CommandBase-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.command_docs/#trestle.core.commands.command_docs.CommandBase.__init__","text":"Override default ILCLI behaviour to include class documentation in command help description. Source code in trestle/core/commands/command_docs.py def __init__ ( self , parser = None , parent = None , name = None , out = None , err = None ) -> None : \"\"\"Override default ILCLI behaviour to include class documentation in command help description.\"\"\" super ( CommandBase , self ) . __init__ ( parser , parent , name , out , err ) self . parser . description = self . __doc__","title":"__init__()"},{"location":"api_reference/trestle.core.commands.command_docs/#trestle.core.commands.command_docs.CommandPlusDocs","text":"This class validates trestle-root argument. Trestle commands requiring trestle-root should extend from this class. All commands that extend this class will validate the state of Trestle workspace. Source code in trestle/core/commands/command_docs.py class CommandPlusDocs ( CommandBase ): \"\"\"This class validates trestle-root argument. Trestle commands requiring trestle-root should extend from this class. All commands that extend this class will validate the state of Trestle workspace. \"\"\" def _validate_arguments ( self , args ): \"\"\"Check trestle-root argument is a valid trestle root directory.\"\"\" root = file_utils . extract_trestle_project_root ( args . trestle_root ) if root is None : logger . error ( f 'Given directory { args . trestle_root } is not in a valid trestle root directory' ) return CmdReturnCodes . TRESTLE_ROOT_ERROR . value is_oscal_dir_valid = file_utils . check_oscal_directories ( args . trestle_root ) if not is_oscal_dir_valid : return CmdReturnCodes . TRESTLE_ROOT_ERROR . value args . trestle_root = root return CmdReturnCodes . SUCCESS . value handler: python","title":"CommandPlusDocs"},{"location":"api_reference/trestle.core.commands.common.cmd_utils/","text":"trestle.core.commands.common.cmd_utils \u00a4 Trestle command related utilities. Functions \u00a4 model_type_is_too_granular ( model_type ) \u00a4 Is an model_type too fine to split. Source code in trestle/core/commands/common/cmd_utils.py def model_type_is_too_granular ( model_type : Type [ Any ]) -> bool : \"\"\"Is an model_type too fine to split.\"\"\" if type_utils . is_collection_field_type ( model_type ): return False if hasattr ( model_type , '__fields__' ) and '__root__' in model_type . __fields__ : return True if model_type . __name__ in [ 'str' , 'ConstrainedStrValue' , 'int' , 'float' , 'datetime' ]: return True return False parse_chain ( model_obj , path_parts , relative_path = None ) \u00a4 Parse the model chain starting from the beginning. Parameters: Name Type Description Default model_obj Optional[trestle.core.base_model.OscalBaseModel] Model to use for inspecting available elements, if available or none required path_parts List[str] list of string paths to parse including wildcards required relative_path Optional[pathlib.Path] Optional relative path (w.r.t trestle project root directory) None Returns: Type Description List[trestle.core.models.elements.ElementPath] List of ElementPath Source code in trestle/core/commands/common/cmd_utils.py def parse_chain ( model_obj : Union [ OscalBaseModel , None ], path_parts : List [ str ], relative_path : Optional [ pathlib . Path ] = None ) -> List [ ElementPath ]: \"\"\"Parse the model chain starting from the beginning. Args: model_obj: Model to use for inspecting available elements, if available or none path_parts: list of string paths to parse including wildcards relative_path: Optional relative path (w.r.t trestle project root directory) Returns: List of ElementPath \"\"\" element_paths : List [ ElementPath ] = [] sub_model = model_obj have_model_to_parse = model_obj is not None prev_element_path = None latest_path = None parent_model = path_parts [ 0 ] i = 1 while i < len ( path_parts ): p = path_parts [ i ] # if hit wildcard create element path up to this point if p == ElementPath . WILDCARD and len ( element_paths ) > 0 : # append wildcard to the latest element path latest_path = element_paths . pop () if latest_path . get_last () == ElementPath . WILDCARD : raise TrestleError ( f 'Invalid element path with consecutive { ElementPath . WILDCARD } ' ) latest_path_str = ElementPath . PATH_SEPARATOR . join ([ latest_path . to_string (), p ]) element_path = ElementPath ( latest_path_str , latest_path . get_parent ()) else : # create and append element_path # at this point sub_model may be a list of items # new element path is needed only if any of the items contains the desired part if p != ElementPath . WILDCARD : new_attrib = str_utils . dash_to_underscore ( p ) if isinstance ( sub_model , list ): for item in sub_model : # go into the list and find one with requested part sub_item = getattr ( item , new_attrib , None ) if sub_item is not None : sub_model = sub_item break else : sub_model = getattr ( sub_model , new_attrib , None ) if have_model_to_parse and sub_model is None : return element_paths p = ElementPath . PATH_SEPARATOR . join ([ parent_model , p ]) element_path = ElementPath ( p , parent_path = prev_element_path ) # If the path has wildcard and there are more parts later, # get the parent model for the alias path # If path has wildcard and it does not refer to a list, then there can be nothing after * if element_path . get_last () == ElementPath . WILDCARD : full_path_str = ElementPath . PATH_SEPARATOR . join ( element_path . get_full_path_parts ()[: - 1 ]) parent_model = ModelUtils . get_singular_alias ( full_path_str , relative_path ) # Does wildcard mean we need to inspect the sub_model to determine what can be split off from it? # If it has __root__ it may mean it contains a list of objects and should be split as a list if isinstance ( sub_model , OscalBaseModel ): root = getattr ( sub_model , '__root__' , None ) if root is None or not isinstance ( root , list ): # Cannot have parts beyond * if it isn't a list if i < len ( path_parts ) - 1 : raise TrestleError ( f 'Cannot split beyond * when the wildcard does not refer to a list. Path: { path_parts } ' ) for key in sub_model . __fields__ . keys (): # only create element path is item is present in the sub_model if getattr ( sub_model , key , None ) is None : continue new_alias = str_utils . underscore_to_dash ( key ) new_path = full_path_str + '.' + new_alias if not split_is_too_fine ( new_path , model_obj ): # to add parts of an element, need to add two links # prev_element_path may be None, for example catalog.* if prev_element_path is not None : element_paths . append ( prev_element_path ) element_paths . append ( ElementPath ( parent_model + '.' + new_alias , latest_path )) # Since wildcard is last in the chain when splitting an oscal model we are done return element_paths else : parent_model = element_path . get_element_name () # store values for next cycle prev_element_path = element_path element_paths . append ( element_path ) i += 1 return element_paths parse_element_arg ( model_obj , element_arg , relative_path = None ) \u00a4 Parse an element arg string into a list of ElementPath. Parameters: Name Type Description Default model_obj Optional[trestle.core.base_model.OscalBaseModel] The OscalBaseModel being inspected to determine available elements that can be split required element_arg str Single element path, as a string. required relative_path Optional[pathlib.Path] Optional relative path (from trestle root) used to validate element args are valid. None Returns: Type Description List[trestle.core.models.elements.ElementPath] The requested parsed list of ElementPath for use in split Source code in trestle/core/commands/common/cmd_utils.py def parse_element_arg ( model_obj : Union [ OscalBaseModel , None ], element_arg : str , relative_path : Optional [ pathlib . Path ] = None ) -> List [ ElementPath ]: \"\"\"Parse an element arg string into a list of ElementPath. Args: model_obj: The OscalBaseModel being inspected to determine available elements that can be split element_arg: Single element path, as a string. relative_path: Optional relative path (from trestle root) used to validate element args are valid. Returns: The requested parsed list of ElementPath for use in split \"\"\" element_arg = element_arg . strip () if element_arg == '*' : raise TrestleError ( 'Invalid element path containing only a single wildcard.' ) if element_arg == '' : raise TrestleError ( 'Invalid element path is empty string.' ) # search for wildcards and create paths with its parent path path_parts = element_arg . split ( ElementPath . PATH_SEPARATOR ) if len ( path_parts ) <= 1 : raise TrestleError ( f 'Invalid element path \" { element_arg } \" with only one element and no wildcard' ) element_paths = parse_chain ( model_obj , path_parts , relative_path ) if len ( element_paths ) <= 0 : # don't complain if nothing to split pass return element_paths parse_element_args ( model , element_args , relative_path = None ) \u00a4 Parse element args into a list of ElementPath. The element paths are either simple links of two elements, or two elements followed by *. The * represents either a list of the items in that element, or a splitting of that element into its parts. The only parts split off are the non-trivial ones determined by the granularity check. contextual_mode specifies if the path is a valid project model path or not. For example, if we are processing a metadata.parties.*, we need to know which metadata we are processing. If we pass contextual_mode=true, we can infer the root model by inspecting the file directory If contextual_mode=False, then the path must include the full path, e.g. catalog.metadata.parties. instead of just metadata.parties. When the * represents splitting a model rather than a list, the model is inspected for what parts are available, and for each new part two element paths are created, one for the parent to the current element, and another from the current element to the child. A path may have multiple *'s, but only the final one can represent splitting a model. Parameters: Name Type Description Default model Optional[trestle.core.base_model.OscalBaseModel] The OscalBaseModel being inspected to determine available elements that can be split required element_args List[str] List of str representing links in the chain of element paths to be parsed required relative_path Optional[pathlib.Path] Optional relative path (from trestle root) used to validate element args are valid. None Returns: Type Description List[trestle.core.models.elements.ElementPath] The requested parsed list of ElementPath for use in split Source code in trestle/core/commands/common/cmd_utils.py def parse_element_args ( model : Union [ OscalBaseModel , None ], element_args : List [ str ], relative_path : Optional [ pathlib . Path ] = None ) -> List [ ElementPath ]: \"\"\"Parse element args into a list of ElementPath. The element paths are either simple links of two elements, or two elements followed by *. The * represents either a list of the items in that element, or a splitting of that element into its parts. The only parts split off are the non-trivial ones determined by the granularity check. contextual_mode specifies if the path is a valid project model path or not. For example, if we are processing a metadata.parties.*, we need to know which metadata we are processing. If we pass contextual_mode=true, we can infer the root model by inspecting the file directory If contextual_mode=False, then the path must include the full path, e.g. catalog.metadata.parties.* instead of just metadata.parties.* When the * represents splitting a model rather than a list, the model is inspected for what parts are available, and for each new part two element paths are created, one for the parent to the current element, and another from the current element to the child. A path may have multiple *'s, but only the final one can represent splitting a model. Args: model: The OscalBaseModel being inspected to determine available elements that can be split element_args: List of str representing links in the chain of element paths to be parsed relative_path: Optional relative path (from trestle root) used to validate element args are valid. Returns: The requested parsed list of ElementPath for use in split \"\"\" # collect all paths element_paths : List [ ElementPath ] = [] for element_arg in element_args : paths = parse_element_arg ( model , element_arg , relative_path ) element_paths . extend ( paths ) return element_paths split_is_too_fine ( split_paths , model_obj ) \u00a4 Determine if the element path list goes too fine, e.g. individual strings. Source code in trestle/core/commands/common/cmd_utils.py def split_is_too_fine ( split_paths : str , model_obj : OscalBaseModel ) -> bool : \"\"\"Determine if the element path list goes too fine, e.g. individual strings.\"\"\" for split_path in split_paths . split ( ',' ): # find model type one level above if finishing with '.*' model_type = ElementPath ( split_path . rstrip ( '.*' )) . get_type ( type ( model_obj )) if model_type_is_too_granular ( model_type ): return True return False to_model_file_name ( model_obj , file_prefix , content_type ) \u00a4 Return the file name for the item. Source code in trestle/core/commands/common/cmd_utils.py def to_model_file_name ( model_obj : OscalBaseModel , file_prefix : str , content_type : FileContentType ) -> str : \"\"\"Return the file name for the item.\"\"\" file_ext = FileContentType . to_file_extension ( content_type ) model_type = classname_to_alias ( type ( model_obj ) . __name__ , AliasMode . JSON ) file_name = f ' { file_prefix }{ const . IDX_SEP }{ model_type }{ file_ext } ' return file_name handler: python","title":"cmd_utils"},{"location":"api_reference/trestle.core.commands.common.cmd_utils/#trestle.core.commands.common.cmd_utils","text":"Trestle command related utilities.","title":"cmd_utils"},{"location":"api_reference/trestle.core.commands.common.cmd_utils/#trestle.core.commands.common.cmd_utils-functions","text":"","title":"Functions"},{"location":"api_reference/trestle.core.commands.common.cmd_utils/#trestle.core.commands.common.cmd_utils.model_type_is_too_granular","text":"Is an model_type too fine to split. Source code in trestle/core/commands/common/cmd_utils.py def model_type_is_too_granular ( model_type : Type [ Any ]) -> bool : \"\"\"Is an model_type too fine to split.\"\"\" if type_utils . is_collection_field_type ( model_type ): return False if hasattr ( model_type , '__fields__' ) and '__root__' in model_type . __fields__ : return True if model_type . __name__ in [ 'str' , 'ConstrainedStrValue' , 'int' , 'float' , 'datetime' ]: return True return False","title":"model_type_is_too_granular()"},{"location":"api_reference/trestle.core.commands.common.cmd_utils/#trestle.core.commands.common.cmd_utils.parse_chain","text":"Parse the model chain starting from the beginning. Parameters: Name Type Description Default model_obj Optional[trestle.core.base_model.OscalBaseModel] Model to use for inspecting available elements, if available or none required path_parts List[str] list of string paths to parse including wildcards required relative_path Optional[pathlib.Path] Optional relative path (w.r.t trestle project root directory) None Returns: Type Description List[trestle.core.models.elements.ElementPath] List of ElementPath Source code in trestle/core/commands/common/cmd_utils.py def parse_chain ( model_obj : Union [ OscalBaseModel , None ], path_parts : List [ str ], relative_path : Optional [ pathlib . Path ] = None ) -> List [ ElementPath ]: \"\"\"Parse the model chain starting from the beginning. Args: model_obj: Model to use for inspecting available elements, if available or none path_parts: list of string paths to parse including wildcards relative_path: Optional relative path (w.r.t trestle project root directory) Returns: List of ElementPath \"\"\" element_paths : List [ ElementPath ] = [] sub_model = model_obj have_model_to_parse = model_obj is not None prev_element_path = None latest_path = None parent_model = path_parts [ 0 ] i = 1 while i < len ( path_parts ): p = path_parts [ i ] # if hit wildcard create element path up to this point if p == ElementPath . WILDCARD and len ( element_paths ) > 0 : # append wildcard to the latest element path latest_path = element_paths . pop () if latest_path . get_last () == ElementPath . WILDCARD : raise TrestleError ( f 'Invalid element path with consecutive { ElementPath . WILDCARD } ' ) latest_path_str = ElementPath . PATH_SEPARATOR . join ([ latest_path . to_string (), p ]) element_path = ElementPath ( latest_path_str , latest_path . get_parent ()) else : # create and append element_path # at this point sub_model may be a list of items # new element path is needed only if any of the items contains the desired part if p != ElementPath . WILDCARD : new_attrib = str_utils . dash_to_underscore ( p ) if isinstance ( sub_model , list ): for item in sub_model : # go into the list and find one with requested part sub_item = getattr ( item , new_attrib , None ) if sub_item is not None : sub_model = sub_item break else : sub_model = getattr ( sub_model , new_attrib , None ) if have_model_to_parse and sub_model is None : return element_paths p = ElementPath . PATH_SEPARATOR . join ([ parent_model , p ]) element_path = ElementPath ( p , parent_path = prev_element_path ) # If the path has wildcard and there are more parts later, # get the parent model for the alias path # If path has wildcard and it does not refer to a list, then there can be nothing after * if element_path . get_last () == ElementPath . WILDCARD : full_path_str = ElementPath . PATH_SEPARATOR . join ( element_path . get_full_path_parts ()[: - 1 ]) parent_model = ModelUtils . get_singular_alias ( full_path_str , relative_path ) # Does wildcard mean we need to inspect the sub_model to determine what can be split off from it? # If it has __root__ it may mean it contains a list of objects and should be split as a list if isinstance ( sub_model , OscalBaseModel ): root = getattr ( sub_model , '__root__' , None ) if root is None or not isinstance ( root , list ): # Cannot have parts beyond * if it isn't a list if i < len ( path_parts ) - 1 : raise TrestleError ( f 'Cannot split beyond * when the wildcard does not refer to a list. Path: { path_parts } ' ) for key in sub_model . __fields__ . keys (): # only create element path is item is present in the sub_model if getattr ( sub_model , key , None ) is None : continue new_alias = str_utils . underscore_to_dash ( key ) new_path = full_path_str + '.' + new_alias if not split_is_too_fine ( new_path , model_obj ): # to add parts of an element, need to add two links # prev_element_path may be None, for example catalog.* if prev_element_path is not None : element_paths . append ( prev_element_path ) element_paths . append ( ElementPath ( parent_model + '.' + new_alias , latest_path )) # Since wildcard is last in the chain when splitting an oscal model we are done return element_paths else : parent_model = element_path . get_element_name () # store values for next cycle prev_element_path = element_path element_paths . append ( element_path ) i += 1 return element_paths","title":"parse_chain()"},{"location":"api_reference/trestle.core.commands.common.cmd_utils/#trestle.core.commands.common.cmd_utils.parse_element_arg","text":"Parse an element arg string into a list of ElementPath. Parameters: Name Type Description Default model_obj Optional[trestle.core.base_model.OscalBaseModel] The OscalBaseModel being inspected to determine available elements that can be split required element_arg str Single element path, as a string. required relative_path Optional[pathlib.Path] Optional relative path (from trestle root) used to validate element args are valid. None Returns: Type Description List[trestle.core.models.elements.ElementPath] The requested parsed list of ElementPath for use in split Source code in trestle/core/commands/common/cmd_utils.py def parse_element_arg ( model_obj : Union [ OscalBaseModel , None ], element_arg : str , relative_path : Optional [ pathlib . Path ] = None ) -> List [ ElementPath ]: \"\"\"Parse an element arg string into a list of ElementPath. Args: model_obj: The OscalBaseModel being inspected to determine available elements that can be split element_arg: Single element path, as a string. relative_path: Optional relative path (from trestle root) used to validate element args are valid. Returns: The requested parsed list of ElementPath for use in split \"\"\" element_arg = element_arg . strip () if element_arg == '*' : raise TrestleError ( 'Invalid element path containing only a single wildcard.' ) if element_arg == '' : raise TrestleError ( 'Invalid element path is empty string.' ) # search for wildcards and create paths with its parent path path_parts = element_arg . split ( ElementPath . PATH_SEPARATOR ) if len ( path_parts ) <= 1 : raise TrestleError ( f 'Invalid element path \" { element_arg } \" with only one element and no wildcard' ) element_paths = parse_chain ( model_obj , path_parts , relative_path ) if len ( element_paths ) <= 0 : # don't complain if nothing to split pass return element_paths","title":"parse_element_arg()"},{"location":"api_reference/trestle.core.commands.common.cmd_utils/#trestle.core.commands.common.cmd_utils.parse_element_args","text":"Parse element args into a list of ElementPath. The element paths are either simple links of two elements, or two elements followed by *. The * represents either a list of the items in that element, or a splitting of that element into its parts. The only parts split off are the non-trivial ones determined by the granularity check. contextual_mode specifies if the path is a valid project model path or not. For example, if we are processing a metadata.parties.*, we need to know which metadata we are processing. If we pass contextual_mode=true, we can infer the root model by inspecting the file directory If contextual_mode=False, then the path must include the full path, e.g. catalog.metadata.parties. instead of just metadata.parties. When the * represents splitting a model rather than a list, the model is inspected for what parts are available, and for each new part two element paths are created, one for the parent to the current element, and another from the current element to the child. A path may have multiple *'s, but only the final one can represent splitting a model. Parameters: Name Type Description Default model Optional[trestle.core.base_model.OscalBaseModel] The OscalBaseModel being inspected to determine available elements that can be split required element_args List[str] List of str representing links in the chain of element paths to be parsed required relative_path Optional[pathlib.Path] Optional relative path (from trestle root) used to validate element args are valid. None Returns: Type Description List[trestle.core.models.elements.ElementPath] The requested parsed list of ElementPath for use in split Source code in trestle/core/commands/common/cmd_utils.py def parse_element_args ( model : Union [ OscalBaseModel , None ], element_args : List [ str ], relative_path : Optional [ pathlib . Path ] = None ) -> List [ ElementPath ]: \"\"\"Parse element args into a list of ElementPath. The element paths are either simple links of two elements, or two elements followed by *. The * represents either a list of the items in that element, or a splitting of that element into its parts. The only parts split off are the non-trivial ones determined by the granularity check. contextual_mode specifies if the path is a valid project model path or not. For example, if we are processing a metadata.parties.*, we need to know which metadata we are processing. If we pass contextual_mode=true, we can infer the root model by inspecting the file directory If contextual_mode=False, then the path must include the full path, e.g. catalog.metadata.parties.* instead of just metadata.parties.* When the * represents splitting a model rather than a list, the model is inspected for what parts are available, and for each new part two element paths are created, one for the parent to the current element, and another from the current element to the child. A path may have multiple *'s, but only the final one can represent splitting a model. Args: model: The OscalBaseModel being inspected to determine available elements that can be split element_args: List of str representing links in the chain of element paths to be parsed relative_path: Optional relative path (from trestle root) used to validate element args are valid. Returns: The requested parsed list of ElementPath for use in split \"\"\" # collect all paths element_paths : List [ ElementPath ] = [] for element_arg in element_args : paths = parse_element_arg ( model , element_arg , relative_path ) element_paths . extend ( paths ) return element_paths","title":"parse_element_args()"},{"location":"api_reference/trestle.core.commands.common.cmd_utils/#trestle.core.commands.common.cmd_utils.split_is_too_fine","text":"Determine if the element path list goes too fine, e.g. individual strings. Source code in trestle/core/commands/common/cmd_utils.py def split_is_too_fine ( split_paths : str , model_obj : OscalBaseModel ) -> bool : \"\"\"Determine if the element path list goes too fine, e.g. individual strings.\"\"\" for split_path in split_paths . split ( ',' ): # find model type one level above if finishing with '.*' model_type = ElementPath ( split_path . rstrip ( '.*' )) . get_type ( type ( model_obj )) if model_type_is_too_granular ( model_type ): return True return False","title":"split_is_too_fine()"},{"location":"api_reference/trestle.core.commands.common.cmd_utils/#trestle.core.commands.common.cmd_utils.to_model_file_name","text":"Return the file name for the item. Source code in trestle/core/commands/common/cmd_utils.py def to_model_file_name ( model_obj : OscalBaseModel , file_prefix : str , content_type : FileContentType ) -> str : \"\"\"Return the file name for the item.\"\"\" file_ext = FileContentType . to_file_extension ( content_type ) model_type = classname_to_alias ( type ( model_obj ) . __name__ , AliasMode . JSON ) file_name = f ' { file_prefix }{ const . IDX_SEP }{ model_type }{ file_ext } ' return file_name handler: python","title":"to_model_file_name()"},{"location":"api_reference/trestle.core.commands.common.return_codes/","text":"trestle.core.commands.common.return_codes \u00a4 Trestle command return codes. Classes \u00a4 CmdReturnCodes ( Enum ) \u00a4 Trestle CLI return codes. SUCCESS - Operation/validation completed successfully COMMAND_ERROR - Generic expected error while executing command (handled by command) INCORRECT_ARGS - Provided arguments were incorrect/incomplete DOCUMENTS_VALIDATION_ERROR - Validation of the markdown or drawio files failed MODEL_VALIDATION_ERROR - Validation of OSCAL model failed TRESTLE_ROOT_ERROR - Trestle project setup has failed, the root is not trestle directory IO_ERROR - IO related errors, i.e. permission issue, non-existing file, etc AUTH_ERROR - Authenication error while accessing/storing cache UNKNOWN_ERROR - Unexpected error (unhandled by command) Source code in trestle/core/commands/common/return_codes.py class CmdReturnCodes ( enum . Enum ): \"\"\" Trestle CLI return codes. SUCCESS - Operation/validation completed successfully COMMAND_ERROR - Generic expected error while executing command (handled by command) INCORRECT_ARGS - Provided arguments were incorrect/incomplete DOCUMENTS_VALIDATION_ERROR - Validation of the markdown or drawio files failed MODEL_VALIDATION_ERROR - Validation of OSCAL model failed TRESTLE_ROOT_ERROR - Trestle project setup has failed, the root is not trestle directory IO_ERROR - IO related errors, i.e. permission issue, non-existing file, etc AUTH_ERROR - Authenication error while accessing/storing cache UNKNOWN_ERROR - Unexpected error (unhandled by command) \"\"\" SUCCESS = 0 COMMAND_ERROR = 1 INCORRECT_ARGS = 2 DOCUMENTS_VALIDATION_ERROR = 3 OSCAL_VALIDATION_ERROR = 4 TRESTLE_ROOT_ERROR = 5 IO_ERROR = 6 AUTH_ERROR = 7 UNKNOWN_ERROR = 8 AUTH_ERROR \u00a4 COMMAND_ERROR \u00a4 DOCUMENTS_VALIDATION_ERROR \u00a4 INCORRECT_ARGS \u00a4 IO_ERROR \u00a4 OSCAL_VALIDATION_ERROR \u00a4 SUCCESS \u00a4 TRESTLE_ROOT_ERROR \u00a4 UNKNOWN_ERROR \u00a4 handler: python","title":"return_codes"},{"location":"api_reference/trestle.core.commands.common.return_codes/#trestle.core.commands.common.return_codes","text":"Trestle command return codes.","title":"return_codes"},{"location":"api_reference/trestle.core.commands.common.return_codes/#trestle.core.commands.common.return_codes-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.common.return_codes/#trestle.core.commands.common.return_codes.CmdReturnCodes","text":"Trestle CLI return codes. SUCCESS - Operation/validation completed successfully COMMAND_ERROR - Generic expected error while executing command (handled by command) INCORRECT_ARGS - Provided arguments were incorrect/incomplete DOCUMENTS_VALIDATION_ERROR - Validation of the markdown or drawio files failed MODEL_VALIDATION_ERROR - Validation of OSCAL model failed TRESTLE_ROOT_ERROR - Trestle project setup has failed, the root is not trestle directory IO_ERROR - IO related errors, i.e. permission issue, non-existing file, etc AUTH_ERROR - Authenication error while accessing/storing cache UNKNOWN_ERROR - Unexpected error (unhandled by command) Source code in trestle/core/commands/common/return_codes.py class CmdReturnCodes ( enum . Enum ): \"\"\" Trestle CLI return codes. SUCCESS - Operation/validation completed successfully COMMAND_ERROR - Generic expected error while executing command (handled by command) INCORRECT_ARGS - Provided arguments were incorrect/incomplete DOCUMENTS_VALIDATION_ERROR - Validation of the markdown or drawio files failed MODEL_VALIDATION_ERROR - Validation of OSCAL model failed TRESTLE_ROOT_ERROR - Trestle project setup has failed, the root is not trestle directory IO_ERROR - IO related errors, i.e. permission issue, non-existing file, etc AUTH_ERROR - Authenication error while accessing/storing cache UNKNOWN_ERROR - Unexpected error (unhandled by command) \"\"\" SUCCESS = 0 COMMAND_ERROR = 1 INCORRECT_ARGS = 2 DOCUMENTS_VALIDATION_ERROR = 3 OSCAL_VALIDATION_ERROR = 4 TRESTLE_ROOT_ERROR = 5 IO_ERROR = 6 AUTH_ERROR = 7 UNKNOWN_ERROR = 8","title":"CmdReturnCodes"},{"location":"api_reference/trestle.core.commands.common.return_codes/#trestle.core.commands.common.return_codes.CmdReturnCodes.AUTH_ERROR","text":"","title":"AUTH_ERROR"},{"location":"api_reference/trestle.core.commands.common.return_codes/#trestle.core.commands.common.return_codes.CmdReturnCodes.COMMAND_ERROR","text":"","title":"COMMAND_ERROR"},{"location":"api_reference/trestle.core.commands.common.return_codes/#trestle.core.commands.common.return_codes.CmdReturnCodes.DOCUMENTS_VALIDATION_ERROR","text":"","title":"DOCUMENTS_VALIDATION_ERROR"},{"location":"api_reference/trestle.core.commands.common.return_codes/#trestle.core.commands.common.return_codes.CmdReturnCodes.INCORRECT_ARGS","text":"","title":"INCORRECT_ARGS"},{"location":"api_reference/trestle.core.commands.common.return_codes/#trestle.core.commands.common.return_codes.CmdReturnCodes.IO_ERROR","text":"","title":"IO_ERROR"},{"location":"api_reference/trestle.core.commands.common.return_codes/#trestle.core.commands.common.return_codes.CmdReturnCodes.OSCAL_VALIDATION_ERROR","text":"","title":"OSCAL_VALIDATION_ERROR"},{"location":"api_reference/trestle.core.commands.common.return_codes/#trestle.core.commands.common.return_codes.CmdReturnCodes.SUCCESS","text":"","title":"SUCCESS"},{"location":"api_reference/trestle.core.commands.common.return_codes/#trestle.core.commands.common.return_codes.CmdReturnCodes.TRESTLE_ROOT_ERROR","text":"","title":"TRESTLE_ROOT_ERROR"},{"location":"api_reference/trestle.core.commands.common.return_codes/#trestle.core.commands.common.return_codes.CmdReturnCodes.UNKNOWN_ERROR","text":"handler: python","title":"UNKNOWN_ERROR"},{"location":"api_reference/trestle.core.commands.create/","text":"trestle.core.commands.create \u00a4 Trestle Create CommandPlusDocs. logger \u00a4 Classes \u00a4 CreateCmd ( CommandPlusDocs ) \u00a4 Create a sample OSCAL model in trestle project or create new elements within a given model. Source code in trestle/core/commands/create.py class CreateCmd ( CommandPlusDocs ): \"\"\"Create a sample OSCAL model in trestle project or create new elements within a given model.\"\"\" name = 'create' def _init_arguments ( self ) -> None : self . add_argument ( '-t' , '--type' , help = 'Type of model if created anew.' , choices = const . MODEL_TYPE_LIST ) self . add_argument ( '-o' , '--output' , help = 'Name of the output created model.' ) self . add_argument ( const . IOF_SHORT , const . IOF_LONG , help = const . IOF_HELP , action = 'store_true' ) self . add_argument ( '-x' , '--extension' , help = 'Type of file output.' , choices = [ 'json' , 'yaml' , 'yml' ], default = 'json' ) self . add_argument ( '-f' , '--file' , help = 'Optional existing OSCAL file that will have elements created within it.' , type = str ) self . add_argument ( '-e' , '--element' , help = 'Optional path of element to be created whithin the specified file.' , type = str ) def _run ( self , args : argparse . Namespace ) -> int : \"\"\" Execute the create command. Notes Either a new model will be created of the specified type, or an existing file will have new elements added within it. \"\"\" try : # Normal create path if args . type and args . output : object_type = ElementPath ( args . type ) . get_type () return self . create_object ( args . type , object_type , args ) # Add path elif args . file and args . element : add = Add () return add . add_from_args ( args ) raise err . TrestleIncorrectArgsError ( 'Create requires either a model type and output name, or a file and element path.' ) except Exception as e : # pragma: no cover return err . handle_generic_command_exception ( e , logger , 'Error while creating a sample OSCAL model' ) @classmethod def create_object ( cls , model_alias : str , object_type : Type [ TopLevelOscalModel ], args : argparse . Namespace ) -> int : \"\"\"Create a top level OSCAL object within the trestle directory, leveraging functionality in add.\"\"\" log . set_log_level_from_args ( args ) trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. if not trestle_root or not file_utils . is_valid_project_root ( args . trestle_root ): raise err . TrestleRootError ( f 'Given directory { trestle_root } is not a trestle project.' ) plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) desired_model_dir = trestle_root / plural_path / args . output desired_model_path = desired_model_dir / ( model_alias + '.' + args . extension ) if desired_model_path . exists (): raise err . TrestleError ( f 'OSCAL file to be created here: { desired_model_path } exists.' ) # Create sample model. sample_model = generators . generate_sample_model ( object_type , include_optional = args . include_optional_fields ) # Presuming top level level model not sure how to do the typing for this. sample_model . metadata . title = f 'Generic { model_alias } created by trestle named { args . output } .' # type: ignore sample_model . metadata . last_modified = datetime . now () . astimezone () sample_model . metadata . oscal_version = trestle . oscal . OSCAL_VERSION sample_model . metadata . version = '0.0.0' top_element = Element ( sample_model , model_alias ) create_action = CreatePathAction ( desired_model_path . resolve (), True ) write_action = WriteFileAction ( desired_model_path . resolve (), top_element , FileContentType . to_content_type ( desired_model_path . suffix ) ) # create a plan to write the directory and file. create_plan = Plan () create_plan . add_action ( create_action ) create_plan . add_action ( write_action ) create_plan . execute () return CmdReturnCodes . SUCCESS . value name \u00a4 Methods \u00a4 create_object ( model_alias , object_type , args ) classmethod \u00a4 Create a top level OSCAL object within the trestle directory, leveraging functionality in add. Source code in trestle/core/commands/create.py @classmethod def create_object ( cls , model_alias : str , object_type : Type [ TopLevelOscalModel ], args : argparse . Namespace ) -> int : \"\"\"Create a top level OSCAL object within the trestle directory, leveraging functionality in add.\"\"\" log . set_log_level_from_args ( args ) trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. if not trestle_root or not file_utils . is_valid_project_root ( args . trestle_root ): raise err . TrestleRootError ( f 'Given directory { trestle_root } is not a trestle project.' ) plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) desired_model_dir = trestle_root / plural_path / args . output desired_model_path = desired_model_dir / ( model_alias + '.' + args . extension ) if desired_model_path . exists (): raise err . TrestleError ( f 'OSCAL file to be created here: { desired_model_path } exists.' ) # Create sample model. sample_model = generators . generate_sample_model ( object_type , include_optional = args . include_optional_fields ) # Presuming top level level model not sure how to do the typing for this. sample_model . metadata . title = f 'Generic { model_alias } created by trestle named { args . output } .' # type: ignore sample_model . metadata . last_modified = datetime . now () . astimezone () sample_model . metadata . oscal_version = trestle . oscal . OSCAL_VERSION sample_model . metadata . version = '0.0.0' top_element = Element ( sample_model , model_alias ) create_action = CreatePathAction ( desired_model_path . resolve (), True ) write_action = WriteFileAction ( desired_model_path . resolve (), top_element , FileContentType . to_content_type ( desired_model_path . suffix ) ) # create a plan to write the directory and file. create_plan = Plan () create_plan . add_action ( create_action ) create_plan . add_action ( write_action ) create_plan . execute () return CmdReturnCodes . SUCCESS . value handler: python","title":"create"},{"location":"api_reference/trestle.core.commands.create/#trestle.core.commands.create","text":"Trestle Create CommandPlusDocs.","title":"create"},{"location":"api_reference/trestle.core.commands.create/#trestle.core.commands.create.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.create/#trestle.core.commands.create-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.create/#trestle.core.commands.create.CreateCmd","text":"Create a sample OSCAL model in trestle project or create new elements within a given model. Source code in trestle/core/commands/create.py class CreateCmd ( CommandPlusDocs ): \"\"\"Create a sample OSCAL model in trestle project or create new elements within a given model.\"\"\" name = 'create' def _init_arguments ( self ) -> None : self . add_argument ( '-t' , '--type' , help = 'Type of model if created anew.' , choices = const . MODEL_TYPE_LIST ) self . add_argument ( '-o' , '--output' , help = 'Name of the output created model.' ) self . add_argument ( const . IOF_SHORT , const . IOF_LONG , help = const . IOF_HELP , action = 'store_true' ) self . add_argument ( '-x' , '--extension' , help = 'Type of file output.' , choices = [ 'json' , 'yaml' , 'yml' ], default = 'json' ) self . add_argument ( '-f' , '--file' , help = 'Optional existing OSCAL file that will have elements created within it.' , type = str ) self . add_argument ( '-e' , '--element' , help = 'Optional path of element to be created whithin the specified file.' , type = str ) def _run ( self , args : argparse . Namespace ) -> int : \"\"\" Execute the create command. Notes Either a new model will be created of the specified type, or an existing file will have new elements added within it. \"\"\" try : # Normal create path if args . type and args . output : object_type = ElementPath ( args . type ) . get_type () return self . create_object ( args . type , object_type , args ) # Add path elif args . file and args . element : add = Add () return add . add_from_args ( args ) raise err . TrestleIncorrectArgsError ( 'Create requires either a model type and output name, or a file and element path.' ) except Exception as e : # pragma: no cover return err . handle_generic_command_exception ( e , logger , 'Error while creating a sample OSCAL model' ) @classmethod def create_object ( cls , model_alias : str , object_type : Type [ TopLevelOscalModel ], args : argparse . Namespace ) -> int : \"\"\"Create a top level OSCAL object within the trestle directory, leveraging functionality in add.\"\"\" log . set_log_level_from_args ( args ) trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. if not trestle_root or not file_utils . is_valid_project_root ( args . trestle_root ): raise err . TrestleRootError ( f 'Given directory { trestle_root } is not a trestle project.' ) plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) desired_model_dir = trestle_root / plural_path / args . output desired_model_path = desired_model_dir / ( model_alias + '.' + args . extension ) if desired_model_path . exists (): raise err . TrestleError ( f 'OSCAL file to be created here: { desired_model_path } exists.' ) # Create sample model. sample_model = generators . generate_sample_model ( object_type , include_optional = args . include_optional_fields ) # Presuming top level level model not sure how to do the typing for this. sample_model . metadata . title = f 'Generic { model_alias } created by trestle named { args . output } .' # type: ignore sample_model . metadata . last_modified = datetime . now () . astimezone () sample_model . metadata . oscal_version = trestle . oscal . OSCAL_VERSION sample_model . metadata . version = '0.0.0' top_element = Element ( sample_model , model_alias ) create_action = CreatePathAction ( desired_model_path . resolve (), True ) write_action = WriteFileAction ( desired_model_path . resolve (), top_element , FileContentType . to_content_type ( desired_model_path . suffix ) ) # create a plan to write the directory and file. create_plan = Plan () create_plan . add_action ( create_action ) create_plan . add_action ( write_action ) create_plan . execute () return CmdReturnCodes . SUCCESS . value","title":"CreateCmd"},{"location":"api_reference/trestle.core.commands.create/#trestle.core.commands.create.CreateCmd.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.create/#trestle.core.commands.create.CreateCmd-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.create/#trestle.core.commands.create.CreateCmd.create_object","text":"Create a top level OSCAL object within the trestle directory, leveraging functionality in add. Source code in trestle/core/commands/create.py @classmethod def create_object ( cls , model_alias : str , object_type : Type [ TopLevelOscalModel ], args : argparse . Namespace ) -> int : \"\"\"Create a top level OSCAL object within the trestle directory, leveraging functionality in add.\"\"\" log . set_log_level_from_args ( args ) trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. if not trestle_root or not file_utils . is_valid_project_root ( args . trestle_root ): raise err . TrestleRootError ( f 'Given directory { trestle_root } is not a trestle project.' ) plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) desired_model_dir = trestle_root / plural_path / args . output desired_model_path = desired_model_dir / ( model_alias + '.' + args . extension ) if desired_model_path . exists (): raise err . TrestleError ( f 'OSCAL file to be created here: { desired_model_path } exists.' ) # Create sample model. sample_model = generators . generate_sample_model ( object_type , include_optional = args . include_optional_fields ) # Presuming top level level model not sure how to do the typing for this. sample_model . metadata . title = f 'Generic { model_alias } created by trestle named { args . output } .' # type: ignore sample_model . metadata . last_modified = datetime . now () . astimezone () sample_model . metadata . oscal_version = trestle . oscal . OSCAL_VERSION sample_model . metadata . version = '0.0.0' top_element = Element ( sample_model , model_alias ) create_action = CreatePathAction ( desired_model_path . resolve (), True ) write_action = WriteFileAction ( desired_model_path . resolve (), top_element , FileContentType . to_content_type ( desired_model_path . suffix ) ) # create a plan to write the directory and file. create_plan = Plan () create_plan . add_action ( create_action ) create_plan . add_action ( write_action ) create_plan . execute () return CmdReturnCodes . SUCCESS . value handler: python","title":"create_object()"},{"location":"api_reference/trestle.core.commands.describe/","text":"trestle.core.commands.describe \u00a4 Trestle Describe Command. logger \u00a4 Classes \u00a4 DescribeCmd ( CommandPlusDocs ) \u00a4 Describe contents of a model file including optional element path. Source code in trestle/core/commands/describe.py class DescribeCmd ( CommandPlusDocs ): \"\"\"Describe contents of a model file including optional element path.\"\"\" # The only output is via log lines. No other results or side-effects. name = 'describe' def _init_arguments ( self ) -> None : logger . debug ( 'Init arguments' ) self . add_argument ( '-f' , '--file' , help = 'OSCAL file to import.' , type = str , required = True ) self . add_argument ( '-e' , '--element' , help = 'Optional name of element in file to describe.' , type = str , required = False ) def _run ( self , args : argparse . Namespace ) -> int : try : logger . debug ( 'Entering trestle describe.' ) log . set_log_level_from_args ( args ) if args . file : model_file = pathlib . Path ( args . file ) element = '' if not args . element else args . element . strip ( \"'\" ) results = self . describe ( model_file . resolve (), element , args . trestle_root ) return CmdReturnCodes . SUCCESS . value if len ( results ) > 0 else CmdReturnCodes . COMMAND_ERROR . value else : raise TrestleIncorrectArgsError ( 'No file specified for command describe.' ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while describing contents of a model' ) @classmethod def _clean_type_string ( cls , text : str ) -> str : text = text . replace ( \"<class '\" , '' ) . replace ( \"'>\" , '' ) text = text . replace ( 'trestle.oscal.' , '' ) text = text . replace ( 'pydantic.main.' , 'stripped.' ) return text @classmethod def _description_text ( cls , sub_model : OscalBaseModel ) -> str : clip_string = 100 if sub_model is None : return 'None' if type ( sub_model ) is list : n_items = len ( sub_model ) type_text = 'Unknown' if not n_items else f ' { cls . _clean_type_string ( str ( type ( sub_model [ 0 ]))) } ' text = f 'list of { n_items } items of type { type_text } ' return text if type ( sub_model ) is str : return sub_model if len ( sub_model ) < clip_string else sub_model [: clip_string ] + '[truncated]' if hasattr ( sub_model , 'type_' ): return cls . _clean_type_string ( str ( sub_model . type_ )) return cls . _clean_type_string ( str ( type ( sub_model ))) @classmethod def describe ( cls , file_path : pathlib . Path , element_path_str : str , trestle_root : pathlib . Path ) -> List [ str ]: \"\"\"Describe the contents of the file. Args: file_path: pathlib.Path Path for model file to describe. element_path_str: Element path of element in model to describe. Can be ''. Returns: The list of lines of text in the description, or an empty list on failure \"\"\" # figure out the model type so we can read it try : model_type , _ = ModelUtils . get_stripped_model_type ( file_path , trestle_root ) model : OscalBaseModel = model_type . oscal_read ( file_path ) except TrestleError as e : logger . warning ( f 'Error loading model { file_path } to describe: { e } ' ) return [] sub_model = model # if an element path was provided, follow the path chain to the desired sub_model if element_path_str : if '*' in element_path_str or ',' in element_path_str : logger . warning ( 'Wildcards and commas are not allowed in the element path for describe.' ) return [] if '.' not in element_path_str : logger . warning ( 'The element path for describe must either be omitted or contain at least 2 parts.' ) return [] element_paths = utils . parse_element_arg ( model , element_path_str ) sub_model_element = Element ( model ) for element_path in element_paths : sub_model = sub_model_element . get_at ( element_path , False ) sub_model_element = Element ( sub_model ) # now that we have the desired sub_model we can describe it text_out : List [ str ] = [] # create top level text depending on whether an element path was used element_text = '' if not element_path_str else f ' at element path { element_path_str } ' if type ( sub_model ) is list : text = f 'Model file { file_path }{ element_text } is a { cls . _description_text ( sub_model ) } ' text_out . append ( text ) logger . info ( text ) else : text = f 'Model file { file_path }{ element_text } is of type ' text += f ' { cls . _clean_type_string ( str ( type ( sub_model ))) } and contains:' text_out . append ( text ) logger . info ( text ) for key in sub_model . __fields__ . keys (): value = getattr ( sub_model , key , None ) text = f ' { key } : { cls . _description_text ( value ) } ' text_out . append ( text ) logger . info ( text ) return text_out name \u00a4 Methods \u00a4 describe ( file_path , element_path_str , trestle_root ) classmethod \u00a4 Describe the contents of the file. Parameters: Name Type Description Default file_path Path pathlib.Path Path for model file to describe. required element_path_str str Element path of element in model to describe. Can be ''. required Returns: Type Description List[str] The list of lines of text in the description, or an empty list on failure Source code in trestle/core/commands/describe.py @classmethod def describe ( cls , file_path : pathlib . Path , element_path_str : str , trestle_root : pathlib . Path ) -> List [ str ]: \"\"\"Describe the contents of the file. Args: file_path: pathlib.Path Path for model file to describe. element_path_str: Element path of element in model to describe. Can be ''. Returns: The list of lines of text in the description, or an empty list on failure \"\"\" # figure out the model type so we can read it try : model_type , _ = ModelUtils . get_stripped_model_type ( file_path , trestle_root ) model : OscalBaseModel = model_type . oscal_read ( file_path ) except TrestleError as e : logger . warning ( f 'Error loading model { file_path } to describe: { e } ' ) return [] sub_model = model # if an element path was provided, follow the path chain to the desired sub_model if element_path_str : if '*' in element_path_str or ',' in element_path_str : logger . warning ( 'Wildcards and commas are not allowed in the element path for describe.' ) return [] if '.' not in element_path_str : logger . warning ( 'The element path for describe must either be omitted or contain at least 2 parts.' ) return [] element_paths = utils . parse_element_arg ( model , element_path_str ) sub_model_element = Element ( model ) for element_path in element_paths : sub_model = sub_model_element . get_at ( element_path , False ) sub_model_element = Element ( sub_model ) # now that we have the desired sub_model we can describe it text_out : List [ str ] = [] # create top level text depending on whether an element path was used element_text = '' if not element_path_str else f ' at element path { element_path_str } ' if type ( sub_model ) is list : text = f 'Model file { file_path }{ element_text } is a { cls . _description_text ( sub_model ) } ' text_out . append ( text ) logger . info ( text ) else : text = f 'Model file { file_path }{ element_text } is of type ' text += f ' { cls . _clean_type_string ( str ( type ( sub_model ))) } and contains:' text_out . append ( text ) logger . info ( text ) for key in sub_model . __fields__ . keys (): value = getattr ( sub_model , key , None ) text = f ' { key } : { cls . _description_text ( value ) } ' text_out . append ( text ) logger . info ( text ) return text_out handler: python","title":"describe"},{"location":"api_reference/trestle.core.commands.describe/#trestle.core.commands.describe","text":"Trestle Describe Command.","title":"describe"},{"location":"api_reference/trestle.core.commands.describe/#trestle.core.commands.describe.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.describe/#trestle.core.commands.describe-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.describe/#trestle.core.commands.describe.DescribeCmd","text":"Describe contents of a model file including optional element path. Source code in trestle/core/commands/describe.py class DescribeCmd ( CommandPlusDocs ): \"\"\"Describe contents of a model file including optional element path.\"\"\" # The only output is via log lines. No other results or side-effects. name = 'describe' def _init_arguments ( self ) -> None : logger . debug ( 'Init arguments' ) self . add_argument ( '-f' , '--file' , help = 'OSCAL file to import.' , type = str , required = True ) self . add_argument ( '-e' , '--element' , help = 'Optional name of element in file to describe.' , type = str , required = False ) def _run ( self , args : argparse . Namespace ) -> int : try : logger . debug ( 'Entering trestle describe.' ) log . set_log_level_from_args ( args ) if args . file : model_file = pathlib . Path ( args . file ) element = '' if not args . element else args . element . strip ( \"'\" ) results = self . describe ( model_file . resolve (), element , args . trestle_root ) return CmdReturnCodes . SUCCESS . value if len ( results ) > 0 else CmdReturnCodes . COMMAND_ERROR . value else : raise TrestleIncorrectArgsError ( 'No file specified for command describe.' ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while describing contents of a model' ) @classmethod def _clean_type_string ( cls , text : str ) -> str : text = text . replace ( \"<class '\" , '' ) . replace ( \"'>\" , '' ) text = text . replace ( 'trestle.oscal.' , '' ) text = text . replace ( 'pydantic.main.' , 'stripped.' ) return text @classmethod def _description_text ( cls , sub_model : OscalBaseModel ) -> str : clip_string = 100 if sub_model is None : return 'None' if type ( sub_model ) is list : n_items = len ( sub_model ) type_text = 'Unknown' if not n_items else f ' { cls . _clean_type_string ( str ( type ( sub_model [ 0 ]))) } ' text = f 'list of { n_items } items of type { type_text } ' return text if type ( sub_model ) is str : return sub_model if len ( sub_model ) < clip_string else sub_model [: clip_string ] + '[truncated]' if hasattr ( sub_model , 'type_' ): return cls . _clean_type_string ( str ( sub_model . type_ )) return cls . _clean_type_string ( str ( type ( sub_model ))) @classmethod def describe ( cls , file_path : pathlib . Path , element_path_str : str , trestle_root : pathlib . Path ) -> List [ str ]: \"\"\"Describe the contents of the file. Args: file_path: pathlib.Path Path for model file to describe. element_path_str: Element path of element in model to describe. Can be ''. Returns: The list of lines of text in the description, or an empty list on failure \"\"\" # figure out the model type so we can read it try : model_type , _ = ModelUtils . get_stripped_model_type ( file_path , trestle_root ) model : OscalBaseModel = model_type . oscal_read ( file_path ) except TrestleError as e : logger . warning ( f 'Error loading model { file_path } to describe: { e } ' ) return [] sub_model = model # if an element path was provided, follow the path chain to the desired sub_model if element_path_str : if '*' in element_path_str or ',' in element_path_str : logger . warning ( 'Wildcards and commas are not allowed in the element path for describe.' ) return [] if '.' not in element_path_str : logger . warning ( 'The element path for describe must either be omitted or contain at least 2 parts.' ) return [] element_paths = utils . parse_element_arg ( model , element_path_str ) sub_model_element = Element ( model ) for element_path in element_paths : sub_model = sub_model_element . get_at ( element_path , False ) sub_model_element = Element ( sub_model ) # now that we have the desired sub_model we can describe it text_out : List [ str ] = [] # create top level text depending on whether an element path was used element_text = '' if not element_path_str else f ' at element path { element_path_str } ' if type ( sub_model ) is list : text = f 'Model file { file_path }{ element_text } is a { cls . _description_text ( sub_model ) } ' text_out . append ( text ) logger . info ( text ) else : text = f 'Model file { file_path }{ element_text } is of type ' text += f ' { cls . _clean_type_string ( str ( type ( sub_model ))) } and contains:' text_out . append ( text ) logger . info ( text ) for key in sub_model . __fields__ . keys (): value = getattr ( sub_model , key , None ) text = f ' { key } : { cls . _description_text ( value ) } ' text_out . append ( text ) logger . info ( text ) return text_out","title":"DescribeCmd"},{"location":"api_reference/trestle.core.commands.describe/#trestle.core.commands.describe.DescribeCmd.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.describe/#trestle.core.commands.describe.DescribeCmd-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.describe/#trestle.core.commands.describe.DescribeCmd.describe","text":"Describe the contents of the file. Parameters: Name Type Description Default file_path Path pathlib.Path Path for model file to describe. required element_path_str str Element path of element in model to describe. Can be ''. required Returns: Type Description List[str] The list of lines of text in the description, or an empty list on failure Source code in trestle/core/commands/describe.py @classmethod def describe ( cls , file_path : pathlib . Path , element_path_str : str , trestle_root : pathlib . Path ) -> List [ str ]: \"\"\"Describe the contents of the file. Args: file_path: pathlib.Path Path for model file to describe. element_path_str: Element path of element in model to describe. Can be ''. Returns: The list of lines of text in the description, or an empty list on failure \"\"\" # figure out the model type so we can read it try : model_type , _ = ModelUtils . get_stripped_model_type ( file_path , trestle_root ) model : OscalBaseModel = model_type . oscal_read ( file_path ) except TrestleError as e : logger . warning ( f 'Error loading model { file_path } to describe: { e } ' ) return [] sub_model = model # if an element path was provided, follow the path chain to the desired sub_model if element_path_str : if '*' in element_path_str or ',' in element_path_str : logger . warning ( 'Wildcards and commas are not allowed in the element path for describe.' ) return [] if '.' not in element_path_str : logger . warning ( 'The element path for describe must either be omitted or contain at least 2 parts.' ) return [] element_paths = utils . parse_element_arg ( model , element_path_str ) sub_model_element = Element ( model ) for element_path in element_paths : sub_model = sub_model_element . get_at ( element_path , False ) sub_model_element = Element ( sub_model ) # now that we have the desired sub_model we can describe it text_out : List [ str ] = [] # create top level text depending on whether an element path was used element_text = '' if not element_path_str else f ' at element path { element_path_str } ' if type ( sub_model ) is list : text = f 'Model file { file_path }{ element_text } is a { cls . _description_text ( sub_model ) } ' text_out . append ( text ) logger . info ( text ) else : text = f 'Model file { file_path }{ element_text } is of type ' text += f ' { cls . _clean_type_string ( str ( type ( sub_model ))) } and contains:' text_out . append ( text ) logger . info ( text ) for key in sub_model . __fields__ . keys (): value = getattr ( sub_model , key , None ) text = f ' { key } : { cls . _description_text ( value ) } ' text_out . append ( text ) logger . info ( text ) return text_out handler: python","title":"describe()"},{"location":"api_reference/trestle.core.commands.href/","text":"trestle.core.commands.href \u00a4 Trestle Href Command. logger \u00a4 Classes \u00a4 HrefCmd ( CommandPlusDocs ) \u00a4 Change href of import in profile to point to catalog in trestle project. This command is needed when generating an SSP with a profile that imports a catalog from a temporary location different from the final intended location of the catalog. Omit the href argument to see the list of current imports in the profile. Source code in trestle/core/commands/href.py class HrefCmd ( CommandPlusDocs ): \"\"\"Change href of import in profile to point to catalog in trestle project. This command is needed when generating an SSP with a profile that imports a catalog from a temporary location different from the final intended location of the catalog. Omit the href argument to see the list of current imports in the profile. \"\"\" name = 'href' def _init_arguments ( self ) -> None : logger . debug ( 'Init arguments' ) self . add_argument ( '-n' , '--name' , help = 'Name of trestle profile to modify (just its name).' , type = str , required = True ) self . add_argument ( '-hr' , '--href' , help = 'New href of form trestle://catalogs/mycat/catalog.json.' , type = str , required = False , default = '' ) self . add_argument ( '-i' , '--item' , help = 'Item number of href to modify. Get list by running href with just -n <prof_name> to list values.' , type = int , required = False , default = 0 ) def _run ( self , args : argparse . Namespace ) -> int : try : logger . debug ( 'Entering trestle href.' ) log . set_log_level_from_args ( args ) profile_name : str = args . name new_href : str = args . href . strip ( \"'\" ) item_num = args . item return self . change_import_href ( args . trestle_root , profile_name , new_href , item_num ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , f 'Error while changing href or import in profile: { e } ' ) @classmethod def change_import_href ( cls , trestle_root : pathlib . Path , profile_name : str , new_href : str , import_num : int ) -> int : \"\"\"Change the href of the import in the profile to point to a catalog in a specific location. A Profile has an Imports list containing at least one href of a catalog or profile to be imported. If the item being referenced is currently in the same trestle project as the main profile, the original href is likely different from the one needed to access the item from the profile. Therefore, in order for trestle to find the item directly from the profile, the href must be modified in a way that trestle can load it. If the item is already at the link referred to by the href as a valid URI or absolute file path then no change is needed. But if the item is being worked on in the same trestle directory as the profile, the href should be modified to something like trestle://catalogs/my_catalog/catalog.json This change only needs to be made once to the profile while the profile is being used to generate SSP's from the local item, but if the final profile is released the href would need to be changed to the intended final location of the referenced item. Args: trestle_root: trestle_root for this call profile_name: Name of profile already imported into trestle containing href's to be changed new_href: New value for the href of the import. If blank just list the hrefs import_num: Item number of the href to change. Returns: 0 on success, 1 on failure Assumptions and requirements: The profile must be a valid profile in the trestle project. The import must either be a valid uri, including local file, or trestle:// The original href is not checked and will be overwritten. If href is the empty string, just list all hrefs. Future work: Allow multiple imports with matching hrefs. Allow href to point to profile in trestle rather than catalog, and by name. Allow full chaining of linked catalogs and profiles. \"\"\" profile_data , profile_path = ModelUtils . load_top_level_model ( trestle_root , profile_name , Profile ) n_imports = len ( profile_data . imports ) if not new_href : logger . info ( f 'List of imports for profile { profile_name } :' ) for ii , import_ in enumerate ( profile_data . imports ): logger . info ( f ' { ii : 2 } : { import_ . href } ' ) return CmdReturnCodes . SUCCESS . value if n_imports <= import_num : raise TrestleError ( f 'Import number { import_num } is too large. This profile has only { n_imports } imports.' ) logger . info ( f 'Changing import { import_num } in profile { profile_name } from, to:' ) logger . info ( f ' { profile_data . imports [ import_num ] . href } ' ) logger . info ( f ' { new_href } ' ) profile_data . imports [ import_num ] . href = new_href profile_data . oscal_write ( profile_path ) return CmdReturnCodes . SUCCESS . value name \u00a4 Methods \u00a4 change_import_href ( trestle_root , profile_name , new_href , import_num ) classmethod \u00a4 Change the href of the import in the profile to point to a catalog in a specific location. A Profile has an Imports list containing at least one href of a catalog or profile to be imported. If the item being referenced is currently in the same trestle project as the main profile, the original href is likely different from the one needed to access the item from the profile. Therefore, in order for trestle to find the item directly from the profile, the href must be modified in a way that trestle can load it. If the item is already at the link referred to by the href as a valid URI or absolute file path then no change is needed. But if the item is being worked on in the same trestle directory as the profile, the href should be modified to something like trestle://catalogs/my_catalog/catalog.json This change only needs to be made once to the profile while the profile is being used to generate SSP's from the local item, but if the final profile is released the href would need to be changed to the intended final location of the referenced item. Parameters: Name Type Description Default trestle_root Path trestle_root for this call required profile_name str Name of profile already imported into trestle containing href's to be changed required new_href str New value for the href of the import. If blank just list the hrefs required import_num int Item number of the href to change. required Returns: Type Description int 0 on success, 1 on failure Assumptions and requirements: The profile must be a valid profile in the trestle project. The import must either be a valid uri, including local file, or trestle:// The original href is not checked and will be overwritten. If href is the empty string, just list all hrefs. Future work: Allow multiple imports with matching hrefs. Allow href to point to profile in trestle rather than catalog, and by name. Allow full chaining of linked catalogs and profiles. Source code in trestle/core/commands/href.py @classmethod def change_import_href ( cls , trestle_root : pathlib . Path , profile_name : str , new_href : str , import_num : int ) -> int : \"\"\"Change the href of the import in the profile to point to a catalog in a specific location. A Profile has an Imports list containing at least one href of a catalog or profile to be imported. If the item being referenced is currently in the same trestle project as the main profile, the original href is likely different from the one needed to access the item from the profile. Therefore, in order for trestle to find the item directly from the profile, the href must be modified in a way that trestle can load it. If the item is already at the link referred to by the href as a valid URI or absolute file path then no change is needed. But if the item is being worked on in the same trestle directory as the profile, the href should be modified to something like trestle://catalogs/my_catalog/catalog.json This change only needs to be made once to the profile while the profile is being used to generate SSP's from the local item, but if the final profile is released the href would need to be changed to the intended final location of the referenced item. Args: trestle_root: trestle_root for this call profile_name: Name of profile already imported into trestle containing href's to be changed new_href: New value for the href of the import. If blank just list the hrefs import_num: Item number of the href to change. Returns: 0 on success, 1 on failure Assumptions and requirements: The profile must be a valid profile in the trestle project. The import must either be a valid uri, including local file, or trestle:// The original href is not checked and will be overwritten. If href is the empty string, just list all hrefs. Future work: Allow multiple imports with matching hrefs. Allow href to point to profile in trestle rather than catalog, and by name. Allow full chaining of linked catalogs and profiles. \"\"\" profile_data , profile_path = ModelUtils . load_top_level_model ( trestle_root , profile_name , Profile ) n_imports = len ( profile_data . imports ) if not new_href : logger . info ( f 'List of imports for profile { profile_name } :' ) for ii , import_ in enumerate ( profile_data . imports ): logger . info ( f ' { ii : 2 } : { import_ . href } ' ) return CmdReturnCodes . SUCCESS . value if n_imports <= import_num : raise TrestleError ( f 'Import number { import_num } is too large. This profile has only { n_imports } imports.' ) logger . info ( f 'Changing import { import_num } in profile { profile_name } from, to:' ) logger . info ( f ' { profile_data . imports [ import_num ] . href } ' ) logger . info ( f ' { new_href } ' ) profile_data . imports [ import_num ] . href = new_href profile_data . oscal_write ( profile_path ) return CmdReturnCodes . SUCCESS . value handler: python","title":"href"},{"location":"api_reference/trestle.core.commands.href/#trestle.core.commands.href","text":"Trestle Href Command.","title":"href"},{"location":"api_reference/trestle.core.commands.href/#trestle.core.commands.href.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.href/#trestle.core.commands.href-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.href/#trestle.core.commands.href.HrefCmd","text":"Change href of import in profile to point to catalog in trestle project. This command is needed when generating an SSP with a profile that imports a catalog from a temporary location different from the final intended location of the catalog. Omit the href argument to see the list of current imports in the profile. Source code in trestle/core/commands/href.py class HrefCmd ( CommandPlusDocs ): \"\"\"Change href of import in profile to point to catalog in trestle project. This command is needed when generating an SSP with a profile that imports a catalog from a temporary location different from the final intended location of the catalog. Omit the href argument to see the list of current imports in the profile. \"\"\" name = 'href' def _init_arguments ( self ) -> None : logger . debug ( 'Init arguments' ) self . add_argument ( '-n' , '--name' , help = 'Name of trestle profile to modify (just its name).' , type = str , required = True ) self . add_argument ( '-hr' , '--href' , help = 'New href of form trestle://catalogs/mycat/catalog.json.' , type = str , required = False , default = '' ) self . add_argument ( '-i' , '--item' , help = 'Item number of href to modify. Get list by running href with just -n <prof_name> to list values.' , type = int , required = False , default = 0 ) def _run ( self , args : argparse . Namespace ) -> int : try : logger . debug ( 'Entering trestle href.' ) log . set_log_level_from_args ( args ) profile_name : str = args . name new_href : str = args . href . strip ( \"'\" ) item_num = args . item return self . change_import_href ( args . trestle_root , profile_name , new_href , item_num ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , f 'Error while changing href or import in profile: { e } ' ) @classmethod def change_import_href ( cls , trestle_root : pathlib . Path , profile_name : str , new_href : str , import_num : int ) -> int : \"\"\"Change the href of the import in the profile to point to a catalog in a specific location. A Profile has an Imports list containing at least one href of a catalog or profile to be imported. If the item being referenced is currently in the same trestle project as the main profile, the original href is likely different from the one needed to access the item from the profile. Therefore, in order for trestle to find the item directly from the profile, the href must be modified in a way that trestle can load it. If the item is already at the link referred to by the href as a valid URI or absolute file path then no change is needed. But if the item is being worked on in the same trestle directory as the profile, the href should be modified to something like trestle://catalogs/my_catalog/catalog.json This change only needs to be made once to the profile while the profile is being used to generate SSP's from the local item, but if the final profile is released the href would need to be changed to the intended final location of the referenced item. Args: trestle_root: trestle_root for this call profile_name: Name of profile already imported into trestle containing href's to be changed new_href: New value for the href of the import. If blank just list the hrefs import_num: Item number of the href to change. Returns: 0 on success, 1 on failure Assumptions and requirements: The profile must be a valid profile in the trestle project. The import must either be a valid uri, including local file, or trestle:// The original href is not checked and will be overwritten. If href is the empty string, just list all hrefs. Future work: Allow multiple imports with matching hrefs. Allow href to point to profile in trestle rather than catalog, and by name. Allow full chaining of linked catalogs and profiles. \"\"\" profile_data , profile_path = ModelUtils . load_top_level_model ( trestle_root , profile_name , Profile ) n_imports = len ( profile_data . imports ) if not new_href : logger . info ( f 'List of imports for profile { profile_name } :' ) for ii , import_ in enumerate ( profile_data . imports ): logger . info ( f ' { ii : 2 } : { import_ . href } ' ) return CmdReturnCodes . SUCCESS . value if n_imports <= import_num : raise TrestleError ( f 'Import number { import_num } is too large. This profile has only { n_imports } imports.' ) logger . info ( f 'Changing import { import_num } in profile { profile_name } from, to:' ) logger . info ( f ' { profile_data . imports [ import_num ] . href } ' ) logger . info ( f ' { new_href } ' ) profile_data . imports [ import_num ] . href = new_href profile_data . oscal_write ( profile_path ) return CmdReturnCodes . SUCCESS . value","title":"HrefCmd"},{"location":"api_reference/trestle.core.commands.href/#trestle.core.commands.href.HrefCmd.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.href/#trestle.core.commands.href.HrefCmd-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.href/#trestle.core.commands.href.HrefCmd.change_import_href","text":"Change the href of the import in the profile to point to a catalog in a specific location. A Profile has an Imports list containing at least one href of a catalog or profile to be imported. If the item being referenced is currently in the same trestle project as the main profile, the original href is likely different from the one needed to access the item from the profile. Therefore, in order for trestle to find the item directly from the profile, the href must be modified in a way that trestle can load it. If the item is already at the link referred to by the href as a valid URI or absolute file path then no change is needed. But if the item is being worked on in the same trestle directory as the profile, the href should be modified to something like trestle://catalogs/my_catalog/catalog.json This change only needs to be made once to the profile while the profile is being used to generate SSP's from the local item, but if the final profile is released the href would need to be changed to the intended final location of the referenced item. Parameters: Name Type Description Default trestle_root Path trestle_root for this call required profile_name str Name of profile already imported into trestle containing href's to be changed required new_href str New value for the href of the import. If blank just list the hrefs required import_num int Item number of the href to change. required Returns: Type Description int 0 on success, 1 on failure Assumptions and requirements: The profile must be a valid profile in the trestle project. The import must either be a valid uri, including local file, or trestle:// The original href is not checked and will be overwritten. If href is the empty string, just list all hrefs. Future work: Allow multiple imports with matching hrefs. Allow href to point to profile in trestle rather than catalog, and by name. Allow full chaining of linked catalogs and profiles. Source code in trestle/core/commands/href.py @classmethod def change_import_href ( cls , trestle_root : pathlib . Path , profile_name : str , new_href : str , import_num : int ) -> int : \"\"\"Change the href of the import in the profile to point to a catalog in a specific location. A Profile has an Imports list containing at least one href of a catalog or profile to be imported. If the item being referenced is currently in the same trestle project as the main profile, the original href is likely different from the one needed to access the item from the profile. Therefore, in order for trestle to find the item directly from the profile, the href must be modified in a way that trestle can load it. If the item is already at the link referred to by the href as a valid URI or absolute file path then no change is needed. But if the item is being worked on in the same trestle directory as the profile, the href should be modified to something like trestle://catalogs/my_catalog/catalog.json This change only needs to be made once to the profile while the profile is being used to generate SSP's from the local item, but if the final profile is released the href would need to be changed to the intended final location of the referenced item. Args: trestle_root: trestle_root for this call profile_name: Name of profile already imported into trestle containing href's to be changed new_href: New value for the href of the import. If blank just list the hrefs import_num: Item number of the href to change. Returns: 0 on success, 1 on failure Assumptions and requirements: The profile must be a valid profile in the trestle project. The import must either be a valid uri, including local file, or trestle:// The original href is not checked and will be overwritten. If href is the empty string, just list all hrefs. Future work: Allow multiple imports with matching hrefs. Allow href to point to profile in trestle rather than catalog, and by name. Allow full chaining of linked catalogs and profiles. \"\"\" profile_data , profile_path = ModelUtils . load_top_level_model ( trestle_root , profile_name , Profile ) n_imports = len ( profile_data . imports ) if not new_href : logger . info ( f 'List of imports for profile { profile_name } :' ) for ii , import_ in enumerate ( profile_data . imports ): logger . info ( f ' { ii : 2 } : { import_ . href } ' ) return CmdReturnCodes . SUCCESS . value if n_imports <= import_num : raise TrestleError ( f 'Import number { import_num } is too large. This profile has only { n_imports } imports.' ) logger . info ( f 'Changing import { import_num } in profile { profile_name } from, to:' ) logger . info ( f ' { profile_data . imports [ import_num ] . href } ' ) logger . info ( f ' { new_href } ' ) profile_data . imports [ import_num ] . href = new_href profile_data . oscal_write ( profile_path ) return CmdReturnCodes . SUCCESS . value handler: python","title":"change_import_href()"},{"location":"api_reference/trestle.core.commands.import_/","text":"trestle.core.commands.import_ \u00a4 Trestle Import Command. logger \u00a4 Classes \u00a4 ImportCmd ( CommandPlusDocs ) \u00a4 Import an existing full OSCAL model into the trestle project. Source code in trestle/core/commands/import_.py class ImportCmd ( CommandPlusDocs ): \"\"\"Import an existing full OSCAL model into the trestle project.\"\"\" name = 'import' def _init_arguments ( self ) -> None : logger . debug ( 'Init arguments' ) self . add_argument ( '-f' , '--file' , help = 'OSCAL file to import - either file path or url.' , type = str , required = True ) self . add_argument ( '-o' , '--output' , help = 'Name of output element.' , type = str , required = True ) self . add_argument ( '-r' , '--regenerate' , action = 'store_true' , help = const . HELP_REGENERATE ) def _run ( self , args : argparse . Namespace ) -> int : \"\"\"Top level import run command.\"\"\" try : log . set_log_level_from_args ( args ) trestle_root = args . trestle_root if not file_utils . is_valid_project_root ( trestle_root ): raise TrestleRootError ( f 'Attempt to import from non-valid trestle project root { trestle_root } ' ) input_uri = args . file if cache . FetcherFactory . in_trestle_directory ( trestle_root , input_uri ): raise TrestleError ( f 'Imported file { input_uri } cannot be from current trestle project. Use duplicate instead.' ) content_type = FileContentType . to_content_type ( '.' + input_uri . split ( '.' )[ - 1 ]) fetcher = cache . FetcherFactory . get_fetcher ( trestle_root , str ( input_uri )) model_read , parent_alias = fetcher . get_oscal ( True ) plural_path = ModelUtils . model_type_to_model_dir ( parent_alias ) output_name = args . output desired_model_dir = trestle_root / plural_path desired_model_path : pathlib . Path = desired_model_dir / output_name / parent_alias desired_model_path = desired_model_path . with_suffix ( FileContentType . to_file_extension ( content_type ) ) . resolve () if desired_model_path . exists (): raise TrestleError ( f 'Cannot import because file to be imported here: { desired_model_path } already exists.' ) if args . regenerate : logger . debug ( f 'regenerating uuids in imported file { input_uri } ' ) model_read , lut , nchanged = ModelUtils . regenerate_uuids ( model_read ) logger . debug ( f 'uuid lut has { len ( lut . items ()) } entries and { nchanged } refs were updated' ) top_element = Element ( model_read ) create_action = CreatePathAction ( desired_model_path , True ) write_action = WriteFileAction ( desired_model_path , top_element , content_type ) # create a plan to create the directory and write the imported file. import_plan = Plan () import_plan . add_action ( create_action ) import_plan . add_action ( write_action ) import_plan . execute () args = argparse . Namespace ( file = desired_model_path , verbose = args . verbose , trestle_root = args . trestle_root , type = None , all = None ) rollback = False try : rc = validatecmd . ValidateCmd () . _run ( args ) if rc > 0 : logger . warning ( f 'Validation of imported file { desired_model_path } did not pass' ) rollback = True except TrestleError as err : logger . warning ( f 'Import of { str ( input_uri ) } failed with validation error: { err } ' ) rollback = True if rollback : logger . debug ( f 'Rolling back import of { str ( input_uri ) } to { desired_model_path } ' ) try : import_plan . rollback () except TrestleError as err : raise TrestleError ( f 'Import failed in plan rollback: { err } . Manually remove { desired_model_path } to recover.' ) logger . debug ( f 'Successful rollback of import to { desired_model_path } ' ) return CmdReturnCodes . COMMAND_ERROR . value return CmdReturnCodes . SUCCESS . value except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while importing OSCAL file' ) name \u00a4 handler: python","title":"import_"},{"location":"api_reference/trestle.core.commands.import_/#trestle.core.commands.import_","text":"Trestle Import Command.","title":"import_"},{"location":"api_reference/trestle.core.commands.import_/#trestle.core.commands.import_.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.import_/#trestle.core.commands.import_-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.import_/#trestle.core.commands.import_.ImportCmd","text":"Import an existing full OSCAL model into the trestle project. Source code in trestle/core/commands/import_.py class ImportCmd ( CommandPlusDocs ): \"\"\"Import an existing full OSCAL model into the trestle project.\"\"\" name = 'import' def _init_arguments ( self ) -> None : logger . debug ( 'Init arguments' ) self . add_argument ( '-f' , '--file' , help = 'OSCAL file to import - either file path or url.' , type = str , required = True ) self . add_argument ( '-o' , '--output' , help = 'Name of output element.' , type = str , required = True ) self . add_argument ( '-r' , '--regenerate' , action = 'store_true' , help = const . HELP_REGENERATE ) def _run ( self , args : argparse . Namespace ) -> int : \"\"\"Top level import run command.\"\"\" try : log . set_log_level_from_args ( args ) trestle_root = args . trestle_root if not file_utils . is_valid_project_root ( trestle_root ): raise TrestleRootError ( f 'Attempt to import from non-valid trestle project root { trestle_root } ' ) input_uri = args . file if cache . FetcherFactory . in_trestle_directory ( trestle_root , input_uri ): raise TrestleError ( f 'Imported file { input_uri } cannot be from current trestle project. Use duplicate instead.' ) content_type = FileContentType . to_content_type ( '.' + input_uri . split ( '.' )[ - 1 ]) fetcher = cache . FetcherFactory . get_fetcher ( trestle_root , str ( input_uri )) model_read , parent_alias = fetcher . get_oscal ( True ) plural_path = ModelUtils . model_type_to_model_dir ( parent_alias ) output_name = args . output desired_model_dir = trestle_root / plural_path desired_model_path : pathlib . Path = desired_model_dir / output_name / parent_alias desired_model_path = desired_model_path . with_suffix ( FileContentType . to_file_extension ( content_type ) ) . resolve () if desired_model_path . exists (): raise TrestleError ( f 'Cannot import because file to be imported here: { desired_model_path } already exists.' ) if args . regenerate : logger . debug ( f 'regenerating uuids in imported file { input_uri } ' ) model_read , lut , nchanged = ModelUtils . regenerate_uuids ( model_read ) logger . debug ( f 'uuid lut has { len ( lut . items ()) } entries and { nchanged } refs were updated' ) top_element = Element ( model_read ) create_action = CreatePathAction ( desired_model_path , True ) write_action = WriteFileAction ( desired_model_path , top_element , content_type ) # create a plan to create the directory and write the imported file. import_plan = Plan () import_plan . add_action ( create_action ) import_plan . add_action ( write_action ) import_plan . execute () args = argparse . Namespace ( file = desired_model_path , verbose = args . verbose , trestle_root = args . trestle_root , type = None , all = None ) rollback = False try : rc = validatecmd . ValidateCmd () . _run ( args ) if rc > 0 : logger . warning ( f 'Validation of imported file { desired_model_path } did not pass' ) rollback = True except TrestleError as err : logger . warning ( f 'Import of { str ( input_uri ) } failed with validation error: { err } ' ) rollback = True if rollback : logger . debug ( f 'Rolling back import of { str ( input_uri ) } to { desired_model_path } ' ) try : import_plan . rollback () except TrestleError as err : raise TrestleError ( f 'Import failed in plan rollback: { err } . Manually remove { desired_model_path } to recover.' ) logger . debug ( f 'Successful rollback of import to { desired_model_path } ' ) return CmdReturnCodes . COMMAND_ERROR . value return CmdReturnCodes . SUCCESS . value except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while importing OSCAL file' )","title":"ImportCmd"},{"location":"api_reference/trestle.core.commands.import_/#trestle.core.commands.import_.ImportCmd.name","text":"handler: python","title":"name"},{"location":"api_reference/trestle.core.commands.init/","text":"trestle.core.commands.init \u00a4 Trestle Init Command. logger \u00a4 Classes \u00a4 InitCmd ( CommandBase ) \u00a4 Initialize a trestle working directory. Source code in trestle/core/commands/init.py class InitCmd ( CommandBase ): \"\"\"Initialize a trestle working directory.\"\"\" name = 'init' def _run ( self , args : argparse . Namespace ) -> int : \"\"\"Create a trestle project in the current directory.\"\"\" try : log . set_log_level_from_args ( args ) dir_path : pathlib . Path = args . trestle_root if not dir_path . exists () or not dir_path . is_dir (): raise TrestleRootError ( f 'Initialization failed. Given directory { dir_path } does not exist or is not a directory.' ) # Create directories self . _create_directories ( dir_path ) # Create config file self . _copy_config_file ( dir_path ) logger . info ( f 'Initialized trestle project successfully in { dir_path } ' ) return CmdReturnCodes . SUCCESS . value except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Failed to initialize Trestle working directory.' ) def _create_directories ( self , root : pathlib . Path ) -> None : \"\"\"Create the directory tree if it does not exist.\"\"\" # Prepare directory list to be created try : directory_list = [ root / pathlib . Path ( const . TRESTLE_CONFIG_DIR )] for model_dir in const . MODEL_DIR_LIST : directory_list . append ( root / pathlib . Path ( model_dir )) directory_list . append ( root / pathlib . Path ( const . TRESTLE_DIST_DIR ) / model_dir ) # Create directories for directory in directory_list : directory . mkdir ( parents = True , exist_ok = True ) file_path = pathlib . Path ( directory ) / const . TRESTLE_KEEP_FILE file_utils . make_hidden_file ( file_path ) except OSError as e : raise TrestleError ( f 'Error while creating directories: { e } ' ) except Exception as e : raise TrestleError ( f 'Unexpected error while creating directories: { e } ' ) def _copy_config_file ( self , root : pathlib . Path ) -> None : \"\"\"Copy the initial config.ini file to .trestle directory.\"\"\" try : source_path = pathlib . Path ( resource_filename ( 'trestle.resources' , const . TRESTLE_CONFIG_FILE )) . resolve () destination_path = ( root / pathlib . Path ( const . TRESTLE_CONFIG_DIR ) / const . TRESTLE_CONFIG_FILE ) . resolve () copyfile ( source_path , destination_path ) except ( shutil . SameFileError , OSError ) as e : raise TrestleError ( f 'Error while copying config file: { e } ' ) except Exception as e : raise TrestleError ( f 'Unexpected error while copying config file: { e } ' ) name \u00a4 handler: python","title":"init"},{"location":"api_reference/trestle.core.commands.init/#trestle.core.commands.init","text":"Trestle Init Command.","title":"init"},{"location":"api_reference/trestle.core.commands.init/#trestle.core.commands.init.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.init/#trestle.core.commands.init-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.init/#trestle.core.commands.init.InitCmd","text":"Initialize a trestle working directory. Source code in trestle/core/commands/init.py class InitCmd ( CommandBase ): \"\"\"Initialize a trestle working directory.\"\"\" name = 'init' def _run ( self , args : argparse . Namespace ) -> int : \"\"\"Create a trestle project in the current directory.\"\"\" try : log . set_log_level_from_args ( args ) dir_path : pathlib . Path = args . trestle_root if not dir_path . exists () or not dir_path . is_dir (): raise TrestleRootError ( f 'Initialization failed. Given directory { dir_path } does not exist or is not a directory.' ) # Create directories self . _create_directories ( dir_path ) # Create config file self . _copy_config_file ( dir_path ) logger . info ( f 'Initialized trestle project successfully in { dir_path } ' ) return CmdReturnCodes . SUCCESS . value except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Failed to initialize Trestle working directory.' ) def _create_directories ( self , root : pathlib . Path ) -> None : \"\"\"Create the directory tree if it does not exist.\"\"\" # Prepare directory list to be created try : directory_list = [ root / pathlib . Path ( const . TRESTLE_CONFIG_DIR )] for model_dir in const . MODEL_DIR_LIST : directory_list . append ( root / pathlib . Path ( model_dir )) directory_list . append ( root / pathlib . Path ( const . TRESTLE_DIST_DIR ) / model_dir ) # Create directories for directory in directory_list : directory . mkdir ( parents = True , exist_ok = True ) file_path = pathlib . Path ( directory ) / const . TRESTLE_KEEP_FILE file_utils . make_hidden_file ( file_path ) except OSError as e : raise TrestleError ( f 'Error while creating directories: { e } ' ) except Exception as e : raise TrestleError ( f 'Unexpected error while creating directories: { e } ' ) def _copy_config_file ( self , root : pathlib . Path ) -> None : \"\"\"Copy the initial config.ini file to .trestle directory.\"\"\" try : source_path = pathlib . Path ( resource_filename ( 'trestle.resources' , const . TRESTLE_CONFIG_FILE )) . resolve () destination_path = ( root / pathlib . Path ( const . TRESTLE_CONFIG_DIR ) / const . TRESTLE_CONFIG_FILE ) . resolve () copyfile ( source_path , destination_path ) except ( shutil . SameFileError , OSError ) as e : raise TrestleError ( f 'Error while copying config file: { e } ' ) except Exception as e : raise TrestleError ( f 'Unexpected error while copying config file: { e } ' )","title":"InitCmd"},{"location":"api_reference/trestle.core.commands.init/#trestle.core.commands.init.InitCmd.name","text":"handler: python","title":"name"},{"location":"api_reference/trestle.core.commands.merge/","text":"trestle.core.commands.merge \u00a4 Trestle Merge Command. logger \u00a4 trace \u00a4 Classes \u00a4 MergeCmd ( CommandPlusDocs ) \u00a4 Merge subcomponents on a trestle model. Source code in trestle/core/commands/merge.py class MergeCmd ( CommandPlusDocs ): \"\"\"Merge subcomponents on a trestle model.\"\"\" name = 'merge' def _init_arguments ( self ) -> None : self . add_argument ( f '- { const . ARG_ELEMENT_SHORT } ' , f '-- { const . ARG_ELEMENT } ' , help = f ' { const . ARG_DESC_ELEMENT } (s) to be merged. The last element is merged into the second last element.' , required = True ) def _run ( self , args : argparse . Namespace ) -> int : \"\"\"Merge elements into the parent oscal model.\"\"\" try : log . set_log_level_from_args ( args ) # remove any quotes passed in as on windows platforms elements_clean = args . element . strip ( \"'\" ) element_paths = elements_clean . split ( ',' ) trace . log ( f 'merge _run element paths { element_paths } ' ) cwd = Path . cwd () rc = self . perform_all_merges ( element_paths , cwd , args . trestle_root ) return rc except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while merging subcomponents on a trestle model' ) @classmethod def perform_all_merges ( cls , element_paths : List [ str ], effective_cwd : Path , trestle_root : Path ) -> int : \"\"\"Run all merges over a list of element paths.\"\"\" for element_path in element_paths : logger . debug ( f 'merge { element_path } ' ) plan = cls . merge ( effective_cwd , ElementPath ( element_path ), trestle_root ) plan . execute () return CmdReturnCodes . SUCCESS . value @classmethod def merge ( cls , effective_cwd : Path , element_path : ElementPath , trestle_root : Path ) -> Plan : \"\"\"Merge operations. It returns a plan for the operation \"\"\" if not element_path . is_multipart (): raise TrestleError ( 'Multiple parts of an element path must be passed to merge e.g. catalog.* or catalog.groups' ) target_model_alias = element_path . get_last () logger . debug ( f 'merge element path list: { element_path } target model alias { target_model_alias } ' ) # 1. Load desination model into a stripped model # Load destination model destination_path = element_path . get_preceding_path () destination_model_alias = destination_path . get_last () trace . log ( f 'merge destination model alias: { destination_model_alias } ' ) trace . log ( 'merge getting contextual file type effective working directory' ) # Destination model filetype file_type = file_utils . get_contextual_file_type ( effective_cwd ) trace . log ( f 'contextual file type is { file_type } ' ) file_ext = FileContentType . to_file_extension ( file_type ) # Destination model filename destination_model_path = ( effective_cwd / f ' { classname_to_alias ( destination_model_alias , AliasMode . JSON ) }{ file_ext } ' ) trace . log ( f 'destination model filename is { destination_model_path } ' ) destination_model_type , _ = ModelUtils . get_stripped_model_type ( destination_model_path , trestle_root ) destination_model_object : OscalBaseModel = None if destination_model_path . exists (): trace . log ( 'dest filename exists so read it' ) destination_model_object = destination_model_type . oscal_read ( destination_model_path ) # 2. If target is wildcard, load distributed destination model and replace destination model. # Handle WILDCARD '*' match. Return plan to load the destination model, with its distributed attributes if target_model_alias == '*' : trace . log ( 'handle target model alias wildcard' ) collection_type = None if destination_model_type . is_collection_container (): collection_type = destination_model_type . get_collection_type () merged_model_type , _ , merged_model_instance = ModelUtils . load_distributed ( destination_model_path , trestle_root , collection_type ) plan = Plan () reset_destination_action = CreatePathAction ( destination_model_path , clear_content = True ) wrapper_alias = destination_model_alias write_destination_action = WriteFileAction ( destination_model_path , Element ( merged_model_instance , wrapper_alias ), content_type = file_type ) remove_path_folder = effective_cwd / destination_model_alias delete_target_action = RemovePathAction ( remove_path_folder ) plan : Plan = Plan () plan . add_action ( reset_destination_action ) plan . add_action ( write_destination_action ) plan . add_action ( delete_target_action ) return plan trace . log ( f 'get dest model with fields stripped: { target_model_alias } ' ) # Get destination model without the target field stripped merged_model_type , _ = ModelUtils . get_stripped_model_type ( destination_model_path , trestle_root , aliases_not_to_be_stripped = [ target_model_alias ]) # 3. Load Target model. Target model could be stripped try : target_model_type = element_path . get_type ( merged_model_type ) except Exception as e : logger . debug ( f 'target model not found, element path list { element_path } type { merged_model_type } ' ) raise TrestleError ( f 'Target model not found. Possibly merge of the elements not allowed at this point. { str ( e ) } ' ) target_model_path = effective_cwd / destination_model_alias trace . log ( f 'look for target model path { target_model_path } at dest alias { destination_model_alias } rel to cwd' ) # target_model filename - depends whether destination model is decomposed or not if target_model_path . exists (): trace . log ( f 'target model path does exist so target path is subdir with target alias { target_model_alias } ' ) target_model_path = target_model_path / target_model_alias else : trace . log ( f 'target model filename does not exist so target path is target alias { target_model_alias } ' ) target_model_path = target_model_path / target_model_alias # FIXME this is same as above trace . log ( f 'final target model path is { target_model_path } ' ) # if target model is a file then handle file. If file doesn't exist, handle the directory, # but in this case it's a list or a dict collection type target_model_filename = target_model_path . with_suffix ( file_ext ) if target_model_filename . exists (): trace . log ( f 'target model path with extension does exist so load distrib { target_model_filename } ' ) _ , _ , target_model_object = ModelUtils . load_distributed ( target_model_filename , trestle_root ) else : target_model_filename = Path ( target_model_path ) trace . log ( f 'target model path plus extension does not exist so load distrib { target_model_filename } ' ) trace . log ( f 'get collection type for model type { target_model_type } ' ) collection_type = type_utils . get_origin ( target_model_type ) trace . log ( f 'load { target_model_filename } as collection type { collection_type } ' ) _ , _ , target_model_object = ModelUtils . load_distributed ( target_model_filename , trestle_root , collection_type ) if hasattr ( target_model_object , '__dict__' ) and '__root__' in target_model_object . __dict__ : trace . log ( 'loaded object has dict and root so set target model object to root contents' ) target_model_object = target_model_object . __dict__ [ '__root__' ] # 4. Insert target model into destination model. merged_dict = {} if destination_model_object is not None : merged_dict = destination_model_object . __dict__ merged_dict [ target_model_alias ] = target_model_object merged_model_object = merged_model_type ( ** merged_dict ) # type: ignore merged_destination_element = Element ( merged_model_object ) # 5. Create action plan trace . log ( f 'create path action clear content: { destination_model_path } ' ) reset_destination_action = CreatePathAction ( destination_model_path , clear_content = True ) trace . log ( f 'write file action { destination_model_path } ' ) write_destination_action = WriteFileAction ( destination_model_path , merged_destination_element , content_type = file_type ) # FIXME this will delete metadata.json but it will leave metadata/roles/roles.* # need to clean up all lower dirs trace . log ( f 'remove path action { target_model_filename } ' ) delete_target_action = RemovePathAction ( target_model_filename ) plan : Plan = Plan () plan . add_action ( reset_destination_action ) plan . add_action ( write_destination_action ) plan . add_action ( delete_target_action ) # TODO: Destination model directory is empty or already merged? Then clean up. return plan name \u00a4 Methods \u00a4 merge ( effective_cwd , element_path , trestle_root ) classmethod \u00a4 Merge operations. It returns a plan for the operation Source code in trestle/core/commands/merge.py @classmethod def merge ( cls , effective_cwd : Path , element_path : ElementPath , trestle_root : Path ) -> Plan : \"\"\"Merge operations. It returns a plan for the operation \"\"\" if not element_path . is_multipart (): raise TrestleError ( 'Multiple parts of an element path must be passed to merge e.g. catalog.* or catalog.groups' ) target_model_alias = element_path . get_last () logger . debug ( f 'merge element path list: { element_path } target model alias { target_model_alias } ' ) # 1. Load desination model into a stripped model # Load destination model destination_path = element_path . get_preceding_path () destination_model_alias = destination_path . get_last () trace . log ( f 'merge destination model alias: { destination_model_alias } ' ) trace . log ( 'merge getting contextual file type effective working directory' ) # Destination model filetype file_type = file_utils . get_contextual_file_type ( effective_cwd ) trace . log ( f 'contextual file type is { file_type } ' ) file_ext = FileContentType . to_file_extension ( file_type ) # Destination model filename destination_model_path = ( effective_cwd / f ' { classname_to_alias ( destination_model_alias , AliasMode . JSON ) }{ file_ext } ' ) trace . log ( f 'destination model filename is { destination_model_path } ' ) destination_model_type , _ = ModelUtils . get_stripped_model_type ( destination_model_path , trestle_root ) destination_model_object : OscalBaseModel = None if destination_model_path . exists (): trace . log ( 'dest filename exists so read it' ) destination_model_object = destination_model_type . oscal_read ( destination_model_path ) # 2. If target is wildcard, load distributed destination model and replace destination model. # Handle WILDCARD '*' match. Return plan to load the destination model, with its distributed attributes if target_model_alias == '*' : trace . log ( 'handle target model alias wildcard' ) collection_type = None if destination_model_type . is_collection_container (): collection_type = destination_model_type . get_collection_type () merged_model_type , _ , merged_model_instance = ModelUtils . load_distributed ( destination_model_path , trestle_root , collection_type ) plan = Plan () reset_destination_action = CreatePathAction ( destination_model_path , clear_content = True ) wrapper_alias = destination_model_alias write_destination_action = WriteFileAction ( destination_model_path , Element ( merged_model_instance , wrapper_alias ), content_type = file_type ) remove_path_folder = effective_cwd / destination_model_alias delete_target_action = RemovePathAction ( remove_path_folder ) plan : Plan = Plan () plan . add_action ( reset_destination_action ) plan . add_action ( write_destination_action ) plan . add_action ( delete_target_action ) return plan trace . log ( f 'get dest model with fields stripped: { target_model_alias } ' ) # Get destination model without the target field stripped merged_model_type , _ = ModelUtils . get_stripped_model_type ( destination_model_path , trestle_root , aliases_not_to_be_stripped = [ target_model_alias ]) # 3. Load Target model. Target model could be stripped try : target_model_type = element_path . get_type ( merged_model_type ) except Exception as e : logger . debug ( f 'target model not found, element path list { element_path } type { merged_model_type } ' ) raise TrestleError ( f 'Target model not found. Possibly merge of the elements not allowed at this point. { str ( e ) } ' ) target_model_path = effective_cwd / destination_model_alias trace . log ( f 'look for target model path { target_model_path } at dest alias { destination_model_alias } rel to cwd' ) # target_model filename - depends whether destination model is decomposed or not if target_model_path . exists (): trace . log ( f 'target model path does exist so target path is subdir with target alias { target_model_alias } ' ) target_model_path = target_model_path / target_model_alias else : trace . log ( f 'target model filename does not exist so target path is target alias { target_model_alias } ' ) target_model_path = target_model_path / target_model_alias # FIXME this is same as above trace . log ( f 'final target model path is { target_model_path } ' ) # if target model is a file then handle file. If file doesn't exist, handle the directory, # but in this case it's a list or a dict collection type target_model_filename = target_model_path . with_suffix ( file_ext ) if target_model_filename . exists (): trace . log ( f 'target model path with extension does exist so load distrib { target_model_filename } ' ) _ , _ , target_model_object = ModelUtils . load_distributed ( target_model_filename , trestle_root ) else : target_model_filename = Path ( target_model_path ) trace . log ( f 'target model path plus extension does not exist so load distrib { target_model_filename } ' ) trace . log ( f 'get collection type for model type { target_model_type } ' ) collection_type = type_utils . get_origin ( target_model_type ) trace . log ( f 'load { target_model_filename } as collection type { collection_type } ' ) _ , _ , target_model_object = ModelUtils . load_distributed ( target_model_filename , trestle_root , collection_type ) if hasattr ( target_model_object , '__dict__' ) and '__root__' in target_model_object . __dict__ : trace . log ( 'loaded object has dict and root so set target model object to root contents' ) target_model_object = target_model_object . __dict__ [ '__root__' ] # 4. Insert target model into destination model. merged_dict = {} if destination_model_object is not None : merged_dict = destination_model_object . __dict__ merged_dict [ target_model_alias ] = target_model_object merged_model_object = merged_model_type ( ** merged_dict ) # type: ignore merged_destination_element = Element ( merged_model_object ) # 5. Create action plan trace . log ( f 'create path action clear content: { destination_model_path } ' ) reset_destination_action = CreatePathAction ( destination_model_path , clear_content = True ) trace . log ( f 'write file action { destination_model_path } ' ) write_destination_action = WriteFileAction ( destination_model_path , merged_destination_element , content_type = file_type ) # FIXME this will delete metadata.json but it will leave metadata/roles/roles.* # need to clean up all lower dirs trace . log ( f 'remove path action { target_model_filename } ' ) delete_target_action = RemovePathAction ( target_model_filename ) plan : Plan = Plan () plan . add_action ( reset_destination_action ) plan . add_action ( write_destination_action ) plan . add_action ( delete_target_action ) # TODO: Destination model directory is empty or already merged? Then clean up. return plan perform_all_merges ( element_paths , effective_cwd , trestle_root ) classmethod \u00a4 Run all merges over a list of element paths. Source code in trestle/core/commands/merge.py @classmethod def perform_all_merges ( cls , element_paths : List [ str ], effective_cwd : Path , trestle_root : Path ) -> int : \"\"\"Run all merges over a list of element paths.\"\"\" for element_path in element_paths : logger . debug ( f 'merge { element_path } ' ) plan = cls . merge ( effective_cwd , ElementPath ( element_path ), trestle_root ) plan . execute () return CmdReturnCodes . SUCCESS . value handler: python","title":"merge"},{"location":"api_reference/trestle.core.commands.merge/#trestle.core.commands.merge","text":"Trestle Merge Command.","title":"merge"},{"location":"api_reference/trestle.core.commands.merge/#trestle.core.commands.merge.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.merge/#trestle.core.commands.merge.trace","text":"","title":"trace"},{"location":"api_reference/trestle.core.commands.merge/#trestle.core.commands.merge-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.merge/#trestle.core.commands.merge.MergeCmd","text":"Merge subcomponents on a trestle model. Source code in trestle/core/commands/merge.py class MergeCmd ( CommandPlusDocs ): \"\"\"Merge subcomponents on a trestle model.\"\"\" name = 'merge' def _init_arguments ( self ) -> None : self . add_argument ( f '- { const . ARG_ELEMENT_SHORT } ' , f '-- { const . ARG_ELEMENT } ' , help = f ' { const . ARG_DESC_ELEMENT } (s) to be merged. The last element is merged into the second last element.' , required = True ) def _run ( self , args : argparse . Namespace ) -> int : \"\"\"Merge elements into the parent oscal model.\"\"\" try : log . set_log_level_from_args ( args ) # remove any quotes passed in as on windows platforms elements_clean = args . element . strip ( \"'\" ) element_paths = elements_clean . split ( ',' ) trace . log ( f 'merge _run element paths { element_paths } ' ) cwd = Path . cwd () rc = self . perform_all_merges ( element_paths , cwd , args . trestle_root ) return rc except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while merging subcomponents on a trestle model' ) @classmethod def perform_all_merges ( cls , element_paths : List [ str ], effective_cwd : Path , trestle_root : Path ) -> int : \"\"\"Run all merges over a list of element paths.\"\"\" for element_path in element_paths : logger . debug ( f 'merge { element_path } ' ) plan = cls . merge ( effective_cwd , ElementPath ( element_path ), trestle_root ) plan . execute () return CmdReturnCodes . SUCCESS . value @classmethod def merge ( cls , effective_cwd : Path , element_path : ElementPath , trestle_root : Path ) -> Plan : \"\"\"Merge operations. It returns a plan for the operation \"\"\" if not element_path . is_multipart (): raise TrestleError ( 'Multiple parts of an element path must be passed to merge e.g. catalog.* or catalog.groups' ) target_model_alias = element_path . get_last () logger . debug ( f 'merge element path list: { element_path } target model alias { target_model_alias } ' ) # 1. Load desination model into a stripped model # Load destination model destination_path = element_path . get_preceding_path () destination_model_alias = destination_path . get_last () trace . log ( f 'merge destination model alias: { destination_model_alias } ' ) trace . log ( 'merge getting contextual file type effective working directory' ) # Destination model filetype file_type = file_utils . get_contextual_file_type ( effective_cwd ) trace . log ( f 'contextual file type is { file_type } ' ) file_ext = FileContentType . to_file_extension ( file_type ) # Destination model filename destination_model_path = ( effective_cwd / f ' { classname_to_alias ( destination_model_alias , AliasMode . JSON ) }{ file_ext } ' ) trace . log ( f 'destination model filename is { destination_model_path } ' ) destination_model_type , _ = ModelUtils . get_stripped_model_type ( destination_model_path , trestle_root ) destination_model_object : OscalBaseModel = None if destination_model_path . exists (): trace . log ( 'dest filename exists so read it' ) destination_model_object = destination_model_type . oscal_read ( destination_model_path ) # 2. If target is wildcard, load distributed destination model and replace destination model. # Handle WILDCARD '*' match. Return plan to load the destination model, with its distributed attributes if target_model_alias == '*' : trace . log ( 'handle target model alias wildcard' ) collection_type = None if destination_model_type . is_collection_container (): collection_type = destination_model_type . get_collection_type () merged_model_type , _ , merged_model_instance = ModelUtils . load_distributed ( destination_model_path , trestle_root , collection_type ) plan = Plan () reset_destination_action = CreatePathAction ( destination_model_path , clear_content = True ) wrapper_alias = destination_model_alias write_destination_action = WriteFileAction ( destination_model_path , Element ( merged_model_instance , wrapper_alias ), content_type = file_type ) remove_path_folder = effective_cwd / destination_model_alias delete_target_action = RemovePathAction ( remove_path_folder ) plan : Plan = Plan () plan . add_action ( reset_destination_action ) plan . add_action ( write_destination_action ) plan . add_action ( delete_target_action ) return plan trace . log ( f 'get dest model with fields stripped: { target_model_alias } ' ) # Get destination model without the target field stripped merged_model_type , _ = ModelUtils . get_stripped_model_type ( destination_model_path , trestle_root , aliases_not_to_be_stripped = [ target_model_alias ]) # 3. Load Target model. Target model could be stripped try : target_model_type = element_path . get_type ( merged_model_type ) except Exception as e : logger . debug ( f 'target model not found, element path list { element_path } type { merged_model_type } ' ) raise TrestleError ( f 'Target model not found. Possibly merge of the elements not allowed at this point. { str ( e ) } ' ) target_model_path = effective_cwd / destination_model_alias trace . log ( f 'look for target model path { target_model_path } at dest alias { destination_model_alias } rel to cwd' ) # target_model filename - depends whether destination model is decomposed or not if target_model_path . exists (): trace . log ( f 'target model path does exist so target path is subdir with target alias { target_model_alias } ' ) target_model_path = target_model_path / target_model_alias else : trace . log ( f 'target model filename does not exist so target path is target alias { target_model_alias } ' ) target_model_path = target_model_path / target_model_alias # FIXME this is same as above trace . log ( f 'final target model path is { target_model_path } ' ) # if target model is a file then handle file. If file doesn't exist, handle the directory, # but in this case it's a list or a dict collection type target_model_filename = target_model_path . with_suffix ( file_ext ) if target_model_filename . exists (): trace . log ( f 'target model path with extension does exist so load distrib { target_model_filename } ' ) _ , _ , target_model_object = ModelUtils . load_distributed ( target_model_filename , trestle_root ) else : target_model_filename = Path ( target_model_path ) trace . log ( f 'target model path plus extension does not exist so load distrib { target_model_filename } ' ) trace . log ( f 'get collection type for model type { target_model_type } ' ) collection_type = type_utils . get_origin ( target_model_type ) trace . log ( f 'load { target_model_filename } as collection type { collection_type } ' ) _ , _ , target_model_object = ModelUtils . load_distributed ( target_model_filename , trestle_root , collection_type ) if hasattr ( target_model_object , '__dict__' ) and '__root__' in target_model_object . __dict__ : trace . log ( 'loaded object has dict and root so set target model object to root contents' ) target_model_object = target_model_object . __dict__ [ '__root__' ] # 4. Insert target model into destination model. merged_dict = {} if destination_model_object is not None : merged_dict = destination_model_object . __dict__ merged_dict [ target_model_alias ] = target_model_object merged_model_object = merged_model_type ( ** merged_dict ) # type: ignore merged_destination_element = Element ( merged_model_object ) # 5. Create action plan trace . log ( f 'create path action clear content: { destination_model_path } ' ) reset_destination_action = CreatePathAction ( destination_model_path , clear_content = True ) trace . log ( f 'write file action { destination_model_path } ' ) write_destination_action = WriteFileAction ( destination_model_path , merged_destination_element , content_type = file_type ) # FIXME this will delete metadata.json but it will leave metadata/roles/roles.* # need to clean up all lower dirs trace . log ( f 'remove path action { target_model_filename } ' ) delete_target_action = RemovePathAction ( target_model_filename ) plan : Plan = Plan () plan . add_action ( reset_destination_action ) plan . add_action ( write_destination_action ) plan . add_action ( delete_target_action ) # TODO: Destination model directory is empty or already merged? Then clean up. return plan","title":"MergeCmd"},{"location":"api_reference/trestle.core.commands.merge/#trestle.core.commands.merge.MergeCmd.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.merge/#trestle.core.commands.merge.MergeCmd-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.merge/#trestle.core.commands.merge.MergeCmd.merge","text":"Merge operations. It returns a plan for the operation Source code in trestle/core/commands/merge.py @classmethod def merge ( cls , effective_cwd : Path , element_path : ElementPath , trestle_root : Path ) -> Plan : \"\"\"Merge operations. It returns a plan for the operation \"\"\" if not element_path . is_multipart (): raise TrestleError ( 'Multiple parts of an element path must be passed to merge e.g. catalog.* or catalog.groups' ) target_model_alias = element_path . get_last () logger . debug ( f 'merge element path list: { element_path } target model alias { target_model_alias } ' ) # 1. Load desination model into a stripped model # Load destination model destination_path = element_path . get_preceding_path () destination_model_alias = destination_path . get_last () trace . log ( f 'merge destination model alias: { destination_model_alias } ' ) trace . log ( 'merge getting contextual file type effective working directory' ) # Destination model filetype file_type = file_utils . get_contextual_file_type ( effective_cwd ) trace . log ( f 'contextual file type is { file_type } ' ) file_ext = FileContentType . to_file_extension ( file_type ) # Destination model filename destination_model_path = ( effective_cwd / f ' { classname_to_alias ( destination_model_alias , AliasMode . JSON ) }{ file_ext } ' ) trace . log ( f 'destination model filename is { destination_model_path } ' ) destination_model_type , _ = ModelUtils . get_stripped_model_type ( destination_model_path , trestle_root ) destination_model_object : OscalBaseModel = None if destination_model_path . exists (): trace . log ( 'dest filename exists so read it' ) destination_model_object = destination_model_type . oscal_read ( destination_model_path ) # 2. If target is wildcard, load distributed destination model and replace destination model. # Handle WILDCARD '*' match. Return plan to load the destination model, with its distributed attributes if target_model_alias == '*' : trace . log ( 'handle target model alias wildcard' ) collection_type = None if destination_model_type . is_collection_container (): collection_type = destination_model_type . get_collection_type () merged_model_type , _ , merged_model_instance = ModelUtils . load_distributed ( destination_model_path , trestle_root , collection_type ) plan = Plan () reset_destination_action = CreatePathAction ( destination_model_path , clear_content = True ) wrapper_alias = destination_model_alias write_destination_action = WriteFileAction ( destination_model_path , Element ( merged_model_instance , wrapper_alias ), content_type = file_type ) remove_path_folder = effective_cwd / destination_model_alias delete_target_action = RemovePathAction ( remove_path_folder ) plan : Plan = Plan () plan . add_action ( reset_destination_action ) plan . add_action ( write_destination_action ) plan . add_action ( delete_target_action ) return plan trace . log ( f 'get dest model with fields stripped: { target_model_alias } ' ) # Get destination model without the target field stripped merged_model_type , _ = ModelUtils . get_stripped_model_type ( destination_model_path , trestle_root , aliases_not_to_be_stripped = [ target_model_alias ]) # 3. Load Target model. Target model could be stripped try : target_model_type = element_path . get_type ( merged_model_type ) except Exception as e : logger . debug ( f 'target model not found, element path list { element_path } type { merged_model_type } ' ) raise TrestleError ( f 'Target model not found. Possibly merge of the elements not allowed at this point. { str ( e ) } ' ) target_model_path = effective_cwd / destination_model_alias trace . log ( f 'look for target model path { target_model_path } at dest alias { destination_model_alias } rel to cwd' ) # target_model filename - depends whether destination model is decomposed or not if target_model_path . exists (): trace . log ( f 'target model path does exist so target path is subdir with target alias { target_model_alias } ' ) target_model_path = target_model_path / target_model_alias else : trace . log ( f 'target model filename does not exist so target path is target alias { target_model_alias } ' ) target_model_path = target_model_path / target_model_alias # FIXME this is same as above trace . log ( f 'final target model path is { target_model_path } ' ) # if target model is a file then handle file. If file doesn't exist, handle the directory, # but in this case it's a list or a dict collection type target_model_filename = target_model_path . with_suffix ( file_ext ) if target_model_filename . exists (): trace . log ( f 'target model path with extension does exist so load distrib { target_model_filename } ' ) _ , _ , target_model_object = ModelUtils . load_distributed ( target_model_filename , trestle_root ) else : target_model_filename = Path ( target_model_path ) trace . log ( f 'target model path plus extension does not exist so load distrib { target_model_filename } ' ) trace . log ( f 'get collection type for model type { target_model_type } ' ) collection_type = type_utils . get_origin ( target_model_type ) trace . log ( f 'load { target_model_filename } as collection type { collection_type } ' ) _ , _ , target_model_object = ModelUtils . load_distributed ( target_model_filename , trestle_root , collection_type ) if hasattr ( target_model_object , '__dict__' ) and '__root__' in target_model_object . __dict__ : trace . log ( 'loaded object has dict and root so set target model object to root contents' ) target_model_object = target_model_object . __dict__ [ '__root__' ] # 4. Insert target model into destination model. merged_dict = {} if destination_model_object is not None : merged_dict = destination_model_object . __dict__ merged_dict [ target_model_alias ] = target_model_object merged_model_object = merged_model_type ( ** merged_dict ) # type: ignore merged_destination_element = Element ( merged_model_object ) # 5. Create action plan trace . log ( f 'create path action clear content: { destination_model_path } ' ) reset_destination_action = CreatePathAction ( destination_model_path , clear_content = True ) trace . log ( f 'write file action { destination_model_path } ' ) write_destination_action = WriteFileAction ( destination_model_path , merged_destination_element , content_type = file_type ) # FIXME this will delete metadata.json but it will leave metadata/roles/roles.* # need to clean up all lower dirs trace . log ( f 'remove path action { target_model_filename } ' ) delete_target_action = RemovePathAction ( target_model_filename ) plan : Plan = Plan () plan . add_action ( reset_destination_action ) plan . add_action ( write_destination_action ) plan . add_action ( delete_target_action ) # TODO: Destination model directory is empty or already merged? Then clean up. return plan","title":"merge()"},{"location":"api_reference/trestle.core.commands.merge/#trestle.core.commands.merge.MergeCmd.perform_all_merges","text":"Run all merges over a list of element paths. Source code in trestle/core/commands/merge.py @classmethod def perform_all_merges ( cls , element_paths : List [ str ], effective_cwd : Path , trestle_root : Path ) -> int : \"\"\"Run all merges over a list of element paths.\"\"\" for element_path in element_paths : logger . debug ( f 'merge { element_path } ' ) plan = cls . merge ( effective_cwd , ElementPath ( element_path ), trestle_root ) plan . execute () return CmdReturnCodes . SUCCESS . value handler: python","title":"perform_all_merges()"},{"location":"api_reference/trestle.core.commands.partial_object_validate/","text":"trestle.core.commands.partial_object_validate \u00a4 Trestle schema-validate command. logger \u00a4 Classes \u00a4 PartialObjectValidate ( CommandBase ) \u00a4 Direct validation any oscal object in a file, including list objects. Source code in trestle/core/commands/partial_object_validate.py class PartialObjectValidate ( CommandBase ): \"\"\"Direct validation any oscal object in a file, including list objects.\"\"\" name = 'partial-object-validate' def _init_arguments ( self ) -> None : self . add_argument ( f '- { const . ARG_FILE_SHORT } ' , f '-- { const . ARG_FILE } ' , help = const . ARG_DESC_FILE + ' to validate' , required = True , type = pathlib . Path ) self . add_argument ( f '- { const . ARG_ELEMENT_SHORT } ' , f '-- { const . ARG_ELEMENT } ' , help = const . ARG_DESC_ELEMENT + ' to validate.' , required = True ) self . add_argument ( '-nv' , '--no-validators' , help = 'Only perform the most basic validation of the file' , action = 'store_true' ) def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) file_path : pathlib . Path = args . file . resolve () if not file_path . exists () or not file_path . is_file (): raise TrestleError ( 'File path provided does not exist or is a directory' ) element_str : str = args . element if ',' in element_str : logger . warning ( 'Only a single element path is allowed.' ) return self . partial_object_validate ( file_path , element_str ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while validating OSCAL file' ) @classmethod def partial_object_validate ( cls , file_path : pathlib . Path , element_string : str ) -> int : \"\"\"Run a schema validation on a file inferring file type based on element string.\"\"\" # get model type logger . info ( f 'Validating { file_path } ' ) element_path = elements . ElementPath ( element_string ) # get a wrapped object obm_type = element_path . get_obm_wrapped_type () obm_type . oscal_read ( file_path ) logger . info ( f 'VALID: { file_path } for { element_string } ' ) return CmdReturnCodes . SUCCESS . value name \u00a4 Methods \u00a4 partial_object_validate ( file_path , element_string ) classmethod \u00a4 Run a schema validation on a file inferring file type based on element string. Source code in trestle/core/commands/partial_object_validate.py @classmethod def partial_object_validate ( cls , file_path : pathlib . Path , element_string : str ) -> int : \"\"\"Run a schema validation on a file inferring file type based on element string.\"\"\" # get model type logger . info ( f 'Validating { file_path } ' ) element_path = elements . ElementPath ( element_string ) # get a wrapped object obm_type = element_path . get_obm_wrapped_type () obm_type . oscal_read ( file_path ) logger . info ( f 'VALID: { file_path } for { element_string } ' ) return CmdReturnCodes . SUCCESS . value handler: python","title":"partial_object_validate"},{"location":"api_reference/trestle.core.commands.partial_object_validate/#trestle.core.commands.partial_object_validate","text":"Trestle schema-validate command.","title":"partial_object_validate"},{"location":"api_reference/trestle.core.commands.partial_object_validate/#trestle.core.commands.partial_object_validate.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.partial_object_validate/#trestle.core.commands.partial_object_validate-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.partial_object_validate/#trestle.core.commands.partial_object_validate.PartialObjectValidate","text":"Direct validation any oscal object in a file, including list objects. Source code in trestle/core/commands/partial_object_validate.py class PartialObjectValidate ( CommandBase ): \"\"\"Direct validation any oscal object in a file, including list objects.\"\"\" name = 'partial-object-validate' def _init_arguments ( self ) -> None : self . add_argument ( f '- { const . ARG_FILE_SHORT } ' , f '-- { const . ARG_FILE } ' , help = const . ARG_DESC_FILE + ' to validate' , required = True , type = pathlib . Path ) self . add_argument ( f '- { const . ARG_ELEMENT_SHORT } ' , f '-- { const . ARG_ELEMENT } ' , help = const . ARG_DESC_ELEMENT + ' to validate.' , required = True ) self . add_argument ( '-nv' , '--no-validators' , help = 'Only perform the most basic validation of the file' , action = 'store_true' ) def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) file_path : pathlib . Path = args . file . resolve () if not file_path . exists () or not file_path . is_file (): raise TrestleError ( 'File path provided does not exist or is a directory' ) element_str : str = args . element if ',' in element_str : logger . warning ( 'Only a single element path is allowed.' ) return self . partial_object_validate ( file_path , element_str ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while validating OSCAL file' ) @classmethod def partial_object_validate ( cls , file_path : pathlib . Path , element_string : str ) -> int : \"\"\"Run a schema validation on a file inferring file type based on element string.\"\"\" # get model type logger . info ( f 'Validating { file_path } ' ) element_path = elements . ElementPath ( element_string ) # get a wrapped object obm_type = element_path . get_obm_wrapped_type () obm_type . oscal_read ( file_path ) logger . info ( f 'VALID: { file_path } for { element_string } ' ) return CmdReturnCodes . SUCCESS . value","title":"PartialObjectValidate"},{"location":"api_reference/trestle.core.commands.partial_object_validate/#trestle.core.commands.partial_object_validate.PartialObjectValidate.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.partial_object_validate/#trestle.core.commands.partial_object_validate.PartialObjectValidate-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.partial_object_validate/#trestle.core.commands.partial_object_validate.PartialObjectValidate.partial_object_validate","text":"Run a schema validation on a file inferring file type based on element string. Source code in trestle/core/commands/partial_object_validate.py @classmethod def partial_object_validate ( cls , file_path : pathlib . Path , element_string : str ) -> int : \"\"\"Run a schema validation on a file inferring file type based on element string.\"\"\" # get model type logger . info ( f 'Validating { file_path } ' ) element_path = elements . ElementPath ( element_string ) # get a wrapped object obm_type = element_path . get_obm_wrapped_type () obm_type . oscal_read ( file_path ) logger . info ( f 'VALID: { file_path } for { element_string } ' ) return CmdReturnCodes . SUCCESS . value handler: python","title":"partial_object_validate()"},{"location":"api_reference/trestle.core.commands.remove/","text":"trestle.core.commands.remove \u00a4 Trestle Remove Command. logger \u00a4 Classes \u00a4 RemoveCmd ( CommandPlusDocs ) \u00a4 Remove a subcomponent from an existing model. Source code in trestle/core/commands/remove.py class RemoveCmd ( CommandPlusDocs ): \"\"\"Remove a subcomponent from an existing model.\"\"\" name = 'remove' def _init_arguments ( self ) -> None : self . add_argument ( f '- { const . ARG_FILE_SHORT } ' , f '-- { const . ARG_FILE } ' , help = const . ARG_DESC_FILE + ' to remove component/subcomponent to.' , required = True ) self . add_argument ( f '- { const . ARG_ELEMENT_SHORT } ' , f '-- { const . ARG_ELEMENT } ' , help = const . ARG_DESC_ELEMENT + ' to remove.' , required = True ) def _run ( self , args : argparse . Namespace ) -> int : \"\"\"Remove an OSCAL component/subcomponent to the specified component. This method takes input a filename and a list of comma-seperated element path. Element paths are field aliases. The method first finds the parent model from the file and loads the file into the model. Then the method executes 'remove' for each of the element paths specified. \"\"\" try : log . set_log_level_from_args ( args ) args_dict = args . __dict__ file_path = pathlib . Path ( args_dict [ const . ARG_FILE ]) . resolve () relative_path = file_path . relative_to ( args . trestle_root ) # Get parent model and then load json into parent model parent_model , parent_alias = ModelUtils . get_relative_model_type ( relative_path ) parent_object = parent_model . oscal_read ( file_path ) parent_element = Element ( parent_object , parent_alias ) add_plan = Plan () # Do _remove for each element_path specified in args element_paths : List [ str ] = str ( args_dict [ const . ARG_ELEMENT ]) . split ( ',' ) for elm_path_str in element_paths : element_path = ElementPath ( elm_path_str ) remove_action , parent_element = self . remove ( element_path , parent_element ) add_plan . add_action ( remove_action ) create_action = CreatePathAction ( file_path , True ) write_action = WriteFileAction ( file_path , parent_element , FileContentType . to_content_type ( file_path . suffix )) add_plan . add_action ( remove_action ) add_plan . add_action ( create_action ) add_plan . add_action ( write_action ) add_plan . execute () return CmdReturnCodes . SUCCESS . value except Exception as e : return err . handle_generic_command_exception ( e , logger , 'Error while removing OSCAL component' ) @classmethod def remove ( cls , element_path : ElementPath , parent_element : Element ) -> Tuple [ RemoveAction , Element ]: \"\"\"For the element_path, remove a model from the parent_element of a given parent_model. First we check if there is an existing element at that path If not, we complain. Then we set up an action plan to update the model (specified by file_path) in memory, return the action and return the parent_element. LIMITATIONS: 1. This does not remove elements of a list or dict. Instead, the entire list or dict is removed. 2. This cannot remove arbitrarily named elements that are not specified in the schema. For example, \"responsible-parties\" contains named elements, e.g., \"organisation\". The tool will not remove the \"organisation\" as it is not in the schema, but one can remove its elements, e.g., \"party-uuids\". \"\"\" element_path_list = element_path . get_full_path_parts () if '*' in element_path_list : raise err . TrestleError ( 'trestle remove does not support Wildcard element path.' ) deleting_element = parent_element . get_at ( element_path ) if deleting_element is not None : # The element already exists if type ( deleting_element ) is list : logger . warning ( 'Warning: trestle remove does not support removing elements of a list: ' 'this removes the entire list' ) elif type ( deleting_element ) is dict : logger . warning ( 'Warning: trestle remove does not support removing dict elements: ' 'this removes the entire dict element' ) else : raise err . TrestleError ( f 'Bad element path: { str ( element_path ) } ' ) remove_action = RemoveAction ( parent_element , element_path ) return remove_action , parent_element name \u00a4 Methods \u00a4 remove ( element_path , parent_element ) classmethod \u00a4 For the element_path, remove a model from the parent_element of a given parent_model. First we check if there is an existing element at that path If not, we complain. Then we set up an action plan to update the model (specified by file_path) in memory, return the action and return the parent_element. LIMITATIONS: 1. This does not remove elements of a list or dict. Instead, the entire list or dict is removed. 2. This cannot remove arbitrarily named elements that are not specified in the schema. For example, \"responsible-parties\" contains named elements, e.g., \"organisation\". The tool will not remove the \"organisation\" as it is not in the schema, but one can remove its elements, e.g., \"party-uuids\". Source code in trestle/core/commands/remove.py @classmethod def remove ( cls , element_path : ElementPath , parent_element : Element ) -> Tuple [ RemoveAction , Element ]: \"\"\"For the element_path, remove a model from the parent_element of a given parent_model. First we check if there is an existing element at that path If not, we complain. Then we set up an action plan to update the model (specified by file_path) in memory, return the action and return the parent_element. LIMITATIONS: 1. This does not remove elements of a list or dict. Instead, the entire list or dict is removed. 2. This cannot remove arbitrarily named elements that are not specified in the schema. For example, \"responsible-parties\" contains named elements, e.g., \"organisation\". The tool will not remove the \"organisation\" as it is not in the schema, but one can remove its elements, e.g., \"party-uuids\". \"\"\" element_path_list = element_path . get_full_path_parts () if '*' in element_path_list : raise err . TrestleError ( 'trestle remove does not support Wildcard element path.' ) deleting_element = parent_element . get_at ( element_path ) if deleting_element is not None : # The element already exists if type ( deleting_element ) is list : logger . warning ( 'Warning: trestle remove does not support removing elements of a list: ' 'this removes the entire list' ) elif type ( deleting_element ) is dict : logger . warning ( 'Warning: trestle remove does not support removing dict elements: ' 'this removes the entire dict element' ) else : raise err . TrestleError ( f 'Bad element path: { str ( element_path ) } ' ) remove_action = RemoveAction ( parent_element , element_path ) return remove_action , parent_element handler: python","title":"remove"},{"location":"api_reference/trestle.core.commands.remove/#trestle.core.commands.remove","text":"Trestle Remove Command.","title":"remove"},{"location":"api_reference/trestle.core.commands.remove/#trestle.core.commands.remove.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.remove/#trestle.core.commands.remove-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.remove/#trestle.core.commands.remove.RemoveCmd","text":"Remove a subcomponent from an existing model. Source code in trestle/core/commands/remove.py class RemoveCmd ( CommandPlusDocs ): \"\"\"Remove a subcomponent from an existing model.\"\"\" name = 'remove' def _init_arguments ( self ) -> None : self . add_argument ( f '- { const . ARG_FILE_SHORT } ' , f '-- { const . ARG_FILE } ' , help = const . ARG_DESC_FILE + ' to remove component/subcomponent to.' , required = True ) self . add_argument ( f '- { const . ARG_ELEMENT_SHORT } ' , f '-- { const . ARG_ELEMENT } ' , help = const . ARG_DESC_ELEMENT + ' to remove.' , required = True ) def _run ( self , args : argparse . Namespace ) -> int : \"\"\"Remove an OSCAL component/subcomponent to the specified component. This method takes input a filename and a list of comma-seperated element path. Element paths are field aliases. The method first finds the parent model from the file and loads the file into the model. Then the method executes 'remove' for each of the element paths specified. \"\"\" try : log . set_log_level_from_args ( args ) args_dict = args . __dict__ file_path = pathlib . Path ( args_dict [ const . ARG_FILE ]) . resolve () relative_path = file_path . relative_to ( args . trestle_root ) # Get parent model and then load json into parent model parent_model , parent_alias = ModelUtils . get_relative_model_type ( relative_path ) parent_object = parent_model . oscal_read ( file_path ) parent_element = Element ( parent_object , parent_alias ) add_plan = Plan () # Do _remove for each element_path specified in args element_paths : List [ str ] = str ( args_dict [ const . ARG_ELEMENT ]) . split ( ',' ) for elm_path_str in element_paths : element_path = ElementPath ( elm_path_str ) remove_action , parent_element = self . remove ( element_path , parent_element ) add_plan . add_action ( remove_action ) create_action = CreatePathAction ( file_path , True ) write_action = WriteFileAction ( file_path , parent_element , FileContentType . to_content_type ( file_path . suffix )) add_plan . add_action ( remove_action ) add_plan . add_action ( create_action ) add_plan . add_action ( write_action ) add_plan . execute () return CmdReturnCodes . SUCCESS . value except Exception as e : return err . handle_generic_command_exception ( e , logger , 'Error while removing OSCAL component' ) @classmethod def remove ( cls , element_path : ElementPath , parent_element : Element ) -> Tuple [ RemoveAction , Element ]: \"\"\"For the element_path, remove a model from the parent_element of a given parent_model. First we check if there is an existing element at that path If not, we complain. Then we set up an action plan to update the model (specified by file_path) in memory, return the action and return the parent_element. LIMITATIONS: 1. This does not remove elements of a list or dict. Instead, the entire list or dict is removed. 2. This cannot remove arbitrarily named elements that are not specified in the schema. For example, \"responsible-parties\" contains named elements, e.g., \"organisation\". The tool will not remove the \"organisation\" as it is not in the schema, but one can remove its elements, e.g., \"party-uuids\". \"\"\" element_path_list = element_path . get_full_path_parts () if '*' in element_path_list : raise err . TrestleError ( 'trestle remove does not support Wildcard element path.' ) deleting_element = parent_element . get_at ( element_path ) if deleting_element is not None : # The element already exists if type ( deleting_element ) is list : logger . warning ( 'Warning: trestle remove does not support removing elements of a list: ' 'this removes the entire list' ) elif type ( deleting_element ) is dict : logger . warning ( 'Warning: trestle remove does not support removing dict elements: ' 'this removes the entire dict element' ) else : raise err . TrestleError ( f 'Bad element path: { str ( element_path ) } ' ) remove_action = RemoveAction ( parent_element , element_path ) return remove_action , parent_element","title":"RemoveCmd"},{"location":"api_reference/trestle.core.commands.remove/#trestle.core.commands.remove.RemoveCmd.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.remove/#trestle.core.commands.remove.RemoveCmd-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.remove/#trestle.core.commands.remove.RemoveCmd.remove","text":"For the element_path, remove a model from the parent_element of a given parent_model. First we check if there is an existing element at that path If not, we complain. Then we set up an action plan to update the model (specified by file_path) in memory, return the action and return the parent_element. LIMITATIONS: 1. This does not remove elements of a list or dict. Instead, the entire list or dict is removed. 2. This cannot remove arbitrarily named elements that are not specified in the schema. For example, \"responsible-parties\" contains named elements, e.g., \"organisation\". The tool will not remove the \"organisation\" as it is not in the schema, but one can remove its elements, e.g., \"party-uuids\". Source code in trestle/core/commands/remove.py @classmethod def remove ( cls , element_path : ElementPath , parent_element : Element ) -> Tuple [ RemoveAction , Element ]: \"\"\"For the element_path, remove a model from the parent_element of a given parent_model. First we check if there is an existing element at that path If not, we complain. Then we set up an action plan to update the model (specified by file_path) in memory, return the action and return the parent_element. LIMITATIONS: 1. This does not remove elements of a list or dict. Instead, the entire list or dict is removed. 2. This cannot remove arbitrarily named elements that are not specified in the schema. For example, \"responsible-parties\" contains named elements, e.g., \"organisation\". The tool will not remove the \"organisation\" as it is not in the schema, but one can remove its elements, e.g., \"party-uuids\". \"\"\" element_path_list = element_path . get_full_path_parts () if '*' in element_path_list : raise err . TrestleError ( 'trestle remove does not support Wildcard element path.' ) deleting_element = parent_element . get_at ( element_path ) if deleting_element is not None : # The element already exists if type ( deleting_element ) is list : logger . warning ( 'Warning: trestle remove does not support removing elements of a list: ' 'this removes the entire list' ) elif type ( deleting_element ) is dict : logger . warning ( 'Warning: trestle remove does not support removing dict elements: ' 'this removes the entire dict element' ) else : raise err . TrestleError ( f 'Bad element path: { str ( element_path ) } ' ) remove_action = RemoveAction ( parent_element , element_path ) return remove_action , parent_element handler: python","title":"remove()"},{"location":"api_reference/trestle.core.commands.replicate/","text":"trestle.core.commands.replicate \u00a4 Trestle Replicate Command. logger \u00a4 Classes \u00a4 ReplicateCmd ( CommandPlusDocs ) \u00a4 Replicate a top level model within the trestle directory structure. Source code in trestle/core/commands/replicate.py class ReplicateCmd ( CommandPlusDocs ): \"\"\"Replicate a top level model within the trestle directory structure.\"\"\" name = 'replicate' def _init_arguments ( self ) -> None : logger . debug ( 'Init arguments' ) self . add_argument ( 'model' , help = 'Choose OSCAL model' , choices = const . MODEL_TYPE_LIST ) self . add_argument ( '-n' , '--name' , help = 'Name of model to replicate.' , type = str , required = True ) self . add_argument ( '-o' , '--output' , help = 'Name of replicated model.' , type = str , required = True ) self . add_argument ( '-r' , '--regenerate' , action = 'store_true' , help = const . HELP_REGENERATE ) def _run ( self , args : argparse . Namespace ) -> int : \"\"\"Execute and process the args.\"\"\" try : log . set_log_level_from_args ( args ) return self . replicate_object ( args . model , args ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while replicating model' ) @classmethod def replicate_object ( cls , model_alias : str , args : argparse . Namespace ) -> int : \"\"\" Core replicate routine invoked by subcommands. Args: model_alias: Name of the top level model in the trestle directory. args: CLI arguments Returns: A return code that can be used as standard posix codes. 0 is success. \"\"\" logger . debug ( 'Entering replicate_object.' ) # 1 Bad working directory if not running from current working directory trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. if not trestle_root or not file_utils . is_valid_project_root ( trestle_root ): raise TrestleError ( f 'Given directory: { trestle_root } is not a trestle project.' ) plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) # 2 Check that input file given exists. input_file_stem = trestle_root / plural_path / args . name / model_alias content_type = FileContentType . path_to_content_type ( input_file_stem ) if content_type == FileContentType . UNKNOWN : raise TrestleError ( f 'Input file { args . name } has no json or yaml file at expected location { input_file_stem } .' ) input_file = input_file_stem . with_suffix ( FileContentType . to_file_extension ( content_type )) # 3 Distributed load from file _ , model_alias , model_instance = ModelUtils . load_distributed ( input_file , trestle_root ) rep_model_path = trestle_root / plural_path / args . output / ( model_alias + FileContentType . to_file_extension ( content_type ) ) if rep_model_path . exists (): raise TrestleError ( f 'OSCAL file to be replicated here: { rep_model_path } exists.' ) if args . regenerate : logger . debug ( f 'regenerating uuids for model { input_file } ' ) model_instance , uuid_lut , n_refs_updated = ModelUtils . regenerate_uuids ( model_instance ) logger . debug ( f ' { len ( uuid_lut ) } uuids generated and { n_refs_updated } references updated' ) # 4 Prepare actions and plan top_element = Element ( model_instance ) create_action = CreatePathAction ( rep_model_path , True ) write_action = WriteFileAction ( rep_model_path , top_element , content_type ) # create a plan to create the directory and imported file. replicate_plan = Plan () replicate_plan . add_action ( create_action ) replicate_plan . add_action ( write_action ) replicate_plan . execute () return CmdReturnCodes . SUCCESS . value name \u00a4 Methods \u00a4 replicate_object ( model_alias , args ) classmethod \u00a4 Core replicate routine invoked by subcommands. Parameters: Name Type Description Default model_alias str Name of the top level model in the trestle directory. required args Namespace CLI arguments required Returns: Type Description int A return code that can be used as standard posix codes. 0 is success. Source code in trestle/core/commands/replicate.py @classmethod def replicate_object ( cls , model_alias : str , args : argparse . Namespace ) -> int : \"\"\" Core replicate routine invoked by subcommands. Args: model_alias: Name of the top level model in the trestle directory. args: CLI arguments Returns: A return code that can be used as standard posix codes. 0 is success. \"\"\" logger . debug ( 'Entering replicate_object.' ) # 1 Bad working directory if not running from current working directory trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. if not trestle_root or not file_utils . is_valid_project_root ( trestle_root ): raise TrestleError ( f 'Given directory: { trestle_root } is not a trestle project.' ) plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) # 2 Check that input file given exists. input_file_stem = trestle_root / plural_path / args . name / model_alias content_type = FileContentType . path_to_content_type ( input_file_stem ) if content_type == FileContentType . UNKNOWN : raise TrestleError ( f 'Input file { args . name } has no json or yaml file at expected location { input_file_stem } .' ) input_file = input_file_stem . with_suffix ( FileContentType . to_file_extension ( content_type )) # 3 Distributed load from file _ , model_alias , model_instance = ModelUtils . load_distributed ( input_file , trestle_root ) rep_model_path = trestle_root / plural_path / args . output / ( model_alias + FileContentType . to_file_extension ( content_type ) ) if rep_model_path . exists (): raise TrestleError ( f 'OSCAL file to be replicated here: { rep_model_path } exists.' ) if args . regenerate : logger . debug ( f 'regenerating uuids for model { input_file } ' ) model_instance , uuid_lut , n_refs_updated = ModelUtils . regenerate_uuids ( model_instance ) logger . debug ( f ' { len ( uuid_lut ) } uuids generated and { n_refs_updated } references updated' ) # 4 Prepare actions and plan top_element = Element ( model_instance ) create_action = CreatePathAction ( rep_model_path , True ) write_action = WriteFileAction ( rep_model_path , top_element , content_type ) # create a plan to create the directory and imported file. replicate_plan = Plan () replicate_plan . add_action ( create_action ) replicate_plan . add_action ( write_action ) replicate_plan . execute () return CmdReturnCodes . SUCCESS . value handler: python","title":"replicate"},{"location":"api_reference/trestle.core.commands.replicate/#trestle.core.commands.replicate","text":"Trestle Replicate Command.","title":"replicate"},{"location":"api_reference/trestle.core.commands.replicate/#trestle.core.commands.replicate.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.replicate/#trestle.core.commands.replicate-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.replicate/#trestle.core.commands.replicate.ReplicateCmd","text":"Replicate a top level model within the trestle directory structure. Source code in trestle/core/commands/replicate.py class ReplicateCmd ( CommandPlusDocs ): \"\"\"Replicate a top level model within the trestle directory structure.\"\"\" name = 'replicate' def _init_arguments ( self ) -> None : logger . debug ( 'Init arguments' ) self . add_argument ( 'model' , help = 'Choose OSCAL model' , choices = const . MODEL_TYPE_LIST ) self . add_argument ( '-n' , '--name' , help = 'Name of model to replicate.' , type = str , required = True ) self . add_argument ( '-o' , '--output' , help = 'Name of replicated model.' , type = str , required = True ) self . add_argument ( '-r' , '--regenerate' , action = 'store_true' , help = const . HELP_REGENERATE ) def _run ( self , args : argparse . Namespace ) -> int : \"\"\"Execute and process the args.\"\"\" try : log . set_log_level_from_args ( args ) return self . replicate_object ( args . model , args ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while replicating model' ) @classmethod def replicate_object ( cls , model_alias : str , args : argparse . Namespace ) -> int : \"\"\" Core replicate routine invoked by subcommands. Args: model_alias: Name of the top level model in the trestle directory. args: CLI arguments Returns: A return code that can be used as standard posix codes. 0 is success. \"\"\" logger . debug ( 'Entering replicate_object.' ) # 1 Bad working directory if not running from current working directory trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. if not trestle_root or not file_utils . is_valid_project_root ( trestle_root ): raise TrestleError ( f 'Given directory: { trestle_root } is not a trestle project.' ) plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) # 2 Check that input file given exists. input_file_stem = trestle_root / plural_path / args . name / model_alias content_type = FileContentType . path_to_content_type ( input_file_stem ) if content_type == FileContentType . UNKNOWN : raise TrestleError ( f 'Input file { args . name } has no json or yaml file at expected location { input_file_stem } .' ) input_file = input_file_stem . with_suffix ( FileContentType . to_file_extension ( content_type )) # 3 Distributed load from file _ , model_alias , model_instance = ModelUtils . load_distributed ( input_file , trestle_root ) rep_model_path = trestle_root / plural_path / args . output / ( model_alias + FileContentType . to_file_extension ( content_type ) ) if rep_model_path . exists (): raise TrestleError ( f 'OSCAL file to be replicated here: { rep_model_path } exists.' ) if args . regenerate : logger . debug ( f 'regenerating uuids for model { input_file } ' ) model_instance , uuid_lut , n_refs_updated = ModelUtils . regenerate_uuids ( model_instance ) logger . debug ( f ' { len ( uuid_lut ) } uuids generated and { n_refs_updated } references updated' ) # 4 Prepare actions and plan top_element = Element ( model_instance ) create_action = CreatePathAction ( rep_model_path , True ) write_action = WriteFileAction ( rep_model_path , top_element , content_type ) # create a plan to create the directory and imported file. replicate_plan = Plan () replicate_plan . add_action ( create_action ) replicate_plan . add_action ( write_action ) replicate_plan . execute () return CmdReturnCodes . SUCCESS . value","title":"ReplicateCmd"},{"location":"api_reference/trestle.core.commands.replicate/#trestle.core.commands.replicate.ReplicateCmd.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.replicate/#trestle.core.commands.replicate.ReplicateCmd-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.replicate/#trestle.core.commands.replicate.ReplicateCmd.replicate_object","text":"Core replicate routine invoked by subcommands. Parameters: Name Type Description Default model_alias str Name of the top level model in the trestle directory. required args Namespace CLI arguments required Returns: Type Description int A return code that can be used as standard posix codes. 0 is success. Source code in trestle/core/commands/replicate.py @classmethod def replicate_object ( cls , model_alias : str , args : argparse . Namespace ) -> int : \"\"\" Core replicate routine invoked by subcommands. Args: model_alias: Name of the top level model in the trestle directory. args: CLI arguments Returns: A return code that can be used as standard posix codes. 0 is success. \"\"\" logger . debug ( 'Entering replicate_object.' ) # 1 Bad working directory if not running from current working directory trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. if not trestle_root or not file_utils . is_valid_project_root ( trestle_root ): raise TrestleError ( f 'Given directory: { trestle_root } is not a trestle project.' ) plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) # 2 Check that input file given exists. input_file_stem = trestle_root / plural_path / args . name / model_alias content_type = FileContentType . path_to_content_type ( input_file_stem ) if content_type == FileContentType . UNKNOWN : raise TrestleError ( f 'Input file { args . name } has no json or yaml file at expected location { input_file_stem } .' ) input_file = input_file_stem . with_suffix ( FileContentType . to_file_extension ( content_type )) # 3 Distributed load from file _ , model_alias , model_instance = ModelUtils . load_distributed ( input_file , trestle_root ) rep_model_path = trestle_root / plural_path / args . output / ( model_alias + FileContentType . to_file_extension ( content_type ) ) if rep_model_path . exists (): raise TrestleError ( f 'OSCAL file to be replicated here: { rep_model_path } exists.' ) if args . regenerate : logger . debug ( f 'regenerating uuids for model { input_file } ' ) model_instance , uuid_lut , n_refs_updated = ModelUtils . regenerate_uuids ( model_instance ) logger . debug ( f ' { len ( uuid_lut ) } uuids generated and { n_refs_updated } references updated' ) # 4 Prepare actions and plan top_element = Element ( model_instance ) create_action = CreatePathAction ( rep_model_path , True ) write_action = WriteFileAction ( rep_model_path , top_element , content_type ) # create a plan to create the directory and imported file. replicate_plan = Plan () replicate_plan . add_action ( create_action ) replicate_plan . add_action ( write_action ) replicate_plan . execute () return CmdReturnCodes . SUCCESS . value handler: python","title":"replicate_object()"},{"location":"api_reference/trestle.core.commands.split/","text":"trestle.core.commands.split \u00a4 Trestle Split Command. logger \u00a4 trace \u00a4 Classes \u00a4 AliasTracker ( TrestleBaseModel ) pydantic-model \u00a4 Convenience class to track writing out of models. Source code in trestle/core/commands/split.py class AliasTracker ( TrestleBaseModel ): \"\"\"Convenience class to track writing out of models.\"\"\" # This tracks the parts that need to be split from each element # and makes sure it is written out once aliases : List [ str ] written : bool = False def add_alias ( self , alias : str ) -> None : \"\"\"Add alias.\"\"\" if alias not in self . aliases : self . aliases . append ( alias ) def get_aliases ( self ) -> List [ str ]: \"\"\"Get the list of aliases.\"\"\" return self . aliases def needs_writing ( self ) -> bool : \"\"\"Need to write the model.\"\"\" return not self . written def mark_written ( self ) -> None : \"\"\"Mark this model as written.\"\"\" self . written = True aliases : List [ str ] pydantic-field required \u00a4 written : bool pydantic-field \u00a4 Methods \u00a4 add_alias ( self , alias ) \u00a4 Add alias. Source code in trestle/core/commands/split.py def add_alias ( self , alias : str ) -> None : \"\"\"Add alias.\"\"\" if alias not in self . aliases : self . aliases . append ( alias ) get_aliases ( self ) \u00a4 Get the list of aliases. Source code in trestle/core/commands/split.py def get_aliases ( self ) -> List [ str ]: \"\"\"Get the list of aliases.\"\"\" return self . aliases mark_written ( self ) \u00a4 Mark this model as written. Source code in trestle/core/commands/split.py def mark_written ( self ) -> None : \"\"\"Mark this model as written.\"\"\" self . written = True needs_writing ( self ) \u00a4 Need to write the model. Source code in trestle/core/commands/split.py def needs_writing ( self ) -> bool : \"\"\"Need to write the model.\"\"\" return not self . written SplitCmd ( CommandPlusDocs ) \u00a4 Split subcomponents on a trestle model. Source code in trestle/core/commands/split.py class SplitCmd ( CommandPlusDocs ): \"\"\"Split subcomponents on a trestle model.\"\"\" name = 'split' def _init_arguments ( self ) -> None : self . add_argument ( f '- { const . ARG_FILE_SHORT } ' , f '-- { const . ARG_FILE } ' , help = const . ARG_DESC_FILE + ' to split.' , required = False ) self . add_argument ( f '- { const . ARG_ELEMENT_SHORT } ' , f '-- { const . ARG_ELEMENT } ' , help = const . ARG_DESC_ELEMENT + ' to split.' , required = False ) def _run ( self , args : argparse . Namespace ) -> int : \"\"\"Split an OSCAL file into elements.\"\"\" try : log . set_log_level_from_args ( args ) trace . log ( 'Entering trestle split.' ) # get the Model args_raw : Dict [ str , str ] = args . __dict__ # remove any quotes passed in as on windows platforms elements_clean : str = args_raw [ const . ARG_ELEMENT ] . strip ( \"'\" ) file_name = '' file_name = '' if not args_raw [ const . ARG_FILE ] else args_raw [ const . ARG_FILE ] # cwd must be in the model directory if file to split is not specified effective_cwd = pathlib . Path . cwd () return self . perform_split ( effective_cwd , file_name , elements_clean , args . trestle_root ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while performing a split operation' ) @classmethod def perform_split ( cls , effective_cwd : pathlib . Path , file_name : str , elements : str , trestle_root : pathlib . Path ) -> int : \"\"\"Perform the split operation. Args: effective_cwd: effective directory in which the the split operation is performed file_name: file name of model to split, or '' if deduced from elements and cwd elements: comma separated list of paths to strip from the file, with quotes removed Returns: 0 on success and 1 on failure \"\"\" file_path_list : List [ Tuple [ str , str ]] = [] if file_name : file_path_list . append (( file_name , elements )) else : # cwd must be in the model directory if file to split is not specified # find top directory for this model based on trestle root and cwd model_dir = file_utils . extract_project_model_path ( effective_cwd ) if model_dir is None : raise TrestleError ( 'Current directory must be within a model directory if file is not specified' ) content_type : FileContentType = FileContentType . dir_to_content_type ( model_dir ) # determine the file needed for each split path element_paths = elements . split ( ',' ) for path in element_paths : element_path = ElementPath ( path ) # if element path is relative use directory context to determine absolute path element_path . make_absolute ( model_dir , effective_cwd ) file_path = element_path . find_last_file_in_path ( content_type , model_dir ) # now make the element path relative to the model file to be loaded if file_path is None or element_path . make_relative ( file_path . relative_to ( model_dir )) != 0 : raise TrestleError ( f 'Unable to match element path with files in model directory { element_path } ' ) file_path_list . append (( file_path , element_path . to_string ())) # match paths to corresponding files since several paths may be split from the same file file_path_dict : Dict [ str , str ] = {} for file_path in file_path_list : key = file_path [ 0 ] path = file_path [ 1 ] if key not in file_path_dict : file_path_dict [ key ] = path else : current_path = file_path_dict [ key ] file_path_dict [ key ] = f ' { current_path } , { path } ' for raw_file_name , element_path in file_path_dict . items (): file_path = file_utils . relative_resolve ( pathlib . Path ( raw_file_name ), effective_cwd ) # this makes assumptions that the path is relative. if not file_path . exists (): raise TrestleError ( f 'File { file_path } does not exist.' ) content_type = FileContentType . to_content_type ( file_path . suffix ) # find the base directory of the file base_dir = file_path . parent model_type , _ = ModelUtils . get_stripped_model_type ( file_path , trestle_root ) model : OscalBaseModel = model_type . oscal_read ( file_path ) if cmd_utils . split_is_too_fine ( element_path , model ): raise TrestleError ( 'Cannot split the model to the level of uuids, strings, etc.' ) # use the model itself to resolve any wildcards and create list of element paths logger . debug ( f 'split calling parse_element_args on { element_path } ' ) # use contextual mode to parse element_paths : List [ ElementPath ] = cmd_utils . parse_element_args ( model , element_path . split ( ',' ), base_dir . relative_to ( trestle_root ) ) # analyze the split tree and determine which aliases should be stripped from each file aliases_to_strip = cls . find_aliases_to_strip ( element_paths ) # need the file name relative to the base directory file_name_no_path = str ( file_path . name ) split_plan = cls . split_model ( model , element_paths , base_dir , content_type , file_name_no_path , aliases_to_strip ) trash . store ( file_path , True ) try : split_plan . execute () except Exception as e : trash . recover ( file_path , True ) raise TrestleError ( f 'Split has failed with error: { e } .' ) return CmdReturnCodes . SUCCESS . value @classmethod def prepare_sub_model_split_actions ( cls , sub_model_item : OscalBaseModel , sub_model_dir : pathlib . Path , file_prefix : str , content_type : FileContentType ) -> List [ Action ]: \"\"\"Create split actions of sub model.\"\"\" actions : List [ Action ] = [] file_name = cmd_utils . to_model_file_name ( sub_model_item , file_prefix , content_type ) model_type = classname_to_alias ( type ( sub_model_item ) . __name__ , AliasMode . JSON ) sub_model_file = sub_model_dir / file_name actions . append ( CreatePathAction ( sub_model_file )) actions . append ( WriteFileAction ( sub_model_file , Element ( sub_model_item , model_type ), content_type )) return actions @classmethod def split_model_at_path_chain ( cls , model_obj : OscalBaseModel , element_paths : List [ ElementPath ], base_dir : pathlib . Path , content_type : FileContentType , cur_path_index : int , split_plan : Plan , strip_root : bool , root_file_name : str , aliases_to_strip : Dict [ str , AliasTracker ], last_one : bool = True ) -> int : \"\"\"Recursively split the model at the provided chain of element paths. It assumes that a chain of element paths starts at the cur_path_index with the first path ending with a wildcard (*) If the wildcard follows an element that is inherently a list of items, the list of items is extracted. But if the wildcard follows a generic model than members of that model class found in the model will be split off. But only the non-trivial elements are removed, i.e. not str, int, datetime, etc. Args: model_obj: The OscalBaseModel to be split element_paths: The List[ElementPath] of elements to split, including embedded wildcards base_dir: pathlib.Path of the file being split content_type: json or yaml files cur_path_index: Index into the list of element paths for the current split operation split_plan: The accumulated plan of actions needed to perform the split strip_root: Whether to strip elements from the root object root_file_name: Filename of root file that gets split into a list of items aliases_to_strip: AliasTracker previously loaded with aliases that need to be split from each element last_one: bool indicating last item in array has been split and stripped model can now be written Returns: int representing the index where the chain of the path ends. Examples: For example, element paths could have a list of paths as below for a `ComponentDefinition` model where the first path is the start of the chain. For each of the sub model described by the first element path (e.g component-defintion.components.*) in the chain, the subsequent paths (e.g component.control-implementations.*) will be applied recursively to retrieve the sub-sub models: [ 'component-definition.component.*', 'component.control-implementations.*' ] for a command like below: trestle split -f component.yaml -e component-definition.components.*.control-implementations.* \"\"\" if split_plan is None : raise TrestleError ( 'Split plan must have been initialized' ) if cur_path_index < 0 : raise TrestleError ( 'Current index of the chain of paths cannot be less than 0' ) # if there are no more element_paths, return the current plan if cur_path_index >= len ( element_paths ): return cur_path_index # initialize local variables element = Element ( model_obj ) stripped_field_alias : List [ str ] = [] # get the sub_model specified by the element_path of this round element_path = element_paths [ cur_path_index ] # does the next element_path point back at me is_parent = cur_path_index + 1 < len ( element_paths ) and element_paths [ cur_path_index + 1 ] . get_parent () == element_path # root dir name for sub models dir # 00000__group.json will have the root_dir name as 00000__group for sub models of group # catalog.json will have the root_dir name as catalog root_dir = '' if root_file_name != '' : root_dir = str ( pathlib . Path ( root_file_name ) . with_suffix ( '' )) sub_models = element . get_at ( element_path , False ) # we call sub_models as in plural, but it can be just one # assume cur_path_index is the end of the chain # value of this variable may change during recursive split of the sub-models below path_chain_end = cur_path_index # if wildcard is present in the element_path and the next path in the chain has current path as the parent, # Then deal with case of list, or split of arbitrary oscalbasemodel if is_parent and element_path . get_last () is not ElementPath . WILDCARD : # create dir for all sub model items sub_models_dir = base_dir / element_path . to_root_path () sub_model_plan = Plan () path_chain_end = cls . split_model_at_path_chain ( sub_models , element_paths , sub_models_dir , content_type , cur_path_index + 1 , sub_model_plan , True , '' , aliases_to_strip ) sub_model_actions = sub_model_plan . get_actions () split_plan . add_actions ( sub_model_actions ) elif element_path . get_last () == ElementPath . WILDCARD : # extract sub-models into a dict with appropriate prefix sub_model_items : Dict [ str , OscalBaseModel ] = {} sub_models_dir = base_dir / element_path . to_file_path ( root_dir = root_dir ) if isinstance ( sub_models , list ): for i , sub_model_item in enumerate ( sub_models ): # e.g. `groups/00000_groups/` prefix = str ( i ) . zfill ( const . FILE_DIGIT_PREFIX_LENGTH ) sub_model_items [ prefix ] = sub_model_item # process list sub model items count = 0 for key , sub_model_item in sub_model_items . items (): count += 1 # recursively split the sub-model if there are more element paths to traverse # e.g. split component.control-implementations.* require_recursive_split = cur_path_index + 1 < len ( element_paths ) and element_paths [ cur_path_index + 1 ] . get_parent () == element_path if require_recursive_split : # prepare individual directory for each sub-model sub_root_file_name = cmd_utils . to_model_file_name ( sub_model_item , key , content_type ) sub_model_plan = Plan () last_one : bool = count == len ( sub_model_items ) path_chain_end = cls . split_model_at_path_chain ( sub_model_item , element_paths , sub_models_dir , content_type , cur_path_index + 1 , sub_model_plan , True , sub_root_file_name , aliases_to_strip , last_one ) sub_model_actions = sub_model_plan . get_actions () else : sub_model_actions = cls . prepare_sub_model_split_actions ( sub_model_item , sub_models_dir , key , content_type ) split_plan . add_actions ( sub_model_actions ) else : # the chain of path ends at the current index. # so no recursive call. Let's just write the sub model to the file and get out if sub_models is not None : sub_model_file = base_dir / element_path . to_file_path ( content_type , root_dir = root_dir ) split_plan . add_action ( CreatePathAction ( sub_model_file )) split_plan . add_action ( WriteFileAction ( sub_model_file , Element ( sub_models , element_path . get_element_name ()), content_type ) ) # Strip the root model and add a WriteAction for the updated model object in the plan if strip_root : full_path = element_path . get_full () path = '.' . join ( full_path . split ( '.' )[: - 1 ]) aliases = [ element_path . get_element_name ()] need_to_write = True use_alias_dict = aliases_to_strip is not None and path in aliases_to_strip if use_alias_dict : aliases = aliases_to_strip [ path ] . get_aliases () need_to_write = aliases_to_strip [ path ] . needs_writing () stripped_model = model_obj . stripped_instance ( stripped_fields_aliases = aliases ) # can mark it written even if it doesn't need writing since it is empty # but if an array only mark it written if it's the last one if last_one and use_alias_dict : aliases_to_strip [ path ] . mark_written () # If it's an empty model after stripping the fields, don't create path and don't write field_list = [ x for x in model_obj . __fields__ . keys () if model_obj . __fields__ [ x ] is not None ] if set ( field_list ) == set ( stripped_field_alias ): return path_chain_end if need_to_write : if root_file_name != '' : root_file = base_dir / root_file_name else : root_file = base_dir / element_path . to_root_path ( content_type ) split_plan . add_action ( CreatePathAction ( root_file )) wrapper_alias = classname_to_alias ( stripped_model . __class__ . __name__ , AliasMode . JSON ) split_plan . add_action ( WriteFileAction ( root_file , Element ( stripped_model , wrapper_alias ), content_type )) # return the end of the current path chain return path_chain_end @classmethod def split_model ( cls , model_obj : OscalBaseModel , element_paths : List [ ElementPath ], base_dir : pathlib . Path , content_type : FileContentType , root_file_name : str , aliases_to_strip : Dict [ str , AliasTracker ] ) -> Plan : \"\"\"Split the model at the provided element paths. It returns a plan for the operation \"\"\" # initialize plan split_plan = Plan () # loop through the element path list and update the split_plan stripped_field_alias = [] cur_path_index = 0 while cur_path_index < len ( element_paths ): # extract the sub element name for each of the root path of the path chain element_path = element_paths [ cur_path_index ] if element_path . get_parent () is None and len ( element_path . get ()) > 1 : stripped_part = element_path . get ()[ 1 ] if stripped_part == ElementPath . WILDCARD : stripped_field_alias . append ( '__root__' ) else : if stripped_part not in stripped_field_alias : stripped_field_alias . append ( stripped_part ) # split model at the path chain cur_path_index = cls . split_model_at_path_chain ( model_obj , element_paths , base_dir , content_type , cur_path_index , split_plan , False , root_file_name , aliases_to_strip ) cur_path_index += 1 # strip the root model object and add a WriteAction stripped_root = model_obj . stripped_instance ( stripped_fields_aliases = stripped_field_alias ) # If it's an empty model after stripping the fields, don't create path and don't write if set ( model_obj . __fields__ . keys ()) == set ( stripped_field_alias ): return split_plan if root_file_name != '' : root_file = base_dir / root_file_name else : root_file = base_dir / element_paths [ 0 ] . to_root_path ( content_type ) split_plan . add_action ( CreatePathAction ( root_file , True )) wrapper_alias = classname_to_alias ( stripped_root . __class__ . __name__ , AliasMode . JSON ) split_plan . add_action ( WriteFileAction ( root_file , Element ( stripped_root , wrapper_alias ), content_type )) return split_plan @classmethod def find_aliases_to_strip ( cls , element_paths : List [ ElementPath ]) -> Dict [ str , AliasTracker ]: \"\"\"Find list of aliases that need to be stripped as each element written out.\"\"\" # A given path may be present in several split actions # Need to determine all parts stripped at each node in order to strip them all and # write the stripped model only once tracker_map : Dict [ str , AliasTracker ] = {} for element_path in element_paths : path = element_path . get_full () path_parts = path . split ( '.' ) alias = path_parts [ - 1 ] if len ( path_parts ) > 2 and alias != '*' : root_path = '.' . join ( path_parts [: - 1 ]) if root_path in tracker_map : tracker_map [ root_path ] . add_alias ( alias ) else : tracker_map [ root_path ] = AliasTracker ( aliases = [ alias ]) return tracker_map name \u00a4 Methods \u00a4 find_aliases_to_strip ( element_paths ) classmethod \u00a4 Find list of aliases that need to be stripped as each element written out. Source code in trestle/core/commands/split.py @classmethod def find_aliases_to_strip ( cls , element_paths : List [ ElementPath ]) -> Dict [ str , AliasTracker ]: \"\"\"Find list of aliases that need to be stripped as each element written out.\"\"\" # A given path may be present in several split actions # Need to determine all parts stripped at each node in order to strip them all and # write the stripped model only once tracker_map : Dict [ str , AliasTracker ] = {} for element_path in element_paths : path = element_path . get_full () path_parts = path . split ( '.' ) alias = path_parts [ - 1 ] if len ( path_parts ) > 2 and alias != '*' : root_path = '.' . join ( path_parts [: - 1 ]) if root_path in tracker_map : tracker_map [ root_path ] . add_alias ( alias ) else : tracker_map [ root_path ] = AliasTracker ( aliases = [ alias ]) return tracker_map perform_split ( effective_cwd , file_name , elements , trestle_root ) classmethod \u00a4 Perform the split operation. Parameters: Name Type Description Default effective_cwd Path effective directory in which the the split operation is performed required file_name str file name of model to split, or '' if deduced from elements and cwd required elements str comma separated list of paths to strip from the file, with quotes removed required Returns: Type Description int 0 on success and 1 on failure Source code in trestle/core/commands/split.py @classmethod def perform_split ( cls , effective_cwd : pathlib . Path , file_name : str , elements : str , trestle_root : pathlib . Path ) -> int : \"\"\"Perform the split operation. Args: effective_cwd: effective directory in which the the split operation is performed file_name: file name of model to split, or '' if deduced from elements and cwd elements: comma separated list of paths to strip from the file, with quotes removed Returns: 0 on success and 1 on failure \"\"\" file_path_list : List [ Tuple [ str , str ]] = [] if file_name : file_path_list . append (( file_name , elements )) else : # cwd must be in the model directory if file to split is not specified # find top directory for this model based on trestle root and cwd model_dir = file_utils . extract_project_model_path ( effective_cwd ) if model_dir is None : raise TrestleError ( 'Current directory must be within a model directory if file is not specified' ) content_type : FileContentType = FileContentType . dir_to_content_type ( model_dir ) # determine the file needed for each split path element_paths = elements . split ( ',' ) for path in element_paths : element_path = ElementPath ( path ) # if element path is relative use directory context to determine absolute path element_path . make_absolute ( model_dir , effective_cwd ) file_path = element_path . find_last_file_in_path ( content_type , model_dir ) # now make the element path relative to the model file to be loaded if file_path is None or element_path . make_relative ( file_path . relative_to ( model_dir )) != 0 : raise TrestleError ( f 'Unable to match element path with files in model directory { element_path } ' ) file_path_list . append (( file_path , element_path . to_string ())) # match paths to corresponding files since several paths may be split from the same file file_path_dict : Dict [ str , str ] = {} for file_path in file_path_list : key = file_path [ 0 ] path = file_path [ 1 ] if key not in file_path_dict : file_path_dict [ key ] = path else : current_path = file_path_dict [ key ] file_path_dict [ key ] = f ' { current_path } , { path } ' for raw_file_name , element_path in file_path_dict . items (): file_path = file_utils . relative_resolve ( pathlib . Path ( raw_file_name ), effective_cwd ) # this makes assumptions that the path is relative. if not file_path . exists (): raise TrestleError ( f 'File { file_path } does not exist.' ) content_type = FileContentType . to_content_type ( file_path . suffix ) # find the base directory of the file base_dir = file_path . parent model_type , _ = ModelUtils . get_stripped_model_type ( file_path , trestle_root ) model : OscalBaseModel = model_type . oscal_read ( file_path ) if cmd_utils . split_is_too_fine ( element_path , model ): raise TrestleError ( 'Cannot split the model to the level of uuids, strings, etc.' ) # use the model itself to resolve any wildcards and create list of element paths logger . debug ( f 'split calling parse_element_args on { element_path } ' ) # use contextual mode to parse element_paths : List [ ElementPath ] = cmd_utils . parse_element_args ( model , element_path . split ( ',' ), base_dir . relative_to ( trestle_root ) ) # analyze the split tree and determine which aliases should be stripped from each file aliases_to_strip = cls . find_aliases_to_strip ( element_paths ) # need the file name relative to the base directory file_name_no_path = str ( file_path . name ) split_plan = cls . split_model ( model , element_paths , base_dir , content_type , file_name_no_path , aliases_to_strip ) trash . store ( file_path , True ) try : split_plan . execute () except Exception as e : trash . recover ( file_path , True ) raise TrestleError ( f 'Split has failed with error: { e } .' ) return CmdReturnCodes . SUCCESS . value prepare_sub_model_split_actions ( sub_model_item , sub_model_dir , file_prefix , content_type ) classmethod \u00a4 Create split actions of sub model. Source code in trestle/core/commands/split.py @classmethod def prepare_sub_model_split_actions ( cls , sub_model_item : OscalBaseModel , sub_model_dir : pathlib . Path , file_prefix : str , content_type : FileContentType ) -> List [ Action ]: \"\"\"Create split actions of sub model.\"\"\" actions : List [ Action ] = [] file_name = cmd_utils . to_model_file_name ( sub_model_item , file_prefix , content_type ) model_type = classname_to_alias ( type ( sub_model_item ) . __name__ , AliasMode . JSON ) sub_model_file = sub_model_dir / file_name actions . append ( CreatePathAction ( sub_model_file )) actions . append ( WriteFileAction ( sub_model_file , Element ( sub_model_item , model_type ), content_type )) return actions split_model ( model_obj , element_paths , base_dir , content_type , root_file_name , aliases_to_strip ) classmethod \u00a4 Split the model at the provided element paths. It returns a plan for the operation Source code in trestle/core/commands/split.py @classmethod def split_model ( cls , model_obj : OscalBaseModel , element_paths : List [ ElementPath ], base_dir : pathlib . Path , content_type : FileContentType , root_file_name : str , aliases_to_strip : Dict [ str , AliasTracker ] ) -> Plan : \"\"\"Split the model at the provided element paths. It returns a plan for the operation \"\"\" # initialize plan split_plan = Plan () # loop through the element path list and update the split_plan stripped_field_alias = [] cur_path_index = 0 while cur_path_index < len ( element_paths ): # extract the sub element name for each of the root path of the path chain element_path = element_paths [ cur_path_index ] if element_path . get_parent () is None and len ( element_path . get ()) > 1 : stripped_part = element_path . get ()[ 1 ] if stripped_part == ElementPath . WILDCARD : stripped_field_alias . append ( '__root__' ) else : if stripped_part not in stripped_field_alias : stripped_field_alias . append ( stripped_part ) # split model at the path chain cur_path_index = cls . split_model_at_path_chain ( model_obj , element_paths , base_dir , content_type , cur_path_index , split_plan , False , root_file_name , aliases_to_strip ) cur_path_index += 1 # strip the root model object and add a WriteAction stripped_root = model_obj . stripped_instance ( stripped_fields_aliases = stripped_field_alias ) # If it's an empty model after stripping the fields, don't create path and don't write if set ( model_obj . __fields__ . keys ()) == set ( stripped_field_alias ): return split_plan if root_file_name != '' : root_file = base_dir / root_file_name else : root_file = base_dir / element_paths [ 0 ] . to_root_path ( content_type ) split_plan . add_action ( CreatePathAction ( root_file , True )) wrapper_alias = classname_to_alias ( stripped_root . __class__ . __name__ , AliasMode . JSON ) split_plan . add_action ( WriteFileAction ( root_file , Element ( stripped_root , wrapper_alias ), content_type )) return split_plan split_model_at_path_chain ( model_obj , element_paths , base_dir , content_type , cur_path_index , split_plan , strip_root , root_file_name , aliases_to_strip , last_one = True ) classmethod \u00a4 Recursively split the model at the provided chain of element paths. It assumes that a chain of element paths starts at the cur_path_index with the first path ending with a wildcard (*) If the wildcard follows an element that is inherently a list of items, the list of items is extracted. But if the wildcard follows a generic model than members of that model class found in the model will be split off. But only the non-trivial elements are removed, i.e. not str, int, datetime, etc. Parameters: Name Type Description Default model_obj OscalBaseModel The OscalBaseModel to be split required element_paths List[trestle.core.models.elements.ElementPath] The List[ElementPath] of elements to split, including embedded wildcards required base_dir Path pathlib.Path of the file being split required content_type FileContentType json or yaml files required cur_path_index int Index into the list of element paths for the current split operation required split_plan Plan The accumulated plan of actions needed to perform the split required strip_root bool Whether to strip elements from the root object required root_file_name str Filename of root file that gets split into a list of items required aliases_to_strip Dict[str, trestle.core.commands.split.AliasTracker] AliasTracker previously loaded with aliases that need to be split from each element required last_one bool bool indicating last item in array has been split and stripped model can now be written True Returns: Type Description int int representing the index where the chain of the path ends. Examples: For example, element paths could have a list of paths as below for a ComponentDefinition model where the first path is the start of the chain. For each of the sub model described by the first element path (e.g component-defintion.components. ) in the chain, the subsequent paths (e.g component.control-implementations. ) will be applied recursively to retrieve the sub-sub models: [ 'component-definition.component. ', 'component.control-implementations. ' ] for a command like below: trestle split -f component.yaml -e component-definition.components. .control-implementations. Source code in trestle/core/commands/split.py @classmethod def split_model_at_path_chain ( cls , model_obj : OscalBaseModel , element_paths : List [ ElementPath ], base_dir : pathlib . Path , content_type : FileContentType , cur_path_index : int , split_plan : Plan , strip_root : bool , root_file_name : str , aliases_to_strip : Dict [ str , AliasTracker ], last_one : bool = True ) -> int : \"\"\"Recursively split the model at the provided chain of element paths. It assumes that a chain of element paths starts at the cur_path_index with the first path ending with a wildcard (*) If the wildcard follows an element that is inherently a list of items, the list of items is extracted. But if the wildcard follows a generic model than members of that model class found in the model will be split off. But only the non-trivial elements are removed, i.e. not str, int, datetime, etc. Args: model_obj: The OscalBaseModel to be split element_paths: The List[ElementPath] of elements to split, including embedded wildcards base_dir: pathlib.Path of the file being split content_type: json or yaml files cur_path_index: Index into the list of element paths for the current split operation split_plan: The accumulated plan of actions needed to perform the split strip_root: Whether to strip elements from the root object root_file_name: Filename of root file that gets split into a list of items aliases_to_strip: AliasTracker previously loaded with aliases that need to be split from each element last_one: bool indicating last item in array has been split and stripped model can now be written Returns: int representing the index where the chain of the path ends. Examples: For example, element paths could have a list of paths as below for a `ComponentDefinition` model where the first path is the start of the chain. For each of the sub model described by the first element path (e.g component-defintion.components.*) in the chain, the subsequent paths (e.g component.control-implementations.*) will be applied recursively to retrieve the sub-sub models: [ 'component-definition.component.*', 'component.control-implementations.*' ] for a command like below: trestle split -f component.yaml -e component-definition.components.*.control-implementations.* \"\"\" if split_plan is None : raise TrestleError ( 'Split plan must have been initialized' ) if cur_path_index < 0 : raise TrestleError ( 'Current index of the chain of paths cannot be less than 0' ) # if there are no more element_paths, return the current plan if cur_path_index >= len ( element_paths ): return cur_path_index # initialize local variables element = Element ( model_obj ) stripped_field_alias : List [ str ] = [] # get the sub_model specified by the element_path of this round element_path = element_paths [ cur_path_index ] # does the next element_path point back at me is_parent = cur_path_index + 1 < len ( element_paths ) and element_paths [ cur_path_index + 1 ] . get_parent () == element_path # root dir name for sub models dir # 00000__group.json will have the root_dir name as 00000__group for sub models of group # catalog.json will have the root_dir name as catalog root_dir = '' if root_file_name != '' : root_dir = str ( pathlib . Path ( root_file_name ) . with_suffix ( '' )) sub_models = element . get_at ( element_path , False ) # we call sub_models as in plural, but it can be just one # assume cur_path_index is the end of the chain # value of this variable may change during recursive split of the sub-models below path_chain_end = cur_path_index # if wildcard is present in the element_path and the next path in the chain has current path as the parent, # Then deal with case of list, or split of arbitrary oscalbasemodel if is_parent and element_path . get_last () is not ElementPath . WILDCARD : # create dir for all sub model items sub_models_dir = base_dir / element_path . to_root_path () sub_model_plan = Plan () path_chain_end = cls . split_model_at_path_chain ( sub_models , element_paths , sub_models_dir , content_type , cur_path_index + 1 , sub_model_plan , True , '' , aliases_to_strip ) sub_model_actions = sub_model_plan . get_actions () split_plan . add_actions ( sub_model_actions ) elif element_path . get_last () == ElementPath . WILDCARD : # extract sub-models into a dict with appropriate prefix sub_model_items : Dict [ str , OscalBaseModel ] = {} sub_models_dir = base_dir / element_path . to_file_path ( root_dir = root_dir ) if isinstance ( sub_models , list ): for i , sub_model_item in enumerate ( sub_models ): # e.g. `groups/00000_groups/` prefix = str ( i ) . zfill ( const . FILE_DIGIT_PREFIX_LENGTH ) sub_model_items [ prefix ] = sub_model_item # process list sub model items count = 0 for key , sub_model_item in sub_model_items . items (): count += 1 # recursively split the sub-model if there are more element paths to traverse # e.g. split component.control-implementations.* require_recursive_split = cur_path_index + 1 < len ( element_paths ) and element_paths [ cur_path_index + 1 ] . get_parent () == element_path if require_recursive_split : # prepare individual directory for each sub-model sub_root_file_name = cmd_utils . to_model_file_name ( sub_model_item , key , content_type ) sub_model_plan = Plan () last_one : bool = count == len ( sub_model_items ) path_chain_end = cls . split_model_at_path_chain ( sub_model_item , element_paths , sub_models_dir , content_type , cur_path_index + 1 , sub_model_plan , True , sub_root_file_name , aliases_to_strip , last_one ) sub_model_actions = sub_model_plan . get_actions () else : sub_model_actions = cls . prepare_sub_model_split_actions ( sub_model_item , sub_models_dir , key , content_type ) split_plan . add_actions ( sub_model_actions ) else : # the chain of path ends at the current index. # so no recursive call. Let's just write the sub model to the file and get out if sub_models is not None : sub_model_file = base_dir / element_path . to_file_path ( content_type , root_dir = root_dir ) split_plan . add_action ( CreatePathAction ( sub_model_file )) split_plan . add_action ( WriteFileAction ( sub_model_file , Element ( sub_models , element_path . get_element_name ()), content_type ) ) # Strip the root model and add a WriteAction for the updated model object in the plan if strip_root : full_path = element_path . get_full () path = '.' . join ( full_path . split ( '.' )[: - 1 ]) aliases = [ element_path . get_element_name ()] need_to_write = True use_alias_dict = aliases_to_strip is not None and path in aliases_to_strip if use_alias_dict : aliases = aliases_to_strip [ path ] . get_aliases () need_to_write = aliases_to_strip [ path ] . needs_writing () stripped_model = model_obj . stripped_instance ( stripped_fields_aliases = aliases ) # can mark it written even if it doesn't need writing since it is empty # but if an array only mark it written if it's the last one if last_one and use_alias_dict : aliases_to_strip [ path ] . mark_written () # If it's an empty model after stripping the fields, don't create path and don't write field_list = [ x for x in model_obj . __fields__ . keys () if model_obj . __fields__ [ x ] is not None ] if set ( field_list ) == set ( stripped_field_alias ): return path_chain_end if need_to_write : if root_file_name != '' : root_file = base_dir / root_file_name else : root_file = base_dir / element_path . to_root_path ( content_type ) split_plan . add_action ( CreatePathAction ( root_file )) wrapper_alias = classname_to_alias ( stripped_model . __class__ . __name__ , AliasMode . JSON ) split_plan . add_action ( WriteFileAction ( root_file , Element ( stripped_model , wrapper_alias ), content_type )) # return the end of the current path chain return path_chain_end handler: python","title":"split"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split","text":"Trestle Split Command.","title":"split"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.trace","text":"","title":"trace"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.AliasTracker","text":"Convenience class to track writing out of models. Source code in trestle/core/commands/split.py class AliasTracker ( TrestleBaseModel ): \"\"\"Convenience class to track writing out of models.\"\"\" # This tracks the parts that need to be split from each element # and makes sure it is written out once aliases : List [ str ] written : bool = False def add_alias ( self , alias : str ) -> None : \"\"\"Add alias.\"\"\" if alias not in self . aliases : self . aliases . append ( alias ) def get_aliases ( self ) -> List [ str ]: \"\"\"Get the list of aliases.\"\"\" return self . aliases def needs_writing ( self ) -> bool : \"\"\"Need to write the model.\"\"\" return not self . written def mark_written ( self ) -> None : \"\"\"Mark this model as written.\"\"\" self . written = True","title":"AliasTracker"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.AliasTracker.aliases","text":"","title":"aliases"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.AliasTracker.written","text":"","title":"written"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.AliasTracker-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.AliasTracker.add_alias","text":"Add alias. Source code in trestle/core/commands/split.py def add_alias ( self , alias : str ) -> None : \"\"\"Add alias.\"\"\" if alias not in self . aliases : self . aliases . append ( alias )","title":"add_alias()"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.AliasTracker.get_aliases","text":"Get the list of aliases. Source code in trestle/core/commands/split.py def get_aliases ( self ) -> List [ str ]: \"\"\"Get the list of aliases.\"\"\" return self . aliases","title":"get_aliases()"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.AliasTracker.mark_written","text":"Mark this model as written. Source code in trestle/core/commands/split.py def mark_written ( self ) -> None : \"\"\"Mark this model as written.\"\"\" self . written = True","title":"mark_written()"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.AliasTracker.needs_writing","text":"Need to write the model. Source code in trestle/core/commands/split.py def needs_writing ( self ) -> bool : \"\"\"Need to write the model.\"\"\" return not self . written","title":"needs_writing()"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.SplitCmd","text":"Split subcomponents on a trestle model. Source code in trestle/core/commands/split.py class SplitCmd ( CommandPlusDocs ): \"\"\"Split subcomponents on a trestle model.\"\"\" name = 'split' def _init_arguments ( self ) -> None : self . add_argument ( f '- { const . ARG_FILE_SHORT } ' , f '-- { const . ARG_FILE } ' , help = const . ARG_DESC_FILE + ' to split.' , required = False ) self . add_argument ( f '- { const . ARG_ELEMENT_SHORT } ' , f '-- { const . ARG_ELEMENT } ' , help = const . ARG_DESC_ELEMENT + ' to split.' , required = False ) def _run ( self , args : argparse . Namespace ) -> int : \"\"\"Split an OSCAL file into elements.\"\"\" try : log . set_log_level_from_args ( args ) trace . log ( 'Entering trestle split.' ) # get the Model args_raw : Dict [ str , str ] = args . __dict__ # remove any quotes passed in as on windows platforms elements_clean : str = args_raw [ const . ARG_ELEMENT ] . strip ( \"'\" ) file_name = '' file_name = '' if not args_raw [ const . ARG_FILE ] else args_raw [ const . ARG_FILE ] # cwd must be in the model directory if file to split is not specified effective_cwd = pathlib . Path . cwd () return self . perform_split ( effective_cwd , file_name , elements_clean , args . trestle_root ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while performing a split operation' ) @classmethod def perform_split ( cls , effective_cwd : pathlib . Path , file_name : str , elements : str , trestle_root : pathlib . Path ) -> int : \"\"\"Perform the split operation. Args: effective_cwd: effective directory in which the the split operation is performed file_name: file name of model to split, or '' if deduced from elements and cwd elements: comma separated list of paths to strip from the file, with quotes removed Returns: 0 on success and 1 on failure \"\"\" file_path_list : List [ Tuple [ str , str ]] = [] if file_name : file_path_list . append (( file_name , elements )) else : # cwd must be in the model directory if file to split is not specified # find top directory for this model based on trestle root and cwd model_dir = file_utils . extract_project_model_path ( effective_cwd ) if model_dir is None : raise TrestleError ( 'Current directory must be within a model directory if file is not specified' ) content_type : FileContentType = FileContentType . dir_to_content_type ( model_dir ) # determine the file needed for each split path element_paths = elements . split ( ',' ) for path in element_paths : element_path = ElementPath ( path ) # if element path is relative use directory context to determine absolute path element_path . make_absolute ( model_dir , effective_cwd ) file_path = element_path . find_last_file_in_path ( content_type , model_dir ) # now make the element path relative to the model file to be loaded if file_path is None or element_path . make_relative ( file_path . relative_to ( model_dir )) != 0 : raise TrestleError ( f 'Unable to match element path with files in model directory { element_path } ' ) file_path_list . append (( file_path , element_path . to_string ())) # match paths to corresponding files since several paths may be split from the same file file_path_dict : Dict [ str , str ] = {} for file_path in file_path_list : key = file_path [ 0 ] path = file_path [ 1 ] if key not in file_path_dict : file_path_dict [ key ] = path else : current_path = file_path_dict [ key ] file_path_dict [ key ] = f ' { current_path } , { path } ' for raw_file_name , element_path in file_path_dict . items (): file_path = file_utils . relative_resolve ( pathlib . Path ( raw_file_name ), effective_cwd ) # this makes assumptions that the path is relative. if not file_path . exists (): raise TrestleError ( f 'File { file_path } does not exist.' ) content_type = FileContentType . to_content_type ( file_path . suffix ) # find the base directory of the file base_dir = file_path . parent model_type , _ = ModelUtils . get_stripped_model_type ( file_path , trestle_root ) model : OscalBaseModel = model_type . oscal_read ( file_path ) if cmd_utils . split_is_too_fine ( element_path , model ): raise TrestleError ( 'Cannot split the model to the level of uuids, strings, etc.' ) # use the model itself to resolve any wildcards and create list of element paths logger . debug ( f 'split calling parse_element_args on { element_path } ' ) # use contextual mode to parse element_paths : List [ ElementPath ] = cmd_utils . parse_element_args ( model , element_path . split ( ',' ), base_dir . relative_to ( trestle_root ) ) # analyze the split tree and determine which aliases should be stripped from each file aliases_to_strip = cls . find_aliases_to_strip ( element_paths ) # need the file name relative to the base directory file_name_no_path = str ( file_path . name ) split_plan = cls . split_model ( model , element_paths , base_dir , content_type , file_name_no_path , aliases_to_strip ) trash . store ( file_path , True ) try : split_plan . execute () except Exception as e : trash . recover ( file_path , True ) raise TrestleError ( f 'Split has failed with error: { e } .' ) return CmdReturnCodes . SUCCESS . value @classmethod def prepare_sub_model_split_actions ( cls , sub_model_item : OscalBaseModel , sub_model_dir : pathlib . Path , file_prefix : str , content_type : FileContentType ) -> List [ Action ]: \"\"\"Create split actions of sub model.\"\"\" actions : List [ Action ] = [] file_name = cmd_utils . to_model_file_name ( sub_model_item , file_prefix , content_type ) model_type = classname_to_alias ( type ( sub_model_item ) . __name__ , AliasMode . JSON ) sub_model_file = sub_model_dir / file_name actions . append ( CreatePathAction ( sub_model_file )) actions . append ( WriteFileAction ( sub_model_file , Element ( sub_model_item , model_type ), content_type )) return actions @classmethod def split_model_at_path_chain ( cls , model_obj : OscalBaseModel , element_paths : List [ ElementPath ], base_dir : pathlib . Path , content_type : FileContentType , cur_path_index : int , split_plan : Plan , strip_root : bool , root_file_name : str , aliases_to_strip : Dict [ str , AliasTracker ], last_one : bool = True ) -> int : \"\"\"Recursively split the model at the provided chain of element paths. It assumes that a chain of element paths starts at the cur_path_index with the first path ending with a wildcard (*) If the wildcard follows an element that is inherently a list of items, the list of items is extracted. But if the wildcard follows a generic model than members of that model class found in the model will be split off. But only the non-trivial elements are removed, i.e. not str, int, datetime, etc. Args: model_obj: The OscalBaseModel to be split element_paths: The List[ElementPath] of elements to split, including embedded wildcards base_dir: pathlib.Path of the file being split content_type: json or yaml files cur_path_index: Index into the list of element paths for the current split operation split_plan: The accumulated plan of actions needed to perform the split strip_root: Whether to strip elements from the root object root_file_name: Filename of root file that gets split into a list of items aliases_to_strip: AliasTracker previously loaded with aliases that need to be split from each element last_one: bool indicating last item in array has been split and stripped model can now be written Returns: int representing the index where the chain of the path ends. Examples: For example, element paths could have a list of paths as below for a `ComponentDefinition` model where the first path is the start of the chain. For each of the sub model described by the first element path (e.g component-defintion.components.*) in the chain, the subsequent paths (e.g component.control-implementations.*) will be applied recursively to retrieve the sub-sub models: [ 'component-definition.component.*', 'component.control-implementations.*' ] for a command like below: trestle split -f component.yaml -e component-definition.components.*.control-implementations.* \"\"\" if split_plan is None : raise TrestleError ( 'Split plan must have been initialized' ) if cur_path_index < 0 : raise TrestleError ( 'Current index of the chain of paths cannot be less than 0' ) # if there are no more element_paths, return the current plan if cur_path_index >= len ( element_paths ): return cur_path_index # initialize local variables element = Element ( model_obj ) stripped_field_alias : List [ str ] = [] # get the sub_model specified by the element_path of this round element_path = element_paths [ cur_path_index ] # does the next element_path point back at me is_parent = cur_path_index + 1 < len ( element_paths ) and element_paths [ cur_path_index + 1 ] . get_parent () == element_path # root dir name for sub models dir # 00000__group.json will have the root_dir name as 00000__group for sub models of group # catalog.json will have the root_dir name as catalog root_dir = '' if root_file_name != '' : root_dir = str ( pathlib . Path ( root_file_name ) . with_suffix ( '' )) sub_models = element . get_at ( element_path , False ) # we call sub_models as in plural, but it can be just one # assume cur_path_index is the end of the chain # value of this variable may change during recursive split of the sub-models below path_chain_end = cur_path_index # if wildcard is present in the element_path and the next path in the chain has current path as the parent, # Then deal with case of list, or split of arbitrary oscalbasemodel if is_parent and element_path . get_last () is not ElementPath . WILDCARD : # create dir for all sub model items sub_models_dir = base_dir / element_path . to_root_path () sub_model_plan = Plan () path_chain_end = cls . split_model_at_path_chain ( sub_models , element_paths , sub_models_dir , content_type , cur_path_index + 1 , sub_model_plan , True , '' , aliases_to_strip ) sub_model_actions = sub_model_plan . get_actions () split_plan . add_actions ( sub_model_actions ) elif element_path . get_last () == ElementPath . WILDCARD : # extract sub-models into a dict with appropriate prefix sub_model_items : Dict [ str , OscalBaseModel ] = {} sub_models_dir = base_dir / element_path . to_file_path ( root_dir = root_dir ) if isinstance ( sub_models , list ): for i , sub_model_item in enumerate ( sub_models ): # e.g. `groups/00000_groups/` prefix = str ( i ) . zfill ( const . FILE_DIGIT_PREFIX_LENGTH ) sub_model_items [ prefix ] = sub_model_item # process list sub model items count = 0 for key , sub_model_item in sub_model_items . items (): count += 1 # recursively split the sub-model if there are more element paths to traverse # e.g. split component.control-implementations.* require_recursive_split = cur_path_index + 1 < len ( element_paths ) and element_paths [ cur_path_index + 1 ] . get_parent () == element_path if require_recursive_split : # prepare individual directory for each sub-model sub_root_file_name = cmd_utils . to_model_file_name ( sub_model_item , key , content_type ) sub_model_plan = Plan () last_one : bool = count == len ( sub_model_items ) path_chain_end = cls . split_model_at_path_chain ( sub_model_item , element_paths , sub_models_dir , content_type , cur_path_index + 1 , sub_model_plan , True , sub_root_file_name , aliases_to_strip , last_one ) sub_model_actions = sub_model_plan . get_actions () else : sub_model_actions = cls . prepare_sub_model_split_actions ( sub_model_item , sub_models_dir , key , content_type ) split_plan . add_actions ( sub_model_actions ) else : # the chain of path ends at the current index. # so no recursive call. Let's just write the sub model to the file and get out if sub_models is not None : sub_model_file = base_dir / element_path . to_file_path ( content_type , root_dir = root_dir ) split_plan . add_action ( CreatePathAction ( sub_model_file )) split_plan . add_action ( WriteFileAction ( sub_model_file , Element ( sub_models , element_path . get_element_name ()), content_type ) ) # Strip the root model and add a WriteAction for the updated model object in the plan if strip_root : full_path = element_path . get_full () path = '.' . join ( full_path . split ( '.' )[: - 1 ]) aliases = [ element_path . get_element_name ()] need_to_write = True use_alias_dict = aliases_to_strip is not None and path in aliases_to_strip if use_alias_dict : aliases = aliases_to_strip [ path ] . get_aliases () need_to_write = aliases_to_strip [ path ] . needs_writing () stripped_model = model_obj . stripped_instance ( stripped_fields_aliases = aliases ) # can mark it written even if it doesn't need writing since it is empty # but if an array only mark it written if it's the last one if last_one and use_alias_dict : aliases_to_strip [ path ] . mark_written () # If it's an empty model after stripping the fields, don't create path and don't write field_list = [ x for x in model_obj . __fields__ . keys () if model_obj . __fields__ [ x ] is not None ] if set ( field_list ) == set ( stripped_field_alias ): return path_chain_end if need_to_write : if root_file_name != '' : root_file = base_dir / root_file_name else : root_file = base_dir / element_path . to_root_path ( content_type ) split_plan . add_action ( CreatePathAction ( root_file )) wrapper_alias = classname_to_alias ( stripped_model . __class__ . __name__ , AliasMode . JSON ) split_plan . add_action ( WriteFileAction ( root_file , Element ( stripped_model , wrapper_alias ), content_type )) # return the end of the current path chain return path_chain_end @classmethod def split_model ( cls , model_obj : OscalBaseModel , element_paths : List [ ElementPath ], base_dir : pathlib . Path , content_type : FileContentType , root_file_name : str , aliases_to_strip : Dict [ str , AliasTracker ] ) -> Plan : \"\"\"Split the model at the provided element paths. It returns a plan for the operation \"\"\" # initialize plan split_plan = Plan () # loop through the element path list and update the split_plan stripped_field_alias = [] cur_path_index = 0 while cur_path_index < len ( element_paths ): # extract the sub element name for each of the root path of the path chain element_path = element_paths [ cur_path_index ] if element_path . get_parent () is None and len ( element_path . get ()) > 1 : stripped_part = element_path . get ()[ 1 ] if stripped_part == ElementPath . WILDCARD : stripped_field_alias . append ( '__root__' ) else : if stripped_part not in stripped_field_alias : stripped_field_alias . append ( stripped_part ) # split model at the path chain cur_path_index = cls . split_model_at_path_chain ( model_obj , element_paths , base_dir , content_type , cur_path_index , split_plan , False , root_file_name , aliases_to_strip ) cur_path_index += 1 # strip the root model object and add a WriteAction stripped_root = model_obj . stripped_instance ( stripped_fields_aliases = stripped_field_alias ) # If it's an empty model after stripping the fields, don't create path and don't write if set ( model_obj . __fields__ . keys ()) == set ( stripped_field_alias ): return split_plan if root_file_name != '' : root_file = base_dir / root_file_name else : root_file = base_dir / element_paths [ 0 ] . to_root_path ( content_type ) split_plan . add_action ( CreatePathAction ( root_file , True )) wrapper_alias = classname_to_alias ( stripped_root . __class__ . __name__ , AliasMode . JSON ) split_plan . add_action ( WriteFileAction ( root_file , Element ( stripped_root , wrapper_alias ), content_type )) return split_plan @classmethod def find_aliases_to_strip ( cls , element_paths : List [ ElementPath ]) -> Dict [ str , AliasTracker ]: \"\"\"Find list of aliases that need to be stripped as each element written out.\"\"\" # A given path may be present in several split actions # Need to determine all parts stripped at each node in order to strip them all and # write the stripped model only once tracker_map : Dict [ str , AliasTracker ] = {} for element_path in element_paths : path = element_path . get_full () path_parts = path . split ( '.' ) alias = path_parts [ - 1 ] if len ( path_parts ) > 2 and alias != '*' : root_path = '.' . join ( path_parts [: - 1 ]) if root_path in tracker_map : tracker_map [ root_path ] . add_alias ( alias ) else : tracker_map [ root_path ] = AliasTracker ( aliases = [ alias ]) return tracker_map","title":"SplitCmd"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.SplitCmd.name","text":"","title":"name"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.SplitCmd-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.SplitCmd.find_aliases_to_strip","text":"Find list of aliases that need to be stripped as each element written out. Source code in trestle/core/commands/split.py @classmethod def find_aliases_to_strip ( cls , element_paths : List [ ElementPath ]) -> Dict [ str , AliasTracker ]: \"\"\"Find list of aliases that need to be stripped as each element written out.\"\"\" # A given path may be present in several split actions # Need to determine all parts stripped at each node in order to strip them all and # write the stripped model only once tracker_map : Dict [ str , AliasTracker ] = {} for element_path in element_paths : path = element_path . get_full () path_parts = path . split ( '.' ) alias = path_parts [ - 1 ] if len ( path_parts ) > 2 and alias != '*' : root_path = '.' . join ( path_parts [: - 1 ]) if root_path in tracker_map : tracker_map [ root_path ] . add_alias ( alias ) else : tracker_map [ root_path ] = AliasTracker ( aliases = [ alias ]) return tracker_map","title":"find_aliases_to_strip()"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.SplitCmd.perform_split","text":"Perform the split operation. Parameters: Name Type Description Default effective_cwd Path effective directory in which the the split operation is performed required file_name str file name of model to split, or '' if deduced from elements and cwd required elements str comma separated list of paths to strip from the file, with quotes removed required Returns: Type Description int 0 on success and 1 on failure Source code in trestle/core/commands/split.py @classmethod def perform_split ( cls , effective_cwd : pathlib . Path , file_name : str , elements : str , trestle_root : pathlib . Path ) -> int : \"\"\"Perform the split operation. Args: effective_cwd: effective directory in which the the split operation is performed file_name: file name of model to split, or '' if deduced from elements and cwd elements: comma separated list of paths to strip from the file, with quotes removed Returns: 0 on success and 1 on failure \"\"\" file_path_list : List [ Tuple [ str , str ]] = [] if file_name : file_path_list . append (( file_name , elements )) else : # cwd must be in the model directory if file to split is not specified # find top directory for this model based on trestle root and cwd model_dir = file_utils . extract_project_model_path ( effective_cwd ) if model_dir is None : raise TrestleError ( 'Current directory must be within a model directory if file is not specified' ) content_type : FileContentType = FileContentType . dir_to_content_type ( model_dir ) # determine the file needed for each split path element_paths = elements . split ( ',' ) for path in element_paths : element_path = ElementPath ( path ) # if element path is relative use directory context to determine absolute path element_path . make_absolute ( model_dir , effective_cwd ) file_path = element_path . find_last_file_in_path ( content_type , model_dir ) # now make the element path relative to the model file to be loaded if file_path is None or element_path . make_relative ( file_path . relative_to ( model_dir )) != 0 : raise TrestleError ( f 'Unable to match element path with files in model directory { element_path } ' ) file_path_list . append (( file_path , element_path . to_string ())) # match paths to corresponding files since several paths may be split from the same file file_path_dict : Dict [ str , str ] = {} for file_path in file_path_list : key = file_path [ 0 ] path = file_path [ 1 ] if key not in file_path_dict : file_path_dict [ key ] = path else : current_path = file_path_dict [ key ] file_path_dict [ key ] = f ' { current_path } , { path } ' for raw_file_name , element_path in file_path_dict . items (): file_path = file_utils . relative_resolve ( pathlib . Path ( raw_file_name ), effective_cwd ) # this makes assumptions that the path is relative. if not file_path . exists (): raise TrestleError ( f 'File { file_path } does not exist.' ) content_type = FileContentType . to_content_type ( file_path . suffix ) # find the base directory of the file base_dir = file_path . parent model_type , _ = ModelUtils . get_stripped_model_type ( file_path , trestle_root ) model : OscalBaseModel = model_type . oscal_read ( file_path ) if cmd_utils . split_is_too_fine ( element_path , model ): raise TrestleError ( 'Cannot split the model to the level of uuids, strings, etc.' ) # use the model itself to resolve any wildcards and create list of element paths logger . debug ( f 'split calling parse_element_args on { element_path } ' ) # use contextual mode to parse element_paths : List [ ElementPath ] = cmd_utils . parse_element_args ( model , element_path . split ( ',' ), base_dir . relative_to ( trestle_root ) ) # analyze the split tree and determine which aliases should be stripped from each file aliases_to_strip = cls . find_aliases_to_strip ( element_paths ) # need the file name relative to the base directory file_name_no_path = str ( file_path . name ) split_plan = cls . split_model ( model , element_paths , base_dir , content_type , file_name_no_path , aliases_to_strip ) trash . store ( file_path , True ) try : split_plan . execute () except Exception as e : trash . recover ( file_path , True ) raise TrestleError ( f 'Split has failed with error: { e } .' ) return CmdReturnCodes . SUCCESS . value","title":"perform_split()"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.SplitCmd.prepare_sub_model_split_actions","text":"Create split actions of sub model. Source code in trestle/core/commands/split.py @classmethod def prepare_sub_model_split_actions ( cls , sub_model_item : OscalBaseModel , sub_model_dir : pathlib . Path , file_prefix : str , content_type : FileContentType ) -> List [ Action ]: \"\"\"Create split actions of sub model.\"\"\" actions : List [ Action ] = [] file_name = cmd_utils . to_model_file_name ( sub_model_item , file_prefix , content_type ) model_type = classname_to_alias ( type ( sub_model_item ) . __name__ , AliasMode . JSON ) sub_model_file = sub_model_dir / file_name actions . append ( CreatePathAction ( sub_model_file )) actions . append ( WriteFileAction ( sub_model_file , Element ( sub_model_item , model_type ), content_type )) return actions","title":"prepare_sub_model_split_actions()"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.SplitCmd.split_model","text":"Split the model at the provided element paths. It returns a plan for the operation Source code in trestle/core/commands/split.py @classmethod def split_model ( cls , model_obj : OscalBaseModel , element_paths : List [ ElementPath ], base_dir : pathlib . Path , content_type : FileContentType , root_file_name : str , aliases_to_strip : Dict [ str , AliasTracker ] ) -> Plan : \"\"\"Split the model at the provided element paths. It returns a plan for the operation \"\"\" # initialize plan split_plan = Plan () # loop through the element path list and update the split_plan stripped_field_alias = [] cur_path_index = 0 while cur_path_index < len ( element_paths ): # extract the sub element name for each of the root path of the path chain element_path = element_paths [ cur_path_index ] if element_path . get_parent () is None and len ( element_path . get ()) > 1 : stripped_part = element_path . get ()[ 1 ] if stripped_part == ElementPath . WILDCARD : stripped_field_alias . append ( '__root__' ) else : if stripped_part not in stripped_field_alias : stripped_field_alias . append ( stripped_part ) # split model at the path chain cur_path_index = cls . split_model_at_path_chain ( model_obj , element_paths , base_dir , content_type , cur_path_index , split_plan , False , root_file_name , aliases_to_strip ) cur_path_index += 1 # strip the root model object and add a WriteAction stripped_root = model_obj . stripped_instance ( stripped_fields_aliases = stripped_field_alias ) # If it's an empty model after stripping the fields, don't create path and don't write if set ( model_obj . __fields__ . keys ()) == set ( stripped_field_alias ): return split_plan if root_file_name != '' : root_file = base_dir / root_file_name else : root_file = base_dir / element_paths [ 0 ] . to_root_path ( content_type ) split_plan . add_action ( CreatePathAction ( root_file , True )) wrapper_alias = classname_to_alias ( stripped_root . __class__ . __name__ , AliasMode . JSON ) split_plan . add_action ( WriteFileAction ( root_file , Element ( stripped_root , wrapper_alias ), content_type )) return split_plan","title":"split_model()"},{"location":"api_reference/trestle.core.commands.split/#trestle.core.commands.split.SplitCmd.split_model_at_path_chain","text":"Recursively split the model at the provided chain of element paths. It assumes that a chain of element paths starts at the cur_path_index with the first path ending with a wildcard (*) If the wildcard follows an element that is inherently a list of items, the list of items is extracted. But if the wildcard follows a generic model than members of that model class found in the model will be split off. But only the non-trivial elements are removed, i.e. not str, int, datetime, etc. Parameters: Name Type Description Default model_obj OscalBaseModel The OscalBaseModel to be split required element_paths List[trestle.core.models.elements.ElementPath] The List[ElementPath] of elements to split, including embedded wildcards required base_dir Path pathlib.Path of the file being split required content_type FileContentType json or yaml files required cur_path_index int Index into the list of element paths for the current split operation required split_plan Plan The accumulated plan of actions needed to perform the split required strip_root bool Whether to strip elements from the root object required root_file_name str Filename of root file that gets split into a list of items required aliases_to_strip Dict[str, trestle.core.commands.split.AliasTracker] AliasTracker previously loaded with aliases that need to be split from each element required last_one bool bool indicating last item in array has been split and stripped model can now be written True Returns: Type Description int int representing the index where the chain of the path ends. Examples: For example, element paths could have a list of paths as below for a ComponentDefinition model where the first path is the start of the chain. For each of the sub model described by the first element path (e.g component-defintion.components. ) in the chain, the subsequent paths (e.g component.control-implementations. ) will be applied recursively to retrieve the sub-sub models: [ 'component-definition.component. ', 'component.control-implementations. ' ] for a command like below: trestle split -f component.yaml -e component-definition.components. .control-implementations. Source code in trestle/core/commands/split.py @classmethod def split_model_at_path_chain ( cls , model_obj : OscalBaseModel , element_paths : List [ ElementPath ], base_dir : pathlib . Path , content_type : FileContentType , cur_path_index : int , split_plan : Plan , strip_root : bool , root_file_name : str , aliases_to_strip : Dict [ str , AliasTracker ], last_one : bool = True ) -> int : \"\"\"Recursively split the model at the provided chain of element paths. It assumes that a chain of element paths starts at the cur_path_index with the first path ending with a wildcard (*) If the wildcard follows an element that is inherently a list of items, the list of items is extracted. But if the wildcard follows a generic model than members of that model class found in the model will be split off. But only the non-trivial elements are removed, i.e. not str, int, datetime, etc. Args: model_obj: The OscalBaseModel to be split element_paths: The List[ElementPath] of elements to split, including embedded wildcards base_dir: pathlib.Path of the file being split content_type: json or yaml files cur_path_index: Index into the list of element paths for the current split operation split_plan: The accumulated plan of actions needed to perform the split strip_root: Whether to strip elements from the root object root_file_name: Filename of root file that gets split into a list of items aliases_to_strip: AliasTracker previously loaded with aliases that need to be split from each element last_one: bool indicating last item in array has been split and stripped model can now be written Returns: int representing the index where the chain of the path ends. Examples: For example, element paths could have a list of paths as below for a `ComponentDefinition` model where the first path is the start of the chain. For each of the sub model described by the first element path (e.g component-defintion.components.*) in the chain, the subsequent paths (e.g component.control-implementations.*) will be applied recursively to retrieve the sub-sub models: [ 'component-definition.component.*', 'component.control-implementations.*' ] for a command like below: trestle split -f component.yaml -e component-definition.components.*.control-implementations.* \"\"\" if split_plan is None : raise TrestleError ( 'Split plan must have been initialized' ) if cur_path_index < 0 : raise TrestleError ( 'Current index of the chain of paths cannot be less than 0' ) # if there are no more element_paths, return the current plan if cur_path_index >= len ( element_paths ): return cur_path_index # initialize local variables element = Element ( model_obj ) stripped_field_alias : List [ str ] = [] # get the sub_model specified by the element_path of this round element_path = element_paths [ cur_path_index ] # does the next element_path point back at me is_parent = cur_path_index + 1 < len ( element_paths ) and element_paths [ cur_path_index + 1 ] . get_parent () == element_path # root dir name for sub models dir # 00000__group.json will have the root_dir name as 00000__group for sub models of group # catalog.json will have the root_dir name as catalog root_dir = '' if root_file_name != '' : root_dir = str ( pathlib . Path ( root_file_name ) . with_suffix ( '' )) sub_models = element . get_at ( element_path , False ) # we call sub_models as in plural, but it can be just one # assume cur_path_index is the end of the chain # value of this variable may change during recursive split of the sub-models below path_chain_end = cur_path_index # if wildcard is present in the element_path and the next path in the chain has current path as the parent, # Then deal with case of list, or split of arbitrary oscalbasemodel if is_parent and element_path . get_last () is not ElementPath . WILDCARD : # create dir for all sub model items sub_models_dir = base_dir / element_path . to_root_path () sub_model_plan = Plan () path_chain_end = cls . split_model_at_path_chain ( sub_models , element_paths , sub_models_dir , content_type , cur_path_index + 1 , sub_model_plan , True , '' , aliases_to_strip ) sub_model_actions = sub_model_plan . get_actions () split_plan . add_actions ( sub_model_actions ) elif element_path . get_last () == ElementPath . WILDCARD : # extract sub-models into a dict with appropriate prefix sub_model_items : Dict [ str , OscalBaseModel ] = {} sub_models_dir = base_dir / element_path . to_file_path ( root_dir = root_dir ) if isinstance ( sub_models , list ): for i , sub_model_item in enumerate ( sub_models ): # e.g. `groups/00000_groups/` prefix = str ( i ) . zfill ( const . FILE_DIGIT_PREFIX_LENGTH ) sub_model_items [ prefix ] = sub_model_item # process list sub model items count = 0 for key , sub_model_item in sub_model_items . items (): count += 1 # recursively split the sub-model if there are more element paths to traverse # e.g. split component.control-implementations.* require_recursive_split = cur_path_index + 1 < len ( element_paths ) and element_paths [ cur_path_index + 1 ] . get_parent () == element_path if require_recursive_split : # prepare individual directory for each sub-model sub_root_file_name = cmd_utils . to_model_file_name ( sub_model_item , key , content_type ) sub_model_plan = Plan () last_one : bool = count == len ( sub_model_items ) path_chain_end = cls . split_model_at_path_chain ( sub_model_item , element_paths , sub_models_dir , content_type , cur_path_index + 1 , sub_model_plan , True , sub_root_file_name , aliases_to_strip , last_one ) sub_model_actions = sub_model_plan . get_actions () else : sub_model_actions = cls . prepare_sub_model_split_actions ( sub_model_item , sub_models_dir , key , content_type ) split_plan . add_actions ( sub_model_actions ) else : # the chain of path ends at the current index. # so no recursive call. Let's just write the sub model to the file and get out if sub_models is not None : sub_model_file = base_dir / element_path . to_file_path ( content_type , root_dir = root_dir ) split_plan . add_action ( CreatePathAction ( sub_model_file )) split_plan . add_action ( WriteFileAction ( sub_model_file , Element ( sub_models , element_path . get_element_name ()), content_type ) ) # Strip the root model and add a WriteAction for the updated model object in the plan if strip_root : full_path = element_path . get_full () path = '.' . join ( full_path . split ( '.' )[: - 1 ]) aliases = [ element_path . get_element_name ()] need_to_write = True use_alias_dict = aliases_to_strip is not None and path in aliases_to_strip if use_alias_dict : aliases = aliases_to_strip [ path ] . get_aliases () need_to_write = aliases_to_strip [ path ] . needs_writing () stripped_model = model_obj . stripped_instance ( stripped_fields_aliases = aliases ) # can mark it written even if it doesn't need writing since it is empty # but if an array only mark it written if it's the last one if last_one and use_alias_dict : aliases_to_strip [ path ] . mark_written () # If it's an empty model after stripping the fields, don't create path and don't write field_list = [ x for x in model_obj . __fields__ . keys () if model_obj . __fields__ [ x ] is not None ] if set ( field_list ) == set ( stripped_field_alias ): return path_chain_end if need_to_write : if root_file_name != '' : root_file = base_dir / root_file_name else : root_file = base_dir / element_path . to_root_path ( content_type ) split_plan . add_action ( CreatePathAction ( root_file )) wrapper_alias = classname_to_alias ( stripped_model . __class__ . __name__ , AliasMode . JSON ) split_plan . add_action ( WriteFileAction ( root_file , Element ( stripped_model , wrapper_alias ), content_type )) # return the end of the current path chain return path_chain_end handler: python","title":"split_model_at_path_chain()"},{"location":"api_reference/trestle.core.commands.task/","text":"trestle.core.commands.task \u00a4 Trestle task command. logger \u00a4 Classes \u00a4 TaskCmd ( CommandPlusDocs ) \u00a4 Run arbitrary trestle tasks in a simple and extensible methodology. Source code in trestle/core/commands/task.py class TaskCmd ( CommandPlusDocs ): \"\"\"Run arbitrary trestle tasks in a simple and extensible methodology.\"\"\" name = 'task' def _init_arguments ( self ) -> None : self . add_argument ( 'task' , nargs = '?' , type = str , help = 'The name of the task to be run, trestle task -l will list available tasks.' ) self . add_argument ( '-l' , '--list' , action = 'store_true' , help = 'List the available tasks' ) self . add_argument ( '-c' , '--config' , type = pathlib . Path , help = 'Pass a customized configuration file specifically for a task' ) self . add_argument ( '-i' , '--info' , action = 'store_true' , help = 'Print information about a particular task.' ) def _run ( self , args : argparse . Namespace ) -> int : try : logger . debug ( 'Entering trestle task.' ) log . set_log_level_from_args ( args ) # Initial logic for conflicting args if args . task and args . list : raise TrestleIncorrectArgsError ( 'Task name or -l can be provided not both.' ) if not args . task and not args . list : raise TrestleIncorrectArgsError ( 'Either a trestle task or \"-l/--list\" shoudl be passed as input arguments.' ) # Ensure trestle directory (must be true) trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. if not trestle_root or not file_utils . is_valid_project_root ( args . trestle_root ): raise TrestleError ( f 'Given directory: { trestle_root } is not a trestle project.' ) config_path = trestle_root / const . TRESTLE_CONFIG_DIR / const . TRESTLE_CONFIG_FILE if args . config : config_path = pathlib . Path ( args . config ) if not config_path . exists (): raise TrestleError ( f 'Config file at { config_path } does not exist.' ) # permit ${name} in config definitions global_config = configparser . ConfigParser ( interpolation = configparser . ExtendedInterpolation ()) global_config . read_file ( config_path . open ( 'r' , encoding = const . FILE_ENCODING )) # run setup task_index = self . _build_task_index () # Clean to run if args . list : self . _list_tasks ( task_index ) return CmdReturnCodes . SUCCESS . value # run the task if args . task not in task_index . keys (): raise TrestleIncorrectArgsError ( f 'Unknown trestle task: { args . task } ' ) logger . debug ( f 'Loading task: { args . task } ' ) section_label = 'task.' + args . task config_section : Optional [ configparser . SectionProxy ] = None if section_label in global_config . sections (): config_section = global_config [ section_label ] else : logger . warning ( f 'Config file was not configured with the appropriate section for the task: \"[ { section_label } ]\"' ) task = task_index [ args . task ]( config_section ) if args . info : task . print_info () return CmdReturnCodes . SUCCESS . value simulate_result = task . simulate () if not ( simulate_result == TaskOutcome . SIM_SUCCESS ): raise TrestleError ( f 'Task { args . task } reported a { simulate_result } ' ) actual_result = task . execute () if not ( actual_result == TaskOutcome . SUCCESS ): raise TrestleError ( f 'Task { args . task } reported a { actual_result } ' ) logger . info ( f 'Task: { args . task } executed successfully.' ) return CmdReturnCodes . SUCCESS . value except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while executing Trestle task' ) def _build_task_index ( self ) -> Dict [ str , Type [ TaskBase ]]: \"\"\"Build an index of all classes in which are tasks and present as a dictionary.\"\"\" task_index : Dict [ str , Type [ TaskBase ]] = {} pkgpath = str ( pathlib . Path ( trestle . tasks . __file__ ) . parent ) for _ , name , _ in pkgutil . iter_modules ([ pkgpath ]): __import__ ( f 'trestle.tasks. { name } ' ) clsmembers = inspect . getmembers ( sys . modules [ f 'trestle.tasks. { name } ' ], inspect . isclass ) for candidate in clsmembers : if issubclass ( candidate [ 1 ], TaskBase ): task_index [ candidate [ 1 ] . name ] = candidate [ 1 ] return task_index def _list_tasks ( self , task_index : Dict [ str , Type [ TaskBase ]]) -> None : logger . info ( 'Available tasks:' ) for key in task_index . keys (): logger . info ( f ' { key } ' ) name \u00a4 handler: python","title":"task"},{"location":"api_reference/trestle.core.commands.task/#trestle.core.commands.task","text":"Trestle task command.","title":"task"},{"location":"api_reference/trestle.core.commands.task/#trestle.core.commands.task.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.task/#trestle.core.commands.task-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.task/#trestle.core.commands.task.TaskCmd","text":"Run arbitrary trestle tasks in a simple and extensible methodology. Source code in trestle/core/commands/task.py class TaskCmd ( CommandPlusDocs ): \"\"\"Run arbitrary trestle tasks in a simple and extensible methodology.\"\"\" name = 'task' def _init_arguments ( self ) -> None : self . add_argument ( 'task' , nargs = '?' , type = str , help = 'The name of the task to be run, trestle task -l will list available tasks.' ) self . add_argument ( '-l' , '--list' , action = 'store_true' , help = 'List the available tasks' ) self . add_argument ( '-c' , '--config' , type = pathlib . Path , help = 'Pass a customized configuration file specifically for a task' ) self . add_argument ( '-i' , '--info' , action = 'store_true' , help = 'Print information about a particular task.' ) def _run ( self , args : argparse . Namespace ) -> int : try : logger . debug ( 'Entering trestle task.' ) log . set_log_level_from_args ( args ) # Initial logic for conflicting args if args . task and args . list : raise TrestleIncorrectArgsError ( 'Task name or -l can be provided not both.' ) if not args . task and not args . list : raise TrestleIncorrectArgsError ( 'Either a trestle task or \"-l/--list\" shoudl be passed as input arguments.' ) # Ensure trestle directory (must be true) trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. if not trestle_root or not file_utils . is_valid_project_root ( args . trestle_root ): raise TrestleError ( f 'Given directory: { trestle_root } is not a trestle project.' ) config_path = trestle_root / const . TRESTLE_CONFIG_DIR / const . TRESTLE_CONFIG_FILE if args . config : config_path = pathlib . Path ( args . config ) if not config_path . exists (): raise TrestleError ( f 'Config file at { config_path } does not exist.' ) # permit ${name} in config definitions global_config = configparser . ConfigParser ( interpolation = configparser . ExtendedInterpolation ()) global_config . read_file ( config_path . open ( 'r' , encoding = const . FILE_ENCODING )) # run setup task_index = self . _build_task_index () # Clean to run if args . list : self . _list_tasks ( task_index ) return CmdReturnCodes . SUCCESS . value # run the task if args . task not in task_index . keys (): raise TrestleIncorrectArgsError ( f 'Unknown trestle task: { args . task } ' ) logger . debug ( f 'Loading task: { args . task } ' ) section_label = 'task.' + args . task config_section : Optional [ configparser . SectionProxy ] = None if section_label in global_config . sections (): config_section = global_config [ section_label ] else : logger . warning ( f 'Config file was not configured with the appropriate section for the task: \"[ { section_label } ]\"' ) task = task_index [ args . task ]( config_section ) if args . info : task . print_info () return CmdReturnCodes . SUCCESS . value simulate_result = task . simulate () if not ( simulate_result == TaskOutcome . SIM_SUCCESS ): raise TrestleError ( f 'Task { args . task } reported a { simulate_result } ' ) actual_result = task . execute () if not ( actual_result == TaskOutcome . SUCCESS ): raise TrestleError ( f 'Task { args . task } reported a { actual_result } ' ) logger . info ( f 'Task: { args . task } executed successfully.' ) return CmdReturnCodes . SUCCESS . value except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while executing Trestle task' ) def _build_task_index ( self ) -> Dict [ str , Type [ TaskBase ]]: \"\"\"Build an index of all classes in which are tasks and present as a dictionary.\"\"\" task_index : Dict [ str , Type [ TaskBase ]] = {} pkgpath = str ( pathlib . Path ( trestle . tasks . __file__ ) . parent ) for _ , name , _ in pkgutil . iter_modules ([ pkgpath ]): __import__ ( f 'trestle.tasks. { name } ' ) clsmembers = inspect . getmembers ( sys . modules [ f 'trestle.tasks. { name } ' ], inspect . isclass ) for candidate in clsmembers : if issubclass ( candidate [ 1 ], TaskBase ): task_index [ candidate [ 1 ] . name ] = candidate [ 1 ] return task_index def _list_tasks ( self , task_index : Dict [ str , Type [ TaskBase ]]) -> None : logger . info ( 'Available tasks:' ) for key in task_index . keys (): logger . info ( f ' { key } ' )","title":"TaskCmd"},{"location":"api_reference/trestle.core.commands.task/#trestle.core.commands.task.TaskCmd.name","text":"handler: python","title":"name"},{"location":"api_reference/trestle.core.commands.validate/","text":"trestle.core.commands.validate \u00a4 Trestle Validate Command. logger \u00a4 Classes \u00a4 ValidateCmd ( CommandPlusDocs ) \u00a4 Validate contents of a trestle model in different modes. Source code in trestle/core/commands/validate.py class ValidateCmd ( CommandPlusDocs ): \"\"\"Validate contents of a trestle model in different modes.\"\"\" name = ARG_VALIDATE def _init_arguments ( self ) -> None : vfact . init_arguments ( self ) def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) mode_args = argparse . Namespace ( mode = VAL_MODE_ALL ) validator = vfact . validator_factory . get ( mode_args ) return validator . validate ( args ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while validating contents of a trestle model' ) name \u00a4 handler: python","title":"validate"},{"location":"api_reference/trestle.core.commands.validate/#trestle.core.commands.validate","text":"Trestle Validate Command.","title":"validate"},{"location":"api_reference/trestle.core.commands.validate/#trestle.core.commands.validate.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.validate/#trestle.core.commands.validate-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.validate/#trestle.core.commands.validate.ValidateCmd","text":"Validate contents of a trestle model in different modes. Source code in trestle/core/commands/validate.py class ValidateCmd ( CommandPlusDocs ): \"\"\"Validate contents of a trestle model in different modes.\"\"\" name = ARG_VALIDATE def _init_arguments ( self ) -> None : vfact . init_arguments ( self ) def _run ( self , args : argparse . Namespace ) -> int : try : log . set_log_level_from_args ( args ) mode_args = argparse . Namespace ( mode = VAL_MODE_ALL ) validator = vfact . validator_factory . get ( mode_args ) return validator . validate ( args ) except Exception as e : # pragma: no cover return handle_generic_command_exception ( e , logger , 'Error while validating contents of a trestle model' )","title":"ValidateCmd"},{"location":"api_reference/trestle.core.commands.validate/#trestle.core.commands.validate.ValidateCmd.name","text":"handler: python","title":"name"},{"location":"api_reference/trestle.core.commands.version/","text":"trestle.core.commands.version \u00a4 Trestle Validate Command. logger \u00a4 Classes \u00a4 VersionCmd ( CommandBase ) \u00a4 Output version info for trestle and OSCAL. Source code in trestle/core/commands/version.py class VersionCmd ( CommandBase ): \"\"\"Output version info for trestle and OSCAL.\"\"\" name = 'version' def _run ( self , args : argparse . Namespace ) -> int : version_string = f 'Trestle version v { __version__ } based on OSCAL version { OSCAL_VERSION } ' self . out ( version_string ) return CmdReturnCodes . SUCCESS . value name \u00a4 handler: python","title":"version"},{"location":"api_reference/trestle.core.commands.version/#trestle.core.commands.version","text":"Trestle Validate Command.","title":"version"},{"location":"api_reference/trestle.core.commands.version/#trestle.core.commands.version.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.commands.version/#trestle.core.commands.version-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.commands.version/#trestle.core.commands.version.VersionCmd","text":"Output version info for trestle and OSCAL. Source code in trestle/core/commands/version.py class VersionCmd ( CommandBase ): \"\"\"Output version info for trestle and OSCAL.\"\"\" name = 'version' def _run ( self , args : argparse . Namespace ) -> int : version_string = f 'Trestle version v { __version__ } based on OSCAL version { OSCAL_VERSION } ' self . out ( version_string ) return CmdReturnCodes . SUCCESS . value","title":"VersionCmd"},{"location":"api_reference/trestle.core.commands.version/#trestle.core.commands.version.VersionCmd.name","text":"handler: python","title":"name"},{"location":"api_reference/trestle.core.control_io/","text":"trestle.core.control_io \u00a4 Handle direct i/o reading and writing controls as markdown. logger \u00a4 Classes \u00a4 ControlIOReader \u00a4 Class to read controls from markdown. Source code in trestle/core/control_io.py class ControlIOReader (): \"\"\"Class to read controls from markdown.\"\"\" @staticmethod def _strip_to_make_ncname ( label : str ) -> str : \"\"\"Strip chars to conform with NCNAME regex.\"\"\" orig_label = label # make sure first char is allowed while label and label [ 0 ] not in const . NCNAME_UTF8_FIRST_CHAR_OPTIONS : label = label [ 1 :] new_label = label [: 1 ] # now check remaining chars if len ( label ) > 1 : for ii in range ( 1 , len ( label )): if label [ ii ] in const . NCNAME_UTF8_OTHER_CHAR_OPTIONS : new_label += label [ ii ] # do final check to confirm it is NCNAME match = re . search ( const . NCNAME_REGEX , new_label ) if not match : raise TrestleError ( f 'Unable to convert label { orig_label } to NCNAME format.' ) return new_label @staticmethod def _load_control_lines_and_header ( control_file : pathlib . Path ) -> Tuple [ List [ str ], Dict [ str , Any ]]: lines : List [ str ] = [] try : content = control_file . open ( 'r' , encoding = const . FILE_ENCODING ) . read () except UnicodeDecodeError as e : logger . debug ( f 'See: { const . WEBSITE_ROOT } /errors/#utf-8-encoding-only' ) raise TrestleError ( f 'Unable to load file due to utf-8 encoding issues: { e } ' ) try : fm = frontmatter . loads ( content ) except Exception as e : logger . error ( f 'Error parsing yaml header from file { control_file } . ' f 'This is most likely due to an incorrect yaml structure.' ) raise TrestleError ( f 'Failure parsing yaml header on file { control_file } : { e } ' ) raw_lines = fm . content . split ( ' \\n ' ) header = fm . metadata # Any fully blank lines will be retained but as empty strings lines = [ line . strip ( ' \\r\\n ' ) . rstrip () for line in raw_lines ] clean_lines = [] # need to keep indentation and empty lines for line in lines : if line . startswith ( '<!--' ) or line . startswith ( '__________________' ): continue clean_lines . append ( line ) return clean_lines , header @staticmethod def _parse_control_title_line ( line : str ) -> Tuple [ int , str , str ]: \"\"\"Process the title line and extract the control id, group title (in brackets) and control title.\"\"\" if line . count ( '-' ) == 0 : raise TrestleError ( f 'Markdown control title format error, missing - after control id: { line } ' ) split_line = line . split () if len ( split_line ) < 3 or split_line [ 2 ] != '-' : raise TrestleError ( f 'Cannot parse control markdown title for control_id group and title: { line } ' ) # first token after the # control_id = split_line [ 1 ] group_title_start = line . find ( '\\[' ) group_title_end = line . find ( '\\]' ) if group_title_start < 0 or group_title_end < 0 or group_title_start > group_title_end : raise TrestleError ( f 'unable to read group title for control { control_id } ' ) group_title = line [ group_title_start + 2 : group_title_end ] . strip () control_title = line [ group_title_end + 2 :] . strip () return control_id , group_title , control_title @staticmethod def _indent ( line : str ) -> int : \"\"\"Measure indent of non-empty line.\"\"\" if not line : raise TrestleError ( 'Empty line queried for indent.' ) if line [ 0 ] not in [ ' ' , '-' ]: return - 1 for ii in range ( len ( line )): if line [ ii ] == '-' : return ii # if line is indented it must start with - if line [ ii ] != ' ' : break raise TrestleError ( f 'List elements must start with -: { line } ' ) @staticmethod def _get_next_line ( ii : int , lines : List [ str ]) -> Tuple [ int , str ]: while ii < len ( lines ): line = lines [ ii ] if line : return ii , line ii += 1 return - 1 , '' @staticmethod def _get_next_indent ( ii : int , lines : List [ str ]) -> Tuple [ int , int , str ]: \"\"\"Seek to next content line. ii remains at line read.\"\"\" while 0 <= ii < len ( lines ): line = lines [ ii ] if line : if line [ 0 ] == '#' : return ii , - 1 , line indent = ControlIOReader . _indent ( line ) if indent >= 0 : # extract text after - start = indent + 1 while start < len ( line ) and line [ start ] == ' ' : start += 1 if start >= len ( line ): raise TrestleError ( f 'Invalid line { line } ' ) return ii , indent , line [ start :] return ii , indent , line ii += 1 return ii , - 1 , '' @staticmethod def _read_part_id_prose ( line : str ) -> Tuple [ str , str ]: \"\"\"Extract the part id letter or number and prose from line.\"\"\" start = line . find ( ' \\\\ [' ) end = line . find ( ' \\\\ ]' ) prose = line . strip () if start < 0 else line [ end + 2 :] . strip () id_ = '' if start < 0 or end < 0 else line [ start + 2 : end ] return id_ , prose @staticmethod def _bump_label ( label : str ) -> str : \"\"\" Find next label given a string of 1 or more pure letters or digits. The input must be either a string of digits or a string of ascii letters - or empty string. \"\"\" if not label : return 'a' if label [ 0 ] in string . digits : return str ( int ( label ) + 1 ) if len ( label ) == 1 and label [ 0 ] . lower () < 'z' : return chr ( ord ( label [ 0 ]) + 1 ) # if this happens to be a string of letters, force it lowercase and bump label = label . lower () factor = 1 value = 0 # delta is needed because a counts as 0 when first value on right, but 1 for all others delta = 0 for letter in label [:: - 1 ]: value += ( ord ( letter ) - ord ( 'a' ) + delta ) * factor factor *= 26 delta = 1 value += 1 new_label = '' delta = 0 while value > 0 : new_label += chr ( ord ( 'a' ) + value % 26 - delta ) value = value // 26 delta = 1 return new_label [:: - 1 ] @staticmethod def _create_next_label ( prev_label : str , indent : int ) -> str : \"\"\" Create new label at indent level based on previous label if available. If previous label is available, make this the next one in the sequence. Otherwise start with a or 1 on alternate levels of indentation. If alphabetic label reaches z, next one is aa. Numeric ranges from 1 to 9, then 10 etc. \"\"\" if not prev_label : # assume indent goes in steps of 2 return [ 'a' , '1' ][( indent // 2 ) % 2 ] label_prefix = '' label_suffix = prev_label is_char = prev_label [ - 1 ] in string . ascii_letters # if it isn't ending in letter or digit just append 'a' to end if not is_char and prev_label [ - 1 ] not in string . digits : return prev_label + 'a' # break in middle of string if mixed types if len ( prev_label ) > 1 : ii = len ( prev_label ) - 1 while ii >= 0 : if prev_label [ ii ] not in string . ascii_letters + string . digits : break if ( prev_label [ ii ] in string . ascii_letters ) != is_char : break ii -= 1 if ii >= 0 : label_prefix = prev_label [:( ii + 1 )] label_suffix = prev_label [( ii + 1 ):] return label_prefix + ControlIOReader . _bump_label ( label_suffix ) @staticmethod def _read_parts ( indent : int , ii : int , lines : List [ str ], parent_id : str , parts : List [ common . Part ]) -> Tuple [ int , List [ common . Part ]]: \"\"\"If indentation level goes up or down, create new list or close current one.\"\"\" while True : ii , new_indent , line = ControlIOReader . _get_next_indent ( ii , lines ) if new_indent < 0 : # we are done reading control statement return ii , parts if new_indent == indent : # create new item part and add to current list of parts id_text , prose = ControlIOReader . _read_part_id_prose ( line ) # id_text is the part id and needs to be as a label property value # if none is there then create one from previous part, or use default if not id_text : prev_label = ControlIOWriter . get_label ( parts [ - 1 ]) if parts else '' id_text = ControlIOReader . _create_next_label ( prev_label , indent ) id_ = ControlIOReader . _strip_to_make_ncname ( parent_id . rstrip ( '.' ) + '.' + id_text . strip ( '.' )) name = 'objective' if id_ . find ( '_obj' ) > 0 else 'item' prop = common . Property ( name = 'label' , value = id_text ) part = common . Part ( name = name , id = id_ , prose = prose , props = [ prop ]) parts . append ( part ) ii += 1 elif new_indent > indent : # add new list of parts to last part and continue if len ( parts ) == 0 : raise TrestleError ( f 'Improper indentation structure: { line } ' ) ii , new_parts = ControlIOReader . _read_parts ( new_indent , ii , lines , parts [ - 1 ] . id , []) if new_parts : parts [ - 1 ] . parts = new_parts else : # return list of sub-parts return ii , parts @staticmethod def _read_control_statement ( ii : int , lines : List [ str ], control_id : str ) -> Tuple [ int , common . Part ]: \"\"\"Search for the Control statement and read until next ## Control.\"\"\" while 0 <= ii < len ( lines ) and not lines [ ii ] . startswith ( '## Control ' ): ii += 1 if ii >= len ( lines ): raise TrestleError ( f 'Control statement not found for control { control_id } ' ) ii += 1 ii , line = ControlIOReader . _get_next_line ( ii , lines ) if ii < 0 : # This means no statement and control withdrawn (this happens in NIST catalog) return ii , None if line and line [ 0 ] == ' ' and line . lstrip ()[ 0 ] != '-' : # prose that appears indented but has no - : treat it as the normal statement prose line = line . lstrip () indent = - 1 ii += 1 else : ii , indent , line = ControlIOReader . _get_next_indent ( ii , lines ) statement_part = common . Part ( name = 'statement' , id = f ' { control_id } _smt' ) # first line is either statement prose or start of statement parts if indent < 0 : statement_part . prose = line ii += 1 # we have absorbed possible statement prose. # now just read parts recursively # if there was no statement prose, this will re-read the line just read # as the start of the statement's parts ii , parts = ControlIOReader . _read_parts ( 0 , ii , lines , statement_part . id , []) statement_part . parts = parts if parts else None return ii , statement_part @staticmethod def _read_control_objective ( ii : int , lines : List [ str ], control_id : str ) -> Tuple [ int , Optional [ common . Part ]]: ii_orig = ii while 0 <= ii < len ( lines ) and not lines [ ii ] . startswith ( '## Control Objective' ): ii += 1 if ii >= len ( lines ): return ii_orig , None ii += 1 ii , line = ControlIOReader . _get_next_line ( ii , lines ) if ii < 0 : raise TrestleError ( f 'Unable to parse objective from control markdown { control_id } ' ) if line and line [ 0 ] == ' ' and line . lstrip ()[ 0 ] != '-' : # prose that appears indented but has no - : treat it as the normal objective prose line = line . lstrip () indent = - 1 ii += 1 else : ii , indent , line = ControlIOReader . _get_next_indent ( ii , lines ) objective_part = common . Part ( name = 'objective' , id = f ' { control_id } _obj' ) # first line is either objective prose or start of objective parts if indent < 0 : objective_part . prose = line ii += 1 # we have absorbed possible objective prose. # now just read parts recursively # if there was no objective prose, this will re-read the line just read # as the start of the objective's parts ii , parts = ControlIOReader . _read_parts ( 0 , ii , lines , objective_part . id , []) objective_part . parts = parts if parts else None return ii , objective_part @staticmethod def _read_sections ( ii : int , lines : List [ str ], control_id : str , control_parts : List [ common . Part ]) -> Tuple [ int , Optional [ List [ common . Part ]]]: \"\"\"Read all sections following the section separated by ## Control.\"\"\" new_parts = [] prefix = '## Control ' while 0 <= ii < len ( lines ): line = lines [ ii ] if line . startswith ( '## What is the solution' ) or line . startswith ( f '# { const . EDITABLE_CONTENT } ' ): ii += 1 continue if not line : ii += 1 continue if line and not line . startswith ( prefix ): # the control has no sections to read, so exit the loop break label = line [ len ( prefix ):] . strip () prose = '' ii += 1 while 0 <= ii < len ( lines ) and not lines [ ii ] . startswith ( prefix ) and not lines [ ii ] . startswith ( f '# { const . EDITABLE_CONTENT } ' ): prose = ' \\n ' . join ([ prose , lines [ ii ]]) ii += 1 if prose : if label . lower () == 'guidance' : id_ = ControlIOReader . _strip_to_make_ncname ( control_id + '_gdn' ) else : id_ = ControlIOReader . _strip_to_make_ncname ( control_id + '_' + label ) label = ControlIOReader . _strip_to_make_ncname ( label ) new_parts . append ( common . Part ( id = id_ , name = label , prose = prose . strip ( ' \\n ' ))) if new_parts : control_parts = [] if not control_parts else control_parts control_parts . extend ( new_parts ) control_parts = none_if_empty ( control_parts ) return ii , control_parts @staticmethod def _clean_prose ( prose : List [ str ]) -> List [ str ]: # remove empty and horizontal rule lines at start and end of list of prose lines forward_index = 0 for line in prose : if line . strip () and not line . startswith ( '____' ): break forward_index += 1 new_prose = prose [ forward_index :] reverse_index = 0 for line in reversed ( new_prose ): if line . strip () and not line . startswith ( '____' ): break reverse_index += 1 clean_prose = new_prose [: len ( new_prose ) - reverse_index ] clean_prose = clean_prose if clean_prose else [ '' ] # if there is no useful prose this will return [''] and allow generation of a statement with empty prose return clean_prose @staticmethod def _simplify_name ( name : str ) -> str : name = name . lower () . strip () return re . sub ( ' +' , ' ' , name ) @staticmethod def _comp_name_in_dict ( comp_name : str , comp_dict : Dict [ str , List [ Dict [ str , str ]]]) -> str : \"\"\"If the name is already in the dict in a similar form, stick to that form.\"\"\" simple_name = ControlIOReader . _simplify_name ( comp_name ) for name in comp_dict . keys (): if simple_name == ControlIOReader . _simplify_name ( name ): return name return comp_name @staticmethod def _add_node_to_dict ( comp_name : str , label : str , comp_dict : Dict [ str , Dict [ str , List [ str ]]], node : MarkdownNode , control_id : str , comp_list : List [ str ] ) -> None : prose = ControlIOReader . _clean_prose ( node . content . text ) if node . key . startswith ( '### ' ): if len ( node . key . split ()) <= 1 : raise TrestleError ( f 'Line in control { control_id } markdown starts with ### but has no component name.' ) comp_name = node . key . split ( ' ' , 1 )[ 1 ] . strip () simp_comp_name = ControlIOReader . _simplify_name ( comp_name ) if simp_comp_name == ControlIOReader . _simplify_name ( const . SSP_MAIN_COMP_NAME ): raise TrestleError ( f 'Response in control { control_id } has { const . SSP_MAIN_COMP_NAME } as a component heading. ' 'Instead, place all response prose for the default component at the top of th section, ' 'with no ### component specified. It will be entered as prose for the default system component.' ) if simp_comp_name in comp_list : raise TrestleError ( f 'Control { control_id } has a section with two ### component headings for { comp_name } . ' 'Please combine the sections so there is only one heading for each component in a statement.' ) comp_list . append ( simp_comp_name ) comp_name = ControlIOReader . _comp_name_in_dict ( comp_name , comp_dict ) if comp_name in comp_dict : if label in comp_dict [ comp_name ]: comp_dict [ comp_name ][ label ] . extend ( prose ) else : comp_dict [ comp_name ][ label ] = prose else : comp_dict [ comp_name ] = { label : prose } for subnode in node . subnodes : ControlIOReader . _add_node_to_dict ( comp_name , label , comp_dict , subnode , control_id , comp_list ) @staticmethod def read_all_implementation_prose_and_header ( control_file : pathlib . Path ) -> Tuple [ Dict [ str , Dict [ str , List [ str ]]], Dict [ str , List [ str ]]]: \"\"\" Find all labels and associated prose in this control. Args: control_file: path to the control markdown file Returns: Dictionary by comp_name of Dictionaries of part labels and corresponding prose read from the markdown file. Also returns the yaml header as dict in second part of tuple. This does not generate components - it only tracks component names and associated responses. \"\"\" comp_dict = {} yaml_header = {} # this level only adds for top level component but add_node_to_dict can add for other components comp_name = const . SSP_MAIN_COMP_NAME control_id = control_file . stem try : if not control_file . exists (): return comp_dict , yaml_header md_api = MarkdownAPI () yaml_header , control = md_api . processor . process_markdown ( control_file ) imp_string = 'Implementation' headers = control . get_all_headers_for_key ( imp_string , False ) header_list = list ( headers ) if not header_list : # if statement has no parts there is only one response for entire control headers = control . get_all_headers_for_key ( const . SSP_MD_IMPLEMENTATION_QUESTION , False ) # should be only one header, so warn if others found n_headers = 0 for header in headers : node = control . get_node_for_key ( header ) ControlIOReader . _add_node_to_dict ( comp_name , 'Statement' , comp_dict , node , control_id , []) n_headers += 1 if n_headers > 1 : logger . warning ( f 'Control { control_id } has single statement with extra response # { n_headers } ' ' when it should only have one.' ) else : for header in header_list : tokens = header . split ( ' ' , 2 ) if tokens [ 0 ] == '##' and tokens [ 1 ] == imp_string : label = tokens [ 2 ] . strip () node = control . get_node_for_key ( header ) ControlIOReader . _add_node_to_dict ( comp_name , label , comp_dict , node , control_id , []) except TrestleError as e : raise TrestleError ( f 'Error occurred reading { control_file } : { e } ' ) return comp_dict , yaml_header @staticmethod def _insert_header_content ( imp_req : ossp . ImplementedRequirement , header : Dict [ str , Any ], control_id : str ) -> None : \"\"\"Insert yaml header content into the imp_req and its by_comps.\"\"\" dict_ = header . get ( const . SSP_FEDRAMP_TAG , {}) # if an attribute is in the dict but it is None, need to make sure we get empty list anyway control_orig = as_list ( dict_ . get ( const . CONTROL_ORIGINATION , [])) imp_status = as_list ( dict_ . get ( const . IMPLEMENTATION_STATUS , [])) roles = as_list ( dict_ . get ( const . RESPONSIBLE_ROLES , [])) props = [] responsible_roles = [] for co in control_orig : if isinstance ( co , str ): props . append ( common . Property ( ns = const . NAMESPACE_FEDRAMP , name = const . CONTROL_ORIGINATION , value = co )) elif isinstance ( co , dict ): if const . INHERITED in co : uuid = co [ const . INHERITED ] props . append ( common . Property ( name = const . LEV_AUTH_UUID , value = uuid )) props . append ( common . Property ( ns = const . NAMESPACE_FEDRAMP , name = const . CONTROL_ORIGINATION , value = const . INHERITED ) ) else : raise TrestleError ( f 'The yaml header for control { control_id } has unexpected content: { co } ' ) else : raise TrestleError ( f 'The yaml header for control { control_id } has unexpected content: { co } ' ) for status in imp_status : if isinstance ( status , str ): props . append ( common . Property ( ns = const . NAMESPACE_FEDRAMP , name = const . IMPLEMENTATION_STATUS , value = status ) ) elif isinstance ( status , dict ): if const . PLANNED in status : if const . COMPLETION_DATE not in status : raise TrestleError ( f 'Planned status in the control { control_id } yaml header must ' f 'specify completion date: { status } ' ) props . append ( common . Property ( ns = const . NAMESPACE_FEDRAMP , name = const . PLANNED , value = status [ const . PLANNED ]) ) datestr = status [ const . COMPLETION_DATE ] if isinstance ( datestr , datetime ): datestr = datestr . strftime ( '%Y-%m- %d ' ) else : datestr = str ( datestr ) props . append ( common . Property ( ns = const . NAMESPACE_FEDRAMP , name = const . PLANNED_COMPLETION_DATE , value = datestr ) ) else : if len ( status ) != 1 : raise TrestleError ( f 'Unexpected content in control { control_id } yaml header: { status } ' ) value = list ( status . keys ())[ 0 ] remark = list ( status . values ())[ 0 ] props . append ( common . Property ( ns = const . NAMESPACE_FEDRAMP , name = const . IMPLEMENTATION_STATUS , value = value , remarks = common . Remarks ( __root__ = remark ) ) ) else : raise TrestleError ( f 'Unexpected content in control { control_id } yaml header: { status } ' ) for role in roles : if isinstance ( role , str ): # role_id must conform to NCNAME regex role = role . strip () . replace ( ' ' , '_' ) if role : responsible_roles . append ( common . ResponsibleRole ( role_id = role )) else : logger . warning ( f 'Role in header for control { control_id } not recognized: { role } ' ) if props : imp_req . props = as_list ( imp_req . props ) imp_req . props . extend ( props ) if responsible_roles : imp_req . responsible_roles = as_list ( imp_req . responsible_roles ) imp_req . responsible_roles . extend ( responsible_roles ) imp_req . responsible_roles = none_if_empty ( imp_req . responsible_roles ) # enforce single list of resp. roles for control and each by_comp for by_comp in as_list ( imp_req . by_components ): by_comp . responsible_roles = imp_req . responsible_roles @staticmethod def read_implemented_requirement ( control_file : pathlib . Path , avail_comps : Dict [ str , ossp . SystemComponent ] ) -> Tuple [ str , ossp . ImplementedRequirement ]: \"\"\" Get the implementated requirement associated with given control and link to existing components or new ones. Args: control_file: path of the control markdown file avail_comps: dictionary of known components keyed by component name Returns: Tuple: The control sort-id and the one implemented requirement for this control. Notes: Each statement may have several responses, with each response in a by_component for a specific component. statement_map keeps track of statements that may have several by_component responses. \"\"\" control_id = control_file . stem comp_dict , header = ControlIOReader . read_all_implementation_prose_and_header ( control_file ) statement_map : Dict [ str , ossp . Statement ] = {} # create a new implemented requirement linked to the control id to hold the statements imp_req : ossp . ImplementedRequirement = gens . generate_sample_model ( ossp . ImplementedRequirement ) imp_req . control_id = control_id # the comp_dict captures all component names referenced by the control for comp_name in comp_dict . keys (): if comp_name in avail_comps : component = avail_comps [ comp_name ] else : # here is where we create a new component on the fly as needed component = gens . generate_sample_model ( ossp . SystemComponent ) component . title = comp_name avail_comps [ comp_name ] = component for label , prose_lines in comp_dict [ comp_name ] . items (): # create a statement to hold the by-components and assign the statement id if label == 'Statement' : statement_id = f ' { control_id } _smt' else : clean_label = label . strip ( '.' ) statement_id = ControlIOReader . _strip_to_make_ncname ( f ' { control_id } _smt. { clean_label } ' ) if statement_id in statement_map : statement = statement_map [ statement_id ] else : statement : ossp . Statement = gens . generate_sample_model ( ossp . Statement ) statement . statement_id = statement_id statement . by_components = [] statement_map [ statement_id ] = statement # create a new by-component to add to this statement by_comp : ossp . ByComponent = gens . generate_sample_model ( ossp . ByComponent ) # link it to the component uuid by_comp . component_uuid = component . uuid # add the response prose to the description by_comp . description = ' \\n ' . join ( prose_lines ) statement . by_components . append ( by_comp ) imp_req . statements = list ( statement_map . values ()) ControlIOReader . _insert_header_content ( imp_req , header , control_id ) sort_id = header . get ( const . SORT_ID , control_id ) return sort_id , imp_req @staticmethod def _read_added_part ( ii : int , lines : List [ str ], control_id : str , sections_dict : Dict [ str , str ]) -> Tuple [ int , Optional [ common . Part ]]: \"\"\"Read a single part indicated by ## Control foo.\"\"\" snake_dict : Dict [ str , str ] = {} # create reverse lookup of long snake name to short name needed for part for key , value in sections_dict . items (): snake_dict [ spaces_and_caps_to_snake ( value )] = key while 0 <= ii < len ( lines ): # look for ## Control foo - then read prose line = lines [ ii ] prefix = '## Control ' if line : if not line . startswith ( prefix ): raise TrestleError ( f 'Unexpected line in { const . EDITABLE_CONTENT } for control { control_id } : { line } ' ) part_name_long_raw = line [ len ( prefix ):] . strip () part_name_snake = spaces_and_caps_to_snake ( part_name_long_raw ) # if the long name isn't there use the snake version for the part # otherwise the part will have the desired short name for the corresponding section part_name = snake_dict . get ( part_name_snake , part_name_snake ) # use sections dict to find correct title otherwise use the title from the markdown part_title = sections_dict . get ( part_name , part_name_long_raw ) prose_lines = [] ii += 1 have_content = False while 0 <= ii < len ( lines ): line = lines [ ii ] if not line . startswith ( prefix ): if line : have_content = True prose_lines . append ( line ) ii += 1 continue break if have_content : prose = ' \\n ' . join ( prose_lines ) # strip leading / trailing new lines. prose = prose . strip ( ' \\n ' ) id_ = f ' { control_id } _ { part_name } ' part = common . Part ( id = id_ , name = part_name , prose = prose , title = part_title ) return ii , part ii += 1 return - 1 , None @staticmethod def read_new_alters_and_params ( control_path : pathlib . Path , required_sections_list : List [ str ]) -> Tuple [ str , List [ prof . Alter ], Dict [ str , Any ]]: \"\"\"Get parts for the markdown control corresponding to Editable Content - along with the set-parameter dict.\"\"\" control_id = control_path . stem new_alters : List [ prof . Alter ] = [] lines , header = ControlIOReader . _load_control_lines_and_header ( control_path ) # extract the sort_id if present in header sort_id = header . get ( const . SORT_ID , control_id ) # query header for mapping of short to long section names sections_dict : Dict [ str , str ] = header . get ( const . SECTIONS_TAG , {}) found_sections : List [ str ] = [] ii = 0 while 0 <= ii < len ( lines ): line = lines [ ii ] if line . startswith ( f '# { const . EDITABLE_CONTENT } ' ): ii += 1 while 0 <= ii < len ( lines ): ii , part = ControlIOReader . _read_added_part ( ii , lines , control_id , sections_dict ) if ii < 0 : break # if section is required and it hasn't been edited with prose raise error if part . name in required_sections_list and part . prose . startswith ( const . PROFILE_ADD_REQUIRED_SECTION_FOR_CONTROL_TEXT ): missing_section = sections_dict . get ( part . name , part . name ) raise TrestleError ( f 'Control { control_id } is missing prose for required section { missing_section } ' ) alter = prof . Alter ( control_id = control_id , adds = [ prof . Add ( parts = [ part ], position = 'after' , by_id = f ' { control_id } _smt' )] ) new_alters . append ( alter ) found_sections . append ( part . name ) else : ii += 1 missing_sections = set ( required_sections_list ) - set ( found_sections ) if missing_sections : raise TrestleError ( f 'Control { control_id } is missing required sections { missing_sections } ' ) param_dict : Dict [ str , Any ] = {} header_params = header . get ( const . SET_PARAMS_TAG , {}) if header_params : param_dict . update ( header_params ) return sort_id , new_alters , param_dict @staticmethod def param_values_as_str_list ( param : common . Parameter ) -> List [ str ]: \"\"\"Convert param values to list of strings.\"\"\" return [ val . __root__ for val in as_list ( param . values )] @staticmethod def param_values_as_str ( param : common . Parameter , brackets = False ) -> Optional [ str ]: \"\"\"Convert param values to string with optional brackets.\"\"\" if not param . values : return None values_str = ', ' . join ( ControlIOReader . param_values_as_str_list ( param )) return f '[ { values_str } ]' if brackets else values_str @staticmethod def param_selection_as_str ( param : common . Parameter , verbose = False , brackets = False ) -> str : \"\"\"Convert parameter selection to str.\"\"\" if param . select and param . select . choice : how_many_str = '' if param . select . how_many : how_many_str = 'one' if param . select . how_many == common . HowMany . one else 'one or more' choices_str = '; ' . join ( as_list ( param . select . choice )) choices_str = f '[ { choices_str } ]' if brackets else choices_str choices_str = f 'Choose { how_many_str } : { choices_str } ' if verbose else choices_str return choices_str return '' @staticmethod def param_label_choices_as_str ( param : common . Parameter , verbose = False , brackets = False ) -> str : \"\"\"Convert param label or choices to string, using choices if present.\"\"\" choices = ControlIOReader . param_selection_as_str ( param , verbose , brackets ) text = choices if choices else param . label text = text if text else param . id return text @staticmethod def param_to_str ( param : common . Parameter , param_rep : ParameterRep , verbose = False , brackets = False , params_format : Optional [ str ] = None , ) -> Optional [ str ]: \"\"\" Convert parameter to string based on best available representation. Args: param_rep: how to represent the parameter verbose: provide verbose text for selection choices brackets: add brackets around the lists of items params_format: a string containing a single dot that represents a form of highlighting around the param Returns: formatted string or None \"\"\" param_str = None if param_rep == ParameterRep . VALUE_OR_STRING_NONE : param_str = ControlIOReader . param_values_as_str ( param ) param_str = param_str if param_str else 'None' elif param_rep == ParameterRep . LABEL_OR_CHOICES : param_str = ControlIOReader . param_label_choices_as_str ( param , verbose , brackets ) elif param_rep == ParameterRep . VALUE_OR_LABEL_OR_CHOICES : param_str = ControlIOReader . param_values_as_str ( param ) if not param_str : param_str = ControlIOReader . param_label_choices_as_str ( param , verbose , brackets ) elif param_rep == ParameterRep . VALUE_OR_EMPTY_STRING : param_str = ControlIOReader . param_values_as_str ( param , brackets ) if not param_str : param_str = '' if param_str is not None and params_format : if params_format . count ( '.' ) > 1 : raise TrestleError ( f 'Additional text { params_format } ' f 'for the parameters cannot contain multiple dots (.)' ) param_str = params_format . replace ( '.' , param_str ) return param_str @staticmethod def str_to_param ( param : common . Parameter , param_str : str ) -> None : \"\"\"Replace parameter contents with contents in string.\"\"\" # this is a simple version that replaces the values but it can be more elaborate param . values = [ common . ParameterValue ( __root__ = param_str )] @staticmethod def get_control_param_dict ( control : cat . Control , values_only : bool , ) -> Dict [ str , common . Parameter ]: \"\"\" Create mapping of param id's to params. Args: control: the control containing params of interest values_only: only add params to the dict that have actual values Returns: Dictionary of param_id mapped to param Notes: Warning is given if there is a parameter with no ID \"\"\" param_dict : Dict [ str , common . Parameter ] = {} for param in as_list ( control . params ): if not param . id : logger . warning ( f 'Control { control . id } has parameter with no id. Ignoring.' ) if param . values or not values_only : param_dict [ param . id ] = param return param_dict @staticmethod def read_control ( control_path : pathlib . Path , set_parameters : bool ) -> Tuple [ cat . Control , str ]: \"\"\"Read the control and group title from the markdown file.\"\"\" control = gens . generate_sample_model ( cat . Control ) md_api = MarkdownAPI () yaml_header , control_tree = md_api . processor . process_markdown ( control_path ) control_titles = list ( control_tree . get_all_headers_for_level ( 1 )) if len ( control_titles ) == 0 : raise TrestleError ( f 'Control markdown: { control_path } contains no control title.' ) control . id , group_title , control . title = ControlIOReader . _parse_control_title_line ( control_titles [ 0 ]) control_headers = list ( control_tree . get_all_headers_for_level ( 2 )) if len ( control_headers ) == 0 : raise TrestleError ( f 'Control markdown: { control_path } contains no control statements.' ) control_statement = control_tree . get_node_for_key ( control_headers [ 0 ]) rc , statement_part = ControlIOReader . _read_control_statement ( 0 , control_statement . content . raw_text . split ( ' \\n ' ), control . id ) if rc < 0 : return control , group_title control . parts = [ statement_part ] if statement_part else None control_objective = control_tree . get_node_for_key ( '## Control Objective' ) if control_objective is not None : _ , objective_part = ControlIOReader . _read_control_objective ( 0 , control_objective . content . raw_text . split ( ' \\n ' ), control . id ) if objective_part : if control . parts : control . parts . append ( objective_part ) else : control . parts = [ objective_part ] for header_key in control_tree . get_all_headers_for_key ( '## Control' , False ): if header_key not in { control_headers [ 0 ], '## Control Objective' , control_titles [ 0 ]}: section_node = control_tree . get_node_for_key ( header_key ) _ , control . parts = ControlIOReader . _read_sections ( 0 , section_node . content . raw_text . split ( ' \\n ' ), control . id , control . parts ) if set_parameters : params : Dict [ str , str ] = yaml_header . get ( const . SET_PARAMS_TAG , []) if params : control . params = [] for id_ , param_dict in params . items (): param_dict [ 'id' ] = id_ param = ModelUtils . dict_to_parameter ( param_dict ) control . params . append ( param ) if const . SORT_ID in yaml_header : control . props = control . props if control . props else [] control . props . append ( common . Property ( name = const . SORT_ID , value = yaml_header [ const . SORT_ID ])) return control , group_title Methods \u00a4 get_control_param_dict ( control , values_only ) staticmethod \u00a4 Create mapping of param id's to params. Parameters: Name Type Description Default control Control the control containing params of interest required values_only bool only add params to the dict that have actual values required Returns: Type Description Dict[str, trestle.oscal.common.Parameter] Dictionary of param_id mapped to param Notes Warning is given if there is a parameter with no ID Source code in trestle/core/control_io.py @staticmethod def get_control_param_dict ( control : cat . Control , values_only : bool , ) -> Dict [ str , common . Parameter ]: \"\"\" Create mapping of param id's to params. Args: control: the control containing params of interest values_only: only add params to the dict that have actual values Returns: Dictionary of param_id mapped to param Notes: Warning is given if there is a parameter with no ID \"\"\" param_dict : Dict [ str , common . Parameter ] = {} for param in as_list ( control . params ): if not param . id : logger . warning ( f 'Control { control . id } has parameter with no id. Ignoring.' ) if param . values or not values_only : param_dict [ param . id ] = param return param_dict param_label_choices_as_str ( param , verbose = False , brackets = False ) staticmethod \u00a4 Convert param label or choices to string, using choices if present. Source code in trestle/core/control_io.py @staticmethod def param_label_choices_as_str ( param : common . Parameter , verbose = False , brackets = False ) -> str : \"\"\"Convert param label or choices to string, using choices if present.\"\"\" choices = ControlIOReader . param_selection_as_str ( param , verbose , brackets ) text = choices if choices else param . label text = text if text else param . id return text param_selection_as_str ( param , verbose = False , brackets = False ) staticmethod \u00a4 Convert parameter selection to str. Source code in trestle/core/control_io.py @staticmethod def param_selection_as_str ( param : common . Parameter , verbose = False , brackets = False ) -> str : \"\"\"Convert parameter selection to str.\"\"\" if param . select and param . select . choice : how_many_str = '' if param . select . how_many : how_many_str = 'one' if param . select . how_many == common . HowMany . one else 'one or more' choices_str = '; ' . join ( as_list ( param . select . choice )) choices_str = f '[ { choices_str } ]' if brackets else choices_str choices_str = f 'Choose { how_many_str } : { choices_str } ' if verbose else choices_str return choices_str return '' param_to_str ( param , param_rep , verbose = False , brackets = False , params_format = None ) staticmethod \u00a4 Convert parameter to string based on best available representation. Parameters: Name Type Description Default param_rep ParameterRep how to represent the parameter required verbose provide verbose text for selection choices False brackets add brackets around the lists of items False params_format Optional[str] a string containing a single dot that represents a form of highlighting around the param None Returns: Type Description Optional[str] formatted string or None Source code in trestle/core/control_io.py @staticmethod def param_to_str ( param : common . Parameter , param_rep : ParameterRep , verbose = False , brackets = False , params_format : Optional [ str ] = None , ) -> Optional [ str ]: \"\"\" Convert parameter to string based on best available representation. Args: param_rep: how to represent the parameter verbose: provide verbose text for selection choices brackets: add brackets around the lists of items params_format: a string containing a single dot that represents a form of highlighting around the param Returns: formatted string or None \"\"\" param_str = None if param_rep == ParameterRep . VALUE_OR_STRING_NONE : param_str = ControlIOReader . param_values_as_str ( param ) param_str = param_str if param_str else 'None' elif param_rep == ParameterRep . LABEL_OR_CHOICES : param_str = ControlIOReader . param_label_choices_as_str ( param , verbose , brackets ) elif param_rep == ParameterRep . VALUE_OR_LABEL_OR_CHOICES : param_str = ControlIOReader . param_values_as_str ( param ) if not param_str : param_str = ControlIOReader . param_label_choices_as_str ( param , verbose , brackets ) elif param_rep == ParameterRep . VALUE_OR_EMPTY_STRING : param_str = ControlIOReader . param_values_as_str ( param , brackets ) if not param_str : param_str = '' if param_str is not None and params_format : if params_format . count ( '.' ) > 1 : raise TrestleError ( f 'Additional text { params_format } ' f 'for the parameters cannot contain multiple dots (.)' ) param_str = params_format . replace ( '.' , param_str ) return param_str param_values_as_str ( param , brackets = False ) staticmethod \u00a4 Convert param values to string with optional brackets. Source code in trestle/core/control_io.py @staticmethod def param_values_as_str ( param : common . Parameter , brackets = False ) -> Optional [ str ]: \"\"\"Convert param values to string with optional brackets.\"\"\" if not param . values : return None values_str = ', ' . join ( ControlIOReader . param_values_as_str_list ( param )) return f '[ { values_str } ]' if brackets else values_str param_values_as_str_list ( param ) staticmethod \u00a4 Convert param values to list of strings. Source code in trestle/core/control_io.py @staticmethod def param_values_as_str_list ( param : common . Parameter ) -> List [ str ]: \"\"\"Convert param values to list of strings.\"\"\" return [ val . __root__ for val in as_list ( param . values )] read_all_implementation_prose_and_header ( control_file ) staticmethod \u00a4 Find all labels and associated prose in this control. Parameters: Name Type Description Default control_file Path path to the control markdown file required Returns: Type Description Tuple[Dict[str, Dict[str, List[str]]], Dict[str, List[str]]] Dictionary by comp_name of Dictionaries of part labels and corresponding prose read from the markdown file. Also returns the yaml header as dict in second part of tuple. This does not generate components - it only tracks component names and associated responses. Source code in trestle/core/control_io.py @staticmethod def read_all_implementation_prose_and_header ( control_file : pathlib . Path ) -> Tuple [ Dict [ str , Dict [ str , List [ str ]]], Dict [ str , List [ str ]]]: \"\"\" Find all labels and associated prose in this control. Args: control_file: path to the control markdown file Returns: Dictionary by comp_name of Dictionaries of part labels and corresponding prose read from the markdown file. Also returns the yaml header as dict in second part of tuple. This does not generate components - it only tracks component names and associated responses. \"\"\" comp_dict = {} yaml_header = {} # this level only adds for top level component but add_node_to_dict can add for other components comp_name = const . SSP_MAIN_COMP_NAME control_id = control_file . stem try : if not control_file . exists (): return comp_dict , yaml_header md_api = MarkdownAPI () yaml_header , control = md_api . processor . process_markdown ( control_file ) imp_string = 'Implementation' headers = control . get_all_headers_for_key ( imp_string , False ) header_list = list ( headers ) if not header_list : # if statement has no parts there is only one response for entire control headers = control . get_all_headers_for_key ( const . SSP_MD_IMPLEMENTATION_QUESTION , False ) # should be only one header, so warn if others found n_headers = 0 for header in headers : node = control . get_node_for_key ( header ) ControlIOReader . _add_node_to_dict ( comp_name , 'Statement' , comp_dict , node , control_id , []) n_headers += 1 if n_headers > 1 : logger . warning ( f 'Control { control_id } has single statement with extra response # { n_headers } ' ' when it should only have one.' ) else : for header in header_list : tokens = header . split ( ' ' , 2 ) if tokens [ 0 ] == '##' and tokens [ 1 ] == imp_string : label = tokens [ 2 ] . strip () node = control . get_node_for_key ( header ) ControlIOReader . _add_node_to_dict ( comp_name , label , comp_dict , node , control_id , []) except TrestleError as e : raise TrestleError ( f 'Error occurred reading { control_file } : { e } ' ) return comp_dict , yaml_header read_control ( control_path , set_parameters ) staticmethod \u00a4 Read the control and group title from the markdown file. Source code in trestle/core/control_io.py @staticmethod def read_control ( control_path : pathlib . Path , set_parameters : bool ) -> Tuple [ cat . Control , str ]: \"\"\"Read the control and group title from the markdown file.\"\"\" control = gens . generate_sample_model ( cat . Control ) md_api = MarkdownAPI () yaml_header , control_tree = md_api . processor . process_markdown ( control_path ) control_titles = list ( control_tree . get_all_headers_for_level ( 1 )) if len ( control_titles ) == 0 : raise TrestleError ( f 'Control markdown: { control_path } contains no control title.' ) control . id , group_title , control . title = ControlIOReader . _parse_control_title_line ( control_titles [ 0 ]) control_headers = list ( control_tree . get_all_headers_for_level ( 2 )) if len ( control_headers ) == 0 : raise TrestleError ( f 'Control markdown: { control_path } contains no control statements.' ) control_statement = control_tree . get_node_for_key ( control_headers [ 0 ]) rc , statement_part = ControlIOReader . _read_control_statement ( 0 , control_statement . content . raw_text . split ( ' \\n ' ), control . id ) if rc < 0 : return control , group_title control . parts = [ statement_part ] if statement_part else None control_objective = control_tree . get_node_for_key ( '## Control Objective' ) if control_objective is not None : _ , objective_part = ControlIOReader . _read_control_objective ( 0 , control_objective . content . raw_text . split ( ' \\n ' ), control . id ) if objective_part : if control . parts : control . parts . append ( objective_part ) else : control . parts = [ objective_part ] for header_key in control_tree . get_all_headers_for_key ( '## Control' , False ): if header_key not in { control_headers [ 0 ], '## Control Objective' , control_titles [ 0 ]}: section_node = control_tree . get_node_for_key ( header_key ) _ , control . parts = ControlIOReader . _read_sections ( 0 , section_node . content . raw_text . split ( ' \\n ' ), control . id , control . parts ) if set_parameters : params : Dict [ str , str ] = yaml_header . get ( const . SET_PARAMS_TAG , []) if params : control . params = [] for id_ , param_dict in params . items (): param_dict [ 'id' ] = id_ param = ModelUtils . dict_to_parameter ( param_dict ) control . params . append ( param ) if const . SORT_ID in yaml_header : control . props = control . props if control . props else [] control . props . append ( common . Property ( name = const . SORT_ID , value = yaml_header [ const . SORT_ID ])) return control , group_title read_implemented_requirement ( control_file , avail_comps ) staticmethod \u00a4 Get the implementated requirement associated with given control and link to existing components or new ones. Parameters: Name Type Description Default control_file Path path of the control markdown file required avail_comps Dict[str, trestle.oscal.ssp.SystemComponent] dictionary of known components keyed by component name required Returns: Type Description Tuple The control sort-id and the one implemented requirement for this control. Notes Each statement may have several responses, with each response in a by_component for a specific component. statement_map keeps track of statements that may have several by_component responses. Source code in trestle/core/control_io.py @staticmethod def read_implemented_requirement ( control_file : pathlib . Path , avail_comps : Dict [ str , ossp . SystemComponent ] ) -> Tuple [ str , ossp . ImplementedRequirement ]: \"\"\" Get the implementated requirement associated with given control and link to existing components or new ones. Args: control_file: path of the control markdown file avail_comps: dictionary of known components keyed by component name Returns: Tuple: The control sort-id and the one implemented requirement for this control. Notes: Each statement may have several responses, with each response in a by_component for a specific component. statement_map keeps track of statements that may have several by_component responses. \"\"\" control_id = control_file . stem comp_dict , header = ControlIOReader . read_all_implementation_prose_and_header ( control_file ) statement_map : Dict [ str , ossp . Statement ] = {} # create a new implemented requirement linked to the control id to hold the statements imp_req : ossp . ImplementedRequirement = gens . generate_sample_model ( ossp . ImplementedRequirement ) imp_req . control_id = control_id # the comp_dict captures all component names referenced by the control for comp_name in comp_dict . keys (): if comp_name in avail_comps : component = avail_comps [ comp_name ] else : # here is where we create a new component on the fly as needed component = gens . generate_sample_model ( ossp . SystemComponent ) component . title = comp_name avail_comps [ comp_name ] = component for label , prose_lines in comp_dict [ comp_name ] . items (): # create a statement to hold the by-components and assign the statement id if label == 'Statement' : statement_id = f ' { control_id } _smt' else : clean_label = label . strip ( '.' ) statement_id = ControlIOReader . _strip_to_make_ncname ( f ' { control_id } _smt. { clean_label } ' ) if statement_id in statement_map : statement = statement_map [ statement_id ] else : statement : ossp . Statement = gens . generate_sample_model ( ossp . Statement ) statement . statement_id = statement_id statement . by_components = [] statement_map [ statement_id ] = statement # create a new by-component to add to this statement by_comp : ossp . ByComponent = gens . generate_sample_model ( ossp . ByComponent ) # link it to the component uuid by_comp . component_uuid = component . uuid # add the response prose to the description by_comp . description = ' \\n ' . join ( prose_lines ) statement . by_components . append ( by_comp ) imp_req . statements = list ( statement_map . values ()) ControlIOReader . _insert_header_content ( imp_req , header , control_id ) sort_id = header . get ( const . SORT_ID , control_id ) return sort_id , imp_req read_new_alters_and_params ( control_path , required_sections_list ) staticmethod \u00a4 Get parts for the markdown control corresponding to Editable Content - along with the set-parameter dict. Source code in trestle/core/control_io.py @staticmethod def read_new_alters_and_params ( control_path : pathlib . Path , required_sections_list : List [ str ]) -> Tuple [ str , List [ prof . Alter ], Dict [ str , Any ]]: \"\"\"Get parts for the markdown control corresponding to Editable Content - along with the set-parameter dict.\"\"\" control_id = control_path . stem new_alters : List [ prof . Alter ] = [] lines , header = ControlIOReader . _load_control_lines_and_header ( control_path ) # extract the sort_id if present in header sort_id = header . get ( const . SORT_ID , control_id ) # query header for mapping of short to long section names sections_dict : Dict [ str , str ] = header . get ( const . SECTIONS_TAG , {}) found_sections : List [ str ] = [] ii = 0 while 0 <= ii < len ( lines ): line = lines [ ii ] if line . startswith ( f '# { const . EDITABLE_CONTENT } ' ): ii += 1 while 0 <= ii < len ( lines ): ii , part = ControlIOReader . _read_added_part ( ii , lines , control_id , sections_dict ) if ii < 0 : break # if section is required and it hasn't been edited with prose raise error if part . name in required_sections_list and part . prose . startswith ( const . PROFILE_ADD_REQUIRED_SECTION_FOR_CONTROL_TEXT ): missing_section = sections_dict . get ( part . name , part . name ) raise TrestleError ( f 'Control { control_id } is missing prose for required section { missing_section } ' ) alter = prof . Alter ( control_id = control_id , adds = [ prof . Add ( parts = [ part ], position = 'after' , by_id = f ' { control_id } _smt' )] ) new_alters . append ( alter ) found_sections . append ( part . name ) else : ii += 1 missing_sections = set ( required_sections_list ) - set ( found_sections ) if missing_sections : raise TrestleError ( f 'Control { control_id } is missing required sections { missing_sections } ' ) param_dict : Dict [ str , Any ] = {} header_params = header . get ( const . SET_PARAMS_TAG , {}) if header_params : param_dict . update ( header_params ) return sort_id , new_alters , param_dict str_to_param ( param , param_str ) staticmethod \u00a4 Replace parameter contents with contents in string. Source code in trestle/core/control_io.py @staticmethod def str_to_param ( param : common . Parameter , param_str : str ) -> None : \"\"\"Replace parameter contents with contents in string.\"\"\" # this is a simple version that replaces the values but it can be more elaborate param . values = [ common . ParameterValue ( __root__ = param_str )] ControlIOWriter \u00a4 Class to write controls as markdown. Source code in trestle/core/control_io.py class ControlIOWriter (): \"\"\"Class to write controls as markdown.\"\"\" def __init__ ( self ): \"\"\"Initialize the class.\"\"\" self . _md_file : Optional [ MDWriter ] = None @staticmethod def _wrap_label ( label : str ): l_side = '\\[' r_side = '\\]' wrapped = '' if label == '' else f ' { l_side }{ label }{ r_side } ' return wrapped @staticmethod def get_prop ( part_control : Union [ common . Part , cat . Control ], prop_name : str ) -> str : \"\"\"Get the property with that name.\"\"\" for prop in as_list ( part_control . props ): if prop . name . strip () . lower () == prop_name . strip () . lower (): return prop . value . strip () return '' @staticmethod def get_sort_id ( control : cat . Control , allow_none = False ) -> Optional [ str ]: \"\"\"Get the sort-id for the control.\"\"\" for prop in as_list ( control . props ): if prop . name == const . SORT_ID : return prop . value . strip () return None if allow_none else control . id @staticmethod def get_label ( part_control : Union [ common . Part , cat . Control ]) -> str : \"\"\"Get the label from the props of a part or control.\"\"\" return ControlIOWriter . get_prop ( part_control , 'label' ) def _get_part ( self , part : common . Part , item_type : str , skip_id : Optional [ str ]) -> List [ Union [ str , List [ str ]]]: \"\"\" Find parts with the specified item type, within the given part. For a part in a control find the parts in it that match the item_type Return list of string formatted labels and associated descriptive prose \"\"\" items = [] if part . name in [ 'statement' , item_type ]: # the options here are to force the label to be the part.id or the part.label # the label may be of the form (a) while the part.id is ac-1_smt.a.1.a # here we choose the latter and extract the final element label = ControlIOWriter . get_label ( part ) label = part . id . split ( '.' )[ - 1 ] if not label else label wrapped_label = self . _wrap_label ( label ) pad = '' if wrapped_label == '' or not part . prose else ' ' prose = '' if part . prose is None else part . prose # top level prose has already been written out, if present # use presence of . in id to tell if this is top level prose if part . id != skip_id : items . append ( f ' { wrapped_label }{ pad }{ prose } ' ) if part . parts : sub_list = [] for prt in part . parts : sub_list . extend ( self . _get_part ( prt , item_type , skip_id )) sub_list . append ( '' ) items . append ( sub_list ) return items def _add_part_and_its_items ( self , control : cat . Control , name : str , item_type : str ) -> None : \"\"\"For a given control add its one statement and its items to the md file after replacing params.\"\"\" items = [] if control . parts : for part in control . parts : if part . name == name : # If the part has prose write it as a raw line and not list element skip_id = part . id if part . prose : # need to avoid split lines in statement items self . _md_file . new_line ( part . prose . replace ( ' \\n ' , ' ' )) items . append ( self . _get_part ( part , item_type , skip_id )) # unwrap the list if it is many levels deep while not isinstance ( items , str ) and len ( items ) == 1 : items = items [ 0 ] self . _md_file . new_paragraph () self . _md_file . new_list ( items ) def _add_yaml_header ( self , yaml_header : Optional [ Dict ]) -> None : if yaml_header : self . _md_file . add_yaml_header ( yaml_header ) @staticmethod def _gap_join ( a_str : str , b_str : str ) -> str : a_clean = a_str . strip () b_clean = b_str . strip () if not b_clean : return a_clean gap = ' \\n ' if a_clean else '' return a_clean + gap + b_clean def _add_control_statement ( self , control : cat . Control , group_title : str , sections_dict : Optional [ Dict [ str , str ]] = None , capitalize_title = False ) -> None : \"\"\"Add the control statement and items to the md file.\"\"\" self . _md_file . new_paragraph () title = f ' { control . id } - \\[ { group_title } \\] { control . title } ' if capitalize_title : title = f ' { control . id . upper () } - \\[ { group_title . title () } \\] { control . title . title () } ' header_title = 'Control Statement' if sections_dict and sections_dict [ 'statement' ]: header_title = sections_dict [ 'statement' ] self . _md_file . new_header ( level = 1 , title = title ) self . _md_file . new_header ( level = 2 , title = header_title ) self . _md_file . set_indent_level ( - 1 ) self . _add_part_and_its_items ( control , 'statement' , 'item' ) self . _md_file . set_indent_level ( - 1 ) def _add_control_statement_ssp ( self , control : cat . Control ) -> None : \"\"\"Add the control statement and items to the markdown SSP.\"\"\" self . _md_file . new_paragraph () label = self . get_label ( control ) label = label if label else control . id . upper () title = f ' { label } - { control . title } ' self . _md_file . new_header ( level = 1 , title = title ) self . _md_file . new_header ( level = 2 , title = 'Control Statement' ) self . _md_file . set_indent_level ( - 1 ) self . _add_part_and_its_items ( control , 'statement' , 'item' ) self . _md_file . set_indent_level ( - 1 ) def _add_control_objective ( self , control : cat . Control , sections_dict : Optional [ Dict [ str , str ]] = None ) -> None : if control . parts : for part in control . parts : if part . name == 'objective' : self . _md_file . new_paragraph () heading_title = 'Control Objective' if sections_dict and sections_dict [ 'objective' ]: heading_title = sections_dict [ 'objective' ] self . _md_file . new_header ( level = 2 , title = heading_title ) self . _md_file . set_indent_level ( - 1 ) self . _add_part_and_its_items ( control , 'objective' , 'objective' ) self . _md_file . set_indent_level ( - 1 ) return @staticmethod def _get_control_section_part ( part : common . Part , section_name : str ) -> str : \"\"\"Get the prose for a named section in the control.\"\"\" prose = '' if part . name == section_name and part . prose is not None : prose = ControlIOWriter . _gap_join ( prose , part . prose ) if part . parts : for sub_part in part . parts : prose = ControlIOWriter . _gap_join ( prose , ControlIOWriter . _get_control_section_part ( sub_part , section_name ) ) return prose @staticmethod def _get_control_section_prose ( control : cat . Control , section_name : str ) -> str : prose = '' if control . parts : for part in control . parts : prose = ControlIOWriter . _gap_join ( prose , ControlIOWriter . _get_control_section_part ( part , section_name )) return prose @staticmethod def _find_section_info ( part : common . Part , skip_section_list : List [ str ]) -> Tuple [ str , str , str ]: \"\"\"Find section not in list.\"\"\" if part . prose and part . name not in skip_section_list : return part . id , part . name , part . title if part . parts : for sub_part in part . parts : id_ , name , title = ControlIOWriter . _find_section_info ( sub_part , skip_section_list ) if id_ : return id_ , name , title return '' , '' , '' @staticmethod def _find_section ( control : cat . Control , skip_section_list : List [ str ]) -> Tuple [ str , str , str ]: \"\"\"Find next section not in list.\"\"\" if control . parts : for part in control . parts : id_ , name , title = ControlIOWriter . _find_section_info ( part , skip_section_list ) if id_ : return id_ , name , title return '' , '' , '' @staticmethod def _get_section ( control : cat . Control , skip_section_list : List [ str ]) -> Tuple [ str , str , str , str ]: \"\"\"Get sections that are not in the list.\"\"\" id_ , name , title = ControlIOWriter . _find_section ( control , skip_section_list ) if id_ : return id_ , name , title , ControlIOWriter . _get_control_section_prose ( control , name ) return '' , '' , '' , '' def _add_sections ( self , control : cat . Control , allowed_sections : Optional [ List [ str ]]) -> None : \"\"\"Add the extra control sections after the main ones.\"\"\" skip_section_list = [ 'statement' , 'item' , 'objective' ] while True : _ , name , title , prose = self . _get_section ( control , skip_section_list ) if not name : return if allowed_sections and name not in allowed_sections : skip_section_list . append ( name ) continue if prose : # section title will be from the section_dict, the part title, or the part name in that order # this way the user-provided section title can override the part title section_title = self . _sections_dict . get ( name , title ) if self . _sections_dict else title section_title = section_title if section_title else name skip_section_list . append ( name ) self . _md_file . new_header ( level = 2 , title = f 'Control { section_title } ' ) self . _md_file . new_line ( prose ) self . _md_file . new_paragraph () def _add_one_section ( self , control : cat . Control , section : str ) -> None : \"\"\"Add specific control section.\"\"\" prose = ControlIOWriter . _get_control_section_prose ( control , section ) if prose : section_title = self . _sections_dict . get ( section ) if self . _sections_dict else section section_title = section_title if section_title else section self . _md_file . new_header ( level = 2 , title = f 'Control { section_title } ' ) self . _md_file . new_line ( prose ) self . _md_file . new_paragraph () def _insert_existing_text ( self , part_label : str , existing_text : Dict [ str , List [ str ]]) -> None : \"\"\"Insert text captured in the previous markdown and reinsert to avoid overwrite.\"\"\" if part_label in existing_text : self . _md_file . new_paragraph () for line in existing_text [ part_label ]: self . _md_file . new_line ( line ) def _add_implementation_response_prompts ( self , control : cat . Control , comp_dict : Dict [ str , Dict [ str , List [ str ]]] ) -> None : \"\"\"Add the response request text for all parts to the markdown along with the header.\"\"\" self . _md_file . new_hr () self . _md_file . new_paragraph () self . _md_file . new_header ( level = 2 , title = f ' { const . SSP_MD_IMPLEMENTATION_QUESTION } ' ) # if the control has no parts written out then enter implementation in the top level entry # but if it does have parts written out, leave top level blank and provide details in the parts # Note that parts corresponding to sections don't get written out here so a check is needed # If we have responses per component then enter them in separate ### sections did_write_part = False if control . parts : for part in control . parts : if part . parts : if part . name == 'statement' : for prt in part . parts : if prt . name != 'item' : continue if not did_write_part : self . _md_file . new_line ( const . SSP_MD_LEAVE_BLANK_TEXT ) # insert extra line to make mdformat happy self . _md_file . _add_line_raw ( '' ) self . _md_file . new_hr () # if no label guess the label from the sub-part id part_label = self . get_label ( prt ) part_label = prt . id . split ( '.' )[ - 1 ] if not part_label else part_label self . _md_file . new_header ( level = 2 , title = f 'Implementation { part_label } ' ) added_content = False for comp_name , prose_dict in comp_dict . items (): if part_label in prose_dict : if comp_name != const . SSP_MAIN_COMP_NAME : self . _md_file . new_header ( level = 3 , title = comp_name ) self . _insert_existing_text ( part_label , prose_dict ) added_content = True self . _md_file . new_paragraph () if not added_content : self . _md_file . new_line ( f ' { const . SSP_ADD_IMPLEMENTATION_FOR_ITEM_TEXT } { prt . id } ' ) did_write_part = True # if we loaded nothing for this control yet then it must need a fresh prompt for the control statement if not comp_dict and not did_write_part : self . _md_file . new_line ( f ' { const . SSP_ADD_IMPLEMENTATION_FOR_CONTROL_TEXT } { control . id } ' ) part_label = 'Statement' for comp_name , prose_dict in comp_dict . items (): if part_label in prose_dict : if comp_name != const . SSP_MAIN_COMP_NAME : self . _md_file . new_header ( level = 3 , title = comp_name ) self . _insert_existing_text ( part_label , prose_dict ) self . _md_file . new_hr () @staticmethod def _get_adds ( control_id : str , profile : prof . Profile ) -> List [ Tuple [ str , str ]]: adds = [] if profile and profile . modify and profile . modify . alters : for alter in profile . modify . alters : if alter . control_id == control_id and alter . adds : for add in alter . adds : if add . parts : for part in add . parts : if part . prose : adds . append (( part . name , part . prose )) return adds def _add_additional_content ( self , control : cat . Control , profile : prof . Profile ) -> List [ str ]: adds = ControlIOWriter . _get_adds ( control . id , profile ) has_content = len ( adds ) > 0 self . _md_file . new_header ( level = 1 , title = const . EDITABLE_CONTENT ) self . _md_file . new_line ( '<!-- Make additions and edits below -->' ) self . _md_file . new_line ( '<!-- The above represents the contents of the control as received by the profile, prior to additions. -->' # noqa E501 ) self . _md_file . new_line ( '<!-- If the profile makes additions to the control, they will appear below. -->' # noqa E501 ) self . _md_file . new_line ( '<!-- The above markdown may not be edited but you may edit the content below, and/or introduce new additions to be made by the profile. -->' # noqa E501 ) self . _md_file . new_line ( '<!-- If there is a yaml header at the top, parameter values may be edited. Use --set-parameters to incorporate the changes during assembly. -->' # noqa E501 ) self . _md_file . new_line ( '<!-- The content here will then replace what is in the profile for this control, after running profile-assemble. -->' # noqa E501 ) if has_content : self . _md_file . new_line ( '<!-- The added parts in the profile for this control are below. You may edit them and/or add new ones. -->' # noqa E501 ) else : self . _md_file . new_line ( '<!-- The current profile has no added parts for this control, but you may add new ones here. -->' ) self . _md_file . new_line ( '<!-- Each addition must have a heading of the form ## Control my_addition_name -->' ) self . _md_file . new_line ( '<!-- See https://ibm.github.io/compliance-trestle/tutorials/ssp_profile_catalog_authoring/ssp_profile_catalog_authoring for guidance. -->' # noqa E501 ) # next is to make mdformat happy self . _md_file . _add_line_raw ( '' ) added_sections : List [ str ] = [] for add in adds : name , prose = add title = self . _sections_dict . get ( name , name ) if self . _sections_dict else name self . _md_file . new_header ( level = 2 , title = f 'Control { title } ' ) self . _md_file . new_paraline ( prose ) added_sections . append ( name ) return added_sections @staticmethod def get_part_prose ( control : cat . Control , part_name : str ) -> str : \"\"\"Get the prose for a named part.\"\"\" prose = '' if control . parts : for part in control . parts : prose += ControlIOWriter . _get_control_section_part ( part , part_name ) return prose . strip () @staticmethod def merge_dicts_deep ( dest : Dict [ Any , Any ], src : Dict [ Any , Any ], overwrite_header_values : bool ) -> None : \"\"\" Merge dict src into dest. New items are always added from src to dest. Items present in both will be overriden dest if overwrite_header_values is True. \"\"\" for key in src . keys (): if key in dest : # if they are both dicts, recurse if isinstance ( dest [ key ], dict ) and isinstance ( src [ key ], dict ): ControlIOWriter . merge_dicts_deep ( dest [ key ], src [ key ], overwrite_header_values ) # otherwise override dest if needed elif overwrite_header_values : dest [ key ] = src [ key ] else : # if the item was not already in dest, add it from src dest [ key ] = src [ key ] def _prompt_required_sections ( self , required_sections : List [ str ], added_sections : List [ str ]) -> None : \"\"\"Add prompts for any required sections that haven't already been written out.\"\"\" missing_sections = set ( required_sections ) . difference ( added_sections ) for section in missing_sections : section_title = self . _sections_dict . get ( section , section ) self . _md_file . new_header ( 2 , f 'Control { section_title } ' ) self . _md_file . new_line ( f ' { const . PROFILE_ADD_REQUIRED_SECTION_FOR_CONTROL_TEXT } : { section_title } ' ) @staticmethod def is_withdrawn ( control : cat . Control ) -> bool : \"\"\" Determine if control is marked Withdrawn. Args: control: The control that may be marked withdrawn. Returns: True if marked withdrawn, false otherwise. This is determined by property with name 'status' with value 'Withdrawn'. \"\"\" for prop in as_list ( control . props ): if prop . name and prop . value : if prop . name . lower () . strip () == 'status' and prop . value . lower () . strip () == 'withdrawn' : return True return False def write_control_for_editing ( self , dest_path : pathlib . Path , control : cat . Control , group_title : str , yaml_header : Optional [ Dict ], sections_dict : Optional [ Dict [ str , str ]], additional_content : bool , prompt_responses : bool , profile : Optional [ prof . Profile ], overwrite_header_values : bool , required_sections : Optional [ List [ str ]], allowed_sections : Optional [ List [ str ]] ) -> None : \"\"\" Write out the control in markdown format into the specified directory. Args: dest_path: Path to the directory where the control will be written control: The control to write as markdown group_title: Title of the group containing the control yaml_header: Optional dict to be written as markdown yaml header sections_dict: Optional dict mapping short section names to long additional_content: Should the additional content be printed corresponding to profile adds prompt_responses: Should the markdown include prompts for implementation detail responses profile: Profile containing the adds making up additional content overwrite_header_values: Overwrite existing values in markdown header content but add new content required_sections: List of required sections that may need prompting for content allowed_sections: List of allowed sections that will appear in markdown Returns: None Notes: The filename is constructed from the control's id, so only the markdown directory is required. If a yaml header is present in the file, new values in provided header will not replace those in the markdown header unless overwrite_header_values is true. If it is true then overwrite any existing values, but in all cases new items from the provided header will be added to the markdown header. If the markdown file already exists, its current header and prose are read. Controls are checked if they are marked withdrawn, and if so they are not written out. \"\"\" if ControlIOWriter . is_withdrawn ( control ): logger . debug ( f 'Not writing out control { control . id } since it is marked Withdrawn.' ) return control_file = dest_path / ( control . id + '.md' ) # first read the existing markdown header and content if it exists existing_text , header = ControlIOReader . read_all_implementation_prose_and_header ( control_file ) self . _md_file = MDWriter ( control_file ) self . _sections_dict = sections_dict merged_header = copy . deepcopy ( header ) # if the control has an explicitly defined sort-id and there is none in the yaml_header, then insert it # in the yaml header and allow overwrite_header_values to control whether it overwrites an existing one # in the markdown header yaml_header = yaml_header if yaml_header else {} sort_id = ControlIOWriter . get_sort_id ( control , True ) if sort_id and const . SORT_ID not in yaml_header : yaml_header [ const . SORT_ID ] = sort_id ControlIOWriter . merge_dicts_deep ( merged_header , yaml_header , overwrite_header_values ) # merge any provided sections with sections in the header, with overwrite header_sections_dict = merged_header . get ( const . SECTIONS_TAG , {}) if sections_dict : header_sections_dict . update ( sections_dict ) if header_sections_dict : merged_header [ const . SECTIONS_TAG ] = header_sections_dict self . _add_yaml_header ( merged_header ) self . _add_control_statement ( control , group_title ) self . _add_control_objective ( control ) # add allowed sections to the markdown self . _add_sections ( control , allowed_sections ) # only used for ssp-generate if prompt_responses : self . _add_implementation_response_prompts ( control , existing_text ) # only used for profile-generate # add sections corresponding to added parts in the profile added_sections : List [ str ] = [] if additional_content : added_sections = self . _add_additional_content ( control , profile ) if required_sections : self . _prompt_required_sections ( required_sections , added_sections ) self . _md_file . write_out () def write_control_with_sections ( self , control : cat . Control , group_title : str , sections : List [ str ], sections_dict : Optional [ Dict [ str , str ]] = None , label_column : bool = True ) -> str : \"\"\"Write the control into markdown file with specified sections.\"\"\" self . _md_file = MDWriter ( None ) self . _sections_dict = sections_dict if not isinstance ( group_title , str ): raise TrestleError ( f 'Group title must be provided and be a string, instead received: { group_title } ' ) for section in sections : if 'statement' == section : self . _add_control_statement ( control , group_title , sections_dict , True ) elif 'objective' == section : self . _add_control_objective ( control , sections_dict ) elif 'table_of_parameters' == section : self . get_params ( control , label_column , self . _md_file ) else : self . _add_one_section ( control , section ) return ' \\n ' . join ( self . _md_file . _lines ) def get_control_statement ( self , control : cat . Control ) -> List [ str ]: \"\"\"Get the control statement as formatted markdown from a control.\"\"\" self . _md_file = MDWriter ( None ) self . _add_control_statement_ssp ( control ) return self . _md_file . get_lines () def get_params ( self , control : cat . Control , label_column = False , md_file = None ) -> List [ str ]: \"\"\"Get parameters of a control as a markdown table for ssp_io, with optional third label column.\"\"\" reader = ControlIOReader () param_dict = reader . get_control_param_dict ( control , False ) if param_dict : if md_file : self . _md_file = md_file else : self . _md_file = MDWriter ( None ) self . _md_file . new_paragraph () self . _md_file . set_indent_level ( - 1 ) if label_column : self . _md_file . new_table ( [ [ key , ControlIOReader . param_to_str ( param_dict [ key ], ParameterRep . VALUE_OR_EMPTY_STRING ), ControlIOReader . param_to_str ( param_dict [ key ], ParameterRep . LABEL_OR_CHOICES , True ), ] for key in param_dict . keys () ], [ 'Parameter ID' , 'Values' , 'Label or Choices' ] ) else : self . _md_file . new_table ( [ [ key , ControlIOReader . param_to_str ( param_dict [ key ], ParameterRep . VALUE_OR_LABEL_OR_CHOICES )] for key in param_dict . keys () ], [ 'Parameter ID' , 'Values' ] ) self . _md_file . set_indent_level ( - 1 ) return self . _md_file . get_lines () return [] Methods \u00a4 __init__ ( self ) special \u00a4 Initialize the class. Source code in trestle/core/control_io.py def __init__ ( self ): \"\"\"Initialize the class.\"\"\" self . _md_file : Optional [ MDWriter ] = None get_control_statement ( self , control ) \u00a4 Get the control statement as formatted markdown from a control. Source code in trestle/core/control_io.py def get_control_statement ( self , control : cat . Control ) -> List [ str ]: \"\"\"Get the control statement as formatted markdown from a control.\"\"\" self . _md_file = MDWriter ( None ) self . _add_control_statement_ssp ( control ) return self . _md_file . get_lines () get_label ( part_control ) staticmethod \u00a4 Get the label from the props of a part or control. Source code in trestle/core/control_io.py @staticmethod def get_label ( part_control : Union [ common . Part , cat . Control ]) -> str : \"\"\"Get the label from the props of a part or control.\"\"\" return ControlIOWriter . get_prop ( part_control , 'label' ) get_params ( self , control , label_column = False , md_file = None ) \u00a4 Get parameters of a control as a markdown table for ssp_io, with optional third label column. Source code in trestle/core/control_io.py def get_params ( self , control : cat . Control , label_column = False , md_file = None ) -> List [ str ]: \"\"\"Get parameters of a control as a markdown table for ssp_io, with optional third label column.\"\"\" reader = ControlIOReader () param_dict = reader . get_control_param_dict ( control , False ) if param_dict : if md_file : self . _md_file = md_file else : self . _md_file = MDWriter ( None ) self . _md_file . new_paragraph () self . _md_file . set_indent_level ( - 1 ) if label_column : self . _md_file . new_table ( [ [ key , ControlIOReader . param_to_str ( param_dict [ key ], ParameterRep . VALUE_OR_EMPTY_STRING ), ControlIOReader . param_to_str ( param_dict [ key ], ParameterRep . LABEL_OR_CHOICES , True ), ] for key in param_dict . keys () ], [ 'Parameter ID' , 'Values' , 'Label or Choices' ] ) else : self . _md_file . new_table ( [ [ key , ControlIOReader . param_to_str ( param_dict [ key ], ParameterRep . VALUE_OR_LABEL_OR_CHOICES )] for key in param_dict . keys () ], [ 'Parameter ID' , 'Values' ] ) self . _md_file . set_indent_level ( - 1 ) return self . _md_file . get_lines () return [] get_part_prose ( control , part_name ) staticmethod \u00a4 Get the prose for a named part. Source code in trestle/core/control_io.py @staticmethod def get_part_prose ( control : cat . Control , part_name : str ) -> str : \"\"\"Get the prose for a named part.\"\"\" prose = '' if control . parts : for part in control . parts : prose += ControlIOWriter . _get_control_section_part ( part , part_name ) return prose . strip () get_prop ( part_control , prop_name ) staticmethod \u00a4 Get the property with that name. Source code in trestle/core/control_io.py @staticmethod def get_prop ( part_control : Union [ common . Part , cat . Control ], prop_name : str ) -> str : \"\"\"Get the property with that name.\"\"\" for prop in as_list ( part_control . props ): if prop . name . strip () . lower () == prop_name . strip () . lower (): return prop . value . strip () return '' get_sort_id ( control , allow_none = False ) staticmethod \u00a4 Get the sort-id for the control. Source code in trestle/core/control_io.py @staticmethod def get_sort_id ( control : cat . Control , allow_none = False ) -> Optional [ str ]: \"\"\"Get the sort-id for the control.\"\"\" for prop in as_list ( control . props ): if prop . name == const . SORT_ID : return prop . value . strip () return None if allow_none else control . id is_withdrawn ( control ) staticmethod \u00a4 Determine if control is marked Withdrawn. Parameters: Name Type Description Default control Control The control that may be marked withdrawn. required Returns: Type Description bool True if marked withdrawn, false otherwise. This is determined by property with name 'status' with value 'Withdrawn'. Source code in trestle/core/control_io.py @staticmethod def is_withdrawn ( control : cat . Control ) -> bool : \"\"\" Determine if control is marked Withdrawn. Args: control: The control that may be marked withdrawn. Returns: True if marked withdrawn, false otherwise. This is determined by property with name 'status' with value 'Withdrawn'. \"\"\" for prop in as_list ( control . props ): if prop . name and prop . value : if prop . name . lower () . strip () == 'status' and prop . value . lower () . strip () == 'withdrawn' : return True return False merge_dicts_deep ( dest , src , overwrite_header_values ) staticmethod \u00a4 Merge dict src into dest. New items are always added from src to dest. Items present in both will be overriden dest if overwrite_header_values is True. Source code in trestle/core/control_io.py @staticmethod def merge_dicts_deep ( dest : Dict [ Any , Any ], src : Dict [ Any , Any ], overwrite_header_values : bool ) -> None : \"\"\" Merge dict src into dest. New items are always added from src to dest. Items present in both will be overriden dest if overwrite_header_values is True. \"\"\" for key in src . keys (): if key in dest : # if they are both dicts, recurse if isinstance ( dest [ key ], dict ) and isinstance ( src [ key ], dict ): ControlIOWriter . merge_dicts_deep ( dest [ key ], src [ key ], overwrite_header_values ) # otherwise override dest if needed elif overwrite_header_values : dest [ key ] = src [ key ] else : # if the item was not already in dest, add it from src dest [ key ] = src [ key ] write_control_for_editing ( self , dest_path , control , group_title , yaml_header , sections_dict , additional_content , prompt_responses , profile , overwrite_header_values , required_sections , allowed_sections ) \u00a4 Write out the control in markdown format into the specified directory. Parameters: Name Type Description Default dest_path Path Path to the directory where the control will be written required control Control The control to write as markdown required group_title str Title of the group containing the control required yaml_header Optional[Dict] Optional dict to be written as markdown yaml header required sections_dict Optional[Dict[str, str]] Optional dict mapping short section names to long required additional_content bool Should the additional content be printed corresponding to profile adds required prompt_responses bool Should the markdown include prompts for implementation detail responses required profile Optional[trestle.oscal.profile.Profile] Profile containing the adds making up additional content required overwrite_header_values bool Overwrite existing values in markdown header content but add new content required required_sections Optional[List[str]] List of required sections that may need prompting for content required allowed_sections Optional[List[str]] List of allowed sections that will appear in markdown required Returns: Type Description None None Notes The filename is constructed from the control's id, so only the markdown directory is required. If a yaml header is present in the file, new values in provided header will not replace those in the markdown header unless overwrite_header_values is true. If it is true then overwrite any existing values, but in all cases new items from the provided header will be added to the markdown header. If the markdown file already exists, its current header and prose are read. Controls are checked if they are marked withdrawn, and if so they are not written out. Source code in trestle/core/control_io.py def write_control_for_editing ( self , dest_path : pathlib . Path , control : cat . Control , group_title : str , yaml_header : Optional [ Dict ], sections_dict : Optional [ Dict [ str , str ]], additional_content : bool , prompt_responses : bool , profile : Optional [ prof . Profile ], overwrite_header_values : bool , required_sections : Optional [ List [ str ]], allowed_sections : Optional [ List [ str ]] ) -> None : \"\"\" Write out the control in markdown format into the specified directory. Args: dest_path: Path to the directory where the control will be written control: The control to write as markdown group_title: Title of the group containing the control yaml_header: Optional dict to be written as markdown yaml header sections_dict: Optional dict mapping short section names to long additional_content: Should the additional content be printed corresponding to profile adds prompt_responses: Should the markdown include prompts for implementation detail responses profile: Profile containing the adds making up additional content overwrite_header_values: Overwrite existing values in markdown header content but add new content required_sections: List of required sections that may need prompting for content allowed_sections: List of allowed sections that will appear in markdown Returns: None Notes: The filename is constructed from the control's id, so only the markdown directory is required. If a yaml header is present in the file, new values in provided header will not replace those in the markdown header unless overwrite_header_values is true. If it is true then overwrite any existing values, but in all cases new items from the provided header will be added to the markdown header. If the markdown file already exists, its current header and prose are read. Controls are checked if they are marked withdrawn, and if so they are not written out. \"\"\" if ControlIOWriter . is_withdrawn ( control ): logger . debug ( f 'Not writing out control { control . id } since it is marked Withdrawn.' ) return control_file = dest_path / ( control . id + '.md' ) # first read the existing markdown header and content if it exists existing_text , header = ControlIOReader . read_all_implementation_prose_and_header ( control_file ) self . _md_file = MDWriter ( control_file ) self . _sections_dict = sections_dict merged_header = copy . deepcopy ( header ) # if the control has an explicitly defined sort-id and there is none in the yaml_header, then insert it # in the yaml header and allow overwrite_header_values to control whether it overwrites an existing one # in the markdown header yaml_header = yaml_header if yaml_header else {} sort_id = ControlIOWriter . get_sort_id ( control , True ) if sort_id and const . SORT_ID not in yaml_header : yaml_header [ const . SORT_ID ] = sort_id ControlIOWriter . merge_dicts_deep ( merged_header , yaml_header , overwrite_header_values ) # merge any provided sections with sections in the header, with overwrite header_sections_dict = merged_header . get ( const . SECTIONS_TAG , {}) if sections_dict : header_sections_dict . update ( sections_dict ) if header_sections_dict : merged_header [ const . SECTIONS_TAG ] = header_sections_dict self . _add_yaml_header ( merged_header ) self . _add_control_statement ( control , group_title ) self . _add_control_objective ( control ) # add allowed sections to the markdown self . _add_sections ( control , allowed_sections ) # only used for ssp-generate if prompt_responses : self . _add_implementation_response_prompts ( control , existing_text ) # only used for profile-generate # add sections corresponding to added parts in the profile added_sections : List [ str ] = [] if additional_content : added_sections = self . _add_additional_content ( control , profile ) if required_sections : self . _prompt_required_sections ( required_sections , added_sections ) self . _md_file . write_out () write_control_with_sections ( self , control , group_title , sections , sections_dict = None , label_column = True ) \u00a4 Write the control into markdown file with specified sections. Source code in trestle/core/control_io.py def write_control_with_sections ( self , control : cat . Control , group_title : str , sections : List [ str ], sections_dict : Optional [ Dict [ str , str ]] = None , label_column : bool = True ) -> str : \"\"\"Write the control into markdown file with specified sections.\"\"\" self . _md_file = MDWriter ( None ) self . _sections_dict = sections_dict if not isinstance ( group_title , str ): raise TrestleError ( f 'Group title must be provided and be a string, instead received: { group_title } ' ) for section in sections : if 'statement' == section : self . _add_control_statement ( control , group_title , sections_dict , True ) elif 'objective' == section : self . _add_control_objective ( control , sections_dict ) elif 'table_of_parameters' == section : self . get_params ( control , label_column , self . _md_file ) else : self . _add_one_section ( control , section ) return ' \\n ' . join ( self . _md_file . _lines ) ParameterRep ( Enum ) \u00a4 Enum for ways to represent a parameter. Source code in trestle/core/control_io.py class ParameterRep ( Enum ): \"\"\"Enum for ways to represent a parameter.\"\"\" LEAVE_MOUSTACHE = 0 VALUE_OR_STRING_NONE = 1 LABEL_OR_CHOICES = 2 VALUE_OR_LABEL_OR_CHOICES = 3 VALUE_OR_EMPTY_STRING = 4 LABEL_OR_CHOICES \u00a4 LEAVE_MOUSTACHE \u00a4 VALUE_OR_EMPTY_STRING \u00a4 VALUE_OR_LABEL_OR_CHOICES \u00a4 VALUE_OR_STRING_NONE \u00a4 handler: python","title":"control_io"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io","text":"Handle direct i/o reading and writing controls as markdown.","title":"control_io"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOReader","text":"Class to read controls from markdown. Source code in trestle/core/control_io.py class ControlIOReader (): \"\"\"Class to read controls from markdown.\"\"\" @staticmethod def _strip_to_make_ncname ( label : str ) -> str : \"\"\"Strip chars to conform with NCNAME regex.\"\"\" orig_label = label # make sure first char is allowed while label and label [ 0 ] not in const . NCNAME_UTF8_FIRST_CHAR_OPTIONS : label = label [ 1 :] new_label = label [: 1 ] # now check remaining chars if len ( label ) > 1 : for ii in range ( 1 , len ( label )): if label [ ii ] in const . NCNAME_UTF8_OTHER_CHAR_OPTIONS : new_label += label [ ii ] # do final check to confirm it is NCNAME match = re . search ( const . NCNAME_REGEX , new_label ) if not match : raise TrestleError ( f 'Unable to convert label { orig_label } to NCNAME format.' ) return new_label @staticmethod def _load_control_lines_and_header ( control_file : pathlib . Path ) -> Tuple [ List [ str ], Dict [ str , Any ]]: lines : List [ str ] = [] try : content = control_file . open ( 'r' , encoding = const . FILE_ENCODING ) . read () except UnicodeDecodeError as e : logger . debug ( f 'See: { const . WEBSITE_ROOT } /errors/#utf-8-encoding-only' ) raise TrestleError ( f 'Unable to load file due to utf-8 encoding issues: { e } ' ) try : fm = frontmatter . loads ( content ) except Exception as e : logger . error ( f 'Error parsing yaml header from file { control_file } . ' f 'This is most likely due to an incorrect yaml structure.' ) raise TrestleError ( f 'Failure parsing yaml header on file { control_file } : { e } ' ) raw_lines = fm . content . split ( ' \\n ' ) header = fm . metadata # Any fully blank lines will be retained but as empty strings lines = [ line . strip ( ' \\r\\n ' ) . rstrip () for line in raw_lines ] clean_lines = [] # need to keep indentation and empty lines for line in lines : if line . startswith ( '<!--' ) or line . startswith ( '__________________' ): continue clean_lines . append ( line ) return clean_lines , header @staticmethod def _parse_control_title_line ( line : str ) -> Tuple [ int , str , str ]: \"\"\"Process the title line and extract the control id, group title (in brackets) and control title.\"\"\" if line . count ( '-' ) == 0 : raise TrestleError ( f 'Markdown control title format error, missing - after control id: { line } ' ) split_line = line . split () if len ( split_line ) < 3 or split_line [ 2 ] != '-' : raise TrestleError ( f 'Cannot parse control markdown title for control_id group and title: { line } ' ) # first token after the # control_id = split_line [ 1 ] group_title_start = line . find ( '\\[' ) group_title_end = line . find ( '\\]' ) if group_title_start < 0 or group_title_end < 0 or group_title_start > group_title_end : raise TrestleError ( f 'unable to read group title for control { control_id } ' ) group_title = line [ group_title_start + 2 : group_title_end ] . strip () control_title = line [ group_title_end + 2 :] . strip () return control_id , group_title , control_title @staticmethod def _indent ( line : str ) -> int : \"\"\"Measure indent of non-empty line.\"\"\" if not line : raise TrestleError ( 'Empty line queried for indent.' ) if line [ 0 ] not in [ ' ' , '-' ]: return - 1 for ii in range ( len ( line )): if line [ ii ] == '-' : return ii # if line is indented it must start with - if line [ ii ] != ' ' : break raise TrestleError ( f 'List elements must start with -: { line } ' ) @staticmethod def _get_next_line ( ii : int , lines : List [ str ]) -> Tuple [ int , str ]: while ii < len ( lines ): line = lines [ ii ] if line : return ii , line ii += 1 return - 1 , '' @staticmethod def _get_next_indent ( ii : int , lines : List [ str ]) -> Tuple [ int , int , str ]: \"\"\"Seek to next content line. ii remains at line read.\"\"\" while 0 <= ii < len ( lines ): line = lines [ ii ] if line : if line [ 0 ] == '#' : return ii , - 1 , line indent = ControlIOReader . _indent ( line ) if indent >= 0 : # extract text after - start = indent + 1 while start < len ( line ) and line [ start ] == ' ' : start += 1 if start >= len ( line ): raise TrestleError ( f 'Invalid line { line } ' ) return ii , indent , line [ start :] return ii , indent , line ii += 1 return ii , - 1 , '' @staticmethod def _read_part_id_prose ( line : str ) -> Tuple [ str , str ]: \"\"\"Extract the part id letter or number and prose from line.\"\"\" start = line . find ( ' \\\\ [' ) end = line . find ( ' \\\\ ]' ) prose = line . strip () if start < 0 else line [ end + 2 :] . strip () id_ = '' if start < 0 or end < 0 else line [ start + 2 : end ] return id_ , prose @staticmethod def _bump_label ( label : str ) -> str : \"\"\" Find next label given a string of 1 or more pure letters or digits. The input must be either a string of digits or a string of ascii letters - or empty string. \"\"\" if not label : return 'a' if label [ 0 ] in string . digits : return str ( int ( label ) + 1 ) if len ( label ) == 1 and label [ 0 ] . lower () < 'z' : return chr ( ord ( label [ 0 ]) + 1 ) # if this happens to be a string of letters, force it lowercase and bump label = label . lower () factor = 1 value = 0 # delta is needed because a counts as 0 when first value on right, but 1 for all others delta = 0 for letter in label [:: - 1 ]: value += ( ord ( letter ) - ord ( 'a' ) + delta ) * factor factor *= 26 delta = 1 value += 1 new_label = '' delta = 0 while value > 0 : new_label += chr ( ord ( 'a' ) + value % 26 - delta ) value = value // 26 delta = 1 return new_label [:: - 1 ] @staticmethod def _create_next_label ( prev_label : str , indent : int ) -> str : \"\"\" Create new label at indent level based on previous label if available. If previous label is available, make this the next one in the sequence. Otherwise start with a or 1 on alternate levels of indentation. If alphabetic label reaches z, next one is aa. Numeric ranges from 1 to 9, then 10 etc. \"\"\" if not prev_label : # assume indent goes in steps of 2 return [ 'a' , '1' ][( indent // 2 ) % 2 ] label_prefix = '' label_suffix = prev_label is_char = prev_label [ - 1 ] in string . ascii_letters # if it isn't ending in letter or digit just append 'a' to end if not is_char and prev_label [ - 1 ] not in string . digits : return prev_label + 'a' # break in middle of string if mixed types if len ( prev_label ) > 1 : ii = len ( prev_label ) - 1 while ii >= 0 : if prev_label [ ii ] not in string . ascii_letters + string . digits : break if ( prev_label [ ii ] in string . ascii_letters ) != is_char : break ii -= 1 if ii >= 0 : label_prefix = prev_label [:( ii + 1 )] label_suffix = prev_label [( ii + 1 ):] return label_prefix + ControlIOReader . _bump_label ( label_suffix ) @staticmethod def _read_parts ( indent : int , ii : int , lines : List [ str ], parent_id : str , parts : List [ common . Part ]) -> Tuple [ int , List [ common . Part ]]: \"\"\"If indentation level goes up or down, create new list or close current one.\"\"\" while True : ii , new_indent , line = ControlIOReader . _get_next_indent ( ii , lines ) if new_indent < 0 : # we are done reading control statement return ii , parts if new_indent == indent : # create new item part and add to current list of parts id_text , prose = ControlIOReader . _read_part_id_prose ( line ) # id_text is the part id and needs to be as a label property value # if none is there then create one from previous part, or use default if not id_text : prev_label = ControlIOWriter . get_label ( parts [ - 1 ]) if parts else '' id_text = ControlIOReader . _create_next_label ( prev_label , indent ) id_ = ControlIOReader . _strip_to_make_ncname ( parent_id . rstrip ( '.' ) + '.' + id_text . strip ( '.' )) name = 'objective' if id_ . find ( '_obj' ) > 0 else 'item' prop = common . Property ( name = 'label' , value = id_text ) part = common . Part ( name = name , id = id_ , prose = prose , props = [ prop ]) parts . append ( part ) ii += 1 elif new_indent > indent : # add new list of parts to last part and continue if len ( parts ) == 0 : raise TrestleError ( f 'Improper indentation structure: { line } ' ) ii , new_parts = ControlIOReader . _read_parts ( new_indent , ii , lines , parts [ - 1 ] . id , []) if new_parts : parts [ - 1 ] . parts = new_parts else : # return list of sub-parts return ii , parts @staticmethod def _read_control_statement ( ii : int , lines : List [ str ], control_id : str ) -> Tuple [ int , common . Part ]: \"\"\"Search for the Control statement and read until next ## Control.\"\"\" while 0 <= ii < len ( lines ) and not lines [ ii ] . startswith ( '## Control ' ): ii += 1 if ii >= len ( lines ): raise TrestleError ( f 'Control statement not found for control { control_id } ' ) ii += 1 ii , line = ControlIOReader . _get_next_line ( ii , lines ) if ii < 0 : # This means no statement and control withdrawn (this happens in NIST catalog) return ii , None if line and line [ 0 ] == ' ' and line . lstrip ()[ 0 ] != '-' : # prose that appears indented but has no - : treat it as the normal statement prose line = line . lstrip () indent = - 1 ii += 1 else : ii , indent , line = ControlIOReader . _get_next_indent ( ii , lines ) statement_part = common . Part ( name = 'statement' , id = f ' { control_id } _smt' ) # first line is either statement prose or start of statement parts if indent < 0 : statement_part . prose = line ii += 1 # we have absorbed possible statement prose. # now just read parts recursively # if there was no statement prose, this will re-read the line just read # as the start of the statement's parts ii , parts = ControlIOReader . _read_parts ( 0 , ii , lines , statement_part . id , []) statement_part . parts = parts if parts else None return ii , statement_part @staticmethod def _read_control_objective ( ii : int , lines : List [ str ], control_id : str ) -> Tuple [ int , Optional [ common . Part ]]: ii_orig = ii while 0 <= ii < len ( lines ) and not lines [ ii ] . startswith ( '## Control Objective' ): ii += 1 if ii >= len ( lines ): return ii_orig , None ii += 1 ii , line = ControlIOReader . _get_next_line ( ii , lines ) if ii < 0 : raise TrestleError ( f 'Unable to parse objective from control markdown { control_id } ' ) if line and line [ 0 ] == ' ' and line . lstrip ()[ 0 ] != '-' : # prose that appears indented but has no - : treat it as the normal objective prose line = line . lstrip () indent = - 1 ii += 1 else : ii , indent , line = ControlIOReader . _get_next_indent ( ii , lines ) objective_part = common . Part ( name = 'objective' , id = f ' { control_id } _obj' ) # first line is either objective prose or start of objective parts if indent < 0 : objective_part . prose = line ii += 1 # we have absorbed possible objective prose. # now just read parts recursively # if there was no objective prose, this will re-read the line just read # as the start of the objective's parts ii , parts = ControlIOReader . _read_parts ( 0 , ii , lines , objective_part . id , []) objective_part . parts = parts if parts else None return ii , objective_part @staticmethod def _read_sections ( ii : int , lines : List [ str ], control_id : str , control_parts : List [ common . Part ]) -> Tuple [ int , Optional [ List [ common . Part ]]]: \"\"\"Read all sections following the section separated by ## Control.\"\"\" new_parts = [] prefix = '## Control ' while 0 <= ii < len ( lines ): line = lines [ ii ] if line . startswith ( '## What is the solution' ) or line . startswith ( f '# { const . EDITABLE_CONTENT } ' ): ii += 1 continue if not line : ii += 1 continue if line and not line . startswith ( prefix ): # the control has no sections to read, so exit the loop break label = line [ len ( prefix ):] . strip () prose = '' ii += 1 while 0 <= ii < len ( lines ) and not lines [ ii ] . startswith ( prefix ) and not lines [ ii ] . startswith ( f '# { const . EDITABLE_CONTENT } ' ): prose = ' \\n ' . join ([ prose , lines [ ii ]]) ii += 1 if prose : if label . lower () == 'guidance' : id_ = ControlIOReader . _strip_to_make_ncname ( control_id + '_gdn' ) else : id_ = ControlIOReader . _strip_to_make_ncname ( control_id + '_' + label ) label = ControlIOReader . _strip_to_make_ncname ( label ) new_parts . append ( common . Part ( id = id_ , name = label , prose = prose . strip ( ' \\n ' ))) if new_parts : control_parts = [] if not control_parts else control_parts control_parts . extend ( new_parts ) control_parts = none_if_empty ( control_parts ) return ii , control_parts @staticmethod def _clean_prose ( prose : List [ str ]) -> List [ str ]: # remove empty and horizontal rule lines at start and end of list of prose lines forward_index = 0 for line in prose : if line . strip () and not line . startswith ( '____' ): break forward_index += 1 new_prose = prose [ forward_index :] reverse_index = 0 for line in reversed ( new_prose ): if line . strip () and not line . startswith ( '____' ): break reverse_index += 1 clean_prose = new_prose [: len ( new_prose ) - reverse_index ] clean_prose = clean_prose if clean_prose else [ '' ] # if there is no useful prose this will return [''] and allow generation of a statement with empty prose return clean_prose @staticmethod def _simplify_name ( name : str ) -> str : name = name . lower () . strip () return re . sub ( ' +' , ' ' , name ) @staticmethod def _comp_name_in_dict ( comp_name : str , comp_dict : Dict [ str , List [ Dict [ str , str ]]]) -> str : \"\"\"If the name is already in the dict in a similar form, stick to that form.\"\"\" simple_name = ControlIOReader . _simplify_name ( comp_name ) for name in comp_dict . keys (): if simple_name == ControlIOReader . _simplify_name ( name ): return name return comp_name @staticmethod def _add_node_to_dict ( comp_name : str , label : str , comp_dict : Dict [ str , Dict [ str , List [ str ]]], node : MarkdownNode , control_id : str , comp_list : List [ str ] ) -> None : prose = ControlIOReader . _clean_prose ( node . content . text ) if node . key . startswith ( '### ' ): if len ( node . key . split ()) <= 1 : raise TrestleError ( f 'Line in control { control_id } markdown starts with ### but has no component name.' ) comp_name = node . key . split ( ' ' , 1 )[ 1 ] . strip () simp_comp_name = ControlIOReader . _simplify_name ( comp_name ) if simp_comp_name == ControlIOReader . _simplify_name ( const . SSP_MAIN_COMP_NAME ): raise TrestleError ( f 'Response in control { control_id } has { const . SSP_MAIN_COMP_NAME } as a component heading. ' 'Instead, place all response prose for the default component at the top of th section, ' 'with no ### component specified. It will be entered as prose for the default system component.' ) if simp_comp_name in comp_list : raise TrestleError ( f 'Control { control_id } has a section with two ### component headings for { comp_name } . ' 'Please combine the sections so there is only one heading for each component in a statement.' ) comp_list . append ( simp_comp_name ) comp_name = ControlIOReader . _comp_name_in_dict ( comp_name , comp_dict ) if comp_name in comp_dict : if label in comp_dict [ comp_name ]: comp_dict [ comp_name ][ label ] . extend ( prose ) else : comp_dict [ comp_name ][ label ] = prose else : comp_dict [ comp_name ] = { label : prose } for subnode in node . subnodes : ControlIOReader . _add_node_to_dict ( comp_name , label , comp_dict , subnode , control_id , comp_list ) @staticmethod def read_all_implementation_prose_and_header ( control_file : pathlib . Path ) -> Tuple [ Dict [ str , Dict [ str , List [ str ]]], Dict [ str , List [ str ]]]: \"\"\" Find all labels and associated prose in this control. Args: control_file: path to the control markdown file Returns: Dictionary by comp_name of Dictionaries of part labels and corresponding prose read from the markdown file. Also returns the yaml header as dict in second part of tuple. This does not generate components - it only tracks component names and associated responses. \"\"\" comp_dict = {} yaml_header = {} # this level only adds for top level component but add_node_to_dict can add for other components comp_name = const . SSP_MAIN_COMP_NAME control_id = control_file . stem try : if not control_file . exists (): return comp_dict , yaml_header md_api = MarkdownAPI () yaml_header , control = md_api . processor . process_markdown ( control_file ) imp_string = 'Implementation' headers = control . get_all_headers_for_key ( imp_string , False ) header_list = list ( headers ) if not header_list : # if statement has no parts there is only one response for entire control headers = control . get_all_headers_for_key ( const . SSP_MD_IMPLEMENTATION_QUESTION , False ) # should be only one header, so warn if others found n_headers = 0 for header in headers : node = control . get_node_for_key ( header ) ControlIOReader . _add_node_to_dict ( comp_name , 'Statement' , comp_dict , node , control_id , []) n_headers += 1 if n_headers > 1 : logger . warning ( f 'Control { control_id } has single statement with extra response # { n_headers } ' ' when it should only have one.' ) else : for header in header_list : tokens = header . split ( ' ' , 2 ) if tokens [ 0 ] == '##' and tokens [ 1 ] == imp_string : label = tokens [ 2 ] . strip () node = control . get_node_for_key ( header ) ControlIOReader . _add_node_to_dict ( comp_name , label , comp_dict , node , control_id , []) except TrestleError as e : raise TrestleError ( f 'Error occurred reading { control_file } : { e } ' ) return comp_dict , yaml_header @staticmethod def _insert_header_content ( imp_req : ossp . ImplementedRequirement , header : Dict [ str , Any ], control_id : str ) -> None : \"\"\"Insert yaml header content into the imp_req and its by_comps.\"\"\" dict_ = header . get ( const . SSP_FEDRAMP_TAG , {}) # if an attribute is in the dict but it is None, need to make sure we get empty list anyway control_orig = as_list ( dict_ . get ( const . CONTROL_ORIGINATION , [])) imp_status = as_list ( dict_ . get ( const . IMPLEMENTATION_STATUS , [])) roles = as_list ( dict_ . get ( const . RESPONSIBLE_ROLES , [])) props = [] responsible_roles = [] for co in control_orig : if isinstance ( co , str ): props . append ( common . Property ( ns = const . NAMESPACE_FEDRAMP , name = const . CONTROL_ORIGINATION , value = co )) elif isinstance ( co , dict ): if const . INHERITED in co : uuid = co [ const . INHERITED ] props . append ( common . Property ( name = const . LEV_AUTH_UUID , value = uuid )) props . append ( common . Property ( ns = const . NAMESPACE_FEDRAMP , name = const . CONTROL_ORIGINATION , value = const . INHERITED ) ) else : raise TrestleError ( f 'The yaml header for control { control_id } has unexpected content: { co } ' ) else : raise TrestleError ( f 'The yaml header for control { control_id } has unexpected content: { co } ' ) for status in imp_status : if isinstance ( status , str ): props . append ( common . Property ( ns = const . NAMESPACE_FEDRAMP , name = const . IMPLEMENTATION_STATUS , value = status ) ) elif isinstance ( status , dict ): if const . PLANNED in status : if const . COMPLETION_DATE not in status : raise TrestleError ( f 'Planned status in the control { control_id } yaml header must ' f 'specify completion date: { status } ' ) props . append ( common . Property ( ns = const . NAMESPACE_FEDRAMP , name = const . PLANNED , value = status [ const . PLANNED ]) ) datestr = status [ const . COMPLETION_DATE ] if isinstance ( datestr , datetime ): datestr = datestr . strftime ( '%Y-%m- %d ' ) else : datestr = str ( datestr ) props . append ( common . Property ( ns = const . NAMESPACE_FEDRAMP , name = const . PLANNED_COMPLETION_DATE , value = datestr ) ) else : if len ( status ) != 1 : raise TrestleError ( f 'Unexpected content in control { control_id } yaml header: { status } ' ) value = list ( status . keys ())[ 0 ] remark = list ( status . values ())[ 0 ] props . append ( common . Property ( ns = const . NAMESPACE_FEDRAMP , name = const . IMPLEMENTATION_STATUS , value = value , remarks = common . Remarks ( __root__ = remark ) ) ) else : raise TrestleError ( f 'Unexpected content in control { control_id } yaml header: { status } ' ) for role in roles : if isinstance ( role , str ): # role_id must conform to NCNAME regex role = role . strip () . replace ( ' ' , '_' ) if role : responsible_roles . append ( common . ResponsibleRole ( role_id = role )) else : logger . warning ( f 'Role in header for control { control_id } not recognized: { role } ' ) if props : imp_req . props = as_list ( imp_req . props ) imp_req . props . extend ( props ) if responsible_roles : imp_req . responsible_roles = as_list ( imp_req . responsible_roles ) imp_req . responsible_roles . extend ( responsible_roles ) imp_req . responsible_roles = none_if_empty ( imp_req . responsible_roles ) # enforce single list of resp. roles for control and each by_comp for by_comp in as_list ( imp_req . by_components ): by_comp . responsible_roles = imp_req . responsible_roles @staticmethod def read_implemented_requirement ( control_file : pathlib . Path , avail_comps : Dict [ str , ossp . SystemComponent ] ) -> Tuple [ str , ossp . ImplementedRequirement ]: \"\"\" Get the implementated requirement associated with given control and link to existing components or new ones. Args: control_file: path of the control markdown file avail_comps: dictionary of known components keyed by component name Returns: Tuple: The control sort-id and the one implemented requirement for this control. Notes: Each statement may have several responses, with each response in a by_component for a specific component. statement_map keeps track of statements that may have several by_component responses. \"\"\" control_id = control_file . stem comp_dict , header = ControlIOReader . read_all_implementation_prose_and_header ( control_file ) statement_map : Dict [ str , ossp . Statement ] = {} # create a new implemented requirement linked to the control id to hold the statements imp_req : ossp . ImplementedRequirement = gens . generate_sample_model ( ossp . ImplementedRequirement ) imp_req . control_id = control_id # the comp_dict captures all component names referenced by the control for comp_name in comp_dict . keys (): if comp_name in avail_comps : component = avail_comps [ comp_name ] else : # here is where we create a new component on the fly as needed component = gens . generate_sample_model ( ossp . SystemComponent ) component . title = comp_name avail_comps [ comp_name ] = component for label , prose_lines in comp_dict [ comp_name ] . items (): # create a statement to hold the by-components and assign the statement id if label == 'Statement' : statement_id = f ' { control_id } _smt' else : clean_label = label . strip ( '.' ) statement_id = ControlIOReader . _strip_to_make_ncname ( f ' { control_id } _smt. { clean_label } ' ) if statement_id in statement_map : statement = statement_map [ statement_id ] else : statement : ossp . Statement = gens . generate_sample_model ( ossp . Statement ) statement . statement_id = statement_id statement . by_components = [] statement_map [ statement_id ] = statement # create a new by-component to add to this statement by_comp : ossp . ByComponent = gens . generate_sample_model ( ossp . ByComponent ) # link it to the component uuid by_comp . component_uuid = component . uuid # add the response prose to the description by_comp . description = ' \\n ' . join ( prose_lines ) statement . by_components . append ( by_comp ) imp_req . statements = list ( statement_map . values ()) ControlIOReader . _insert_header_content ( imp_req , header , control_id ) sort_id = header . get ( const . SORT_ID , control_id ) return sort_id , imp_req @staticmethod def _read_added_part ( ii : int , lines : List [ str ], control_id : str , sections_dict : Dict [ str , str ]) -> Tuple [ int , Optional [ common . Part ]]: \"\"\"Read a single part indicated by ## Control foo.\"\"\" snake_dict : Dict [ str , str ] = {} # create reverse lookup of long snake name to short name needed for part for key , value in sections_dict . items (): snake_dict [ spaces_and_caps_to_snake ( value )] = key while 0 <= ii < len ( lines ): # look for ## Control foo - then read prose line = lines [ ii ] prefix = '## Control ' if line : if not line . startswith ( prefix ): raise TrestleError ( f 'Unexpected line in { const . EDITABLE_CONTENT } for control { control_id } : { line } ' ) part_name_long_raw = line [ len ( prefix ):] . strip () part_name_snake = spaces_and_caps_to_snake ( part_name_long_raw ) # if the long name isn't there use the snake version for the part # otherwise the part will have the desired short name for the corresponding section part_name = snake_dict . get ( part_name_snake , part_name_snake ) # use sections dict to find correct title otherwise use the title from the markdown part_title = sections_dict . get ( part_name , part_name_long_raw ) prose_lines = [] ii += 1 have_content = False while 0 <= ii < len ( lines ): line = lines [ ii ] if not line . startswith ( prefix ): if line : have_content = True prose_lines . append ( line ) ii += 1 continue break if have_content : prose = ' \\n ' . join ( prose_lines ) # strip leading / trailing new lines. prose = prose . strip ( ' \\n ' ) id_ = f ' { control_id } _ { part_name } ' part = common . Part ( id = id_ , name = part_name , prose = prose , title = part_title ) return ii , part ii += 1 return - 1 , None @staticmethod def read_new_alters_and_params ( control_path : pathlib . Path , required_sections_list : List [ str ]) -> Tuple [ str , List [ prof . Alter ], Dict [ str , Any ]]: \"\"\"Get parts for the markdown control corresponding to Editable Content - along with the set-parameter dict.\"\"\" control_id = control_path . stem new_alters : List [ prof . Alter ] = [] lines , header = ControlIOReader . _load_control_lines_and_header ( control_path ) # extract the sort_id if present in header sort_id = header . get ( const . SORT_ID , control_id ) # query header for mapping of short to long section names sections_dict : Dict [ str , str ] = header . get ( const . SECTIONS_TAG , {}) found_sections : List [ str ] = [] ii = 0 while 0 <= ii < len ( lines ): line = lines [ ii ] if line . startswith ( f '# { const . EDITABLE_CONTENT } ' ): ii += 1 while 0 <= ii < len ( lines ): ii , part = ControlIOReader . _read_added_part ( ii , lines , control_id , sections_dict ) if ii < 0 : break # if section is required and it hasn't been edited with prose raise error if part . name in required_sections_list and part . prose . startswith ( const . PROFILE_ADD_REQUIRED_SECTION_FOR_CONTROL_TEXT ): missing_section = sections_dict . get ( part . name , part . name ) raise TrestleError ( f 'Control { control_id } is missing prose for required section { missing_section } ' ) alter = prof . Alter ( control_id = control_id , adds = [ prof . Add ( parts = [ part ], position = 'after' , by_id = f ' { control_id } _smt' )] ) new_alters . append ( alter ) found_sections . append ( part . name ) else : ii += 1 missing_sections = set ( required_sections_list ) - set ( found_sections ) if missing_sections : raise TrestleError ( f 'Control { control_id } is missing required sections { missing_sections } ' ) param_dict : Dict [ str , Any ] = {} header_params = header . get ( const . SET_PARAMS_TAG , {}) if header_params : param_dict . update ( header_params ) return sort_id , new_alters , param_dict @staticmethod def param_values_as_str_list ( param : common . Parameter ) -> List [ str ]: \"\"\"Convert param values to list of strings.\"\"\" return [ val . __root__ for val in as_list ( param . values )] @staticmethod def param_values_as_str ( param : common . Parameter , brackets = False ) -> Optional [ str ]: \"\"\"Convert param values to string with optional brackets.\"\"\" if not param . values : return None values_str = ', ' . join ( ControlIOReader . param_values_as_str_list ( param )) return f '[ { values_str } ]' if brackets else values_str @staticmethod def param_selection_as_str ( param : common . Parameter , verbose = False , brackets = False ) -> str : \"\"\"Convert parameter selection to str.\"\"\" if param . select and param . select . choice : how_many_str = '' if param . select . how_many : how_many_str = 'one' if param . select . how_many == common . HowMany . one else 'one or more' choices_str = '; ' . join ( as_list ( param . select . choice )) choices_str = f '[ { choices_str } ]' if brackets else choices_str choices_str = f 'Choose { how_many_str } : { choices_str } ' if verbose else choices_str return choices_str return '' @staticmethod def param_label_choices_as_str ( param : common . Parameter , verbose = False , brackets = False ) -> str : \"\"\"Convert param label or choices to string, using choices if present.\"\"\" choices = ControlIOReader . param_selection_as_str ( param , verbose , brackets ) text = choices if choices else param . label text = text if text else param . id return text @staticmethod def param_to_str ( param : common . Parameter , param_rep : ParameterRep , verbose = False , brackets = False , params_format : Optional [ str ] = None , ) -> Optional [ str ]: \"\"\" Convert parameter to string based on best available representation. Args: param_rep: how to represent the parameter verbose: provide verbose text for selection choices brackets: add brackets around the lists of items params_format: a string containing a single dot that represents a form of highlighting around the param Returns: formatted string or None \"\"\" param_str = None if param_rep == ParameterRep . VALUE_OR_STRING_NONE : param_str = ControlIOReader . param_values_as_str ( param ) param_str = param_str if param_str else 'None' elif param_rep == ParameterRep . LABEL_OR_CHOICES : param_str = ControlIOReader . param_label_choices_as_str ( param , verbose , brackets ) elif param_rep == ParameterRep . VALUE_OR_LABEL_OR_CHOICES : param_str = ControlIOReader . param_values_as_str ( param ) if not param_str : param_str = ControlIOReader . param_label_choices_as_str ( param , verbose , brackets ) elif param_rep == ParameterRep . VALUE_OR_EMPTY_STRING : param_str = ControlIOReader . param_values_as_str ( param , brackets ) if not param_str : param_str = '' if param_str is not None and params_format : if params_format . count ( '.' ) > 1 : raise TrestleError ( f 'Additional text { params_format } ' f 'for the parameters cannot contain multiple dots (.)' ) param_str = params_format . replace ( '.' , param_str ) return param_str @staticmethod def str_to_param ( param : common . Parameter , param_str : str ) -> None : \"\"\"Replace parameter contents with contents in string.\"\"\" # this is a simple version that replaces the values but it can be more elaborate param . values = [ common . ParameterValue ( __root__ = param_str )] @staticmethod def get_control_param_dict ( control : cat . Control , values_only : bool , ) -> Dict [ str , common . Parameter ]: \"\"\" Create mapping of param id's to params. Args: control: the control containing params of interest values_only: only add params to the dict that have actual values Returns: Dictionary of param_id mapped to param Notes: Warning is given if there is a parameter with no ID \"\"\" param_dict : Dict [ str , common . Parameter ] = {} for param in as_list ( control . params ): if not param . id : logger . warning ( f 'Control { control . id } has parameter with no id. Ignoring.' ) if param . values or not values_only : param_dict [ param . id ] = param return param_dict @staticmethod def read_control ( control_path : pathlib . Path , set_parameters : bool ) -> Tuple [ cat . Control , str ]: \"\"\"Read the control and group title from the markdown file.\"\"\" control = gens . generate_sample_model ( cat . Control ) md_api = MarkdownAPI () yaml_header , control_tree = md_api . processor . process_markdown ( control_path ) control_titles = list ( control_tree . get_all_headers_for_level ( 1 )) if len ( control_titles ) == 0 : raise TrestleError ( f 'Control markdown: { control_path } contains no control title.' ) control . id , group_title , control . title = ControlIOReader . _parse_control_title_line ( control_titles [ 0 ]) control_headers = list ( control_tree . get_all_headers_for_level ( 2 )) if len ( control_headers ) == 0 : raise TrestleError ( f 'Control markdown: { control_path } contains no control statements.' ) control_statement = control_tree . get_node_for_key ( control_headers [ 0 ]) rc , statement_part = ControlIOReader . _read_control_statement ( 0 , control_statement . content . raw_text . split ( ' \\n ' ), control . id ) if rc < 0 : return control , group_title control . parts = [ statement_part ] if statement_part else None control_objective = control_tree . get_node_for_key ( '## Control Objective' ) if control_objective is not None : _ , objective_part = ControlIOReader . _read_control_objective ( 0 , control_objective . content . raw_text . split ( ' \\n ' ), control . id ) if objective_part : if control . parts : control . parts . append ( objective_part ) else : control . parts = [ objective_part ] for header_key in control_tree . get_all_headers_for_key ( '## Control' , False ): if header_key not in { control_headers [ 0 ], '## Control Objective' , control_titles [ 0 ]}: section_node = control_tree . get_node_for_key ( header_key ) _ , control . parts = ControlIOReader . _read_sections ( 0 , section_node . content . raw_text . split ( ' \\n ' ), control . id , control . parts ) if set_parameters : params : Dict [ str , str ] = yaml_header . get ( const . SET_PARAMS_TAG , []) if params : control . params = [] for id_ , param_dict in params . items (): param_dict [ 'id' ] = id_ param = ModelUtils . dict_to_parameter ( param_dict ) control . params . append ( param ) if const . SORT_ID in yaml_header : control . props = control . props if control . props else [] control . props . append ( common . Property ( name = const . SORT_ID , value = yaml_header [ const . SORT_ID ])) return control , group_title","title":"ControlIOReader"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOReader-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOReader.get_control_param_dict","text":"Create mapping of param id's to params. Parameters: Name Type Description Default control Control the control containing params of interest required values_only bool only add params to the dict that have actual values required Returns: Type Description Dict[str, trestle.oscal.common.Parameter] Dictionary of param_id mapped to param Notes Warning is given if there is a parameter with no ID Source code in trestle/core/control_io.py @staticmethod def get_control_param_dict ( control : cat . Control , values_only : bool , ) -> Dict [ str , common . Parameter ]: \"\"\" Create mapping of param id's to params. Args: control: the control containing params of interest values_only: only add params to the dict that have actual values Returns: Dictionary of param_id mapped to param Notes: Warning is given if there is a parameter with no ID \"\"\" param_dict : Dict [ str , common . Parameter ] = {} for param in as_list ( control . params ): if not param . id : logger . warning ( f 'Control { control . id } has parameter with no id. Ignoring.' ) if param . values or not values_only : param_dict [ param . id ] = param return param_dict","title":"get_control_param_dict()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOReader.param_label_choices_as_str","text":"Convert param label or choices to string, using choices if present. Source code in trestle/core/control_io.py @staticmethod def param_label_choices_as_str ( param : common . Parameter , verbose = False , brackets = False ) -> str : \"\"\"Convert param label or choices to string, using choices if present.\"\"\" choices = ControlIOReader . param_selection_as_str ( param , verbose , brackets ) text = choices if choices else param . label text = text if text else param . id return text","title":"param_label_choices_as_str()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOReader.param_selection_as_str","text":"Convert parameter selection to str. Source code in trestle/core/control_io.py @staticmethod def param_selection_as_str ( param : common . Parameter , verbose = False , brackets = False ) -> str : \"\"\"Convert parameter selection to str.\"\"\" if param . select and param . select . choice : how_many_str = '' if param . select . how_many : how_many_str = 'one' if param . select . how_many == common . HowMany . one else 'one or more' choices_str = '; ' . join ( as_list ( param . select . choice )) choices_str = f '[ { choices_str } ]' if brackets else choices_str choices_str = f 'Choose { how_many_str } : { choices_str } ' if verbose else choices_str return choices_str return ''","title":"param_selection_as_str()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOReader.param_to_str","text":"Convert parameter to string based on best available representation. Parameters: Name Type Description Default param_rep ParameterRep how to represent the parameter required verbose provide verbose text for selection choices False brackets add brackets around the lists of items False params_format Optional[str] a string containing a single dot that represents a form of highlighting around the param None Returns: Type Description Optional[str] formatted string or None Source code in trestle/core/control_io.py @staticmethod def param_to_str ( param : common . Parameter , param_rep : ParameterRep , verbose = False , brackets = False , params_format : Optional [ str ] = None , ) -> Optional [ str ]: \"\"\" Convert parameter to string based on best available representation. Args: param_rep: how to represent the parameter verbose: provide verbose text for selection choices brackets: add brackets around the lists of items params_format: a string containing a single dot that represents a form of highlighting around the param Returns: formatted string or None \"\"\" param_str = None if param_rep == ParameterRep . VALUE_OR_STRING_NONE : param_str = ControlIOReader . param_values_as_str ( param ) param_str = param_str if param_str else 'None' elif param_rep == ParameterRep . LABEL_OR_CHOICES : param_str = ControlIOReader . param_label_choices_as_str ( param , verbose , brackets ) elif param_rep == ParameterRep . VALUE_OR_LABEL_OR_CHOICES : param_str = ControlIOReader . param_values_as_str ( param ) if not param_str : param_str = ControlIOReader . param_label_choices_as_str ( param , verbose , brackets ) elif param_rep == ParameterRep . VALUE_OR_EMPTY_STRING : param_str = ControlIOReader . param_values_as_str ( param , brackets ) if not param_str : param_str = '' if param_str is not None and params_format : if params_format . count ( '.' ) > 1 : raise TrestleError ( f 'Additional text { params_format } ' f 'for the parameters cannot contain multiple dots (.)' ) param_str = params_format . replace ( '.' , param_str ) return param_str","title":"param_to_str()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOReader.param_values_as_str","text":"Convert param values to string with optional brackets. Source code in trestle/core/control_io.py @staticmethod def param_values_as_str ( param : common . Parameter , brackets = False ) -> Optional [ str ]: \"\"\"Convert param values to string with optional brackets.\"\"\" if not param . values : return None values_str = ', ' . join ( ControlIOReader . param_values_as_str_list ( param )) return f '[ { values_str } ]' if brackets else values_str","title":"param_values_as_str()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOReader.param_values_as_str_list","text":"Convert param values to list of strings. Source code in trestle/core/control_io.py @staticmethod def param_values_as_str_list ( param : common . Parameter ) -> List [ str ]: \"\"\"Convert param values to list of strings.\"\"\" return [ val . __root__ for val in as_list ( param . values )]","title":"param_values_as_str_list()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOReader.read_all_implementation_prose_and_header","text":"Find all labels and associated prose in this control. Parameters: Name Type Description Default control_file Path path to the control markdown file required Returns: Type Description Tuple[Dict[str, Dict[str, List[str]]], Dict[str, List[str]]] Dictionary by comp_name of Dictionaries of part labels and corresponding prose read from the markdown file. Also returns the yaml header as dict in second part of tuple. This does not generate components - it only tracks component names and associated responses. Source code in trestle/core/control_io.py @staticmethod def read_all_implementation_prose_and_header ( control_file : pathlib . Path ) -> Tuple [ Dict [ str , Dict [ str , List [ str ]]], Dict [ str , List [ str ]]]: \"\"\" Find all labels and associated prose in this control. Args: control_file: path to the control markdown file Returns: Dictionary by comp_name of Dictionaries of part labels and corresponding prose read from the markdown file. Also returns the yaml header as dict in second part of tuple. This does not generate components - it only tracks component names and associated responses. \"\"\" comp_dict = {} yaml_header = {} # this level only adds for top level component but add_node_to_dict can add for other components comp_name = const . SSP_MAIN_COMP_NAME control_id = control_file . stem try : if not control_file . exists (): return comp_dict , yaml_header md_api = MarkdownAPI () yaml_header , control = md_api . processor . process_markdown ( control_file ) imp_string = 'Implementation' headers = control . get_all_headers_for_key ( imp_string , False ) header_list = list ( headers ) if not header_list : # if statement has no parts there is only one response for entire control headers = control . get_all_headers_for_key ( const . SSP_MD_IMPLEMENTATION_QUESTION , False ) # should be only one header, so warn if others found n_headers = 0 for header in headers : node = control . get_node_for_key ( header ) ControlIOReader . _add_node_to_dict ( comp_name , 'Statement' , comp_dict , node , control_id , []) n_headers += 1 if n_headers > 1 : logger . warning ( f 'Control { control_id } has single statement with extra response # { n_headers } ' ' when it should only have one.' ) else : for header in header_list : tokens = header . split ( ' ' , 2 ) if tokens [ 0 ] == '##' and tokens [ 1 ] == imp_string : label = tokens [ 2 ] . strip () node = control . get_node_for_key ( header ) ControlIOReader . _add_node_to_dict ( comp_name , label , comp_dict , node , control_id , []) except TrestleError as e : raise TrestleError ( f 'Error occurred reading { control_file } : { e } ' ) return comp_dict , yaml_header","title":"read_all_implementation_prose_and_header()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOReader.read_control","text":"Read the control and group title from the markdown file. Source code in trestle/core/control_io.py @staticmethod def read_control ( control_path : pathlib . Path , set_parameters : bool ) -> Tuple [ cat . Control , str ]: \"\"\"Read the control and group title from the markdown file.\"\"\" control = gens . generate_sample_model ( cat . Control ) md_api = MarkdownAPI () yaml_header , control_tree = md_api . processor . process_markdown ( control_path ) control_titles = list ( control_tree . get_all_headers_for_level ( 1 )) if len ( control_titles ) == 0 : raise TrestleError ( f 'Control markdown: { control_path } contains no control title.' ) control . id , group_title , control . title = ControlIOReader . _parse_control_title_line ( control_titles [ 0 ]) control_headers = list ( control_tree . get_all_headers_for_level ( 2 )) if len ( control_headers ) == 0 : raise TrestleError ( f 'Control markdown: { control_path } contains no control statements.' ) control_statement = control_tree . get_node_for_key ( control_headers [ 0 ]) rc , statement_part = ControlIOReader . _read_control_statement ( 0 , control_statement . content . raw_text . split ( ' \\n ' ), control . id ) if rc < 0 : return control , group_title control . parts = [ statement_part ] if statement_part else None control_objective = control_tree . get_node_for_key ( '## Control Objective' ) if control_objective is not None : _ , objective_part = ControlIOReader . _read_control_objective ( 0 , control_objective . content . raw_text . split ( ' \\n ' ), control . id ) if objective_part : if control . parts : control . parts . append ( objective_part ) else : control . parts = [ objective_part ] for header_key in control_tree . get_all_headers_for_key ( '## Control' , False ): if header_key not in { control_headers [ 0 ], '## Control Objective' , control_titles [ 0 ]}: section_node = control_tree . get_node_for_key ( header_key ) _ , control . parts = ControlIOReader . _read_sections ( 0 , section_node . content . raw_text . split ( ' \\n ' ), control . id , control . parts ) if set_parameters : params : Dict [ str , str ] = yaml_header . get ( const . SET_PARAMS_TAG , []) if params : control . params = [] for id_ , param_dict in params . items (): param_dict [ 'id' ] = id_ param = ModelUtils . dict_to_parameter ( param_dict ) control . params . append ( param ) if const . SORT_ID in yaml_header : control . props = control . props if control . props else [] control . props . append ( common . Property ( name = const . SORT_ID , value = yaml_header [ const . SORT_ID ])) return control , group_title","title":"read_control()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOReader.read_implemented_requirement","text":"Get the implementated requirement associated with given control and link to existing components or new ones. Parameters: Name Type Description Default control_file Path path of the control markdown file required avail_comps Dict[str, trestle.oscal.ssp.SystemComponent] dictionary of known components keyed by component name required Returns: Type Description Tuple The control sort-id and the one implemented requirement for this control. Notes Each statement may have several responses, with each response in a by_component for a specific component. statement_map keeps track of statements that may have several by_component responses. Source code in trestle/core/control_io.py @staticmethod def read_implemented_requirement ( control_file : pathlib . Path , avail_comps : Dict [ str , ossp . SystemComponent ] ) -> Tuple [ str , ossp . ImplementedRequirement ]: \"\"\" Get the implementated requirement associated with given control and link to existing components or new ones. Args: control_file: path of the control markdown file avail_comps: dictionary of known components keyed by component name Returns: Tuple: The control sort-id and the one implemented requirement for this control. Notes: Each statement may have several responses, with each response in a by_component for a specific component. statement_map keeps track of statements that may have several by_component responses. \"\"\" control_id = control_file . stem comp_dict , header = ControlIOReader . read_all_implementation_prose_and_header ( control_file ) statement_map : Dict [ str , ossp . Statement ] = {} # create a new implemented requirement linked to the control id to hold the statements imp_req : ossp . ImplementedRequirement = gens . generate_sample_model ( ossp . ImplementedRequirement ) imp_req . control_id = control_id # the comp_dict captures all component names referenced by the control for comp_name in comp_dict . keys (): if comp_name in avail_comps : component = avail_comps [ comp_name ] else : # here is where we create a new component on the fly as needed component = gens . generate_sample_model ( ossp . SystemComponent ) component . title = comp_name avail_comps [ comp_name ] = component for label , prose_lines in comp_dict [ comp_name ] . items (): # create a statement to hold the by-components and assign the statement id if label == 'Statement' : statement_id = f ' { control_id } _smt' else : clean_label = label . strip ( '.' ) statement_id = ControlIOReader . _strip_to_make_ncname ( f ' { control_id } _smt. { clean_label } ' ) if statement_id in statement_map : statement = statement_map [ statement_id ] else : statement : ossp . Statement = gens . generate_sample_model ( ossp . Statement ) statement . statement_id = statement_id statement . by_components = [] statement_map [ statement_id ] = statement # create a new by-component to add to this statement by_comp : ossp . ByComponent = gens . generate_sample_model ( ossp . ByComponent ) # link it to the component uuid by_comp . component_uuid = component . uuid # add the response prose to the description by_comp . description = ' \\n ' . join ( prose_lines ) statement . by_components . append ( by_comp ) imp_req . statements = list ( statement_map . values ()) ControlIOReader . _insert_header_content ( imp_req , header , control_id ) sort_id = header . get ( const . SORT_ID , control_id ) return sort_id , imp_req","title":"read_implemented_requirement()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOReader.read_new_alters_and_params","text":"Get parts for the markdown control corresponding to Editable Content - along with the set-parameter dict. Source code in trestle/core/control_io.py @staticmethod def read_new_alters_and_params ( control_path : pathlib . Path , required_sections_list : List [ str ]) -> Tuple [ str , List [ prof . Alter ], Dict [ str , Any ]]: \"\"\"Get parts for the markdown control corresponding to Editable Content - along with the set-parameter dict.\"\"\" control_id = control_path . stem new_alters : List [ prof . Alter ] = [] lines , header = ControlIOReader . _load_control_lines_and_header ( control_path ) # extract the sort_id if present in header sort_id = header . get ( const . SORT_ID , control_id ) # query header for mapping of short to long section names sections_dict : Dict [ str , str ] = header . get ( const . SECTIONS_TAG , {}) found_sections : List [ str ] = [] ii = 0 while 0 <= ii < len ( lines ): line = lines [ ii ] if line . startswith ( f '# { const . EDITABLE_CONTENT } ' ): ii += 1 while 0 <= ii < len ( lines ): ii , part = ControlIOReader . _read_added_part ( ii , lines , control_id , sections_dict ) if ii < 0 : break # if section is required and it hasn't been edited with prose raise error if part . name in required_sections_list and part . prose . startswith ( const . PROFILE_ADD_REQUIRED_SECTION_FOR_CONTROL_TEXT ): missing_section = sections_dict . get ( part . name , part . name ) raise TrestleError ( f 'Control { control_id } is missing prose for required section { missing_section } ' ) alter = prof . Alter ( control_id = control_id , adds = [ prof . Add ( parts = [ part ], position = 'after' , by_id = f ' { control_id } _smt' )] ) new_alters . append ( alter ) found_sections . append ( part . name ) else : ii += 1 missing_sections = set ( required_sections_list ) - set ( found_sections ) if missing_sections : raise TrestleError ( f 'Control { control_id } is missing required sections { missing_sections } ' ) param_dict : Dict [ str , Any ] = {} header_params = header . get ( const . SET_PARAMS_TAG , {}) if header_params : param_dict . update ( header_params ) return sort_id , new_alters , param_dict","title":"read_new_alters_and_params()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOReader.str_to_param","text":"Replace parameter contents with contents in string. Source code in trestle/core/control_io.py @staticmethod def str_to_param ( param : common . Parameter , param_str : str ) -> None : \"\"\"Replace parameter contents with contents in string.\"\"\" # this is a simple version that replaces the values but it can be more elaborate param . values = [ common . ParameterValue ( __root__ = param_str )]","title":"str_to_param()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOWriter","text":"Class to write controls as markdown. Source code in trestle/core/control_io.py class ControlIOWriter (): \"\"\"Class to write controls as markdown.\"\"\" def __init__ ( self ): \"\"\"Initialize the class.\"\"\" self . _md_file : Optional [ MDWriter ] = None @staticmethod def _wrap_label ( label : str ): l_side = '\\[' r_side = '\\]' wrapped = '' if label == '' else f ' { l_side }{ label }{ r_side } ' return wrapped @staticmethod def get_prop ( part_control : Union [ common . Part , cat . Control ], prop_name : str ) -> str : \"\"\"Get the property with that name.\"\"\" for prop in as_list ( part_control . props ): if prop . name . strip () . lower () == prop_name . strip () . lower (): return prop . value . strip () return '' @staticmethod def get_sort_id ( control : cat . Control , allow_none = False ) -> Optional [ str ]: \"\"\"Get the sort-id for the control.\"\"\" for prop in as_list ( control . props ): if prop . name == const . SORT_ID : return prop . value . strip () return None if allow_none else control . id @staticmethod def get_label ( part_control : Union [ common . Part , cat . Control ]) -> str : \"\"\"Get the label from the props of a part or control.\"\"\" return ControlIOWriter . get_prop ( part_control , 'label' ) def _get_part ( self , part : common . Part , item_type : str , skip_id : Optional [ str ]) -> List [ Union [ str , List [ str ]]]: \"\"\" Find parts with the specified item type, within the given part. For a part in a control find the parts in it that match the item_type Return list of string formatted labels and associated descriptive prose \"\"\" items = [] if part . name in [ 'statement' , item_type ]: # the options here are to force the label to be the part.id or the part.label # the label may be of the form (a) while the part.id is ac-1_smt.a.1.a # here we choose the latter and extract the final element label = ControlIOWriter . get_label ( part ) label = part . id . split ( '.' )[ - 1 ] if not label else label wrapped_label = self . _wrap_label ( label ) pad = '' if wrapped_label == '' or not part . prose else ' ' prose = '' if part . prose is None else part . prose # top level prose has already been written out, if present # use presence of . in id to tell if this is top level prose if part . id != skip_id : items . append ( f ' { wrapped_label }{ pad }{ prose } ' ) if part . parts : sub_list = [] for prt in part . parts : sub_list . extend ( self . _get_part ( prt , item_type , skip_id )) sub_list . append ( '' ) items . append ( sub_list ) return items def _add_part_and_its_items ( self , control : cat . Control , name : str , item_type : str ) -> None : \"\"\"For a given control add its one statement and its items to the md file after replacing params.\"\"\" items = [] if control . parts : for part in control . parts : if part . name == name : # If the part has prose write it as a raw line and not list element skip_id = part . id if part . prose : # need to avoid split lines in statement items self . _md_file . new_line ( part . prose . replace ( ' \\n ' , ' ' )) items . append ( self . _get_part ( part , item_type , skip_id )) # unwrap the list if it is many levels deep while not isinstance ( items , str ) and len ( items ) == 1 : items = items [ 0 ] self . _md_file . new_paragraph () self . _md_file . new_list ( items ) def _add_yaml_header ( self , yaml_header : Optional [ Dict ]) -> None : if yaml_header : self . _md_file . add_yaml_header ( yaml_header ) @staticmethod def _gap_join ( a_str : str , b_str : str ) -> str : a_clean = a_str . strip () b_clean = b_str . strip () if not b_clean : return a_clean gap = ' \\n ' if a_clean else '' return a_clean + gap + b_clean def _add_control_statement ( self , control : cat . Control , group_title : str , sections_dict : Optional [ Dict [ str , str ]] = None , capitalize_title = False ) -> None : \"\"\"Add the control statement and items to the md file.\"\"\" self . _md_file . new_paragraph () title = f ' { control . id } - \\[ { group_title } \\] { control . title } ' if capitalize_title : title = f ' { control . id . upper () } - \\[ { group_title . title () } \\] { control . title . title () } ' header_title = 'Control Statement' if sections_dict and sections_dict [ 'statement' ]: header_title = sections_dict [ 'statement' ] self . _md_file . new_header ( level = 1 , title = title ) self . _md_file . new_header ( level = 2 , title = header_title ) self . _md_file . set_indent_level ( - 1 ) self . _add_part_and_its_items ( control , 'statement' , 'item' ) self . _md_file . set_indent_level ( - 1 ) def _add_control_statement_ssp ( self , control : cat . Control ) -> None : \"\"\"Add the control statement and items to the markdown SSP.\"\"\" self . _md_file . new_paragraph () label = self . get_label ( control ) label = label if label else control . id . upper () title = f ' { label } - { control . title } ' self . _md_file . new_header ( level = 1 , title = title ) self . _md_file . new_header ( level = 2 , title = 'Control Statement' ) self . _md_file . set_indent_level ( - 1 ) self . _add_part_and_its_items ( control , 'statement' , 'item' ) self . _md_file . set_indent_level ( - 1 ) def _add_control_objective ( self , control : cat . Control , sections_dict : Optional [ Dict [ str , str ]] = None ) -> None : if control . parts : for part in control . parts : if part . name == 'objective' : self . _md_file . new_paragraph () heading_title = 'Control Objective' if sections_dict and sections_dict [ 'objective' ]: heading_title = sections_dict [ 'objective' ] self . _md_file . new_header ( level = 2 , title = heading_title ) self . _md_file . set_indent_level ( - 1 ) self . _add_part_and_its_items ( control , 'objective' , 'objective' ) self . _md_file . set_indent_level ( - 1 ) return @staticmethod def _get_control_section_part ( part : common . Part , section_name : str ) -> str : \"\"\"Get the prose for a named section in the control.\"\"\" prose = '' if part . name == section_name and part . prose is not None : prose = ControlIOWriter . _gap_join ( prose , part . prose ) if part . parts : for sub_part in part . parts : prose = ControlIOWriter . _gap_join ( prose , ControlIOWriter . _get_control_section_part ( sub_part , section_name ) ) return prose @staticmethod def _get_control_section_prose ( control : cat . Control , section_name : str ) -> str : prose = '' if control . parts : for part in control . parts : prose = ControlIOWriter . _gap_join ( prose , ControlIOWriter . _get_control_section_part ( part , section_name )) return prose @staticmethod def _find_section_info ( part : common . Part , skip_section_list : List [ str ]) -> Tuple [ str , str , str ]: \"\"\"Find section not in list.\"\"\" if part . prose and part . name not in skip_section_list : return part . id , part . name , part . title if part . parts : for sub_part in part . parts : id_ , name , title = ControlIOWriter . _find_section_info ( sub_part , skip_section_list ) if id_ : return id_ , name , title return '' , '' , '' @staticmethod def _find_section ( control : cat . Control , skip_section_list : List [ str ]) -> Tuple [ str , str , str ]: \"\"\"Find next section not in list.\"\"\" if control . parts : for part in control . parts : id_ , name , title = ControlIOWriter . _find_section_info ( part , skip_section_list ) if id_ : return id_ , name , title return '' , '' , '' @staticmethod def _get_section ( control : cat . Control , skip_section_list : List [ str ]) -> Tuple [ str , str , str , str ]: \"\"\"Get sections that are not in the list.\"\"\" id_ , name , title = ControlIOWriter . _find_section ( control , skip_section_list ) if id_ : return id_ , name , title , ControlIOWriter . _get_control_section_prose ( control , name ) return '' , '' , '' , '' def _add_sections ( self , control : cat . Control , allowed_sections : Optional [ List [ str ]]) -> None : \"\"\"Add the extra control sections after the main ones.\"\"\" skip_section_list = [ 'statement' , 'item' , 'objective' ] while True : _ , name , title , prose = self . _get_section ( control , skip_section_list ) if not name : return if allowed_sections and name not in allowed_sections : skip_section_list . append ( name ) continue if prose : # section title will be from the section_dict, the part title, or the part name in that order # this way the user-provided section title can override the part title section_title = self . _sections_dict . get ( name , title ) if self . _sections_dict else title section_title = section_title if section_title else name skip_section_list . append ( name ) self . _md_file . new_header ( level = 2 , title = f 'Control { section_title } ' ) self . _md_file . new_line ( prose ) self . _md_file . new_paragraph () def _add_one_section ( self , control : cat . Control , section : str ) -> None : \"\"\"Add specific control section.\"\"\" prose = ControlIOWriter . _get_control_section_prose ( control , section ) if prose : section_title = self . _sections_dict . get ( section ) if self . _sections_dict else section section_title = section_title if section_title else section self . _md_file . new_header ( level = 2 , title = f 'Control { section_title } ' ) self . _md_file . new_line ( prose ) self . _md_file . new_paragraph () def _insert_existing_text ( self , part_label : str , existing_text : Dict [ str , List [ str ]]) -> None : \"\"\"Insert text captured in the previous markdown and reinsert to avoid overwrite.\"\"\" if part_label in existing_text : self . _md_file . new_paragraph () for line in existing_text [ part_label ]: self . _md_file . new_line ( line ) def _add_implementation_response_prompts ( self , control : cat . Control , comp_dict : Dict [ str , Dict [ str , List [ str ]]] ) -> None : \"\"\"Add the response request text for all parts to the markdown along with the header.\"\"\" self . _md_file . new_hr () self . _md_file . new_paragraph () self . _md_file . new_header ( level = 2 , title = f ' { const . SSP_MD_IMPLEMENTATION_QUESTION } ' ) # if the control has no parts written out then enter implementation in the top level entry # but if it does have parts written out, leave top level blank and provide details in the parts # Note that parts corresponding to sections don't get written out here so a check is needed # If we have responses per component then enter them in separate ### sections did_write_part = False if control . parts : for part in control . parts : if part . parts : if part . name == 'statement' : for prt in part . parts : if prt . name != 'item' : continue if not did_write_part : self . _md_file . new_line ( const . SSP_MD_LEAVE_BLANK_TEXT ) # insert extra line to make mdformat happy self . _md_file . _add_line_raw ( '' ) self . _md_file . new_hr () # if no label guess the label from the sub-part id part_label = self . get_label ( prt ) part_label = prt . id . split ( '.' )[ - 1 ] if not part_label else part_label self . _md_file . new_header ( level = 2 , title = f 'Implementation { part_label } ' ) added_content = False for comp_name , prose_dict in comp_dict . items (): if part_label in prose_dict : if comp_name != const . SSP_MAIN_COMP_NAME : self . _md_file . new_header ( level = 3 , title = comp_name ) self . _insert_existing_text ( part_label , prose_dict ) added_content = True self . _md_file . new_paragraph () if not added_content : self . _md_file . new_line ( f ' { const . SSP_ADD_IMPLEMENTATION_FOR_ITEM_TEXT } { prt . id } ' ) did_write_part = True # if we loaded nothing for this control yet then it must need a fresh prompt for the control statement if not comp_dict and not did_write_part : self . _md_file . new_line ( f ' { const . SSP_ADD_IMPLEMENTATION_FOR_CONTROL_TEXT } { control . id } ' ) part_label = 'Statement' for comp_name , prose_dict in comp_dict . items (): if part_label in prose_dict : if comp_name != const . SSP_MAIN_COMP_NAME : self . _md_file . new_header ( level = 3 , title = comp_name ) self . _insert_existing_text ( part_label , prose_dict ) self . _md_file . new_hr () @staticmethod def _get_adds ( control_id : str , profile : prof . Profile ) -> List [ Tuple [ str , str ]]: adds = [] if profile and profile . modify and profile . modify . alters : for alter in profile . modify . alters : if alter . control_id == control_id and alter . adds : for add in alter . adds : if add . parts : for part in add . parts : if part . prose : adds . append (( part . name , part . prose )) return adds def _add_additional_content ( self , control : cat . Control , profile : prof . Profile ) -> List [ str ]: adds = ControlIOWriter . _get_adds ( control . id , profile ) has_content = len ( adds ) > 0 self . _md_file . new_header ( level = 1 , title = const . EDITABLE_CONTENT ) self . _md_file . new_line ( '<!-- Make additions and edits below -->' ) self . _md_file . new_line ( '<!-- The above represents the contents of the control as received by the profile, prior to additions. -->' # noqa E501 ) self . _md_file . new_line ( '<!-- If the profile makes additions to the control, they will appear below. -->' # noqa E501 ) self . _md_file . new_line ( '<!-- The above markdown may not be edited but you may edit the content below, and/or introduce new additions to be made by the profile. -->' # noqa E501 ) self . _md_file . new_line ( '<!-- If there is a yaml header at the top, parameter values may be edited. Use --set-parameters to incorporate the changes during assembly. -->' # noqa E501 ) self . _md_file . new_line ( '<!-- The content here will then replace what is in the profile for this control, after running profile-assemble. -->' # noqa E501 ) if has_content : self . _md_file . new_line ( '<!-- The added parts in the profile for this control are below. You may edit them and/or add new ones. -->' # noqa E501 ) else : self . _md_file . new_line ( '<!-- The current profile has no added parts for this control, but you may add new ones here. -->' ) self . _md_file . new_line ( '<!-- Each addition must have a heading of the form ## Control my_addition_name -->' ) self . _md_file . new_line ( '<!-- See https://ibm.github.io/compliance-trestle/tutorials/ssp_profile_catalog_authoring/ssp_profile_catalog_authoring for guidance. -->' # noqa E501 ) # next is to make mdformat happy self . _md_file . _add_line_raw ( '' ) added_sections : List [ str ] = [] for add in adds : name , prose = add title = self . _sections_dict . get ( name , name ) if self . _sections_dict else name self . _md_file . new_header ( level = 2 , title = f 'Control { title } ' ) self . _md_file . new_paraline ( prose ) added_sections . append ( name ) return added_sections @staticmethod def get_part_prose ( control : cat . Control , part_name : str ) -> str : \"\"\"Get the prose for a named part.\"\"\" prose = '' if control . parts : for part in control . parts : prose += ControlIOWriter . _get_control_section_part ( part , part_name ) return prose . strip () @staticmethod def merge_dicts_deep ( dest : Dict [ Any , Any ], src : Dict [ Any , Any ], overwrite_header_values : bool ) -> None : \"\"\" Merge dict src into dest. New items are always added from src to dest. Items present in both will be overriden dest if overwrite_header_values is True. \"\"\" for key in src . keys (): if key in dest : # if they are both dicts, recurse if isinstance ( dest [ key ], dict ) and isinstance ( src [ key ], dict ): ControlIOWriter . merge_dicts_deep ( dest [ key ], src [ key ], overwrite_header_values ) # otherwise override dest if needed elif overwrite_header_values : dest [ key ] = src [ key ] else : # if the item was not already in dest, add it from src dest [ key ] = src [ key ] def _prompt_required_sections ( self , required_sections : List [ str ], added_sections : List [ str ]) -> None : \"\"\"Add prompts for any required sections that haven't already been written out.\"\"\" missing_sections = set ( required_sections ) . difference ( added_sections ) for section in missing_sections : section_title = self . _sections_dict . get ( section , section ) self . _md_file . new_header ( 2 , f 'Control { section_title } ' ) self . _md_file . new_line ( f ' { const . PROFILE_ADD_REQUIRED_SECTION_FOR_CONTROL_TEXT } : { section_title } ' ) @staticmethod def is_withdrawn ( control : cat . Control ) -> bool : \"\"\" Determine if control is marked Withdrawn. Args: control: The control that may be marked withdrawn. Returns: True if marked withdrawn, false otherwise. This is determined by property with name 'status' with value 'Withdrawn'. \"\"\" for prop in as_list ( control . props ): if prop . name and prop . value : if prop . name . lower () . strip () == 'status' and prop . value . lower () . strip () == 'withdrawn' : return True return False def write_control_for_editing ( self , dest_path : pathlib . Path , control : cat . Control , group_title : str , yaml_header : Optional [ Dict ], sections_dict : Optional [ Dict [ str , str ]], additional_content : bool , prompt_responses : bool , profile : Optional [ prof . Profile ], overwrite_header_values : bool , required_sections : Optional [ List [ str ]], allowed_sections : Optional [ List [ str ]] ) -> None : \"\"\" Write out the control in markdown format into the specified directory. Args: dest_path: Path to the directory where the control will be written control: The control to write as markdown group_title: Title of the group containing the control yaml_header: Optional dict to be written as markdown yaml header sections_dict: Optional dict mapping short section names to long additional_content: Should the additional content be printed corresponding to profile adds prompt_responses: Should the markdown include prompts for implementation detail responses profile: Profile containing the adds making up additional content overwrite_header_values: Overwrite existing values in markdown header content but add new content required_sections: List of required sections that may need prompting for content allowed_sections: List of allowed sections that will appear in markdown Returns: None Notes: The filename is constructed from the control's id, so only the markdown directory is required. If a yaml header is present in the file, new values in provided header will not replace those in the markdown header unless overwrite_header_values is true. If it is true then overwrite any existing values, but in all cases new items from the provided header will be added to the markdown header. If the markdown file already exists, its current header and prose are read. Controls are checked if they are marked withdrawn, and if so they are not written out. \"\"\" if ControlIOWriter . is_withdrawn ( control ): logger . debug ( f 'Not writing out control { control . id } since it is marked Withdrawn.' ) return control_file = dest_path / ( control . id + '.md' ) # first read the existing markdown header and content if it exists existing_text , header = ControlIOReader . read_all_implementation_prose_and_header ( control_file ) self . _md_file = MDWriter ( control_file ) self . _sections_dict = sections_dict merged_header = copy . deepcopy ( header ) # if the control has an explicitly defined sort-id and there is none in the yaml_header, then insert it # in the yaml header and allow overwrite_header_values to control whether it overwrites an existing one # in the markdown header yaml_header = yaml_header if yaml_header else {} sort_id = ControlIOWriter . get_sort_id ( control , True ) if sort_id and const . SORT_ID not in yaml_header : yaml_header [ const . SORT_ID ] = sort_id ControlIOWriter . merge_dicts_deep ( merged_header , yaml_header , overwrite_header_values ) # merge any provided sections with sections in the header, with overwrite header_sections_dict = merged_header . get ( const . SECTIONS_TAG , {}) if sections_dict : header_sections_dict . update ( sections_dict ) if header_sections_dict : merged_header [ const . SECTIONS_TAG ] = header_sections_dict self . _add_yaml_header ( merged_header ) self . _add_control_statement ( control , group_title ) self . _add_control_objective ( control ) # add allowed sections to the markdown self . _add_sections ( control , allowed_sections ) # only used for ssp-generate if prompt_responses : self . _add_implementation_response_prompts ( control , existing_text ) # only used for profile-generate # add sections corresponding to added parts in the profile added_sections : List [ str ] = [] if additional_content : added_sections = self . _add_additional_content ( control , profile ) if required_sections : self . _prompt_required_sections ( required_sections , added_sections ) self . _md_file . write_out () def write_control_with_sections ( self , control : cat . Control , group_title : str , sections : List [ str ], sections_dict : Optional [ Dict [ str , str ]] = None , label_column : bool = True ) -> str : \"\"\"Write the control into markdown file with specified sections.\"\"\" self . _md_file = MDWriter ( None ) self . _sections_dict = sections_dict if not isinstance ( group_title , str ): raise TrestleError ( f 'Group title must be provided and be a string, instead received: { group_title } ' ) for section in sections : if 'statement' == section : self . _add_control_statement ( control , group_title , sections_dict , True ) elif 'objective' == section : self . _add_control_objective ( control , sections_dict ) elif 'table_of_parameters' == section : self . get_params ( control , label_column , self . _md_file ) else : self . _add_one_section ( control , section ) return ' \\n ' . join ( self . _md_file . _lines ) def get_control_statement ( self , control : cat . Control ) -> List [ str ]: \"\"\"Get the control statement as formatted markdown from a control.\"\"\" self . _md_file = MDWriter ( None ) self . _add_control_statement_ssp ( control ) return self . _md_file . get_lines () def get_params ( self , control : cat . Control , label_column = False , md_file = None ) -> List [ str ]: \"\"\"Get parameters of a control as a markdown table for ssp_io, with optional third label column.\"\"\" reader = ControlIOReader () param_dict = reader . get_control_param_dict ( control , False ) if param_dict : if md_file : self . _md_file = md_file else : self . _md_file = MDWriter ( None ) self . _md_file . new_paragraph () self . _md_file . set_indent_level ( - 1 ) if label_column : self . _md_file . new_table ( [ [ key , ControlIOReader . param_to_str ( param_dict [ key ], ParameterRep . VALUE_OR_EMPTY_STRING ), ControlIOReader . param_to_str ( param_dict [ key ], ParameterRep . LABEL_OR_CHOICES , True ), ] for key in param_dict . keys () ], [ 'Parameter ID' , 'Values' , 'Label or Choices' ] ) else : self . _md_file . new_table ( [ [ key , ControlIOReader . param_to_str ( param_dict [ key ], ParameterRep . VALUE_OR_LABEL_OR_CHOICES )] for key in param_dict . keys () ], [ 'Parameter ID' , 'Values' ] ) self . _md_file . set_indent_level ( - 1 ) return self . _md_file . get_lines () return []","title":"ControlIOWriter"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOWriter-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOWriter.__init__","text":"Initialize the class. Source code in trestle/core/control_io.py def __init__ ( self ): \"\"\"Initialize the class.\"\"\" self . _md_file : Optional [ MDWriter ] = None","title":"__init__()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOWriter.get_control_statement","text":"Get the control statement as formatted markdown from a control. Source code in trestle/core/control_io.py def get_control_statement ( self , control : cat . Control ) -> List [ str ]: \"\"\"Get the control statement as formatted markdown from a control.\"\"\" self . _md_file = MDWriter ( None ) self . _add_control_statement_ssp ( control ) return self . _md_file . get_lines ()","title":"get_control_statement()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOWriter.get_label","text":"Get the label from the props of a part or control. Source code in trestle/core/control_io.py @staticmethod def get_label ( part_control : Union [ common . Part , cat . Control ]) -> str : \"\"\"Get the label from the props of a part or control.\"\"\" return ControlIOWriter . get_prop ( part_control , 'label' )","title":"get_label()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOWriter.get_params","text":"Get parameters of a control as a markdown table for ssp_io, with optional third label column. Source code in trestle/core/control_io.py def get_params ( self , control : cat . Control , label_column = False , md_file = None ) -> List [ str ]: \"\"\"Get parameters of a control as a markdown table for ssp_io, with optional third label column.\"\"\" reader = ControlIOReader () param_dict = reader . get_control_param_dict ( control , False ) if param_dict : if md_file : self . _md_file = md_file else : self . _md_file = MDWriter ( None ) self . _md_file . new_paragraph () self . _md_file . set_indent_level ( - 1 ) if label_column : self . _md_file . new_table ( [ [ key , ControlIOReader . param_to_str ( param_dict [ key ], ParameterRep . VALUE_OR_EMPTY_STRING ), ControlIOReader . param_to_str ( param_dict [ key ], ParameterRep . LABEL_OR_CHOICES , True ), ] for key in param_dict . keys () ], [ 'Parameter ID' , 'Values' , 'Label or Choices' ] ) else : self . _md_file . new_table ( [ [ key , ControlIOReader . param_to_str ( param_dict [ key ], ParameterRep . VALUE_OR_LABEL_OR_CHOICES )] for key in param_dict . keys () ], [ 'Parameter ID' , 'Values' ] ) self . _md_file . set_indent_level ( - 1 ) return self . _md_file . get_lines () return []","title":"get_params()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOWriter.get_part_prose","text":"Get the prose for a named part. Source code in trestle/core/control_io.py @staticmethod def get_part_prose ( control : cat . Control , part_name : str ) -> str : \"\"\"Get the prose for a named part.\"\"\" prose = '' if control . parts : for part in control . parts : prose += ControlIOWriter . _get_control_section_part ( part , part_name ) return prose . strip ()","title":"get_part_prose()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOWriter.get_prop","text":"Get the property with that name. Source code in trestle/core/control_io.py @staticmethod def get_prop ( part_control : Union [ common . Part , cat . Control ], prop_name : str ) -> str : \"\"\"Get the property with that name.\"\"\" for prop in as_list ( part_control . props ): if prop . name . strip () . lower () == prop_name . strip () . lower (): return prop . value . strip () return ''","title":"get_prop()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOWriter.get_sort_id","text":"Get the sort-id for the control. Source code in trestle/core/control_io.py @staticmethod def get_sort_id ( control : cat . Control , allow_none = False ) -> Optional [ str ]: \"\"\"Get the sort-id for the control.\"\"\" for prop in as_list ( control . props ): if prop . name == const . SORT_ID : return prop . value . strip () return None if allow_none else control . id","title":"get_sort_id()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOWriter.is_withdrawn","text":"Determine if control is marked Withdrawn. Parameters: Name Type Description Default control Control The control that may be marked withdrawn. required Returns: Type Description bool True if marked withdrawn, false otherwise. This is determined by property with name 'status' with value 'Withdrawn'. Source code in trestle/core/control_io.py @staticmethod def is_withdrawn ( control : cat . Control ) -> bool : \"\"\" Determine if control is marked Withdrawn. Args: control: The control that may be marked withdrawn. Returns: True if marked withdrawn, false otherwise. This is determined by property with name 'status' with value 'Withdrawn'. \"\"\" for prop in as_list ( control . props ): if prop . name and prop . value : if prop . name . lower () . strip () == 'status' and prop . value . lower () . strip () == 'withdrawn' : return True return False","title":"is_withdrawn()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOWriter.merge_dicts_deep","text":"Merge dict src into dest. New items are always added from src to dest. Items present in both will be overriden dest if overwrite_header_values is True. Source code in trestle/core/control_io.py @staticmethod def merge_dicts_deep ( dest : Dict [ Any , Any ], src : Dict [ Any , Any ], overwrite_header_values : bool ) -> None : \"\"\" Merge dict src into dest. New items are always added from src to dest. Items present in both will be overriden dest if overwrite_header_values is True. \"\"\" for key in src . keys (): if key in dest : # if they are both dicts, recurse if isinstance ( dest [ key ], dict ) and isinstance ( src [ key ], dict ): ControlIOWriter . merge_dicts_deep ( dest [ key ], src [ key ], overwrite_header_values ) # otherwise override dest if needed elif overwrite_header_values : dest [ key ] = src [ key ] else : # if the item was not already in dest, add it from src dest [ key ] = src [ key ]","title":"merge_dicts_deep()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOWriter.write_control_for_editing","text":"Write out the control in markdown format into the specified directory. Parameters: Name Type Description Default dest_path Path Path to the directory where the control will be written required control Control The control to write as markdown required group_title str Title of the group containing the control required yaml_header Optional[Dict] Optional dict to be written as markdown yaml header required sections_dict Optional[Dict[str, str]] Optional dict mapping short section names to long required additional_content bool Should the additional content be printed corresponding to profile adds required prompt_responses bool Should the markdown include prompts for implementation detail responses required profile Optional[trestle.oscal.profile.Profile] Profile containing the adds making up additional content required overwrite_header_values bool Overwrite existing values in markdown header content but add new content required required_sections Optional[List[str]] List of required sections that may need prompting for content required allowed_sections Optional[List[str]] List of allowed sections that will appear in markdown required Returns: Type Description None None Notes The filename is constructed from the control's id, so only the markdown directory is required. If a yaml header is present in the file, new values in provided header will not replace those in the markdown header unless overwrite_header_values is true. If it is true then overwrite any existing values, but in all cases new items from the provided header will be added to the markdown header. If the markdown file already exists, its current header and prose are read. Controls are checked if they are marked withdrawn, and if so they are not written out. Source code in trestle/core/control_io.py def write_control_for_editing ( self , dest_path : pathlib . Path , control : cat . Control , group_title : str , yaml_header : Optional [ Dict ], sections_dict : Optional [ Dict [ str , str ]], additional_content : bool , prompt_responses : bool , profile : Optional [ prof . Profile ], overwrite_header_values : bool , required_sections : Optional [ List [ str ]], allowed_sections : Optional [ List [ str ]] ) -> None : \"\"\" Write out the control in markdown format into the specified directory. Args: dest_path: Path to the directory where the control will be written control: The control to write as markdown group_title: Title of the group containing the control yaml_header: Optional dict to be written as markdown yaml header sections_dict: Optional dict mapping short section names to long additional_content: Should the additional content be printed corresponding to profile adds prompt_responses: Should the markdown include prompts for implementation detail responses profile: Profile containing the adds making up additional content overwrite_header_values: Overwrite existing values in markdown header content but add new content required_sections: List of required sections that may need prompting for content allowed_sections: List of allowed sections that will appear in markdown Returns: None Notes: The filename is constructed from the control's id, so only the markdown directory is required. If a yaml header is present in the file, new values in provided header will not replace those in the markdown header unless overwrite_header_values is true. If it is true then overwrite any existing values, but in all cases new items from the provided header will be added to the markdown header. If the markdown file already exists, its current header and prose are read. Controls are checked if they are marked withdrawn, and if so they are not written out. \"\"\" if ControlIOWriter . is_withdrawn ( control ): logger . debug ( f 'Not writing out control { control . id } since it is marked Withdrawn.' ) return control_file = dest_path / ( control . id + '.md' ) # first read the existing markdown header and content if it exists existing_text , header = ControlIOReader . read_all_implementation_prose_and_header ( control_file ) self . _md_file = MDWriter ( control_file ) self . _sections_dict = sections_dict merged_header = copy . deepcopy ( header ) # if the control has an explicitly defined sort-id and there is none in the yaml_header, then insert it # in the yaml header and allow overwrite_header_values to control whether it overwrites an existing one # in the markdown header yaml_header = yaml_header if yaml_header else {} sort_id = ControlIOWriter . get_sort_id ( control , True ) if sort_id and const . SORT_ID not in yaml_header : yaml_header [ const . SORT_ID ] = sort_id ControlIOWriter . merge_dicts_deep ( merged_header , yaml_header , overwrite_header_values ) # merge any provided sections with sections in the header, with overwrite header_sections_dict = merged_header . get ( const . SECTIONS_TAG , {}) if sections_dict : header_sections_dict . update ( sections_dict ) if header_sections_dict : merged_header [ const . SECTIONS_TAG ] = header_sections_dict self . _add_yaml_header ( merged_header ) self . _add_control_statement ( control , group_title ) self . _add_control_objective ( control ) # add allowed sections to the markdown self . _add_sections ( control , allowed_sections ) # only used for ssp-generate if prompt_responses : self . _add_implementation_response_prompts ( control , existing_text ) # only used for profile-generate # add sections corresponding to added parts in the profile added_sections : List [ str ] = [] if additional_content : added_sections = self . _add_additional_content ( control , profile ) if required_sections : self . _prompt_required_sections ( required_sections , added_sections ) self . _md_file . write_out ()","title":"write_control_for_editing()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ControlIOWriter.write_control_with_sections","text":"Write the control into markdown file with specified sections. Source code in trestle/core/control_io.py def write_control_with_sections ( self , control : cat . Control , group_title : str , sections : List [ str ], sections_dict : Optional [ Dict [ str , str ]] = None , label_column : bool = True ) -> str : \"\"\"Write the control into markdown file with specified sections.\"\"\" self . _md_file = MDWriter ( None ) self . _sections_dict = sections_dict if not isinstance ( group_title , str ): raise TrestleError ( f 'Group title must be provided and be a string, instead received: { group_title } ' ) for section in sections : if 'statement' == section : self . _add_control_statement ( control , group_title , sections_dict , True ) elif 'objective' == section : self . _add_control_objective ( control , sections_dict ) elif 'table_of_parameters' == section : self . get_params ( control , label_column , self . _md_file ) else : self . _add_one_section ( control , section ) return ' \\n ' . join ( self . _md_file . _lines )","title":"write_control_with_sections()"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ParameterRep","text":"Enum for ways to represent a parameter. Source code in trestle/core/control_io.py class ParameterRep ( Enum ): \"\"\"Enum for ways to represent a parameter.\"\"\" LEAVE_MOUSTACHE = 0 VALUE_OR_STRING_NONE = 1 LABEL_OR_CHOICES = 2 VALUE_OR_LABEL_OR_CHOICES = 3 VALUE_OR_EMPTY_STRING = 4","title":"ParameterRep"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ParameterRep.LABEL_OR_CHOICES","text":"","title":"LABEL_OR_CHOICES"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ParameterRep.LEAVE_MOUSTACHE","text":"","title":"LEAVE_MOUSTACHE"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ParameterRep.VALUE_OR_EMPTY_STRING","text":"","title":"VALUE_OR_EMPTY_STRING"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ParameterRep.VALUE_OR_LABEL_OR_CHOICES","text":"","title":"VALUE_OR_LABEL_OR_CHOICES"},{"location":"api_reference/trestle.core.control_io/#trestle.core.control_io.ParameterRep.VALUE_OR_STRING_NONE","text":"handler: python","title":"VALUE_OR_STRING_NONE"},{"location":"api_reference/trestle.core.draw_io/","text":"trestle.core.draw_io \u00a4 Functionality for reading information from a drawio file. logger \u00a4 Classes \u00a4 DrawIO \u00a4 Access and process drawio data / metadata. Source code in trestle/core/draw_io.py class DrawIO (): \"\"\"Access and process drawio data / metadata.\"\"\" def __init__ ( self , file_path : pathlib . Path ) -> None : \"\"\" Load drawio object into memory. args: file_path: Path to the drawio object. \"\"\" self . file_path : pathlib . Path = file_path self . _load () self . banned_keys = [ 'id' , 'label' ] def _load ( self ) -> None : \"\"\"Load the file.\"\"\" if not self . file_path . exists () or self . file_path . is_dir (): raise TrestleError ( f 'Candidate drawio file { str ( self . file_path ) } does not exist or is a directory' ) try : self . raw_xml = defusedxml . ElementTree . parse ( self . file_path , forbid_dtd = True ) except Exception as e : raise TrestleError ( f 'Exception loading Element tree from file: { e } ' ) self . mx_file = self . raw_xml . getroot () if not self . mx_file . tag == 'mxfile' : raise TrestleError ( 'DrawIO file is not a draw io file (mxfile)' ) self . diagrams = [] for diagram in list ( self . mx_file ): # Determine if compressed or not # Assumption 1 mxGraphModel n_children = len ( list ( diagram )) if n_children == 0 : # Compressed object self . diagrams . append ( self . _uncompress ( diagram . text )) elif n_children == 1 : self . diagrams . append ( list ( diagram )[ 0 ]) else : raise TrestleError ( 'Unhandled behaviour in drawio read.' ) def _uncompress ( self , compressed_text : str ) -> Element : \"\"\" Given a compressed object from a drawio file return an xml element for the mxGraphModel. Args: compressed_text: A compressed mxGraphModel from inside an mxfile Returns: An element containing the mxGraphModel \"\"\" # Assume b64 encode decoded = base64 . b64decode ( compressed_text ) clean_text = unquote ( zlib . decompress ( decoded , - 15 ) . decode ( const . FILE_ENCODING )) element = defusedxml . ElementTree . fromstring ( clean_text , forbid_dtd = True ) if not element . tag == 'mxGraphModel' : raise TrestleError ( 'Unknown data structure within a compressed drawio file.' ) return element def get_metadata ( self ) -> List [ Dict [ str , str ]]: \"\"\"Get metadata from each tab if it exists or provide an empty dict.\"\"\" # Note that id and label are special for drawio. md_list : List [ Dict [ str , str ]] = [] for diagram in self . diagrams : md_dict : Dict [ str , str ] = {} # Drawio creates data within a root and then an object element type children = list ( diagram ) root_obj = children [ 0 ] md_objects = root_obj . findall ( 'object' ) # Should always be true - to test presumptions. if len ( md_objects ) == 0 : md_list . append ( md_dict ) continue items = md_objects [ 0 ] . items () for item in items : key = item [ 0 ] val = item [ 1 ] if key in self . banned_keys : continue md_dict [ key ] = val md_list . append ( md_dict ) return md_list @classmethod def restructure_metadata ( cls , input_dict : Dict [ str , str ]) -> Dict [ str , Any ]: \"\"\"Restructure metadata into a hierarchial dict assuming a period separator.\"\"\" # get the list of duplicate keys # Get a count of keys result = {} key_map = {} for keys in input_dict . keys (): stub = keys . split ( '.' )[ 0 ] tmp = key_map . get ( stub , []) tmp . append ( keys ) key_map [ stub ] = tmp for key , values in key_map . items (): holding = {} if len ( values ) == 1 and key == values [ 0 ]: result [ key ] = input_dict [ key ] else : for value in values : holding [ value . split ( '.' , 1 )[ - 1 ]] = input_dict [ value ] result [ key ] = cls . restructure_metadata ( holding ) return result def write_drawio_with_metadata ( self , path : pathlib . Path , metadata : Dict , diagram_metadata_idx : int , target_path : pathlib . Path = None ) -> None : \"\"\" Write modified metadata to drawio file. Writes given metadata to 'object' element attributes inside of the selected drawio diagram element. Currently supports writing only uncompressed elements. Args: path: path to write modified drawio file to metadata: dictionary of modified metadata to insert to drawio diagram_metadata_idx: index of diagram which metadata was modified target_path: if not provided the changes will be written to path \"\"\" flattened_dict = self . _flatten_dictionary ( metadata ) if diagram_metadata_idx >= len ( list ( self . diagrams )): raise TrestleError ( f 'Drawio file { path } does not contain a diagram for index { diagram_metadata_idx } ' ) diagram = list ( self . diagrams )[ diagram_metadata_idx ] children = list ( diagram ) root_obj = children [ 0 ] md_objects = root_obj . findall ( 'object' ) if len ( md_objects ) == 0 : raise TrestleError ( f 'Unable to write metadata, diagram in drawio file { path } does not have objects.' ) for key in md_objects [ 0 ] . attrib . copy (): if key not in flattened_dict . keys () and key not in self . banned_keys : # outdated key delete del md_objects [ 0 ] . attrib [ key ] continue if key in self . banned_keys : continue md_objects [ 0 ] . attrib [ key ] = flattened_dict [ key ] for key in flattened_dict . keys (): if key in self . banned_keys : continue md_objects [ 0 ] . attrib [ key ] = flattened_dict [ key ] parent_diagram = self . mx_file . findall ( 'diagram' )[ diagram_metadata_idx ] if len ( parent_diagram . findall ( 'mxGraphModel' )) == 0 : parent_diagram . insert ( 0 , diagram ) if target_path : self . raw_xml . write ( target_path ) else : self . raw_xml . write ( path ) def _flatten_dictionary ( self , metadata : Dict , parent_key = '' , separator = '.' ) -> Dict [ str , str ]: \"\"\"Flatten hierarchial dict back to xml attributes.\"\"\" items = [] for key , value in metadata . items (): new_key = parent_key + separator + key if parent_key else key if isinstance ( value , Dict ): items . extend ( self . _flatten_dictionary ( value , new_key , separator ) . items ()) else : items . append (( new_key , value )) return dict ( items ) Methods \u00a4 __init__ ( self , file_path ) special \u00a4 Load drawio object into memory. Parameters: Name Type Description Default file_path Path Path to the drawio object. required Source code in trestle/core/draw_io.py def __init__ ( self , file_path : pathlib . Path ) -> None : \"\"\" Load drawio object into memory. args: file_path: Path to the drawio object. \"\"\" self . file_path : pathlib . Path = file_path self . _load () self . banned_keys = [ 'id' , 'label' ] get_metadata ( self ) \u00a4 Get metadata from each tab if it exists or provide an empty dict. Source code in trestle/core/draw_io.py def get_metadata ( self ) -> List [ Dict [ str , str ]]: \"\"\"Get metadata from each tab if it exists or provide an empty dict.\"\"\" # Note that id and label are special for drawio. md_list : List [ Dict [ str , str ]] = [] for diagram in self . diagrams : md_dict : Dict [ str , str ] = {} # Drawio creates data within a root and then an object element type children = list ( diagram ) root_obj = children [ 0 ] md_objects = root_obj . findall ( 'object' ) # Should always be true - to test presumptions. if len ( md_objects ) == 0 : md_list . append ( md_dict ) continue items = md_objects [ 0 ] . items () for item in items : key = item [ 0 ] val = item [ 1 ] if key in self . banned_keys : continue md_dict [ key ] = val md_list . append ( md_dict ) return md_list restructure_metadata ( input_dict ) classmethod \u00a4 Restructure metadata into a hierarchial dict assuming a period separator. Source code in trestle/core/draw_io.py @classmethod def restructure_metadata ( cls , input_dict : Dict [ str , str ]) -> Dict [ str , Any ]: \"\"\"Restructure metadata into a hierarchial dict assuming a period separator.\"\"\" # get the list of duplicate keys # Get a count of keys result = {} key_map = {} for keys in input_dict . keys (): stub = keys . split ( '.' )[ 0 ] tmp = key_map . get ( stub , []) tmp . append ( keys ) key_map [ stub ] = tmp for key , values in key_map . items (): holding = {} if len ( values ) == 1 and key == values [ 0 ]: result [ key ] = input_dict [ key ] else : for value in values : holding [ value . split ( '.' , 1 )[ - 1 ]] = input_dict [ value ] result [ key ] = cls . restructure_metadata ( holding ) return result write_drawio_with_metadata ( self , path , metadata , diagram_metadata_idx , target_path = None ) \u00a4 Write modified metadata to drawio file. Writes given metadata to 'object' element attributes inside of the selected drawio diagram element. Currently supports writing only uncompressed elements. Parameters: Name Type Description Default path Path path to write modified drawio file to required metadata Dict dictionary of modified metadata to insert to drawio required diagram_metadata_idx int index of diagram which metadata was modified required target_path Path if not provided the changes will be written to path None Source code in trestle/core/draw_io.py def write_drawio_with_metadata ( self , path : pathlib . Path , metadata : Dict , diagram_metadata_idx : int , target_path : pathlib . Path = None ) -> None : \"\"\" Write modified metadata to drawio file. Writes given metadata to 'object' element attributes inside of the selected drawio diagram element. Currently supports writing only uncompressed elements. Args: path: path to write modified drawio file to metadata: dictionary of modified metadata to insert to drawio diagram_metadata_idx: index of diagram which metadata was modified target_path: if not provided the changes will be written to path \"\"\" flattened_dict = self . _flatten_dictionary ( metadata ) if diagram_metadata_idx >= len ( list ( self . diagrams )): raise TrestleError ( f 'Drawio file { path } does not contain a diagram for index { diagram_metadata_idx } ' ) diagram = list ( self . diagrams )[ diagram_metadata_idx ] children = list ( diagram ) root_obj = children [ 0 ] md_objects = root_obj . findall ( 'object' ) if len ( md_objects ) == 0 : raise TrestleError ( f 'Unable to write metadata, diagram in drawio file { path } does not have objects.' ) for key in md_objects [ 0 ] . attrib . copy (): if key not in flattened_dict . keys () and key not in self . banned_keys : # outdated key delete del md_objects [ 0 ] . attrib [ key ] continue if key in self . banned_keys : continue md_objects [ 0 ] . attrib [ key ] = flattened_dict [ key ] for key in flattened_dict . keys (): if key in self . banned_keys : continue md_objects [ 0 ] . attrib [ key ] = flattened_dict [ key ] parent_diagram = self . mx_file . findall ( 'diagram' )[ diagram_metadata_idx ] if len ( parent_diagram . findall ( 'mxGraphModel' )) == 0 : parent_diagram . insert ( 0 , diagram ) if target_path : self . raw_xml . write ( target_path ) else : self . raw_xml . write ( path ) DrawIOMetadataValidator \u00a4 Validator to check whether drawio metadata meets validation expectations. Source code in trestle/core/draw_io.py class DrawIOMetadataValidator (): \"\"\"Validator to check whether drawio metadata meets validation expectations.\"\"\" def __init__ ( self , template_path : pathlib . Path , must_be_first_tab : bool = True ) -> None : \"\"\" Initialize drawio validator. Args: template_path: Path to a templated drawio file where metadata will be looked up on the first tab only. must_be_first_tab: Whether to search the candidate file for a metadata across multiple tabs. \"\"\" self . template_path = template_path self . must_be_first_tab = must_be_first_tab # Load metadat from template template_drawio = DrawIO ( self . template_path ) # Zero index as must be first tab self . template_metadata = template_drawio . get_metadata ()[ 0 ] self . template_version = MarkdownValidator . extract_template_version ( self . template_metadata ) if self . template_version not in str ( self . template_path ): raise TrestleError ( f 'Version of the template { self . template_version } does not match the path { self . template_path } .' + f 'Move the template to the folder { self . template_version } ' ) if 'Version' in self . template_metadata . keys () and self . template_metadata [ 'Version' ] != self . template_version : raise TrestleError ( f 'Version does not match template-version in template: { self . template_path } .' ) def validate ( self , candidate : pathlib . Path ) -> bool : \"\"\" Run drawio validation against a candidate file. Args: candidate: The path to a candidate markdown file to be validated. Returns: Whether or not the validation passes. Raises: err.TrestleError: If a file IO / formatting error occurs. \"\"\" logging . info ( f 'Validating drawio file { candidate } against template file { self . template_path } ' ) candidate_drawio = DrawIO ( candidate ) drawio_metadata = candidate_drawio . get_metadata () if self . must_be_first_tab : return MarkdownValidator . compare_keys ( self . template_metadata , drawio_metadata [ 0 ]) for md_tab in drawio_metadata : status = MarkdownValidator . compare_keys ( self . template_metadata , md_tab ) if status : return status return False Methods \u00a4 __init__ ( self , template_path , must_be_first_tab = True ) special \u00a4 Initialize drawio validator. Parameters: Name Type Description Default template_path Path Path to a templated drawio file where metadata will be looked up on the first tab only. required must_be_first_tab bool Whether to search the candidate file for a metadata across multiple tabs. True Source code in trestle/core/draw_io.py def __init__ ( self , template_path : pathlib . Path , must_be_first_tab : bool = True ) -> None : \"\"\" Initialize drawio validator. Args: template_path: Path to a templated drawio file where metadata will be looked up on the first tab only. must_be_first_tab: Whether to search the candidate file for a metadata across multiple tabs. \"\"\" self . template_path = template_path self . must_be_first_tab = must_be_first_tab # Load metadat from template template_drawio = DrawIO ( self . template_path ) # Zero index as must be first tab self . template_metadata = template_drawio . get_metadata ()[ 0 ] self . template_version = MarkdownValidator . extract_template_version ( self . template_metadata ) if self . template_version not in str ( self . template_path ): raise TrestleError ( f 'Version of the template { self . template_version } does not match the path { self . template_path } .' + f 'Move the template to the folder { self . template_version } ' ) if 'Version' in self . template_metadata . keys () and self . template_metadata [ 'Version' ] != self . template_version : raise TrestleError ( f 'Version does not match template-version in template: { self . template_path } .' ) validate ( self , candidate ) \u00a4 Run drawio validation against a candidate file. Parameters: Name Type Description Default candidate Path The path to a candidate markdown file to be validated. required Returns: Type Description bool Whether or not the validation passes. Exceptions: Type Description err.TrestleError If a file IO / formatting error occurs. Source code in trestle/core/draw_io.py def validate ( self , candidate : pathlib . Path ) -> bool : \"\"\" Run drawio validation against a candidate file. Args: candidate: The path to a candidate markdown file to be validated. Returns: Whether or not the validation passes. Raises: err.TrestleError: If a file IO / formatting error occurs. \"\"\" logging . info ( f 'Validating drawio file { candidate } against template file { self . template_path } ' ) candidate_drawio = DrawIO ( candidate ) drawio_metadata = candidate_drawio . get_metadata () if self . must_be_first_tab : return MarkdownValidator . compare_keys ( self . template_metadata , drawio_metadata [ 0 ]) for md_tab in drawio_metadata : status = MarkdownValidator . compare_keys ( self . template_metadata , md_tab ) if status : return status return False handler: python","title":"draw_io"},{"location":"api_reference/trestle.core.draw_io/#trestle.core.draw_io","text":"Functionality for reading information from a drawio file.","title":"draw_io"},{"location":"api_reference/trestle.core.draw_io/#trestle.core.draw_io.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.draw_io/#trestle.core.draw_io-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.draw_io/#trestle.core.draw_io.DrawIO","text":"Access and process drawio data / metadata. Source code in trestle/core/draw_io.py class DrawIO (): \"\"\"Access and process drawio data / metadata.\"\"\" def __init__ ( self , file_path : pathlib . Path ) -> None : \"\"\" Load drawio object into memory. args: file_path: Path to the drawio object. \"\"\" self . file_path : pathlib . Path = file_path self . _load () self . banned_keys = [ 'id' , 'label' ] def _load ( self ) -> None : \"\"\"Load the file.\"\"\" if not self . file_path . exists () or self . file_path . is_dir (): raise TrestleError ( f 'Candidate drawio file { str ( self . file_path ) } does not exist or is a directory' ) try : self . raw_xml = defusedxml . ElementTree . parse ( self . file_path , forbid_dtd = True ) except Exception as e : raise TrestleError ( f 'Exception loading Element tree from file: { e } ' ) self . mx_file = self . raw_xml . getroot () if not self . mx_file . tag == 'mxfile' : raise TrestleError ( 'DrawIO file is not a draw io file (mxfile)' ) self . diagrams = [] for diagram in list ( self . mx_file ): # Determine if compressed or not # Assumption 1 mxGraphModel n_children = len ( list ( diagram )) if n_children == 0 : # Compressed object self . diagrams . append ( self . _uncompress ( diagram . text )) elif n_children == 1 : self . diagrams . append ( list ( diagram )[ 0 ]) else : raise TrestleError ( 'Unhandled behaviour in drawio read.' ) def _uncompress ( self , compressed_text : str ) -> Element : \"\"\" Given a compressed object from a drawio file return an xml element for the mxGraphModel. Args: compressed_text: A compressed mxGraphModel from inside an mxfile Returns: An element containing the mxGraphModel \"\"\" # Assume b64 encode decoded = base64 . b64decode ( compressed_text ) clean_text = unquote ( zlib . decompress ( decoded , - 15 ) . decode ( const . FILE_ENCODING )) element = defusedxml . ElementTree . fromstring ( clean_text , forbid_dtd = True ) if not element . tag == 'mxGraphModel' : raise TrestleError ( 'Unknown data structure within a compressed drawio file.' ) return element def get_metadata ( self ) -> List [ Dict [ str , str ]]: \"\"\"Get metadata from each tab if it exists or provide an empty dict.\"\"\" # Note that id and label are special for drawio. md_list : List [ Dict [ str , str ]] = [] for diagram in self . diagrams : md_dict : Dict [ str , str ] = {} # Drawio creates data within a root and then an object element type children = list ( diagram ) root_obj = children [ 0 ] md_objects = root_obj . findall ( 'object' ) # Should always be true - to test presumptions. if len ( md_objects ) == 0 : md_list . append ( md_dict ) continue items = md_objects [ 0 ] . items () for item in items : key = item [ 0 ] val = item [ 1 ] if key in self . banned_keys : continue md_dict [ key ] = val md_list . append ( md_dict ) return md_list @classmethod def restructure_metadata ( cls , input_dict : Dict [ str , str ]) -> Dict [ str , Any ]: \"\"\"Restructure metadata into a hierarchial dict assuming a period separator.\"\"\" # get the list of duplicate keys # Get a count of keys result = {} key_map = {} for keys in input_dict . keys (): stub = keys . split ( '.' )[ 0 ] tmp = key_map . get ( stub , []) tmp . append ( keys ) key_map [ stub ] = tmp for key , values in key_map . items (): holding = {} if len ( values ) == 1 and key == values [ 0 ]: result [ key ] = input_dict [ key ] else : for value in values : holding [ value . split ( '.' , 1 )[ - 1 ]] = input_dict [ value ] result [ key ] = cls . restructure_metadata ( holding ) return result def write_drawio_with_metadata ( self , path : pathlib . Path , metadata : Dict , diagram_metadata_idx : int , target_path : pathlib . Path = None ) -> None : \"\"\" Write modified metadata to drawio file. Writes given metadata to 'object' element attributes inside of the selected drawio diagram element. Currently supports writing only uncompressed elements. Args: path: path to write modified drawio file to metadata: dictionary of modified metadata to insert to drawio diagram_metadata_idx: index of diagram which metadata was modified target_path: if not provided the changes will be written to path \"\"\" flattened_dict = self . _flatten_dictionary ( metadata ) if diagram_metadata_idx >= len ( list ( self . diagrams )): raise TrestleError ( f 'Drawio file { path } does not contain a diagram for index { diagram_metadata_idx } ' ) diagram = list ( self . diagrams )[ diagram_metadata_idx ] children = list ( diagram ) root_obj = children [ 0 ] md_objects = root_obj . findall ( 'object' ) if len ( md_objects ) == 0 : raise TrestleError ( f 'Unable to write metadata, diagram in drawio file { path } does not have objects.' ) for key in md_objects [ 0 ] . attrib . copy (): if key not in flattened_dict . keys () and key not in self . banned_keys : # outdated key delete del md_objects [ 0 ] . attrib [ key ] continue if key in self . banned_keys : continue md_objects [ 0 ] . attrib [ key ] = flattened_dict [ key ] for key in flattened_dict . keys (): if key in self . banned_keys : continue md_objects [ 0 ] . attrib [ key ] = flattened_dict [ key ] parent_diagram = self . mx_file . findall ( 'diagram' )[ diagram_metadata_idx ] if len ( parent_diagram . findall ( 'mxGraphModel' )) == 0 : parent_diagram . insert ( 0 , diagram ) if target_path : self . raw_xml . write ( target_path ) else : self . raw_xml . write ( path ) def _flatten_dictionary ( self , metadata : Dict , parent_key = '' , separator = '.' ) -> Dict [ str , str ]: \"\"\"Flatten hierarchial dict back to xml attributes.\"\"\" items = [] for key , value in metadata . items (): new_key = parent_key + separator + key if parent_key else key if isinstance ( value , Dict ): items . extend ( self . _flatten_dictionary ( value , new_key , separator ) . items ()) else : items . append (( new_key , value )) return dict ( items )","title":"DrawIO"},{"location":"api_reference/trestle.core.draw_io/#trestle.core.draw_io.DrawIO-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.draw_io/#trestle.core.draw_io.DrawIO.__init__","text":"Load drawio object into memory. Parameters: Name Type Description Default file_path Path Path to the drawio object. required Source code in trestle/core/draw_io.py def __init__ ( self , file_path : pathlib . Path ) -> None : \"\"\" Load drawio object into memory. args: file_path: Path to the drawio object. \"\"\" self . file_path : pathlib . Path = file_path self . _load () self . banned_keys = [ 'id' , 'label' ]","title":"__init__()"},{"location":"api_reference/trestle.core.draw_io/#trestle.core.draw_io.DrawIO.get_metadata","text":"Get metadata from each tab if it exists or provide an empty dict. Source code in trestle/core/draw_io.py def get_metadata ( self ) -> List [ Dict [ str , str ]]: \"\"\"Get metadata from each tab if it exists or provide an empty dict.\"\"\" # Note that id and label are special for drawio. md_list : List [ Dict [ str , str ]] = [] for diagram in self . diagrams : md_dict : Dict [ str , str ] = {} # Drawio creates data within a root and then an object element type children = list ( diagram ) root_obj = children [ 0 ] md_objects = root_obj . findall ( 'object' ) # Should always be true - to test presumptions. if len ( md_objects ) == 0 : md_list . append ( md_dict ) continue items = md_objects [ 0 ] . items () for item in items : key = item [ 0 ] val = item [ 1 ] if key in self . banned_keys : continue md_dict [ key ] = val md_list . append ( md_dict ) return md_list","title":"get_metadata()"},{"location":"api_reference/trestle.core.draw_io/#trestle.core.draw_io.DrawIO.restructure_metadata","text":"Restructure metadata into a hierarchial dict assuming a period separator. Source code in trestle/core/draw_io.py @classmethod def restructure_metadata ( cls , input_dict : Dict [ str , str ]) -> Dict [ str , Any ]: \"\"\"Restructure metadata into a hierarchial dict assuming a period separator.\"\"\" # get the list of duplicate keys # Get a count of keys result = {} key_map = {} for keys in input_dict . keys (): stub = keys . split ( '.' )[ 0 ] tmp = key_map . get ( stub , []) tmp . append ( keys ) key_map [ stub ] = tmp for key , values in key_map . items (): holding = {} if len ( values ) == 1 and key == values [ 0 ]: result [ key ] = input_dict [ key ] else : for value in values : holding [ value . split ( '.' , 1 )[ - 1 ]] = input_dict [ value ] result [ key ] = cls . restructure_metadata ( holding ) return result","title":"restructure_metadata()"},{"location":"api_reference/trestle.core.draw_io/#trestle.core.draw_io.DrawIO.write_drawio_with_metadata","text":"Write modified metadata to drawio file. Writes given metadata to 'object' element attributes inside of the selected drawio diagram element. Currently supports writing only uncompressed elements. Parameters: Name Type Description Default path Path path to write modified drawio file to required metadata Dict dictionary of modified metadata to insert to drawio required diagram_metadata_idx int index of diagram which metadata was modified required target_path Path if not provided the changes will be written to path None Source code in trestle/core/draw_io.py def write_drawio_with_metadata ( self , path : pathlib . Path , metadata : Dict , diagram_metadata_idx : int , target_path : pathlib . Path = None ) -> None : \"\"\" Write modified metadata to drawio file. Writes given metadata to 'object' element attributes inside of the selected drawio diagram element. Currently supports writing only uncompressed elements. Args: path: path to write modified drawio file to metadata: dictionary of modified metadata to insert to drawio diagram_metadata_idx: index of diagram which metadata was modified target_path: if not provided the changes will be written to path \"\"\" flattened_dict = self . _flatten_dictionary ( metadata ) if diagram_metadata_idx >= len ( list ( self . diagrams )): raise TrestleError ( f 'Drawio file { path } does not contain a diagram for index { diagram_metadata_idx } ' ) diagram = list ( self . diagrams )[ diagram_metadata_idx ] children = list ( diagram ) root_obj = children [ 0 ] md_objects = root_obj . findall ( 'object' ) if len ( md_objects ) == 0 : raise TrestleError ( f 'Unable to write metadata, diagram in drawio file { path } does not have objects.' ) for key in md_objects [ 0 ] . attrib . copy (): if key not in flattened_dict . keys () and key not in self . banned_keys : # outdated key delete del md_objects [ 0 ] . attrib [ key ] continue if key in self . banned_keys : continue md_objects [ 0 ] . attrib [ key ] = flattened_dict [ key ] for key in flattened_dict . keys (): if key in self . banned_keys : continue md_objects [ 0 ] . attrib [ key ] = flattened_dict [ key ] parent_diagram = self . mx_file . findall ( 'diagram' )[ diagram_metadata_idx ] if len ( parent_diagram . findall ( 'mxGraphModel' )) == 0 : parent_diagram . insert ( 0 , diagram ) if target_path : self . raw_xml . write ( target_path ) else : self . raw_xml . write ( path )","title":"write_drawio_with_metadata()"},{"location":"api_reference/trestle.core.draw_io/#trestle.core.draw_io.DrawIOMetadataValidator","text":"Validator to check whether drawio metadata meets validation expectations. Source code in trestle/core/draw_io.py class DrawIOMetadataValidator (): \"\"\"Validator to check whether drawio metadata meets validation expectations.\"\"\" def __init__ ( self , template_path : pathlib . Path , must_be_first_tab : bool = True ) -> None : \"\"\" Initialize drawio validator. Args: template_path: Path to a templated drawio file where metadata will be looked up on the first tab only. must_be_first_tab: Whether to search the candidate file for a metadata across multiple tabs. \"\"\" self . template_path = template_path self . must_be_first_tab = must_be_first_tab # Load metadat from template template_drawio = DrawIO ( self . template_path ) # Zero index as must be first tab self . template_metadata = template_drawio . get_metadata ()[ 0 ] self . template_version = MarkdownValidator . extract_template_version ( self . template_metadata ) if self . template_version not in str ( self . template_path ): raise TrestleError ( f 'Version of the template { self . template_version } does not match the path { self . template_path } .' + f 'Move the template to the folder { self . template_version } ' ) if 'Version' in self . template_metadata . keys () and self . template_metadata [ 'Version' ] != self . template_version : raise TrestleError ( f 'Version does not match template-version in template: { self . template_path } .' ) def validate ( self , candidate : pathlib . Path ) -> bool : \"\"\" Run drawio validation against a candidate file. Args: candidate: The path to a candidate markdown file to be validated. Returns: Whether or not the validation passes. Raises: err.TrestleError: If a file IO / formatting error occurs. \"\"\" logging . info ( f 'Validating drawio file { candidate } against template file { self . template_path } ' ) candidate_drawio = DrawIO ( candidate ) drawio_metadata = candidate_drawio . get_metadata () if self . must_be_first_tab : return MarkdownValidator . compare_keys ( self . template_metadata , drawio_metadata [ 0 ]) for md_tab in drawio_metadata : status = MarkdownValidator . compare_keys ( self . template_metadata , md_tab ) if status : return status return False","title":"DrawIOMetadataValidator"},{"location":"api_reference/trestle.core.draw_io/#trestle.core.draw_io.DrawIOMetadataValidator-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.draw_io/#trestle.core.draw_io.DrawIOMetadataValidator.__init__","text":"Initialize drawio validator. Parameters: Name Type Description Default template_path Path Path to a templated drawio file where metadata will be looked up on the first tab only. required must_be_first_tab bool Whether to search the candidate file for a metadata across multiple tabs. True Source code in trestle/core/draw_io.py def __init__ ( self , template_path : pathlib . Path , must_be_first_tab : bool = True ) -> None : \"\"\" Initialize drawio validator. Args: template_path: Path to a templated drawio file where metadata will be looked up on the first tab only. must_be_first_tab: Whether to search the candidate file for a metadata across multiple tabs. \"\"\" self . template_path = template_path self . must_be_first_tab = must_be_first_tab # Load metadat from template template_drawio = DrawIO ( self . template_path ) # Zero index as must be first tab self . template_metadata = template_drawio . get_metadata ()[ 0 ] self . template_version = MarkdownValidator . extract_template_version ( self . template_metadata ) if self . template_version not in str ( self . template_path ): raise TrestleError ( f 'Version of the template { self . template_version } does not match the path { self . template_path } .' + f 'Move the template to the folder { self . template_version } ' ) if 'Version' in self . template_metadata . keys () and self . template_metadata [ 'Version' ] != self . template_version : raise TrestleError ( f 'Version does not match template-version in template: { self . template_path } .' )","title":"__init__()"},{"location":"api_reference/trestle.core.draw_io/#trestle.core.draw_io.DrawIOMetadataValidator.validate","text":"Run drawio validation against a candidate file. Parameters: Name Type Description Default candidate Path The path to a candidate markdown file to be validated. required Returns: Type Description bool Whether or not the validation passes. Exceptions: Type Description err.TrestleError If a file IO / formatting error occurs. Source code in trestle/core/draw_io.py def validate ( self , candidate : pathlib . Path ) -> bool : \"\"\" Run drawio validation against a candidate file. Args: candidate: The path to a candidate markdown file to be validated. Returns: Whether or not the validation passes. Raises: err.TrestleError: If a file IO / formatting error occurs. \"\"\" logging . info ( f 'Validating drawio file { candidate } against template file { self . template_path } ' ) candidate_drawio = DrawIO ( candidate ) drawio_metadata = candidate_drawio . get_metadata () if self . must_be_first_tab : return MarkdownValidator . compare_keys ( self . template_metadata , drawio_metadata [ 0 ]) for md_tab in drawio_metadata : status = MarkdownValidator . compare_keys ( self . template_metadata , md_tab ) if status : return status return False handler: python","title":"validate()"},{"location":"api_reference/trestle.core.duplicates_validator/","text":"trestle.core.duplicates_validator \u00a4 Validate by confirming no duplicate uuids. Classes \u00a4 DuplicatesValidator ( Validator ) \u00a4 Validator to check for duplicate uuids in the model. Source code in trestle/core/duplicates_validator.py class DuplicatesValidator ( Validator ): \"\"\"Validator to check for duplicate uuids in the model.\"\"\" def model_is_valid ( self , model : OscalBaseModel ) -> bool : \"\"\" Test if the model is valid and contains no duplicate uuids. args: model: An Oscal model that can be passed to the validator. returns: True (valid) if the model does not contain duplicate uuid's. \"\"\" return ModelUtils . has_no_duplicate_values_by_name ( model , 'uuid' ) Methods \u00a4 model_is_valid ( self , model ) \u00a4 Test if the model is valid and contains no duplicate uuids. Parameters: Name Type Description Default model OscalBaseModel An Oscal model that can be passed to the validator. required Returns: Type Description bool True (valid) if the model does not contain duplicate uuid's. Source code in trestle/core/duplicates_validator.py def model_is_valid ( self , model : OscalBaseModel ) -> bool : \"\"\" Test if the model is valid and contains no duplicate uuids. args: model: An Oscal model that can be passed to the validator. returns: True (valid) if the model does not contain duplicate uuid's. \"\"\" return ModelUtils . has_no_duplicate_values_by_name ( model , 'uuid' ) handler: python","title":"duplicates_validator"},{"location":"api_reference/trestle.core.duplicates_validator/#trestle.core.duplicates_validator","text":"Validate by confirming no duplicate uuids.","title":"duplicates_validator"},{"location":"api_reference/trestle.core.duplicates_validator/#trestle.core.duplicates_validator-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.duplicates_validator/#trestle.core.duplicates_validator.DuplicatesValidator","text":"Validator to check for duplicate uuids in the model. Source code in trestle/core/duplicates_validator.py class DuplicatesValidator ( Validator ): \"\"\"Validator to check for duplicate uuids in the model.\"\"\" def model_is_valid ( self , model : OscalBaseModel ) -> bool : \"\"\" Test if the model is valid and contains no duplicate uuids. args: model: An Oscal model that can be passed to the validator. returns: True (valid) if the model does not contain duplicate uuid's. \"\"\" return ModelUtils . has_no_duplicate_values_by_name ( model , 'uuid' )","title":"DuplicatesValidator"},{"location":"api_reference/trestle.core.duplicates_validator/#trestle.core.duplicates_validator.DuplicatesValidator-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.duplicates_validator/#trestle.core.duplicates_validator.DuplicatesValidator.model_is_valid","text":"Test if the model is valid and contains no duplicate uuids. Parameters: Name Type Description Default model OscalBaseModel An Oscal model that can be passed to the validator. required Returns: Type Description bool True (valid) if the model does not contain duplicate uuid's. Source code in trestle/core/duplicates_validator.py def model_is_valid ( self , model : OscalBaseModel ) -> bool : \"\"\" Test if the model is valid and contains no duplicate uuids. args: model: An Oscal model that can be passed to the validator. returns: True (valid) if the model does not contain duplicate uuid's. \"\"\" return ModelUtils . has_no_duplicate_values_by_name ( model , 'uuid' ) handler: python","title":"model_is_valid()"},{"location":"api_reference/trestle.core.generators/","text":"trestle.core.generators \u00a4 Capabilities to allow the generation of various oscal objects. TG \u00a4 logger \u00a4 Functions \u00a4 generate_sample_model ( model , include_optional = False , depth =- 1 ) \u00a4 Given a model class, generate an object of that class with sample values. Can generate optional variables with an enabled flag. Any array objects will have a single entry injected into it. Note: Trestle generate will not activate recursive loops irrespective of the depth flag. Parameters: Name Type Description Default model Union[Type[~TG], List[~TG], Dict[str, ~TG]] The model type provided. Typically for a user as an OscalBaseModel Subclass. required include_optional bool Whether or not to generate optional fields. False depth int Depth of the tree at which optional fields are generated. Negative values (default) removes the limit. -1 Returns: Type Description ~TG The generated instance with a pro-forma values filled out as best as possible. Source code in trestle/core/generators.py def generate_sample_model ( model : Union [ Type [ TG ], List [ TG ], Dict [ str , TG ]], include_optional : bool = False , depth : int = - 1 ) -> TG : \"\"\"Given a model class, generate an object of that class with sample values. Can generate optional variables with an enabled flag. Any array objects will have a single entry injected into it. Note: Trestle generate will not activate recursive loops irrespective of the depth flag. Args: model: The model type provided. Typically for a user as an OscalBaseModel Subclass. include_optional: Whether or not to generate optional fields. depth: Depth of the tree at which optional fields are generated. Negative values (default) removes the limit. Returns: The generated instance with a pro-forma values filled out as best as possible. \"\"\" effective_optional = include_optional and not depth == 0 model_type = model # This block normalizes model type down to if utils . is_collection_field_type ( model ): # type: ignore model_type = utils . get_origin ( model ) # type: ignore model = utils . get_inner_type ( model ) # type: ignore model = cast ( TG , model ) model_dict = {} # this block is needed to avoid situations where an inbuilt is inside a list / dict. # the only time dict ever appears is with include_all, which is handled specially # the only type of collection possible after OSCAL 1.0.0 is list if safe_is_sub ( model , OscalBaseModel ): for field in model . __fields__ : if field == 'include_all' : if include_optional : model_dict [ field ] = {} continue outer_type = model . __fields__ [ field ] . outer_type_ # next appears to be needed for python 3.7 if utils . get_origin ( outer_type ) == Union : outer_type = outer_type . __args__ [ 0 ] if model . __fields__ [ field ] . required or effective_optional : # FIXME could be ForwardRef('SystemComponentStatus') if utils . is_collection_field_type ( outer_type ): inner_type = utils . get_inner_type ( outer_type ) if inner_type == model : continue model_dict [ field ] = generate_sample_model ( outer_type , include_optional = include_optional , depth = depth - 1 ) elif safe_is_sub ( outer_type , OscalBaseModel ): model_dict [ field ] = generate_sample_model ( outer_type , include_optional = include_optional , depth = depth - 1 ) else : # Hacking here: # Root models should ideally not exist, however, sometimes we are stuck with them. # If that is the case we need sufficient information on the type in order to generate a model. # E.g. we need the type of the container. if field == '__root__' and hasattr ( model , '__name__' ): model_dict [ field ] = generate_sample_value_by_type ( outer_type , str_utils . classname_to_alias ( model . __name__ , AliasMode . FIELD ) ) else : model_dict [ field ] = generate_sample_value_by_type ( outer_type , field ) # Note: this assumes list constrains in oscal are always 1 as a minimum size. if two this may still fail. else : if model_type is list : return [ generate_sample_value_by_type ( model , '' )] if model_type is dict : return { 'REPLACE_ME' : generate_sample_value_by_type ( model , '' )} raise err . TrestleError ( 'Unhandled collection type.' ) if model_type is list : return [ model ( ** model_dict )] if model_type is dict : return { 'REPLACE_ME' : model ( ** model_dict )} return model ( ** model_dict ) generate_sample_value_by_type ( type_ , field_name ) \u00a4 Given a type, return sample value. Includes the Optional use of passing down a parent_model Source code in trestle/core/generators.py def generate_sample_value_by_type ( type_ : type , field_name : str , ) -> Union [ datetime , bool , int , str , float , Enum ]: \"\"\"Given a type, return sample value. Includes the Optional use of passing down a parent_model \"\"\" # FIXME: Should be in separate generator module as it inherits EVERYTHING if type_ is datetime : return datetime . now () . astimezone () if type_ is bool : return False if type_ is int : return 0 if type_ is str : if field_name == 'oscal_version' : return OSCAL_VERSION return 'REPLACE_ME' if type_ is float : return 0.00 if safe_is_sub ( type_ , ConstrainedStr ) or ( hasattr ( type_ , '__name__' ) and 'ConstrainedStr' in type_ . __name__ ): # This code here is messy. we need to meet a set of constraints. If we do # TODO: handle regex directly if 'uuid' == field_name : return str ( uuid . uuid4 ()) if field_name == 'date_authorized' : return str ( date . today () . isoformat ()) if field_name == 'oscal_version' : return OSCAL_VERSION if 'uuid' in field_name : return const . SAMPLE_UUID_STR # Only case where are UUID is required but not in name. if field_name . rstrip ( 's' ) == 'member_of_organization' : return const . SAMPLE_UUID_STR return 'REPLACE_ME' if hasattr ( type_ , '__name__' ) and 'ConstrainedIntValue' in type_ . __name__ : # create an int value as close to the floor as possible does not test upper bound multiple = type_ . multiple_of if type_ . multiple_of else 1 # default to every integer # this command is a bit of a problem floor = type_ . ge if type_ . ge else 0 floor = type_ . gt + 1 if type_ . gt else floor if math . remainder ( floor , multiple ) == 0 : return floor return ( floor + 1 ) * multiple if safe_is_sub ( type_ , Enum ): # keys and values diverge due to hypens in oscal names return type_ ( list ( type_ . __members__ . values ())[ 0 ]) if type_ is pydantic . networks . EmailStr : return pydantic . networks . EmailStr ( 'dummy@sample.com' ) if type_ is pydantic . networks . AnyUrl : # TODO: Cleanup: this should be usable from a url.. but it's not inuitive. return pydantic . networks . AnyUrl ( 'https://sample.com/replaceme.html' , scheme = 'http' , host = 'sample.com' ) if type_ is Any or type_ is Dict [ str , Any ]: # Return empty dict - aka users can put whatever they want here. return {} raise err . TrestleError ( f 'Fatal: Bad type in model { type_ } ' ) safe_is_sub ( sub , parent ) \u00a4 Is this a subclass of parent. Source code in trestle/core/generators.py def safe_is_sub ( sub : Any , parent : Any ) -> bool : \"\"\"Is this a subclass of parent.\"\"\" is_class = inspect . isclass ( sub ) return is_class and issubclass ( sub , parent ) handler: python","title":"generators"},{"location":"api_reference/trestle.core.generators/#trestle.core.generators","text":"Capabilities to allow the generation of various oscal objects.","title":"generators"},{"location":"api_reference/trestle.core.generators/#trestle.core.generators.TG","text":"","title":"TG"},{"location":"api_reference/trestle.core.generators/#trestle.core.generators.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.generators/#trestle.core.generators-functions","text":"","title":"Functions"},{"location":"api_reference/trestle.core.generators/#trestle.core.generators.generate_sample_model","text":"Given a model class, generate an object of that class with sample values. Can generate optional variables with an enabled flag. Any array objects will have a single entry injected into it. Note: Trestle generate will not activate recursive loops irrespective of the depth flag. Parameters: Name Type Description Default model Union[Type[~TG], List[~TG], Dict[str, ~TG]] The model type provided. Typically for a user as an OscalBaseModel Subclass. required include_optional bool Whether or not to generate optional fields. False depth int Depth of the tree at which optional fields are generated. Negative values (default) removes the limit. -1 Returns: Type Description ~TG The generated instance with a pro-forma values filled out as best as possible. Source code in trestle/core/generators.py def generate_sample_model ( model : Union [ Type [ TG ], List [ TG ], Dict [ str , TG ]], include_optional : bool = False , depth : int = - 1 ) -> TG : \"\"\"Given a model class, generate an object of that class with sample values. Can generate optional variables with an enabled flag. Any array objects will have a single entry injected into it. Note: Trestle generate will not activate recursive loops irrespective of the depth flag. Args: model: The model type provided. Typically for a user as an OscalBaseModel Subclass. include_optional: Whether or not to generate optional fields. depth: Depth of the tree at which optional fields are generated. Negative values (default) removes the limit. Returns: The generated instance with a pro-forma values filled out as best as possible. \"\"\" effective_optional = include_optional and not depth == 0 model_type = model # This block normalizes model type down to if utils . is_collection_field_type ( model ): # type: ignore model_type = utils . get_origin ( model ) # type: ignore model = utils . get_inner_type ( model ) # type: ignore model = cast ( TG , model ) model_dict = {} # this block is needed to avoid situations where an inbuilt is inside a list / dict. # the only time dict ever appears is with include_all, which is handled specially # the only type of collection possible after OSCAL 1.0.0 is list if safe_is_sub ( model , OscalBaseModel ): for field in model . __fields__ : if field == 'include_all' : if include_optional : model_dict [ field ] = {} continue outer_type = model . __fields__ [ field ] . outer_type_ # next appears to be needed for python 3.7 if utils . get_origin ( outer_type ) == Union : outer_type = outer_type . __args__ [ 0 ] if model . __fields__ [ field ] . required or effective_optional : # FIXME could be ForwardRef('SystemComponentStatus') if utils . is_collection_field_type ( outer_type ): inner_type = utils . get_inner_type ( outer_type ) if inner_type == model : continue model_dict [ field ] = generate_sample_model ( outer_type , include_optional = include_optional , depth = depth - 1 ) elif safe_is_sub ( outer_type , OscalBaseModel ): model_dict [ field ] = generate_sample_model ( outer_type , include_optional = include_optional , depth = depth - 1 ) else : # Hacking here: # Root models should ideally not exist, however, sometimes we are stuck with them. # If that is the case we need sufficient information on the type in order to generate a model. # E.g. we need the type of the container. if field == '__root__' and hasattr ( model , '__name__' ): model_dict [ field ] = generate_sample_value_by_type ( outer_type , str_utils . classname_to_alias ( model . __name__ , AliasMode . FIELD ) ) else : model_dict [ field ] = generate_sample_value_by_type ( outer_type , field ) # Note: this assumes list constrains in oscal are always 1 as a minimum size. if two this may still fail. else : if model_type is list : return [ generate_sample_value_by_type ( model , '' )] if model_type is dict : return { 'REPLACE_ME' : generate_sample_value_by_type ( model , '' )} raise err . TrestleError ( 'Unhandled collection type.' ) if model_type is list : return [ model ( ** model_dict )] if model_type is dict : return { 'REPLACE_ME' : model ( ** model_dict )} return model ( ** model_dict )","title":"generate_sample_model()"},{"location":"api_reference/trestle.core.generators/#trestle.core.generators.generate_sample_value_by_type","text":"Given a type, return sample value. Includes the Optional use of passing down a parent_model Source code in trestle/core/generators.py def generate_sample_value_by_type ( type_ : type , field_name : str , ) -> Union [ datetime , bool , int , str , float , Enum ]: \"\"\"Given a type, return sample value. Includes the Optional use of passing down a parent_model \"\"\" # FIXME: Should be in separate generator module as it inherits EVERYTHING if type_ is datetime : return datetime . now () . astimezone () if type_ is bool : return False if type_ is int : return 0 if type_ is str : if field_name == 'oscal_version' : return OSCAL_VERSION return 'REPLACE_ME' if type_ is float : return 0.00 if safe_is_sub ( type_ , ConstrainedStr ) or ( hasattr ( type_ , '__name__' ) and 'ConstrainedStr' in type_ . __name__ ): # This code here is messy. we need to meet a set of constraints. If we do # TODO: handle regex directly if 'uuid' == field_name : return str ( uuid . uuid4 ()) if field_name == 'date_authorized' : return str ( date . today () . isoformat ()) if field_name == 'oscal_version' : return OSCAL_VERSION if 'uuid' in field_name : return const . SAMPLE_UUID_STR # Only case where are UUID is required but not in name. if field_name . rstrip ( 's' ) == 'member_of_organization' : return const . SAMPLE_UUID_STR return 'REPLACE_ME' if hasattr ( type_ , '__name__' ) and 'ConstrainedIntValue' in type_ . __name__ : # create an int value as close to the floor as possible does not test upper bound multiple = type_ . multiple_of if type_ . multiple_of else 1 # default to every integer # this command is a bit of a problem floor = type_ . ge if type_ . ge else 0 floor = type_ . gt + 1 if type_ . gt else floor if math . remainder ( floor , multiple ) == 0 : return floor return ( floor + 1 ) * multiple if safe_is_sub ( type_ , Enum ): # keys and values diverge due to hypens in oscal names return type_ ( list ( type_ . __members__ . values ())[ 0 ]) if type_ is pydantic . networks . EmailStr : return pydantic . networks . EmailStr ( 'dummy@sample.com' ) if type_ is pydantic . networks . AnyUrl : # TODO: Cleanup: this should be usable from a url.. but it's not inuitive. return pydantic . networks . AnyUrl ( 'https://sample.com/replaceme.html' , scheme = 'http' , host = 'sample.com' ) if type_ is Any or type_ is Dict [ str , Any ]: # Return empty dict - aka users can put whatever they want here. return {} raise err . TrestleError ( f 'Fatal: Bad type in model { type_ } ' )","title":"generate_sample_value_by_type()"},{"location":"api_reference/trestle.core.generators/#trestle.core.generators.safe_is_sub","text":"Is this a subclass of parent. Source code in trestle/core/generators.py def safe_is_sub ( sub : Any , parent : Any ) -> bool : \"\"\"Is this a subclass of parent.\"\"\" is_class = inspect . isclass ( sub ) return is_class and issubclass ( sub , parent ) handler: python","title":"safe_is_sub()"},{"location":"api_reference/trestle.core.jinja/","text":"trestle.core.jinja \u00a4 Trestle utilities to customize . logger \u00a4 Classes \u00a4 MDCleanInclude ( TrestleJinjaExtension ) \u00a4 Inject the parameter of the tag as the resulting content. Source code in trestle/core/jinja.py class MDCleanInclude ( TrestleJinjaExtension ): \"\"\"Inject the parameter of the tag as the resulting content.\"\"\" tags = { 'md_clean_include' } def __init__ ( self , environment : Environment ) -> None : \"\"\"Ensure enviroment is set and carried into class vars.\"\"\" super () . __init__ ( environment ) def parse ( self , parser ): \"\"\"Execute parsing of md token and return nodes.\"\"\" kwargs = None expected_heading_level = None count = 0 while parser . stream . current . type != lexer . TOKEN_BLOCK_END : count = count + 1 if count > self . max_tag_parse : raise err . TrestleError ( 'Unexpected Jinja tag structure provided, please review docs.' ) token = parser . stream . current if token . test ( 'name:md_clean_include' ): parser . stream . expect ( lexer . TOKEN_NAME ) markdown_source = parser . stream . expect ( lexer . TOKEN_STRING ) elif kwargs is not None : arg = token . value next ( parser . stream ) parser . stream . expect ( lexer . TOKEN_ASSIGN ) token = parser . stream . current exp = self . parse_expression ( parser ) kwargs [ arg ] = exp . value else : if parser . stream . look () . type == lexer . TOKEN_ASSIGN : kwargs = {} continue md_content , _ , _ = self . environment . loader . get_source ( self . environment , markdown_source . value ) fm = frontmatter . loads ( md_content ) content = fm . content content += ' \\n\\n ' if kwargs is not None : expected_heading_level = kwargs . get ( 'heading_level' ) if expected_heading_level is not None : content = adjust_heading_level ( content , expected_heading_level ) local_parser = Parser ( self . environment , content ) top_level_output = local_parser . parse () return top_level_output . body identifier : ClassVar [ str ] \u00a4 tags : Set [ str ] \u00a4 Methods \u00a4 __init__ ( self , environment ) special \u00a4 Source code in trestle/core/jinja.py def __init__ ( self , environment : Environment ) -> None : \"\"\"Ensure enviroment is set and carried into class vars.\"\"\" super () . __init__ ( environment ) parse ( self , parser ) \u00a4 Execute parsing of md token and return nodes. Source code in trestle/core/jinja.py def parse ( self , parser ): \"\"\"Execute parsing of md token and return nodes.\"\"\" kwargs = None expected_heading_level = None count = 0 while parser . stream . current . type != lexer . TOKEN_BLOCK_END : count = count + 1 if count > self . max_tag_parse : raise err . TrestleError ( 'Unexpected Jinja tag structure provided, please review docs.' ) token = parser . stream . current if token . test ( 'name:md_clean_include' ): parser . stream . expect ( lexer . TOKEN_NAME ) markdown_source = parser . stream . expect ( lexer . TOKEN_STRING ) elif kwargs is not None : arg = token . value next ( parser . stream ) parser . stream . expect ( lexer . TOKEN_ASSIGN ) token = parser . stream . current exp = self . parse_expression ( parser ) kwargs [ arg ] = exp . value else : if parser . stream . look () . type == lexer . TOKEN_ASSIGN : kwargs = {} continue md_content , _ , _ = self . environment . loader . get_source ( self . environment , markdown_source . value ) fm = frontmatter . loads ( md_content ) content = fm . content content += ' \\n\\n ' if kwargs is not None : expected_heading_level = kwargs . get ( 'heading_level' ) if expected_heading_level is not None : content = adjust_heading_level ( content , expected_heading_level ) local_parser = Parser ( self . environment , content ) top_level_output = local_parser . parse () return top_level_output . body MDDatestamp ( TrestleJinjaExtension ) \u00a4 Inject the parameter of the tag as the resulting content. Source code in trestle/core/jinja.py class MDDatestamp ( TrestleJinjaExtension ): \"\"\"Inject the parameter of the tag as the resulting content.\"\"\" tags = { 'md_datestamp' } def __init__ ( self , environment : Environment ) -> None : \"\"\"Ensure enviroment is set and carried into class vars.\"\"\" super () . __init__ ( environment ) def parse ( self , parser ): \"\"\"Execute parsing of md token and return nodes.\"\"\" kwargs = None count = 0 while parser . stream . current . type != lexer . TOKEN_BLOCK_END : count = count + 1 token = parser . stream . current if count > self . max_tag_parse : raise err . TrestleError ( f 'Unexpected Jinja tag structure provided at token { token . value } ' ) if token . test ( 'name:md_datestamp' ): parser . stream . expect ( lexer . TOKEN_NAME ) elif kwargs is not None : arg = token . value next ( parser . stream ) parser . stream . expect ( lexer . TOKEN_ASSIGN ) token = parser . stream . current exp = self . parse_expression ( parser ) kwargs [ arg ] = exp . value else : if parser . stream . look () . type == lexer . TOKEN_ASSIGN or parser . stream . look () . type == lexer . TOKEN_STRING : kwargs = {} continue if kwargs is not None : if 'format' in kwargs and type ( kwargs [ 'format' ] is str ): date_string = date . today () . strftime ( kwargs [ 'format' ]) else : date_string = date . today () . strftime ( markdown_const . JINJA_DATESTAMP_FORMAT ) if 'newline' in kwargs and kwargs [ 'newline' ] is False : pass else : date_string += ' \\n\\n ' else : date_string = date . today () . strftime ( markdown_const . JINJA_DATESTAMP_FORMAT ) + ' \\n\\n ' local_parser = Parser ( self . environment , date_string ) datestamp_output = local_parser . parse () return datestamp_output . body identifier : ClassVar [ str ] \u00a4 tags : Set [ str ] \u00a4 Methods \u00a4 __init__ ( self , environment ) special \u00a4 Source code in trestle/core/jinja.py def __init__ ( self , environment : Environment ) -> None : \"\"\"Ensure enviroment is set and carried into class vars.\"\"\" super () . __init__ ( environment ) parse ( self , parser ) \u00a4 Execute parsing of md token and return nodes. Source code in trestle/core/jinja.py def parse ( self , parser ): \"\"\"Execute parsing of md token and return nodes.\"\"\" kwargs = None count = 0 while parser . stream . current . type != lexer . TOKEN_BLOCK_END : count = count + 1 token = parser . stream . current if count > self . max_tag_parse : raise err . TrestleError ( f 'Unexpected Jinja tag structure provided at token { token . value } ' ) if token . test ( 'name:md_datestamp' ): parser . stream . expect ( lexer . TOKEN_NAME ) elif kwargs is not None : arg = token . value next ( parser . stream ) parser . stream . expect ( lexer . TOKEN_ASSIGN ) token = parser . stream . current exp = self . parse_expression ( parser ) kwargs [ arg ] = exp . value else : if parser . stream . look () . type == lexer . TOKEN_ASSIGN or parser . stream . look () . type == lexer . TOKEN_STRING : kwargs = {} continue if kwargs is not None : if 'format' in kwargs and type ( kwargs [ 'format' ] is str ): date_string = date . today () . strftime ( kwargs [ 'format' ]) else : date_string = date . today () . strftime ( markdown_const . JINJA_DATESTAMP_FORMAT ) if 'newline' in kwargs and kwargs [ 'newline' ] is False : pass else : date_string += ' \\n\\n ' else : date_string = date . today () . strftime ( markdown_const . JINJA_DATESTAMP_FORMAT ) + ' \\n\\n ' local_parser = Parser ( self . environment , date_string ) datestamp_output = local_parser . parse () return datestamp_output . body MDSectionInclude ( TrestleJinjaExtension ) \u00a4 Inject the parameter of the tag as the resulting content. Source code in trestle/core/jinja.py class MDSectionInclude ( TrestleJinjaExtension ): \"\"\"Inject the parameter of the tag as the resulting content.\"\"\" tags = { 'mdsection_include' } def __init__ ( self , environment : Environment ) -> None : \"\"\"Ensure enviroment is set and carried into class vars.\"\"\" super () . __init__ ( environment ) def parse ( self , parser ): \"\"\"Execute parsing of md token and return nodes.\"\"\" kwargs = None expected_heading_level = None count = 0 while parser . stream . current . type != lexer . TOKEN_BLOCK_END : count = count + 1 if count > self . max_tag_parse : raise err . TrestleError ( 'Unexpected Jinja tag structure provided, please review docs.' ) token = parser . stream . current if token . test ( 'name:mdsection_include' ): parser . stream . expect ( lexer . TOKEN_NAME ) markdown_source = parser . stream . expect ( lexer . TOKEN_STRING ) section_title = parser . stream . expect ( lexer . TOKEN_STRING ) elif kwargs is not None : arg = token . value next ( parser . stream ) parser . stream . expect ( lexer . TOKEN_ASSIGN ) token = parser . stream . current exp = self . parse_expression ( parser ) kwargs [ arg ] = exp . value else : if parser . stream . look () . type == lexer . TOKEN_ASSIGN : kwargs = {} continue # Use the established environment to source the file md_content , _ , _ = self . environment . loader . get_source ( self . environment , markdown_source . value ) fm = frontmatter . loads ( md_content ) if not fm . metadata == {}: logger . warning ( 'Non zero metadata on MD section include - ignoring' ) full_md = markdown_node . MarkdownNode . build_tree_from_markdown ( fm . content . split ( ' \\n ' )) md_section = full_md . get_node_for_key ( section_title . value , strict_matching = True ) # adjust if kwargs is not None : expected_heading_level = kwargs . get ( 'heading_level' ) if expected_heading_level is not None : level = md_section . get_node_header_lvl () delta = int ( expected_heading_level ) - level if not delta == 0 : md_section . change_header_level_by ( delta ) if not md_section : raise err . TrestleError ( f 'Unable to retrieve section \" { section_title . value } \"\" from { markdown_source . value } jinja template.' ) local_parser = Parser ( self . environment , md_section . content . raw_text ) top_level_output = local_parser . parse () return top_level_output . body identifier : ClassVar [ str ] \u00a4 tags : Set [ str ] \u00a4 Methods \u00a4 __init__ ( self , environment ) special \u00a4 Source code in trestle/core/jinja.py def __init__ ( self , environment : Environment ) -> None : \"\"\"Ensure enviroment is set and carried into class vars.\"\"\" super () . __init__ ( environment ) parse ( self , parser ) \u00a4 Execute parsing of md token and return nodes. Source code in trestle/core/jinja.py def parse ( self , parser ): \"\"\"Execute parsing of md token and return nodes.\"\"\" kwargs = None expected_heading_level = None count = 0 while parser . stream . current . type != lexer . TOKEN_BLOCK_END : count = count + 1 if count > self . max_tag_parse : raise err . TrestleError ( 'Unexpected Jinja tag structure provided, please review docs.' ) token = parser . stream . current if token . test ( 'name:mdsection_include' ): parser . stream . expect ( lexer . TOKEN_NAME ) markdown_source = parser . stream . expect ( lexer . TOKEN_STRING ) section_title = parser . stream . expect ( lexer . TOKEN_STRING ) elif kwargs is not None : arg = token . value next ( parser . stream ) parser . stream . expect ( lexer . TOKEN_ASSIGN ) token = parser . stream . current exp = self . parse_expression ( parser ) kwargs [ arg ] = exp . value else : if parser . stream . look () . type == lexer . TOKEN_ASSIGN : kwargs = {} continue # Use the established environment to source the file md_content , _ , _ = self . environment . loader . get_source ( self . environment , markdown_source . value ) fm = frontmatter . loads ( md_content ) if not fm . metadata == {}: logger . warning ( 'Non zero metadata on MD section include - ignoring' ) full_md = markdown_node . MarkdownNode . build_tree_from_markdown ( fm . content . split ( ' \\n ' )) md_section = full_md . get_node_for_key ( section_title . value , strict_matching = True ) # adjust if kwargs is not None : expected_heading_level = kwargs . get ( 'heading_level' ) if expected_heading_level is not None : level = md_section . get_node_header_lvl () delta = int ( expected_heading_level ) - level if not delta == 0 : md_section . change_header_level_by ( delta ) if not md_section : raise err . TrestleError ( f 'Unable to retrieve section \" { section_title . value } \"\" from { markdown_source . value } jinja template.' ) local_parser = Parser ( self . environment , md_section . content . raw_text ) top_level_output = local_parser . parse () return top_level_output . body TrestleJinjaExtension ( Extension ) \u00a4 Class to define common methods to be inherited from for use in trestle. Source code in trestle/core/jinja.py class TrestleJinjaExtension ( Extension ): \"\"\"Class to define common methods to be inherited from for use in trestle.\"\"\" # This max_tag_parse = 20 def __init__ ( self , environment : Environment ) -> None : \"\"\"Ensure enviroment is set and carried into class vars.\"\"\" super () . __init__ ( environment ) @staticmethod def parse_expression ( parser ): \"\"\"Safely parse jinja expression.\"\"\" # Licensed under MIT from: # https://github.com/MoritzS/jinja2-django-tags/blob/master/jdj_tags/extensions.py#L424 # Due to how the jinja2 parser works, it treats \"foo\" \"bar\" as a single # string literal as it is the case in python. # But the url tag in django supports multiple string arguments, e.g. # \"{% url 'my_view' 'arg1' 'arg2' %}\". # That's why we have to check if it's a string literal first. token = parser . stream . current if token . test ( lexer . TOKEN_STRING ): expr = nodes . Const ( token . value , lineno = token . lineno ) next ( parser . stream ) else : expr = parser . parse_expression ( False ) return expr identifier : ClassVar [ str ] \u00a4 max_tag_parse \u00a4 Methods \u00a4 __init__ ( self , environment ) special \u00a4 Ensure enviroment is set and carried into class vars. Source code in trestle/core/jinja.py def __init__ ( self , environment : Environment ) -> None : \"\"\"Ensure enviroment is set and carried into class vars.\"\"\" super () . __init__ ( environment ) parse_expression ( parser ) staticmethod \u00a4 Safely parse jinja expression. Source code in trestle/core/jinja.py @staticmethod def parse_expression ( parser ): \"\"\"Safely parse jinja expression.\"\"\" # Licensed under MIT from: # https://github.com/MoritzS/jinja2-django-tags/blob/master/jdj_tags/extensions.py#L424 # Due to how the jinja2 parser works, it treats \"foo\" \"bar\" as a single # string literal as it is the case in python. # But the url tag in django supports multiple string arguments, e.g. # \"{% url 'my_view' 'arg1' 'arg2' %}\". # That's why we have to check if it's a string literal first. token = parser . stream . current if token . test ( lexer . TOKEN_STRING ): expr = nodes . Const ( token . value , lineno = token . lineno ) next ( parser . stream ) else : expr = parser . parse_expression ( False ) return expr Functions \u00a4 adjust_heading_level ( input_md , expected ) \u00a4 Adjust the header level of a markdown string such that the most significant header matches the expected #'s. Source code in trestle/core/jinja.py def adjust_heading_level ( input_md : str , expected : int ) -> str : \"\"\"Adjust the header level of a markdown string such that the most significant header matches the expected #'s.\"\"\" output_md = input_md mdn = markdown_node . MarkdownNode . build_tree_from_markdown ( input_md . split ( ' \\n ' )) if mdn . subnodes : mdn_top_heading = mdn . subnodes [ 0 ] . get_node_header_lvl () delta = int ( expected ) - mdn_top_heading if not delta == 0 : mdn . change_header_level_by ( delta ) output_md = mdn . content . raw_text return output_md handler: python","title":"jinja"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja","text":"Trestle utilities to customize .","title":"jinja"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDCleanInclude","text":"Inject the parameter of the tag as the resulting content. Source code in trestle/core/jinja.py class MDCleanInclude ( TrestleJinjaExtension ): \"\"\"Inject the parameter of the tag as the resulting content.\"\"\" tags = { 'md_clean_include' } def __init__ ( self , environment : Environment ) -> None : \"\"\"Ensure enviroment is set and carried into class vars.\"\"\" super () . __init__ ( environment ) def parse ( self , parser ): \"\"\"Execute parsing of md token and return nodes.\"\"\" kwargs = None expected_heading_level = None count = 0 while parser . stream . current . type != lexer . TOKEN_BLOCK_END : count = count + 1 if count > self . max_tag_parse : raise err . TrestleError ( 'Unexpected Jinja tag structure provided, please review docs.' ) token = parser . stream . current if token . test ( 'name:md_clean_include' ): parser . stream . expect ( lexer . TOKEN_NAME ) markdown_source = parser . stream . expect ( lexer . TOKEN_STRING ) elif kwargs is not None : arg = token . value next ( parser . stream ) parser . stream . expect ( lexer . TOKEN_ASSIGN ) token = parser . stream . current exp = self . parse_expression ( parser ) kwargs [ arg ] = exp . value else : if parser . stream . look () . type == lexer . TOKEN_ASSIGN : kwargs = {} continue md_content , _ , _ = self . environment . loader . get_source ( self . environment , markdown_source . value ) fm = frontmatter . loads ( md_content ) content = fm . content content += ' \\n\\n ' if kwargs is not None : expected_heading_level = kwargs . get ( 'heading_level' ) if expected_heading_level is not None : content = adjust_heading_level ( content , expected_heading_level ) local_parser = Parser ( self . environment , content ) top_level_output = local_parser . parse () return top_level_output . body","title":"MDCleanInclude"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDCleanInclude.identifier","text":"","title":"identifier"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDCleanInclude.tags","text":"","title":"tags"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDCleanInclude-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDCleanInclude.__init__","text":"Source code in trestle/core/jinja.py def __init__ ( self , environment : Environment ) -> None : \"\"\"Ensure enviroment is set and carried into class vars.\"\"\" super () . __init__ ( environment )","title":"__init__()"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDCleanInclude.parse","text":"Execute parsing of md token and return nodes. Source code in trestle/core/jinja.py def parse ( self , parser ): \"\"\"Execute parsing of md token and return nodes.\"\"\" kwargs = None expected_heading_level = None count = 0 while parser . stream . current . type != lexer . TOKEN_BLOCK_END : count = count + 1 if count > self . max_tag_parse : raise err . TrestleError ( 'Unexpected Jinja tag structure provided, please review docs.' ) token = parser . stream . current if token . test ( 'name:md_clean_include' ): parser . stream . expect ( lexer . TOKEN_NAME ) markdown_source = parser . stream . expect ( lexer . TOKEN_STRING ) elif kwargs is not None : arg = token . value next ( parser . stream ) parser . stream . expect ( lexer . TOKEN_ASSIGN ) token = parser . stream . current exp = self . parse_expression ( parser ) kwargs [ arg ] = exp . value else : if parser . stream . look () . type == lexer . TOKEN_ASSIGN : kwargs = {} continue md_content , _ , _ = self . environment . loader . get_source ( self . environment , markdown_source . value ) fm = frontmatter . loads ( md_content ) content = fm . content content += ' \\n\\n ' if kwargs is not None : expected_heading_level = kwargs . get ( 'heading_level' ) if expected_heading_level is not None : content = adjust_heading_level ( content , expected_heading_level ) local_parser = Parser ( self . environment , content ) top_level_output = local_parser . parse () return top_level_output . body","title":"parse()"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDDatestamp","text":"Inject the parameter of the tag as the resulting content. Source code in trestle/core/jinja.py class MDDatestamp ( TrestleJinjaExtension ): \"\"\"Inject the parameter of the tag as the resulting content.\"\"\" tags = { 'md_datestamp' } def __init__ ( self , environment : Environment ) -> None : \"\"\"Ensure enviroment is set and carried into class vars.\"\"\" super () . __init__ ( environment ) def parse ( self , parser ): \"\"\"Execute parsing of md token and return nodes.\"\"\" kwargs = None count = 0 while parser . stream . current . type != lexer . TOKEN_BLOCK_END : count = count + 1 token = parser . stream . current if count > self . max_tag_parse : raise err . TrestleError ( f 'Unexpected Jinja tag structure provided at token { token . value } ' ) if token . test ( 'name:md_datestamp' ): parser . stream . expect ( lexer . TOKEN_NAME ) elif kwargs is not None : arg = token . value next ( parser . stream ) parser . stream . expect ( lexer . TOKEN_ASSIGN ) token = parser . stream . current exp = self . parse_expression ( parser ) kwargs [ arg ] = exp . value else : if parser . stream . look () . type == lexer . TOKEN_ASSIGN or parser . stream . look () . type == lexer . TOKEN_STRING : kwargs = {} continue if kwargs is not None : if 'format' in kwargs and type ( kwargs [ 'format' ] is str ): date_string = date . today () . strftime ( kwargs [ 'format' ]) else : date_string = date . today () . strftime ( markdown_const . JINJA_DATESTAMP_FORMAT ) if 'newline' in kwargs and kwargs [ 'newline' ] is False : pass else : date_string += ' \\n\\n ' else : date_string = date . today () . strftime ( markdown_const . JINJA_DATESTAMP_FORMAT ) + ' \\n\\n ' local_parser = Parser ( self . environment , date_string ) datestamp_output = local_parser . parse () return datestamp_output . body","title":"MDDatestamp"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDDatestamp.identifier","text":"","title":"identifier"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDDatestamp.tags","text":"","title":"tags"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDDatestamp-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDDatestamp.__init__","text":"Source code in trestle/core/jinja.py def __init__ ( self , environment : Environment ) -> None : \"\"\"Ensure enviroment is set and carried into class vars.\"\"\" super () . __init__ ( environment )","title":"__init__()"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDDatestamp.parse","text":"Execute parsing of md token and return nodes. Source code in trestle/core/jinja.py def parse ( self , parser ): \"\"\"Execute parsing of md token and return nodes.\"\"\" kwargs = None count = 0 while parser . stream . current . type != lexer . TOKEN_BLOCK_END : count = count + 1 token = parser . stream . current if count > self . max_tag_parse : raise err . TrestleError ( f 'Unexpected Jinja tag structure provided at token { token . value } ' ) if token . test ( 'name:md_datestamp' ): parser . stream . expect ( lexer . TOKEN_NAME ) elif kwargs is not None : arg = token . value next ( parser . stream ) parser . stream . expect ( lexer . TOKEN_ASSIGN ) token = parser . stream . current exp = self . parse_expression ( parser ) kwargs [ arg ] = exp . value else : if parser . stream . look () . type == lexer . TOKEN_ASSIGN or parser . stream . look () . type == lexer . TOKEN_STRING : kwargs = {} continue if kwargs is not None : if 'format' in kwargs and type ( kwargs [ 'format' ] is str ): date_string = date . today () . strftime ( kwargs [ 'format' ]) else : date_string = date . today () . strftime ( markdown_const . JINJA_DATESTAMP_FORMAT ) if 'newline' in kwargs and kwargs [ 'newline' ] is False : pass else : date_string += ' \\n\\n ' else : date_string = date . today () . strftime ( markdown_const . JINJA_DATESTAMP_FORMAT ) + ' \\n\\n ' local_parser = Parser ( self . environment , date_string ) datestamp_output = local_parser . parse () return datestamp_output . body","title":"parse()"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDSectionInclude","text":"Inject the parameter of the tag as the resulting content. Source code in trestle/core/jinja.py class MDSectionInclude ( TrestleJinjaExtension ): \"\"\"Inject the parameter of the tag as the resulting content.\"\"\" tags = { 'mdsection_include' } def __init__ ( self , environment : Environment ) -> None : \"\"\"Ensure enviroment is set and carried into class vars.\"\"\" super () . __init__ ( environment ) def parse ( self , parser ): \"\"\"Execute parsing of md token and return nodes.\"\"\" kwargs = None expected_heading_level = None count = 0 while parser . stream . current . type != lexer . TOKEN_BLOCK_END : count = count + 1 if count > self . max_tag_parse : raise err . TrestleError ( 'Unexpected Jinja tag structure provided, please review docs.' ) token = parser . stream . current if token . test ( 'name:mdsection_include' ): parser . stream . expect ( lexer . TOKEN_NAME ) markdown_source = parser . stream . expect ( lexer . TOKEN_STRING ) section_title = parser . stream . expect ( lexer . TOKEN_STRING ) elif kwargs is not None : arg = token . value next ( parser . stream ) parser . stream . expect ( lexer . TOKEN_ASSIGN ) token = parser . stream . current exp = self . parse_expression ( parser ) kwargs [ arg ] = exp . value else : if parser . stream . look () . type == lexer . TOKEN_ASSIGN : kwargs = {} continue # Use the established environment to source the file md_content , _ , _ = self . environment . loader . get_source ( self . environment , markdown_source . value ) fm = frontmatter . loads ( md_content ) if not fm . metadata == {}: logger . warning ( 'Non zero metadata on MD section include - ignoring' ) full_md = markdown_node . MarkdownNode . build_tree_from_markdown ( fm . content . split ( ' \\n ' )) md_section = full_md . get_node_for_key ( section_title . value , strict_matching = True ) # adjust if kwargs is not None : expected_heading_level = kwargs . get ( 'heading_level' ) if expected_heading_level is not None : level = md_section . get_node_header_lvl () delta = int ( expected_heading_level ) - level if not delta == 0 : md_section . change_header_level_by ( delta ) if not md_section : raise err . TrestleError ( f 'Unable to retrieve section \" { section_title . value } \"\" from { markdown_source . value } jinja template.' ) local_parser = Parser ( self . environment , md_section . content . raw_text ) top_level_output = local_parser . parse () return top_level_output . body","title":"MDSectionInclude"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDSectionInclude.identifier","text":"","title":"identifier"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDSectionInclude.tags","text":"","title":"tags"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDSectionInclude-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDSectionInclude.__init__","text":"Source code in trestle/core/jinja.py def __init__ ( self , environment : Environment ) -> None : \"\"\"Ensure enviroment is set and carried into class vars.\"\"\" super () . __init__ ( environment )","title":"__init__()"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.MDSectionInclude.parse","text":"Execute parsing of md token and return nodes. Source code in trestle/core/jinja.py def parse ( self , parser ): \"\"\"Execute parsing of md token and return nodes.\"\"\" kwargs = None expected_heading_level = None count = 0 while parser . stream . current . type != lexer . TOKEN_BLOCK_END : count = count + 1 if count > self . max_tag_parse : raise err . TrestleError ( 'Unexpected Jinja tag structure provided, please review docs.' ) token = parser . stream . current if token . test ( 'name:mdsection_include' ): parser . stream . expect ( lexer . TOKEN_NAME ) markdown_source = parser . stream . expect ( lexer . TOKEN_STRING ) section_title = parser . stream . expect ( lexer . TOKEN_STRING ) elif kwargs is not None : arg = token . value next ( parser . stream ) parser . stream . expect ( lexer . TOKEN_ASSIGN ) token = parser . stream . current exp = self . parse_expression ( parser ) kwargs [ arg ] = exp . value else : if parser . stream . look () . type == lexer . TOKEN_ASSIGN : kwargs = {} continue # Use the established environment to source the file md_content , _ , _ = self . environment . loader . get_source ( self . environment , markdown_source . value ) fm = frontmatter . loads ( md_content ) if not fm . metadata == {}: logger . warning ( 'Non zero metadata on MD section include - ignoring' ) full_md = markdown_node . MarkdownNode . build_tree_from_markdown ( fm . content . split ( ' \\n ' )) md_section = full_md . get_node_for_key ( section_title . value , strict_matching = True ) # adjust if kwargs is not None : expected_heading_level = kwargs . get ( 'heading_level' ) if expected_heading_level is not None : level = md_section . get_node_header_lvl () delta = int ( expected_heading_level ) - level if not delta == 0 : md_section . change_header_level_by ( delta ) if not md_section : raise err . TrestleError ( f 'Unable to retrieve section \" { section_title . value } \"\" from { markdown_source . value } jinja template.' ) local_parser = Parser ( self . environment , md_section . content . raw_text ) top_level_output = local_parser . parse () return top_level_output . body","title":"parse()"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.TrestleJinjaExtension","text":"Class to define common methods to be inherited from for use in trestle. Source code in trestle/core/jinja.py class TrestleJinjaExtension ( Extension ): \"\"\"Class to define common methods to be inherited from for use in trestle.\"\"\" # This max_tag_parse = 20 def __init__ ( self , environment : Environment ) -> None : \"\"\"Ensure enviroment is set and carried into class vars.\"\"\" super () . __init__ ( environment ) @staticmethod def parse_expression ( parser ): \"\"\"Safely parse jinja expression.\"\"\" # Licensed under MIT from: # https://github.com/MoritzS/jinja2-django-tags/blob/master/jdj_tags/extensions.py#L424 # Due to how the jinja2 parser works, it treats \"foo\" \"bar\" as a single # string literal as it is the case in python. # But the url tag in django supports multiple string arguments, e.g. # \"{% url 'my_view' 'arg1' 'arg2' %}\". # That's why we have to check if it's a string literal first. token = parser . stream . current if token . test ( lexer . TOKEN_STRING ): expr = nodes . Const ( token . value , lineno = token . lineno ) next ( parser . stream ) else : expr = parser . parse_expression ( False ) return expr","title":"TrestleJinjaExtension"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.TrestleJinjaExtension.identifier","text":"","title":"identifier"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.TrestleJinjaExtension.max_tag_parse","text":"","title":"max_tag_parse"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.TrestleJinjaExtension-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.TrestleJinjaExtension.__init__","text":"Ensure enviroment is set and carried into class vars. Source code in trestle/core/jinja.py def __init__ ( self , environment : Environment ) -> None : \"\"\"Ensure enviroment is set and carried into class vars.\"\"\" super () . __init__ ( environment )","title":"__init__()"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.TrestleJinjaExtension.parse_expression","text":"Safely parse jinja expression. Source code in trestle/core/jinja.py @staticmethod def parse_expression ( parser ): \"\"\"Safely parse jinja expression.\"\"\" # Licensed under MIT from: # https://github.com/MoritzS/jinja2-django-tags/blob/master/jdj_tags/extensions.py#L424 # Due to how the jinja2 parser works, it treats \"foo\" \"bar\" as a single # string literal as it is the case in python. # But the url tag in django supports multiple string arguments, e.g. # \"{% url 'my_view' 'arg1' 'arg2' %}\". # That's why we have to check if it's a string literal first. token = parser . stream . current if token . test ( lexer . TOKEN_STRING ): expr = nodes . Const ( token . value , lineno = token . lineno ) next ( parser . stream ) else : expr = parser . parse_expression ( False ) return expr","title":"parse_expression()"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja-functions","text":"","title":"Functions"},{"location":"api_reference/trestle.core.jinja/#trestle.core.jinja.adjust_heading_level","text":"Adjust the header level of a markdown string such that the most significant header matches the expected #'s. Source code in trestle/core/jinja.py def adjust_heading_level ( input_md : str , expected : int ) -> str : \"\"\"Adjust the header level of a markdown string such that the most significant header matches the expected #'s.\"\"\" output_md = input_md mdn = markdown_node . MarkdownNode . build_tree_from_markdown ( input_md . split ( ' \\n ' )) if mdn . subnodes : mdn_top_heading = mdn . subnodes [ 0 ] . get_node_header_lvl () delta = int ( expected ) - mdn_top_heading if not delta == 0 : mdn . change_header_level_by ( delta ) output_md = mdn . content . raw_text return output_md handler: python","title":"adjust_heading_level()"},{"location":"api_reference/trestle.core.markdown.markdown_api/","text":"trestle.core.markdown.markdown_api \u00a4 A markdown API. logger \u00a4 Classes \u00a4 MarkdownAPI \u00a4 A common API that wraps around the existing markdown functionality. Source code in trestle/core/markdown/markdown_api.py class MarkdownAPI : \"\"\"A common API that wraps around the existing markdown functionality.\"\"\" def __init__ ( self ): \"\"\"Initialize markdown API.\"\"\" self . processor = MarkdownProcessor () self . validator = None def load_validator_with_template ( self , md_template_path : pathlib . Path , validate_yaml_header : bool , validate_md_body : bool , md_header_to_validate : Optional [ str ] = None ) -> None : \"\"\"Load and initialize markdown validator.\"\"\" try : self . processor . governed_header = md_header_to_validate template_header , template_tree = self . processor . process_markdown ( md_template_path ) if len ( template_header ) == 0 and validate_yaml_header : raise TrestleError ( f 'Expected yaml header for markdown template where none exists { md_template_path } ' ) self . validator = MarkdownValidator ( md_template_path , template_header , template_tree , validate_yaml_header , validate_md_body , md_header_to_validate ) except TrestleError as e : raise TrestleError ( f 'Error while loading markdown template { md_template_path } : { e } .' ) def validate_instance ( self , md_instance_path : pathlib . Path ) -> bool : \"\"\"Validate a given markdown instance against a template.\"\"\" if self . validator is None : raise TrestleError ( 'Markdown validator is not initialized, load template first.' ) instance_header , instance_tree = self . processor . process_markdown ( md_instance_path ) return self . validator . is_valid_against_template ( md_instance_path , instance_header , instance_tree ) def write_markdown_with_header ( self , path , header , md_body ) -> None : \"\"\"Write markdown with the YAML header.\"\"\" try : # use encoding to handle character sets as well as possible with open ( path , 'w' , encoding = const . FILE_ENCODING , errors = 'replace' ) as md_file : md_file . write ( '--- \\n ' ) yaml . safe_dump ( header , md_file , sort_keys = False ) md_file . write ( '--- \\n\\n ' ) md_file . write ( md_body ) except IOError as e : raise TrestleError ( f 'Error while writing markdown file: { e } ' ) Methods \u00a4 __init__ ( self ) special \u00a4 Initialize markdown API. Source code in trestle/core/markdown/markdown_api.py def __init__ ( self ): \"\"\"Initialize markdown API.\"\"\" self . processor = MarkdownProcessor () self . validator = None load_validator_with_template ( self , md_template_path , validate_yaml_header , validate_md_body , md_header_to_validate = None ) \u00a4 Load and initialize markdown validator. Source code in trestle/core/markdown/markdown_api.py def load_validator_with_template ( self , md_template_path : pathlib . Path , validate_yaml_header : bool , validate_md_body : bool , md_header_to_validate : Optional [ str ] = None ) -> None : \"\"\"Load and initialize markdown validator.\"\"\" try : self . processor . governed_header = md_header_to_validate template_header , template_tree = self . processor . process_markdown ( md_template_path ) if len ( template_header ) == 0 and validate_yaml_header : raise TrestleError ( f 'Expected yaml header for markdown template where none exists { md_template_path } ' ) self . validator = MarkdownValidator ( md_template_path , template_header , template_tree , validate_yaml_header , validate_md_body , md_header_to_validate ) except TrestleError as e : raise TrestleError ( f 'Error while loading markdown template { md_template_path } : { e } .' ) validate_instance ( self , md_instance_path ) \u00a4 Validate a given markdown instance against a template. Source code in trestle/core/markdown/markdown_api.py def validate_instance ( self , md_instance_path : pathlib . Path ) -> bool : \"\"\"Validate a given markdown instance against a template.\"\"\" if self . validator is None : raise TrestleError ( 'Markdown validator is not initialized, load template first.' ) instance_header , instance_tree = self . processor . process_markdown ( md_instance_path ) return self . validator . is_valid_against_template ( md_instance_path , instance_header , instance_tree ) write_markdown_with_header ( self , path , header , md_body ) \u00a4 Write markdown with the YAML header. Source code in trestle/core/markdown/markdown_api.py def write_markdown_with_header ( self , path , header , md_body ) -> None : \"\"\"Write markdown with the YAML header.\"\"\" try : # use encoding to handle character sets as well as possible with open ( path , 'w' , encoding = const . FILE_ENCODING , errors = 'replace' ) as md_file : md_file . write ( '--- \\n ' ) yaml . safe_dump ( header , md_file , sort_keys = False ) md_file . write ( '--- \\n\\n ' ) md_file . write ( md_body ) except IOError as e : raise TrestleError ( f 'Error while writing markdown file: { e } ' ) handler: python","title":"markdown_api"},{"location":"api_reference/trestle.core.markdown.markdown_api/#trestle.core.markdown.markdown_api","text":"A markdown API.","title":"markdown_api"},{"location":"api_reference/trestle.core.markdown.markdown_api/#trestle.core.markdown.markdown_api.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.markdown.markdown_api/#trestle.core.markdown.markdown_api-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.markdown.markdown_api/#trestle.core.markdown.markdown_api.MarkdownAPI","text":"A common API that wraps around the existing markdown functionality. Source code in trestle/core/markdown/markdown_api.py class MarkdownAPI : \"\"\"A common API that wraps around the existing markdown functionality.\"\"\" def __init__ ( self ): \"\"\"Initialize markdown API.\"\"\" self . processor = MarkdownProcessor () self . validator = None def load_validator_with_template ( self , md_template_path : pathlib . Path , validate_yaml_header : bool , validate_md_body : bool , md_header_to_validate : Optional [ str ] = None ) -> None : \"\"\"Load and initialize markdown validator.\"\"\" try : self . processor . governed_header = md_header_to_validate template_header , template_tree = self . processor . process_markdown ( md_template_path ) if len ( template_header ) == 0 and validate_yaml_header : raise TrestleError ( f 'Expected yaml header for markdown template where none exists { md_template_path } ' ) self . validator = MarkdownValidator ( md_template_path , template_header , template_tree , validate_yaml_header , validate_md_body , md_header_to_validate ) except TrestleError as e : raise TrestleError ( f 'Error while loading markdown template { md_template_path } : { e } .' ) def validate_instance ( self , md_instance_path : pathlib . Path ) -> bool : \"\"\"Validate a given markdown instance against a template.\"\"\" if self . validator is None : raise TrestleError ( 'Markdown validator is not initialized, load template first.' ) instance_header , instance_tree = self . processor . process_markdown ( md_instance_path ) return self . validator . is_valid_against_template ( md_instance_path , instance_header , instance_tree ) def write_markdown_with_header ( self , path , header , md_body ) -> None : \"\"\"Write markdown with the YAML header.\"\"\" try : # use encoding to handle character sets as well as possible with open ( path , 'w' , encoding = const . FILE_ENCODING , errors = 'replace' ) as md_file : md_file . write ( '--- \\n ' ) yaml . safe_dump ( header , md_file , sort_keys = False ) md_file . write ( '--- \\n\\n ' ) md_file . write ( md_body ) except IOError as e : raise TrestleError ( f 'Error while writing markdown file: { e } ' )","title":"MarkdownAPI"},{"location":"api_reference/trestle.core.markdown.markdown_api/#trestle.core.markdown.markdown_api.MarkdownAPI-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.markdown.markdown_api/#trestle.core.markdown.markdown_api.MarkdownAPI.__init__","text":"Initialize markdown API. Source code in trestle/core/markdown/markdown_api.py def __init__ ( self ): \"\"\"Initialize markdown API.\"\"\" self . processor = MarkdownProcessor () self . validator = None","title":"__init__()"},{"location":"api_reference/trestle.core.markdown.markdown_api/#trestle.core.markdown.markdown_api.MarkdownAPI.load_validator_with_template","text":"Load and initialize markdown validator. Source code in trestle/core/markdown/markdown_api.py def load_validator_with_template ( self , md_template_path : pathlib . Path , validate_yaml_header : bool , validate_md_body : bool , md_header_to_validate : Optional [ str ] = None ) -> None : \"\"\"Load and initialize markdown validator.\"\"\" try : self . processor . governed_header = md_header_to_validate template_header , template_tree = self . processor . process_markdown ( md_template_path ) if len ( template_header ) == 0 and validate_yaml_header : raise TrestleError ( f 'Expected yaml header for markdown template where none exists { md_template_path } ' ) self . validator = MarkdownValidator ( md_template_path , template_header , template_tree , validate_yaml_header , validate_md_body , md_header_to_validate ) except TrestleError as e : raise TrestleError ( f 'Error while loading markdown template { md_template_path } : { e } .' )","title":"load_validator_with_template()"},{"location":"api_reference/trestle.core.markdown.markdown_api/#trestle.core.markdown.markdown_api.MarkdownAPI.validate_instance","text":"Validate a given markdown instance against a template. Source code in trestle/core/markdown/markdown_api.py def validate_instance ( self , md_instance_path : pathlib . Path ) -> bool : \"\"\"Validate a given markdown instance against a template.\"\"\" if self . validator is None : raise TrestleError ( 'Markdown validator is not initialized, load template first.' ) instance_header , instance_tree = self . processor . process_markdown ( md_instance_path ) return self . validator . is_valid_against_template ( md_instance_path , instance_header , instance_tree )","title":"validate_instance()"},{"location":"api_reference/trestle.core.markdown.markdown_api/#trestle.core.markdown.markdown_api.MarkdownAPI.write_markdown_with_header","text":"Write markdown with the YAML header. Source code in trestle/core/markdown/markdown_api.py def write_markdown_with_header ( self , path , header , md_body ) -> None : \"\"\"Write markdown with the YAML header.\"\"\" try : # use encoding to handle character sets as well as possible with open ( path , 'w' , encoding = const . FILE_ENCODING , errors = 'replace' ) as md_file : md_file . write ( '--- \\n ' ) yaml . safe_dump ( header , md_file , sort_keys = False ) md_file . write ( '--- \\n\\n ' ) md_file . write ( md_body ) except IOError as e : raise TrestleError ( f 'Error while writing markdown file: { e } ' ) handler: python","title":"write_markdown_with_header()"},{"location":"api_reference/trestle.core.markdown.markdown_const/","text":"trestle.core.markdown.markdown_const \u00a4 Markdown specific constants. BLOCKQUOTE_CHAR \u00a4 CODEBLOCK_DEF \u00a4 GOVERNED_DOC_REGEX \u00a4 HEADER_REGEX \u00a4 HTML_COMMENT_END_REGEX \u00a4 HTML_COMMENT_START \u00a4 HTML_TAG_REGEX_END \u00a4 HTML_TAG_REGEX_START \u00a4 INLINE_CODE_CHAR \u00a4 JINJA_DATESTAMP_FORMAT \u00a4 LIST_CHAR \u00a4 SUBSTITUTION_REGEX \u00a4 TABLE_REGEX \u00a4 TABLE_SYMBOL \u00a4 handler: python","title":"markdown_const"},{"location":"api_reference/trestle.core.markdown.markdown_const/#trestle.core.markdown.markdown_const","text":"Markdown specific constants.","title":"markdown_const"},{"location":"api_reference/trestle.core.markdown.markdown_const/#trestle.core.markdown.markdown_const.BLOCKQUOTE_CHAR","text":"","title":"BLOCKQUOTE_CHAR"},{"location":"api_reference/trestle.core.markdown.markdown_const/#trestle.core.markdown.markdown_const.CODEBLOCK_DEF","text":"","title":"CODEBLOCK_DEF"},{"location":"api_reference/trestle.core.markdown.markdown_const/#trestle.core.markdown.markdown_const.GOVERNED_DOC_REGEX","text":"","title":"GOVERNED_DOC_REGEX"},{"location":"api_reference/trestle.core.markdown.markdown_const/#trestle.core.markdown.markdown_const.HEADER_REGEX","text":"","title":"HEADER_REGEX"},{"location":"api_reference/trestle.core.markdown.markdown_const/#trestle.core.markdown.markdown_const.HTML_COMMENT_END_REGEX","text":"","title":"HTML_COMMENT_END_REGEX"},{"location":"api_reference/trestle.core.markdown.markdown_const/#trestle.core.markdown.markdown_const.HTML_COMMENT_START","text":"","title":"HTML_COMMENT_START"},{"location":"api_reference/trestle.core.markdown.markdown_const/#trestle.core.markdown.markdown_const.HTML_TAG_REGEX_END","text":"","title":"HTML_TAG_REGEX_END"},{"location":"api_reference/trestle.core.markdown.markdown_const/#trestle.core.markdown.markdown_const.HTML_TAG_REGEX_START","text":"","title":"HTML_TAG_REGEX_START"},{"location":"api_reference/trestle.core.markdown.markdown_const/#trestle.core.markdown.markdown_const.INLINE_CODE_CHAR","text":"","title":"INLINE_CODE_CHAR"},{"location":"api_reference/trestle.core.markdown.markdown_const/#trestle.core.markdown.markdown_const.JINJA_DATESTAMP_FORMAT","text":"","title":"JINJA_DATESTAMP_FORMAT"},{"location":"api_reference/trestle.core.markdown.markdown_const/#trestle.core.markdown.markdown_const.LIST_CHAR","text":"","title":"LIST_CHAR"},{"location":"api_reference/trestle.core.markdown.markdown_const/#trestle.core.markdown.markdown_const.SUBSTITUTION_REGEX","text":"","title":"SUBSTITUTION_REGEX"},{"location":"api_reference/trestle.core.markdown.markdown_const/#trestle.core.markdown.markdown_const.TABLE_REGEX","text":"","title":"TABLE_REGEX"},{"location":"api_reference/trestle.core.markdown.markdown_const/#trestle.core.markdown.markdown_const.TABLE_SYMBOL","text":"handler: python","title":"TABLE_SYMBOL"},{"location":"api_reference/trestle.core.markdown.markdown_node/","text":"trestle.core.markdown.markdown_node \u00a4 A markdown node. logger \u00a4 Classes \u00a4 MarkdownNode \u00a4 Markdown will be read to the tree. Source code in trestle/core/markdown/markdown_node.py class MarkdownNode : \"\"\"Markdown will be read to the tree.\"\"\" def __init__ ( self , key : str , content : SectionContent ): \"\"\"Initialize markdown node.\"\"\" self . subnodes : List [ MarkdownNode ] = [] self . key = key self . content = content @classmethod def build_tree_from_markdown ( cls , lines : List [ str ], governed_header : Optional [ str ] = None ): \"\"\"Construct a tree out of the given markdown.\"\"\" ob = cls . __new__ ( cls ) start_level = ob . _get_max_header_lvl ( lines ) ob , _ = ob . _build_tree ( lines , 'root' , 0 , start_level , governed_header ) return ob def get_all_headers_for_level ( self , level : int ) -> Iterable [ str ]: \"\"\"Return all headers per specified level of heirarchy.\"\"\" return list ( filter ( lambda header : self . _get_header_level_if_valid ( header ) == level , self . content . subnodes_keys ) ) . __iter__ () def get_node_for_key ( self , key : str , strict_matching : bool = True ) -> Optional [ MarkdownNode ]: \"\"\"Return a node for the given key, substring matching is supported.\"\"\" if not strict_matching : if not any ([ key in el for el in self . content . subnodes_keys ]): return None elif key not in self . content . subnodes_keys : return None return self . _rec_traverse ( self , key , strict_matching ) def get_all_headers_for_key ( self , key : str , strict_matching : bool = True ) -> Iterable [ str ]: \"\"\"Return all headers contained in the node with a given key.\"\"\" if strict_matching : return list ( filter ( lambda header : key == header , self . content . subnodes_keys )) . __iter__ () else : return list ( filter ( lambda header : key in header , self . content . subnodes_keys )) . __iter__ () def get_node_header_lvl ( self ) -> Optional [ int ]: \"\"\"Return current node header level.\"\"\" return self . _get_header_level_if_valid ( self . key ) def change_header_level_by ( self , delta_level : int ) -> None : \"\"\" Change all headers in the tree by specified level up or down. All children nodes will be modified by specified level as well. Args: delta_level: each header will be modified by this number, can be negative. \"\"\" # construct a map header_map = {} if self . key != 'root' : new_key = self . _modify_header_level ( self . key , delta_level ) header_map [ self . key ] = new_key for key in self . content . subnodes_keys : new_key = self . _modify_header_level ( key , delta_level ) header_map [ key ] = new_key # go through all contents and modify headers self . _rec_traverse_header_update ( self , header_map ) def _build_tree ( self , lines : List [ str ], root_key : str , starting_line : int , level : int , governed_header : Optional [ str ] = None ) -> Tuple [ MarkdownNode , int ]: \"\"\" Build a tree from the markdown recursively. The tree is contructed with valid headers as node's keys and node's content contains everything that is under that header. The subsections are placed into node's children with the same structure. A header is valid iff the line starts with # and it is not: 1. Inside of the html blocks 2. Inside single lined in the <> tags 3. Inside the html comment 4. Inside any table, code block or blockquotes \"\"\" content = SectionContent () node_children = [] i = starting_line while True : if i >= len ( lines ): break line = lines [ i ] . strip ( ' ' ) header_lvl = self . _get_header_level_if_valid ( line ) if header_lvl is not None : if header_lvl >= level + 1 : # build subtree subtree , i = self . _build_tree ( lines , line , i + 1 , level + 1 , governed_header ) node_children . append ( subtree ) content . union ( subtree ) else : break # level of the header is above or equal to the current level, subtree is over elif self . _does_start_with ( line , md_const . CODEBLOCK_DEF ): code_lines , i = self . _read_code_lines ( lines , line , i + 1 ) content . code_lines . extend ( code_lines ) elif self . _does_start_with ( line , md_const . HTML_COMMENT_START ): html_lines , i = self . _read_html_block ( lines , line , i + 1 , md_const . HTML_COMMENT_END_REGEX ) content . html_lines . extend ( html_lines ) elif self . _does_contain ( line , md_const . HTML_TAG_REGEX_START ): html_lines , i = self . _read_html_block ( lines , line , i + 1 , md_const . HTML_TAG_REGEX_END ) content . html_lines . extend ( html_lines ) elif self . _does_start_with ( line , md_const . TABLE_SYMBOL ): table_block , i = self . _read_table_block ( lines , line , i + 1 ) content . tables . extend ( table_block ) elif self . _does_start_with ( line , md_const . BLOCKQUOTE_CHAR ): content . blockquotes . append ( line ) i += 1 elif governed_header is not None and self . _does_contain ( root_key , fr '^[#]+ { governed_header } $' ) and self . _does_contain ( line , md_const . GOVERNED_DOC_REGEX ): regexp = re . compile ( md_const . GOVERNED_DOC_REGEX ) match = regexp . search ( line ) header = match . group ( 0 ) . strip ( '*' ) . strip ( ':' ) content . governed_document . append ( header ) i += 1 else : content . text . append ( line ) i += 1 if starting_line == 0 : starting_line = 1 content . raw_text = ' \\n ' . join ( lines [ starting_line - 1 : i ]) md_node = MarkdownNode ( key = root_key , content = content ) md_node . subnodes = node_children return ( md_node , i ) def _modify_header_level ( self , header : str , delta_level : int ) -> str : \"\"\"Modify header level by specified level.\"\"\" if delta_level == 0 : logger . debug ( 'Nothing to modify in header, level 0 is given.' ) return header current_level = self . _get_header_level_if_valid ( header ) if current_level is None : current_level = 0 if current_level + delta_level < 0 : logger . warning ( f 'Cannot substract { delta_level } as level of { header } is { current_level } . All `#` will be removed.' ) delta_level = current_level * - 1 if current_level + delta_level == 0 : replacement = '' else : replacement = '#' * ( current_level + delta_level ) header = header . replace ( '#' * current_level , replacement ) return header . strip ( ' ' ) def _get_header_level_if_valid ( self , line : str ) -> Optional [ int ]: \"\"\" Return a level of the header if the given line is indeed a header. Level of the header is determined by the number of # symbols. \"\"\" header_symbols = re . match ( md_const . HEADER_REGEX , line ) # Header is valid only if it line starts with header if header_symbols is not None and header_symbols . regs [ 0 ][ 0 ] == 0 : return header_symbols . regs [ 0 ][ 1 ] return None def _does_start_with ( self , line : str , start_chars : str ) -> bool : \"\"\"Determine whether the line starts with given characters.\"\"\" return line . startswith ( start_chars ) def _does_contain ( self , line : str , reg : str ) -> bool : \"\"\"Determine if the line matches regex.\"\"\" if len ( line ) == 0 and reg != r '' : return False regexp = re . compile ( reg ) return regexp . search ( line ) is not None def _read_code_lines ( self , lines : List [ str ], line : str , i : int ) -> Tuple [ str , int ]: \"\"\"Read code block.\"\"\" code_lines = [ line ] while True : if i >= len ( lines ): raise TrestleError ( f 'Code block is not closed: { code_lines } ' ) line = lines [ i ] code_lines . append ( line ) i += 1 if self . _does_contain ( line , md_const . CODEBLOCK_DEF ): break return code_lines , i def _read_html_block ( self , lines : List [ str ], line : str , i : int , ending_regex : str ) -> Tuple [ str , int ]: \"\"\"Read html block.\"\"\" html_block = [ line ] if self . _does_contain ( line , r '<br[ /]*>' ): return html_block , i if self . _does_contain ( line , ending_regex ): return html_block , i while True : if i >= len ( lines ): raise TrestleError ( f 'HTML block is not closed: { html_block } ' ) line = lines [ i ] html_block . append ( line ) i += 1 if self . _does_contain ( line , ending_regex ): break return html_block , i def _read_table_block ( self , lines : List [ str ], line : str , i : int ) -> Tuple [ str , int ]: \"\"\"Read table.\"\"\" table_block = [ line ] while True : if i >= len ( lines ): return table_block , i line = lines [ i ] if not self . _does_contain ( line , md_const . TABLE_REGEX ): table_block . append ( line ) break table_block . append ( line ) i += 1 return table_block , i def _rec_traverse ( self , node , key : str , strict_matching : bool ) -> Optional [ MarkdownNode ]: \"\"\" Recursevely traverses the tree and searches for the given key. If strict matching is turned off, node will be matched if key is a substring of the node's header. \"\"\" if key == node . key or ( not strict_matching and key in node . key ): return node if ( not strict_matching and any ([ key in el for el in node . content . subnodes_keys ])) or ( key in node . content . subnodes_keys ): for subnode in node . subnodes : matched_node = self . _rec_traverse ( subnode , key , strict_matching ) if matched_node is not None : return matched_node return None def _rec_traverse_header_update ( self , node : MarkdownNode , header_map : Dict [ str , str ]) -> None : \"\"\"Recursively traverse tree and update the contents.\"\"\" if node : if node . key != 'root' : new_key = header_map [ node . key ] node . key = new_key # update text lines = node . content . raw_text . split ( ' \\n ' ) if lines : for i in range ( 0 , len ( lines )): line = lines [ i ] if line in header_map . keys (): new_key = header_map [ line ] lines [ i ] = new_key elif line . strip ( ' ' ) in header_map . keys (): # keep spaces if any new_key = header_map [ line . strip ( ' ' )] lines [ i ] = line . replace ( line . strip ( ' ' ), new_key ) node . content . raw_text = ' \\n ' . join ( lines ) # update subnodes if node . content . subnodes_keys : for i in range ( 0 , len ( node . content . subnodes_keys )): subnode_key = node . content . subnodes_keys [ i ] if subnode_key in header_map . keys (): new_key = header_map [ subnode_key ] node . content . subnodes_keys [ i ] = new_key for subnode in node . subnodes : self . _rec_traverse_header_update ( subnode , header_map ) def _get_max_header_lvl ( self , lines : List [ str ]): \"\"\"Go through all lines to determine highest header level. Less # means higher.\"\"\" min_lvl = math . inf for line in lines : line = line . strip ( ' ' ) header_lvl = self . _get_header_level_if_valid ( line ) if header_lvl is not None and header_lvl < min_lvl : min_lvl = header_lvl return min_lvl - 1 Methods \u00a4 __init__ ( self , key , content ) special \u00a4 Initialize markdown node. Source code in trestle/core/markdown/markdown_node.py def __init__ ( self , key : str , content : SectionContent ): \"\"\"Initialize markdown node.\"\"\" self . subnodes : List [ MarkdownNode ] = [] self . key = key self . content = content build_tree_from_markdown ( lines , governed_header = None ) classmethod \u00a4 Construct a tree out of the given markdown. Source code in trestle/core/markdown/markdown_node.py @classmethod def build_tree_from_markdown ( cls , lines : List [ str ], governed_header : Optional [ str ] = None ): \"\"\"Construct a tree out of the given markdown.\"\"\" ob = cls . __new__ ( cls ) start_level = ob . _get_max_header_lvl ( lines ) ob , _ = ob . _build_tree ( lines , 'root' , 0 , start_level , governed_header ) return ob change_header_level_by ( self , delta_level ) \u00a4 Change all headers in the tree by specified level up or down. All children nodes will be modified by specified level as well. Parameters: Name Type Description Default delta_level int each header will be modified by this number, can be negative. required Source code in trestle/core/markdown/markdown_node.py def change_header_level_by ( self , delta_level : int ) -> None : \"\"\" Change all headers in the tree by specified level up or down. All children nodes will be modified by specified level as well. Args: delta_level: each header will be modified by this number, can be negative. \"\"\" # construct a map header_map = {} if self . key != 'root' : new_key = self . _modify_header_level ( self . key , delta_level ) header_map [ self . key ] = new_key for key in self . content . subnodes_keys : new_key = self . _modify_header_level ( key , delta_level ) header_map [ key ] = new_key # go through all contents and modify headers self . _rec_traverse_header_update ( self , header_map ) get_all_headers_for_key ( self , key , strict_matching = True ) \u00a4 Return all headers contained in the node with a given key. Source code in trestle/core/markdown/markdown_node.py def get_all_headers_for_key ( self , key : str , strict_matching : bool = True ) -> Iterable [ str ]: \"\"\"Return all headers contained in the node with a given key.\"\"\" if strict_matching : return list ( filter ( lambda header : key == header , self . content . subnodes_keys )) . __iter__ () else : return list ( filter ( lambda header : key in header , self . content . subnodes_keys )) . __iter__ () get_all_headers_for_level ( self , level ) \u00a4 Return all headers per specified level of heirarchy. Source code in trestle/core/markdown/markdown_node.py def get_all_headers_for_level ( self , level : int ) -> Iterable [ str ]: \"\"\"Return all headers per specified level of heirarchy.\"\"\" return list ( filter ( lambda header : self . _get_header_level_if_valid ( header ) == level , self . content . subnodes_keys ) ) . __iter__ () get_node_for_key ( self , key , strict_matching = True ) \u00a4 Return a node for the given key, substring matching is supported. Source code in trestle/core/markdown/markdown_node.py def get_node_for_key ( self , key : str , strict_matching : bool = True ) -> Optional [ MarkdownNode ]: \"\"\"Return a node for the given key, substring matching is supported.\"\"\" if not strict_matching : if not any ([ key in el for el in self . content . subnodes_keys ]): return None elif key not in self . content . subnodes_keys : return None return self . _rec_traverse ( self , key , strict_matching ) get_node_header_lvl ( self ) \u00a4 Return current node header level. Source code in trestle/core/markdown/markdown_node.py def get_node_header_lvl ( self ) -> Optional [ int ]: \"\"\"Return current node header level.\"\"\" return self . _get_header_level_if_valid ( self . key ) SectionContent \u00a4 A content of the node. Source code in trestle/core/markdown/markdown_node.py class SectionContent : \"\"\"A content of the node.\"\"\" def __init__ ( self ): \"\"\"Initialize section content.\"\"\" self . tables = [] self . text = [] self . code_lines = [] self . html_lines = [] self . blockquotes = [] self . raw_text = '' self . subnodes_keys = [] self . governed_document = [] def union ( self , node : MarkdownNode ) -> None : \"\"\"Unites contents together.\"\"\" self . subnodes_keys . append ( node . key ) self . subnodes_keys . extend ( node . content . subnodes_keys ) self . code_lines . extend ( node . content . code_lines ) self . html_lines . extend ( node . content . html_lines ) self . tables . extend ( node . content . tables ) self . blockquotes . extend ( node . content . blockquotes ) Methods \u00a4 __init__ ( self ) special \u00a4 Initialize section content. Source code in trestle/core/markdown/markdown_node.py def __init__ ( self ): \"\"\"Initialize section content.\"\"\" self . tables = [] self . text = [] self . code_lines = [] self . html_lines = [] self . blockquotes = [] self . raw_text = '' self . subnodes_keys = [] self . governed_document = [] union ( self , node ) \u00a4 Unites contents together. Source code in trestle/core/markdown/markdown_node.py def union ( self , node : MarkdownNode ) -> None : \"\"\"Unites contents together.\"\"\" self . subnodes_keys . append ( node . key ) self . subnodes_keys . extend ( node . content . subnodes_keys ) self . code_lines . extend ( node . content . code_lines ) self . html_lines . extend ( node . content . html_lines ) self . tables . extend ( node . content . tables ) self . blockquotes . extend ( node . content . blockquotes ) handler: python","title":"markdown_node"},{"location":"api_reference/trestle.core.markdown.markdown_node/#trestle.core.markdown.markdown_node","text":"A markdown node.","title":"markdown_node"},{"location":"api_reference/trestle.core.markdown.markdown_node/#trestle.core.markdown.markdown_node.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.markdown.markdown_node/#trestle.core.markdown.markdown_node-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.markdown.markdown_node/#trestle.core.markdown.markdown_node.MarkdownNode","text":"Markdown will be read to the tree. Source code in trestle/core/markdown/markdown_node.py class MarkdownNode : \"\"\"Markdown will be read to the tree.\"\"\" def __init__ ( self , key : str , content : SectionContent ): \"\"\"Initialize markdown node.\"\"\" self . subnodes : List [ MarkdownNode ] = [] self . key = key self . content = content @classmethod def build_tree_from_markdown ( cls , lines : List [ str ], governed_header : Optional [ str ] = None ): \"\"\"Construct a tree out of the given markdown.\"\"\" ob = cls . __new__ ( cls ) start_level = ob . _get_max_header_lvl ( lines ) ob , _ = ob . _build_tree ( lines , 'root' , 0 , start_level , governed_header ) return ob def get_all_headers_for_level ( self , level : int ) -> Iterable [ str ]: \"\"\"Return all headers per specified level of heirarchy.\"\"\" return list ( filter ( lambda header : self . _get_header_level_if_valid ( header ) == level , self . content . subnodes_keys ) ) . __iter__ () def get_node_for_key ( self , key : str , strict_matching : bool = True ) -> Optional [ MarkdownNode ]: \"\"\"Return a node for the given key, substring matching is supported.\"\"\" if not strict_matching : if not any ([ key in el for el in self . content . subnodes_keys ]): return None elif key not in self . content . subnodes_keys : return None return self . _rec_traverse ( self , key , strict_matching ) def get_all_headers_for_key ( self , key : str , strict_matching : bool = True ) -> Iterable [ str ]: \"\"\"Return all headers contained in the node with a given key.\"\"\" if strict_matching : return list ( filter ( lambda header : key == header , self . content . subnodes_keys )) . __iter__ () else : return list ( filter ( lambda header : key in header , self . content . subnodes_keys )) . __iter__ () def get_node_header_lvl ( self ) -> Optional [ int ]: \"\"\"Return current node header level.\"\"\" return self . _get_header_level_if_valid ( self . key ) def change_header_level_by ( self , delta_level : int ) -> None : \"\"\" Change all headers in the tree by specified level up or down. All children nodes will be modified by specified level as well. Args: delta_level: each header will be modified by this number, can be negative. \"\"\" # construct a map header_map = {} if self . key != 'root' : new_key = self . _modify_header_level ( self . key , delta_level ) header_map [ self . key ] = new_key for key in self . content . subnodes_keys : new_key = self . _modify_header_level ( key , delta_level ) header_map [ key ] = new_key # go through all contents and modify headers self . _rec_traverse_header_update ( self , header_map ) def _build_tree ( self , lines : List [ str ], root_key : str , starting_line : int , level : int , governed_header : Optional [ str ] = None ) -> Tuple [ MarkdownNode , int ]: \"\"\" Build a tree from the markdown recursively. The tree is contructed with valid headers as node's keys and node's content contains everything that is under that header. The subsections are placed into node's children with the same structure. A header is valid iff the line starts with # and it is not: 1. Inside of the html blocks 2. Inside single lined in the <> tags 3. Inside the html comment 4. Inside any table, code block or blockquotes \"\"\" content = SectionContent () node_children = [] i = starting_line while True : if i >= len ( lines ): break line = lines [ i ] . strip ( ' ' ) header_lvl = self . _get_header_level_if_valid ( line ) if header_lvl is not None : if header_lvl >= level + 1 : # build subtree subtree , i = self . _build_tree ( lines , line , i + 1 , level + 1 , governed_header ) node_children . append ( subtree ) content . union ( subtree ) else : break # level of the header is above or equal to the current level, subtree is over elif self . _does_start_with ( line , md_const . CODEBLOCK_DEF ): code_lines , i = self . _read_code_lines ( lines , line , i + 1 ) content . code_lines . extend ( code_lines ) elif self . _does_start_with ( line , md_const . HTML_COMMENT_START ): html_lines , i = self . _read_html_block ( lines , line , i + 1 , md_const . HTML_COMMENT_END_REGEX ) content . html_lines . extend ( html_lines ) elif self . _does_contain ( line , md_const . HTML_TAG_REGEX_START ): html_lines , i = self . _read_html_block ( lines , line , i + 1 , md_const . HTML_TAG_REGEX_END ) content . html_lines . extend ( html_lines ) elif self . _does_start_with ( line , md_const . TABLE_SYMBOL ): table_block , i = self . _read_table_block ( lines , line , i + 1 ) content . tables . extend ( table_block ) elif self . _does_start_with ( line , md_const . BLOCKQUOTE_CHAR ): content . blockquotes . append ( line ) i += 1 elif governed_header is not None and self . _does_contain ( root_key , fr '^[#]+ { governed_header } $' ) and self . _does_contain ( line , md_const . GOVERNED_DOC_REGEX ): regexp = re . compile ( md_const . GOVERNED_DOC_REGEX ) match = regexp . search ( line ) header = match . group ( 0 ) . strip ( '*' ) . strip ( ':' ) content . governed_document . append ( header ) i += 1 else : content . text . append ( line ) i += 1 if starting_line == 0 : starting_line = 1 content . raw_text = ' \\n ' . join ( lines [ starting_line - 1 : i ]) md_node = MarkdownNode ( key = root_key , content = content ) md_node . subnodes = node_children return ( md_node , i ) def _modify_header_level ( self , header : str , delta_level : int ) -> str : \"\"\"Modify header level by specified level.\"\"\" if delta_level == 0 : logger . debug ( 'Nothing to modify in header, level 0 is given.' ) return header current_level = self . _get_header_level_if_valid ( header ) if current_level is None : current_level = 0 if current_level + delta_level < 0 : logger . warning ( f 'Cannot substract { delta_level } as level of { header } is { current_level } . All `#` will be removed.' ) delta_level = current_level * - 1 if current_level + delta_level == 0 : replacement = '' else : replacement = '#' * ( current_level + delta_level ) header = header . replace ( '#' * current_level , replacement ) return header . strip ( ' ' ) def _get_header_level_if_valid ( self , line : str ) -> Optional [ int ]: \"\"\" Return a level of the header if the given line is indeed a header. Level of the header is determined by the number of # symbols. \"\"\" header_symbols = re . match ( md_const . HEADER_REGEX , line ) # Header is valid only if it line starts with header if header_symbols is not None and header_symbols . regs [ 0 ][ 0 ] == 0 : return header_symbols . regs [ 0 ][ 1 ] return None def _does_start_with ( self , line : str , start_chars : str ) -> bool : \"\"\"Determine whether the line starts with given characters.\"\"\" return line . startswith ( start_chars ) def _does_contain ( self , line : str , reg : str ) -> bool : \"\"\"Determine if the line matches regex.\"\"\" if len ( line ) == 0 and reg != r '' : return False regexp = re . compile ( reg ) return regexp . search ( line ) is not None def _read_code_lines ( self , lines : List [ str ], line : str , i : int ) -> Tuple [ str , int ]: \"\"\"Read code block.\"\"\" code_lines = [ line ] while True : if i >= len ( lines ): raise TrestleError ( f 'Code block is not closed: { code_lines } ' ) line = lines [ i ] code_lines . append ( line ) i += 1 if self . _does_contain ( line , md_const . CODEBLOCK_DEF ): break return code_lines , i def _read_html_block ( self , lines : List [ str ], line : str , i : int , ending_regex : str ) -> Tuple [ str , int ]: \"\"\"Read html block.\"\"\" html_block = [ line ] if self . _does_contain ( line , r '<br[ /]*>' ): return html_block , i if self . _does_contain ( line , ending_regex ): return html_block , i while True : if i >= len ( lines ): raise TrestleError ( f 'HTML block is not closed: { html_block } ' ) line = lines [ i ] html_block . append ( line ) i += 1 if self . _does_contain ( line , ending_regex ): break return html_block , i def _read_table_block ( self , lines : List [ str ], line : str , i : int ) -> Tuple [ str , int ]: \"\"\"Read table.\"\"\" table_block = [ line ] while True : if i >= len ( lines ): return table_block , i line = lines [ i ] if not self . _does_contain ( line , md_const . TABLE_REGEX ): table_block . append ( line ) break table_block . append ( line ) i += 1 return table_block , i def _rec_traverse ( self , node , key : str , strict_matching : bool ) -> Optional [ MarkdownNode ]: \"\"\" Recursevely traverses the tree and searches for the given key. If strict matching is turned off, node will be matched if key is a substring of the node's header. \"\"\" if key == node . key or ( not strict_matching and key in node . key ): return node if ( not strict_matching and any ([ key in el for el in node . content . subnodes_keys ])) or ( key in node . content . subnodes_keys ): for subnode in node . subnodes : matched_node = self . _rec_traverse ( subnode , key , strict_matching ) if matched_node is not None : return matched_node return None def _rec_traverse_header_update ( self , node : MarkdownNode , header_map : Dict [ str , str ]) -> None : \"\"\"Recursively traverse tree and update the contents.\"\"\" if node : if node . key != 'root' : new_key = header_map [ node . key ] node . key = new_key # update text lines = node . content . raw_text . split ( ' \\n ' ) if lines : for i in range ( 0 , len ( lines )): line = lines [ i ] if line in header_map . keys (): new_key = header_map [ line ] lines [ i ] = new_key elif line . strip ( ' ' ) in header_map . keys (): # keep spaces if any new_key = header_map [ line . strip ( ' ' )] lines [ i ] = line . replace ( line . strip ( ' ' ), new_key ) node . content . raw_text = ' \\n ' . join ( lines ) # update subnodes if node . content . subnodes_keys : for i in range ( 0 , len ( node . content . subnodes_keys )): subnode_key = node . content . subnodes_keys [ i ] if subnode_key in header_map . keys (): new_key = header_map [ subnode_key ] node . content . subnodes_keys [ i ] = new_key for subnode in node . subnodes : self . _rec_traverse_header_update ( subnode , header_map ) def _get_max_header_lvl ( self , lines : List [ str ]): \"\"\"Go through all lines to determine highest header level. Less # means higher.\"\"\" min_lvl = math . inf for line in lines : line = line . strip ( ' ' ) header_lvl = self . _get_header_level_if_valid ( line ) if header_lvl is not None and header_lvl < min_lvl : min_lvl = header_lvl return min_lvl - 1","title":"MarkdownNode"},{"location":"api_reference/trestle.core.markdown.markdown_node/#trestle.core.markdown.markdown_node.MarkdownNode-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.markdown.markdown_node/#trestle.core.markdown.markdown_node.MarkdownNode.__init__","text":"Initialize markdown node. Source code in trestle/core/markdown/markdown_node.py def __init__ ( self , key : str , content : SectionContent ): \"\"\"Initialize markdown node.\"\"\" self . subnodes : List [ MarkdownNode ] = [] self . key = key self . content = content","title":"__init__()"},{"location":"api_reference/trestle.core.markdown.markdown_node/#trestle.core.markdown.markdown_node.MarkdownNode.build_tree_from_markdown","text":"Construct a tree out of the given markdown. Source code in trestle/core/markdown/markdown_node.py @classmethod def build_tree_from_markdown ( cls , lines : List [ str ], governed_header : Optional [ str ] = None ): \"\"\"Construct a tree out of the given markdown.\"\"\" ob = cls . __new__ ( cls ) start_level = ob . _get_max_header_lvl ( lines ) ob , _ = ob . _build_tree ( lines , 'root' , 0 , start_level , governed_header ) return ob","title":"build_tree_from_markdown()"},{"location":"api_reference/trestle.core.markdown.markdown_node/#trestle.core.markdown.markdown_node.MarkdownNode.change_header_level_by","text":"Change all headers in the tree by specified level up or down. All children nodes will be modified by specified level as well. Parameters: Name Type Description Default delta_level int each header will be modified by this number, can be negative. required Source code in trestle/core/markdown/markdown_node.py def change_header_level_by ( self , delta_level : int ) -> None : \"\"\" Change all headers in the tree by specified level up or down. All children nodes will be modified by specified level as well. Args: delta_level: each header will be modified by this number, can be negative. \"\"\" # construct a map header_map = {} if self . key != 'root' : new_key = self . _modify_header_level ( self . key , delta_level ) header_map [ self . key ] = new_key for key in self . content . subnodes_keys : new_key = self . _modify_header_level ( key , delta_level ) header_map [ key ] = new_key # go through all contents and modify headers self . _rec_traverse_header_update ( self , header_map )","title":"change_header_level_by()"},{"location":"api_reference/trestle.core.markdown.markdown_node/#trestle.core.markdown.markdown_node.MarkdownNode.get_all_headers_for_key","text":"Return all headers contained in the node with a given key. Source code in trestle/core/markdown/markdown_node.py def get_all_headers_for_key ( self , key : str , strict_matching : bool = True ) -> Iterable [ str ]: \"\"\"Return all headers contained in the node with a given key.\"\"\" if strict_matching : return list ( filter ( lambda header : key == header , self . content . subnodes_keys )) . __iter__ () else : return list ( filter ( lambda header : key in header , self . content . subnodes_keys )) . __iter__ ()","title":"get_all_headers_for_key()"},{"location":"api_reference/trestle.core.markdown.markdown_node/#trestle.core.markdown.markdown_node.MarkdownNode.get_all_headers_for_level","text":"Return all headers per specified level of heirarchy. Source code in trestle/core/markdown/markdown_node.py def get_all_headers_for_level ( self , level : int ) -> Iterable [ str ]: \"\"\"Return all headers per specified level of heirarchy.\"\"\" return list ( filter ( lambda header : self . _get_header_level_if_valid ( header ) == level , self . content . subnodes_keys ) ) . __iter__ ()","title":"get_all_headers_for_level()"},{"location":"api_reference/trestle.core.markdown.markdown_node/#trestle.core.markdown.markdown_node.MarkdownNode.get_node_for_key","text":"Return a node for the given key, substring matching is supported. Source code in trestle/core/markdown/markdown_node.py def get_node_for_key ( self , key : str , strict_matching : bool = True ) -> Optional [ MarkdownNode ]: \"\"\"Return a node for the given key, substring matching is supported.\"\"\" if not strict_matching : if not any ([ key in el for el in self . content . subnodes_keys ]): return None elif key not in self . content . subnodes_keys : return None return self . _rec_traverse ( self , key , strict_matching )","title":"get_node_for_key()"},{"location":"api_reference/trestle.core.markdown.markdown_node/#trestle.core.markdown.markdown_node.MarkdownNode.get_node_header_lvl","text":"Return current node header level. Source code in trestle/core/markdown/markdown_node.py def get_node_header_lvl ( self ) -> Optional [ int ]: \"\"\"Return current node header level.\"\"\" return self . _get_header_level_if_valid ( self . key )","title":"get_node_header_lvl()"},{"location":"api_reference/trestle.core.markdown.markdown_node/#trestle.core.markdown.markdown_node.SectionContent","text":"A content of the node. Source code in trestle/core/markdown/markdown_node.py class SectionContent : \"\"\"A content of the node.\"\"\" def __init__ ( self ): \"\"\"Initialize section content.\"\"\" self . tables = [] self . text = [] self . code_lines = [] self . html_lines = [] self . blockquotes = [] self . raw_text = '' self . subnodes_keys = [] self . governed_document = [] def union ( self , node : MarkdownNode ) -> None : \"\"\"Unites contents together.\"\"\" self . subnodes_keys . append ( node . key ) self . subnodes_keys . extend ( node . content . subnodes_keys ) self . code_lines . extend ( node . content . code_lines ) self . html_lines . extend ( node . content . html_lines ) self . tables . extend ( node . content . tables ) self . blockquotes . extend ( node . content . blockquotes )","title":"SectionContent"},{"location":"api_reference/trestle.core.markdown.markdown_node/#trestle.core.markdown.markdown_node.SectionContent-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.markdown.markdown_node/#trestle.core.markdown.markdown_node.SectionContent.__init__","text":"Initialize section content. Source code in trestle/core/markdown/markdown_node.py def __init__ ( self ): \"\"\"Initialize section content.\"\"\" self . tables = [] self . text = [] self . code_lines = [] self . html_lines = [] self . blockquotes = [] self . raw_text = '' self . subnodes_keys = [] self . governed_document = []","title":"__init__()"},{"location":"api_reference/trestle.core.markdown.markdown_node/#trestle.core.markdown.markdown_node.SectionContent.union","text":"Unites contents together. Source code in trestle/core/markdown/markdown_node.py def union ( self , node : MarkdownNode ) -> None : \"\"\"Unites contents together.\"\"\" self . subnodes_keys . append ( node . key ) self . subnodes_keys . extend ( node . content . subnodes_keys ) self . code_lines . extend ( node . content . code_lines ) self . html_lines . extend ( node . content . html_lines ) self . tables . extend ( node . content . tables ) self . blockquotes . extend ( node . content . blockquotes ) handler: python","title":"union()"},{"location":"api_reference/trestle.core.markdown.markdown_processor/","text":"trestle.core.markdown.markdown_processor \u00a4 A markdown processor. logger \u00a4 Classes \u00a4 MarkdownProcessor \u00a4 A markdown processor. Source code in trestle/core/markdown/markdown_processor.py class MarkdownProcessor : \"\"\"A markdown processor.\"\"\" def __init__ ( self ) -> None : \"\"\"Initialize markdown processor.\"\"\" self . governed_header = None def render_gfm_to_html ( self , markdown_text : str ) -> str : \"\"\"Render given Github Flavored Markdown to HTML.\"\"\" try : html = cmarkgfm . github_flavored_markdown_to_html ( markdown_text ) return html except ValueError as e : raise TrestleError ( f 'Not a valid Github Flavored markdown: { e } .' ) def process_markdown ( self , md_path : pathlib . Path ) -> Tuple [ Dict , MarkdownNode ]: \"\"\"Parse the markdown and builds the tree to operate over it.\"\"\" header , markdown_wo_header = self . read_markdown_wo_processing ( md_path ) _ = self . render_gfm_to_html ( markdown_wo_header ) lines = markdown_wo_header . split ( ' \\n ' ) tree = MarkdownNode . build_tree_from_markdown ( lines , self . governed_header ) return header , tree def read_markdown_wo_processing ( self , md_path : pathlib . Path ) -> Tuple [ Dict , str ]: \"\"\"Read markdown header to dictionary and body to string.\"\"\" try : contents = frontmatter . loads ( md_path . open ( 'r' , encoding = const . FILE_ENCODING ) . read ()) header = contents . metadata markdown_wo_header = contents . content return header , markdown_wo_header except UnicodeDecodeError as e : logger . debug ( traceback . format_exc ()) raise TrestleError ( f 'Markdown cannot be decoded into { const . FILE_ENCODING } , error: { e } ' ) except ScannerError as e : logger . debug ( traceback . format_exc ()) raise TrestleError ( f 'Header is not in a valid YAML format: { e } ' ) except FileNotFoundError as e : logger . debug ( traceback . format_exc ()) raise TrestleError ( f 'Markdown with path { md_path } , not found: { e } ' ) def fetch_value_from_header ( self , md_path : pathlib . Path , key : str ) -> Optional [ str ]: \"\"\"Fetch value for the given key from the markdown header if exists.\"\"\" header , _ = self . read_markdown_wo_processing ( md_path ) value = None if key in header . keys (): value = header [ key ] return value Methods \u00a4 __init__ ( self ) special \u00a4 Initialize markdown processor. Source code in trestle/core/markdown/markdown_processor.py def __init__ ( self ) -> None : \"\"\"Initialize markdown processor.\"\"\" self . governed_header = None fetch_value_from_header ( self , md_path , key ) \u00a4 Fetch value for the given key from the markdown header if exists. Source code in trestle/core/markdown/markdown_processor.py def fetch_value_from_header ( self , md_path : pathlib . Path , key : str ) -> Optional [ str ]: \"\"\"Fetch value for the given key from the markdown header if exists.\"\"\" header , _ = self . read_markdown_wo_processing ( md_path ) value = None if key in header . keys (): value = header [ key ] return value process_markdown ( self , md_path ) \u00a4 Parse the markdown and builds the tree to operate over it. Source code in trestle/core/markdown/markdown_processor.py def process_markdown ( self , md_path : pathlib . Path ) -> Tuple [ Dict , MarkdownNode ]: \"\"\"Parse the markdown and builds the tree to operate over it.\"\"\" header , markdown_wo_header = self . read_markdown_wo_processing ( md_path ) _ = self . render_gfm_to_html ( markdown_wo_header ) lines = markdown_wo_header . split ( ' \\n ' ) tree = MarkdownNode . build_tree_from_markdown ( lines , self . governed_header ) return header , tree read_markdown_wo_processing ( self , md_path ) \u00a4 Read markdown header to dictionary and body to string. Source code in trestle/core/markdown/markdown_processor.py def read_markdown_wo_processing ( self , md_path : pathlib . Path ) -> Tuple [ Dict , str ]: \"\"\"Read markdown header to dictionary and body to string.\"\"\" try : contents = frontmatter . loads ( md_path . open ( 'r' , encoding = const . FILE_ENCODING ) . read ()) header = contents . metadata markdown_wo_header = contents . content return header , markdown_wo_header except UnicodeDecodeError as e : logger . debug ( traceback . format_exc ()) raise TrestleError ( f 'Markdown cannot be decoded into { const . FILE_ENCODING } , error: { e } ' ) except ScannerError as e : logger . debug ( traceback . format_exc ()) raise TrestleError ( f 'Header is not in a valid YAML format: { e } ' ) except FileNotFoundError as e : logger . debug ( traceback . format_exc ()) raise TrestleError ( f 'Markdown with path { md_path } , not found: { e } ' ) render_gfm_to_html ( self , markdown_text ) \u00a4 Render given Github Flavored Markdown to HTML. Source code in trestle/core/markdown/markdown_processor.py def render_gfm_to_html ( self , markdown_text : str ) -> str : \"\"\"Render given Github Flavored Markdown to HTML.\"\"\" try : html = cmarkgfm . github_flavored_markdown_to_html ( markdown_text ) return html except ValueError as e : raise TrestleError ( f 'Not a valid Github Flavored markdown: { e } .' ) handler: python","title":"markdown_processor"},{"location":"api_reference/trestle.core.markdown.markdown_processor/#trestle.core.markdown.markdown_processor","text":"A markdown processor.","title":"markdown_processor"},{"location":"api_reference/trestle.core.markdown.markdown_processor/#trestle.core.markdown.markdown_processor.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.markdown.markdown_processor/#trestle.core.markdown.markdown_processor-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.markdown.markdown_processor/#trestle.core.markdown.markdown_processor.MarkdownProcessor","text":"A markdown processor. Source code in trestle/core/markdown/markdown_processor.py class MarkdownProcessor : \"\"\"A markdown processor.\"\"\" def __init__ ( self ) -> None : \"\"\"Initialize markdown processor.\"\"\" self . governed_header = None def render_gfm_to_html ( self , markdown_text : str ) -> str : \"\"\"Render given Github Flavored Markdown to HTML.\"\"\" try : html = cmarkgfm . github_flavored_markdown_to_html ( markdown_text ) return html except ValueError as e : raise TrestleError ( f 'Not a valid Github Flavored markdown: { e } .' ) def process_markdown ( self , md_path : pathlib . Path ) -> Tuple [ Dict , MarkdownNode ]: \"\"\"Parse the markdown and builds the tree to operate over it.\"\"\" header , markdown_wo_header = self . read_markdown_wo_processing ( md_path ) _ = self . render_gfm_to_html ( markdown_wo_header ) lines = markdown_wo_header . split ( ' \\n ' ) tree = MarkdownNode . build_tree_from_markdown ( lines , self . governed_header ) return header , tree def read_markdown_wo_processing ( self , md_path : pathlib . Path ) -> Tuple [ Dict , str ]: \"\"\"Read markdown header to dictionary and body to string.\"\"\" try : contents = frontmatter . loads ( md_path . open ( 'r' , encoding = const . FILE_ENCODING ) . read ()) header = contents . metadata markdown_wo_header = contents . content return header , markdown_wo_header except UnicodeDecodeError as e : logger . debug ( traceback . format_exc ()) raise TrestleError ( f 'Markdown cannot be decoded into { const . FILE_ENCODING } , error: { e } ' ) except ScannerError as e : logger . debug ( traceback . format_exc ()) raise TrestleError ( f 'Header is not in a valid YAML format: { e } ' ) except FileNotFoundError as e : logger . debug ( traceback . format_exc ()) raise TrestleError ( f 'Markdown with path { md_path } , not found: { e } ' ) def fetch_value_from_header ( self , md_path : pathlib . Path , key : str ) -> Optional [ str ]: \"\"\"Fetch value for the given key from the markdown header if exists.\"\"\" header , _ = self . read_markdown_wo_processing ( md_path ) value = None if key in header . keys (): value = header [ key ] return value","title":"MarkdownProcessor"},{"location":"api_reference/trestle.core.markdown.markdown_processor/#trestle.core.markdown.markdown_processor.MarkdownProcessor-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.markdown.markdown_processor/#trestle.core.markdown.markdown_processor.MarkdownProcessor.__init__","text":"Initialize markdown processor. Source code in trestle/core/markdown/markdown_processor.py def __init__ ( self ) -> None : \"\"\"Initialize markdown processor.\"\"\" self . governed_header = None","title":"__init__()"},{"location":"api_reference/trestle.core.markdown.markdown_processor/#trestle.core.markdown.markdown_processor.MarkdownProcessor.fetch_value_from_header","text":"Fetch value for the given key from the markdown header if exists. Source code in trestle/core/markdown/markdown_processor.py def fetch_value_from_header ( self , md_path : pathlib . Path , key : str ) -> Optional [ str ]: \"\"\"Fetch value for the given key from the markdown header if exists.\"\"\" header , _ = self . read_markdown_wo_processing ( md_path ) value = None if key in header . keys (): value = header [ key ] return value","title":"fetch_value_from_header()"},{"location":"api_reference/trestle.core.markdown.markdown_processor/#trestle.core.markdown.markdown_processor.MarkdownProcessor.process_markdown","text":"Parse the markdown and builds the tree to operate over it. Source code in trestle/core/markdown/markdown_processor.py def process_markdown ( self , md_path : pathlib . Path ) -> Tuple [ Dict , MarkdownNode ]: \"\"\"Parse the markdown and builds the tree to operate over it.\"\"\" header , markdown_wo_header = self . read_markdown_wo_processing ( md_path ) _ = self . render_gfm_to_html ( markdown_wo_header ) lines = markdown_wo_header . split ( ' \\n ' ) tree = MarkdownNode . build_tree_from_markdown ( lines , self . governed_header ) return header , tree","title":"process_markdown()"},{"location":"api_reference/trestle.core.markdown.markdown_processor/#trestle.core.markdown.markdown_processor.MarkdownProcessor.read_markdown_wo_processing","text":"Read markdown header to dictionary and body to string. Source code in trestle/core/markdown/markdown_processor.py def read_markdown_wo_processing ( self , md_path : pathlib . Path ) -> Tuple [ Dict , str ]: \"\"\"Read markdown header to dictionary and body to string.\"\"\" try : contents = frontmatter . loads ( md_path . open ( 'r' , encoding = const . FILE_ENCODING ) . read ()) header = contents . metadata markdown_wo_header = contents . content return header , markdown_wo_header except UnicodeDecodeError as e : logger . debug ( traceback . format_exc ()) raise TrestleError ( f 'Markdown cannot be decoded into { const . FILE_ENCODING } , error: { e } ' ) except ScannerError as e : logger . debug ( traceback . format_exc ()) raise TrestleError ( f 'Header is not in a valid YAML format: { e } ' ) except FileNotFoundError as e : logger . debug ( traceback . format_exc ()) raise TrestleError ( f 'Markdown with path { md_path } , not found: { e } ' )","title":"read_markdown_wo_processing()"},{"location":"api_reference/trestle.core.markdown.markdown_processor/#trestle.core.markdown.markdown_processor.MarkdownProcessor.render_gfm_to_html","text":"Render given Github Flavored Markdown to HTML. Source code in trestle/core/markdown/markdown_processor.py def render_gfm_to_html ( self , markdown_text : str ) -> str : \"\"\"Render given Github Flavored Markdown to HTML.\"\"\" try : html = cmarkgfm . github_flavored_markdown_to_html ( markdown_text ) return html except ValueError as e : raise TrestleError ( f 'Not a valid Github Flavored markdown: { e } .' ) handler: python","title":"render_gfm_to_html()"},{"location":"api_reference/trestle.core.markdown.markdown_validator/","text":"trestle.core.markdown.markdown_validator \u00a4 Markdown Validator. logger \u00a4 Classes \u00a4 MarkdownValidator \u00a4 A markdown validator. Validates markdown instance against given template. Source code in trestle/core/markdown/markdown_validator.py class MarkdownValidator : \"\"\"A markdown validator. Validates markdown instance against given template.\"\"\" def __init__ ( self , tmp_path : pathlib . Path , template_header : Dict , template_tree : MarkdownNode , validate_yaml_header : bool , validate_md_body : bool , md_header_to_validate : Optional [ str ] = None ): \"\"\"Initialize markdown validator.\"\"\" self . _validate_yaml_header = validate_yaml_header self . _validate_md_body = validate_md_body self . md_header_to_validate = md_header_to_validate . strip ( ' ' ) if md_header_to_validate is not None else None self . template_header = template_header self . template_tree = template_tree self . template_path = tmp_path self . template_version = self . extract_template_version ( self . template_header ) if self . template_version not in str ( self . template_path ): raise TrestleError ( f 'Version of the template { self . template_version } does not match the path { self . template_path } .' + f 'Move the template to the folder { self . template_version } ' ) if 'Version' in self . template_header . keys () and self . template_header [ 'Version' ] != self . template_version : raise TrestleError ( f 'Version does not match template-version in template: { self . template_path } .' ) self . _ignore_headers = [] for key in self . template_header . keys (): if key . lower () . startswith ( 'x-trestle-' ): self . _ignore_headers . append ( key . lower ()) if key . lower () == 'x-trestle-ignore' : for key2 in template_header [ 'x-trestle-ignore' ]: self . _ignore_headers . append ( key2 . lower ()) def is_valid_against_template ( self , instance : pathlib . Path , instance_header : Dict , instance_tree : MarkdownNode ) -> bool : \"\"\" Validate instance markdown against template. Instance is correct against a template iff: 1. For YAML header keys: a. All keys from the template are present and not modified b. Template version in the template and instance match 2. On the Markdown w/o YAML header: a. No additional headers of the level 1 were added b. Headers were not reordered c. Headers in the instance should be a superset of the template headers d. Headers must be in heirarchical order (i.e. # then ### then ## is not allowed) 3. If Governed Header is given then: a. Governed Header is not modified b. All keys (i.e. key: something) inside the section are present Args: instance: a path to the markdown instance that should be validated instance_header: a YAML header extracted from the markdown instance_tree: a tree structure representing markdown contents Returns: Whether or not the the candidate is valid against the template. \"\"\" if self . _validate_yaml_header : headers_match = self . compare_keys ( self . template_header , instance_header , self . _ignore_headers ) if not headers_match : logger . info ( f 'YAML header mismatch between template { self . template_path } and instance { instance } ' ) return False elif headers_match and not self . _validate_md_body : return True if self . md_header_to_validate is not None : instance_gov_node = instance_tree . get_node_for_key ( self . md_header_to_validate , False ) template_gov_node = self . template_tree . get_node_for_key ( self . md_header_to_validate , False ) if instance_gov_node is None : logger . info ( f 'Governed document not found in instance: { instance } ' ) return False instance_keys = instance_gov_node . content . governed_document template_keys = template_gov_node . content . governed_document is_valid = self . _validate_headers ( instance , template_keys , instance_keys ) if not is_valid : return False if self . _validate_md_body : instance_keys = instance_tree . content . subnodes_keys template_keys = self . template_tree . content . subnodes_keys if len ( template_keys ) > len ( instance_keys ): logger . info ( f 'Headings in the instance: { instance } were removed.' ) return False instance_lvl1_keys = list ( instance_tree . get_all_headers_for_level ( 1 )) template_lvl1_keys = list ( self . template_tree . get_all_headers_for_level ( 1 )) if len ( template_lvl1_keys ) < len ( instance_lvl1_keys ): logger . info ( f 'New headers of level 1 were added to the markdown instance: { instance } . ' ) return False is_valid = self . _validate_headers ( instance , template_keys , instance_keys ) if not is_valid : return False return True @classmethod def compare_keys ( cls , template : Dict [ str , Any ], candidate : Dict [ str , Any ], ignore_fields : Optional [ Dict [ str , Any ]] = None ) -> bool : \"\"\" Compare a template dictionary against a candidate as to whether key structure is maintained. Args: template: Template dict which is used as a model of key-value pairs candidate: Candidate dictionary to be measured Returns: Whether or not the the candidate matches the template keys. \"\"\" if ignore_fields is None : ignore_fields = [] for key in list ( candidate . keys ()): if key . lower () in ignore_fields : candidate . pop ( key ) for key in list ( template . keys ()): if key . lower () in ignore_fields : template . pop ( key ) template_version = cls . extract_template_version ( template ) candidate_version = cls . extract_template_version ( candidate ) if template_version != candidate_version : logger . info ( f 'Versions of the template { template_version } and instance { candidate_version } are different' ) return False if len ( template . keys ()) != len ( candidate . keys ()): logger . info ( f 'Number of keys does not match in template { template } and instance { candidate } ' ) return False for key in template . keys (): if key in candidate . keys (): if type ( template [ key ]) == dict : if type ( candidate [ key ]) == dict : status = cls . compare_keys ( template [ key ], candidate [ key ], ignore_fields ) if not status : return status else : logger . info ( f 'Value under { key } must be dictionary in candidate { candidate } ' ) return False else : logger . info ( f 'Key { key } is not in candidate { candidate } ' ) return False return True def _validate_headers ( self , instance : pathlib . Path , template_keys : List [ str ], instance_keys : List [ str ]) -> bool : \"\"\"Validate instance headers against template.\"\"\" if len ( template_keys ) > len ( instance_keys ): logger . info ( f 'Headings in the instance: { instance } were removed.' ) return False template_header_pointer = 0 for key in instance_keys : if template_header_pointer >= len ( template_keys ): break if key in template_keys and key != template_keys [ template_header_pointer ]: logger . info ( f 'Headers in the instance: { instance } were shuffled or modified.' ) return False elif key in template_keys and key == template_keys [ template_header_pointer ]: template_header_pointer += 1 elif re . search ( md_const . SUBSTITUTION_REGEX , template_keys [ template_header_pointer ]) is not None : template_header_pointer += 1 # skip headers with substitutions if template_header_pointer != len ( template_keys ): logger . info ( f 'Headings in the instance: { instance } were removed.' ) return False return True @classmethod def extract_template_version ( cls , header : Dict [ str , Any ]) -> Optional [ str ]: \"\"\" Extract the template version from the header. If no header is found then starting version(0.0.1) will be used by default \"\"\" if TEMPLATE_VERSION_HEADER not in header . keys (): return START_TEMPLATE_VERSION return header [ TEMPLATE_VERSION_HEADER ] Methods \u00a4 __init__ ( self , tmp_path , template_header , template_tree , validate_yaml_header , validate_md_body , md_header_to_validate = None ) special \u00a4 Initialize markdown validator. Source code in trestle/core/markdown/markdown_validator.py def __init__ ( self , tmp_path : pathlib . Path , template_header : Dict , template_tree : MarkdownNode , validate_yaml_header : bool , validate_md_body : bool , md_header_to_validate : Optional [ str ] = None ): \"\"\"Initialize markdown validator.\"\"\" self . _validate_yaml_header = validate_yaml_header self . _validate_md_body = validate_md_body self . md_header_to_validate = md_header_to_validate . strip ( ' ' ) if md_header_to_validate is not None else None self . template_header = template_header self . template_tree = template_tree self . template_path = tmp_path self . template_version = self . extract_template_version ( self . template_header ) if self . template_version not in str ( self . template_path ): raise TrestleError ( f 'Version of the template { self . template_version } does not match the path { self . template_path } .' + f 'Move the template to the folder { self . template_version } ' ) if 'Version' in self . template_header . keys () and self . template_header [ 'Version' ] != self . template_version : raise TrestleError ( f 'Version does not match template-version in template: { self . template_path } .' ) self . _ignore_headers = [] for key in self . template_header . keys (): if key . lower () . startswith ( 'x-trestle-' ): self . _ignore_headers . append ( key . lower ()) if key . lower () == 'x-trestle-ignore' : for key2 in template_header [ 'x-trestle-ignore' ]: self . _ignore_headers . append ( key2 . lower ()) compare_keys ( template , candidate , ignore_fields = None ) classmethod \u00a4 Compare a template dictionary against a candidate as to whether key structure is maintained. Parameters: Name Type Description Default template Dict[str, Any] Template dict which is used as a model of key-value pairs required candidate Dict[str, Any] Candidate dictionary to be measured required Returns: Type Description bool Whether or not the the candidate matches the template keys. Source code in trestle/core/markdown/markdown_validator.py @classmethod def compare_keys ( cls , template : Dict [ str , Any ], candidate : Dict [ str , Any ], ignore_fields : Optional [ Dict [ str , Any ]] = None ) -> bool : \"\"\" Compare a template dictionary against a candidate as to whether key structure is maintained. Args: template: Template dict which is used as a model of key-value pairs candidate: Candidate dictionary to be measured Returns: Whether or not the the candidate matches the template keys. \"\"\" if ignore_fields is None : ignore_fields = [] for key in list ( candidate . keys ()): if key . lower () in ignore_fields : candidate . pop ( key ) for key in list ( template . keys ()): if key . lower () in ignore_fields : template . pop ( key ) template_version = cls . extract_template_version ( template ) candidate_version = cls . extract_template_version ( candidate ) if template_version != candidate_version : logger . info ( f 'Versions of the template { template_version } and instance { candidate_version } are different' ) return False if len ( template . keys ()) != len ( candidate . keys ()): logger . info ( f 'Number of keys does not match in template { template } and instance { candidate } ' ) return False for key in template . keys (): if key in candidate . keys (): if type ( template [ key ]) == dict : if type ( candidate [ key ]) == dict : status = cls . compare_keys ( template [ key ], candidate [ key ], ignore_fields ) if not status : return status else : logger . info ( f 'Value under { key } must be dictionary in candidate { candidate } ' ) return False else : logger . info ( f 'Key { key } is not in candidate { candidate } ' ) return False return True extract_template_version ( header ) classmethod \u00a4 Extract the template version from the header. If no header is found then starting version(0.0.1) will be used by default Source code in trestle/core/markdown/markdown_validator.py @classmethod def extract_template_version ( cls , header : Dict [ str , Any ]) -> Optional [ str ]: \"\"\" Extract the template version from the header. If no header is found then starting version(0.0.1) will be used by default \"\"\" if TEMPLATE_VERSION_HEADER not in header . keys (): return START_TEMPLATE_VERSION return header [ TEMPLATE_VERSION_HEADER ] is_valid_against_template ( self , instance , instance_header , instance_tree ) \u00a4 Validate instance markdown against template. Instance is correct against a template iff: 1. For YAML header keys: a. All keys from the template are present and not modified b. Template version in the template and instance match 2. On the Markdown w/o YAML header: a. No additional headers of the level 1 were added b. Headers were not reordered c. Headers in the instance should be a superset of the template headers d. Headers must be in heirarchical order (i.e. # then ### then ## is not allowed) 3. If Governed Header is given then: a. Governed Header is not modified b. All keys (i.e. key: something) inside the section are present Parameters: Name Type Description Default instance Path a path to the markdown instance that should be validated required instance_header Dict a YAML header extracted from the markdown required instance_tree MarkdownNode a tree structure representing markdown contents required Returns: Type Description bool Whether or not the the candidate is valid against the template. Source code in trestle/core/markdown/markdown_validator.py def is_valid_against_template ( self , instance : pathlib . Path , instance_header : Dict , instance_tree : MarkdownNode ) -> bool : \"\"\" Validate instance markdown against template. Instance is correct against a template iff: 1. For YAML header keys: a. All keys from the template are present and not modified b. Template version in the template and instance match 2. On the Markdown w/o YAML header: a. No additional headers of the level 1 were added b. Headers were not reordered c. Headers in the instance should be a superset of the template headers d. Headers must be in heirarchical order (i.e. # then ### then ## is not allowed) 3. If Governed Header is given then: a. Governed Header is not modified b. All keys (i.e. key: something) inside the section are present Args: instance: a path to the markdown instance that should be validated instance_header: a YAML header extracted from the markdown instance_tree: a tree structure representing markdown contents Returns: Whether or not the the candidate is valid against the template. \"\"\" if self . _validate_yaml_header : headers_match = self . compare_keys ( self . template_header , instance_header , self . _ignore_headers ) if not headers_match : logger . info ( f 'YAML header mismatch between template { self . template_path } and instance { instance } ' ) return False elif headers_match and not self . _validate_md_body : return True if self . md_header_to_validate is not None : instance_gov_node = instance_tree . get_node_for_key ( self . md_header_to_validate , False ) template_gov_node = self . template_tree . get_node_for_key ( self . md_header_to_validate , False ) if instance_gov_node is None : logger . info ( f 'Governed document not found in instance: { instance } ' ) return False instance_keys = instance_gov_node . content . governed_document template_keys = template_gov_node . content . governed_document is_valid = self . _validate_headers ( instance , template_keys , instance_keys ) if not is_valid : return False if self . _validate_md_body : instance_keys = instance_tree . content . subnodes_keys template_keys = self . template_tree . content . subnodes_keys if len ( template_keys ) > len ( instance_keys ): logger . info ( f 'Headings in the instance: { instance } were removed.' ) return False instance_lvl1_keys = list ( instance_tree . get_all_headers_for_level ( 1 )) template_lvl1_keys = list ( self . template_tree . get_all_headers_for_level ( 1 )) if len ( template_lvl1_keys ) < len ( instance_lvl1_keys ): logger . info ( f 'New headers of level 1 were added to the markdown instance: { instance } . ' ) return False is_valid = self . _validate_headers ( instance , template_keys , instance_keys ) if not is_valid : return False return True handler: python","title":"markdown_validator"},{"location":"api_reference/trestle.core.markdown.markdown_validator/#trestle.core.markdown.markdown_validator","text":"Markdown Validator.","title":"markdown_validator"},{"location":"api_reference/trestle.core.markdown.markdown_validator/#trestle.core.markdown.markdown_validator.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.markdown.markdown_validator/#trestle.core.markdown.markdown_validator-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.markdown.markdown_validator/#trestle.core.markdown.markdown_validator.MarkdownValidator","text":"A markdown validator. Validates markdown instance against given template. Source code in trestle/core/markdown/markdown_validator.py class MarkdownValidator : \"\"\"A markdown validator. Validates markdown instance against given template.\"\"\" def __init__ ( self , tmp_path : pathlib . Path , template_header : Dict , template_tree : MarkdownNode , validate_yaml_header : bool , validate_md_body : bool , md_header_to_validate : Optional [ str ] = None ): \"\"\"Initialize markdown validator.\"\"\" self . _validate_yaml_header = validate_yaml_header self . _validate_md_body = validate_md_body self . md_header_to_validate = md_header_to_validate . strip ( ' ' ) if md_header_to_validate is not None else None self . template_header = template_header self . template_tree = template_tree self . template_path = tmp_path self . template_version = self . extract_template_version ( self . template_header ) if self . template_version not in str ( self . template_path ): raise TrestleError ( f 'Version of the template { self . template_version } does not match the path { self . template_path } .' + f 'Move the template to the folder { self . template_version } ' ) if 'Version' in self . template_header . keys () and self . template_header [ 'Version' ] != self . template_version : raise TrestleError ( f 'Version does not match template-version in template: { self . template_path } .' ) self . _ignore_headers = [] for key in self . template_header . keys (): if key . lower () . startswith ( 'x-trestle-' ): self . _ignore_headers . append ( key . lower ()) if key . lower () == 'x-trestle-ignore' : for key2 in template_header [ 'x-trestle-ignore' ]: self . _ignore_headers . append ( key2 . lower ()) def is_valid_against_template ( self , instance : pathlib . Path , instance_header : Dict , instance_tree : MarkdownNode ) -> bool : \"\"\" Validate instance markdown against template. Instance is correct against a template iff: 1. For YAML header keys: a. All keys from the template are present and not modified b. Template version in the template and instance match 2. On the Markdown w/o YAML header: a. No additional headers of the level 1 were added b. Headers were not reordered c. Headers in the instance should be a superset of the template headers d. Headers must be in heirarchical order (i.e. # then ### then ## is not allowed) 3. If Governed Header is given then: a. Governed Header is not modified b. All keys (i.e. key: something) inside the section are present Args: instance: a path to the markdown instance that should be validated instance_header: a YAML header extracted from the markdown instance_tree: a tree structure representing markdown contents Returns: Whether or not the the candidate is valid against the template. \"\"\" if self . _validate_yaml_header : headers_match = self . compare_keys ( self . template_header , instance_header , self . _ignore_headers ) if not headers_match : logger . info ( f 'YAML header mismatch between template { self . template_path } and instance { instance } ' ) return False elif headers_match and not self . _validate_md_body : return True if self . md_header_to_validate is not None : instance_gov_node = instance_tree . get_node_for_key ( self . md_header_to_validate , False ) template_gov_node = self . template_tree . get_node_for_key ( self . md_header_to_validate , False ) if instance_gov_node is None : logger . info ( f 'Governed document not found in instance: { instance } ' ) return False instance_keys = instance_gov_node . content . governed_document template_keys = template_gov_node . content . governed_document is_valid = self . _validate_headers ( instance , template_keys , instance_keys ) if not is_valid : return False if self . _validate_md_body : instance_keys = instance_tree . content . subnodes_keys template_keys = self . template_tree . content . subnodes_keys if len ( template_keys ) > len ( instance_keys ): logger . info ( f 'Headings in the instance: { instance } were removed.' ) return False instance_lvl1_keys = list ( instance_tree . get_all_headers_for_level ( 1 )) template_lvl1_keys = list ( self . template_tree . get_all_headers_for_level ( 1 )) if len ( template_lvl1_keys ) < len ( instance_lvl1_keys ): logger . info ( f 'New headers of level 1 were added to the markdown instance: { instance } . ' ) return False is_valid = self . _validate_headers ( instance , template_keys , instance_keys ) if not is_valid : return False return True @classmethod def compare_keys ( cls , template : Dict [ str , Any ], candidate : Dict [ str , Any ], ignore_fields : Optional [ Dict [ str , Any ]] = None ) -> bool : \"\"\" Compare a template dictionary against a candidate as to whether key structure is maintained. Args: template: Template dict which is used as a model of key-value pairs candidate: Candidate dictionary to be measured Returns: Whether or not the the candidate matches the template keys. \"\"\" if ignore_fields is None : ignore_fields = [] for key in list ( candidate . keys ()): if key . lower () in ignore_fields : candidate . pop ( key ) for key in list ( template . keys ()): if key . lower () in ignore_fields : template . pop ( key ) template_version = cls . extract_template_version ( template ) candidate_version = cls . extract_template_version ( candidate ) if template_version != candidate_version : logger . info ( f 'Versions of the template { template_version } and instance { candidate_version } are different' ) return False if len ( template . keys ()) != len ( candidate . keys ()): logger . info ( f 'Number of keys does not match in template { template } and instance { candidate } ' ) return False for key in template . keys (): if key in candidate . keys (): if type ( template [ key ]) == dict : if type ( candidate [ key ]) == dict : status = cls . compare_keys ( template [ key ], candidate [ key ], ignore_fields ) if not status : return status else : logger . info ( f 'Value under { key } must be dictionary in candidate { candidate } ' ) return False else : logger . info ( f 'Key { key } is not in candidate { candidate } ' ) return False return True def _validate_headers ( self , instance : pathlib . Path , template_keys : List [ str ], instance_keys : List [ str ]) -> bool : \"\"\"Validate instance headers against template.\"\"\" if len ( template_keys ) > len ( instance_keys ): logger . info ( f 'Headings in the instance: { instance } were removed.' ) return False template_header_pointer = 0 for key in instance_keys : if template_header_pointer >= len ( template_keys ): break if key in template_keys and key != template_keys [ template_header_pointer ]: logger . info ( f 'Headers in the instance: { instance } were shuffled or modified.' ) return False elif key in template_keys and key == template_keys [ template_header_pointer ]: template_header_pointer += 1 elif re . search ( md_const . SUBSTITUTION_REGEX , template_keys [ template_header_pointer ]) is not None : template_header_pointer += 1 # skip headers with substitutions if template_header_pointer != len ( template_keys ): logger . info ( f 'Headings in the instance: { instance } were removed.' ) return False return True @classmethod def extract_template_version ( cls , header : Dict [ str , Any ]) -> Optional [ str ]: \"\"\" Extract the template version from the header. If no header is found then starting version(0.0.1) will be used by default \"\"\" if TEMPLATE_VERSION_HEADER not in header . keys (): return START_TEMPLATE_VERSION return header [ TEMPLATE_VERSION_HEADER ]","title":"MarkdownValidator"},{"location":"api_reference/trestle.core.markdown.markdown_validator/#trestle.core.markdown.markdown_validator.MarkdownValidator-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.markdown.markdown_validator/#trestle.core.markdown.markdown_validator.MarkdownValidator.__init__","text":"Initialize markdown validator. Source code in trestle/core/markdown/markdown_validator.py def __init__ ( self , tmp_path : pathlib . Path , template_header : Dict , template_tree : MarkdownNode , validate_yaml_header : bool , validate_md_body : bool , md_header_to_validate : Optional [ str ] = None ): \"\"\"Initialize markdown validator.\"\"\" self . _validate_yaml_header = validate_yaml_header self . _validate_md_body = validate_md_body self . md_header_to_validate = md_header_to_validate . strip ( ' ' ) if md_header_to_validate is not None else None self . template_header = template_header self . template_tree = template_tree self . template_path = tmp_path self . template_version = self . extract_template_version ( self . template_header ) if self . template_version not in str ( self . template_path ): raise TrestleError ( f 'Version of the template { self . template_version } does not match the path { self . template_path } .' + f 'Move the template to the folder { self . template_version } ' ) if 'Version' in self . template_header . keys () and self . template_header [ 'Version' ] != self . template_version : raise TrestleError ( f 'Version does not match template-version in template: { self . template_path } .' ) self . _ignore_headers = [] for key in self . template_header . keys (): if key . lower () . startswith ( 'x-trestle-' ): self . _ignore_headers . append ( key . lower ()) if key . lower () == 'x-trestle-ignore' : for key2 in template_header [ 'x-trestle-ignore' ]: self . _ignore_headers . append ( key2 . lower ())","title":"__init__()"},{"location":"api_reference/trestle.core.markdown.markdown_validator/#trestle.core.markdown.markdown_validator.MarkdownValidator.compare_keys","text":"Compare a template dictionary against a candidate as to whether key structure is maintained. Parameters: Name Type Description Default template Dict[str, Any] Template dict which is used as a model of key-value pairs required candidate Dict[str, Any] Candidate dictionary to be measured required Returns: Type Description bool Whether or not the the candidate matches the template keys. Source code in trestle/core/markdown/markdown_validator.py @classmethod def compare_keys ( cls , template : Dict [ str , Any ], candidate : Dict [ str , Any ], ignore_fields : Optional [ Dict [ str , Any ]] = None ) -> bool : \"\"\" Compare a template dictionary against a candidate as to whether key structure is maintained. Args: template: Template dict which is used as a model of key-value pairs candidate: Candidate dictionary to be measured Returns: Whether or not the the candidate matches the template keys. \"\"\" if ignore_fields is None : ignore_fields = [] for key in list ( candidate . keys ()): if key . lower () in ignore_fields : candidate . pop ( key ) for key in list ( template . keys ()): if key . lower () in ignore_fields : template . pop ( key ) template_version = cls . extract_template_version ( template ) candidate_version = cls . extract_template_version ( candidate ) if template_version != candidate_version : logger . info ( f 'Versions of the template { template_version } and instance { candidate_version } are different' ) return False if len ( template . keys ()) != len ( candidate . keys ()): logger . info ( f 'Number of keys does not match in template { template } and instance { candidate } ' ) return False for key in template . keys (): if key in candidate . keys (): if type ( template [ key ]) == dict : if type ( candidate [ key ]) == dict : status = cls . compare_keys ( template [ key ], candidate [ key ], ignore_fields ) if not status : return status else : logger . info ( f 'Value under { key } must be dictionary in candidate { candidate } ' ) return False else : logger . info ( f 'Key { key } is not in candidate { candidate } ' ) return False return True","title":"compare_keys()"},{"location":"api_reference/trestle.core.markdown.markdown_validator/#trestle.core.markdown.markdown_validator.MarkdownValidator.extract_template_version","text":"Extract the template version from the header. If no header is found then starting version(0.0.1) will be used by default Source code in trestle/core/markdown/markdown_validator.py @classmethod def extract_template_version ( cls , header : Dict [ str , Any ]) -> Optional [ str ]: \"\"\" Extract the template version from the header. If no header is found then starting version(0.0.1) will be used by default \"\"\" if TEMPLATE_VERSION_HEADER not in header . keys (): return START_TEMPLATE_VERSION return header [ TEMPLATE_VERSION_HEADER ]","title":"extract_template_version()"},{"location":"api_reference/trestle.core.markdown.markdown_validator/#trestle.core.markdown.markdown_validator.MarkdownValidator.is_valid_against_template","text":"Validate instance markdown against template. Instance is correct against a template iff: 1. For YAML header keys: a. All keys from the template are present and not modified b. Template version in the template and instance match 2. On the Markdown w/o YAML header: a. No additional headers of the level 1 were added b. Headers were not reordered c. Headers in the instance should be a superset of the template headers d. Headers must be in heirarchical order (i.e. # then ### then ## is not allowed) 3. If Governed Header is given then: a. Governed Header is not modified b. All keys (i.e. key: something) inside the section are present Parameters: Name Type Description Default instance Path a path to the markdown instance that should be validated required instance_header Dict a YAML header extracted from the markdown required instance_tree MarkdownNode a tree structure representing markdown contents required Returns: Type Description bool Whether or not the the candidate is valid against the template. Source code in trestle/core/markdown/markdown_validator.py def is_valid_against_template ( self , instance : pathlib . Path , instance_header : Dict , instance_tree : MarkdownNode ) -> bool : \"\"\" Validate instance markdown against template. Instance is correct against a template iff: 1. For YAML header keys: a. All keys from the template are present and not modified b. Template version in the template and instance match 2. On the Markdown w/o YAML header: a. No additional headers of the level 1 were added b. Headers were not reordered c. Headers in the instance should be a superset of the template headers d. Headers must be in heirarchical order (i.e. # then ### then ## is not allowed) 3. If Governed Header is given then: a. Governed Header is not modified b. All keys (i.e. key: something) inside the section are present Args: instance: a path to the markdown instance that should be validated instance_header: a YAML header extracted from the markdown instance_tree: a tree structure representing markdown contents Returns: Whether or not the the candidate is valid against the template. \"\"\" if self . _validate_yaml_header : headers_match = self . compare_keys ( self . template_header , instance_header , self . _ignore_headers ) if not headers_match : logger . info ( f 'YAML header mismatch between template { self . template_path } and instance { instance } ' ) return False elif headers_match and not self . _validate_md_body : return True if self . md_header_to_validate is not None : instance_gov_node = instance_tree . get_node_for_key ( self . md_header_to_validate , False ) template_gov_node = self . template_tree . get_node_for_key ( self . md_header_to_validate , False ) if instance_gov_node is None : logger . info ( f 'Governed document not found in instance: { instance } ' ) return False instance_keys = instance_gov_node . content . governed_document template_keys = template_gov_node . content . governed_document is_valid = self . _validate_headers ( instance , template_keys , instance_keys ) if not is_valid : return False if self . _validate_md_body : instance_keys = instance_tree . content . subnodes_keys template_keys = self . template_tree . content . subnodes_keys if len ( template_keys ) > len ( instance_keys ): logger . info ( f 'Headings in the instance: { instance } were removed.' ) return False instance_lvl1_keys = list ( instance_tree . get_all_headers_for_level ( 1 )) template_lvl1_keys = list ( self . template_tree . get_all_headers_for_level ( 1 )) if len ( template_lvl1_keys ) < len ( instance_lvl1_keys ): logger . info ( f 'New headers of level 1 were added to the markdown instance: { instance } . ' ) return False is_valid = self . _validate_headers ( instance , template_keys , instance_keys ) if not is_valid : return False return True handler: python","title":"is_valid_against_template()"},{"location":"api_reference/trestle.core.markdown.md_writer/","text":"trestle.core.markdown.md_writer \u00a4 Create formatted markdown files with optional yaml header. logger \u00a4 Classes \u00a4 MDWriter \u00a4 Simple class to create markdown files. Source code in trestle/core/markdown/md_writer.py class MDWriter (): \"\"\"Simple class to create markdown files.\"\"\" def __init__ ( self , file_path : pathlib . Path ): \"\"\"Initialize the class.\"\"\" self . _file_path = file_path self . _lines = [] self . _indent_level = 0 self . _indent_size = 2 self . _yaml_header = None def _current_indent_space ( self ): if self . _indent_level <= 0 : return '' return ' ' * ( self . _indent_level * self . _indent_size ) def _add_line_raw ( self , line : str ) -> None : out_line = '' if self . _is_blank ( line ) else line self . _lines . append ( out_line ) def _add_indent_level ( self , delta : int ) -> None : self . _indent_level += delta def add_yaml_header ( self , header : dict ) -> None : \"\"\"Add the yaml header.\"\"\" self . _yaml_header = header def set_indent_level ( self , level : int ) -> None : \"\"\"Set the current indent level.\"\"\" self . _indent_level = level def set_indent_step_size ( self , size : int ) -> None : \"\"\"Set the indent step size in spaces.\"\"\" self . _indent_size = size def _is_blank ( self , line : str ) -> bool : return line . strip () == '' def _prev_blank_line ( self ) -> bool : return len ( self . _lines ) > 0 and self . _is_blank ( self . _lines [ - 1 ]) def new_line ( self , line : str ) -> None : \"\"\"Add a line of text to the output.\"\"\" # prevent double empty lines out_line = '' if self . _is_blank ( line ) else self . _current_indent_space () + line if self . _prev_blank_line () and out_line == '' : return self . _add_line_raw ( out_line ) def new_paraline ( self , line : str ) -> None : \"\"\"Add a paragraph and a line to output.\"\"\" self . new_paragraph () self . new_line ( line ) def new_paragraph ( self ): \"\"\"Start a new paragraph.\"\"\" self . new_line ( '' ) def new_header ( self , level : int , title : str ) -> None : \"\"\"Add new header.\"\"\" # headers must be separated by blank lines self . new_paragraph () self . new_line ( '#' * level + ' ' + title ) self . new_paragraph () def new_hr ( self ) -> None : \"\"\"Add horizontal rule.\"\"\" self . new_paragraph () self . new_line ( const . SSP_MD_HRULE_LINE ) self . new_paragraph () def new_list ( self , list_ : List [ Any ]) -> None : \"\"\"Add a list to the markdown.\"\"\" # in general this is a list of lists # if string just write it out if isinstance ( list_ , str ): if self . _is_blank ( list_ ): self . new_paragraph () else : self . new_line ( '- ' + list_ ) # else it is a sublist so indent else : self . _add_indent_level ( 1 ) self . new_paragraph () for item in list_ : if self . _indent_level <= 0 : self . new_paragraph () self . new_list ( item ) self . _add_indent_level ( - 1 ) def new_table ( self , table_list : List [ List [ str ]], header : List [ str ]): \"\"\"Add table to the markdown. All rows must be of equal length.\"\"\" header_str = '| ' + ' | ' . join ( header ) + ' |' sep_str = '|---' * len ( header ) + '|' self . new_line ( header_str ) self . new_line ( sep_str ) for row in table_list : row_str = '| ' + ' | ' . join ( row ) + ' |' self . new_line ( row_str ) def _check_header ( self ) -> None : while len ( self . _lines ) > 0 and self . _lines [ 0 ] == '' : self . _lines = self . _lines [ 1 :] def write_out ( self ) -> None : \"\"\"Write out the markdown file.\"\"\" self . _check_header () try : self . _file_path . parent . mkdir ( exist_ok = True , parents = True ) with open ( self . _file_path , 'w' , encoding = const . FILE_ENCODING ) as f : # Make sure yaml header is written first if self . _yaml_header : f . write ( '--- \\n ' ) yaml = YAML () yaml . indent ( mapping = 2 , sequence = 4 , offset = 2 ) yaml . dump ( self . _yaml_header , f ) f . write ( '--- \\n\\n ' ) f . write ( ' \\n ' . join ( self . _lines )) except IOError as e : logger . debug ( f 'md_writer error attempting to write out md file { self . _file_path } { e } ' ) raise TrestleError ( f 'Error attempting to write out md file { self . _file_path } { e } ' ) def get_lines ( self ) -> List [ str ]: \"\"\"Return the current lines in the file.\"\"\" return self . _lines def get_text ( self ) -> str : \"\"\"Get the text as currently written.\"\"\" return ' \\n ' . join ( self . _lines ) Methods \u00a4 __init__ ( self , file_path ) special \u00a4 Initialize the class. Source code in trestle/core/markdown/md_writer.py def __init__ ( self , file_path : pathlib . Path ): \"\"\"Initialize the class.\"\"\" self . _file_path = file_path self . _lines = [] self . _indent_level = 0 self . _indent_size = 2 self . _yaml_header = None add_yaml_header ( self , header ) \u00a4 Add the yaml header. Source code in trestle/core/markdown/md_writer.py def add_yaml_header ( self , header : dict ) -> None : \"\"\"Add the yaml header.\"\"\" self . _yaml_header = header get_lines ( self ) \u00a4 Return the current lines in the file. Source code in trestle/core/markdown/md_writer.py def get_lines ( self ) -> List [ str ]: \"\"\"Return the current lines in the file.\"\"\" return self . _lines get_text ( self ) \u00a4 Get the text as currently written. Source code in trestle/core/markdown/md_writer.py def get_text ( self ) -> str : \"\"\"Get the text as currently written.\"\"\" return ' \\n ' . join ( self . _lines ) new_header ( self , level , title ) \u00a4 Add new header. Source code in trestle/core/markdown/md_writer.py def new_header ( self , level : int , title : str ) -> None : \"\"\"Add new header.\"\"\" # headers must be separated by blank lines self . new_paragraph () self . new_line ( '#' * level + ' ' + title ) self . new_paragraph () new_hr ( self ) \u00a4 Add horizontal rule. Source code in trestle/core/markdown/md_writer.py def new_hr ( self ) -> None : \"\"\"Add horizontal rule.\"\"\" self . new_paragraph () self . new_line ( const . SSP_MD_HRULE_LINE ) self . new_paragraph () new_line ( self , line ) \u00a4 Add a line of text to the output. Source code in trestle/core/markdown/md_writer.py def new_line ( self , line : str ) -> None : \"\"\"Add a line of text to the output.\"\"\" # prevent double empty lines out_line = '' if self . _is_blank ( line ) else self . _current_indent_space () + line if self . _prev_blank_line () and out_line == '' : return self . _add_line_raw ( out_line ) new_list ( self , list_ ) \u00a4 Add a list to the markdown. Source code in trestle/core/markdown/md_writer.py def new_list ( self , list_ : List [ Any ]) -> None : \"\"\"Add a list to the markdown.\"\"\" # in general this is a list of lists # if string just write it out if isinstance ( list_ , str ): if self . _is_blank ( list_ ): self . new_paragraph () else : self . new_line ( '- ' + list_ ) # else it is a sublist so indent else : self . _add_indent_level ( 1 ) self . new_paragraph () for item in list_ : if self . _indent_level <= 0 : self . new_paragraph () self . new_list ( item ) self . _add_indent_level ( - 1 ) new_paragraph ( self ) \u00a4 Start a new paragraph. Source code in trestle/core/markdown/md_writer.py def new_paragraph ( self ): \"\"\"Start a new paragraph.\"\"\" self . new_line ( '' ) new_paraline ( self , line ) \u00a4 Add a paragraph and a line to output. Source code in trestle/core/markdown/md_writer.py def new_paraline ( self , line : str ) -> None : \"\"\"Add a paragraph and a line to output.\"\"\" self . new_paragraph () self . new_line ( line ) new_table ( self , table_list , header ) \u00a4 Add table to the markdown. All rows must be of equal length. Source code in trestle/core/markdown/md_writer.py def new_table ( self , table_list : List [ List [ str ]], header : List [ str ]): \"\"\"Add table to the markdown. All rows must be of equal length.\"\"\" header_str = '| ' + ' | ' . join ( header ) + ' |' sep_str = '|---' * len ( header ) + '|' self . new_line ( header_str ) self . new_line ( sep_str ) for row in table_list : row_str = '| ' + ' | ' . join ( row ) + ' |' self . new_line ( row_str ) set_indent_level ( self , level ) \u00a4 Set the current indent level. Source code in trestle/core/markdown/md_writer.py def set_indent_level ( self , level : int ) -> None : \"\"\"Set the current indent level.\"\"\" self . _indent_level = level set_indent_step_size ( self , size ) \u00a4 Set the indent step size in spaces. Source code in trestle/core/markdown/md_writer.py def set_indent_step_size ( self , size : int ) -> None : \"\"\"Set the indent step size in spaces.\"\"\" self . _indent_size = size write_out ( self ) \u00a4 Write out the markdown file. Source code in trestle/core/markdown/md_writer.py def write_out ( self ) -> None : \"\"\"Write out the markdown file.\"\"\" self . _check_header () try : self . _file_path . parent . mkdir ( exist_ok = True , parents = True ) with open ( self . _file_path , 'w' , encoding = const . FILE_ENCODING ) as f : # Make sure yaml header is written first if self . _yaml_header : f . write ( '--- \\n ' ) yaml = YAML () yaml . indent ( mapping = 2 , sequence = 4 , offset = 2 ) yaml . dump ( self . _yaml_header , f ) f . write ( '--- \\n\\n ' ) f . write ( ' \\n ' . join ( self . _lines )) except IOError as e : logger . debug ( f 'md_writer error attempting to write out md file { self . _file_path } { e } ' ) raise TrestleError ( f 'Error attempting to write out md file { self . _file_path } { e } ' ) handler: python","title":"md_writer"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer","text":"Create formatted markdown files with optional yaml header.","title":"md_writer"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer.MDWriter","text":"Simple class to create markdown files. Source code in trestle/core/markdown/md_writer.py class MDWriter (): \"\"\"Simple class to create markdown files.\"\"\" def __init__ ( self , file_path : pathlib . Path ): \"\"\"Initialize the class.\"\"\" self . _file_path = file_path self . _lines = [] self . _indent_level = 0 self . _indent_size = 2 self . _yaml_header = None def _current_indent_space ( self ): if self . _indent_level <= 0 : return '' return ' ' * ( self . _indent_level * self . _indent_size ) def _add_line_raw ( self , line : str ) -> None : out_line = '' if self . _is_blank ( line ) else line self . _lines . append ( out_line ) def _add_indent_level ( self , delta : int ) -> None : self . _indent_level += delta def add_yaml_header ( self , header : dict ) -> None : \"\"\"Add the yaml header.\"\"\" self . _yaml_header = header def set_indent_level ( self , level : int ) -> None : \"\"\"Set the current indent level.\"\"\" self . _indent_level = level def set_indent_step_size ( self , size : int ) -> None : \"\"\"Set the indent step size in spaces.\"\"\" self . _indent_size = size def _is_blank ( self , line : str ) -> bool : return line . strip () == '' def _prev_blank_line ( self ) -> bool : return len ( self . _lines ) > 0 and self . _is_blank ( self . _lines [ - 1 ]) def new_line ( self , line : str ) -> None : \"\"\"Add a line of text to the output.\"\"\" # prevent double empty lines out_line = '' if self . _is_blank ( line ) else self . _current_indent_space () + line if self . _prev_blank_line () and out_line == '' : return self . _add_line_raw ( out_line ) def new_paraline ( self , line : str ) -> None : \"\"\"Add a paragraph and a line to output.\"\"\" self . new_paragraph () self . new_line ( line ) def new_paragraph ( self ): \"\"\"Start a new paragraph.\"\"\" self . new_line ( '' ) def new_header ( self , level : int , title : str ) -> None : \"\"\"Add new header.\"\"\" # headers must be separated by blank lines self . new_paragraph () self . new_line ( '#' * level + ' ' + title ) self . new_paragraph () def new_hr ( self ) -> None : \"\"\"Add horizontal rule.\"\"\" self . new_paragraph () self . new_line ( const . SSP_MD_HRULE_LINE ) self . new_paragraph () def new_list ( self , list_ : List [ Any ]) -> None : \"\"\"Add a list to the markdown.\"\"\" # in general this is a list of lists # if string just write it out if isinstance ( list_ , str ): if self . _is_blank ( list_ ): self . new_paragraph () else : self . new_line ( '- ' + list_ ) # else it is a sublist so indent else : self . _add_indent_level ( 1 ) self . new_paragraph () for item in list_ : if self . _indent_level <= 0 : self . new_paragraph () self . new_list ( item ) self . _add_indent_level ( - 1 ) def new_table ( self , table_list : List [ List [ str ]], header : List [ str ]): \"\"\"Add table to the markdown. All rows must be of equal length.\"\"\" header_str = '| ' + ' | ' . join ( header ) + ' |' sep_str = '|---' * len ( header ) + '|' self . new_line ( header_str ) self . new_line ( sep_str ) for row in table_list : row_str = '| ' + ' | ' . join ( row ) + ' |' self . new_line ( row_str ) def _check_header ( self ) -> None : while len ( self . _lines ) > 0 and self . _lines [ 0 ] == '' : self . _lines = self . _lines [ 1 :] def write_out ( self ) -> None : \"\"\"Write out the markdown file.\"\"\" self . _check_header () try : self . _file_path . parent . mkdir ( exist_ok = True , parents = True ) with open ( self . _file_path , 'w' , encoding = const . FILE_ENCODING ) as f : # Make sure yaml header is written first if self . _yaml_header : f . write ( '--- \\n ' ) yaml = YAML () yaml . indent ( mapping = 2 , sequence = 4 , offset = 2 ) yaml . dump ( self . _yaml_header , f ) f . write ( '--- \\n\\n ' ) f . write ( ' \\n ' . join ( self . _lines )) except IOError as e : logger . debug ( f 'md_writer error attempting to write out md file { self . _file_path } { e } ' ) raise TrestleError ( f 'Error attempting to write out md file { self . _file_path } { e } ' ) def get_lines ( self ) -> List [ str ]: \"\"\"Return the current lines in the file.\"\"\" return self . _lines def get_text ( self ) -> str : \"\"\"Get the text as currently written.\"\"\" return ' \\n ' . join ( self . _lines )","title":"MDWriter"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer.MDWriter-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer.MDWriter.__init__","text":"Initialize the class. Source code in trestle/core/markdown/md_writer.py def __init__ ( self , file_path : pathlib . Path ): \"\"\"Initialize the class.\"\"\" self . _file_path = file_path self . _lines = [] self . _indent_level = 0 self . _indent_size = 2 self . _yaml_header = None","title":"__init__()"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer.MDWriter.add_yaml_header","text":"Add the yaml header. Source code in trestle/core/markdown/md_writer.py def add_yaml_header ( self , header : dict ) -> None : \"\"\"Add the yaml header.\"\"\" self . _yaml_header = header","title":"add_yaml_header()"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer.MDWriter.get_lines","text":"Return the current lines in the file. Source code in trestle/core/markdown/md_writer.py def get_lines ( self ) -> List [ str ]: \"\"\"Return the current lines in the file.\"\"\" return self . _lines","title":"get_lines()"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer.MDWriter.get_text","text":"Get the text as currently written. Source code in trestle/core/markdown/md_writer.py def get_text ( self ) -> str : \"\"\"Get the text as currently written.\"\"\" return ' \\n ' . join ( self . _lines )","title":"get_text()"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer.MDWriter.new_header","text":"Add new header. Source code in trestle/core/markdown/md_writer.py def new_header ( self , level : int , title : str ) -> None : \"\"\"Add new header.\"\"\" # headers must be separated by blank lines self . new_paragraph () self . new_line ( '#' * level + ' ' + title ) self . new_paragraph ()","title":"new_header()"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer.MDWriter.new_hr","text":"Add horizontal rule. Source code in trestle/core/markdown/md_writer.py def new_hr ( self ) -> None : \"\"\"Add horizontal rule.\"\"\" self . new_paragraph () self . new_line ( const . SSP_MD_HRULE_LINE ) self . new_paragraph ()","title":"new_hr()"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer.MDWriter.new_line","text":"Add a line of text to the output. Source code in trestle/core/markdown/md_writer.py def new_line ( self , line : str ) -> None : \"\"\"Add a line of text to the output.\"\"\" # prevent double empty lines out_line = '' if self . _is_blank ( line ) else self . _current_indent_space () + line if self . _prev_blank_line () and out_line == '' : return self . _add_line_raw ( out_line )","title":"new_line()"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer.MDWriter.new_list","text":"Add a list to the markdown. Source code in trestle/core/markdown/md_writer.py def new_list ( self , list_ : List [ Any ]) -> None : \"\"\"Add a list to the markdown.\"\"\" # in general this is a list of lists # if string just write it out if isinstance ( list_ , str ): if self . _is_blank ( list_ ): self . new_paragraph () else : self . new_line ( '- ' + list_ ) # else it is a sublist so indent else : self . _add_indent_level ( 1 ) self . new_paragraph () for item in list_ : if self . _indent_level <= 0 : self . new_paragraph () self . new_list ( item ) self . _add_indent_level ( - 1 )","title":"new_list()"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer.MDWriter.new_paragraph","text":"Start a new paragraph. Source code in trestle/core/markdown/md_writer.py def new_paragraph ( self ): \"\"\"Start a new paragraph.\"\"\" self . new_line ( '' )","title":"new_paragraph()"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer.MDWriter.new_paraline","text":"Add a paragraph and a line to output. Source code in trestle/core/markdown/md_writer.py def new_paraline ( self , line : str ) -> None : \"\"\"Add a paragraph and a line to output.\"\"\" self . new_paragraph () self . new_line ( line )","title":"new_paraline()"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer.MDWriter.new_table","text":"Add table to the markdown. All rows must be of equal length. Source code in trestle/core/markdown/md_writer.py def new_table ( self , table_list : List [ List [ str ]], header : List [ str ]): \"\"\"Add table to the markdown. All rows must be of equal length.\"\"\" header_str = '| ' + ' | ' . join ( header ) + ' |' sep_str = '|---' * len ( header ) + '|' self . new_line ( header_str ) self . new_line ( sep_str ) for row in table_list : row_str = '| ' + ' | ' . join ( row ) + ' |' self . new_line ( row_str )","title":"new_table()"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer.MDWriter.set_indent_level","text":"Set the current indent level. Source code in trestle/core/markdown/md_writer.py def set_indent_level ( self , level : int ) -> None : \"\"\"Set the current indent level.\"\"\" self . _indent_level = level","title":"set_indent_level()"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer.MDWriter.set_indent_step_size","text":"Set the indent step size in spaces. Source code in trestle/core/markdown/md_writer.py def set_indent_step_size ( self , size : int ) -> None : \"\"\"Set the indent step size in spaces.\"\"\" self . _indent_size = size","title":"set_indent_step_size()"},{"location":"api_reference/trestle.core.markdown.md_writer/#trestle.core.markdown.md_writer.MDWriter.write_out","text":"Write out the markdown file. Source code in trestle/core/markdown/md_writer.py def write_out ( self ) -> None : \"\"\"Write out the markdown file.\"\"\" self . _check_header () try : self . _file_path . parent . mkdir ( exist_ok = True , parents = True ) with open ( self . _file_path , 'w' , encoding = const . FILE_ENCODING ) as f : # Make sure yaml header is written first if self . _yaml_header : f . write ( '--- \\n ' ) yaml = YAML () yaml . indent ( mapping = 2 , sequence = 4 , offset = 2 ) yaml . dump ( self . _yaml_header , f ) f . write ( '--- \\n\\n ' ) f . write ( ' \\n ' . join ( self . _lines )) except IOError as e : logger . debug ( f 'md_writer error attempting to write out md file { self . _file_path } { e } ' ) raise TrestleError ( f 'Error attempting to write out md file { self . _file_path } { e } ' ) handler: python","title":"write_out()"},{"location":"api_reference/trestle.core.models.actions/","text":"trestle.core.models.actions \u00a4 Action wrapper of a command. logger \u00a4 Classes \u00a4 Action ( ABC ) \u00a4 Action wrapper of a command. Source code in trestle/core/models/actions.py class Action ( ABC ): \"\"\"Action wrapper of a command.\"\"\" def __init__ ( self , action_type : ActionType , has_rollback : bool ) -> None : \"\"\"Initialize an base action.\"\"\" self . _type : ActionType = action_type self . _has_rollback : bool = has_rollback # child class must set this flag once it executes self . _has_executed = False def to_string ( self ) -> str : \"\"\"Return a string representation.\"\"\" return self . __str__ () def get_type ( self ) -> ActionType : \"\"\"Return the action type.\"\"\" return self . _type def _mark_executed ( self ) -> None : \"\"\"Set flag that the action has been executed.\"\"\" self . _has_executed = True def has_executed ( self ) -> bool : \"\"\"Return if the action has been executed.\"\"\" return self . _has_executed def _mark_rollback ( self ) -> None : \"\"\"Set flag that the action has been rollbacked.\"\"\" self . _has_executed = False def has_rollback ( self ) -> bool : \"\"\"Return if rollback of the action is possible.\"\"\" return self . _has_rollback def __eq__ ( self , other : object ) -> bool : \"\"\"Check that two actions are equal.\"\"\" if not isinstance ( other , Action ): return False if self . get_type () is not other . get_type (): return False is_eq = self . __dict__ == other . __dict__ return is_eq @abstractmethod def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" @abstractmethod def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" Methods \u00a4 __eq__ ( self , other ) special \u00a4 Check that two actions are equal. Source code in trestle/core/models/actions.py def __eq__ ( self , other : object ) -> bool : \"\"\"Check that two actions are equal.\"\"\" if not isinstance ( other , Action ): return False if self . get_type () is not other . get_type (): return False is_eq = self . __dict__ == other . __dict__ return is_eq __init__ ( self , action_type , has_rollback ) special \u00a4 Initialize an base action. Source code in trestle/core/models/actions.py def __init__ ( self , action_type : ActionType , has_rollback : bool ) -> None : \"\"\"Initialize an base action.\"\"\" self . _type : ActionType = action_type self . _has_rollback : bool = has_rollback # child class must set this flag once it executes self . _has_executed = False execute ( self ) \u00a4 Execute the action. Source code in trestle/core/models/actions.py @abstractmethod def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" get_type ( self ) \u00a4 Return the action type. Source code in trestle/core/models/actions.py def get_type ( self ) -> ActionType : \"\"\"Return the action type.\"\"\" return self . _type has_executed ( self ) \u00a4 Return if the action has been executed. Source code in trestle/core/models/actions.py def has_executed ( self ) -> bool : \"\"\"Return if the action has been executed.\"\"\" return self . _has_executed has_rollback ( self ) \u00a4 Return if rollback of the action is possible. Source code in trestle/core/models/actions.py def has_rollback ( self ) -> bool : \"\"\"Return if rollback of the action is possible.\"\"\" return self . _has_rollback rollback ( self ) \u00a4 Rollback the action. Source code in trestle/core/models/actions.py @abstractmethod def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" to_string ( self ) \u00a4 Return a string representation. Source code in trestle/core/models/actions.py def to_string ( self ) -> str : \"\"\"Return a string representation.\"\"\" return self . __str__ () ActionType ( Enum ) \u00a4 Action type enum for different action type. File system related actions have code like 1 Model processing related actions have code like 2 Source code in trestle/core/models/actions.py class ActionType ( Enum ): \"\"\"Action type enum for different action type. File system related actions have code like 1* Model processing related actions have code like 2* \"\"\" # create a file or directory path CREATE_PATH = 10 # remove a file or directory path REMOVE_PATH = 12 # write element to a destination file or stream WRITE = 11 # update or add the element at the path UPDATE = 20 # remove the element at the path REMOVE = 21 CREATE_PATH \u00a4 REMOVE \u00a4 REMOVE_PATH \u00a4 UPDATE \u00a4 WRITE \u00a4 CreatePathAction ( Action ) \u00a4 Create a file or directory path. Source code in trestle/core/models/actions.py class CreatePathAction ( Action ): \"\"\"Create a file or directory path.\"\"\" def __init__ ( self , sub_path : pathlib . Path , clear_content : bool = False ) -> None : \"\"\"Initialize a create path action. It creates all the missing directories in the path. If it is a file, then it also creates an empty file with the name provided Arguments: sub_path: this is the desired file or directory path that needs to be created under the project root \"\"\" sub_path = sub_path . resolve () self . _trestle_project_root = file_utils . extract_trestle_project_root ( sub_path ) if self . _trestle_project_root is None : raise TrestleError ( f 'Sub path \" { sub_path } \" should be child of a valid trestle project' ) self . _sub_path = sub_path self . _created_paths : List [ pathlib . Path ] = [] # variables for handling with file content self . _clear_content = clear_content self . _old_file_content = None super () . __init__ ( ActionType . CREATE_PATH , True ) def get_trestle_project_root ( self ) -> pathlib . Path : \"\"\"Return the trestle project root path.\"\"\" return self . _trestle_project_root def get_created_paths ( self ) -> List [ pathlib . Path ]: \"\"\"Get the list of paths that were created after being executed.\"\"\" return self . _created_paths def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" # find the start of the sub_path relative to trestle project root cur_index = len ( self . _trestle_project_root . parts ) # loop through the sub_path parts and create as necessary cur_path = self . _trestle_project_root while cur_index < len ( self . _sub_path . parts ): part = self . _sub_path . parts [ cur_index ] # create a path relative to the current # it starts with the project root, so we shall always create # sub directories or files relative to the project root cur_path = cur_path / part # create the sub_path file or directory if it does not exists already if cur_path . suffix != '' : # suffix will denote a file if not cur_path . exists (): # create file cur_path . touch () # add in the list for rollback self . _created_paths . append ( cur_path ) elif self . _clear_content : # read file content for rollback with open ( cur_path , 'r+' , encoding = const . FILE_ENCODING ) as fp : # read all content self . _old_file_content = fp . read () # clear file content fp . truncate ( 0 ) else : if not cur_path . exists (): # create directory cur_path . mkdir () # add in the list for rollback self . _created_paths . append ( cur_path ) # move to the next part of the sub_path parts cur_index = cur_index + 1 self . _mark_executed () def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if self . has_executed (): if len ( self . _created_paths ) > 0 : for cur_path in reversed ( self . _created_paths ): if cur_path . exists (): if cur_path . is_file (): cur_path . unlink () elif cur_path . is_dir (): cur_path . rmdir () self . _created_paths . clear () # rollback the content of a file if required # we should be here only if there were no path created and the sub_part already existed elif self . _sub_path . is_file () and self . _sub_path . exists () and self . _clear_content is True : if self . _old_file_content is not None : with open ( self . _sub_path , 'w' , encoding = const . FILE_ENCODING ) as fp : fp . write ( self . _old_file_content ) self . _mark_rollback () def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } { self . _sub_path } ' Methods \u00a4 __init__ ( self , sub_path , clear_content = False ) special \u00a4 Initialize a create path action. It creates all the missing directories in the path. If it is a file, then it also creates an empty file with the name provided Parameters: Name Type Description Default sub_path Path this is the desired file or directory path that needs to be created under the project root required Source code in trestle/core/models/actions.py def __init__ ( self , sub_path : pathlib . Path , clear_content : bool = False ) -> None : \"\"\"Initialize a create path action. It creates all the missing directories in the path. If it is a file, then it also creates an empty file with the name provided Arguments: sub_path: this is the desired file or directory path that needs to be created under the project root \"\"\" sub_path = sub_path . resolve () self . _trestle_project_root = file_utils . extract_trestle_project_root ( sub_path ) if self . _trestle_project_root is None : raise TrestleError ( f 'Sub path \" { sub_path } \" should be child of a valid trestle project' ) self . _sub_path = sub_path self . _created_paths : List [ pathlib . Path ] = [] # variables for handling with file content self . _clear_content = clear_content self . _old_file_content = None super () . __init__ ( ActionType . CREATE_PATH , True ) __str__ ( self ) special \u00a4 Return string representation. Source code in trestle/core/models/actions.py def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } { self . _sub_path } ' execute ( self ) \u00a4 Execute the action. Source code in trestle/core/models/actions.py def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" # find the start of the sub_path relative to trestle project root cur_index = len ( self . _trestle_project_root . parts ) # loop through the sub_path parts and create as necessary cur_path = self . _trestle_project_root while cur_index < len ( self . _sub_path . parts ): part = self . _sub_path . parts [ cur_index ] # create a path relative to the current # it starts with the project root, so we shall always create # sub directories or files relative to the project root cur_path = cur_path / part # create the sub_path file or directory if it does not exists already if cur_path . suffix != '' : # suffix will denote a file if not cur_path . exists (): # create file cur_path . touch () # add in the list for rollback self . _created_paths . append ( cur_path ) elif self . _clear_content : # read file content for rollback with open ( cur_path , 'r+' , encoding = const . FILE_ENCODING ) as fp : # read all content self . _old_file_content = fp . read () # clear file content fp . truncate ( 0 ) else : if not cur_path . exists (): # create directory cur_path . mkdir () # add in the list for rollback self . _created_paths . append ( cur_path ) # move to the next part of the sub_path parts cur_index = cur_index + 1 self . _mark_executed () get_created_paths ( self ) \u00a4 Get the list of paths that were created after being executed. Source code in trestle/core/models/actions.py def get_created_paths ( self ) -> List [ pathlib . Path ]: \"\"\"Get the list of paths that were created after being executed.\"\"\" return self . _created_paths get_trestle_project_root ( self ) \u00a4 Return the trestle project root path. Source code in trestle/core/models/actions.py def get_trestle_project_root ( self ) -> pathlib . Path : \"\"\"Return the trestle project root path.\"\"\" return self . _trestle_project_root rollback ( self ) \u00a4 Rollback the action. Source code in trestle/core/models/actions.py def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if self . has_executed (): if len ( self . _created_paths ) > 0 : for cur_path in reversed ( self . _created_paths ): if cur_path . exists (): if cur_path . is_file (): cur_path . unlink () elif cur_path . is_dir (): cur_path . rmdir () self . _created_paths . clear () # rollback the content of a file if required # we should be here only if there were no path created and the sub_part already existed elif self . _sub_path . is_file () and self . _sub_path . exists () and self . _clear_content is True : if self . _old_file_content is not None : with open ( self . _sub_path , 'w' , encoding = const . FILE_ENCODING ) as fp : fp . write ( self . _old_file_content ) self . _mark_rollback () RemoveAction ( Action ) \u00a4 Remove sub element at the element path in the source element. Source code in trestle/core/models/actions.py class RemoveAction ( Action ): \"\"\"Remove sub element at the element path in the source element.\"\"\" def __init__ ( self , src_element : Element , sub_element_path : ElementPath ) -> None : \"\"\"Initialize a remove element action.\"\"\" super () . __init__ ( ActionType . REMOVE , True ) self . _src_element : Element = src_element self . _sub_element_path : ElementPath = sub_element_path self . _prev_sub_element = None def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" self . _prev_sub_element = self . _src_element . get_at ( self . _sub_element_path ) self . _src_element . set_at ( self . _sub_element_path , None ) self . _mark_executed () def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if self . has_executed (): self . _src_element . set_at ( self . _sub_element_path , self . _prev_sub_element ) self . _mark_rollback () def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } element at { self . _sub_element_path } from { self . _src_element } ' Methods \u00a4 __init__ ( self , src_element , sub_element_path ) special \u00a4 Initialize a remove element action. Source code in trestle/core/models/actions.py def __init__ ( self , src_element : Element , sub_element_path : ElementPath ) -> None : \"\"\"Initialize a remove element action.\"\"\" super () . __init__ ( ActionType . REMOVE , True ) self . _src_element : Element = src_element self . _sub_element_path : ElementPath = sub_element_path self . _prev_sub_element = None __str__ ( self ) special \u00a4 Return string representation. Source code in trestle/core/models/actions.py def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } element at { self . _sub_element_path } from { self . _src_element } ' execute ( self ) \u00a4 Execute the action. Source code in trestle/core/models/actions.py def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" self . _prev_sub_element = self . _src_element . get_at ( self . _sub_element_path ) self . _src_element . set_at ( self . _sub_element_path , None ) self . _mark_executed () rollback ( self ) \u00a4 Rollback the action. Source code in trestle/core/models/actions.py def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if self . has_executed (): self . _src_element . set_at ( self . _sub_element_path , self . _prev_sub_element ) self . _mark_rollback () RemovePathAction ( Action ) \u00a4 Remove a file or directory path. Source code in trestle/core/models/actions.py class RemovePathAction ( Action ): \"\"\"Remove a file or directory path.\"\"\" def __init__ ( self , sub_path : pathlib . Path ) -> None : \"\"\"Initialize a remove path action. It removes the file or directory recursively into trash. Arguments: sub_path: this is the desired file or directory path that needs to be removed under the project root \"\"\" if not isinstance ( sub_path , pathlib . Path ): raise TrestleError ( 'Sub path must be of type pathlib.Path' ) self . _trestle_project_root = file_utils . extract_trestle_project_root ( sub_path ) if self . _trestle_project_root is None : raise TrestleError ( f 'Sub path \" { sub_path } \" should be child of a valid trestle project.' ) self . _sub_path = sub_path super () . __init__ ( ActionType . REMOVE_PATH , True ) def get_trestle_project_root ( self ) -> Optional [ pathlib . Path ]: \"\"\"Return the trestle project root path.\"\"\" return self . _trestle_project_root def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" if not self . _sub_path . exists (): logger . debug ( f 'path { self . _sub_path } does not exist in remove path action - ignoring.' ) trash . store ( self . _sub_path , True ) # check if parent folder is empty and if so delete parent_dir = pathlib . Path ( os . path . dirname ( self . _sub_path )) files = list ( parent_dir . iterdir ()) if not files : trash . store ( parent_dir , True ) self . _mark_executed () def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if self . has_executed (): trash_path = trash . to_trash_path ( self . _sub_path ) if trash_path is None or trash_path . exists () is False : # FIXME suppress file contents not found message til trash/rollback behavior is fixed. # issue 412 return trash . recover ( self . _sub_path , True ) self . _mark_rollback () def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } { self . _sub_path } ' Methods \u00a4 __init__ ( self , sub_path ) special \u00a4 Initialize a remove path action. It removes the file or directory recursively into trash. Parameters: Name Type Description Default sub_path Path this is the desired file or directory path that needs to be removed under the project root required Source code in trestle/core/models/actions.py def __init__ ( self , sub_path : pathlib . Path ) -> None : \"\"\"Initialize a remove path action. It removes the file or directory recursively into trash. Arguments: sub_path: this is the desired file or directory path that needs to be removed under the project root \"\"\" if not isinstance ( sub_path , pathlib . Path ): raise TrestleError ( 'Sub path must be of type pathlib.Path' ) self . _trestle_project_root = file_utils . extract_trestle_project_root ( sub_path ) if self . _trestle_project_root is None : raise TrestleError ( f 'Sub path \" { sub_path } \" should be child of a valid trestle project.' ) self . _sub_path = sub_path super () . __init__ ( ActionType . REMOVE_PATH , True ) __str__ ( self ) special \u00a4 Return string representation. Source code in trestle/core/models/actions.py def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } { self . _sub_path } ' execute ( self ) \u00a4 Execute the action. Source code in trestle/core/models/actions.py def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" if not self . _sub_path . exists (): logger . debug ( f 'path { self . _sub_path } does not exist in remove path action - ignoring.' ) trash . store ( self . _sub_path , True ) # check if parent folder is empty and if so delete parent_dir = pathlib . Path ( os . path . dirname ( self . _sub_path )) files = list ( parent_dir . iterdir ()) if not files : trash . store ( parent_dir , True ) self . _mark_executed () get_trestle_project_root ( self ) \u00a4 Return the trestle project root path. Source code in trestle/core/models/actions.py def get_trestle_project_root ( self ) -> Optional [ pathlib . Path ]: \"\"\"Return the trestle project root path.\"\"\" return self . _trestle_project_root rollback ( self ) \u00a4 Rollback the action. Source code in trestle/core/models/actions.py def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if self . has_executed (): trash_path = trash . to_trash_path ( self . _sub_path ) if trash_path is None or trash_path . exists () is False : # FIXME suppress file contents not found message til trash/rollback behavior is fixed. # issue 412 return trash . recover ( self . _sub_path , True ) self . _mark_rollback () UpdateAction ( Action ) \u00a4 Update element at the element path in the destination element with the source element. Source code in trestle/core/models/actions.py class UpdateAction ( Action ): \"\"\"Update element at the element path in the destination element with the source element.\"\"\" def __init__ ( self , sub_element , dest_element : Element , sub_element_path : ElementPath ) -> None : \"\"\"Initialize an add element action. Sub element can be OscalBaseModel, Element, list or None \"\"\" super () . __init__ ( ActionType . UPDATE , True ) if not Element . is_allowed_sub_element_type ( sub_element ): allowed_types = Element . get_allowed_sub_element_types () raise TrestleError ( f 'Sub element \" { sub_element . __class__ } is not a allowed sub element types in \" { allowed_types } \"' ) self . _sub_element = sub_element self . _dest_element : Element = dest_element self . _sub_element_path : ElementPath = sub_element_path self . _prev_sub_element = None def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" self . _prev_sub_element = self . _dest_element . get_at ( self . _sub_element_path ) self . _dest_element . set_at ( self . _sub_element_path , self . _sub_element ) self . _mark_executed () def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if self . has_executed (): self . _dest_element . set_at ( self . _sub_element_path , self . _prev_sub_element ) self . _mark_rollback () def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } { self . _model_obj . __class__ } to { self . _dest_element } at { self . _sub_element_path } ' Methods \u00a4 __init__ ( self , sub_element , dest_element , sub_element_path ) special \u00a4 Initialize an add element action. Sub element can be OscalBaseModel, Element, list or None Source code in trestle/core/models/actions.py def __init__ ( self , sub_element , dest_element : Element , sub_element_path : ElementPath ) -> None : \"\"\"Initialize an add element action. Sub element can be OscalBaseModel, Element, list or None \"\"\" super () . __init__ ( ActionType . UPDATE , True ) if not Element . is_allowed_sub_element_type ( sub_element ): allowed_types = Element . get_allowed_sub_element_types () raise TrestleError ( f 'Sub element \" { sub_element . __class__ } is not a allowed sub element types in \" { allowed_types } \"' ) self . _sub_element = sub_element self . _dest_element : Element = dest_element self . _sub_element_path : ElementPath = sub_element_path self . _prev_sub_element = None __str__ ( self ) special \u00a4 Return string representation. Source code in trestle/core/models/actions.py def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } { self . _model_obj . __class__ } to { self . _dest_element } at { self . _sub_element_path } ' execute ( self ) \u00a4 Execute the action. Source code in trestle/core/models/actions.py def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" self . _prev_sub_element = self . _dest_element . get_at ( self . _sub_element_path ) self . _dest_element . set_at ( self . _sub_element_path , self . _sub_element ) self . _mark_executed () rollback ( self ) \u00a4 Rollback the action. Source code in trestle/core/models/actions.py def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if self . has_executed (): self . _dest_element . set_at ( self . _sub_element_path , self . _prev_sub_element ) self . _mark_rollback () WriteAction ( Action ) \u00a4 Write the element to a destination stream. Source code in trestle/core/models/actions.py class WriteAction ( Action ): \"\"\"Write the element to a destination stream.\"\"\" def __init__ ( self , writer : Optional [ io . TextIOWrapper ], element : Element , content_type : FileContentType ) -> None : \"\"\"Initialize an write file action.\"\"\" super () . __init__ ( ActionType . WRITE , True ) if writer is not None and not issubclass ( io . TextIOWrapper , writer . __class__ ): raise TrestleError ( f 'Writer must be of io.TextIOWrapper, given f { writer . __class__ } ' ) self . _writer : Optional [ io . TextIOWrapper ] = writer self . _element : Element = element self . _content_type : FileContentType = content_type self . _lastStreamPos = - 1 if self . _writer is not None : self . _lastStreamPos = self . _writer . tell () def _is_writer_valid ( self ) -> bool : if self . _writer is not None and isinstance ( self . _writer , io . TextIOWrapper ) and not self . _writer . closed : return True return False def _encode ( self ) -> str : \"\"\"Encode the element to appropriate content type.\"\"\" if self . _content_type == FileContentType . YAML : return self . _element . to_yaml () if self . _content_type == FileContentType . JSON : return self . _element . to_json () raise TrestleError ( f 'Invalid content type { self . _content_type } ' ) def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" if self . _element is None : raise TrestleError ( 'Element is empty and cannot write' ) if not self . _is_writer_valid (): raise TrestleError ( 'Writer is not provided or closed' ) self . _writer . write ( self . _encode ()) self . _writer . flush () self . _mark_executed () def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if not self . _is_writer_valid (): raise TrestleError ( 'Writer is not provided or closed' ) if self . _lastStreamPos < 0 : raise TrestleError ( 'Last stream position is not available to rollback to' ) if self . has_executed (): self . _writer . seek ( self . _lastStreamPos ) self . _writer . truncate () self . _mark_rollback () def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . get_type () } { self . _element } ' Methods \u00a4 __init__ ( self , writer , element , content_type ) special \u00a4 Initialize an write file action. Source code in trestle/core/models/actions.py def __init__ ( self , writer : Optional [ io . TextIOWrapper ], element : Element , content_type : FileContentType ) -> None : \"\"\"Initialize an write file action.\"\"\" super () . __init__ ( ActionType . WRITE , True ) if writer is not None and not issubclass ( io . TextIOWrapper , writer . __class__ ): raise TrestleError ( f 'Writer must be of io.TextIOWrapper, given f { writer . __class__ } ' ) self . _writer : Optional [ io . TextIOWrapper ] = writer self . _element : Element = element self . _content_type : FileContentType = content_type self . _lastStreamPos = - 1 if self . _writer is not None : self . _lastStreamPos = self . _writer . tell () __str__ ( self ) special \u00a4 Return string representation. Source code in trestle/core/models/actions.py def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . get_type () } { self . _element } ' execute ( self ) \u00a4 Execute the action. Source code in trestle/core/models/actions.py def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" if self . _element is None : raise TrestleError ( 'Element is empty and cannot write' ) if not self . _is_writer_valid (): raise TrestleError ( 'Writer is not provided or closed' ) self . _writer . write ( self . _encode ()) self . _writer . flush () self . _mark_executed () rollback ( self ) \u00a4 Rollback the action. Source code in trestle/core/models/actions.py def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if not self . _is_writer_valid (): raise TrestleError ( 'Writer is not provided or closed' ) if self . _lastStreamPos < 0 : raise TrestleError ( 'Last stream position is not available to rollback to' ) if self . has_executed (): self . _writer . seek ( self . _lastStreamPos ) self . _writer . truncate () self . _mark_rollback () WriteFileAction ( WriteAction ) \u00a4 Write the element to a destination file. Source code in trestle/core/models/actions.py class WriteFileAction ( WriteAction ): \"\"\"Write the element to a destination file.\"\"\" def __init__ ( self , file_path : pathlib . Path , element : Element , content_type : FileContentType ) -> None : \"\"\"Initialize a write file action. It opens the file in append mode. Therefore the file needs to exist even if it is a new file. \"\"\" if not isinstance ( file_path , pathlib . Path ): raise TrestleError ( 'file_path should be of type pathlib.Path' ) inferred_content_type = FileContentType . to_content_type ( file_path . suffix ) if inferred_content_type != content_type : raise TrestleError ( f 'Mismatch between stated content type { content_type . name } and file path { file_path } ' ) self . _file_path = file_path # initialize super without writer for now # Note, execute and rollback sets the writer as appropriate super () . __init__ ( None , element , content_type ) def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" if not self . _file_path . exists (): raise TrestleError ( f 'File at { self . _file_path } does not exist' ) with open ( self . _file_path , 'a+' , encoding = const . FILE_ENCODING ) as writer : if self . _lastStreamPos < 0 : self . _lastStreamPos = writer . tell () else : writer . seek ( self . _lastStreamPos ) self . _writer = writer super () . execute () def rollback ( self ) -> None : \"\"\"Execute the rollback action.\"\"\" if not self . _file_path . exists (): raise TrestleError ( f 'File at { self . _file_path } does not exist' ) with open ( self . _file_path , 'a+' , encoding = const . FILE_ENCODING ) as writer : self . _writer = writer super () . rollback () def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } { self . _element } to \" { self . _file_path } \"' Methods \u00a4 __init__ ( self , file_path , element , content_type ) special \u00a4 Initialize a write file action. It opens the file in append mode. Therefore the file needs to exist even if it is a new file. Source code in trestle/core/models/actions.py def __init__ ( self , file_path : pathlib . Path , element : Element , content_type : FileContentType ) -> None : \"\"\"Initialize a write file action. It opens the file in append mode. Therefore the file needs to exist even if it is a new file. \"\"\" if not isinstance ( file_path , pathlib . Path ): raise TrestleError ( 'file_path should be of type pathlib.Path' ) inferred_content_type = FileContentType . to_content_type ( file_path . suffix ) if inferred_content_type != content_type : raise TrestleError ( f 'Mismatch between stated content type { content_type . name } and file path { file_path } ' ) self . _file_path = file_path # initialize super without writer for now # Note, execute and rollback sets the writer as appropriate super () . __init__ ( None , element , content_type ) __str__ ( self ) special \u00a4 Source code in trestle/core/models/actions.py def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } { self . _element } to \" { self . _file_path } \"' execute ( self ) \u00a4 Execute the action. Source code in trestle/core/models/actions.py def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" if not self . _file_path . exists (): raise TrestleError ( f 'File at { self . _file_path } does not exist' ) with open ( self . _file_path , 'a+' , encoding = const . FILE_ENCODING ) as writer : if self . _lastStreamPos < 0 : self . _lastStreamPos = writer . tell () else : writer . seek ( self . _lastStreamPos ) self . _writer = writer super () . execute () rollback ( self ) \u00a4 Execute the rollback action. Source code in trestle/core/models/actions.py def rollback ( self ) -> None : \"\"\"Execute the rollback action.\"\"\" if not self . _file_path . exists (): raise TrestleError ( f 'File at { self . _file_path } does not exist' ) with open ( self . _file_path , 'a+' , encoding = const . FILE_ENCODING ) as writer : self . _writer = writer super () . rollback () handler: python","title":"actions"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions","text":"Action wrapper of a command.","title":"actions"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.Action","text":"Action wrapper of a command. Source code in trestle/core/models/actions.py class Action ( ABC ): \"\"\"Action wrapper of a command.\"\"\" def __init__ ( self , action_type : ActionType , has_rollback : bool ) -> None : \"\"\"Initialize an base action.\"\"\" self . _type : ActionType = action_type self . _has_rollback : bool = has_rollback # child class must set this flag once it executes self . _has_executed = False def to_string ( self ) -> str : \"\"\"Return a string representation.\"\"\" return self . __str__ () def get_type ( self ) -> ActionType : \"\"\"Return the action type.\"\"\" return self . _type def _mark_executed ( self ) -> None : \"\"\"Set flag that the action has been executed.\"\"\" self . _has_executed = True def has_executed ( self ) -> bool : \"\"\"Return if the action has been executed.\"\"\" return self . _has_executed def _mark_rollback ( self ) -> None : \"\"\"Set flag that the action has been rollbacked.\"\"\" self . _has_executed = False def has_rollback ( self ) -> bool : \"\"\"Return if rollback of the action is possible.\"\"\" return self . _has_rollback def __eq__ ( self , other : object ) -> bool : \"\"\"Check that two actions are equal.\"\"\" if not isinstance ( other , Action ): return False if self . get_type () is not other . get_type (): return False is_eq = self . __dict__ == other . __dict__ return is_eq @abstractmethod def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" @abstractmethod def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\"","title":"Action"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.Action-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.Action.__eq__","text":"Check that two actions are equal. Source code in trestle/core/models/actions.py def __eq__ ( self , other : object ) -> bool : \"\"\"Check that two actions are equal.\"\"\" if not isinstance ( other , Action ): return False if self . get_type () is not other . get_type (): return False is_eq = self . __dict__ == other . __dict__ return is_eq","title":"__eq__()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.Action.__init__","text":"Initialize an base action. Source code in trestle/core/models/actions.py def __init__ ( self , action_type : ActionType , has_rollback : bool ) -> None : \"\"\"Initialize an base action.\"\"\" self . _type : ActionType = action_type self . _has_rollback : bool = has_rollback # child class must set this flag once it executes self . _has_executed = False","title":"__init__()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.Action.execute","text":"Execute the action. Source code in trestle/core/models/actions.py @abstractmethod def execute ( self ) -> None : \"\"\"Execute the action.\"\"\"","title":"execute()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.Action.get_type","text":"Return the action type. Source code in trestle/core/models/actions.py def get_type ( self ) -> ActionType : \"\"\"Return the action type.\"\"\" return self . _type","title":"get_type()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.Action.has_executed","text":"Return if the action has been executed. Source code in trestle/core/models/actions.py def has_executed ( self ) -> bool : \"\"\"Return if the action has been executed.\"\"\" return self . _has_executed","title":"has_executed()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.Action.has_rollback","text":"Return if rollback of the action is possible. Source code in trestle/core/models/actions.py def has_rollback ( self ) -> bool : \"\"\"Return if rollback of the action is possible.\"\"\" return self . _has_rollback","title":"has_rollback()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.Action.rollback","text":"Rollback the action. Source code in trestle/core/models/actions.py @abstractmethod def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\"","title":"rollback()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.Action.to_string","text":"Return a string representation. Source code in trestle/core/models/actions.py def to_string ( self ) -> str : \"\"\"Return a string representation.\"\"\" return self . __str__ ()","title":"to_string()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.ActionType","text":"Action type enum for different action type. File system related actions have code like 1 Model processing related actions have code like 2 Source code in trestle/core/models/actions.py class ActionType ( Enum ): \"\"\"Action type enum for different action type. File system related actions have code like 1* Model processing related actions have code like 2* \"\"\" # create a file or directory path CREATE_PATH = 10 # remove a file or directory path REMOVE_PATH = 12 # write element to a destination file or stream WRITE = 11 # update or add the element at the path UPDATE = 20 # remove the element at the path REMOVE = 21","title":"ActionType"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.ActionType.CREATE_PATH","text":"","title":"CREATE_PATH"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.ActionType.REMOVE","text":"","title":"REMOVE"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.ActionType.REMOVE_PATH","text":"","title":"REMOVE_PATH"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.ActionType.UPDATE","text":"","title":"UPDATE"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.ActionType.WRITE","text":"","title":"WRITE"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.CreatePathAction","text":"Create a file or directory path. Source code in trestle/core/models/actions.py class CreatePathAction ( Action ): \"\"\"Create a file or directory path.\"\"\" def __init__ ( self , sub_path : pathlib . Path , clear_content : bool = False ) -> None : \"\"\"Initialize a create path action. It creates all the missing directories in the path. If it is a file, then it also creates an empty file with the name provided Arguments: sub_path: this is the desired file or directory path that needs to be created under the project root \"\"\" sub_path = sub_path . resolve () self . _trestle_project_root = file_utils . extract_trestle_project_root ( sub_path ) if self . _trestle_project_root is None : raise TrestleError ( f 'Sub path \" { sub_path } \" should be child of a valid trestle project' ) self . _sub_path = sub_path self . _created_paths : List [ pathlib . Path ] = [] # variables for handling with file content self . _clear_content = clear_content self . _old_file_content = None super () . __init__ ( ActionType . CREATE_PATH , True ) def get_trestle_project_root ( self ) -> pathlib . Path : \"\"\"Return the trestle project root path.\"\"\" return self . _trestle_project_root def get_created_paths ( self ) -> List [ pathlib . Path ]: \"\"\"Get the list of paths that were created after being executed.\"\"\" return self . _created_paths def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" # find the start of the sub_path relative to trestle project root cur_index = len ( self . _trestle_project_root . parts ) # loop through the sub_path parts and create as necessary cur_path = self . _trestle_project_root while cur_index < len ( self . _sub_path . parts ): part = self . _sub_path . parts [ cur_index ] # create a path relative to the current # it starts with the project root, so we shall always create # sub directories or files relative to the project root cur_path = cur_path / part # create the sub_path file or directory if it does not exists already if cur_path . suffix != '' : # suffix will denote a file if not cur_path . exists (): # create file cur_path . touch () # add in the list for rollback self . _created_paths . append ( cur_path ) elif self . _clear_content : # read file content for rollback with open ( cur_path , 'r+' , encoding = const . FILE_ENCODING ) as fp : # read all content self . _old_file_content = fp . read () # clear file content fp . truncate ( 0 ) else : if not cur_path . exists (): # create directory cur_path . mkdir () # add in the list for rollback self . _created_paths . append ( cur_path ) # move to the next part of the sub_path parts cur_index = cur_index + 1 self . _mark_executed () def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if self . has_executed (): if len ( self . _created_paths ) > 0 : for cur_path in reversed ( self . _created_paths ): if cur_path . exists (): if cur_path . is_file (): cur_path . unlink () elif cur_path . is_dir (): cur_path . rmdir () self . _created_paths . clear () # rollback the content of a file if required # we should be here only if there were no path created and the sub_part already existed elif self . _sub_path . is_file () and self . _sub_path . exists () and self . _clear_content is True : if self . _old_file_content is not None : with open ( self . _sub_path , 'w' , encoding = const . FILE_ENCODING ) as fp : fp . write ( self . _old_file_content ) self . _mark_rollback () def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } { self . _sub_path } '","title":"CreatePathAction"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.CreatePathAction-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.CreatePathAction.__init__","text":"Initialize a create path action. It creates all the missing directories in the path. If it is a file, then it also creates an empty file with the name provided Parameters: Name Type Description Default sub_path Path this is the desired file or directory path that needs to be created under the project root required Source code in trestle/core/models/actions.py def __init__ ( self , sub_path : pathlib . Path , clear_content : bool = False ) -> None : \"\"\"Initialize a create path action. It creates all the missing directories in the path. If it is a file, then it also creates an empty file with the name provided Arguments: sub_path: this is the desired file or directory path that needs to be created under the project root \"\"\" sub_path = sub_path . resolve () self . _trestle_project_root = file_utils . extract_trestle_project_root ( sub_path ) if self . _trestle_project_root is None : raise TrestleError ( f 'Sub path \" { sub_path } \" should be child of a valid trestle project' ) self . _sub_path = sub_path self . _created_paths : List [ pathlib . Path ] = [] # variables for handling with file content self . _clear_content = clear_content self . _old_file_content = None super () . __init__ ( ActionType . CREATE_PATH , True )","title":"__init__()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.CreatePathAction.__str__","text":"Return string representation. Source code in trestle/core/models/actions.py def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } { self . _sub_path } '","title":"__str__()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.CreatePathAction.execute","text":"Execute the action. Source code in trestle/core/models/actions.py def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" # find the start of the sub_path relative to trestle project root cur_index = len ( self . _trestle_project_root . parts ) # loop through the sub_path parts and create as necessary cur_path = self . _trestle_project_root while cur_index < len ( self . _sub_path . parts ): part = self . _sub_path . parts [ cur_index ] # create a path relative to the current # it starts with the project root, so we shall always create # sub directories or files relative to the project root cur_path = cur_path / part # create the sub_path file or directory if it does not exists already if cur_path . suffix != '' : # suffix will denote a file if not cur_path . exists (): # create file cur_path . touch () # add in the list for rollback self . _created_paths . append ( cur_path ) elif self . _clear_content : # read file content for rollback with open ( cur_path , 'r+' , encoding = const . FILE_ENCODING ) as fp : # read all content self . _old_file_content = fp . read () # clear file content fp . truncate ( 0 ) else : if not cur_path . exists (): # create directory cur_path . mkdir () # add in the list for rollback self . _created_paths . append ( cur_path ) # move to the next part of the sub_path parts cur_index = cur_index + 1 self . _mark_executed ()","title":"execute()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.CreatePathAction.get_created_paths","text":"Get the list of paths that were created after being executed. Source code in trestle/core/models/actions.py def get_created_paths ( self ) -> List [ pathlib . Path ]: \"\"\"Get the list of paths that were created after being executed.\"\"\" return self . _created_paths","title":"get_created_paths()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.CreatePathAction.get_trestle_project_root","text":"Return the trestle project root path. Source code in trestle/core/models/actions.py def get_trestle_project_root ( self ) -> pathlib . Path : \"\"\"Return the trestle project root path.\"\"\" return self . _trestle_project_root","title":"get_trestle_project_root()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.CreatePathAction.rollback","text":"Rollback the action. Source code in trestle/core/models/actions.py def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if self . has_executed (): if len ( self . _created_paths ) > 0 : for cur_path in reversed ( self . _created_paths ): if cur_path . exists (): if cur_path . is_file (): cur_path . unlink () elif cur_path . is_dir (): cur_path . rmdir () self . _created_paths . clear () # rollback the content of a file if required # we should be here only if there were no path created and the sub_part already existed elif self . _sub_path . is_file () and self . _sub_path . exists () and self . _clear_content is True : if self . _old_file_content is not None : with open ( self . _sub_path , 'w' , encoding = const . FILE_ENCODING ) as fp : fp . write ( self . _old_file_content ) self . _mark_rollback ()","title":"rollback()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.RemoveAction","text":"Remove sub element at the element path in the source element. Source code in trestle/core/models/actions.py class RemoveAction ( Action ): \"\"\"Remove sub element at the element path in the source element.\"\"\" def __init__ ( self , src_element : Element , sub_element_path : ElementPath ) -> None : \"\"\"Initialize a remove element action.\"\"\" super () . __init__ ( ActionType . REMOVE , True ) self . _src_element : Element = src_element self . _sub_element_path : ElementPath = sub_element_path self . _prev_sub_element = None def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" self . _prev_sub_element = self . _src_element . get_at ( self . _sub_element_path ) self . _src_element . set_at ( self . _sub_element_path , None ) self . _mark_executed () def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if self . has_executed (): self . _src_element . set_at ( self . _sub_element_path , self . _prev_sub_element ) self . _mark_rollback () def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } element at { self . _sub_element_path } from { self . _src_element } '","title":"RemoveAction"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.RemoveAction-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.RemoveAction.__init__","text":"Initialize a remove element action. Source code in trestle/core/models/actions.py def __init__ ( self , src_element : Element , sub_element_path : ElementPath ) -> None : \"\"\"Initialize a remove element action.\"\"\" super () . __init__ ( ActionType . REMOVE , True ) self . _src_element : Element = src_element self . _sub_element_path : ElementPath = sub_element_path self . _prev_sub_element = None","title":"__init__()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.RemoveAction.__str__","text":"Return string representation. Source code in trestle/core/models/actions.py def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } element at { self . _sub_element_path } from { self . _src_element } '","title":"__str__()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.RemoveAction.execute","text":"Execute the action. Source code in trestle/core/models/actions.py def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" self . _prev_sub_element = self . _src_element . get_at ( self . _sub_element_path ) self . _src_element . set_at ( self . _sub_element_path , None ) self . _mark_executed ()","title":"execute()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.RemoveAction.rollback","text":"Rollback the action. Source code in trestle/core/models/actions.py def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if self . has_executed (): self . _src_element . set_at ( self . _sub_element_path , self . _prev_sub_element ) self . _mark_rollback ()","title":"rollback()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.RemovePathAction","text":"Remove a file or directory path. Source code in trestle/core/models/actions.py class RemovePathAction ( Action ): \"\"\"Remove a file or directory path.\"\"\" def __init__ ( self , sub_path : pathlib . Path ) -> None : \"\"\"Initialize a remove path action. It removes the file or directory recursively into trash. Arguments: sub_path: this is the desired file or directory path that needs to be removed under the project root \"\"\" if not isinstance ( sub_path , pathlib . Path ): raise TrestleError ( 'Sub path must be of type pathlib.Path' ) self . _trestle_project_root = file_utils . extract_trestle_project_root ( sub_path ) if self . _trestle_project_root is None : raise TrestleError ( f 'Sub path \" { sub_path } \" should be child of a valid trestle project.' ) self . _sub_path = sub_path super () . __init__ ( ActionType . REMOVE_PATH , True ) def get_trestle_project_root ( self ) -> Optional [ pathlib . Path ]: \"\"\"Return the trestle project root path.\"\"\" return self . _trestle_project_root def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" if not self . _sub_path . exists (): logger . debug ( f 'path { self . _sub_path } does not exist in remove path action - ignoring.' ) trash . store ( self . _sub_path , True ) # check if parent folder is empty and if so delete parent_dir = pathlib . Path ( os . path . dirname ( self . _sub_path )) files = list ( parent_dir . iterdir ()) if not files : trash . store ( parent_dir , True ) self . _mark_executed () def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if self . has_executed (): trash_path = trash . to_trash_path ( self . _sub_path ) if trash_path is None or trash_path . exists () is False : # FIXME suppress file contents not found message til trash/rollback behavior is fixed. # issue 412 return trash . recover ( self . _sub_path , True ) self . _mark_rollback () def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } { self . _sub_path } '","title":"RemovePathAction"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.RemovePathAction-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.RemovePathAction.__init__","text":"Initialize a remove path action. It removes the file or directory recursively into trash. Parameters: Name Type Description Default sub_path Path this is the desired file or directory path that needs to be removed under the project root required Source code in trestle/core/models/actions.py def __init__ ( self , sub_path : pathlib . Path ) -> None : \"\"\"Initialize a remove path action. It removes the file or directory recursively into trash. Arguments: sub_path: this is the desired file or directory path that needs to be removed under the project root \"\"\" if not isinstance ( sub_path , pathlib . Path ): raise TrestleError ( 'Sub path must be of type pathlib.Path' ) self . _trestle_project_root = file_utils . extract_trestle_project_root ( sub_path ) if self . _trestle_project_root is None : raise TrestleError ( f 'Sub path \" { sub_path } \" should be child of a valid trestle project.' ) self . _sub_path = sub_path super () . __init__ ( ActionType . REMOVE_PATH , True )","title":"__init__()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.RemovePathAction.__str__","text":"Return string representation. Source code in trestle/core/models/actions.py def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } { self . _sub_path } '","title":"__str__()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.RemovePathAction.execute","text":"Execute the action. Source code in trestle/core/models/actions.py def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" if not self . _sub_path . exists (): logger . debug ( f 'path { self . _sub_path } does not exist in remove path action - ignoring.' ) trash . store ( self . _sub_path , True ) # check if parent folder is empty and if so delete parent_dir = pathlib . Path ( os . path . dirname ( self . _sub_path )) files = list ( parent_dir . iterdir ()) if not files : trash . store ( parent_dir , True ) self . _mark_executed ()","title":"execute()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.RemovePathAction.get_trestle_project_root","text":"Return the trestle project root path. Source code in trestle/core/models/actions.py def get_trestle_project_root ( self ) -> Optional [ pathlib . Path ]: \"\"\"Return the trestle project root path.\"\"\" return self . _trestle_project_root","title":"get_trestle_project_root()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.RemovePathAction.rollback","text":"Rollback the action. Source code in trestle/core/models/actions.py def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if self . has_executed (): trash_path = trash . to_trash_path ( self . _sub_path ) if trash_path is None or trash_path . exists () is False : # FIXME suppress file contents not found message til trash/rollback behavior is fixed. # issue 412 return trash . recover ( self . _sub_path , True ) self . _mark_rollback ()","title":"rollback()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.UpdateAction","text":"Update element at the element path in the destination element with the source element. Source code in trestle/core/models/actions.py class UpdateAction ( Action ): \"\"\"Update element at the element path in the destination element with the source element.\"\"\" def __init__ ( self , sub_element , dest_element : Element , sub_element_path : ElementPath ) -> None : \"\"\"Initialize an add element action. Sub element can be OscalBaseModel, Element, list or None \"\"\" super () . __init__ ( ActionType . UPDATE , True ) if not Element . is_allowed_sub_element_type ( sub_element ): allowed_types = Element . get_allowed_sub_element_types () raise TrestleError ( f 'Sub element \" { sub_element . __class__ } is not a allowed sub element types in \" { allowed_types } \"' ) self . _sub_element = sub_element self . _dest_element : Element = dest_element self . _sub_element_path : ElementPath = sub_element_path self . _prev_sub_element = None def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" self . _prev_sub_element = self . _dest_element . get_at ( self . _sub_element_path ) self . _dest_element . set_at ( self . _sub_element_path , self . _sub_element ) self . _mark_executed () def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if self . has_executed (): self . _dest_element . set_at ( self . _sub_element_path , self . _prev_sub_element ) self . _mark_rollback () def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } { self . _model_obj . __class__ } to { self . _dest_element } at { self . _sub_element_path } '","title":"UpdateAction"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.UpdateAction-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.UpdateAction.__init__","text":"Initialize an add element action. Sub element can be OscalBaseModel, Element, list or None Source code in trestle/core/models/actions.py def __init__ ( self , sub_element , dest_element : Element , sub_element_path : ElementPath ) -> None : \"\"\"Initialize an add element action. Sub element can be OscalBaseModel, Element, list or None \"\"\" super () . __init__ ( ActionType . UPDATE , True ) if not Element . is_allowed_sub_element_type ( sub_element ): allowed_types = Element . get_allowed_sub_element_types () raise TrestleError ( f 'Sub element \" { sub_element . __class__ } is not a allowed sub element types in \" { allowed_types } \"' ) self . _sub_element = sub_element self . _dest_element : Element = dest_element self . _sub_element_path : ElementPath = sub_element_path self . _prev_sub_element = None","title":"__init__()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.UpdateAction.__str__","text":"Return string representation. Source code in trestle/core/models/actions.py def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } { self . _model_obj . __class__ } to { self . _dest_element } at { self . _sub_element_path } '","title":"__str__()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.UpdateAction.execute","text":"Execute the action. Source code in trestle/core/models/actions.py def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" self . _prev_sub_element = self . _dest_element . get_at ( self . _sub_element_path ) self . _dest_element . set_at ( self . _sub_element_path , self . _sub_element ) self . _mark_executed ()","title":"execute()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.UpdateAction.rollback","text":"Rollback the action. Source code in trestle/core/models/actions.py def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if self . has_executed (): self . _dest_element . set_at ( self . _sub_element_path , self . _prev_sub_element ) self . _mark_rollback ()","title":"rollback()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.WriteAction","text":"Write the element to a destination stream. Source code in trestle/core/models/actions.py class WriteAction ( Action ): \"\"\"Write the element to a destination stream.\"\"\" def __init__ ( self , writer : Optional [ io . TextIOWrapper ], element : Element , content_type : FileContentType ) -> None : \"\"\"Initialize an write file action.\"\"\" super () . __init__ ( ActionType . WRITE , True ) if writer is not None and not issubclass ( io . TextIOWrapper , writer . __class__ ): raise TrestleError ( f 'Writer must be of io.TextIOWrapper, given f { writer . __class__ } ' ) self . _writer : Optional [ io . TextIOWrapper ] = writer self . _element : Element = element self . _content_type : FileContentType = content_type self . _lastStreamPos = - 1 if self . _writer is not None : self . _lastStreamPos = self . _writer . tell () def _is_writer_valid ( self ) -> bool : if self . _writer is not None and isinstance ( self . _writer , io . TextIOWrapper ) and not self . _writer . closed : return True return False def _encode ( self ) -> str : \"\"\"Encode the element to appropriate content type.\"\"\" if self . _content_type == FileContentType . YAML : return self . _element . to_yaml () if self . _content_type == FileContentType . JSON : return self . _element . to_json () raise TrestleError ( f 'Invalid content type { self . _content_type } ' ) def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" if self . _element is None : raise TrestleError ( 'Element is empty and cannot write' ) if not self . _is_writer_valid (): raise TrestleError ( 'Writer is not provided or closed' ) self . _writer . write ( self . _encode ()) self . _writer . flush () self . _mark_executed () def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if not self . _is_writer_valid (): raise TrestleError ( 'Writer is not provided or closed' ) if self . _lastStreamPos < 0 : raise TrestleError ( 'Last stream position is not available to rollback to' ) if self . has_executed (): self . _writer . seek ( self . _lastStreamPos ) self . _writer . truncate () self . _mark_rollback () def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . get_type () } { self . _element } '","title":"WriteAction"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.WriteAction-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.WriteAction.__init__","text":"Initialize an write file action. Source code in trestle/core/models/actions.py def __init__ ( self , writer : Optional [ io . TextIOWrapper ], element : Element , content_type : FileContentType ) -> None : \"\"\"Initialize an write file action.\"\"\" super () . __init__ ( ActionType . WRITE , True ) if writer is not None and not issubclass ( io . TextIOWrapper , writer . __class__ ): raise TrestleError ( f 'Writer must be of io.TextIOWrapper, given f { writer . __class__ } ' ) self . _writer : Optional [ io . TextIOWrapper ] = writer self . _element : Element = element self . _content_type : FileContentType = content_type self . _lastStreamPos = - 1 if self . _writer is not None : self . _lastStreamPos = self . _writer . tell ()","title":"__init__()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.WriteAction.__str__","text":"Return string representation. Source code in trestle/core/models/actions.py def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . get_type () } { self . _element } '","title":"__str__()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.WriteAction.execute","text":"Execute the action. Source code in trestle/core/models/actions.py def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" if self . _element is None : raise TrestleError ( 'Element is empty and cannot write' ) if not self . _is_writer_valid (): raise TrestleError ( 'Writer is not provided or closed' ) self . _writer . write ( self . _encode ()) self . _writer . flush () self . _mark_executed ()","title":"execute()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.WriteAction.rollback","text":"Rollback the action. Source code in trestle/core/models/actions.py def rollback ( self ) -> None : \"\"\"Rollback the action.\"\"\" if not self . _is_writer_valid (): raise TrestleError ( 'Writer is not provided or closed' ) if self . _lastStreamPos < 0 : raise TrestleError ( 'Last stream position is not available to rollback to' ) if self . has_executed (): self . _writer . seek ( self . _lastStreamPos ) self . _writer . truncate () self . _mark_rollback ()","title":"rollback()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.WriteFileAction","text":"Write the element to a destination file. Source code in trestle/core/models/actions.py class WriteFileAction ( WriteAction ): \"\"\"Write the element to a destination file.\"\"\" def __init__ ( self , file_path : pathlib . Path , element : Element , content_type : FileContentType ) -> None : \"\"\"Initialize a write file action. It opens the file in append mode. Therefore the file needs to exist even if it is a new file. \"\"\" if not isinstance ( file_path , pathlib . Path ): raise TrestleError ( 'file_path should be of type pathlib.Path' ) inferred_content_type = FileContentType . to_content_type ( file_path . suffix ) if inferred_content_type != content_type : raise TrestleError ( f 'Mismatch between stated content type { content_type . name } and file path { file_path } ' ) self . _file_path = file_path # initialize super without writer for now # Note, execute and rollback sets the writer as appropriate super () . __init__ ( None , element , content_type ) def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" if not self . _file_path . exists (): raise TrestleError ( f 'File at { self . _file_path } does not exist' ) with open ( self . _file_path , 'a+' , encoding = const . FILE_ENCODING ) as writer : if self . _lastStreamPos < 0 : self . _lastStreamPos = writer . tell () else : writer . seek ( self . _lastStreamPos ) self . _writer = writer super () . execute () def rollback ( self ) -> None : \"\"\"Execute the rollback action.\"\"\" if not self . _file_path . exists (): raise TrestleError ( f 'File at { self . _file_path } does not exist' ) with open ( self . _file_path , 'a+' , encoding = const . FILE_ENCODING ) as writer : self . _writer = writer super () . rollback () def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } { self . _element } to \" { self . _file_path } \"'","title":"WriteFileAction"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.WriteFileAction-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.WriteFileAction.__init__","text":"Initialize a write file action. It opens the file in append mode. Therefore the file needs to exist even if it is a new file. Source code in trestle/core/models/actions.py def __init__ ( self , file_path : pathlib . Path , element : Element , content_type : FileContentType ) -> None : \"\"\"Initialize a write file action. It opens the file in append mode. Therefore the file needs to exist even if it is a new file. \"\"\" if not isinstance ( file_path , pathlib . Path ): raise TrestleError ( 'file_path should be of type pathlib.Path' ) inferred_content_type = FileContentType . to_content_type ( file_path . suffix ) if inferred_content_type != content_type : raise TrestleError ( f 'Mismatch between stated content type { content_type . name } and file path { file_path } ' ) self . _file_path = file_path # initialize super without writer for now # Note, execute and rollback sets the writer as appropriate super () . __init__ ( None , element , content_type )","title":"__init__()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.WriteFileAction.__str__","text":"Source code in trestle/core/models/actions.py def __str__ ( self ) -> str : \"\"\"Return string representation.\"\"\" return f ' { self . _type } { self . _element } to \" { self . _file_path } \"'","title":"__str__()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.WriteFileAction.execute","text":"Execute the action. Source code in trestle/core/models/actions.py def execute ( self ) -> None : \"\"\"Execute the action.\"\"\" if not self . _file_path . exists (): raise TrestleError ( f 'File at { self . _file_path } does not exist' ) with open ( self . _file_path , 'a+' , encoding = const . FILE_ENCODING ) as writer : if self . _lastStreamPos < 0 : self . _lastStreamPos = writer . tell () else : writer . seek ( self . _lastStreamPos ) self . _writer = writer super () . execute ()","title":"execute()"},{"location":"api_reference/trestle.core.models.actions/#trestle.core.models.actions.WriteFileAction.rollback","text":"Execute the rollback action. Source code in trestle/core/models/actions.py def rollback ( self ) -> None : \"\"\"Execute the rollback action.\"\"\" if not self . _file_path . exists (): raise TrestleError ( f 'File at { self . _file_path } does not exist' ) with open ( self . _file_path , 'a+' , encoding = const . FILE_ENCODING ) as writer : self . _writer = writer super () . rollback () handler: python","title":"rollback()"},{"location":"api_reference/trestle.core.models.elements/","text":"trestle.core.models.elements \u00a4 Element wrapper of an OSCAL model element. logger \u00a4 Classes \u00a4 Element \u00a4 Element wrapper of an OSCAL model. Source code in trestle/core/models/elements.py class Element : \"\"\"Element wrapper of an OSCAL model.\"\"\" IGNORE_WRAPPER_ALIAS = '__' _allowed_sub_element_types : List [ str ] = [ 'Element' , 'OscalBaseModel' , 'list' , 'None' , 'dict' ] def __init__ ( self , elem : OscalBaseModel , wrapper_alias : str = '' ): \"\"\"Initialize an element wrapper. wrapper_alias is the OSCAL alias for the given elem object and used for seriazation in to_json() method. For example, - List[Catalog.Group] element should have wrapper alias 'groups' - Catalog element should have wrapper alias 'catalog' wrapper_alias is deduced for collection type object if wrapper_alias = IGNORE_WRAPPER_ALIAS, then it is ignored and assumed to be json-serializable during to_json() \"\"\" # FIXME: There are instances where elem is a list. self . _elem : OscalBaseModel = elem if wrapper_alias == '' and wrapper_alias != self . IGNORE_WRAPPER_ALIAS : class_name = elem . __class__ . __name__ if utils . is_collection_field_type ( elem ): class_name = self . _get_singular_classname () if class_name is None : raise TrestleError ( f 'wrapper_alias not found for a collection type object: { elem . __class__ . __name__ } ' ) wrapper_alias = str_utils . classname_to_alias ( class_name , AliasMode . JSON ) self . _wrapper_alias : str = wrapper_alias def _get_singular_classname ( self ) -> str : \"\"\"Get the inner class name for list or dict objects.\"\"\" # this assumes all items in list and all values in dict are same type class_name = None root = getattr ( self . _elem , '__root__' , None ) if root is not None : type_str = root . __class__ . __name__ if type_str == 'list' : class_name = self . _elem . __root__ [ 0 ] . __class__ . __name__ elif type_str == 'dict' : class_name = list ( self . _elem . __root__ . values ())[ 0 ] . __class__ . __name__ return class_name def get ( self ) -> OscalBaseModel : \"\"\"Return the model object.\"\"\" return self . _elem def _split_element_path ( self , element_path : ElementPath ): \"\"\"Split the element path into root_model and remaing attr names.\"\"\" path_parts = element_path . get () root_model = path_parts [ 0 ] path_parts = path_parts [ 1 :] return root_model , path_parts def get_at ( self , element_path : ElementPath = None , check_parent : bool = True ) -> Union [ OscalBaseModel , List [ OscalBaseModel ]]: \"\"\"Get the element at the specified element path. it will return the sub-model object at the path. Sub-model object can be of type OscalBaseModel or List \"\"\" if element_path is None : return self . _elem # find the root-model and element path parts _ , path_parts = self . _split_element_path ( element_path ) # TODO validate that self._elem is of same type as root_model # initialize the starting element for search elm = self . _elem if hasattr ( elm , '__root__' ) and ( isinstance ( elm . __root__ , dict ) or isinstance ( elm . __root__ , list )): elm = elm . __root__ # if parent exists and does not end with wildcard, use the parent as the starting element for search if check_parent and element_path . get_parent ( ) is not None and element_path . get_parent () . get_last () != ElementPath . WILDCARD : elm_at = self . get_at ( element_path . get_parent ()) if elm_at is None : raise TrestleNotFoundError ( f 'Invalid parent path { element_path . get_parent () } ' ) elm = elm_at # return the sub-element at the specified path for attr in path_parts : if elm is None : break # process for wildcard and array indexes if attr == ElementPath . WILDCARD : break elif attr . isnumeric (): if isinstance ( elm , list ): elm = elm [ int ( attr )] else : # index to a non list type should return None return None else : elm = elm . get_field_value_by_alias ( attr ) return elm def get_preceding_element ( self , element_path : ElementPath ) -> Optional [ OscalBaseModel ]: \"\"\"Get the preceding element in the path.\"\"\" preceding_path = element_path . get_preceding_path () preceding_elm : Optional [ OscalBaseModel ] = self . get_at ( preceding_path ) return preceding_elm def _get_sub_element_obj ( self , sub_element ): \"\"\"Convert sub element into allowed model obj.\"\"\" if not self . is_allowed_sub_element_type ( sub_element ): raise TrestleError ( f 'Sub element must be one of \" { self . get_allowed_sub_element_types () } \", found \" { sub_element . __class__ } \"' ) model_obj = sub_element if isinstance ( sub_element , Element ): model_obj = sub_element . get () return model_obj def set_at ( self , element_path : ElementPath , sub_element : OscalBaseModel ) -> 'Element' : \"\"\"Set a sub_element at the path in the current element. Sub element can be Element, OscalBaseModel, list or None type It returns the element itself so that chaining operation can be done such as `element.set_at(path, sub-element).get()`. \"\"\" # convert the element_path to ElementPath if needed if isinstance ( element_path , str ): element_path = ElementPath ( element_path ) # convert sub-element to OscalBaseModel if needed model_obj = self . _get_sub_element_obj ( sub_element ) # find the root-model and element path parts _ , path_parts = self . _split_element_path ( element_path ) # TODO validate that self._elem is of same type as root_model # If wildcard is present, check the input type and determine the preceding element if element_path . get_last () == ElementPath . WILDCARD : # validate the type is either list or OscalBaseModel if not isinstance ( model_obj , list ) and not isinstance ( model_obj , OscalBaseModel ): raise TrestleError ( f 'The model object needs to be a List or OscalBaseModel for path with \" { ElementPath . WILDCARD } \"' ) # since wildcard * is there, we need to go one level up for preceding element in the path preceding_elm = self . get_preceding_element ( element_path . get_preceding_path ()) else : # get the preceding element in the path preceding_elm = self . get_preceding_element ( element_path ) if preceding_elm is None : raise TrestleError ( f 'Invalid sub element path { element_path } with no valid preceding element' ) # check if it can be a valid sub_element of the parent sub_element_name = element_path . get_element_name () . replace ( '-' , '_' ) if hasattr ( preceding_elm , sub_element_name ) is False : raise TrestleError ( f 'Element \" { preceding_elm . __class__ } \" does not have the attribute \" { sub_element_name } \" ' f 'of type \" { model_obj . __class__ } \"' ) # set the sub-element try : setattr ( preceding_elm , sub_element_name , model_obj ) except ValidationError : sub_element_class = self . get_sub_element_class ( preceding_elm , sub_element_name ) raise TrestleError ( f 'Validation error: { sub_element_name } is expected to be \" { sub_element_class } \", ' f 'but found \" { model_obj . __class__ } \"' ) # returning self will allow to do 'chaining' of commands after set return self def to_yaml ( self ) -> str : \"\"\"Convert into YAML string.\"\"\" yaml = YAML ( typ = 'safe' ) yaml . default_flow_style = False from io import StringIO string_stream = StringIO () yaml . dump ( yaml . load ( self . to_json ( pretty = False )), string_stream ) yaml_data = string_stream . getvalue () string_stream . close () return yaml_data def to_json ( self , pretty : bool = True ) -> str : \"\"\"Convert into JSON string.\"\"\" if self . _wrapper_alias == self . IGNORE_WRAPPER_ALIAS : json_data = self . _elem . oscal_serialize_json ( pretty = pretty , wrapped = False ) else : # Note before trying to edit this # This transient model allows self._elem not be an OscalBaseModel (e.g. a DICT or LIST) # typing need to be clarified. if isinstance ( self . _elem , OscalBaseModel ): json_data = self . _elem . oscal_serialize_json ( pretty = pretty ) else : dynamic_passer = {} dynamic_passer [ 'TransientField' ] = ( self . _elem . __class__ , Field ( self , alias = self . _wrapper_alias )) wrapper_model = create_model ( 'TransientModel' , __base__ = OscalBaseModel , ** dynamic_passer ) # type: ignore wrapped_model = wrapper_model . construct ( ** { self . _wrapper_alias : self . _elem }) json_data = wrapped_model . oscal_serialize_json ( pretty = pretty , wrapped = False ) return json_data @classmethod def get_sub_element_class ( cls , parent_elm : OscalBaseModel , sub_element_name : str ): \"\"\"Get the class of the sub-element.\"\"\" sub_element_class = parent_elm . __fields__ [ sub_element_name ] . outer_type_ return sub_element_class @classmethod def get_allowed_sub_element_types ( cls ) -> List [ str ]: \"\"\"Get the list of allowed sub element types.\"\"\" return cls . _allowed_sub_element_types @classmethod def is_allowed_sub_element_type ( cls , elm ) -> bool : \"\"\"Check if is of allowed sub element type.\"\"\" # FIXME: The following logic does not use the _allowed_sub_element_types being defined for the class if ( isinstance ( elm , Element ) or isinstance ( elm , OscalBaseModel ) or isinstance ( elm , list ) or isinstance ( elm , dict ) or elm is None ): return True return False def __str__ ( self ) -> str : \"\"\"Return string representation of element.\"\"\" return type ( self . _elem ) . __name__ def __eq__ ( self , other : object ) -> bool : \"\"\"Check that two elements are equal.\"\"\" if not isinstance ( other , Element ): return False return self . get () == other . get () IGNORE_WRAPPER_ALIAS \u00a4 Methods \u00a4 __eq__ ( self , other ) special \u00a4 Check that two elements are equal. Source code in trestle/core/models/elements.py def __eq__ ( self , other : object ) -> bool : \"\"\"Check that two elements are equal.\"\"\" if not isinstance ( other , Element ): return False return self . get () == other . get () __init__ ( self , elem , wrapper_alias = '' ) special \u00a4 Initialize an element wrapper. wrapper_alias is the OSCAL alias for the given elem object and used for seriazation in to_json() method. For example, - List[Catalog.Group] element should have wrapper alias 'groups' - Catalog element should have wrapper alias 'catalog' wrapper_alias is deduced for collection type object if wrapper_alias = IGNORE_WRAPPER_ALIAS, then it is ignored and assumed to be json-serializable during to_json() Source code in trestle/core/models/elements.py def __init__ ( self , elem : OscalBaseModel , wrapper_alias : str = '' ): \"\"\"Initialize an element wrapper. wrapper_alias is the OSCAL alias for the given elem object and used for seriazation in to_json() method. For example, - List[Catalog.Group] element should have wrapper alias 'groups' - Catalog element should have wrapper alias 'catalog' wrapper_alias is deduced for collection type object if wrapper_alias = IGNORE_WRAPPER_ALIAS, then it is ignored and assumed to be json-serializable during to_json() \"\"\" # FIXME: There are instances where elem is a list. self . _elem : OscalBaseModel = elem if wrapper_alias == '' and wrapper_alias != self . IGNORE_WRAPPER_ALIAS : class_name = elem . __class__ . __name__ if utils . is_collection_field_type ( elem ): class_name = self . _get_singular_classname () if class_name is None : raise TrestleError ( f 'wrapper_alias not found for a collection type object: { elem . __class__ . __name__ } ' ) wrapper_alias = str_utils . classname_to_alias ( class_name , AliasMode . JSON ) self . _wrapper_alias : str = wrapper_alias __str__ ( self ) special \u00a4 Return string representation of element. Source code in trestle/core/models/elements.py def __str__ ( self ) -> str : \"\"\"Return string representation of element.\"\"\" return type ( self . _elem ) . __name__ get ( self ) \u00a4 Return the model object. Source code in trestle/core/models/elements.py def get ( self ) -> OscalBaseModel : \"\"\"Return the model object.\"\"\" return self . _elem get_allowed_sub_element_types () classmethod \u00a4 Get the list of allowed sub element types. Source code in trestle/core/models/elements.py @classmethod def get_allowed_sub_element_types ( cls ) -> List [ str ]: \"\"\"Get the list of allowed sub element types.\"\"\" return cls . _allowed_sub_element_types get_at ( self , element_path = None , check_parent = True ) \u00a4 Get the element at the specified element path. it will return the sub-model object at the path. Sub-model object can be of type OscalBaseModel or List Source code in trestle/core/models/elements.py def get_at ( self , element_path : ElementPath = None , check_parent : bool = True ) -> Union [ OscalBaseModel , List [ OscalBaseModel ]]: \"\"\"Get the element at the specified element path. it will return the sub-model object at the path. Sub-model object can be of type OscalBaseModel or List \"\"\" if element_path is None : return self . _elem # find the root-model and element path parts _ , path_parts = self . _split_element_path ( element_path ) # TODO validate that self._elem is of same type as root_model # initialize the starting element for search elm = self . _elem if hasattr ( elm , '__root__' ) and ( isinstance ( elm . __root__ , dict ) or isinstance ( elm . __root__ , list )): elm = elm . __root__ # if parent exists and does not end with wildcard, use the parent as the starting element for search if check_parent and element_path . get_parent ( ) is not None and element_path . get_parent () . get_last () != ElementPath . WILDCARD : elm_at = self . get_at ( element_path . get_parent ()) if elm_at is None : raise TrestleNotFoundError ( f 'Invalid parent path { element_path . get_parent () } ' ) elm = elm_at # return the sub-element at the specified path for attr in path_parts : if elm is None : break # process for wildcard and array indexes if attr == ElementPath . WILDCARD : break elif attr . isnumeric (): if isinstance ( elm , list ): elm = elm [ int ( attr )] else : # index to a non list type should return None return None else : elm = elm . get_field_value_by_alias ( attr ) return elm get_preceding_element ( self , element_path ) \u00a4 Get the preceding element in the path. Source code in trestle/core/models/elements.py def get_preceding_element ( self , element_path : ElementPath ) -> Optional [ OscalBaseModel ]: \"\"\"Get the preceding element in the path.\"\"\" preceding_path = element_path . get_preceding_path () preceding_elm : Optional [ OscalBaseModel ] = self . get_at ( preceding_path ) return preceding_elm get_sub_element_class ( parent_elm , sub_element_name ) classmethod \u00a4 Get the class of the sub-element. Source code in trestle/core/models/elements.py @classmethod def get_sub_element_class ( cls , parent_elm : OscalBaseModel , sub_element_name : str ): \"\"\"Get the class of the sub-element.\"\"\" sub_element_class = parent_elm . __fields__ [ sub_element_name ] . outer_type_ return sub_element_class is_allowed_sub_element_type ( elm ) classmethod \u00a4 Check if is of allowed sub element type. Source code in trestle/core/models/elements.py @classmethod def is_allowed_sub_element_type ( cls , elm ) -> bool : \"\"\"Check if is of allowed sub element type.\"\"\" # FIXME: The following logic does not use the _allowed_sub_element_types being defined for the class if ( isinstance ( elm , Element ) or isinstance ( elm , OscalBaseModel ) or isinstance ( elm , list ) or isinstance ( elm , dict ) or elm is None ): return True return False set_at ( self , element_path , sub_element ) \u00a4 Set a sub_element at the path in the current element. Sub element can be Element, OscalBaseModel, list or None type It returns the element itself so that chaining operation can be done such as element.set_at(path, sub-element).get() . Source code in trestle/core/models/elements.py def set_at ( self , element_path : ElementPath , sub_element : OscalBaseModel ) -> 'Element' : \"\"\"Set a sub_element at the path in the current element. Sub element can be Element, OscalBaseModel, list or None type It returns the element itself so that chaining operation can be done such as `element.set_at(path, sub-element).get()`. \"\"\" # convert the element_path to ElementPath if needed if isinstance ( element_path , str ): element_path = ElementPath ( element_path ) # convert sub-element to OscalBaseModel if needed model_obj = self . _get_sub_element_obj ( sub_element ) # find the root-model and element path parts _ , path_parts = self . _split_element_path ( element_path ) # TODO validate that self._elem is of same type as root_model # If wildcard is present, check the input type and determine the preceding element if element_path . get_last () == ElementPath . WILDCARD : # validate the type is either list or OscalBaseModel if not isinstance ( model_obj , list ) and not isinstance ( model_obj , OscalBaseModel ): raise TrestleError ( f 'The model object needs to be a List or OscalBaseModel for path with \" { ElementPath . WILDCARD } \"' ) # since wildcard * is there, we need to go one level up for preceding element in the path preceding_elm = self . get_preceding_element ( element_path . get_preceding_path ()) else : # get the preceding element in the path preceding_elm = self . get_preceding_element ( element_path ) if preceding_elm is None : raise TrestleError ( f 'Invalid sub element path { element_path } with no valid preceding element' ) # check if it can be a valid sub_element of the parent sub_element_name = element_path . get_element_name () . replace ( '-' , '_' ) if hasattr ( preceding_elm , sub_element_name ) is False : raise TrestleError ( f 'Element \" { preceding_elm . __class__ } \" does not have the attribute \" { sub_element_name } \" ' f 'of type \" { model_obj . __class__ } \"' ) # set the sub-element try : setattr ( preceding_elm , sub_element_name , model_obj ) except ValidationError : sub_element_class = self . get_sub_element_class ( preceding_elm , sub_element_name ) raise TrestleError ( f 'Validation error: { sub_element_name } is expected to be \" { sub_element_class } \", ' f 'but found \" { model_obj . __class__ } \"' ) # returning self will allow to do 'chaining' of commands after set return self to_json ( self , pretty = True ) \u00a4 Convert into JSON string. Source code in trestle/core/models/elements.py def to_json ( self , pretty : bool = True ) -> str : \"\"\"Convert into JSON string.\"\"\" if self . _wrapper_alias == self . IGNORE_WRAPPER_ALIAS : json_data = self . _elem . oscal_serialize_json ( pretty = pretty , wrapped = False ) else : # Note before trying to edit this # This transient model allows self._elem not be an OscalBaseModel (e.g. a DICT or LIST) # typing need to be clarified. if isinstance ( self . _elem , OscalBaseModel ): json_data = self . _elem . oscal_serialize_json ( pretty = pretty ) else : dynamic_passer = {} dynamic_passer [ 'TransientField' ] = ( self . _elem . __class__ , Field ( self , alias = self . _wrapper_alias )) wrapper_model = create_model ( 'TransientModel' , __base__ = OscalBaseModel , ** dynamic_passer ) # type: ignore wrapped_model = wrapper_model . construct ( ** { self . _wrapper_alias : self . _elem }) json_data = wrapped_model . oscal_serialize_json ( pretty = pretty , wrapped = False ) return json_data to_yaml ( self ) \u00a4 Convert into YAML string. Source code in trestle/core/models/elements.py def to_yaml ( self ) -> str : \"\"\"Convert into YAML string.\"\"\" yaml = YAML ( typ = 'safe' ) yaml . default_flow_style = False from io import StringIO string_stream = StringIO () yaml . dump ( yaml . load ( self . to_json ( pretty = False )), string_stream ) yaml_data = string_stream . getvalue () string_stream . close () return yaml_data ElementPath \u00a4 Element path wrapper of an element. This only allows a single wildcard '*' at the end to denote elements of an array or dict Source code in trestle/core/models/elements.py class ElementPath : \"\"\"Element path wrapper of an element. This only allows a single wildcard '*' at the end to denote elements of an array or dict \"\"\" PATH_SEPARATOR : str = const . ALIAS_PATH_SEPARATOR WILDCARD : str = '*' def __init__ ( self , element_path : str , parent_path : Optional [ 'ElementPath' ] = None ) -> None : \"\"\"Initialize an element wrapper. It assumes the element path contains oscal field alias with hyphens only \"\"\" self . _parent_path = parent_path self . _path : List [ str ] = self . _parse ( element_path ) # Initialize private variables for lazy processing and caching self . _element_name : Optional [ str ] = None self . _preceding_path : Optional [ 'ElementPath' ] = None def _parse ( self , element_path : str ) -> List [ str ]: \"\"\"Parse the element path and validate.\"\"\" parts : List [ str ] = element_path . split ( self . PATH_SEPARATOR ) for part in parts : if part == '' : raise TrestleError ( f 'Invalid path \" { element_path } \" because there are empty path parts between \" { self . PATH_SEPARATOR } \" ' 'or in the beginning' ) if parts [ 0 ] == self . WILDCARD : raise TrestleError ( f 'Invalid path { element_path } with wildcard.' ) return parts def get ( self ) -> List [ str ]: \"\"\"Return the path parts as a list.\"\"\" return self . _path def get_type ( self , root_model : Optional [ Type [ Any ]] = None , use_parent : bool = False ) -> Type [ Any ]: \"\"\"Get the type of an element. If possible the model type will be derived from one of the top level models, otherwise a 'root model' can be passed for situations where this is not possible. This type path should *NOT* have wild cards in it. It *may* have* indices. Valid Examples: catalog.metadata catalog.groups catalog.groups.group catalog catalog.groups.0 Args: root_model: An OscalBaseModel Type from which to base the approach on. use_parent: Whether or not to normalise the full path across parent ElementPaths, default to not. Returns: The type of the model whether or not it is an OscalBaseModel or not. \"\"\" effective_path : List [ str ] if use_parent : effective_path = self . get_full_path_parts () else : effective_path = self . _path if not root_model : # lookup root model from top level oscal models or fail prev_model = self . _top_level_type_lookup ( effective_path [ 0 ]) else : prev_model = root_model if len ( effective_path ) == 1 : return prev_model # variables # for current_element_str in effective_path[1:]: for current_element_str in effective_path [ 1 :]: # Determine if the parent model is a collection. if utils . is_collection_field_type ( prev_model ): inner_model = utils . get_inner_type ( prev_model ) inner_class_name = classname_to_alias ( inner_model . __name__ , AliasMode . JSON ) # Assert that the current name fits an expected form. # Valid choices here are *, integer (for arrays) and the inner model alias if ( inner_class_name == current_element_str or current_element_str == self . WILDCARD or current_element_str . isnumeric ()): prev_model = inner_model else : raise TrestleError ( 'Unexpected key in element path when finding type.' ) else : # Indices, * are not allowed on non-collection types if current_element_str == self . WILDCARD : raise TrestleError ( 'Wild card in unexpected position when trying to find class type.' + ' Element path type lookup can only occur where a single type can be identified.' ) prev_model = prev_model . alias_to_field_map ()[ current_element_str ] . outer_type_ return prev_model def get_obm_wrapped_type ( self , root_model : Optional [ Type [ Any ]] = None , use_parent : bool = False ) -> Type [ OscalBaseModel ]: \"\"\"Get the type of the element. If the type is a collection wrap the type in an OscalBaseModel as a __root__ element. This should principally be used for validating content. Args: root_model: An OscalBaseModel Type from which to base the approach on. use_parent: Whether or not to normalise the full path across parent ElementPaths, default to not. Returns: The type of the model whether wrapped or not as an OscalBaseModel. \"\"\" base_type = self . get_type ( root_model , use_parent ) # Get an outer model type. origin_type = utils . get_origin ( base_type ) if origin_type in [ list , dict ]: # OSCAL does not support collections of collections directly. We should not hit this scenario collection_name = self . get_last () if collection_name == self . WILDCARD : logger . critical ( 'Unexpected error in type system when inferring type from element path.' ) logger . critical ( 'Please report this issue.' ) raise TrestleError ( 'Unknown error inferring type from element path.' ) # Final path must be the alias new_base_type = create_model ( str_utils . alias_to_classname ( collection_name , AliasMode . JSON ), __base__ = OscalBaseModel , __root__ = ( base_type , ... ) ) return new_base_type return base_type def _top_level_type_lookup ( self , element_str : str ) -> Type [ common_types . TopLevelOscalModel ]: \"\"\"From an individual element tag, induce the type of the model. Args: element_str: individual element as text such as 'catalog' or 'profile' Returns: Top level object model such as catalog, profile etc. \"\"\" # Even though awkward use chain of models. if element_str not in const . MODEL_TYPE_LIST : raise TrestleError ( f ' { element_str } is not a top level model (e.g. catalog, profile)' ) model_package = const . MODEL_TYPE_TO_MODEL_MODULE [ element_str ] object_type , _ = ModelUtils . get_root_model ( model_package ) object_type = cast ( Type [ common_types . TopLevelOscalModel ], object_type ) return object_type def is_multipart ( self ) -> bool : \"\"\"Assert whether or not an element path is multiple parts. Originally element paths had to have multiple paths. This provides a check for higher level code that still has that requirement. Single part: catalog control assessment-results Multipart: catalog.metadata catalog.controls.control \"\"\" return len ( self . _path ) > 1 def to_string ( self ) -> str : \"\"\"Return the path parts as a dot-separated string.\"\"\" return self . PATH_SEPARATOR . join ( self . get ()) def get_parent ( self ) -> 'ElementPath' : \"\"\"Return the parent path. It can be None or a valid ElementPath \"\"\" return self . _parent_path def get_first ( self ) -> str : \"\"\"Return the first part of the path.\"\"\" return self . _path [ 0 ] def get_last ( self ) -> str : \"\"\"Return the last part of the path.\"\"\" return self . _path [ - 1 ] def get_full ( self ) -> str : \"\"\"Return the full path including parent path parts as a dot separated str.\"\"\" all_parts = self . get_full_path_parts () return self . PATH_SEPARATOR . join ( all_parts ) def get_element_name ( self ) -> str : \"\"\"Return the element alias name from the path. Essentailly this the last part of the element path \"\"\" # if it is available then return otherwise compute if self . _element_name is None : element_name = self . get_last () if element_name == self . WILDCARD : element_name = self . _path [ - 2 ] self . _element_name = element_name return self . _element_name def get_full_path_parts ( self ) -> List [ str ]: \"\"\"Get full path parts to the element including parent path parts as a list.\"\"\" path_parts = [] if self . get_parent () is not None : parent_path_parts = self . get_parent () . get_full_path_parts () path_parts . extend ( parent_path_parts ) path_parts . extend ( self . get ()[ 1 :]) # don't use the first part else : path_parts . extend ( self . get ()) return path_parts def get_preceding_path ( self ) -> 'ElementPath' : \"\"\"Return the element path to the preceding element in the path.\"\"\" # if it is available then return otherwise compute if self . _preceding_path is None : path_parts = self . get_full_path_parts () if len ( path_parts ) > 1 : prec_path_parts = path_parts [: - 1 ] self . _preceding_path = ElementPath ( self . PATH_SEPARATOR . join ( prec_path_parts )) return self . _preceding_path def find_last_file_in_path ( self , content_type : FileContentType , model_dir : pathlib . Path ) -> pathlib . Path : \"\"\"Find the last (nearest) existing file in the element path leading to this element.\"\"\" # model dir is the top level dir for this model, e.g. catalogs/mycat path = model_dir extension = FileContentType . to_file_extension ( content_type ) good_model : pathlib . Path = None for element in self . _path : if element == '*' : break model_file = ( path / element ) . with_suffix ( extension ) if not model_file . exists (): break path = path / element good_model = model_file return good_model def make_absolute ( self , model_dir : pathlib . Path , reference_dir : pathlib . Path ): \"\"\"Make the parts absolute from the top model dir.\"\"\" # Match the current relative element path to the model directory and reference directory # If the element path is partial and doesn't connect to the top of the model, # need to deduce absolute element path from the model_dir and the reference directory # that corresponds to the root of the element path # if first element is a model type it is already absolute if self . _path [ 0 ] not in const . MODEL_TYPE_LIST : rel_path = list ( reference_dir . relative_to ( model_dir ) . parts ) rel_path . extend ( self . _path ) self . _path = rel_path def make_relative ( self , model_relative_path : pathlib . Path ) -> int : \"\"\"Make the parts relative to the model path.\"\"\" # The element path should currently be absolute # The model relative path should be relative to the top leve of the model # Change the element path to be relative to the model being loaded # Returns 0 on success and 1 on failur rel_path_parts = model_relative_path . parts [: - 1 ] n_rel_parts = len ( rel_path_parts ) # the element path can't start above the model path if n_rel_parts >= len ( self . _path ): return 1 # confirm the leading parts match for ii in range ( n_rel_parts ): if rel_path_parts [ ii ] != self . _path [ ii ]: return 1 # chop off the leading parts of the absolute element path self . _path = self . _path [ n_rel_parts :] return 0 def to_file_path ( self , content_type : FileContentType = None , root_dir : str = '' ) -> pathlib . Path : \"\"\"Convert to a file or directory path for the element path. if content_type is not passed, it will return a path for directory \"\"\" path_parts = self . get () # skip wildcard if path_parts [ - 1 ] == ElementPath . WILDCARD : path_parts = path_parts [: - 1 ] if root_dir != '' : path_parts [ 0 ] = root_dir path_str = '/' . join ( path_parts ) # add file extension if required # this will be omitted if it is a dir path if content_type is not None : file_extension = FileContentType . to_file_extension ( content_type ) path_str = path_str + file_extension # prepare the path file_path : pathlib . Path = pathlib . Path ( f './ { path_str } ' ) return file_path def to_root_path ( self , content_type : FileContentType = None ) -> pathlib . Path : \"\"\"Convert to a file path for the element root.\"\"\" path_str = f './ { self . get_first () } ' if content_type is not None : file_extension = FileContentType . to_file_extension ( content_type ) path_str = path_str + file_extension file_path : pathlib . Path = pathlib . Path ( path_str ) return file_path def __str__ ( self ) -> str : \"\"\"Return string representation of element path.\"\"\" return self . to_string () def __eq__ ( self , other ) -> bool : \"\"\"Override equality method.\"\"\" if not isinstance ( other , ElementPath ): return False return self . get () == other . get () PATH_SEPARATOR : str \u00a4 WILDCARD : str \u00a4 Methods \u00a4 __eq__ ( self , other ) special \u00a4 Override equality method. Source code in trestle/core/models/elements.py def __eq__ ( self , other ) -> bool : \"\"\"Override equality method.\"\"\" if not isinstance ( other , ElementPath ): return False return self . get () == other . get () __init__ ( self , element_path , parent_path = None ) special \u00a4 Initialize an element wrapper. It assumes the element path contains oscal field alias with hyphens only Source code in trestle/core/models/elements.py def __init__ ( self , element_path : str , parent_path : Optional [ 'ElementPath' ] = None ) -> None : \"\"\"Initialize an element wrapper. It assumes the element path contains oscal field alias with hyphens only \"\"\" self . _parent_path = parent_path self . _path : List [ str ] = self . _parse ( element_path ) # Initialize private variables for lazy processing and caching self . _element_name : Optional [ str ] = None self . _preceding_path : Optional [ 'ElementPath' ] = None __str__ ( self ) special \u00a4 Return string representation of element path. Source code in trestle/core/models/elements.py def __str__ ( self ) -> str : \"\"\"Return string representation of element path.\"\"\" return self . to_string () find_last_file_in_path ( self , content_type , model_dir ) \u00a4 Find the last (nearest) existing file in the element path leading to this element. Source code in trestle/core/models/elements.py def find_last_file_in_path ( self , content_type : FileContentType , model_dir : pathlib . Path ) -> pathlib . Path : \"\"\"Find the last (nearest) existing file in the element path leading to this element.\"\"\" # model dir is the top level dir for this model, e.g. catalogs/mycat path = model_dir extension = FileContentType . to_file_extension ( content_type ) good_model : pathlib . Path = None for element in self . _path : if element == '*' : break model_file = ( path / element ) . with_suffix ( extension ) if not model_file . exists (): break path = path / element good_model = model_file return good_model get ( self ) \u00a4 Return the path parts as a list. Source code in trestle/core/models/elements.py def get ( self ) -> List [ str ]: \"\"\"Return the path parts as a list.\"\"\" return self . _path get_element_name ( self ) \u00a4 Return the element alias name from the path. Essentailly this the last part of the element path Source code in trestle/core/models/elements.py def get_element_name ( self ) -> str : \"\"\"Return the element alias name from the path. Essentailly this the last part of the element path \"\"\" # if it is available then return otherwise compute if self . _element_name is None : element_name = self . get_last () if element_name == self . WILDCARD : element_name = self . _path [ - 2 ] self . _element_name = element_name return self . _element_name get_first ( self ) \u00a4 Return the first part of the path. Source code in trestle/core/models/elements.py def get_first ( self ) -> str : \"\"\"Return the first part of the path.\"\"\" return self . _path [ 0 ] get_full ( self ) \u00a4 Return the full path including parent path parts as a dot separated str. Source code in trestle/core/models/elements.py def get_full ( self ) -> str : \"\"\"Return the full path including parent path parts as a dot separated str.\"\"\" all_parts = self . get_full_path_parts () return self . PATH_SEPARATOR . join ( all_parts ) get_full_path_parts ( self ) \u00a4 Get full path parts to the element including parent path parts as a list. Source code in trestle/core/models/elements.py def get_full_path_parts ( self ) -> List [ str ]: \"\"\"Get full path parts to the element including parent path parts as a list.\"\"\" path_parts = [] if self . get_parent () is not None : parent_path_parts = self . get_parent () . get_full_path_parts () path_parts . extend ( parent_path_parts ) path_parts . extend ( self . get ()[ 1 :]) # don't use the first part else : path_parts . extend ( self . get ()) return path_parts get_last ( self ) \u00a4 Return the last part of the path. Source code in trestle/core/models/elements.py def get_last ( self ) -> str : \"\"\"Return the last part of the path.\"\"\" return self . _path [ - 1 ] get_obm_wrapped_type ( self , root_model = None , use_parent = False ) \u00a4 Get the type of the element. If the type is a collection wrap the type in an OscalBaseModel as a root element. This should principally be used for validating content. Parameters: Name Type Description Default root_model Optional[Type[Any]] An OscalBaseModel Type from which to base the approach on. None use_parent bool Whether or not to normalise the full path across parent ElementPaths, default to not. False Returns: Type Description Type[trestle.core.base_model.OscalBaseModel] The type of the model whether wrapped or not as an OscalBaseModel. Source code in trestle/core/models/elements.py def get_obm_wrapped_type ( self , root_model : Optional [ Type [ Any ]] = None , use_parent : bool = False ) -> Type [ OscalBaseModel ]: \"\"\"Get the type of the element. If the type is a collection wrap the type in an OscalBaseModel as a __root__ element. This should principally be used for validating content. Args: root_model: An OscalBaseModel Type from which to base the approach on. use_parent: Whether or not to normalise the full path across parent ElementPaths, default to not. Returns: The type of the model whether wrapped or not as an OscalBaseModel. \"\"\" base_type = self . get_type ( root_model , use_parent ) # Get an outer model type. origin_type = utils . get_origin ( base_type ) if origin_type in [ list , dict ]: # OSCAL does not support collections of collections directly. We should not hit this scenario collection_name = self . get_last () if collection_name == self . WILDCARD : logger . critical ( 'Unexpected error in type system when inferring type from element path.' ) logger . critical ( 'Please report this issue.' ) raise TrestleError ( 'Unknown error inferring type from element path.' ) # Final path must be the alias new_base_type = create_model ( str_utils . alias_to_classname ( collection_name , AliasMode . JSON ), __base__ = OscalBaseModel , __root__ = ( base_type , ... ) ) return new_base_type return base_type get_parent ( self ) \u00a4 Return the parent path. It can be None or a valid ElementPath Source code in trestle/core/models/elements.py def get_parent ( self ) -> 'ElementPath' : \"\"\"Return the parent path. It can be None or a valid ElementPath \"\"\" return self . _parent_path get_preceding_path ( self ) \u00a4 Return the element path to the preceding element in the path. Source code in trestle/core/models/elements.py def get_preceding_path ( self ) -> 'ElementPath' : \"\"\"Return the element path to the preceding element in the path.\"\"\" # if it is available then return otherwise compute if self . _preceding_path is None : path_parts = self . get_full_path_parts () if len ( path_parts ) > 1 : prec_path_parts = path_parts [: - 1 ] self . _preceding_path = ElementPath ( self . PATH_SEPARATOR . join ( prec_path_parts )) return self . _preceding_path get_type ( self , root_model = None , use_parent = False ) \u00a4 Get the type of an element. If possible the model type will be derived from one of the top level models, otherwise a 'root model' can be passed for situations where this is not possible. This type path should NOT have wild cards in it. It may have* indices. Valid Examples: catalog.metadata catalog.groups catalog.groups.group catalog catalog.groups.0 Parameters: Name Type Description Default root_model Optional[Type[Any]] An OscalBaseModel Type from which to base the approach on. None use_parent bool Whether or not to normalise the full path across parent ElementPaths, default to not. False Returns: Type Description Type[Any] The type of the model whether or not it is an OscalBaseModel or not. Source code in trestle/core/models/elements.py def get_type ( self , root_model : Optional [ Type [ Any ]] = None , use_parent : bool = False ) -> Type [ Any ]: \"\"\"Get the type of an element. If possible the model type will be derived from one of the top level models, otherwise a 'root model' can be passed for situations where this is not possible. This type path should *NOT* have wild cards in it. It *may* have* indices. Valid Examples: catalog.metadata catalog.groups catalog.groups.group catalog catalog.groups.0 Args: root_model: An OscalBaseModel Type from which to base the approach on. use_parent: Whether or not to normalise the full path across parent ElementPaths, default to not. Returns: The type of the model whether or not it is an OscalBaseModel or not. \"\"\" effective_path : List [ str ] if use_parent : effective_path = self . get_full_path_parts () else : effective_path = self . _path if not root_model : # lookup root model from top level oscal models or fail prev_model = self . _top_level_type_lookup ( effective_path [ 0 ]) else : prev_model = root_model if len ( effective_path ) == 1 : return prev_model # variables # for current_element_str in effective_path[1:]: for current_element_str in effective_path [ 1 :]: # Determine if the parent model is a collection. if utils . is_collection_field_type ( prev_model ): inner_model = utils . get_inner_type ( prev_model ) inner_class_name = classname_to_alias ( inner_model . __name__ , AliasMode . JSON ) # Assert that the current name fits an expected form. # Valid choices here are *, integer (for arrays) and the inner model alias if ( inner_class_name == current_element_str or current_element_str == self . WILDCARD or current_element_str . isnumeric ()): prev_model = inner_model else : raise TrestleError ( 'Unexpected key in element path when finding type.' ) else : # Indices, * are not allowed on non-collection types if current_element_str == self . WILDCARD : raise TrestleError ( 'Wild card in unexpected position when trying to find class type.' + ' Element path type lookup can only occur where a single type can be identified.' ) prev_model = prev_model . alias_to_field_map ()[ current_element_str ] . outer_type_ return prev_model is_multipart ( self ) \u00a4 Assert whether or not an element path is multiple parts. Originally element paths had to have multiple paths. This provides a check for higher level code that still has that requirement. Single part: catalog control assessment-results Multipart catalog.metadata catalog.controls.control Source code in trestle/core/models/elements.py def is_multipart ( self ) -> bool : \"\"\"Assert whether or not an element path is multiple parts. Originally element paths had to have multiple paths. This provides a check for higher level code that still has that requirement. Single part: catalog control assessment-results Multipart: catalog.metadata catalog.controls.control \"\"\" return len ( self . _path ) > 1 make_absolute ( self , model_dir , reference_dir ) \u00a4 Make the parts absolute from the top model dir. Source code in trestle/core/models/elements.py def make_absolute ( self , model_dir : pathlib . Path , reference_dir : pathlib . Path ): \"\"\"Make the parts absolute from the top model dir.\"\"\" # Match the current relative element path to the model directory and reference directory # If the element path is partial and doesn't connect to the top of the model, # need to deduce absolute element path from the model_dir and the reference directory # that corresponds to the root of the element path # if first element is a model type it is already absolute if self . _path [ 0 ] not in const . MODEL_TYPE_LIST : rel_path = list ( reference_dir . relative_to ( model_dir ) . parts ) rel_path . extend ( self . _path ) self . _path = rel_path make_relative ( self , model_relative_path ) \u00a4 Make the parts relative to the model path. Source code in trestle/core/models/elements.py def make_relative ( self , model_relative_path : pathlib . Path ) -> int : \"\"\"Make the parts relative to the model path.\"\"\" # The element path should currently be absolute # The model relative path should be relative to the top leve of the model # Change the element path to be relative to the model being loaded # Returns 0 on success and 1 on failur rel_path_parts = model_relative_path . parts [: - 1 ] n_rel_parts = len ( rel_path_parts ) # the element path can't start above the model path if n_rel_parts >= len ( self . _path ): return 1 # confirm the leading parts match for ii in range ( n_rel_parts ): if rel_path_parts [ ii ] != self . _path [ ii ]: return 1 # chop off the leading parts of the absolute element path self . _path = self . _path [ n_rel_parts :] return 0 to_file_path ( self , content_type = None , root_dir = '' ) \u00a4 Convert to a file or directory path for the element path. if content_type is not passed, it will return a path for directory Source code in trestle/core/models/elements.py def to_file_path ( self , content_type : FileContentType = None , root_dir : str = '' ) -> pathlib . Path : \"\"\"Convert to a file or directory path for the element path. if content_type is not passed, it will return a path for directory \"\"\" path_parts = self . get () # skip wildcard if path_parts [ - 1 ] == ElementPath . WILDCARD : path_parts = path_parts [: - 1 ] if root_dir != '' : path_parts [ 0 ] = root_dir path_str = '/' . join ( path_parts ) # add file extension if required # this will be omitted if it is a dir path if content_type is not None : file_extension = FileContentType . to_file_extension ( content_type ) path_str = path_str + file_extension # prepare the path file_path : pathlib . Path = pathlib . Path ( f './ { path_str } ' ) return file_path to_root_path ( self , content_type = None ) \u00a4 Convert to a file path for the element root. Source code in trestle/core/models/elements.py def to_root_path ( self , content_type : FileContentType = None ) -> pathlib . Path : \"\"\"Convert to a file path for the element root.\"\"\" path_str = f './ { self . get_first () } ' if content_type is not None : file_extension = FileContentType . to_file_extension ( content_type ) path_str = path_str + file_extension file_path : pathlib . Path = pathlib . Path ( path_str ) return file_path to_string ( self ) \u00a4 Return the path parts as a dot-separated string. Source code in trestle/core/models/elements.py def to_string ( self ) -> str : \"\"\"Return the path parts as a dot-separated string.\"\"\" return self . PATH_SEPARATOR . join ( self . get ()) handler: python","title":"elements"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements","text":"Element wrapper of an OSCAL model element.","title":"elements"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.Element","text":"Element wrapper of an OSCAL model. Source code in trestle/core/models/elements.py class Element : \"\"\"Element wrapper of an OSCAL model.\"\"\" IGNORE_WRAPPER_ALIAS = '__' _allowed_sub_element_types : List [ str ] = [ 'Element' , 'OscalBaseModel' , 'list' , 'None' , 'dict' ] def __init__ ( self , elem : OscalBaseModel , wrapper_alias : str = '' ): \"\"\"Initialize an element wrapper. wrapper_alias is the OSCAL alias for the given elem object and used for seriazation in to_json() method. For example, - List[Catalog.Group] element should have wrapper alias 'groups' - Catalog element should have wrapper alias 'catalog' wrapper_alias is deduced for collection type object if wrapper_alias = IGNORE_WRAPPER_ALIAS, then it is ignored and assumed to be json-serializable during to_json() \"\"\" # FIXME: There are instances where elem is a list. self . _elem : OscalBaseModel = elem if wrapper_alias == '' and wrapper_alias != self . IGNORE_WRAPPER_ALIAS : class_name = elem . __class__ . __name__ if utils . is_collection_field_type ( elem ): class_name = self . _get_singular_classname () if class_name is None : raise TrestleError ( f 'wrapper_alias not found for a collection type object: { elem . __class__ . __name__ } ' ) wrapper_alias = str_utils . classname_to_alias ( class_name , AliasMode . JSON ) self . _wrapper_alias : str = wrapper_alias def _get_singular_classname ( self ) -> str : \"\"\"Get the inner class name for list or dict objects.\"\"\" # this assumes all items in list and all values in dict are same type class_name = None root = getattr ( self . _elem , '__root__' , None ) if root is not None : type_str = root . __class__ . __name__ if type_str == 'list' : class_name = self . _elem . __root__ [ 0 ] . __class__ . __name__ elif type_str == 'dict' : class_name = list ( self . _elem . __root__ . values ())[ 0 ] . __class__ . __name__ return class_name def get ( self ) -> OscalBaseModel : \"\"\"Return the model object.\"\"\" return self . _elem def _split_element_path ( self , element_path : ElementPath ): \"\"\"Split the element path into root_model and remaing attr names.\"\"\" path_parts = element_path . get () root_model = path_parts [ 0 ] path_parts = path_parts [ 1 :] return root_model , path_parts def get_at ( self , element_path : ElementPath = None , check_parent : bool = True ) -> Union [ OscalBaseModel , List [ OscalBaseModel ]]: \"\"\"Get the element at the specified element path. it will return the sub-model object at the path. Sub-model object can be of type OscalBaseModel or List \"\"\" if element_path is None : return self . _elem # find the root-model and element path parts _ , path_parts = self . _split_element_path ( element_path ) # TODO validate that self._elem is of same type as root_model # initialize the starting element for search elm = self . _elem if hasattr ( elm , '__root__' ) and ( isinstance ( elm . __root__ , dict ) or isinstance ( elm . __root__ , list )): elm = elm . __root__ # if parent exists and does not end with wildcard, use the parent as the starting element for search if check_parent and element_path . get_parent ( ) is not None and element_path . get_parent () . get_last () != ElementPath . WILDCARD : elm_at = self . get_at ( element_path . get_parent ()) if elm_at is None : raise TrestleNotFoundError ( f 'Invalid parent path { element_path . get_parent () } ' ) elm = elm_at # return the sub-element at the specified path for attr in path_parts : if elm is None : break # process for wildcard and array indexes if attr == ElementPath . WILDCARD : break elif attr . isnumeric (): if isinstance ( elm , list ): elm = elm [ int ( attr )] else : # index to a non list type should return None return None else : elm = elm . get_field_value_by_alias ( attr ) return elm def get_preceding_element ( self , element_path : ElementPath ) -> Optional [ OscalBaseModel ]: \"\"\"Get the preceding element in the path.\"\"\" preceding_path = element_path . get_preceding_path () preceding_elm : Optional [ OscalBaseModel ] = self . get_at ( preceding_path ) return preceding_elm def _get_sub_element_obj ( self , sub_element ): \"\"\"Convert sub element into allowed model obj.\"\"\" if not self . is_allowed_sub_element_type ( sub_element ): raise TrestleError ( f 'Sub element must be one of \" { self . get_allowed_sub_element_types () } \", found \" { sub_element . __class__ } \"' ) model_obj = sub_element if isinstance ( sub_element , Element ): model_obj = sub_element . get () return model_obj def set_at ( self , element_path : ElementPath , sub_element : OscalBaseModel ) -> 'Element' : \"\"\"Set a sub_element at the path in the current element. Sub element can be Element, OscalBaseModel, list or None type It returns the element itself so that chaining operation can be done such as `element.set_at(path, sub-element).get()`. \"\"\" # convert the element_path to ElementPath if needed if isinstance ( element_path , str ): element_path = ElementPath ( element_path ) # convert sub-element to OscalBaseModel if needed model_obj = self . _get_sub_element_obj ( sub_element ) # find the root-model and element path parts _ , path_parts = self . _split_element_path ( element_path ) # TODO validate that self._elem is of same type as root_model # If wildcard is present, check the input type and determine the preceding element if element_path . get_last () == ElementPath . WILDCARD : # validate the type is either list or OscalBaseModel if not isinstance ( model_obj , list ) and not isinstance ( model_obj , OscalBaseModel ): raise TrestleError ( f 'The model object needs to be a List or OscalBaseModel for path with \" { ElementPath . WILDCARD } \"' ) # since wildcard * is there, we need to go one level up for preceding element in the path preceding_elm = self . get_preceding_element ( element_path . get_preceding_path ()) else : # get the preceding element in the path preceding_elm = self . get_preceding_element ( element_path ) if preceding_elm is None : raise TrestleError ( f 'Invalid sub element path { element_path } with no valid preceding element' ) # check if it can be a valid sub_element of the parent sub_element_name = element_path . get_element_name () . replace ( '-' , '_' ) if hasattr ( preceding_elm , sub_element_name ) is False : raise TrestleError ( f 'Element \" { preceding_elm . __class__ } \" does not have the attribute \" { sub_element_name } \" ' f 'of type \" { model_obj . __class__ } \"' ) # set the sub-element try : setattr ( preceding_elm , sub_element_name , model_obj ) except ValidationError : sub_element_class = self . get_sub_element_class ( preceding_elm , sub_element_name ) raise TrestleError ( f 'Validation error: { sub_element_name } is expected to be \" { sub_element_class } \", ' f 'but found \" { model_obj . __class__ } \"' ) # returning self will allow to do 'chaining' of commands after set return self def to_yaml ( self ) -> str : \"\"\"Convert into YAML string.\"\"\" yaml = YAML ( typ = 'safe' ) yaml . default_flow_style = False from io import StringIO string_stream = StringIO () yaml . dump ( yaml . load ( self . to_json ( pretty = False )), string_stream ) yaml_data = string_stream . getvalue () string_stream . close () return yaml_data def to_json ( self , pretty : bool = True ) -> str : \"\"\"Convert into JSON string.\"\"\" if self . _wrapper_alias == self . IGNORE_WRAPPER_ALIAS : json_data = self . _elem . oscal_serialize_json ( pretty = pretty , wrapped = False ) else : # Note before trying to edit this # This transient model allows self._elem not be an OscalBaseModel (e.g. a DICT or LIST) # typing need to be clarified. if isinstance ( self . _elem , OscalBaseModel ): json_data = self . _elem . oscal_serialize_json ( pretty = pretty ) else : dynamic_passer = {} dynamic_passer [ 'TransientField' ] = ( self . _elem . __class__ , Field ( self , alias = self . _wrapper_alias )) wrapper_model = create_model ( 'TransientModel' , __base__ = OscalBaseModel , ** dynamic_passer ) # type: ignore wrapped_model = wrapper_model . construct ( ** { self . _wrapper_alias : self . _elem }) json_data = wrapped_model . oscal_serialize_json ( pretty = pretty , wrapped = False ) return json_data @classmethod def get_sub_element_class ( cls , parent_elm : OscalBaseModel , sub_element_name : str ): \"\"\"Get the class of the sub-element.\"\"\" sub_element_class = parent_elm . __fields__ [ sub_element_name ] . outer_type_ return sub_element_class @classmethod def get_allowed_sub_element_types ( cls ) -> List [ str ]: \"\"\"Get the list of allowed sub element types.\"\"\" return cls . _allowed_sub_element_types @classmethod def is_allowed_sub_element_type ( cls , elm ) -> bool : \"\"\"Check if is of allowed sub element type.\"\"\" # FIXME: The following logic does not use the _allowed_sub_element_types being defined for the class if ( isinstance ( elm , Element ) or isinstance ( elm , OscalBaseModel ) or isinstance ( elm , list ) or isinstance ( elm , dict ) or elm is None ): return True return False def __str__ ( self ) -> str : \"\"\"Return string representation of element.\"\"\" return type ( self . _elem ) . __name__ def __eq__ ( self , other : object ) -> bool : \"\"\"Check that two elements are equal.\"\"\" if not isinstance ( other , Element ): return False return self . get () == other . get ()","title":"Element"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.Element.IGNORE_WRAPPER_ALIAS","text":"","title":"IGNORE_WRAPPER_ALIAS"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.Element-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.Element.__eq__","text":"Check that two elements are equal. Source code in trestle/core/models/elements.py def __eq__ ( self , other : object ) -> bool : \"\"\"Check that two elements are equal.\"\"\" if not isinstance ( other , Element ): return False return self . get () == other . get ()","title":"__eq__()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.Element.__init__","text":"Initialize an element wrapper. wrapper_alias is the OSCAL alias for the given elem object and used for seriazation in to_json() method. For example, - List[Catalog.Group] element should have wrapper alias 'groups' - Catalog element should have wrapper alias 'catalog' wrapper_alias is deduced for collection type object if wrapper_alias = IGNORE_WRAPPER_ALIAS, then it is ignored and assumed to be json-serializable during to_json() Source code in trestle/core/models/elements.py def __init__ ( self , elem : OscalBaseModel , wrapper_alias : str = '' ): \"\"\"Initialize an element wrapper. wrapper_alias is the OSCAL alias for the given elem object and used for seriazation in to_json() method. For example, - List[Catalog.Group] element should have wrapper alias 'groups' - Catalog element should have wrapper alias 'catalog' wrapper_alias is deduced for collection type object if wrapper_alias = IGNORE_WRAPPER_ALIAS, then it is ignored and assumed to be json-serializable during to_json() \"\"\" # FIXME: There are instances where elem is a list. self . _elem : OscalBaseModel = elem if wrapper_alias == '' and wrapper_alias != self . IGNORE_WRAPPER_ALIAS : class_name = elem . __class__ . __name__ if utils . is_collection_field_type ( elem ): class_name = self . _get_singular_classname () if class_name is None : raise TrestleError ( f 'wrapper_alias not found for a collection type object: { elem . __class__ . __name__ } ' ) wrapper_alias = str_utils . classname_to_alias ( class_name , AliasMode . JSON ) self . _wrapper_alias : str = wrapper_alias","title":"__init__()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.Element.__str__","text":"Return string representation of element. Source code in trestle/core/models/elements.py def __str__ ( self ) -> str : \"\"\"Return string representation of element.\"\"\" return type ( self . _elem ) . __name__","title":"__str__()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.Element.get","text":"Return the model object. Source code in trestle/core/models/elements.py def get ( self ) -> OscalBaseModel : \"\"\"Return the model object.\"\"\" return self . _elem","title":"get()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.Element.get_allowed_sub_element_types","text":"Get the list of allowed sub element types. Source code in trestle/core/models/elements.py @classmethod def get_allowed_sub_element_types ( cls ) -> List [ str ]: \"\"\"Get the list of allowed sub element types.\"\"\" return cls . _allowed_sub_element_types","title":"get_allowed_sub_element_types()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.Element.get_at","text":"Get the element at the specified element path. it will return the sub-model object at the path. Sub-model object can be of type OscalBaseModel or List Source code in trestle/core/models/elements.py def get_at ( self , element_path : ElementPath = None , check_parent : bool = True ) -> Union [ OscalBaseModel , List [ OscalBaseModel ]]: \"\"\"Get the element at the specified element path. it will return the sub-model object at the path. Sub-model object can be of type OscalBaseModel or List \"\"\" if element_path is None : return self . _elem # find the root-model and element path parts _ , path_parts = self . _split_element_path ( element_path ) # TODO validate that self._elem is of same type as root_model # initialize the starting element for search elm = self . _elem if hasattr ( elm , '__root__' ) and ( isinstance ( elm . __root__ , dict ) or isinstance ( elm . __root__ , list )): elm = elm . __root__ # if parent exists and does not end with wildcard, use the parent as the starting element for search if check_parent and element_path . get_parent ( ) is not None and element_path . get_parent () . get_last () != ElementPath . WILDCARD : elm_at = self . get_at ( element_path . get_parent ()) if elm_at is None : raise TrestleNotFoundError ( f 'Invalid parent path { element_path . get_parent () } ' ) elm = elm_at # return the sub-element at the specified path for attr in path_parts : if elm is None : break # process for wildcard and array indexes if attr == ElementPath . WILDCARD : break elif attr . isnumeric (): if isinstance ( elm , list ): elm = elm [ int ( attr )] else : # index to a non list type should return None return None else : elm = elm . get_field_value_by_alias ( attr ) return elm","title":"get_at()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.Element.get_preceding_element","text":"Get the preceding element in the path. Source code in trestle/core/models/elements.py def get_preceding_element ( self , element_path : ElementPath ) -> Optional [ OscalBaseModel ]: \"\"\"Get the preceding element in the path.\"\"\" preceding_path = element_path . get_preceding_path () preceding_elm : Optional [ OscalBaseModel ] = self . get_at ( preceding_path ) return preceding_elm","title":"get_preceding_element()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.Element.get_sub_element_class","text":"Get the class of the sub-element. Source code in trestle/core/models/elements.py @classmethod def get_sub_element_class ( cls , parent_elm : OscalBaseModel , sub_element_name : str ): \"\"\"Get the class of the sub-element.\"\"\" sub_element_class = parent_elm . __fields__ [ sub_element_name ] . outer_type_ return sub_element_class","title":"get_sub_element_class()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.Element.is_allowed_sub_element_type","text":"Check if is of allowed sub element type. Source code in trestle/core/models/elements.py @classmethod def is_allowed_sub_element_type ( cls , elm ) -> bool : \"\"\"Check if is of allowed sub element type.\"\"\" # FIXME: The following logic does not use the _allowed_sub_element_types being defined for the class if ( isinstance ( elm , Element ) or isinstance ( elm , OscalBaseModel ) or isinstance ( elm , list ) or isinstance ( elm , dict ) or elm is None ): return True return False","title":"is_allowed_sub_element_type()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.Element.set_at","text":"Set a sub_element at the path in the current element. Sub element can be Element, OscalBaseModel, list or None type It returns the element itself so that chaining operation can be done such as element.set_at(path, sub-element).get() . Source code in trestle/core/models/elements.py def set_at ( self , element_path : ElementPath , sub_element : OscalBaseModel ) -> 'Element' : \"\"\"Set a sub_element at the path in the current element. Sub element can be Element, OscalBaseModel, list or None type It returns the element itself so that chaining operation can be done such as `element.set_at(path, sub-element).get()`. \"\"\" # convert the element_path to ElementPath if needed if isinstance ( element_path , str ): element_path = ElementPath ( element_path ) # convert sub-element to OscalBaseModel if needed model_obj = self . _get_sub_element_obj ( sub_element ) # find the root-model and element path parts _ , path_parts = self . _split_element_path ( element_path ) # TODO validate that self._elem is of same type as root_model # If wildcard is present, check the input type and determine the preceding element if element_path . get_last () == ElementPath . WILDCARD : # validate the type is either list or OscalBaseModel if not isinstance ( model_obj , list ) and not isinstance ( model_obj , OscalBaseModel ): raise TrestleError ( f 'The model object needs to be a List or OscalBaseModel for path with \" { ElementPath . WILDCARD } \"' ) # since wildcard * is there, we need to go one level up for preceding element in the path preceding_elm = self . get_preceding_element ( element_path . get_preceding_path ()) else : # get the preceding element in the path preceding_elm = self . get_preceding_element ( element_path ) if preceding_elm is None : raise TrestleError ( f 'Invalid sub element path { element_path } with no valid preceding element' ) # check if it can be a valid sub_element of the parent sub_element_name = element_path . get_element_name () . replace ( '-' , '_' ) if hasattr ( preceding_elm , sub_element_name ) is False : raise TrestleError ( f 'Element \" { preceding_elm . __class__ } \" does not have the attribute \" { sub_element_name } \" ' f 'of type \" { model_obj . __class__ } \"' ) # set the sub-element try : setattr ( preceding_elm , sub_element_name , model_obj ) except ValidationError : sub_element_class = self . get_sub_element_class ( preceding_elm , sub_element_name ) raise TrestleError ( f 'Validation error: { sub_element_name } is expected to be \" { sub_element_class } \", ' f 'but found \" { model_obj . __class__ } \"' ) # returning self will allow to do 'chaining' of commands after set return self","title":"set_at()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.Element.to_json","text":"Convert into JSON string. Source code in trestle/core/models/elements.py def to_json ( self , pretty : bool = True ) -> str : \"\"\"Convert into JSON string.\"\"\" if self . _wrapper_alias == self . IGNORE_WRAPPER_ALIAS : json_data = self . _elem . oscal_serialize_json ( pretty = pretty , wrapped = False ) else : # Note before trying to edit this # This transient model allows self._elem not be an OscalBaseModel (e.g. a DICT or LIST) # typing need to be clarified. if isinstance ( self . _elem , OscalBaseModel ): json_data = self . _elem . oscal_serialize_json ( pretty = pretty ) else : dynamic_passer = {} dynamic_passer [ 'TransientField' ] = ( self . _elem . __class__ , Field ( self , alias = self . _wrapper_alias )) wrapper_model = create_model ( 'TransientModel' , __base__ = OscalBaseModel , ** dynamic_passer ) # type: ignore wrapped_model = wrapper_model . construct ( ** { self . _wrapper_alias : self . _elem }) json_data = wrapped_model . oscal_serialize_json ( pretty = pretty , wrapped = False ) return json_data","title":"to_json()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.Element.to_yaml","text":"Convert into YAML string. Source code in trestle/core/models/elements.py def to_yaml ( self ) -> str : \"\"\"Convert into YAML string.\"\"\" yaml = YAML ( typ = 'safe' ) yaml . default_flow_style = False from io import StringIO string_stream = StringIO () yaml . dump ( yaml . load ( self . to_json ( pretty = False )), string_stream ) yaml_data = string_stream . getvalue () string_stream . close () return yaml_data","title":"to_yaml()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath","text":"Element path wrapper of an element. This only allows a single wildcard '*' at the end to denote elements of an array or dict Source code in trestle/core/models/elements.py class ElementPath : \"\"\"Element path wrapper of an element. This only allows a single wildcard '*' at the end to denote elements of an array or dict \"\"\" PATH_SEPARATOR : str = const . ALIAS_PATH_SEPARATOR WILDCARD : str = '*' def __init__ ( self , element_path : str , parent_path : Optional [ 'ElementPath' ] = None ) -> None : \"\"\"Initialize an element wrapper. It assumes the element path contains oscal field alias with hyphens only \"\"\" self . _parent_path = parent_path self . _path : List [ str ] = self . _parse ( element_path ) # Initialize private variables for lazy processing and caching self . _element_name : Optional [ str ] = None self . _preceding_path : Optional [ 'ElementPath' ] = None def _parse ( self , element_path : str ) -> List [ str ]: \"\"\"Parse the element path and validate.\"\"\" parts : List [ str ] = element_path . split ( self . PATH_SEPARATOR ) for part in parts : if part == '' : raise TrestleError ( f 'Invalid path \" { element_path } \" because there are empty path parts between \" { self . PATH_SEPARATOR } \" ' 'or in the beginning' ) if parts [ 0 ] == self . WILDCARD : raise TrestleError ( f 'Invalid path { element_path } with wildcard.' ) return parts def get ( self ) -> List [ str ]: \"\"\"Return the path parts as a list.\"\"\" return self . _path def get_type ( self , root_model : Optional [ Type [ Any ]] = None , use_parent : bool = False ) -> Type [ Any ]: \"\"\"Get the type of an element. If possible the model type will be derived from one of the top level models, otherwise a 'root model' can be passed for situations where this is not possible. This type path should *NOT* have wild cards in it. It *may* have* indices. Valid Examples: catalog.metadata catalog.groups catalog.groups.group catalog catalog.groups.0 Args: root_model: An OscalBaseModel Type from which to base the approach on. use_parent: Whether or not to normalise the full path across parent ElementPaths, default to not. Returns: The type of the model whether or not it is an OscalBaseModel or not. \"\"\" effective_path : List [ str ] if use_parent : effective_path = self . get_full_path_parts () else : effective_path = self . _path if not root_model : # lookup root model from top level oscal models or fail prev_model = self . _top_level_type_lookup ( effective_path [ 0 ]) else : prev_model = root_model if len ( effective_path ) == 1 : return prev_model # variables # for current_element_str in effective_path[1:]: for current_element_str in effective_path [ 1 :]: # Determine if the parent model is a collection. if utils . is_collection_field_type ( prev_model ): inner_model = utils . get_inner_type ( prev_model ) inner_class_name = classname_to_alias ( inner_model . __name__ , AliasMode . JSON ) # Assert that the current name fits an expected form. # Valid choices here are *, integer (for arrays) and the inner model alias if ( inner_class_name == current_element_str or current_element_str == self . WILDCARD or current_element_str . isnumeric ()): prev_model = inner_model else : raise TrestleError ( 'Unexpected key in element path when finding type.' ) else : # Indices, * are not allowed on non-collection types if current_element_str == self . WILDCARD : raise TrestleError ( 'Wild card in unexpected position when trying to find class type.' + ' Element path type lookup can only occur where a single type can be identified.' ) prev_model = prev_model . alias_to_field_map ()[ current_element_str ] . outer_type_ return prev_model def get_obm_wrapped_type ( self , root_model : Optional [ Type [ Any ]] = None , use_parent : bool = False ) -> Type [ OscalBaseModel ]: \"\"\"Get the type of the element. If the type is a collection wrap the type in an OscalBaseModel as a __root__ element. This should principally be used for validating content. Args: root_model: An OscalBaseModel Type from which to base the approach on. use_parent: Whether or not to normalise the full path across parent ElementPaths, default to not. Returns: The type of the model whether wrapped or not as an OscalBaseModel. \"\"\" base_type = self . get_type ( root_model , use_parent ) # Get an outer model type. origin_type = utils . get_origin ( base_type ) if origin_type in [ list , dict ]: # OSCAL does not support collections of collections directly. We should not hit this scenario collection_name = self . get_last () if collection_name == self . WILDCARD : logger . critical ( 'Unexpected error in type system when inferring type from element path.' ) logger . critical ( 'Please report this issue.' ) raise TrestleError ( 'Unknown error inferring type from element path.' ) # Final path must be the alias new_base_type = create_model ( str_utils . alias_to_classname ( collection_name , AliasMode . JSON ), __base__ = OscalBaseModel , __root__ = ( base_type , ... ) ) return new_base_type return base_type def _top_level_type_lookup ( self , element_str : str ) -> Type [ common_types . TopLevelOscalModel ]: \"\"\"From an individual element tag, induce the type of the model. Args: element_str: individual element as text such as 'catalog' or 'profile' Returns: Top level object model such as catalog, profile etc. \"\"\" # Even though awkward use chain of models. if element_str not in const . MODEL_TYPE_LIST : raise TrestleError ( f ' { element_str } is not a top level model (e.g. catalog, profile)' ) model_package = const . MODEL_TYPE_TO_MODEL_MODULE [ element_str ] object_type , _ = ModelUtils . get_root_model ( model_package ) object_type = cast ( Type [ common_types . TopLevelOscalModel ], object_type ) return object_type def is_multipart ( self ) -> bool : \"\"\"Assert whether or not an element path is multiple parts. Originally element paths had to have multiple paths. This provides a check for higher level code that still has that requirement. Single part: catalog control assessment-results Multipart: catalog.metadata catalog.controls.control \"\"\" return len ( self . _path ) > 1 def to_string ( self ) -> str : \"\"\"Return the path parts as a dot-separated string.\"\"\" return self . PATH_SEPARATOR . join ( self . get ()) def get_parent ( self ) -> 'ElementPath' : \"\"\"Return the parent path. It can be None or a valid ElementPath \"\"\" return self . _parent_path def get_first ( self ) -> str : \"\"\"Return the first part of the path.\"\"\" return self . _path [ 0 ] def get_last ( self ) -> str : \"\"\"Return the last part of the path.\"\"\" return self . _path [ - 1 ] def get_full ( self ) -> str : \"\"\"Return the full path including parent path parts as a dot separated str.\"\"\" all_parts = self . get_full_path_parts () return self . PATH_SEPARATOR . join ( all_parts ) def get_element_name ( self ) -> str : \"\"\"Return the element alias name from the path. Essentailly this the last part of the element path \"\"\" # if it is available then return otherwise compute if self . _element_name is None : element_name = self . get_last () if element_name == self . WILDCARD : element_name = self . _path [ - 2 ] self . _element_name = element_name return self . _element_name def get_full_path_parts ( self ) -> List [ str ]: \"\"\"Get full path parts to the element including parent path parts as a list.\"\"\" path_parts = [] if self . get_parent () is not None : parent_path_parts = self . get_parent () . get_full_path_parts () path_parts . extend ( parent_path_parts ) path_parts . extend ( self . get ()[ 1 :]) # don't use the first part else : path_parts . extend ( self . get ()) return path_parts def get_preceding_path ( self ) -> 'ElementPath' : \"\"\"Return the element path to the preceding element in the path.\"\"\" # if it is available then return otherwise compute if self . _preceding_path is None : path_parts = self . get_full_path_parts () if len ( path_parts ) > 1 : prec_path_parts = path_parts [: - 1 ] self . _preceding_path = ElementPath ( self . PATH_SEPARATOR . join ( prec_path_parts )) return self . _preceding_path def find_last_file_in_path ( self , content_type : FileContentType , model_dir : pathlib . Path ) -> pathlib . Path : \"\"\"Find the last (nearest) existing file in the element path leading to this element.\"\"\" # model dir is the top level dir for this model, e.g. catalogs/mycat path = model_dir extension = FileContentType . to_file_extension ( content_type ) good_model : pathlib . Path = None for element in self . _path : if element == '*' : break model_file = ( path / element ) . with_suffix ( extension ) if not model_file . exists (): break path = path / element good_model = model_file return good_model def make_absolute ( self , model_dir : pathlib . Path , reference_dir : pathlib . Path ): \"\"\"Make the parts absolute from the top model dir.\"\"\" # Match the current relative element path to the model directory and reference directory # If the element path is partial and doesn't connect to the top of the model, # need to deduce absolute element path from the model_dir and the reference directory # that corresponds to the root of the element path # if first element is a model type it is already absolute if self . _path [ 0 ] not in const . MODEL_TYPE_LIST : rel_path = list ( reference_dir . relative_to ( model_dir ) . parts ) rel_path . extend ( self . _path ) self . _path = rel_path def make_relative ( self , model_relative_path : pathlib . Path ) -> int : \"\"\"Make the parts relative to the model path.\"\"\" # The element path should currently be absolute # The model relative path should be relative to the top leve of the model # Change the element path to be relative to the model being loaded # Returns 0 on success and 1 on failur rel_path_parts = model_relative_path . parts [: - 1 ] n_rel_parts = len ( rel_path_parts ) # the element path can't start above the model path if n_rel_parts >= len ( self . _path ): return 1 # confirm the leading parts match for ii in range ( n_rel_parts ): if rel_path_parts [ ii ] != self . _path [ ii ]: return 1 # chop off the leading parts of the absolute element path self . _path = self . _path [ n_rel_parts :] return 0 def to_file_path ( self , content_type : FileContentType = None , root_dir : str = '' ) -> pathlib . Path : \"\"\"Convert to a file or directory path for the element path. if content_type is not passed, it will return a path for directory \"\"\" path_parts = self . get () # skip wildcard if path_parts [ - 1 ] == ElementPath . WILDCARD : path_parts = path_parts [: - 1 ] if root_dir != '' : path_parts [ 0 ] = root_dir path_str = '/' . join ( path_parts ) # add file extension if required # this will be omitted if it is a dir path if content_type is not None : file_extension = FileContentType . to_file_extension ( content_type ) path_str = path_str + file_extension # prepare the path file_path : pathlib . Path = pathlib . Path ( f './ { path_str } ' ) return file_path def to_root_path ( self , content_type : FileContentType = None ) -> pathlib . Path : \"\"\"Convert to a file path for the element root.\"\"\" path_str = f './ { self . get_first () } ' if content_type is not None : file_extension = FileContentType . to_file_extension ( content_type ) path_str = path_str + file_extension file_path : pathlib . Path = pathlib . Path ( path_str ) return file_path def __str__ ( self ) -> str : \"\"\"Return string representation of element path.\"\"\" return self . to_string () def __eq__ ( self , other ) -> bool : \"\"\"Override equality method.\"\"\" if not isinstance ( other , ElementPath ): return False return self . get () == other . get ()","title":"ElementPath"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.PATH_SEPARATOR","text":"","title":"PATH_SEPARATOR"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.WILDCARD","text":"","title":"WILDCARD"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.__eq__","text":"Override equality method. Source code in trestle/core/models/elements.py def __eq__ ( self , other ) -> bool : \"\"\"Override equality method.\"\"\" if not isinstance ( other , ElementPath ): return False return self . get () == other . get ()","title":"__eq__()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.__init__","text":"Initialize an element wrapper. It assumes the element path contains oscal field alias with hyphens only Source code in trestle/core/models/elements.py def __init__ ( self , element_path : str , parent_path : Optional [ 'ElementPath' ] = None ) -> None : \"\"\"Initialize an element wrapper. It assumes the element path contains oscal field alias with hyphens only \"\"\" self . _parent_path = parent_path self . _path : List [ str ] = self . _parse ( element_path ) # Initialize private variables for lazy processing and caching self . _element_name : Optional [ str ] = None self . _preceding_path : Optional [ 'ElementPath' ] = None","title":"__init__()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.__str__","text":"Return string representation of element path. Source code in trestle/core/models/elements.py def __str__ ( self ) -> str : \"\"\"Return string representation of element path.\"\"\" return self . to_string ()","title":"__str__()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.find_last_file_in_path","text":"Find the last (nearest) existing file in the element path leading to this element. Source code in trestle/core/models/elements.py def find_last_file_in_path ( self , content_type : FileContentType , model_dir : pathlib . Path ) -> pathlib . Path : \"\"\"Find the last (nearest) existing file in the element path leading to this element.\"\"\" # model dir is the top level dir for this model, e.g. catalogs/mycat path = model_dir extension = FileContentType . to_file_extension ( content_type ) good_model : pathlib . Path = None for element in self . _path : if element == '*' : break model_file = ( path / element ) . with_suffix ( extension ) if not model_file . exists (): break path = path / element good_model = model_file return good_model","title":"find_last_file_in_path()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.get","text":"Return the path parts as a list. Source code in trestle/core/models/elements.py def get ( self ) -> List [ str ]: \"\"\"Return the path parts as a list.\"\"\" return self . _path","title":"get()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.get_element_name","text":"Return the element alias name from the path. Essentailly this the last part of the element path Source code in trestle/core/models/elements.py def get_element_name ( self ) -> str : \"\"\"Return the element alias name from the path. Essentailly this the last part of the element path \"\"\" # if it is available then return otherwise compute if self . _element_name is None : element_name = self . get_last () if element_name == self . WILDCARD : element_name = self . _path [ - 2 ] self . _element_name = element_name return self . _element_name","title":"get_element_name()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.get_first","text":"Return the first part of the path. Source code in trestle/core/models/elements.py def get_first ( self ) -> str : \"\"\"Return the first part of the path.\"\"\" return self . _path [ 0 ]","title":"get_first()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.get_full","text":"Return the full path including parent path parts as a dot separated str. Source code in trestle/core/models/elements.py def get_full ( self ) -> str : \"\"\"Return the full path including parent path parts as a dot separated str.\"\"\" all_parts = self . get_full_path_parts () return self . PATH_SEPARATOR . join ( all_parts )","title":"get_full()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.get_full_path_parts","text":"Get full path parts to the element including parent path parts as a list. Source code in trestle/core/models/elements.py def get_full_path_parts ( self ) -> List [ str ]: \"\"\"Get full path parts to the element including parent path parts as a list.\"\"\" path_parts = [] if self . get_parent () is not None : parent_path_parts = self . get_parent () . get_full_path_parts () path_parts . extend ( parent_path_parts ) path_parts . extend ( self . get ()[ 1 :]) # don't use the first part else : path_parts . extend ( self . get ()) return path_parts","title":"get_full_path_parts()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.get_last","text":"Return the last part of the path. Source code in trestle/core/models/elements.py def get_last ( self ) -> str : \"\"\"Return the last part of the path.\"\"\" return self . _path [ - 1 ]","title":"get_last()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.get_obm_wrapped_type","text":"Get the type of the element. If the type is a collection wrap the type in an OscalBaseModel as a root element. This should principally be used for validating content. Parameters: Name Type Description Default root_model Optional[Type[Any]] An OscalBaseModel Type from which to base the approach on. None use_parent bool Whether or not to normalise the full path across parent ElementPaths, default to not. False Returns: Type Description Type[trestle.core.base_model.OscalBaseModel] The type of the model whether wrapped or not as an OscalBaseModel. Source code in trestle/core/models/elements.py def get_obm_wrapped_type ( self , root_model : Optional [ Type [ Any ]] = None , use_parent : bool = False ) -> Type [ OscalBaseModel ]: \"\"\"Get the type of the element. If the type is a collection wrap the type in an OscalBaseModel as a __root__ element. This should principally be used for validating content. Args: root_model: An OscalBaseModel Type from which to base the approach on. use_parent: Whether or not to normalise the full path across parent ElementPaths, default to not. Returns: The type of the model whether wrapped or not as an OscalBaseModel. \"\"\" base_type = self . get_type ( root_model , use_parent ) # Get an outer model type. origin_type = utils . get_origin ( base_type ) if origin_type in [ list , dict ]: # OSCAL does not support collections of collections directly. We should not hit this scenario collection_name = self . get_last () if collection_name == self . WILDCARD : logger . critical ( 'Unexpected error in type system when inferring type from element path.' ) logger . critical ( 'Please report this issue.' ) raise TrestleError ( 'Unknown error inferring type from element path.' ) # Final path must be the alias new_base_type = create_model ( str_utils . alias_to_classname ( collection_name , AliasMode . JSON ), __base__ = OscalBaseModel , __root__ = ( base_type , ... ) ) return new_base_type return base_type","title":"get_obm_wrapped_type()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.get_parent","text":"Return the parent path. It can be None or a valid ElementPath Source code in trestle/core/models/elements.py def get_parent ( self ) -> 'ElementPath' : \"\"\"Return the parent path. It can be None or a valid ElementPath \"\"\" return self . _parent_path","title":"get_parent()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.get_preceding_path","text":"Return the element path to the preceding element in the path. Source code in trestle/core/models/elements.py def get_preceding_path ( self ) -> 'ElementPath' : \"\"\"Return the element path to the preceding element in the path.\"\"\" # if it is available then return otherwise compute if self . _preceding_path is None : path_parts = self . get_full_path_parts () if len ( path_parts ) > 1 : prec_path_parts = path_parts [: - 1 ] self . _preceding_path = ElementPath ( self . PATH_SEPARATOR . join ( prec_path_parts )) return self . _preceding_path","title":"get_preceding_path()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.get_type","text":"Get the type of an element. If possible the model type will be derived from one of the top level models, otherwise a 'root model' can be passed for situations where this is not possible. This type path should NOT have wild cards in it. It may have* indices. Valid Examples: catalog.metadata catalog.groups catalog.groups.group catalog catalog.groups.0 Parameters: Name Type Description Default root_model Optional[Type[Any]] An OscalBaseModel Type from which to base the approach on. None use_parent bool Whether or not to normalise the full path across parent ElementPaths, default to not. False Returns: Type Description Type[Any] The type of the model whether or not it is an OscalBaseModel or not. Source code in trestle/core/models/elements.py def get_type ( self , root_model : Optional [ Type [ Any ]] = None , use_parent : bool = False ) -> Type [ Any ]: \"\"\"Get the type of an element. If possible the model type will be derived from one of the top level models, otherwise a 'root model' can be passed for situations where this is not possible. This type path should *NOT* have wild cards in it. It *may* have* indices. Valid Examples: catalog.metadata catalog.groups catalog.groups.group catalog catalog.groups.0 Args: root_model: An OscalBaseModel Type from which to base the approach on. use_parent: Whether or not to normalise the full path across parent ElementPaths, default to not. Returns: The type of the model whether or not it is an OscalBaseModel or not. \"\"\" effective_path : List [ str ] if use_parent : effective_path = self . get_full_path_parts () else : effective_path = self . _path if not root_model : # lookup root model from top level oscal models or fail prev_model = self . _top_level_type_lookup ( effective_path [ 0 ]) else : prev_model = root_model if len ( effective_path ) == 1 : return prev_model # variables # for current_element_str in effective_path[1:]: for current_element_str in effective_path [ 1 :]: # Determine if the parent model is a collection. if utils . is_collection_field_type ( prev_model ): inner_model = utils . get_inner_type ( prev_model ) inner_class_name = classname_to_alias ( inner_model . __name__ , AliasMode . JSON ) # Assert that the current name fits an expected form. # Valid choices here are *, integer (for arrays) and the inner model alias if ( inner_class_name == current_element_str or current_element_str == self . WILDCARD or current_element_str . isnumeric ()): prev_model = inner_model else : raise TrestleError ( 'Unexpected key in element path when finding type.' ) else : # Indices, * are not allowed on non-collection types if current_element_str == self . WILDCARD : raise TrestleError ( 'Wild card in unexpected position when trying to find class type.' + ' Element path type lookup can only occur where a single type can be identified.' ) prev_model = prev_model . alias_to_field_map ()[ current_element_str ] . outer_type_ return prev_model","title":"get_type()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.is_multipart","text":"Assert whether or not an element path is multiple parts. Originally element paths had to have multiple paths. This provides a check for higher level code that still has that requirement. Single part: catalog control assessment-results Multipart catalog.metadata catalog.controls.control Source code in trestle/core/models/elements.py def is_multipart ( self ) -> bool : \"\"\"Assert whether or not an element path is multiple parts. Originally element paths had to have multiple paths. This provides a check for higher level code that still has that requirement. Single part: catalog control assessment-results Multipart: catalog.metadata catalog.controls.control \"\"\" return len ( self . _path ) > 1","title":"is_multipart()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.make_absolute","text":"Make the parts absolute from the top model dir. Source code in trestle/core/models/elements.py def make_absolute ( self , model_dir : pathlib . Path , reference_dir : pathlib . Path ): \"\"\"Make the parts absolute from the top model dir.\"\"\" # Match the current relative element path to the model directory and reference directory # If the element path is partial and doesn't connect to the top of the model, # need to deduce absolute element path from the model_dir and the reference directory # that corresponds to the root of the element path # if first element is a model type it is already absolute if self . _path [ 0 ] not in const . MODEL_TYPE_LIST : rel_path = list ( reference_dir . relative_to ( model_dir ) . parts ) rel_path . extend ( self . _path ) self . _path = rel_path","title":"make_absolute()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.make_relative","text":"Make the parts relative to the model path. Source code in trestle/core/models/elements.py def make_relative ( self , model_relative_path : pathlib . Path ) -> int : \"\"\"Make the parts relative to the model path.\"\"\" # The element path should currently be absolute # The model relative path should be relative to the top leve of the model # Change the element path to be relative to the model being loaded # Returns 0 on success and 1 on failur rel_path_parts = model_relative_path . parts [: - 1 ] n_rel_parts = len ( rel_path_parts ) # the element path can't start above the model path if n_rel_parts >= len ( self . _path ): return 1 # confirm the leading parts match for ii in range ( n_rel_parts ): if rel_path_parts [ ii ] != self . _path [ ii ]: return 1 # chop off the leading parts of the absolute element path self . _path = self . _path [ n_rel_parts :] return 0","title":"make_relative()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.to_file_path","text":"Convert to a file or directory path for the element path. if content_type is not passed, it will return a path for directory Source code in trestle/core/models/elements.py def to_file_path ( self , content_type : FileContentType = None , root_dir : str = '' ) -> pathlib . Path : \"\"\"Convert to a file or directory path for the element path. if content_type is not passed, it will return a path for directory \"\"\" path_parts = self . get () # skip wildcard if path_parts [ - 1 ] == ElementPath . WILDCARD : path_parts = path_parts [: - 1 ] if root_dir != '' : path_parts [ 0 ] = root_dir path_str = '/' . join ( path_parts ) # add file extension if required # this will be omitted if it is a dir path if content_type is not None : file_extension = FileContentType . to_file_extension ( content_type ) path_str = path_str + file_extension # prepare the path file_path : pathlib . Path = pathlib . Path ( f './ { path_str } ' ) return file_path","title":"to_file_path()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.to_root_path","text":"Convert to a file path for the element root. Source code in trestle/core/models/elements.py def to_root_path ( self , content_type : FileContentType = None ) -> pathlib . Path : \"\"\"Convert to a file path for the element root.\"\"\" path_str = f './ { self . get_first () } ' if content_type is not None : file_extension = FileContentType . to_file_extension ( content_type ) path_str = path_str + file_extension file_path : pathlib . Path = pathlib . Path ( path_str ) return file_path","title":"to_root_path()"},{"location":"api_reference/trestle.core.models.elements/#trestle.core.models.elements.ElementPath.to_string","text":"Return the path parts as a dot-separated string. Source code in trestle/core/models/elements.py def to_string ( self ) -> str : \"\"\"Return the path parts as a dot-separated string.\"\"\" return self . PATH_SEPARATOR . join ( self . get ()) handler: python","title":"to_string()"},{"location":"api_reference/trestle.core.models.file_content_type/","text":"trestle.core.models.file_content_type \u00a4 Action wrapper of a command. Classes \u00a4 FileContentType ( Enum ) \u00a4 File Content type for read/write. Source code in trestle/core/models/file_content_type.py class FileContentType ( Enum ): \"\"\"File Content type for read/write.\"\"\" # JSON formatted content JSON = 1 # YAML formatted content YAML = 2 # No extension and possibly a DIR DIRLIKE = 3 # Type could not be determined UNKNOWN = 4 @classmethod def to_file_extension ( cls , content_type : 'FileContentType' ) -> str : \"\"\"Get file extension for the type, including the dot.\"\"\" if content_type == FileContentType . YAML : return '.yaml' if content_type == FileContentType . JSON : return '.json' raise TrestleError ( f 'Invalid file content type { content_type } ' ) @classmethod def to_content_type ( cls , file_extension : str ) -> 'FileContentType' : \"\"\"Get content type form file extension, including the dot.\"\"\" if file_extension == '.json' : return FileContentType . JSON if file_extension == '.yaml' or file_extension == '.yml' : return FileContentType . YAML if not file_extension : return FileContentType . DIRLIKE raise TrestleError ( f 'Unsupported file extension { file_extension } ' ) @classmethod def path_to_content_type ( cls , file_path : Path ) -> 'FileContentType' : \"\"\"Get content type from file path looking for extension.\"\"\" if file_path . with_suffix ( '.json' ) . exists (): return FileContentType . JSON if file_path . with_suffix ( '.yaml' ) . exists (): return FileContentType . YAML if file_path . with_suffix ( '.yml' ) . exists (): return FileContentType . YAML return FileContentType . UNKNOWN @classmethod def dir_to_content_type ( cls , dir_path : Path ) -> 'FileContentType' : \"\"\"Get content type by looking for json or yaml files in dir.\"\"\" files = dir_path . glob ( '*' ) for file in files : if file . is_file (): suffix = file . suffix if suffix == '.json' : return FileContentType . JSON if suffix in [ '.yaml' , '.yml' ]: return FileContentType . YAML return FileContentType . UNKNOWN @classmethod def path_to_file_extension ( cls , file_path : Path ) -> str : \"\"\"Get extension from file path looking for extension.\"\"\" if file_path . with_suffix ( '.json' ) . exists (): return '.json' if file_path . with_suffix ( '.yaml' ) . exists (): return '.yaml' if file_path . with_suffix ( '.yml' ) . exists (): return '.yml' return '' @classmethod def is_readable_file ( cls , content_type : 'FileContentType' ) -> bool : \"\"\"Is the file a type that can be read directly.\"\"\" return content_type == FileContentType . JSON or content_type == FileContentType . YAML DIRLIKE \u00a4 JSON \u00a4 UNKNOWN \u00a4 YAML \u00a4 handler: python","title":"file_content_type"},{"location":"api_reference/trestle.core.models.file_content_type/#trestle.core.models.file_content_type","text":"Action wrapper of a command.","title":"file_content_type"},{"location":"api_reference/trestle.core.models.file_content_type/#trestle.core.models.file_content_type-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.models.file_content_type/#trestle.core.models.file_content_type.FileContentType","text":"File Content type for read/write. Source code in trestle/core/models/file_content_type.py class FileContentType ( Enum ): \"\"\"File Content type for read/write.\"\"\" # JSON formatted content JSON = 1 # YAML formatted content YAML = 2 # No extension and possibly a DIR DIRLIKE = 3 # Type could not be determined UNKNOWN = 4 @classmethod def to_file_extension ( cls , content_type : 'FileContentType' ) -> str : \"\"\"Get file extension for the type, including the dot.\"\"\" if content_type == FileContentType . YAML : return '.yaml' if content_type == FileContentType . JSON : return '.json' raise TrestleError ( f 'Invalid file content type { content_type } ' ) @classmethod def to_content_type ( cls , file_extension : str ) -> 'FileContentType' : \"\"\"Get content type form file extension, including the dot.\"\"\" if file_extension == '.json' : return FileContentType . JSON if file_extension == '.yaml' or file_extension == '.yml' : return FileContentType . YAML if not file_extension : return FileContentType . DIRLIKE raise TrestleError ( f 'Unsupported file extension { file_extension } ' ) @classmethod def path_to_content_type ( cls , file_path : Path ) -> 'FileContentType' : \"\"\"Get content type from file path looking for extension.\"\"\" if file_path . with_suffix ( '.json' ) . exists (): return FileContentType . JSON if file_path . with_suffix ( '.yaml' ) . exists (): return FileContentType . YAML if file_path . with_suffix ( '.yml' ) . exists (): return FileContentType . YAML return FileContentType . UNKNOWN @classmethod def dir_to_content_type ( cls , dir_path : Path ) -> 'FileContentType' : \"\"\"Get content type by looking for json or yaml files in dir.\"\"\" files = dir_path . glob ( '*' ) for file in files : if file . is_file (): suffix = file . suffix if suffix == '.json' : return FileContentType . JSON if suffix in [ '.yaml' , '.yml' ]: return FileContentType . YAML return FileContentType . UNKNOWN @classmethod def path_to_file_extension ( cls , file_path : Path ) -> str : \"\"\"Get extension from file path looking for extension.\"\"\" if file_path . with_suffix ( '.json' ) . exists (): return '.json' if file_path . with_suffix ( '.yaml' ) . exists (): return '.yaml' if file_path . with_suffix ( '.yml' ) . exists (): return '.yml' return '' @classmethod def is_readable_file ( cls , content_type : 'FileContentType' ) -> bool : \"\"\"Is the file a type that can be read directly.\"\"\" return content_type == FileContentType . JSON or content_type == FileContentType . YAML","title":"FileContentType"},{"location":"api_reference/trestle.core.models.file_content_type/#trestle.core.models.file_content_type.FileContentType.DIRLIKE","text":"","title":"DIRLIKE"},{"location":"api_reference/trestle.core.models.file_content_type/#trestle.core.models.file_content_type.FileContentType.JSON","text":"","title":"JSON"},{"location":"api_reference/trestle.core.models.file_content_type/#trestle.core.models.file_content_type.FileContentType.UNKNOWN","text":"","title":"UNKNOWN"},{"location":"api_reference/trestle.core.models.file_content_type/#trestle.core.models.file_content_type.FileContentType.YAML","text":"handler: python","title":"YAML"},{"location":"api_reference/trestle.core.models.interfaces/","text":"trestle.core.models.interfaces \u00a4 Interfaces for use within other trestle functions defined as pydantic data models. Classes \u00a4 OSCALAssembly ( TrestleBaseModel ) pydantic-model \u00a4 Data model to represent an assembled set of OSCAL objects. Here the assembly represents the constraints as expected by the current OSCAL schema. At this point in time a 'flat' model has been chosen rather than an tree. Source code in trestle/core/models/interfaces.py class OSCALAssembly ( TrestleBaseModel ): \"\"\"Data model to represent an assembled set of OSCAL objects. Here the assembly represents the constraints as expected by the current OSCAL schema. At this point in time a 'flat' model has been chosen rather than an tree. \"\"\" poam : Optional [ o_poam . PlanOfActionAndMilestones ] = None sar : Optional [ o_ar . AssessmentResults ] = None sap : Optional [ o_ap . AssessmentPlan ] = None ssp : Optional [ o_ssp . SystemSecurityPlan ] = None profiles : Optional [ Dict [ str , o_profile . Profile ]] = None catalogs : Optional [ Dict [ str , o_catalog . Catalog ]] = None components : Optional [ Dict [ str , o_component . ComponentDefinition ]] = None class Config : \"\"\"Pydantic config overrides.\"\"\" allow_population_by_field_name = True # Enforce strict schema extra = Extra . forbid # Validate on assignment of variables to ensure no escapes validate_assignment = True catalogs : Dict [ str , trestle . oscal . catalog . Catalog ] pydantic-field \u00a4 components : Dict [ str , trestle . oscal . component . ComponentDefinition ] pydantic-field \u00a4 poam : PlanOfActionAndMilestones pydantic-field \u00a4 profiles : Dict [ str , trestle . oscal . profile . Profile ] pydantic-field \u00a4 sap : AssessmentPlan pydantic-field \u00a4 sar : AssessmentResults pydantic-field \u00a4 ssp : SystemSecurityPlan pydantic-field \u00a4 Classes \u00a4 Config \u00a4 Pydantic config overrides. Source code in trestle/core/models/interfaces.py class Config : \"\"\"Pydantic config overrides.\"\"\" allow_population_by_field_name = True # Enforce strict schema extra = Extra . forbid # Validate on assignment of variables to ensure no escapes validate_assignment = True allow_population_by_field_name \u00a4 extra \u00a4 validate_assignment \u00a4 handler: python","title":"interfaces"},{"location":"api_reference/trestle.core.models.interfaces/#trestle.core.models.interfaces","text":"Interfaces for use within other trestle functions defined as pydantic data models.","title":"interfaces"},{"location":"api_reference/trestle.core.models.interfaces/#trestle.core.models.interfaces-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.models.interfaces/#trestle.core.models.interfaces.OSCALAssembly","text":"Data model to represent an assembled set of OSCAL objects. Here the assembly represents the constraints as expected by the current OSCAL schema. At this point in time a 'flat' model has been chosen rather than an tree. Source code in trestle/core/models/interfaces.py class OSCALAssembly ( TrestleBaseModel ): \"\"\"Data model to represent an assembled set of OSCAL objects. Here the assembly represents the constraints as expected by the current OSCAL schema. At this point in time a 'flat' model has been chosen rather than an tree. \"\"\" poam : Optional [ o_poam . PlanOfActionAndMilestones ] = None sar : Optional [ o_ar . AssessmentResults ] = None sap : Optional [ o_ap . AssessmentPlan ] = None ssp : Optional [ o_ssp . SystemSecurityPlan ] = None profiles : Optional [ Dict [ str , o_profile . Profile ]] = None catalogs : Optional [ Dict [ str , o_catalog . Catalog ]] = None components : Optional [ Dict [ str , o_component . ComponentDefinition ]] = None class Config : \"\"\"Pydantic config overrides.\"\"\" allow_population_by_field_name = True # Enforce strict schema extra = Extra . forbid # Validate on assignment of variables to ensure no escapes validate_assignment = True","title":"OSCALAssembly"},{"location":"api_reference/trestle.core.models.interfaces/#trestle.core.models.interfaces.OSCALAssembly.catalogs","text":"","title":"catalogs"},{"location":"api_reference/trestle.core.models.interfaces/#trestle.core.models.interfaces.OSCALAssembly.components","text":"","title":"components"},{"location":"api_reference/trestle.core.models.interfaces/#trestle.core.models.interfaces.OSCALAssembly.poam","text":"","title":"poam"},{"location":"api_reference/trestle.core.models.interfaces/#trestle.core.models.interfaces.OSCALAssembly.profiles","text":"","title":"profiles"},{"location":"api_reference/trestle.core.models.interfaces/#trestle.core.models.interfaces.OSCALAssembly.sap","text":"","title":"sap"},{"location":"api_reference/trestle.core.models.interfaces/#trestle.core.models.interfaces.OSCALAssembly.sar","text":"","title":"sar"},{"location":"api_reference/trestle.core.models.interfaces/#trestle.core.models.interfaces.OSCALAssembly.ssp","text":"","title":"ssp"},{"location":"api_reference/trestle.core.models.interfaces/#trestle.core.models.interfaces.OSCALAssembly-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.models.interfaces/#trestle.core.models.interfaces.OSCALAssembly.Config","text":"Pydantic config overrides. Source code in trestle/core/models/interfaces.py class Config : \"\"\"Pydantic config overrides.\"\"\" allow_population_by_field_name = True # Enforce strict schema extra = Extra . forbid # Validate on assignment of variables to ensure no escapes validate_assignment = True allow_population_by_field_name \u00a4 extra \u00a4 validate_assignment \u00a4 handler: python","title":"Config"},{"location":"api_reference/trestle.core.models.plans/","text":"trestle.core.models.plans \u00a4 Plan of action of a command. logger \u00a4 Classes \u00a4 Plan \u00a4 Plan of action of a command. Source code in trestle/core/models/plans.py class Plan : \"\"\"Plan of action of a command.\"\"\" def __init__ ( self ) -> None : \"\"\"Initialize a plan.\"\"\" self . _actions : List [ Action ] = [] def _action_key ( self , action : Action ) -> int : return hash ( action ) def __str__ ( self ) -> str : \"\"\"Print the plan.\"\"\" list_actions = [] index = 1 for action in self . _actions : list_actions . append ( f ' { index } . { action } ' ) index = index + 1 list_str = ' \\n ' . join ( list_actions ) return list_str def get_actions ( self ) -> List [ Action ]: \"\"\"Get all actions.\"\"\" return self . _actions def add_action ( self , action : Action ) -> None : \"\"\"Add a new action.\"\"\" self . _actions . append ( action ) def add_actions ( self , actions : List [ Action ]) -> None : \"\"\"Add actions in order.\"\"\" self . _actions . extend ( actions ) def clear_actions ( self ) -> None : \"\"\"Clear all actions.\"\"\" self . _actions = [] def execute ( self ) -> None : \"\"\"Execute the actions in the plan.\"\"\" for action in self . _actions : try : action . execute () except Exception as e : logger . error ( f 'Failed to execute action { action } for the plan: { e } . Rolling back.' ) self . rollback () raise e def rollback ( self ) -> None : \"\"\"Rollback the actions in the plan.\"\"\" # execute in reverse order for action in reversed ( self . _actions ): if action . has_rollback () is False : raise UnsupportedOperation ( f ' { action . get_type () } does not support rollback' ) action . rollback () def __eq__ ( self , other : object ) -> bool : \"\"\"Check that two plans are equal.\"\"\" if not isinstance ( other , Plan ): return False return self . get_actions () == other . get_actions () Methods \u00a4 __eq__ ( self , other ) special \u00a4 Check that two plans are equal. Source code in trestle/core/models/plans.py def __eq__ ( self , other : object ) -> bool : \"\"\"Check that two plans are equal.\"\"\" if not isinstance ( other , Plan ): return False return self . get_actions () == other . get_actions () __init__ ( self ) special \u00a4 Initialize a plan. Source code in trestle/core/models/plans.py def __init__ ( self ) -> None : \"\"\"Initialize a plan.\"\"\" self . _actions : List [ Action ] = [] __str__ ( self ) special \u00a4 Print the plan. Source code in trestle/core/models/plans.py def __str__ ( self ) -> str : \"\"\"Print the plan.\"\"\" list_actions = [] index = 1 for action in self . _actions : list_actions . append ( f ' { index } . { action } ' ) index = index + 1 list_str = ' \\n ' . join ( list_actions ) return list_str add_action ( self , action ) \u00a4 Add a new action. Source code in trestle/core/models/plans.py def add_action ( self , action : Action ) -> None : \"\"\"Add a new action.\"\"\" self . _actions . append ( action ) add_actions ( self , actions ) \u00a4 Add actions in order. Source code in trestle/core/models/plans.py def add_actions ( self , actions : List [ Action ]) -> None : \"\"\"Add actions in order.\"\"\" self . _actions . extend ( actions ) clear_actions ( self ) \u00a4 Clear all actions. Source code in trestle/core/models/plans.py def clear_actions ( self ) -> None : \"\"\"Clear all actions.\"\"\" self . _actions = [] execute ( self ) \u00a4 Execute the actions in the plan. Source code in trestle/core/models/plans.py def execute ( self ) -> None : \"\"\"Execute the actions in the plan.\"\"\" for action in self . _actions : try : action . execute () except Exception as e : logger . error ( f 'Failed to execute action { action } for the plan: { e } . Rolling back.' ) self . rollback () raise e get_actions ( self ) \u00a4 Get all actions. Source code in trestle/core/models/plans.py def get_actions ( self ) -> List [ Action ]: \"\"\"Get all actions.\"\"\" return self . _actions rollback ( self ) \u00a4 Rollback the actions in the plan. Source code in trestle/core/models/plans.py def rollback ( self ) -> None : \"\"\"Rollback the actions in the plan.\"\"\" # execute in reverse order for action in reversed ( self . _actions ): if action . has_rollback () is False : raise UnsupportedOperation ( f ' { action . get_type () } does not support rollback' ) action . rollback () handler: python","title":"plans"},{"location":"api_reference/trestle.core.models.plans/#trestle.core.models.plans","text":"Plan of action of a command.","title":"plans"},{"location":"api_reference/trestle.core.models.plans/#trestle.core.models.plans.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.models.plans/#trestle.core.models.plans-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.models.plans/#trestle.core.models.plans.Plan","text":"Plan of action of a command. Source code in trestle/core/models/plans.py class Plan : \"\"\"Plan of action of a command.\"\"\" def __init__ ( self ) -> None : \"\"\"Initialize a plan.\"\"\" self . _actions : List [ Action ] = [] def _action_key ( self , action : Action ) -> int : return hash ( action ) def __str__ ( self ) -> str : \"\"\"Print the plan.\"\"\" list_actions = [] index = 1 for action in self . _actions : list_actions . append ( f ' { index } . { action } ' ) index = index + 1 list_str = ' \\n ' . join ( list_actions ) return list_str def get_actions ( self ) -> List [ Action ]: \"\"\"Get all actions.\"\"\" return self . _actions def add_action ( self , action : Action ) -> None : \"\"\"Add a new action.\"\"\" self . _actions . append ( action ) def add_actions ( self , actions : List [ Action ]) -> None : \"\"\"Add actions in order.\"\"\" self . _actions . extend ( actions ) def clear_actions ( self ) -> None : \"\"\"Clear all actions.\"\"\" self . _actions = [] def execute ( self ) -> None : \"\"\"Execute the actions in the plan.\"\"\" for action in self . _actions : try : action . execute () except Exception as e : logger . error ( f 'Failed to execute action { action } for the plan: { e } . Rolling back.' ) self . rollback () raise e def rollback ( self ) -> None : \"\"\"Rollback the actions in the plan.\"\"\" # execute in reverse order for action in reversed ( self . _actions ): if action . has_rollback () is False : raise UnsupportedOperation ( f ' { action . get_type () } does not support rollback' ) action . rollback () def __eq__ ( self , other : object ) -> bool : \"\"\"Check that two plans are equal.\"\"\" if not isinstance ( other , Plan ): return False return self . get_actions () == other . get_actions ()","title":"Plan"},{"location":"api_reference/trestle.core.models.plans/#trestle.core.models.plans.Plan-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.models.plans/#trestle.core.models.plans.Plan.__eq__","text":"Check that two plans are equal. Source code in trestle/core/models/plans.py def __eq__ ( self , other : object ) -> bool : \"\"\"Check that two plans are equal.\"\"\" if not isinstance ( other , Plan ): return False return self . get_actions () == other . get_actions ()","title":"__eq__()"},{"location":"api_reference/trestle.core.models.plans/#trestle.core.models.plans.Plan.__init__","text":"Initialize a plan. Source code in trestle/core/models/plans.py def __init__ ( self ) -> None : \"\"\"Initialize a plan.\"\"\" self . _actions : List [ Action ] = []","title":"__init__()"},{"location":"api_reference/trestle.core.models.plans/#trestle.core.models.plans.Plan.__str__","text":"Print the plan. Source code in trestle/core/models/plans.py def __str__ ( self ) -> str : \"\"\"Print the plan.\"\"\" list_actions = [] index = 1 for action in self . _actions : list_actions . append ( f ' { index } . { action } ' ) index = index + 1 list_str = ' \\n ' . join ( list_actions ) return list_str","title":"__str__()"},{"location":"api_reference/trestle.core.models.plans/#trestle.core.models.plans.Plan.add_action","text":"Add a new action. Source code in trestle/core/models/plans.py def add_action ( self , action : Action ) -> None : \"\"\"Add a new action.\"\"\" self . _actions . append ( action )","title":"add_action()"},{"location":"api_reference/trestle.core.models.plans/#trestle.core.models.plans.Plan.add_actions","text":"Add actions in order. Source code in trestle/core/models/plans.py def add_actions ( self , actions : List [ Action ]) -> None : \"\"\"Add actions in order.\"\"\" self . _actions . extend ( actions )","title":"add_actions()"},{"location":"api_reference/trestle.core.models.plans/#trestle.core.models.plans.Plan.clear_actions","text":"Clear all actions. Source code in trestle/core/models/plans.py def clear_actions ( self ) -> None : \"\"\"Clear all actions.\"\"\" self . _actions = []","title":"clear_actions()"},{"location":"api_reference/trestle.core.models.plans/#trestle.core.models.plans.Plan.execute","text":"Execute the actions in the plan. Source code in trestle/core/models/plans.py def execute ( self ) -> None : \"\"\"Execute the actions in the plan.\"\"\" for action in self . _actions : try : action . execute () except Exception as e : logger . error ( f 'Failed to execute action { action } for the plan: { e } . Rolling back.' ) self . rollback () raise e","title":"execute()"},{"location":"api_reference/trestle.core.models.plans/#trestle.core.models.plans.Plan.get_actions","text":"Get all actions. Source code in trestle/core/models/plans.py def get_actions ( self ) -> List [ Action ]: \"\"\"Get all actions.\"\"\" return self . _actions","title":"get_actions()"},{"location":"api_reference/trestle.core.models.plans/#trestle.core.models.plans.Plan.rollback","text":"Rollback the actions in the plan. Source code in trestle/core/models/plans.py def rollback ( self ) -> None : \"\"\"Rollback the actions in the plan.\"\"\" # execute in reverse order for action in reversed ( self . _actions ): if action . has_rollback () is False : raise UnsupportedOperation ( f ' { action . get_type () } does not support rollback' ) action . rollback () handler: python","title":"rollback()"},{"location":"api_reference/trestle.core.object_factory/","text":"trestle.core.object_factory \u00a4 Generic object factory. Classes \u00a4 ObjectFactory \u00a4 Allow registration and creation of factory objects. Source code in trestle/core/object_factory.py class ObjectFactory : \"\"\"Allow registration and creation of factory objects.\"\"\" def __init__ ( self ) -> None : \"\"\"Initialize the objects dictionary as empty.\"\"\" self . _objects : Dict [ str , Any ] = {} def register_object ( self , mode : str , obj : Any ) -> None : \"\"\"Register an object to the object factory. Args: mode: Descriptive key for the mode / type of object to be retrieved. obj: The object type to be registered. \"\"\" self . _objects [ mode ] = obj def get ( self , args : argparse . Namespace ) -> Any : \"\"\"Create the object from the args.\"\"\" return self . _objects . get ( args . mode ) def get_all ( self ) -> ValuesView [ Any ]: \"\"\"Get all registered objects.\"\"\" return self . _objects . values () Methods \u00a4 __init__ ( self ) special \u00a4 Initialize the objects dictionary as empty. Source code in trestle/core/object_factory.py def __init__ ( self ) -> None : \"\"\"Initialize the objects dictionary as empty.\"\"\" self . _objects : Dict [ str , Any ] = {} get ( self , args ) \u00a4 Create the object from the args. Source code in trestle/core/object_factory.py def get ( self , args : argparse . Namespace ) -> Any : \"\"\"Create the object from the args.\"\"\" return self . _objects . get ( args . mode ) get_all ( self ) \u00a4 Get all registered objects. Source code in trestle/core/object_factory.py def get_all ( self ) -> ValuesView [ Any ]: \"\"\"Get all registered objects.\"\"\" return self . _objects . values () register_object ( self , mode , obj ) \u00a4 Register an object to the object factory. Parameters: Name Type Description Default mode str Descriptive key for the mode / type of object to be retrieved. required obj Any The object type to be registered. required Source code in trestle/core/object_factory.py def register_object ( self , mode : str , obj : Any ) -> None : \"\"\"Register an object to the object factory. Args: mode: Descriptive key for the mode / type of object to be retrieved. obj: The object type to be registered. \"\"\" self . _objects [ mode ] = obj handler: python","title":"object_factory"},{"location":"api_reference/trestle.core.object_factory/#trestle.core.object_factory","text":"Generic object factory.","title":"object_factory"},{"location":"api_reference/trestle.core.object_factory/#trestle.core.object_factory-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.object_factory/#trestle.core.object_factory.ObjectFactory","text":"Allow registration and creation of factory objects. Source code in trestle/core/object_factory.py class ObjectFactory : \"\"\"Allow registration and creation of factory objects.\"\"\" def __init__ ( self ) -> None : \"\"\"Initialize the objects dictionary as empty.\"\"\" self . _objects : Dict [ str , Any ] = {} def register_object ( self , mode : str , obj : Any ) -> None : \"\"\"Register an object to the object factory. Args: mode: Descriptive key for the mode / type of object to be retrieved. obj: The object type to be registered. \"\"\" self . _objects [ mode ] = obj def get ( self , args : argparse . Namespace ) -> Any : \"\"\"Create the object from the args.\"\"\" return self . _objects . get ( args . mode ) def get_all ( self ) -> ValuesView [ Any ]: \"\"\"Get all registered objects.\"\"\" return self . _objects . values ()","title":"ObjectFactory"},{"location":"api_reference/trestle.core.object_factory/#trestle.core.object_factory.ObjectFactory-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.object_factory/#trestle.core.object_factory.ObjectFactory.__init__","text":"Initialize the objects dictionary as empty. Source code in trestle/core/object_factory.py def __init__ ( self ) -> None : \"\"\"Initialize the objects dictionary as empty.\"\"\" self . _objects : Dict [ str , Any ] = {}","title":"__init__()"},{"location":"api_reference/trestle.core.object_factory/#trestle.core.object_factory.ObjectFactory.get","text":"Create the object from the args. Source code in trestle/core/object_factory.py def get ( self , args : argparse . Namespace ) -> Any : \"\"\"Create the object from the args.\"\"\" return self . _objects . get ( args . mode )","title":"get()"},{"location":"api_reference/trestle.core.object_factory/#trestle.core.object_factory.ObjectFactory.get_all","text":"Get all registered objects. Source code in trestle/core/object_factory.py def get_all ( self ) -> ValuesView [ Any ]: \"\"\"Get all registered objects.\"\"\" return self . _objects . values ()","title":"get_all()"},{"location":"api_reference/trestle.core.object_factory/#trestle.core.object_factory.ObjectFactory.register_object","text":"Register an object to the object factory. Parameters: Name Type Description Default mode str Descriptive key for the mode / type of object to be retrieved. required obj Any The object type to be registered. required Source code in trestle/core/object_factory.py def register_object ( self , mode : str , obj : Any ) -> None : \"\"\"Register an object to the object factory. Args: mode: Descriptive key for the mode / type of object to be retrieved. obj: The object type to be registered. \"\"\" self . _objects [ mode ] = obj handler: python","title":"register_object()"},{"location":"api_reference/trestle.core.parser/","text":"trestle.core.parser \u00a4 Model parsing for use when models themselves must be inferred and are not known. Under most use cases trestle.core.base_model.OscalBaseModel provides functionality for loading Oscal models from files. However, under some circumstances the model internals are unknown. Use of this module should be avoided unless the BaseModel functionality is inadequate. logger \u00a4 Functions \u00a4 parse_dict ( data , model_name ) \u00a4 Load a model from the data dict. This functionality is provided for situations when the OSCAL data type is not known ahead of time. Here the model has been loaded into memory using json loads or similar and passed as a dict. Parameters: Name Type Description Default data Dict[str, Any] Oscal data loaded into memory as a dictionary with the root key removed. required model_name str should be of the form 'module.class' from trestle.oscal.* modules required Returns: Type Description OscalBaseModel The oscal model of the desired model. Source code in trestle/core/parser.py def parse_dict ( data : Dict [ str , Any ], model_name : str ) -> OscalBaseModel : \"\"\"Load a model from the data dict. This functionality is provided for situations when the OSCAL data type is not known ahead of time. Here the model has been loaded into memory using json loads or similar and passed as a dict. Args: data: Oscal data loaded into memory as a dictionary with the `root key` removed. model_name: should be of the form 'module.class' from trestle.oscal.* modules Returns: The oscal model of the desired model. \"\"\" if data is None : raise TrestleError ( 'data name is required' ) if model_name is None : raise TrestleError ( 'model_name is required' ) parts = model_name . split ( '.' ) class_name = parts . pop () module_name = '.' . join ( parts ) logger . debug ( f 'Loading class \" { class_name } \" from \" { module_name } \"' ) module = importlib . import_module ( module_name ) mclass : OscalBaseModel = getattr ( module , class_name ) if mclass is None : raise TrestleError ( f 'class \" { class_name } \" could not be found in \" { module_name } \"' ) instance = mclass . parse_obj ( data ) return instance root_key ( data ) \u00a4 Find root model name in the data. Source code in trestle/core/parser.py def root_key ( data : Dict [ str , Any ]) -> str : \"\"\"Find root model name in the data.\"\"\" if len ( data . items ()) == 1 : return next ( iter ( data )) raise TrestleError ( 'data does not contain a root key' ) to_full_model_name ( root_key ) \u00a4 Find model name from the root_key in the file. Parameters: Name Type Description Default root_key str root key such as 'system-security-plan' from a top level OSCAL model. required Source code in trestle/core/parser.py def to_full_model_name ( root_key : str ) -> str : \"\"\" Find model name from the root_key in the file. Args: root_key: root key such as 'system-security-plan' from a top level OSCAL model. \"\"\" if root_key not in const . MODEL_TYPE_LIST : raise TrestleError ( f ' { root_key } is not a top level model name.' ) module = const . MODEL_TYPE_TO_MODEL_MODULE [ root_key ] class_name = alias_to_classname ( root_key , AliasMode . JSON ) return f ' { module } . { class_name } ' handler: python","title":"parser"},{"location":"api_reference/trestle.core.parser/#trestle.core.parser","text":"Model parsing for use when models themselves must be inferred and are not known. Under most use cases trestle.core.base_model.OscalBaseModel provides functionality for loading Oscal models from files. However, under some circumstances the model internals are unknown. Use of this module should be avoided unless the BaseModel functionality is inadequate.","title":"parser"},{"location":"api_reference/trestle.core.parser/#trestle.core.parser.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.parser/#trestle.core.parser-functions","text":"","title":"Functions"},{"location":"api_reference/trestle.core.parser/#trestle.core.parser.parse_dict","text":"Load a model from the data dict. This functionality is provided for situations when the OSCAL data type is not known ahead of time. Here the model has been loaded into memory using json loads or similar and passed as a dict. Parameters: Name Type Description Default data Dict[str, Any] Oscal data loaded into memory as a dictionary with the root key removed. required model_name str should be of the form 'module.class' from trestle.oscal.* modules required Returns: Type Description OscalBaseModel The oscal model of the desired model. Source code in trestle/core/parser.py def parse_dict ( data : Dict [ str , Any ], model_name : str ) -> OscalBaseModel : \"\"\"Load a model from the data dict. This functionality is provided for situations when the OSCAL data type is not known ahead of time. Here the model has been loaded into memory using json loads or similar and passed as a dict. Args: data: Oscal data loaded into memory as a dictionary with the `root key` removed. model_name: should be of the form 'module.class' from trestle.oscal.* modules Returns: The oscal model of the desired model. \"\"\" if data is None : raise TrestleError ( 'data name is required' ) if model_name is None : raise TrestleError ( 'model_name is required' ) parts = model_name . split ( '.' ) class_name = parts . pop () module_name = '.' . join ( parts ) logger . debug ( f 'Loading class \" { class_name } \" from \" { module_name } \"' ) module = importlib . import_module ( module_name ) mclass : OscalBaseModel = getattr ( module , class_name ) if mclass is None : raise TrestleError ( f 'class \" { class_name } \" could not be found in \" { module_name } \"' ) instance = mclass . parse_obj ( data ) return instance","title":"parse_dict()"},{"location":"api_reference/trestle.core.parser/#trestle.core.parser.root_key","text":"Find root model name in the data. Source code in trestle/core/parser.py def root_key ( data : Dict [ str , Any ]) -> str : \"\"\"Find root model name in the data.\"\"\" if len ( data . items ()) == 1 : return next ( iter ( data )) raise TrestleError ( 'data does not contain a root key' )","title":"root_key()"},{"location":"api_reference/trestle.core.parser/#trestle.core.parser.to_full_model_name","text":"Find model name from the root_key in the file. Parameters: Name Type Description Default root_key str root key such as 'system-security-plan' from a top level OSCAL model. required Source code in trestle/core/parser.py def to_full_model_name ( root_key : str ) -> str : \"\"\" Find model name from the root_key in the file. Args: root_key: root key such as 'system-security-plan' from a top level OSCAL model. \"\"\" if root_key not in const . MODEL_TYPE_LIST : raise TrestleError ( f ' { root_key } is not a top level model name.' ) module = const . MODEL_TYPE_TO_MODEL_MODULE [ root_key ] class_name = alias_to_classname ( root_key , AliasMode . JSON ) return f ' { module } . { class_name } ' handler: python","title":"to_full_model_name()"},{"location":"api_reference/trestle.core.pipeline/","text":"trestle.core.pipeline \u00a4 Abstract base class for pipelines and filters. Classes \u00a4 Pipeline \u00a4 Pipeline base class. Source code in trestle/core/pipeline.py class Pipeline (): \"\"\"Pipeline base class.\"\"\" class Filter ( ABC ): \"\"\"Filter class used by pipeline.\"\"\" @abstractclassmethod def process ( self , input_ : Any ) -> Any : \"\"\"Process the input to output.\"\"\" return input_ def __init__ ( self , filters : List [ Filter ]) -> None : \"\"\"Initialize the class.\"\"\" self . _filters = filters def process ( self , input_ : Any ) -> Any : \"\"\"Process the filter pipeline.\"\"\" for filter_ in self . _filters : input_ = filter_ . process ( input_ ) return input_ Classes \u00a4 Filter ( ABC ) \u00a4 Filter class used by pipeline. Source code in trestle/core/pipeline.py class Filter ( ABC ): \"\"\"Filter class used by pipeline.\"\"\" @abstractclassmethod def process ( self , input_ : Any ) -> Any : \"\"\"Process the input to output.\"\"\" return input_ Methods \u00a4 process ( input_ ) classmethod \u00a4 Process the input to output. Source code in trestle/core/pipeline.py @abstractclassmethod def process ( self , input_ : Any ) -> Any : \"\"\"Process the input to output.\"\"\" return input_ Methods \u00a4 __init__ ( self , filters ) special \u00a4 Initialize the class. Source code in trestle/core/pipeline.py def __init__ ( self , filters : List [ Filter ]) -> None : \"\"\"Initialize the class.\"\"\" self . _filters = filters process ( self , input_ ) \u00a4 Process the filter pipeline. Source code in trestle/core/pipeline.py def process ( self , input_ : Any ) -> Any : \"\"\"Process the filter pipeline.\"\"\" for filter_ in self . _filters : input_ = filter_ . process ( input_ ) return input_ handler: python","title":"pipeline"},{"location":"api_reference/trestle.core.pipeline/#trestle.core.pipeline","text":"Abstract base class for pipelines and filters.","title":"pipeline"},{"location":"api_reference/trestle.core.pipeline/#trestle.core.pipeline-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.pipeline/#trestle.core.pipeline.Pipeline","text":"Pipeline base class. Source code in trestle/core/pipeline.py class Pipeline (): \"\"\"Pipeline base class.\"\"\" class Filter ( ABC ): \"\"\"Filter class used by pipeline.\"\"\" @abstractclassmethod def process ( self , input_ : Any ) -> Any : \"\"\"Process the input to output.\"\"\" return input_ def __init__ ( self , filters : List [ Filter ]) -> None : \"\"\"Initialize the class.\"\"\" self . _filters = filters def process ( self , input_ : Any ) -> Any : \"\"\"Process the filter pipeline.\"\"\" for filter_ in self . _filters : input_ = filter_ . process ( input_ ) return input_","title":"Pipeline"},{"location":"api_reference/trestle.core.pipeline/#trestle.core.pipeline.Pipeline-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.pipeline/#trestle.core.pipeline.Pipeline.Filter","text":"Filter class used by pipeline. Source code in trestle/core/pipeline.py class Filter ( ABC ): \"\"\"Filter class used by pipeline.\"\"\" @abstractclassmethod def process ( self , input_ : Any ) -> Any : \"\"\"Process the input to output.\"\"\" return input_ Methods \u00a4 process ( input_ ) classmethod \u00a4 Process the input to output. Source code in trestle/core/pipeline.py @abstractclassmethod def process ( self , input_ : Any ) -> Any : \"\"\"Process the input to output.\"\"\" return input_","title":"Filter"},{"location":"api_reference/trestle.core.pipeline/#trestle.core.pipeline.Pipeline-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.pipeline/#trestle.core.pipeline.Pipeline.__init__","text":"Initialize the class. Source code in trestle/core/pipeline.py def __init__ ( self , filters : List [ Filter ]) -> None : \"\"\"Initialize the class.\"\"\" self . _filters = filters","title":"__init__()"},{"location":"api_reference/trestle.core.pipeline/#trestle.core.pipeline.Pipeline.process","text":"Process the filter pipeline. Source code in trestle/core/pipeline.py def process ( self , input_ : Any ) -> Any : \"\"\"Process the filter pipeline.\"\"\" for filter_ in self . _filters : input_ = filter_ . process ( input_ ) return input_ handler: python","title":"process()"},{"location":"api_reference/trestle.core.profile_resolver/","text":"trestle.core.profile_resolver \u00a4 Create resolved catalog from profile. logger \u00a4 Classes \u00a4 ProfileResolver \u00a4 Class to resolve a catalog given a profile. Source code in trestle/core/profile_resolver.py class ProfileResolver (): \"\"\"Class to resolve a catalog given a profile.\"\"\" @staticmethod def get_resolved_profile_catalog ( trestle_root : pathlib . Path , profile_path : pathlib . Path , block_adds : bool = False , block_params : bool = False , params_format : Optional [ str ] = None , param_rep : ParameterRep = ParameterRep . VALUE_OR_LABEL_OR_CHOICES ) -> cat . Catalog : \"\"\" Create the resolved profile catalog given a profile path. Args: trestle_root: root directory of the trestle project profile_path: path of the profile being resolved block_adds: prevent the application of adds in the final profile block_params: prevent the application of setparams in the final profile params_format: optional pattern with dot to wrap the param string, where dot represents the param string param_rep: desired way to convert params to strings Returns: The resolved profile catalog \"\"\" logger . debug ( f 'get resolved profile catalog for { profile_path } via generated Import.' ) import_ = prof . Import ( href = str ( profile_path ), include_all = {}) # The final Import has change_prose=True to force parameter substitution in the prose only at the last stage. import_filter = Import ( trestle_root , import_ , True , block_adds , block_params , params_format , param_rep ) logger . debug ( 'launch pipeline' ) result = next ( import_filter . process ()) return result Methods \u00a4 get_resolved_profile_catalog ( trestle_root , profile_path , block_adds = False , block_params = False , params_format = None , param_rep =< ParameterRep . VALUE_OR_LABEL_OR_CHOICES : 3 > ) staticmethod \u00a4 Create the resolved profile catalog given a profile path. Parameters: Name Type Description Default trestle_root Path root directory of the trestle project required profile_path Path path of the profile being resolved required block_adds bool prevent the application of adds in the final profile False block_params bool prevent the application of setparams in the final profile False params_format Optional[str] optional pattern with dot to wrap the param string, where dot represents the param string None param_rep ParameterRep desired way to convert params to strings <ParameterRep.VALUE_OR_LABEL_OR_CHOICES: 3> Returns: Type Description Catalog The resolved profile catalog Source code in trestle/core/profile_resolver.py @staticmethod def get_resolved_profile_catalog ( trestle_root : pathlib . Path , profile_path : pathlib . Path , block_adds : bool = False , block_params : bool = False , params_format : Optional [ str ] = None , param_rep : ParameterRep = ParameterRep . VALUE_OR_LABEL_OR_CHOICES ) -> cat . Catalog : \"\"\" Create the resolved profile catalog given a profile path. Args: trestle_root: root directory of the trestle project profile_path: path of the profile being resolved block_adds: prevent the application of adds in the final profile block_params: prevent the application of setparams in the final profile params_format: optional pattern with dot to wrap the param string, where dot represents the param string param_rep: desired way to convert params to strings Returns: The resolved profile catalog \"\"\" logger . debug ( f 'get resolved profile catalog for { profile_path } via generated Import.' ) import_ = prof . Import ( href = str ( profile_path ), include_all = {}) # The final Import has change_prose=True to force parameter substitution in the prose only at the last stage. import_filter = Import ( trestle_root , import_ , True , block_adds , block_params , params_format , param_rep ) logger . debug ( 'launch pipeline' ) result = next ( import_filter . process ()) return result handler: python","title":"profile_resolver"},{"location":"api_reference/trestle.core.profile_resolver/#trestle.core.profile_resolver","text":"Create resolved catalog from profile.","title":"profile_resolver"},{"location":"api_reference/trestle.core.profile_resolver/#trestle.core.profile_resolver.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.profile_resolver/#trestle.core.profile_resolver-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.profile_resolver/#trestle.core.profile_resolver.ProfileResolver","text":"Class to resolve a catalog given a profile. Source code in trestle/core/profile_resolver.py class ProfileResolver (): \"\"\"Class to resolve a catalog given a profile.\"\"\" @staticmethod def get_resolved_profile_catalog ( trestle_root : pathlib . Path , profile_path : pathlib . Path , block_adds : bool = False , block_params : bool = False , params_format : Optional [ str ] = None , param_rep : ParameterRep = ParameterRep . VALUE_OR_LABEL_OR_CHOICES ) -> cat . Catalog : \"\"\" Create the resolved profile catalog given a profile path. Args: trestle_root: root directory of the trestle project profile_path: path of the profile being resolved block_adds: prevent the application of adds in the final profile block_params: prevent the application of setparams in the final profile params_format: optional pattern with dot to wrap the param string, where dot represents the param string param_rep: desired way to convert params to strings Returns: The resolved profile catalog \"\"\" logger . debug ( f 'get resolved profile catalog for { profile_path } via generated Import.' ) import_ = prof . Import ( href = str ( profile_path ), include_all = {}) # The final Import has change_prose=True to force parameter substitution in the prose only at the last stage. import_filter = Import ( trestle_root , import_ , True , block_adds , block_params , params_format , param_rep ) logger . debug ( 'launch pipeline' ) result = next ( import_filter . process ()) return result","title":"ProfileResolver"},{"location":"api_reference/trestle.core.profile_resolver/#trestle.core.profile_resolver.ProfileResolver-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.profile_resolver/#trestle.core.profile_resolver.ProfileResolver.get_resolved_profile_catalog","text":"Create the resolved profile catalog given a profile path. Parameters: Name Type Description Default trestle_root Path root directory of the trestle project required profile_path Path path of the profile being resolved required block_adds bool prevent the application of adds in the final profile False block_params bool prevent the application of setparams in the final profile False params_format Optional[str] optional pattern with dot to wrap the param string, where dot represents the param string None param_rep ParameterRep desired way to convert params to strings <ParameterRep.VALUE_OR_LABEL_OR_CHOICES: 3> Returns: Type Description Catalog The resolved profile catalog Source code in trestle/core/profile_resolver.py @staticmethod def get_resolved_profile_catalog ( trestle_root : pathlib . Path , profile_path : pathlib . Path , block_adds : bool = False , block_params : bool = False , params_format : Optional [ str ] = None , param_rep : ParameterRep = ParameterRep . VALUE_OR_LABEL_OR_CHOICES ) -> cat . Catalog : \"\"\" Create the resolved profile catalog given a profile path. Args: trestle_root: root directory of the trestle project profile_path: path of the profile being resolved block_adds: prevent the application of adds in the final profile block_params: prevent the application of setparams in the final profile params_format: optional pattern with dot to wrap the param string, where dot represents the param string param_rep: desired way to convert params to strings Returns: The resolved profile catalog \"\"\" logger . debug ( f 'get resolved profile catalog for { profile_path } via generated Import.' ) import_ = prof . Import ( href = str ( profile_path ), include_all = {}) # The final Import has change_prose=True to force parameter substitution in the prose only at the last stage. import_filter = Import ( trestle_root , import_ , True , block_adds , block_params , params_format , param_rep ) logger . debug ( 'launch pipeline' ) result = next ( import_filter . process ()) return result handler: python","title":"get_resolved_profile_catalog()"},{"location":"api_reference/trestle.core.refs_validator/","text":"trestle.core.refs_validator \u00a4 Validate by confirming all refs have corresponding id. Classes \u00a4 RefsValidator ( Validator ) \u00a4 Validator to confirm all references in responsible parties are found in roles. Source code in trestle/core/refs_validator.py class RefsValidator ( Validator ): \"\"\"Validator to confirm all references in responsible parties are found in roles.\"\"\" def model_is_valid ( self , model : TopLevelOscalModel ) -> bool : \"\"\" Test if the model is valid. args: model: A top level OSCAL model. returns: True (valid) if the model's responsible parties match those found in roles. \"\"\" roles = as_list ( model . metadata . roles ) role_ids = [ role . id for role in roles ] responsible_parties = as_list ( model . metadata . responsible_parties ) if not responsible_parties : return True party_roles = [ party . role_id for party in responsible_parties ] # return true if all party roles are in the roles list return all ( item in role_ids for item in party_roles ) Methods \u00a4 model_is_valid ( self , model ) \u00a4 Test if the model is valid. Parameters: Name Type Description Default model ~TopLevelOscalModel A top level OSCAL model. required Returns: Type Description bool True (valid) if the model's responsible parties match those found in roles. Source code in trestle/core/refs_validator.py def model_is_valid ( self , model : TopLevelOscalModel ) -> bool : \"\"\" Test if the model is valid. args: model: A top level OSCAL model. returns: True (valid) if the model's responsible parties match those found in roles. \"\"\" roles = as_list ( model . metadata . roles ) role_ids = [ role . id for role in roles ] responsible_parties = as_list ( model . metadata . responsible_parties ) if not responsible_parties : return True party_roles = [ party . role_id for party in responsible_parties ] # return true if all party roles are in the roles list return all ( item in role_ids for item in party_roles ) handler: python","title":"refs_validator"},{"location":"api_reference/trestle.core.refs_validator/#trestle.core.refs_validator","text":"Validate by confirming all refs have corresponding id.","title":"refs_validator"},{"location":"api_reference/trestle.core.refs_validator/#trestle.core.refs_validator-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.refs_validator/#trestle.core.refs_validator.RefsValidator","text":"Validator to confirm all references in responsible parties are found in roles. Source code in trestle/core/refs_validator.py class RefsValidator ( Validator ): \"\"\"Validator to confirm all references in responsible parties are found in roles.\"\"\" def model_is_valid ( self , model : TopLevelOscalModel ) -> bool : \"\"\" Test if the model is valid. args: model: A top level OSCAL model. returns: True (valid) if the model's responsible parties match those found in roles. \"\"\" roles = as_list ( model . metadata . roles ) role_ids = [ role . id for role in roles ] responsible_parties = as_list ( model . metadata . responsible_parties ) if not responsible_parties : return True party_roles = [ party . role_id for party in responsible_parties ] # return true if all party roles are in the roles list return all ( item in role_ids for item in party_roles )","title":"RefsValidator"},{"location":"api_reference/trestle.core.refs_validator/#trestle.core.refs_validator.RefsValidator-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.refs_validator/#trestle.core.refs_validator.RefsValidator.model_is_valid","text":"Test if the model is valid. Parameters: Name Type Description Default model ~TopLevelOscalModel A top level OSCAL model. required Returns: Type Description bool True (valid) if the model's responsible parties match those found in roles. Source code in trestle/core/refs_validator.py def model_is_valid ( self , model : TopLevelOscalModel ) -> bool : \"\"\" Test if the model is valid. args: model: A top level OSCAL model. returns: True (valid) if the model's responsible parties match those found in roles. \"\"\" roles = as_list ( model . metadata . roles ) role_ids = [ role . id for role in roles ] responsible_parties = as_list ( model . metadata . responsible_parties ) if not responsible_parties : return True party_roles = [ party . role_id for party in responsible_parties ] # return true if all party roles are in the roles list return all ( item in role_ids for item in party_roles ) handler: python","title":"model_is_valid()"},{"location":"api_reference/trestle.core.remote.cache/","text":"trestle.core.remote.cache \u00a4 Trestle cache operations library. Allows for using URI's to reference external directories and then expand. logger \u00a4 Classes \u00a4 FetcherBase ( ABC ) \u00a4 FetcherBase - base class for caching and fetching remote oscal objects. Source code in trestle/core/remote/cache.py class FetcherBase ( ABC ): \"\"\"FetcherBase - base class for caching and fetching remote oscal objects.\"\"\" def __init__ ( self , trestle_root : pathlib . Path , uri : str ) -> None : \"\"\"Intialize fetcher base. Args: trestle_root: Path of the Trestle project path, i.e., within which .trestle is to be found. uri: Reference to the source object to cache. \"\"\" logger . debug ( 'Initializing FetcherBase' ) self . _cached_object_path : pathlib . Path self . _uri = uri self . _trestle_root = trestle_root . resolve () self . _trestle_cache_path : pathlib . Path = self . _trestle_root / const . TRESTLE_CACHE_DIR # ensure trestle cache directory exists. self . _trestle_cache_path . mkdir ( exist_ok = True ) self . _expiration_seconds = const . DAY_SECONDS @staticmethod def _time_since_modification ( file_path : pathlib . Path ) -> datetime . timedelta : \"\"\"Get time since last modification.\"\"\" last_modification = datetime . datetime . fromtimestamp ( file_path . stat () . st_mtime ) return datetime . datetime . now () - last_modification @abstractmethod def _do_fetch ( self ) -> None : \"\"\"Fetch the object from a remote source.\"\"\" pass def _in_cache ( self ) -> bool : \"\"\"Return whether object is present in the cache or not.\"\"\" return self . _cached_object_path . exists () def _is_stale ( self ) -> bool : # Either cache empty or cached item is too old if not self . _in_cache (): return True return FetcherBase . _time_since_modification ( self . _cached_object_path ) > datetime . timedelta ( seconds = self . _expiration_seconds ) def _update_cache ( self , force_update : bool = False ) -> bool : \"\"\"Update the cache by fetching the target remote object, if stale or forced. Args: force_update: force the fetch regardless of staleness. Returns: True if update occurred \"\"\" if self . _is_stale () or force_update : try : self . _do_fetch () return True except Exception as e : raise TrestleError ( f 'Cache update failure for { self . _uri } : { e } .' ) from e return False def get_raw ( self , force_update = False ) -> Dict [ str , Any ]: \"\"\"Retrieve the raw dictionary representing the underlying object.\"\"\" self . _update_cache ( force_update ) # Return results in the cache, whether yaml or json, or whatever is supported by fs.load_file(). try : raw_data = file_utils . load_file ( self . _cached_object_path ) except Exception : try : raw_data = file_utils . load_file ( self . _cached_object_path ) except Exception as e : raise TrestleError ( f 'Cache get failure for { self . _uri } : { e } .' ) from e return raw_data def get_oscal_with_model_type ( self , model_type : Type [ OscalBaseModel ], force_update = False ) -> OscalBaseModel : \"\"\"Retrieve the cached file as a particular OSCAL model. Arguments: model_type: Type[OscalBaseModel] Specifies the OSCAL model type of the fetched object. \"\"\" self . _update_cache ( force_update ) cache_file = self . _cached_object_path if not cache_file . exists (): raise TrestleError ( f 'get_oscal failure for { self . _uri } ' ) try : return model_type . oscal_read ( cache_file ) except Exception as e : logger . debug ( f 'get_oscal failed, error loading cache file for { self . _uri } as { model_type } ' ) raise TrestleError ( f 'get_oscal failure for { self . _uri } : { e } .' ) from e def get_oscal ( self , force_update = False ) -> Tuple [ OscalBaseModel , str ]: \"\"\"Retrieve the cached file and model name without knowing its model type.\"\"\" model_dict = self . get_raw ( force_update ) root_key = parser . root_key ( model_dict ) model_name = parser . to_full_model_name ( root_key ) if model_name is None : raise TrestleError ( f 'Failed cache read of non top level model with root_key { root_key } ' ) return parser . parse_dict ( model_dict [ root_key ], model_name ), root_key Methods \u00a4 __init__ ( self , trestle_root , uri ) special \u00a4 Intialize fetcher base. Parameters: Name Type Description Default trestle_root Path Path of the Trestle project path, i.e., within which .trestle is to be found. required uri str Reference to the source object to cache. required Source code in trestle/core/remote/cache.py def __init__ ( self , trestle_root : pathlib . Path , uri : str ) -> None : \"\"\"Intialize fetcher base. Args: trestle_root: Path of the Trestle project path, i.e., within which .trestle is to be found. uri: Reference to the source object to cache. \"\"\" logger . debug ( 'Initializing FetcherBase' ) self . _cached_object_path : pathlib . Path self . _uri = uri self . _trestle_root = trestle_root . resolve () self . _trestle_cache_path : pathlib . Path = self . _trestle_root / const . TRESTLE_CACHE_DIR # ensure trestle cache directory exists. self . _trestle_cache_path . mkdir ( exist_ok = True ) self . _expiration_seconds = const . DAY_SECONDS get_oscal ( self , force_update = False ) \u00a4 Retrieve the cached file and model name without knowing its model type. Source code in trestle/core/remote/cache.py def get_oscal ( self , force_update = False ) -> Tuple [ OscalBaseModel , str ]: \"\"\"Retrieve the cached file and model name without knowing its model type.\"\"\" model_dict = self . get_raw ( force_update ) root_key = parser . root_key ( model_dict ) model_name = parser . to_full_model_name ( root_key ) if model_name is None : raise TrestleError ( f 'Failed cache read of non top level model with root_key { root_key } ' ) return parser . parse_dict ( model_dict [ root_key ], model_name ), root_key get_oscal_with_model_type ( self , model_type , force_update = False ) \u00a4 Retrieve the cached file as a particular OSCAL model. Parameters: Name Type Description Default model_type Type[trestle.core.base_model.OscalBaseModel] Type[OscalBaseModel] Specifies the OSCAL model type of the fetched object. required Source code in trestle/core/remote/cache.py def get_oscal_with_model_type ( self , model_type : Type [ OscalBaseModel ], force_update = False ) -> OscalBaseModel : \"\"\"Retrieve the cached file as a particular OSCAL model. Arguments: model_type: Type[OscalBaseModel] Specifies the OSCAL model type of the fetched object. \"\"\" self . _update_cache ( force_update ) cache_file = self . _cached_object_path if not cache_file . exists (): raise TrestleError ( f 'get_oscal failure for { self . _uri } ' ) try : return model_type . oscal_read ( cache_file ) except Exception as e : logger . debug ( f 'get_oscal failed, error loading cache file for { self . _uri } as { model_type } ' ) raise TrestleError ( f 'get_oscal failure for { self . _uri } : { e } .' ) from e get_raw ( self , force_update = False ) \u00a4 Retrieve the raw dictionary representing the underlying object. Source code in trestle/core/remote/cache.py def get_raw ( self , force_update = False ) -> Dict [ str , Any ]: \"\"\"Retrieve the raw dictionary representing the underlying object.\"\"\" self . _update_cache ( force_update ) # Return results in the cache, whether yaml or json, or whatever is supported by fs.load_file(). try : raw_data = file_utils . load_file ( self . _cached_object_path ) except Exception : try : raw_data = file_utils . load_file ( self . _cached_object_path ) except Exception as e : raise TrestleError ( f 'Cache get failure for { self . _uri } : { e } .' ) from e return raw_data FetcherFactory \u00a4 Factory method for creating a fetcher. Source code in trestle/core/remote/cache.py class FetcherFactory : \"\"\"Factory method for creating a fetcher.\"\"\" class UriType ( Enum ): \"\"\"Specify types of URI.\"\"\" LOCAL_FILE = 1 SFTP = 2 HTTPS = 3 TRESTLE = 4 @staticmethod def _get_uri_type ( uri : str ) -> UriType : \"\"\"Determine the type of uri.\"\"\" if uri . startswith ( const . SFTP_URI ): return FetcherFactory . UriType . SFTP if uri . startswith ( const . HTTPS_URI ): return FetcherFactory . UriType . HTTPS if uri . startswith ( const . TRESTLE_HREF_HEADING ): return FetcherFactory . UriType . TRESTLE # if we land here, assume it is a local file and may have relative path # but it at least needs a filename with suffix # the most minimal allowed uri is of the form a.yml uri_clean = uri . strip () uri_len = len ( uri_clean ) # at least 5 chars and ending with dot followed by at least 3 chars if uri_len > 4 and 0 < uri_clean . rfind ( '.' ) < uri_len - 3 : return FetcherFactory . UriType . LOCAL_FILE raise TrestleError ( f 'Invalid uri not recognized as a readable file path with extension: { uri } ' ) @staticmethod def in_trestle_directory ( trestle_root : pathlib . Path , uri : str ) -> bool : \"\"\"Check if in trestle directory when uri may not be a file path.\"\"\" uri_type = FetcherFactory . _get_uri_type ( uri ) if uri_type == FetcherFactory . UriType . TRESTLE : return True if uri_type != FetcherFactory . UriType . LOCAL_FILE : return False try : pathlib . Path ( uri ) . resolve () . relative_to ( str ( trestle_root . resolve ())) except Exception : return False return True @classmethod def get_fetcher ( cls , trestle_root : pathlib . Path , uri : str ) -> FetcherBase : \"\"\"Return an instantiated fetcher object based on the type of URI. Args: trestle_root: Path of the Trestle project path, i.e., within which .trestle is to be found. uri: Reference to the remote object to cache. Returns: fetcher object for the given URI. \"\"\" fetcher_dict = { FetcherFactory . UriType . LOCAL_FILE : LocalFetcher , FetcherFactory . UriType . SFTP : SFTPFetcher , FetcherFactory . UriType . HTTPS : HTTPSFetcher , FetcherFactory . UriType . TRESTLE : LocalFetcher , } uri_type = cls . _get_uri_type ( uri ) return fetcher_dict [ uri_type ]( trestle_root , uri ) Classes \u00a4 UriType ( Enum ) \u00a4 Specify types of URI. Source code in trestle/core/remote/cache.py class UriType ( Enum ): \"\"\"Specify types of URI.\"\"\" LOCAL_FILE = 1 SFTP = 2 HTTPS = 3 TRESTLE = 4 HTTPS \u00a4 LOCAL_FILE \u00a4 SFTP \u00a4 TRESTLE \u00a4 Methods \u00a4 get_fetcher ( trestle_root , uri ) classmethod \u00a4 Return an instantiated fetcher object based on the type of URI. Parameters: Name Type Description Default trestle_root Path Path of the Trestle project path, i.e., within which .trestle is to be found. required uri str Reference to the remote object to cache. required Returns: Type Description FetcherBase fetcher object for the given URI. Source code in trestle/core/remote/cache.py @classmethod def get_fetcher ( cls , trestle_root : pathlib . Path , uri : str ) -> FetcherBase : \"\"\"Return an instantiated fetcher object based on the type of URI. Args: trestle_root: Path of the Trestle project path, i.e., within which .trestle is to be found. uri: Reference to the remote object to cache. Returns: fetcher object for the given URI. \"\"\" fetcher_dict = { FetcherFactory . UriType . LOCAL_FILE : LocalFetcher , FetcherFactory . UriType . SFTP : SFTPFetcher , FetcherFactory . UriType . HTTPS : HTTPSFetcher , FetcherFactory . UriType . TRESTLE : LocalFetcher , } uri_type = cls . _get_uri_type ( uri ) return fetcher_dict [ uri_type ]( trestle_root , uri ) in_trestle_directory ( trestle_root , uri ) staticmethod \u00a4 Check if in trestle directory when uri may not be a file path. Source code in trestle/core/remote/cache.py @staticmethod def in_trestle_directory ( trestle_root : pathlib . Path , uri : str ) -> bool : \"\"\"Check if in trestle directory when uri may not be a file path.\"\"\" uri_type = FetcherFactory . _get_uri_type ( uri ) if uri_type == FetcherFactory . UriType . TRESTLE : return True if uri_type != FetcherFactory . UriType . LOCAL_FILE : return False try : pathlib . Path ( uri ) . resolve () . relative_to ( str ( trestle_root . resolve ())) except Exception : return False return True HTTPSFetcher ( FetcherBase ) \u00a4 Fetcher for https content. Source code in trestle/core/remote/cache.py class HTTPSFetcher ( FetcherBase ): \"\"\"Fetcher for https content.\"\"\" # Use request: https://requests.readthedocs.io/en/master/ def __init__ ( self , trestle_root : pathlib . Path , uri : str ) -> None : \"\"\"Initialize HTTPS fetcher.\"\"\" logger . debug ( 'Initializing HTTPSFetcher' ) super () . __init__ ( trestle_root , uri ) self . _username = None self . _password = None u = parse . urlparse ( self . _uri ) self . _url = uri # If the either the username or password is omitted in the URI, then the other becomes '' # so we test for either None or ''. if u . username != '' and u . username is not None : # This also checks for invalid environment variable name (IEEE 1003.1) if not re . match ( '{{[a-zA-Z_][a-zA-Z0-9_]*}}' , u . username ) or u . username == '{{_}}' : raise TrestleError ( 'Cache request for invalid input URI: ' f 'username must refer to an environment variable using moustache { self . _uri } ' ) username_var = u . username [ 2 : - 2 ] if username_var not in os . environ : raise TrestleError ( f 'Cache request for invalid input URI: username not found in the environment { self . _uri } ' ) self . _username = os . environ [ username_var ] if u . password != '' and u . password is not None : # noqa S105 if not re . match ( '{{[a-zA-Z_][a-zA-Z0-9_]*}}' , u . password ) or u . password == '{{_}}' : # noqa S105 raise TrestleError ( 'Cache request for invalid input URI: ' f 'password must refer to an environment variable using moustache { self . _uri } ' ) password_var = u . password [ 2 : - 2 ] if password_var not in os . environ : raise TrestleError ( 'Cache request for invalid input URI: ' f 'password not found in the environment { self . _uri } ' ) self . _password = os . environ [ password_var ] if self . _username and ( self . _password == '' or self . _password is None ): # noqa S105 raise TrestleError ( f 'Cache request for invalid input URI: username found ' f 'but password not found via environment variable { self . _uri } ' ) if self . _password and not self . _username : raise TrestleError ( f 'Cache request for invalid input URI: password found ' f 'but username not found via environment variable { self . _uri } ' ) https_cached_dir = self . _trestle_cache_path / u . hostname # Skip any number of back- or forward slashes preceding the URI path (u.path) path_parent = pathlib . Path ( u . path [ re . search ( '[^/ \\\\\\\\ ]' , u . path ) . span ()[ 0 ]:]) . parent https_cached_dir = https_cached_dir / path_parent https_cached_dir . mkdir ( parents = True , exist_ok = True ) self . _cached_object_path = https_cached_dir / pathlib . Path ( pathlib . Path ( u . path ) . name ) def _do_fetch ( self ) -> None : auth = None verify = None # This order reflects requests library behavior: REQUESTS_CA_BUNDLE comes first. for env_var_name in [ 'REQUESTS_CA_BUNDLE' , 'CURL_CA_BUNDLE' ]: if env_var_name in os . environ : if pathlib . Path ( os . environ [ env_var_name ]) . exists (): verify = os . environ [ env_var_name ] break else : err_str = f 'Env var $ { env_var_name } found but path does not exist: { os . environ [ env_var_name ] } ' logger . warning ( err_str ) raise TrestleError ( f 'Cache update failure with bad inputenv var: { err_str } ' ) if self . _username is not None and self . _password is not None : auth = HTTPBasicAuth ( self . _username , self . _password ) try : response = requests . get ( self . _url , auth = auth , verify = verify ) except Exception as e : raise TrestleError ( f 'Cache update failure to connect via HTTPS: { self . _url } ( { e } )' ) if response . status_code == 200 : try : result = response . text except Exception as err : raise TrestleError ( f 'Cache update failure reading response via HTTPS: { self . _url } ( { err } )' ) else : self . _cached_object_path . write_text ( result , encoding = const . FILE_ENCODING ) else : raise TrestleError ( f 'GET returned code { response . status_code } : { self . _uri } ' ) Methods \u00a4 __init__ ( self , trestle_root , uri ) special \u00a4 Initialize HTTPS fetcher. Source code in trestle/core/remote/cache.py def __init__ ( self , trestle_root : pathlib . Path , uri : str ) -> None : \"\"\"Initialize HTTPS fetcher.\"\"\" logger . debug ( 'Initializing HTTPSFetcher' ) super () . __init__ ( trestle_root , uri ) self . _username = None self . _password = None u = parse . urlparse ( self . _uri ) self . _url = uri # If the either the username or password is omitted in the URI, then the other becomes '' # so we test for either None or ''. if u . username != '' and u . username is not None : # This also checks for invalid environment variable name (IEEE 1003.1) if not re . match ( '{{[a-zA-Z_][a-zA-Z0-9_]*}}' , u . username ) or u . username == '{{_}}' : raise TrestleError ( 'Cache request for invalid input URI: ' f 'username must refer to an environment variable using moustache { self . _uri } ' ) username_var = u . username [ 2 : - 2 ] if username_var not in os . environ : raise TrestleError ( f 'Cache request for invalid input URI: username not found in the environment { self . _uri } ' ) self . _username = os . environ [ username_var ] if u . password != '' and u . password is not None : # noqa S105 if not re . match ( '{{[a-zA-Z_][a-zA-Z0-9_]*}}' , u . password ) or u . password == '{{_}}' : # noqa S105 raise TrestleError ( 'Cache request for invalid input URI: ' f 'password must refer to an environment variable using moustache { self . _uri } ' ) password_var = u . password [ 2 : - 2 ] if password_var not in os . environ : raise TrestleError ( 'Cache request for invalid input URI: ' f 'password not found in the environment { self . _uri } ' ) self . _password = os . environ [ password_var ] if self . _username and ( self . _password == '' or self . _password is None ): # noqa S105 raise TrestleError ( f 'Cache request for invalid input URI: username found ' f 'but password not found via environment variable { self . _uri } ' ) if self . _password and not self . _username : raise TrestleError ( f 'Cache request for invalid input URI: password found ' f 'but username not found via environment variable { self . _uri } ' ) https_cached_dir = self . _trestle_cache_path / u . hostname # Skip any number of back- or forward slashes preceding the URI path (u.path) path_parent = pathlib . Path ( u . path [ re . search ( '[^/ \\\\\\\\ ]' , u . path ) . span ()[ 0 ]:]) . parent https_cached_dir = https_cached_dir / path_parent https_cached_dir . mkdir ( parents = True , exist_ok = True ) self . _cached_object_path = https_cached_dir / pathlib . Path ( pathlib . Path ( u . path ) . name ) LocalFetcher ( FetcherBase ) \u00a4 Fetcher for local content. Used for both file:/// and C:\\ or C:/ type paths, but the path must be absolute. Also used for trestle:// files present in the current trestle root. If file:/// is used on a Windows system, it must be followed by C:/ or other drive letter to be sure it is an absolute path, e.g. file:///C:/Users/Default/Documents/profile.json. The drive letter may be lowercase. LocalFetcher does not do any caching and assumes the file is quickly accessible. Source code in trestle/core/remote/cache.py class LocalFetcher ( FetcherBase ): r \"\"\"Fetcher for local content. Used for both file:/// and C:\\\\ or C:/ type paths, but the path must be absolute. Also used for trestle:// files present in the current trestle root. If file:/// is used on a Windows system, it must be followed by C:/ or other drive letter to be sure it is an absolute path, e.g. file:///C:/Users/Default/Documents/profile.json. The drive letter may be lowercase. LocalFetcher does not do any caching and assumes the file is quickly accessible. \"\"\" def __init__ ( self , trestle_root : pathlib . Path , uri : str ) -> None : \"\"\"Initialize local fetcher. Args: trestle_root: trestle root path uri: Reference to the file in the local filesystem to cache, which must be outside trestle_root. \"\"\" super () . __init__ ( trestle_root , uri ) # Handle as file:/// form if uri . startswith ( const . FILE_URI ): # strip off entire header including / uri = uri [ len ( const . FILE_URI ):] # if it has a drive letter don't add / to front uri = uri if re . match ( const . WINDOWS_DRIVE_LETTER_REGEX , uri ) else '/' + uri elif uri . startswith ( const . TRESTLE_HREF_HEADING ): uri = str ( trestle_root / uri [ len ( const . TRESTLE_HREF_HEADING ):]) self . _abs_path = pathlib . Path ( uri ) . resolve () self . _cached_object_path = self . _abs_path return # now the URI should be either unix / style or windows C:/ style. It may be relative. if ':' in uri and platform . system () != const . WINDOWS_PLATFORM_STR : raise TrestleError ( f 'Cannot have : in uri on non-Windows system unless ftps, https or trestle: { uri } ' ) # if it has a drive letter but no / after it, it is not absolute if re . match ( const . WINDOWS_DRIVE_LETTER_REGEX , uri ): if platform . system () != const . WINDOWS_PLATFORM_STR : raise TrestleError ( f 'Cannot cache Windows paths on non-Windows system. { uri } ' ) # store the abs path to the file for fetching # if this is a windows file it will have a drive letter at start after resolve try : self . _abs_path = pathlib . Path ( uri ) . resolve () except Exception : raise TrestleError ( f 'The uri provided is invalid or unresolvable as a file path: { uri } ' ) # set the cached path to be the actual file path self . _cached_object_path = self . _abs_path def _is_stale ( self ): # Local file is always stale. return True def _do_fetch ( self ) -> None : \"\"\"No need to fetch since using actual file path.\"\"\" pass Methods \u00a4 __init__ ( self , trestle_root , uri ) special \u00a4 Initialize local fetcher. Parameters: Name Type Description Default trestle_root Path trestle root path required uri str Reference to the file in the local filesystem to cache, which must be outside trestle_root. required Source code in trestle/core/remote/cache.py def __init__ ( self , trestle_root : pathlib . Path , uri : str ) -> None : \"\"\"Initialize local fetcher. Args: trestle_root: trestle root path uri: Reference to the file in the local filesystem to cache, which must be outside trestle_root. \"\"\" super () . __init__ ( trestle_root , uri ) # Handle as file:/// form if uri . startswith ( const . FILE_URI ): # strip off entire header including / uri = uri [ len ( const . FILE_URI ):] # if it has a drive letter don't add / to front uri = uri if re . match ( const . WINDOWS_DRIVE_LETTER_REGEX , uri ) else '/' + uri elif uri . startswith ( const . TRESTLE_HREF_HEADING ): uri = str ( trestle_root / uri [ len ( const . TRESTLE_HREF_HEADING ):]) self . _abs_path = pathlib . Path ( uri ) . resolve () self . _cached_object_path = self . _abs_path return # now the URI should be either unix / style or windows C:/ style. It may be relative. if ':' in uri and platform . system () != const . WINDOWS_PLATFORM_STR : raise TrestleError ( f 'Cannot have : in uri on non-Windows system unless ftps, https or trestle: { uri } ' ) # if it has a drive letter but no / after it, it is not absolute if re . match ( const . WINDOWS_DRIVE_LETTER_REGEX , uri ): if platform . system () != const . WINDOWS_PLATFORM_STR : raise TrestleError ( f 'Cannot cache Windows paths on non-Windows system. { uri } ' ) # store the abs path to the file for fetching # if this is a windows file it will have a drive letter at start after resolve try : self . _abs_path = pathlib . Path ( uri ) . resolve () except Exception : raise TrestleError ( f 'The uri provided is invalid or unresolvable as a file path: { uri } ' ) # set the cached path to be the actual file path self . _cached_object_path = self . _abs_path SFTPFetcher ( FetcherBase ) \u00a4 Fetcher for SFTP content. Source code in trestle/core/remote/cache.py class SFTPFetcher ( FetcherBase ): \"\"\"Fetcher for SFTP content.\"\"\" def __init__ ( self , trestle_root : pathlib . Path , uri : str ) -> None : \"\"\"Initialize SFTP fetcher. Update the expected cache path as per caching specs. Args: trestle_root: Path of the Trestle project path, i.e., within which .trestle is to be found. uri: Reference to the remote file to cache that can be fetched using the sftp:// scheme. \"\"\" logger . debug ( f 'initialize SFTPFetcher for uri { uri } ' ) super () . __init__ ( trestle_root , uri ) # Is this a valid URI, however? Username and password are optional, of course. try : u = parse . urlparse ( self . _uri ) except Exception as e : logger . warning ( f 'SFTP fetcher unable to parse uri { self . _uri } error { e } ' ) raise TrestleError ( f 'Unable to parse malformed url { self . _uri } error { e } ' ) logger . debug ( f 'SFTP fetcher with parsed uri { u } ' ) if not u . hostname : logger . debug ( 'SFTP fetcher uri missing hostname' ) logger . warning ( f 'Malformed URI, cannot parse hostname in URL { self . _uri } ' ) raise TrestleError ( f 'Cache request for invalid input URI: missing hostname { self . _uri } ' ) if not u . path : logger . debug ( 'SFTP fetcher uri missing path' ) logger . warning ( f 'Malformed URI, cannot parse path in URL { self . _uri } ' ) raise TrestleError ( f 'Cache request for invalid input URI: missing file path { self . _uri } ' ) sftp_cached_dir = self . _trestle_cache_path / u . hostname # Skip any number of back- or forward slashes preceding the URL path (u.path) path_parent = pathlib . Path ( u . path [ re . search ( '[^/ \\\\\\\\ ]' , u . path ) . span ()[ 0 ]:]) . parent sftp_cached_dir = sftp_cached_dir / path_parent sftp_cached_dir . mkdir ( parents = True , exist_ok = True ) self . _cached_object_path = sftp_cached_dir / pathlib . Path ( pathlib . Path ( u . path ) . name ) def _do_fetch ( self ) -> None : \"\"\"Fetch remote object and update the cache if appropriate and possible to do so. Authentication relies on the user's private key being either active via ssh-agent or supplied via environment variable SSH_KEY. In the latter case, it must not require a passphrase prompt. \"\"\" u = parse . urlparse ( self . _uri ) client = paramiko . SSHClient () # Must pick up host keys from the default known_hosts on this environment: try : client . load_system_host_keys () except Exception as e : raise TrestleError ( f 'Cache update failure for { self . _uri } : { e } .' ) # Use the supplied private key file if given, or look for keys in default path. if 'SSH_KEY' in os . environ : pkey = paramiko . RSAKey . from_private_key ( StringIO ( os . environ [ 'SSH_KEY' ])) look_for_keys = False else : pkey = None look_for_keys = True username = getpass . getuser () if not u . username else u . username try : client . connect ( u . hostname , username = username , password = u . password , pkey = pkey , look_for_keys = look_for_keys , port = 22 if not u . port else u . port , ) except Exception as e : raise TrestleError ( f 'Cache update failure to connect via SSH: { u . hostname } : { e } .' ) try : sftp_client = client . open_sftp () except Exception as e : raise TrestleError ( f 'Cache update failure to open sftp for { u . hostname } : { e } .' ) localpath = self . _cached_object_path try : sftp_client . get ( remotepath = u . path [ 1 :], localpath = ( localpath . __str__ ())) except Exception as e : raise TrestleError ( f 'Error getting remote resource { self . _uri } into cache { localpath } : { e } ' ) Methods \u00a4 __init__ ( self , trestle_root , uri ) special \u00a4 Initialize SFTP fetcher. Update the expected cache path as per caching specs. Parameters: Name Type Description Default trestle_root Path Path of the Trestle project path, i.e., within which .trestle is to be found. required uri str Reference to the remote file to cache that can be fetched using the sftp:// scheme. required Source code in trestle/core/remote/cache.py def __init__ ( self , trestle_root : pathlib . Path , uri : str ) -> None : \"\"\"Initialize SFTP fetcher. Update the expected cache path as per caching specs. Args: trestle_root: Path of the Trestle project path, i.e., within which .trestle is to be found. uri: Reference to the remote file to cache that can be fetched using the sftp:// scheme. \"\"\" logger . debug ( f 'initialize SFTPFetcher for uri { uri } ' ) super () . __init__ ( trestle_root , uri ) # Is this a valid URI, however? Username and password are optional, of course. try : u = parse . urlparse ( self . _uri ) except Exception as e : logger . warning ( f 'SFTP fetcher unable to parse uri { self . _uri } error { e } ' ) raise TrestleError ( f 'Unable to parse malformed url { self . _uri } error { e } ' ) logger . debug ( f 'SFTP fetcher with parsed uri { u } ' ) if not u . hostname : logger . debug ( 'SFTP fetcher uri missing hostname' ) logger . warning ( f 'Malformed URI, cannot parse hostname in URL { self . _uri } ' ) raise TrestleError ( f 'Cache request for invalid input URI: missing hostname { self . _uri } ' ) if not u . path : logger . debug ( 'SFTP fetcher uri missing path' ) logger . warning ( f 'Malformed URI, cannot parse path in URL { self . _uri } ' ) raise TrestleError ( f 'Cache request for invalid input URI: missing file path { self . _uri } ' ) sftp_cached_dir = self . _trestle_cache_path / u . hostname # Skip any number of back- or forward slashes preceding the URL path (u.path) path_parent = pathlib . Path ( u . path [ re . search ( '[^/ \\\\\\\\ ]' , u . path ) . span ()[ 0 ]:]) . parent sftp_cached_dir = sftp_cached_dir / path_parent sftp_cached_dir . mkdir ( parents = True , exist_ok = True ) self . _cached_object_path = sftp_cached_dir / pathlib . Path ( pathlib . Path ( u . path ) . name ) handler: python","title":"cache"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache","text":"Trestle cache operations library. Allows for using URI's to reference external directories and then expand.","title":"cache"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.FetcherBase","text":"FetcherBase - base class for caching and fetching remote oscal objects. Source code in trestle/core/remote/cache.py class FetcherBase ( ABC ): \"\"\"FetcherBase - base class for caching and fetching remote oscal objects.\"\"\" def __init__ ( self , trestle_root : pathlib . Path , uri : str ) -> None : \"\"\"Intialize fetcher base. Args: trestle_root: Path of the Trestle project path, i.e., within which .trestle is to be found. uri: Reference to the source object to cache. \"\"\" logger . debug ( 'Initializing FetcherBase' ) self . _cached_object_path : pathlib . Path self . _uri = uri self . _trestle_root = trestle_root . resolve () self . _trestle_cache_path : pathlib . Path = self . _trestle_root / const . TRESTLE_CACHE_DIR # ensure trestle cache directory exists. self . _trestle_cache_path . mkdir ( exist_ok = True ) self . _expiration_seconds = const . DAY_SECONDS @staticmethod def _time_since_modification ( file_path : pathlib . Path ) -> datetime . timedelta : \"\"\"Get time since last modification.\"\"\" last_modification = datetime . datetime . fromtimestamp ( file_path . stat () . st_mtime ) return datetime . datetime . now () - last_modification @abstractmethod def _do_fetch ( self ) -> None : \"\"\"Fetch the object from a remote source.\"\"\" pass def _in_cache ( self ) -> bool : \"\"\"Return whether object is present in the cache or not.\"\"\" return self . _cached_object_path . exists () def _is_stale ( self ) -> bool : # Either cache empty or cached item is too old if not self . _in_cache (): return True return FetcherBase . _time_since_modification ( self . _cached_object_path ) > datetime . timedelta ( seconds = self . _expiration_seconds ) def _update_cache ( self , force_update : bool = False ) -> bool : \"\"\"Update the cache by fetching the target remote object, if stale or forced. Args: force_update: force the fetch regardless of staleness. Returns: True if update occurred \"\"\" if self . _is_stale () or force_update : try : self . _do_fetch () return True except Exception as e : raise TrestleError ( f 'Cache update failure for { self . _uri } : { e } .' ) from e return False def get_raw ( self , force_update = False ) -> Dict [ str , Any ]: \"\"\"Retrieve the raw dictionary representing the underlying object.\"\"\" self . _update_cache ( force_update ) # Return results in the cache, whether yaml or json, or whatever is supported by fs.load_file(). try : raw_data = file_utils . load_file ( self . _cached_object_path ) except Exception : try : raw_data = file_utils . load_file ( self . _cached_object_path ) except Exception as e : raise TrestleError ( f 'Cache get failure for { self . _uri } : { e } .' ) from e return raw_data def get_oscal_with_model_type ( self , model_type : Type [ OscalBaseModel ], force_update = False ) -> OscalBaseModel : \"\"\"Retrieve the cached file as a particular OSCAL model. Arguments: model_type: Type[OscalBaseModel] Specifies the OSCAL model type of the fetched object. \"\"\" self . _update_cache ( force_update ) cache_file = self . _cached_object_path if not cache_file . exists (): raise TrestleError ( f 'get_oscal failure for { self . _uri } ' ) try : return model_type . oscal_read ( cache_file ) except Exception as e : logger . debug ( f 'get_oscal failed, error loading cache file for { self . _uri } as { model_type } ' ) raise TrestleError ( f 'get_oscal failure for { self . _uri } : { e } .' ) from e def get_oscal ( self , force_update = False ) -> Tuple [ OscalBaseModel , str ]: \"\"\"Retrieve the cached file and model name without knowing its model type.\"\"\" model_dict = self . get_raw ( force_update ) root_key = parser . root_key ( model_dict ) model_name = parser . to_full_model_name ( root_key ) if model_name is None : raise TrestleError ( f 'Failed cache read of non top level model with root_key { root_key } ' ) return parser . parse_dict ( model_dict [ root_key ], model_name ), root_key","title":"FetcherBase"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.FetcherBase-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.FetcherBase.__init__","text":"Intialize fetcher base. Parameters: Name Type Description Default trestle_root Path Path of the Trestle project path, i.e., within which .trestle is to be found. required uri str Reference to the source object to cache. required Source code in trestle/core/remote/cache.py def __init__ ( self , trestle_root : pathlib . Path , uri : str ) -> None : \"\"\"Intialize fetcher base. Args: trestle_root: Path of the Trestle project path, i.e., within which .trestle is to be found. uri: Reference to the source object to cache. \"\"\" logger . debug ( 'Initializing FetcherBase' ) self . _cached_object_path : pathlib . Path self . _uri = uri self . _trestle_root = trestle_root . resolve () self . _trestle_cache_path : pathlib . Path = self . _trestle_root / const . TRESTLE_CACHE_DIR # ensure trestle cache directory exists. self . _trestle_cache_path . mkdir ( exist_ok = True ) self . _expiration_seconds = const . DAY_SECONDS","title":"__init__()"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.FetcherBase.get_oscal","text":"Retrieve the cached file and model name without knowing its model type. Source code in trestle/core/remote/cache.py def get_oscal ( self , force_update = False ) -> Tuple [ OscalBaseModel , str ]: \"\"\"Retrieve the cached file and model name without knowing its model type.\"\"\" model_dict = self . get_raw ( force_update ) root_key = parser . root_key ( model_dict ) model_name = parser . to_full_model_name ( root_key ) if model_name is None : raise TrestleError ( f 'Failed cache read of non top level model with root_key { root_key } ' ) return parser . parse_dict ( model_dict [ root_key ], model_name ), root_key","title":"get_oscal()"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.FetcherBase.get_oscal_with_model_type","text":"Retrieve the cached file as a particular OSCAL model. Parameters: Name Type Description Default model_type Type[trestle.core.base_model.OscalBaseModel] Type[OscalBaseModel] Specifies the OSCAL model type of the fetched object. required Source code in trestle/core/remote/cache.py def get_oscal_with_model_type ( self , model_type : Type [ OscalBaseModel ], force_update = False ) -> OscalBaseModel : \"\"\"Retrieve the cached file as a particular OSCAL model. Arguments: model_type: Type[OscalBaseModel] Specifies the OSCAL model type of the fetched object. \"\"\" self . _update_cache ( force_update ) cache_file = self . _cached_object_path if not cache_file . exists (): raise TrestleError ( f 'get_oscal failure for { self . _uri } ' ) try : return model_type . oscal_read ( cache_file ) except Exception as e : logger . debug ( f 'get_oscal failed, error loading cache file for { self . _uri } as { model_type } ' ) raise TrestleError ( f 'get_oscal failure for { self . _uri } : { e } .' ) from e","title":"get_oscal_with_model_type()"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.FetcherBase.get_raw","text":"Retrieve the raw dictionary representing the underlying object. Source code in trestle/core/remote/cache.py def get_raw ( self , force_update = False ) -> Dict [ str , Any ]: \"\"\"Retrieve the raw dictionary representing the underlying object.\"\"\" self . _update_cache ( force_update ) # Return results in the cache, whether yaml or json, or whatever is supported by fs.load_file(). try : raw_data = file_utils . load_file ( self . _cached_object_path ) except Exception : try : raw_data = file_utils . load_file ( self . _cached_object_path ) except Exception as e : raise TrestleError ( f 'Cache get failure for { self . _uri } : { e } .' ) from e return raw_data","title":"get_raw()"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.FetcherFactory","text":"Factory method for creating a fetcher. Source code in trestle/core/remote/cache.py class FetcherFactory : \"\"\"Factory method for creating a fetcher.\"\"\" class UriType ( Enum ): \"\"\"Specify types of URI.\"\"\" LOCAL_FILE = 1 SFTP = 2 HTTPS = 3 TRESTLE = 4 @staticmethod def _get_uri_type ( uri : str ) -> UriType : \"\"\"Determine the type of uri.\"\"\" if uri . startswith ( const . SFTP_URI ): return FetcherFactory . UriType . SFTP if uri . startswith ( const . HTTPS_URI ): return FetcherFactory . UriType . HTTPS if uri . startswith ( const . TRESTLE_HREF_HEADING ): return FetcherFactory . UriType . TRESTLE # if we land here, assume it is a local file and may have relative path # but it at least needs a filename with suffix # the most minimal allowed uri is of the form a.yml uri_clean = uri . strip () uri_len = len ( uri_clean ) # at least 5 chars and ending with dot followed by at least 3 chars if uri_len > 4 and 0 < uri_clean . rfind ( '.' ) < uri_len - 3 : return FetcherFactory . UriType . LOCAL_FILE raise TrestleError ( f 'Invalid uri not recognized as a readable file path with extension: { uri } ' ) @staticmethod def in_trestle_directory ( trestle_root : pathlib . Path , uri : str ) -> bool : \"\"\"Check if in trestle directory when uri may not be a file path.\"\"\" uri_type = FetcherFactory . _get_uri_type ( uri ) if uri_type == FetcherFactory . UriType . TRESTLE : return True if uri_type != FetcherFactory . UriType . LOCAL_FILE : return False try : pathlib . Path ( uri ) . resolve () . relative_to ( str ( trestle_root . resolve ())) except Exception : return False return True @classmethod def get_fetcher ( cls , trestle_root : pathlib . Path , uri : str ) -> FetcherBase : \"\"\"Return an instantiated fetcher object based on the type of URI. Args: trestle_root: Path of the Trestle project path, i.e., within which .trestle is to be found. uri: Reference to the remote object to cache. Returns: fetcher object for the given URI. \"\"\" fetcher_dict = { FetcherFactory . UriType . LOCAL_FILE : LocalFetcher , FetcherFactory . UriType . SFTP : SFTPFetcher , FetcherFactory . UriType . HTTPS : HTTPSFetcher , FetcherFactory . UriType . TRESTLE : LocalFetcher , } uri_type = cls . _get_uri_type ( uri ) return fetcher_dict [ uri_type ]( trestle_root , uri )","title":"FetcherFactory"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.FetcherFactory-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.FetcherFactory.UriType","text":"Specify types of URI. Source code in trestle/core/remote/cache.py class UriType ( Enum ): \"\"\"Specify types of URI.\"\"\" LOCAL_FILE = 1 SFTP = 2 HTTPS = 3 TRESTLE = 4 HTTPS \u00a4 LOCAL_FILE \u00a4 SFTP \u00a4 TRESTLE \u00a4","title":"UriType"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.FetcherFactory-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.FetcherFactory.get_fetcher","text":"Return an instantiated fetcher object based on the type of URI. Parameters: Name Type Description Default trestle_root Path Path of the Trestle project path, i.e., within which .trestle is to be found. required uri str Reference to the remote object to cache. required Returns: Type Description FetcherBase fetcher object for the given URI. Source code in trestle/core/remote/cache.py @classmethod def get_fetcher ( cls , trestle_root : pathlib . Path , uri : str ) -> FetcherBase : \"\"\"Return an instantiated fetcher object based on the type of URI. Args: trestle_root: Path of the Trestle project path, i.e., within which .trestle is to be found. uri: Reference to the remote object to cache. Returns: fetcher object for the given URI. \"\"\" fetcher_dict = { FetcherFactory . UriType . LOCAL_FILE : LocalFetcher , FetcherFactory . UriType . SFTP : SFTPFetcher , FetcherFactory . UriType . HTTPS : HTTPSFetcher , FetcherFactory . UriType . TRESTLE : LocalFetcher , } uri_type = cls . _get_uri_type ( uri ) return fetcher_dict [ uri_type ]( trestle_root , uri )","title":"get_fetcher()"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.FetcherFactory.in_trestle_directory","text":"Check if in trestle directory when uri may not be a file path. Source code in trestle/core/remote/cache.py @staticmethod def in_trestle_directory ( trestle_root : pathlib . Path , uri : str ) -> bool : \"\"\"Check if in trestle directory when uri may not be a file path.\"\"\" uri_type = FetcherFactory . _get_uri_type ( uri ) if uri_type == FetcherFactory . UriType . TRESTLE : return True if uri_type != FetcherFactory . UriType . LOCAL_FILE : return False try : pathlib . Path ( uri ) . resolve () . relative_to ( str ( trestle_root . resolve ())) except Exception : return False return True","title":"in_trestle_directory()"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.HTTPSFetcher","text":"Fetcher for https content. Source code in trestle/core/remote/cache.py class HTTPSFetcher ( FetcherBase ): \"\"\"Fetcher for https content.\"\"\" # Use request: https://requests.readthedocs.io/en/master/ def __init__ ( self , trestle_root : pathlib . Path , uri : str ) -> None : \"\"\"Initialize HTTPS fetcher.\"\"\" logger . debug ( 'Initializing HTTPSFetcher' ) super () . __init__ ( trestle_root , uri ) self . _username = None self . _password = None u = parse . urlparse ( self . _uri ) self . _url = uri # If the either the username or password is omitted in the URI, then the other becomes '' # so we test for either None or ''. if u . username != '' and u . username is not None : # This also checks for invalid environment variable name (IEEE 1003.1) if not re . match ( '{{[a-zA-Z_][a-zA-Z0-9_]*}}' , u . username ) or u . username == '{{_}}' : raise TrestleError ( 'Cache request for invalid input URI: ' f 'username must refer to an environment variable using moustache { self . _uri } ' ) username_var = u . username [ 2 : - 2 ] if username_var not in os . environ : raise TrestleError ( f 'Cache request for invalid input URI: username not found in the environment { self . _uri } ' ) self . _username = os . environ [ username_var ] if u . password != '' and u . password is not None : # noqa S105 if not re . match ( '{{[a-zA-Z_][a-zA-Z0-9_]*}}' , u . password ) or u . password == '{{_}}' : # noqa S105 raise TrestleError ( 'Cache request for invalid input URI: ' f 'password must refer to an environment variable using moustache { self . _uri } ' ) password_var = u . password [ 2 : - 2 ] if password_var not in os . environ : raise TrestleError ( 'Cache request for invalid input URI: ' f 'password not found in the environment { self . _uri } ' ) self . _password = os . environ [ password_var ] if self . _username and ( self . _password == '' or self . _password is None ): # noqa S105 raise TrestleError ( f 'Cache request for invalid input URI: username found ' f 'but password not found via environment variable { self . _uri } ' ) if self . _password and not self . _username : raise TrestleError ( f 'Cache request for invalid input URI: password found ' f 'but username not found via environment variable { self . _uri } ' ) https_cached_dir = self . _trestle_cache_path / u . hostname # Skip any number of back- or forward slashes preceding the URI path (u.path) path_parent = pathlib . Path ( u . path [ re . search ( '[^/ \\\\\\\\ ]' , u . path ) . span ()[ 0 ]:]) . parent https_cached_dir = https_cached_dir / path_parent https_cached_dir . mkdir ( parents = True , exist_ok = True ) self . _cached_object_path = https_cached_dir / pathlib . Path ( pathlib . Path ( u . path ) . name ) def _do_fetch ( self ) -> None : auth = None verify = None # This order reflects requests library behavior: REQUESTS_CA_BUNDLE comes first. for env_var_name in [ 'REQUESTS_CA_BUNDLE' , 'CURL_CA_BUNDLE' ]: if env_var_name in os . environ : if pathlib . Path ( os . environ [ env_var_name ]) . exists (): verify = os . environ [ env_var_name ] break else : err_str = f 'Env var $ { env_var_name } found but path does not exist: { os . environ [ env_var_name ] } ' logger . warning ( err_str ) raise TrestleError ( f 'Cache update failure with bad inputenv var: { err_str } ' ) if self . _username is not None and self . _password is not None : auth = HTTPBasicAuth ( self . _username , self . _password ) try : response = requests . get ( self . _url , auth = auth , verify = verify ) except Exception as e : raise TrestleError ( f 'Cache update failure to connect via HTTPS: { self . _url } ( { e } )' ) if response . status_code == 200 : try : result = response . text except Exception as err : raise TrestleError ( f 'Cache update failure reading response via HTTPS: { self . _url } ( { err } )' ) else : self . _cached_object_path . write_text ( result , encoding = const . FILE_ENCODING ) else : raise TrestleError ( f 'GET returned code { response . status_code } : { self . _uri } ' )","title":"HTTPSFetcher"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.HTTPSFetcher-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.HTTPSFetcher.__init__","text":"Initialize HTTPS fetcher. Source code in trestle/core/remote/cache.py def __init__ ( self , trestle_root : pathlib . Path , uri : str ) -> None : \"\"\"Initialize HTTPS fetcher.\"\"\" logger . debug ( 'Initializing HTTPSFetcher' ) super () . __init__ ( trestle_root , uri ) self . _username = None self . _password = None u = parse . urlparse ( self . _uri ) self . _url = uri # If the either the username or password is omitted in the URI, then the other becomes '' # so we test for either None or ''. if u . username != '' and u . username is not None : # This also checks for invalid environment variable name (IEEE 1003.1) if not re . match ( '{{[a-zA-Z_][a-zA-Z0-9_]*}}' , u . username ) or u . username == '{{_}}' : raise TrestleError ( 'Cache request for invalid input URI: ' f 'username must refer to an environment variable using moustache { self . _uri } ' ) username_var = u . username [ 2 : - 2 ] if username_var not in os . environ : raise TrestleError ( f 'Cache request for invalid input URI: username not found in the environment { self . _uri } ' ) self . _username = os . environ [ username_var ] if u . password != '' and u . password is not None : # noqa S105 if not re . match ( '{{[a-zA-Z_][a-zA-Z0-9_]*}}' , u . password ) or u . password == '{{_}}' : # noqa S105 raise TrestleError ( 'Cache request for invalid input URI: ' f 'password must refer to an environment variable using moustache { self . _uri } ' ) password_var = u . password [ 2 : - 2 ] if password_var not in os . environ : raise TrestleError ( 'Cache request for invalid input URI: ' f 'password not found in the environment { self . _uri } ' ) self . _password = os . environ [ password_var ] if self . _username and ( self . _password == '' or self . _password is None ): # noqa S105 raise TrestleError ( f 'Cache request for invalid input URI: username found ' f 'but password not found via environment variable { self . _uri } ' ) if self . _password and not self . _username : raise TrestleError ( f 'Cache request for invalid input URI: password found ' f 'but username not found via environment variable { self . _uri } ' ) https_cached_dir = self . _trestle_cache_path / u . hostname # Skip any number of back- or forward slashes preceding the URI path (u.path) path_parent = pathlib . Path ( u . path [ re . search ( '[^/ \\\\\\\\ ]' , u . path ) . span ()[ 0 ]:]) . parent https_cached_dir = https_cached_dir / path_parent https_cached_dir . mkdir ( parents = True , exist_ok = True ) self . _cached_object_path = https_cached_dir / pathlib . Path ( pathlib . Path ( u . path ) . name )","title":"__init__()"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.LocalFetcher","text":"Fetcher for local content. Used for both file:/// and C:\\ or C:/ type paths, but the path must be absolute. Also used for trestle:// files present in the current trestle root. If file:/// is used on a Windows system, it must be followed by C:/ or other drive letter to be sure it is an absolute path, e.g. file:///C:/Users/Default/Documents/profile.json. The drive letter may be lowercase. LocalFetcher does not do any caching and assumes the file is quickly accessible. Source code in trestle/core/remote/cache.py class LocalFetcher ( FetcherBase ): r \"\"\"Fetcher for local content. Used for both file:/// and C:\\\\ or C:/ type paths, but the path must be absolute. Also used for trestle:// files present in the current trestle root. If file:/// is used on a Windows system, it must be followed by C:/ or other drive letter to be sure it is an absolute path, e.g. file:///C:/Users/Default/Documents/profile.json. The drive letter may be lowercase. LocalFetcher does not do any caching and assumes the file is quickly accessible. \"\"\" def __init__ ( self , trestle_root : pathlib . Path , uri : str ) -> None : \"\"\"Initialize local fetcher. Args: trestle_root: trestle root path uri: Reference to the file in the local filesystem to cache, which must be outside trestle_root. \"\"\" super () . __init__ ( trestle_root , uri ) # Handle as file:/// form if uri . startswith ( const . FILE_URI ): # strip off entire header including / uri = uri [ len ( const . FILE_URI ):] # if it has a drive letter don't add / to front uri = uri if re . match ( const . WINDOWS_DRIVE_LETTER_REGEX , uri ) else '/' + uri elif uri . startswith ( const . TRESTLE_HREF_HEADING ): uri = str ( trestle_root / uri [ len ( const . TRESTLE_HREF_HEADING ):]) self . _abs_path = pathlib . Path ( uri ) . resolve () self . _cached_object_path = self . _abs_path return # now the URI should be either unix / style or windows C:/ style. It may be relative. if ':' in uri and platform . system () != const . WINDOWS_PLATFORM_STR : raise TrestleError ( f 'Cannot have : in uri on non-Windows system unless ftps, https or trestle: { uri } ' ) # if it has a drive letter but no / after it, it is not absolute if re . match ( const . WINDOWS_DRIVE_LETTER_REGEX , uri ): if platform . system () != const . WINDOWS_PLATFORM_STR : raise TrestleError ( f 'Cannot cache Windows paths on non-Windows system. { uri } ' ) # store the abs path to the file for fetching # if this is a windows file it will have a drive letter at start after resolve try : self . _abs_path = pathlib . Path ( uri ) . resolve () except Exception : raise TrestleError ( f 'The uri provided is invalid or unresolvable as a file path: { uri } ' ) # set the cached path to be the actual file path self . _cached_object_path = self . _abs_path def _is_stale ( self ): # Local file is always stale. return True def _do_fetch ( self ) -> None : \"\"\"No need to fetch since using actual file path.\"\"\" pass","title":"LocalFetcher"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.LocalFetcher-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.LocalFetcher.__init__","text":"Initialize local fetcher. Parameters: Name Type Description Default trestle_root Path trestle root path required uri str Reference to the file in the local filesystem to cache, which must be outside trestle_root. required Source code in trestle/core/remote/cache.py def __init__ ( self , trestle_root : pathlib . Path , uri : str ) -> None : \"\"\"Initialize local fetcher. Args: trestle_root: trestle root path uri: Reference to the file in the local filesystem to cache, which must be outside trestle_root. \"\"\" super () . __init__ ( trestle_root , uri ) # Handle as file:/// form if uri . startswith ( const . FILE_URI ): # strip off entire header including / uri = uri [ len ( const . FILE_URI ):] # if it has a drive letter don't add / to front uri = uri if re . match ( const . WINDOWS_DRIVE_LETTER_REGEX , uri ) else '/' + uri elif uri . startswith ( const . TRESTLE_HREF_HEADING ): uri = str ( trestle_root / uri [ len ( const . TRESTLE_HREF_HEADING ):]) self . _abs_path = pathlib . Path ( uri ) . resolve () self . _cached_object_path = self . _abs_path return # now the URI should be either unix / style or windows C:/ style. It may be relative. if ':' in uri and platform . system () != const . WINDOWS_PLATFORM_STR : raise TrestleError ( f 'Cannot have : in uri on non-Windows system unless ftps, https or trestle: { uri } ' ) # if it has a drive letter but no / after it, it is not absolute if re . match ( const . WINDOWS_DRIVE_LETTER_REGEX , uri ): if platform . system () != const . WINDOWS_PLATFORM_STR : raise TrestleError ( f 'Cannot cache Windows paths on non-Windows system. { uri } ' ) # store the abs path to the file for fetching # if this is a windows file it will have a drive letter at start after resolve try : self . _abs_path = pathlib . Path ( uri ) . resolve () except Exception : raise TrestleError ( f 'The uri provided is invalid or unresolvable as a file path: { uri } ' ) # set the cached path to be the actual file path self . _cached_object_path = self . _abs_path","title":"__init__()"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.SFTPFetcher","text":"Fetcher for SFTP content. Source code in trestle/core/remote/cache.py class SFTPFetcher ( FetcherBase ): \"\"\"Fetcher for SFTP content.\"\"\" def __init__ ( self , trestle_root : pathlib . Path , uri : str ) -> None : \"\"\"Initialize SFTP fetcher. Update the expected cache path as per caching specs. Args: trestle_root: Path of the Trestle project path, i.e., within which .trestle is to be found. uri: Reference to the remote file to cache that can be fetched using the sftp:// scheme. \"\"\" logger . debug ( f 'initialize SFTPFetcher for uri { uri } ' ) super () . __init__ ( trestle_root , uri ) # Is this a valid URI, however? Username and password are optional, of course. try : u = parse . urlparse ( self . _uri ) except Exception as e : logger . warning ( f 'SFTP fetcher unable to parse uri { self . _uri } error { e } ' ) raise TrestleError ( f 'Unable to parse malformed url { self . _uri } error { e } ' ) logger . debug ( f 'SFTP fetcher with parsed uri { u } ' ) if not u . hostname : logger . debug ( 'SFTP fetcher uri missing hostname' ) logger . warning ( f 'Malformed URI, cannot parse hostname in URL { self . _uri } ' ) raise TrestleError ( f 'Cache request for invalid input URI: missing hostname { self . _uri } ' ) if not u . path : logger . debug ( 'SFTP fetcher uri missing path' ) logger . warning ( f 'Malformed URI, cannot parse path in URL { self . _uri } ' ) raise TrestleError ( f 'Cache request for invalid input URI: missing file path { self . _uri } ' ) sftp_cached_dir = self . _trestle_cache_path / u . hostname # Skip any number of back- or forward slashes preceding the URL path (u.path) path_parent = pathlib . Path ( u . path [ re . search ( '[^/ \\\\\\\\ ]' , u . path ) . span ()[ 0 ]:]) . parent sftp_cached_dir = sftp_cached_dir / path_parent sftp_cached_dir . mkdir ( parents = True , exist_ok = True ) self . _cached_object_path = sftp_cached_dir / pathlib . Path ( pathlib . Path ( u . path ) . name ) def _do_fetch ( self ) -> None : \"\"\"Fetch remote object and update the cache if appropriate and possible to do so. Authentication relies on the user's private key being either active via ssh-agent or supplied via environment variable SSH_KEY. In the latter case, it must not require a passphrase prompt. \"\"\" u = parse . urlparse ( self . _uri ) client = paramiko . SSHClient () # Must pick up host keys from the default known_hosts on this environment: try : client . load_system_host_keys () except Exception as e : raise TrestleError ( f 'Cache update failure for { self . _uri } : { e } .' ) # Use the supplied private key file if given, or look for keys in default path. if 'SSH_KEY' in os . environ : pkey = paramiko . RSAKey . from_private_key ( StringIO ( os . environ [ 'SSH_KEY' ])) look_for_keys = False else : pkey = None look_for_keys = True username = getpass . getuser () if not u . username else u . username try : client . connect ( u . hostname , username = username , password = u . password , pkey = pkey , look_for_keys = look_for_keys , port = 22 if not u . port else u . port , ) except Exception as e : raise TrestleError ( f 'Cache update failure to connect via SSH: { u . hostname } : { e } .' ) try : sftp_client = client . open_sftp () except Exception as e : raise TrestleError ( f 'Cache update failure to open sftp for { u . hostname } : { e } .' ) localpath = self . _cached_object_path try : sftp_client . get ( remotepath = u . path [ 1 :], localpath = ( localpath . __str__ ())) except Exception as e : raise TrestleError ( f 'Error getting remote resource { self . _uri } into cache { localpath } : { e } ' )","title":"SFTPFetcher"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.SFTPFetcher-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.remote.cache/#trestle.core.remote.cache.SFTPFetcher.__init__","text":"Initialize SFTP fetcher. Update the expected cache path as per caching specs. Parameters: Name Type Description Default trestle_root Path Path of the Trestle project path, i.e., within which .trestle is to be found. required uri str Reference to the remote file to cache that can be fetched using the sftp:// scheme. required Source code in trestle/core/remote/cache.py def __init__ ( self , trestle_root : pathlib . Path , uri : str ) -> None : \"\"\"Initialize SFTP fetcher. Update the expected cache path as per caching specs. Args: trestle_root: Path of the Trestle project path, i.e., within which .trestle is to be found. uri: Reference to the remote file to cache that can be fetched using the sftp:// scheme. \"\"\" logger . debug ( f 'initialize SFTPFetcher for uri { uri } ' ) super () . __init__ ( trestle_root , uri ) # Is this a valid URI, however? Username and password are optional, of course. try : u = parse . urlparse ( self . _uri ) except Exception as e : logger . warning ( f 'SFTP fetcher unable to parse uri { self . _uri } error { e } ' ) raise TrestleError ( f 'Unable to parse malformed url { self . _uri } error { e } ' ) logger . debug ( f 'SFTP fetcher with parsed uri { u } ' ) if not u . hostname : logger . debug ( 'SFTP fetcher uri missing hostname' ) logger . warning ( f 'Malformed URI, cannot parse hostname in URL { self . _uri } ' ) raise TrestleError ( f 'Cache request for invalid input URI: missing hostname { self . _uri } ' ) if not u . path : logger . debug ( 'SFTP fetcher uri missing path' ) logger . warning ( f 'Malformed URI, cannot parse path in URL { self . _uri } ' ) raise TrestleError ( f 'Cache request for invalid input URI: missing file path { self . _uri } ' ) sftp_cached_dir = self . _trestle_cache_path / u . hostname # Skip any number of back- or forward slashes preceding the URL path (u.path) path_parent = pathlib . Path ( u . path [ re . search ( '[^/ \\\\\\\\ ]' , u . path ) . span ()[ 0 ]:]) . parent sftp_cached_dir = sftp_cached_dir / path_parent sftp_cached_dir . mkdir ( parents = True , exist_ok = True ) self . _cached_object_path = sftp_cached_dir / pathlib . Path ( pathlib . Path ( u . path ) . name ) handler: python","title":"__init__()"},{"location":"api_reference/trestle.core.repository/","text":"trestle.core.repository \u00a4 Trestle Repository APIs. logger \u00a4 Classes \u00a4 ManagedOSCAL \u00a4 Object representing OSCAL models in repository for programmatic manipulation. Source code in trestle/core/repository.py class ManagedOSCAL : \"\"\"Object representing OSCAL models in repository for programmatic manipulation.\"\"\" def __init__ ( self , root_dir : pathlib . Path , model_type : Type [ OscalBaseModel ], name : str ) -> None : \"\"\"Initialize repository OSCAL model object.\"\"\" if not file_utils . is_valid_project_root ( root_dir ): raise TrestleError ( f 'Provided root directory { str ( root_dir ) } is not a valid Trestle root directory.' ) self . root_dir = root_dir self . model_type = model_type self . model_name = name # set model alais and dir self . model_alias = classname_to_alias ( self . model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( self . model_alias ) is None : raise TrestleError ( f 'Given model { self . model_alias } is not a top level model.' ) plural_path = ModelUtils . model_type_to_model_dir ( self . model_alias ) self . model_dir = self . root_dir / plural_path / self . model_name if not self . model_dir . exists () or not self . model_dir . is_dir (): raise TrestleError ( f 'Model dir { self . model_name } does not exist.' ) file_content_type = FileContentType . path_to_content_type ( self . model_dir / self . model_alias ) if file_content_type == FileContentType . UNKNOWN : raise TrestleError ( f 'Model file for model { self . model_name } does not exist.' ) self . file_content_type = file_content_type filepath = pathlib . Path ( self . model_dir , self . model_alias + FileContentType . path_to_file_extension ( self . model_dir / self . model_alias ) ) self . filepath = filepath def read ( self ) -> OscalBaseModel : \"\"\"Read OSCAL model from repository.\"\"\" logger . debug ( f 'Reading model { self . model_name } .' ) _ , _ , model = ModelUtils . load_distributed ( self . filepath , self . root_dir ) return model def write ( self , model : OscalBaseModel ) -> bool : \"\"\"Write OSCAL model to repository.\"\"\" logger . debug ( f 'Writing model { self . model_name } .' ) model_alias = classname_to_alias ( model . __class__ . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) # split directory if the model was split split_dir = pathlib . Path ( self . model_dir , self . model_alias ) # Prepare actions; delete split model dir if any, recreate model file, and write to filepath top_element = Element ( model ) remove_action = RemovePathAction ( split_dir ) create_action = CreatePathAction ( self . filepath , True ) write_action = WriteFileAction ( self . filepath , top_element , self . file_content_type ) # create a plan to create the directory and imported file. import_plan = Plan () import_plan . add_action ( remove_action ) import_plan . add_action ( create_action ) import_plan . add_action ( write_action ) import_plan . execute () logger . debug ( f 'Model { self . model_name } written to repository' ) return True def split ( self , model_file : pathlib . Path , elements : List [ str ]) -> bool : \"\"\"Split the given OSCAL model file in repository. Model file path should be relative to the main model directory, e.g., model dir is $TRESTLE_ROOT/catalogs/NIST then model file path can be 'catalog/metadata.json' if metadata is to be split. Elements should be specified relative to model file, e.g., 'metadata.props.*' \"\"\" logger . debug ( f 'Splitting model { self . model_name } , file { model_file } .' ) # input model_file should be relative to the model dir model_file_path = self . model_dir / model_file model_file_path = model_file_path . resolve () file_parent = model_file_path . parent filename = model_file_path . name elems = '' first = True for elem in elements : if first : elems = elem first = False else : elems = elems + ',' + elem success = False try : ret = splitcmd . SplitCmd () . perform_split ( file_parent , filename , elems , self . root_dir ) if ret == 0 : success = True except Exception as e : raise TrestleError ( f 'Error in splitting model: { e } ' ) logger . debug ( f 'Model { self . model_name } , file { model_file } splitted successfully.' ) return success def merge ( self , elements : List [ str ], parent_model_dir : Optional [ pathlib . Path ] = None ) -> bool : \"\"\"Merge OSCAL elements in repository. The parent_model_dir specifies the parent model direcotry in which to merge relative to main model dir. For example, if we have to merge 'metadata.*' into 'metadata' then parent_model_dir should be the 'catalog' dir that contains the 'metadata.json' file or the 'metadata' directory \"\"\" logger . debug ( f 'Merging model { self . model_name } , parent dir { parent_model_dir } .' ) if parent_model_dir is None : effective_cwd = self . model_dir else : effective_cwd = self . model_dir / parent_model_dir success = True try : for elem in elements : plan = mergecmd . MergeCmd . merge ( effective_cwd , ElementPath ( elem ), self . root_dir ) plan . execute () except Exception as e : raise TrestleError ( f 'Error in merging model: { e } ' ) logger . debug ( f 'Model { self . model_name } merged successfully.' ) return success def validate ( self ) -> bool : \"\"\"Validate OSCAL model in repository.\"\"\" logger . debug ( f 'Validating model { self . model_name } .' ) repo = Repository ( self . root_dir ) success = repo . validate_model ( self . model_type , self . model_name ) return success Methods \u00a4 __init__ ( self , root_dir , model_type , name ) special \u00a4 Initialize repository OSCAL model object. Source code in trestle/core/repository.py def __init__ ( self , root_dir : pathlib . Path , model_type : Type [ OscalBaseModel ], name : str ) -> None : \"\"\"Initialize repository OSCAL model object.\"\"\" if not file_utils . is_valid_project_root ( root_dir ): raise TrestleError ( f 'Provided root directory { str ( root_dir ) } is not a valid Trestle root directory.' ) self . root_dir = root_dir self . model_type = model_type self . model_name = name # set model alais and dir self . model_alias = classname_to_alias ( self . model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( self . model_alias ) is None : raise TrestleError ( f 'Given model { self . model_alias } is not a top level model.' ) plural_path = ModelUtils . model_type_to_model_dir ( self . model_alias ) self . model_dir = self . root_dir / plural_path / self . model_name if not self . model_dir . exists () or not self . model_dir . is_dir (): raise TrestleError ( f 'Model dir { self . model_name } does not exist.' ) file_content_type = FileContentType . path_to_content_type ( self . model_dir / self . model_alias ) if file_content_type == FileContentType . UNKNOWN : raise TrestleError ( f 'Model file for model { self . model_name } does not exist.' ) self . file_content_type = file_content_type filepath = pathlib . Path ( self . model_dir , self . model_alias + FileContentType . path_to_file_extension ( self . model_dir / self . model_alias ) ) self . filepath = filepath merge ( self , elements , parent_model_dir = None ) \u00a4 Merge OSCAL elements in repository. The parent_model_dir specifies the parent model direcotry in which to merge relative to main model dir. For example, if we have to merge 'metadata.*' into 'metadata' then parent_model_dir should be the 'catalog' dir that contains the 'metadata.json' file or the 'metadata' directory Source code in trestle/core/repository.py def merge ( self , elements : List [ str ], parent_model_dir : Optional [ pathlib . Path ] = None ) -> bool : \"\"\"Merge OSCAL elements in repository. The parent_model_dir specifies the parent model direcotry in which to merge relative to main model dir. For example, if we have to merge 'metadata.*' into 'metadata' then parent_model_dir should be the 'catalog' dir that contains the 'metadata.json' file or the 'metadata' directory \"\"\" logger . debug ( f 'Merging model { self . model_name } , parent dir { parent_model_dir } .' ) if parent_model_dir is None : effective_cwd = self . model_dir else : effective_cwd = self . model_dir / parent_model_dir success = True try : for elem in elements : plan = mergecmd . MergeCmd . merge ( effective_cwd , ElementPath ( elem ), self . root_dir ) plan . execute () except Exception as e : raise TrestleError ( f 'Error in merging model: { e } ' ) logger . debug ( f 'Model { self . model_name } merged successfully.' ) return success read ( self ) \u00a4 Read OSCAL model from repository. Source code in trestle/core/repository.py def read ( self ) -> OscalBaseModel : \"\"\"Read OSCAL model from repository.\"\"\" logger . debug ( f 'Reading model { self . model_name } .' ) _ , _ , model = ModelUtils . load_distributed ( self . filepath , self . root_dir ) return model split ( self , model_file , elements ) \u00a4 Split the given OSCAL model file in repository. Model file path should be relative to the main model directory, e.g., model dir is $TRESTLE_ROOT/catalogs/NIST then model file path can be 'catalog/metadata.json' if metadata is to be split. Elements should be specified relative to model file, e.g., 'metadata.props.*' Source code in trestle/core/repository.py def split ( self , model_file : pathlib . Path , elements : List [ str ]) -> bool : \"\"\"Split the given OSCAL model file in repository. Model file path should be relative to the main model directory, e.g., model dir is $TRESTLE_ROOT/catalogs/NIST then model file path can be 'catalog/metadata.json' if metadata is to be split. Elements should be specified relative to model file, e.g., 'metadata.props.*' \"\"\" logger . debug ( f 'Splitting model { self . model_name } , file { model_file } .' ) # input model_file should be relative to the model dir model_file_path = self . model_dir / model_file model_file_path = model_file_path . resolve () file_parent = model_file_path . parent filename = model_file_path . name elems = '' first = True for elem in elements : if first : elems = elem first = False else : elems = elems + ',' + elem success = False try : ret = splitcmd . SplitCmd () . perform_split ( file_parent , filename , elems , self . root_dir ) if ret == 0 : success = True except Exception as e : raise TrestleError ( f 'Error in splitting model: { e } ' ) logger . debug ( f 'Model { self . model_name } , file { model_file } splitted successfully.' ) return success validate ( self ) \u00a4 Validate OSCAL model in repository. Source code in trestle/core/repository.py def validate ( self ) -> bool : \"\"\"Validate OSCAL model in repository.\"\"\" logger . debug ( f 'Validating model { self . model_name } .' ) repo = Repository ( self . root_dir ) success = repo . validate_model ( self . model_type , self . model_name ) return success write ( self , model ) \u00a4 Write OSCAL model to repository. Source code in trestle/core/repository.py def write ( self , model : OscalBaseModel ) -> bool : \"\"\"Write OSCAL model to repository.\"\"\" logger . debug ( f 'Writing model { self . model_name } .' ) model_alias = classname_to_alias ( model . __class__ . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) # split directory if the model was split split_dir = pathlib . Path ( self . model_dir , self . model_alias ) # Prepare actions; delete split model dir if any, recreate model file, and write to filepath top_element = Element ( model ) remove_action = RemovePathAction ( split_dir ) create_action = CreatePathAction ( self . filepath , True ) write_action = WriteFileAction ( self . filepath , top_element , self . file_content_type ) # create a plan to create the directory and imported file. import_plan = Plan () import_plan . add_action ( remove_action ) import_plan . add_action ( create_action ) import_plan . add_action ( write_action ) import_plan . execute () logger . debug ( f 'Model { self . model_name } written to repository' ) return True Repository \u00a4 Repository class for performing operations on Trestle repository. This class provides a set of APIs to perform operations on trestle repository programmatically rather than using the command line. It takes the trestle root directory as input while creating an instance of this object. Operations such as import and get model return a ManagedOSCAL object representing the specific model that can be used to perform operations on the specific models. Source code in trestle/core/repository.py class Repository : \"\"\"Repository class for performing operations on Trestle repository. This class provides a set of APIs to perform operations on trestle repository programmatically rather than using the command line. It takes the trestle root directory as input while creating an instance of this object. Operations such as import and get model return a ManagedOSCAL object representing the specific model that can be used to perform operations on the specific models. \"\"\" def __init__ ( self , root_dir : pathlib . Path ) -> None : \"\"\"Initialize trestle repository object.\"\"\" if not file_utils . is_valid_project_root ( root_dir ): raise TrestleError ( f 'Provided root directory { root_dir } is not a valid Trestle root directory.' ) self . root_dir = root_dir def import_model ( self , model : OscalBaseModel , name : str , content_type = 'json' ) -> ManagedOSCAL : \"\"\"Import OSCAL object into trestle repository.\"\"\" logger . debug ( f 'Importing model { name } of type { model . __class__ . __name__ } .' ) model_alias = classname_to_alias ( model . __class__ . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) # Work out output directory and file plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) desired_model_dir = self . root_dir / plural_path desired_model_path = desired_model_dir / name / ( model_alias + '.' + content_type ) desired_model_path = desired_model_path . resolve () if desired_model_path . exists (): raise TrestleError ( f 'OSCAL file to be created here: { desired_model_path } exists.' ) content_type = FileContentType . to_content_type ( pathlib . Path ( desired_model_path ) . suffix ) # Prepare actions top_element = Element ( model ) create_action = CreatePathAction ( desired_model_path , True ) write_action = WriteFileAction ( desired_model_path , top_element , content_type ) # create a plan to create the directory and imported file. import_plan = Plan () import_plan . add_action ( create_action ) import_plan . add_action ( write_action ) import_plan . execute () # Validate the imported file, rollback if unsuccessful success = False errmsg = '' try : success = self . validate_model ( model . __class__ , name ) if not success : errmsg = f 'Validation of model { name } did not pass' logger . error ( errmsg ) except Exception as err : logger . error ( errmsg ) errmsg = f 'Import of model { name } failed. Validation failed with error: { err } ' if not success : # rollback in case of validation error or failure logger . debug ( f 'Rolling back import of model { name } to { desired_model_path } ' ) try : import_plan . rollback () except TrestleError as err : logger . error ( f 'Failed to rollback: { err } . Remove { desired_model_path } to resolve state.' ) else : logger . debug ( f 'Successful rollback of import to { desired_model_path } ' ) # raise trestle error raise TrestleError ( errmsg ) # all well; model was imported and validated successfully logger . debug ( f 'Model { name } of type { model . __class__ . __name__ } imported successfully.' ) return ManagedOSCAL ( self . root_dir , model . __class__ , name ) def load_and_import_model ( self , model_path : pathlib . Path , name : str , content_type = 'json' ) -> ManagedOSCAL : \"\"\"Load the model at the specified path into trestle with the specified name.\"\"\" fetcher = cache . FetcherFactory . get_fetcher ( self . root_dir , str ( model_path )) model , _ = fetcher . get_oscal ( True ) return self . import_model ( model , name , content_type ) def list_models ( self , model_type : Type [ OscalBaseModel ]) -> List [ str ]: \"\"\"List models of a given type in trestle repository.\"\"\" logger . debug ( f 'Listing models of type { model_type . __name__ } .' ) model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) models = ModelUtils . get_models_of_type ( model_alias , self . root_dir ) return models def get_model ( self , model_type : Type [ OscalBaseModel ], name : str ) -> ManagedOSCAL : \"\"\"Get a specific OSCAL model from repository.\"\"\" logger . debug ( f 'Getting model { name } of type { model_type . __name__ } .' ) model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) desired_model_dir = self . root_dir / plural_path / name if not desired_model_dir . exists () or not desired_model_dir . is_dir (): raise TrestleError ( f 'Model { name } does not exist.' ) return ManagedOSCAL ( self . root_dir , model_type , name ) def delete_model ( self , model_type : Type [ OscalBaseModel ], name : str ) -> bool : \"\"\"Delete an OSCAL model from repository.\"\"\" logger . debug ( f 'Deleting model { name } of type { model_type . __name__ } .' ) model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) desired_model_dir = self . root_dir / plural_path / name if not desired_model_dir . exists () or not desired_model_dir . is_dir (): raise TrestleError ( f 'Model { name } does not exist.' ) shutil . rmtree ( desired_model_dir ) # remove model from dist directory if it exists dist_model_dir = self . root_dir / const . TRESTLE_DIST_DIR / plural_path file_content_type = FileContentType . path_to_content_type ( dist_model_dir / name ) if file_content_type != FileContentType . UNKNOWN : file_path = pathlib . Path ( dist_model_dir , name + FileContentType . path_to_file_extension ( dist_model_dir / name ) ) logger . debug ( f 'Deleting model { name } from dist directory.' ) os . remove ( file_path ) logger . debug ( f 'Model { name } deleted successfully.' ) return True def assemble_model ( self , model_type : Type [ OscalBaseModel ], name : str , extension = 'json' ) -> bool : \"\"\"Assemble an OSCAL model in repository and publish it to 'dist' directory.\"\"\" logger . debug ( f 'Assembling model { name } of type { model_type . __name__ } .' ) success = False model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) verbose = log . get_current_verbosity_level ( logger ) args = argparse . Namespace ( type = model_alias , name = name , extension = extension , trestle_root = self . root_dir , verbose = verbose ) try : ret = assemblecmd . AssembleCmd () . assemble_model ( model_alias , args ) if ret == 0 : success = True except Exception as e : raise TrestleError ( f 'Error in assembling model: { e } ' ) logger . debug ( f 'Model { name } assembled successfully.' ) return success def validate_model ( self , model_type : Type [ OscalBaseModel ], name : str ) -> bool : \"\"\"Validate an OSCAL model in repository.\"\"\" logger . debug ( f 'Validating model { name } of type { model_type . __name__ } .' ) success = False model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) verbose = log . get_current_verbosity_level ( logger ) args = argparse . Namespace ( type = model_alias , name = name , trestle_root = self . root_dir , verbose = verbose ) try : ret = validatecmd . ValidateCmd () . _run ( args ) if ret == 0 : success = True except Exception as e : raise TrestleError ( f 'Error in validating model: { e } ' ) logger . debug ( f 'Model { name } validated successfully.' ) return success Methods \u00a4 __init__ ( self , root_dir ) special \u00a4 Initialize trestle repository object. Source code in trestle/core/repository.py def __init__ ( self , root_dir : pathlib . Path ) -> None : \"\"\"Initialize trestle repository object.\"\"\" if not file_utils . is_valid_project_root ( root_dir ): raise TrestleError ( f 'Provided root directory { root_dir } is not a valid Trestle root directory.' ) self . root_dir = root_dir assemble_model ( self , model_type , name , extension = 'json' ) \u00a4 Assemble an OSCAL model in repository and publish it to 'dist' directory. Source code in trestle/core/repository.py def assemble_model ( self , model_type : Type [ OscalBaseModel ], name : str , extension = 'json' ) -> bool : \"\"\"Assemble an OSCAL model in repository and publish it to 'dist' directory.\"\"\" logger . debug ( f 'Assembling model { name } of type { model_type . __name__ } .' ) success = False model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) verbose = log . get_current_verbosity_level ( logger ) args = argparse . Namespace ( type = model_alias , name = name , extension = extension , trestle_root = self . root_dir , verbose = verbose ) try : ret = assemblecmd . AssembleCmd () . assemble_model ( model_alias , args ) if ret == 0 : success = True except Exception as e : raise TrestleError ( f 'Error in assembling model: { e } ' ) logger . debug ( f 'Model { name } assembled successfully.' ) return success delete_model ( self , model_type , name ) \u00a4 Delete an OSCAL model from repository. Source code in trestle/core/repository.py def delete_model ( self , model_type : Type [ OscalBaseModel ], name : str ) -> bool : \"\"\"Delete an OSCAL model from repository.\"\"\" logger . debug ( f 'Deleting model { name } of type { model_type . __name__ } .' ) model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) desired_model_dir = self . root_dir / plural_path / name if not desired_model_dir . exists () or not desired_model_dir . is_dir (): raise TrestleError ( f 'Model { name } does not exist.' ) shutil . rmtree ( desired_model_dir ) # remove model from dist directory if it exists dist_model_dir = self . root_dir / const . TRESTLE_DIST_DIR / plural_path file_content_type = FileContentType . path_to_content_type ( dist_model_dir / name ) if file_content_type != FileContentType . UNKNOWN : file_path = pathlib . Path ( dist_model_dir , name + FileContentType . path_to_file_extension ( dist_model_dir / name ) ) logger . debug ( f 'Deleting model { name } from dist directory.' ) os . remove ( file_path ) logger . debug ( f 'Model { name } deleted successfully.' ) return True get_model ( self , model_type , name ) \u00a4 Get a specific OSCAL model from repository. Source code in trestle/core/repository.py def get_model ( self , model_type : Type [ OscalBaseModel ], name : str ) -> ManagedOSCAL : \"\"\"Get a specific OSCAL model from repository.\"\"\" logger . debug ( f 'Getting model { name } of type { model_type . __name__ } .' ) model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) desired_model_dir = self . root_dir / plural_path / name if not desired_model_dir . exists () or not desired_model_dir . is_dir (): raise TrestleError ( f 'Model { name } does not exist.' ) return ManagedOSCAL ( self . root_dir , model_type , name ) import_model ( self , model , name , content_type = 'json' ) \u00a4 Import OSCAL object into trestle repository. Source code in trestle/core/repository.py def import_model ( self , model : OscalBaseModel , name : str , content_type = 'json' ) -> ManagedOSCAL : \"\"\"Import OSCAL object into trestle repository.\"\"\" logger . debug ( f 'Importing model { name } of type { model . __class__ . __name__ } .' ) model_alias = classname_to_alias ( model . __class__ . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) # Work out output directory and file plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) desired_model_dir = self . root_dir / plural_path desired_model_path = desired_model_dir / name / ( model_alias + '.' + content_type ) desired_model_path = desired_model_path . resolve () if desired_model_path . exists (): raise TrestleError ( f 'OSCAL file to be created here: { desired_model_path } exists.' ) content_type = FileContentType . to_content_type ( pathlib . Path ( desired_model_path ) . suffix ) # Prepare actions top_element = Element ( model ) create_action = CreatePathAction ( desired_model_path , True ) write_action = WriteFileAction ( desired_model_path , top_element , content_type ) # create a plan to create the directory and imported file. import_plan = Plan () import_plan . add_action ( create_action ) import_plan . add_action ( write_action ) import_plan . execute () # Validate the imported file, rollback if unsuccessful success = False errmsg = '' try : success = self . validate_model ( model . __class__ , name ) if not success : errmsg = f 'Validation of model { name } did not pass' logger . error ( errmsg ) except Exception as err : logger . error ( errmsg ) errmsg = f 'Import of model { name } failed. Validation failed with error: { err } ' if not success : # rollback in case of validation error or failure logger . debug ( f 'Rolling back import of model { name } to { desired_model_path } ' ) try : import_plan . rollback () except TrestleError as err : logger . error ( f 'Failed to rollback: { err } . Remove { desired_model_path } to resolve state.' ) else : logger . debug ( f 'Successful rollback of import to { desired_model_path } ' ) # raise trestle error raise TrestleError ( errmsg ) # all well; model was imported and validated successfully logger . debug ( f 'Model { name } of type { model . __class__ . __name__ } imported successfully.' ) return ManagedOSCAL ( self . root_dir , model . __class__ , name ) list_models ( self , model_type ) \u00a4 List models of a given type in trestle repository. Source code in trestle/core/repository.py def list_models ( self , model_type : Type [ OscalBaseModel ]) -> List [ str ]: \"\"\"List models of a given type in trestle repository.\"\"\" logger . debug ( f 'Listing models of type { model_type . __name__ } .' ) model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) models = ModelUtils . get_models_of_type ( model_alias , self . root_dir ) return models load_and_import_model ( self , model_path , name , content_type = 'json' ) \u00a4 Load the model at the specified path into trestle with the specified name. Source code in trestle/core/repository.py def load_and_import_model ( self , model_path : pathlib . Path , name : str , content_type = 'json' ) -> ManagedOSCAL : \"\"\"Load the model at the specified path into trestle with the specified name.\"\"\" fetcher = cache . FetcherFactory . get_fetcher ( self . root_dir , str ( model_path )) model , _ = fetcher . get_oscal ( True ) return self . import_model ( model , name , content_type ) validate_model ( self , model_type , name ) \u00a4 Validate an OSCAL model in repository. Source code in trestle/core/repository.py def validate_model ( self , model_type : Type [ OscalBaseModel ], name : str ) -> bool : \"\"\"Validate an OSCAL model in repository.\"\"\" logger . debug ( f 'Validating model { name } of type { model_type . __name__ } .' ) success = False model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) verbose = log . get_current_verbosity_level ( logger ) args = argparse . Namespace ( type = model_alias , name = name , trestle_root = self . root_dir , verbose = verbose ) try : ret = validatecmd . ValidateCmd () . _run ( args ) if ret == 0 : success = True except Exception as e : raise TrestleError ( f 'Error in validating model: { e } ' ) logger . debug ( f 'Model { name } validated successfully.' ) return success handler: python","title":"repository"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository","text":"Trestle Repository APIs.","title":"repository"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.ManagedOSCAL","text":"Object representing OSCAL models in repository for programmatic manipulation. Source code in trestle/core/repository.py class ManagedOSCAL : \"\"\"Object representing OSCAL models in repository for programmatic manipulation.\"\"\" def __init__ ( self , root_dir : pathlib . Path , model_type : Type [ OscalBaseModel ], name : str ) -> None : \"\"\"Initialize repository OSCAL model object.\"\"\" if not file_utils . is_valid_project_root ( root_dir ): raise TrestleError ( f 'Provided root directory { str ( root_dir ) } is not a valid Trestle root directory.' ) self . root_dir = root_dir self . model_type = model_type self . model_name = name # set model alais and dir self . model_alias = classname_to_alias ( self . model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( self . model_alias ) is None : raise TrestleError ( f 'Given model { self . model_alias } is not a top level model.' ) plural_path = ModelUtils . model_type_to_model_dir ( self . model_alias ) self . model_dir = self . root_dir / plural_path / self . model_name if not self . model_dir . exists () or not self . model_dir . is_dir (): raise TrestleError ( f 'Model dir { self . model_name } does not exist.' ) file_content_type = FileContentType . path_to_content_type ( self . model_dir / self . model_alias ) if file_content_type == FileContentType . UNKNOWN : raise TrestleError ( f 'Model file for model { self . model_name } does not exist.' ) self . file_content_type = file_content_type filepath = pathlib . Path ( self . model_dir , self . model_alias + FileContentType . path_to_file_extension ( self . model_dir / self . model_alias ) ) self . filepath = filepath def read ( self ) -> OscalBaseModel : \"\"\"Read OSCAL model from repository.\"\"\" logger . debug ( f 'Reading model { self . model_name } .' ) _ , _ , model = ModelUtils . load_distributed ( self . filepath , self . root_dir ) return model def write ( self , model : OscalBaseModel ) -> bool : \"\"\"Write OSCAL model to repository.\"\"\" logger . debug ( f 'Writing model { self . model_name } .' ) model_alias = classname_to_alias ( model . __class__ . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) # split directory if the model was split split_dir = pathlib . Path ( self . model_dir , self . model_alias ) # Prepare actions; delete split model dir if any, recreate model file, and write to filepath top_element = Element ( model ) remove_action = RemovePathAction ( split_dir ) create_action = CreatePathAction ( self . filepath , True ) write_action = WriteFileAction ( self . filepath , top_element , self . file_content_type ) # create a plan to create the directory and imported file. import_plan = Plan () import_plan . add_action ( remove_action ) import_plan . add_action ( create_action ) import_plan . add_action ( write_action ) import_plan . execute () logger . debug ( f 'Model { self . model_name } written to repository' ) return True def split ( self , model_file : pathlib . Path , elements : List [ str ]) -> bool : \"\"\"Split the given OSCAL model file in repository. Model file path should be relative to the main model directory, e.g., model dir is $TRESTLE_ROOT/catalogs/NIST then model file path can be 'catalog/metadata.json' if metadata is to be split. Elements should be specified relative to model file, e.g., 'metadata.props.*' \"\"\" logger . debug ( f 'Splitting model { self . model_name } , file { model_file } .' ) # input model_file should be relative to the model dir model_file_path = self . model_dir / model_file model_file_path = model_file_path . resolve () file_parent = model_file_path . parent filename = model_file_path . name elems = '' first = True for elem in elements : if first : elems = elem first = False else : elems = elems + ',' + elem success = False try : ret = splitcmd . SplitCmd () . perform_split ( file_parent , filename , elems , self . root_dir ) if ret == 0 : success = True except Exception as e : raise TrestleError ( f 'Error in splitting model: { e } ' ) logger . debug ( f 'Model { self . model_name } , file { model_file } splitted successfully.' ) return success def merge ( self , elements : List [ str ], parent_model_dir : Optional [ pathlib . Path ] = None ) -> bool : \"\"\"Merge OSCAL elements in repository. The parent_model_dir specifies the parent model direcotry in which to merge relative to main model dir. For example, if we have to merge 'metadata.*' into 'metadata' then parent_model_dir should be the 'catalog' dir that contains the 'metadata.json' file or the 'metadata' directory \"\"\" logger . debug ( f 'Merging model { self . model_name } , parent dir { parent_model_dir } .' ) if parent_model_dir is None : effective_cwd = self . model_dir else : effective_cwd = self . model_dir / parent_model_dir success = True try : for elem in elements : plan = mergecmd . MergeCmd . merge ( effective_cwd , ElementPath ( elem ), self . root_dir ) plan . execute () except Exception as e : raise TrestleError ( f 'Error in merging model: { e } ' ) logger . debug ( f 'Model { self . model_name } merged successfully.' ) return success def validate ( self ) -> bool : \"\"\"Validate OSCAL model in repository.\"\"\" logger . debug ( f 'Validating model { self . model_name } .' ) repo = Repository ( self . root_dir ) success = repo . validate_model ( self . model_type , self . model_name ) return success","title":"ManagedOSCAL"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.ManagedOSCAL-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.ManagedOSCAL.__init__","text":"Initialize repository OSCAL model object. Source code in trestle/core/repository.py def __init__ ( self , root_dir : pathlib . Path , model_type : Type [ OscalBaseModel ], name : str ) -> None : \"\"\"Initialize repository OSCAL model object.\"\"\" if not file_utils . is_valid_project_root ( root_dir ): raise TrestleError ( f 'Provided root directory { str ( root_dir ) } is not a valid Trestle root directory.' ) self . root_dir = root_dir self . model_type = model_type self . model_name = name # set model alais and dir self . model_alias = classname_to_alias ( self . model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( self . model_alias ) is None : raise TrestleError ( f 'Given model { self . model_alias } is not a top level model.' ) plural_path = ModelUtils . model_type_to_model_dir ( self . model_alias ) self . model_dir = self . root_dir / plural_path / self . model_name if not self . model_dir . exists () or not self . model_dir . is_dir (): raise TrestleError ( f 'Model dir { self . model_name } does not exist.' ) file_content_type = FileContentType . path_to_content_type ( self . model_dir / self . model_alias ) if file_content_type == FileContentType . UNKNOWN : raise TrestleError ( f 'Model file for model { self . model_name } does not exist.' ) self . file_content_type = file_content_type filepath = pathlib . Path ( self . model_dir , self . model_alias + FileContentType . path_to_file_extension ( self . model_dir / self . model_alias ) ) self . filepath = filepath","title":"__init__()"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.ManagedOSCAL.merge","text":"Merge OSCAL elements in repository. The parent_model_dir specifies the parent model direcotry in which to merge relative to main model dir. For example, if we have to merge 'metadata.*' into 'metadata' then parent_model_dir should be the 'catalog' dir that contains the 'metadata.json' file or the 'metadata' directory Source code in trestle/core/repository.py def merge ( self , elements : List [ str ], parent_model_dir : Optional [ pathlib . Path ] = None ) -> bool : \"\"\"Merge OSCAL elements in repository. The parent_model_dir specifies the parent model direcotry in which to merge relative to main model dir. For example, if we have to merge 'metadata.*' into 'metadata' then parent_model_dir should be the 'catalog' dir that contains the 'metadata.json' file or the 'metadata' directory \"\"\" logger . debug ( f 'Merging model { self . model_name } , parent dir { parent_model_dir } .' ) if parent_model_dir is None : effective_cwd = self . model_dir else : effective_cwd = self . model_dir / parent_model_dir success = True try : for elem in elements : plan = mergecmd . MergeCmd . merge ( effective_cwd , ElementPath ( elem ), self . root_dir ) plan . execute () except Exception as e : raise TrestleError ( f 'Error in merging model: { e } ' ) logger . debug ( f 'Model { self . model_name } merged successfully.' ) return success","title":"merge()"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.ManagedOSCAL.read","text":"Read OSCAL model from repository. Source code in trestle/core/repository.py def read ( self ) -> OscalBaseModel : \"\"\"Read OSCAL model from repository.\"\"\" logger . debug ( f 'Reading model { self . model_name } .' ) _ , _ , model = ModelUtils . load_distributed ( self . filepath , self . root_dir ) return model","title":"read()"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.ManagedOSCAL.split","text":"Split the given OSCAL model file in repository. Model file path should be relative to the main model directory, e.g., model dir is $TRESTLE_ROOT/catalogs/NIST then model file path can be 'catalog/metadata.json' if metadata is to be split. Elements should be specified relative to model file, e.g., 'metadata.props.*' Source code in trestle/core/repository.py def split ( self , model_file : pathlib . Path , elements : List [ str ]) -> bool : \"\"\"Split the given OSCAL model file in repository. Model file path should be relative to the main model directory, e.g., model dir is $TRESTLE_ROOT/catalogs/NIST then model file path can be 'catalog/metadata.json' if metadata is to be split. Elements should be specified relative to model file, e.g., 'metadata.props.*' \"\"\" logger . debug ( f 'Splitting model { self . model_name } , file { model_file } .' ) # input model_file should be relative to the model dir model_file_path = self . model_dir / model_file model_file_path = model_file_path . resolve () file_parent = model_file_path . parent filename = model_file_path . name elems = '' first = True for elem in elements : if first : elems = elem first = False else : elems = elems + ',' + elem success = False try : ret = splitcmd . SplitCmd () . perform_split ( file_parent , filename , elems , self . root_dir ) if ret == 0 : success = True except Exception as e : raise TrestleError ( f 'Error in splitting model: { e } ' ) logger . debug ( f 'Model { self . model_name } , file { model_file } splitted successfully.' ) return success","title":"split()"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.ManagedOSCAL.validate","text":"Validate OSCAL model in repository. Source code in trestle/core/repository.py def validate ( self ) -> bool : \"\"\"Validate OSCAL model in repository.\"\"\" logger . debug ( f 'Validating model { self . model_name } .' ) repo = Repository ( self . root_dir ) success = repo . validate_model ( self . model_type , self . model_name ) return success","title":"validate()"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.ManagedOSCAL.write","text":"Write OSCAL model to repository. Source code in trestle/core/repository.py def write ( self , model : OscalBaseModel ) -> bool : \"\"\"Write OSCAL model to repository.\"\"\" logger . debug ( f 'Writing model { self . model_name } .' ) model_alias = classname_to_alias ( model . __class__ . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) # split directory if the model was split split_dir = pathlib . Path ( self . model_dir , self . model_alias ) # Prepare actions; delete split model dir if any, recreate model file, and write to filepath top_element = Element ( model ) remove_action = RemovePathAction ( split_dir ) create_action = CreatePathAction ( self . filepath , True ) write_action = WriteFileAction ( self . filepath , top_element , self . file_content_type ) # create a plan to create the directory and imported file. import_plan = Plan () import_plan . add_action ( remove_action ) import_plan . add_action ( create_action ) import_plan . add_action ( write_action ) import_plan . execute () logger . debug ( f 'Model { self . model_name } written to repository' ) return True","title":"write()"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.Repository","text":"Repository class for performing operations on Trestle repository. This class provides a set of APIs to perform operations on trestle repository programmatically rather than using the command line. It takes the trestle root directory as input while creating an instance of this object. Operations such as import and get model return a ManagedOSCAL object representing the specific model that can be used to perform operations on the specific models. Source code in trestle/core/repository.py class Repository : \"\"\"Repository class for performing operations on Trestle repository. This class provides a set of APIs to perform operations on trestle repository programmatically rather than using the command line. It takes the trestle root directory as input while creating an instance of this object. Operations such as import and get model return a ManagedOSCAL object representing the specific model that can be used to perform operations on the specific models. \"\"\" def __init__ ( self , root_dir : pathlib . Path ) -> None : \"\"\"Initialize trestle repository object.\"\"\" if not file_utils . is_valid_project_root ( root_dir ): raise TrestleError ( f 'Provided root directory { root_dir } is not a valid Trestle root directory.' ) self . root_dir = root_dir def import_model ( self , model : OscalBaseModel , name : str , content_type = 'json' ) -> ManagedOSCAL : \"\"\"Import OSCAL object into trestle repository.\"\"\" logger . debug ( f 'Importing model { name } of type { model . __class__ . __name__ } .' ) model_alias = classname_to_alias ( model . __class__ . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) # Work out output directory and file plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) desired_model_dir = self . root_dir / plural_path desired_model_path = desired_model_dir / name / ( model_alias + '.' + content_type ) desired_model_path = desired_model_path . resolve () if desired_model_path . exists (): raise TrestleError ( f 'OSCAL file to be created here: { desired_model_path } exists.' ) content_type = FileContentType . to_content_type ( pathlib . Path ( desired_model_path ) . suffix ) # Prepare actions top_element = Element ( model ) create_action = CreatePathAction ( desired_model_path , True ) write_action = WriteFileAction ( desired_model_path , top_element , content_type ) # create a plan to create the directory and imported file. import_plan = Plan () import_plan . add_action ( create_action ) import_plan . add_action ( write_action ) import_plan . execute () # Validate the imported file, rollback if unsuccessful success = False errmsg = '' try : success = self . validate_model ( model . __class__ , name ) if not success : errmsg = f 'Validation of model { name } did not pass' logger . error ( errmsg ) except Exception as err : logger . error ( errmsg ) errmsg = f 'Import of model { name } failed. Validation failed with error: { err } ' if not success : # rollback in case of validation error or failure logger . debug ( f 'Rolling back import of model { name } to { desired_model_path } ' ) try : import_plan . rollback () except TrestleError as err : logger . error ( f 'Failed to rollback: { err } . Remove { desired_model_path } to resolve state.' ) else : logger . debug ( f 'Successful rollback of import to { desired_model_path } ' ) # raise trestle error raise TrestleError ( errmsg ) # all well; model was imported and validated successfully logger . debug ( f 'Model { name } of type { model . __class__ . __name__ } imported successfully.' ) return ManagedOSCAL ( self . root_dir , model . __class__ , name ) def load_and_import_model ( self , model_path : pathlib . Path , name : str , content_type = 'json' ) -> ManagedOSCAL : \"\"\"Load the model at the specified path into trestle with the specified name.\"\"\" fetcher = cache . FetcherFactory . get_fetcher ( self . root_dir , str ( model_path )) model , _ = fetcher . get_oscal ( True ) return self . import_model ( model , name , content_type ) def list_models ( self , model_type : Type [ OscalBaseModel ]) -> List [ str ]: \"\"\"List models of a given type in trestle repository.\"\"\" logger . debug ( f 'Listing models of type { model_type . __name__ } .' ) model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) models = ModelUtils . get_models_of_type ( model_alias , self . root_dir ) return models def get_model ( self , model_type : Type [ OscalBaseModel ], name : str ) -> ManagedOSCAL : \"\"\"Get a specific OSCAL model from repository.\"\"\" logger . debug ( f 'Getting model { name } of type { model_type . __name__ } .' ) model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) desired_model_dir = self . root_dir / plural_path / name if not desired_model_dir . exists () or not desired_model_dir . is_dir (): raise TrestleError ( f 'Model { name } does not exist.' ) return ManagedOSCAL ( self . root_dir , model_type , name ) def delete_model ( self , model_type : Type [ OscalBaseModel ], name : str ) -> bool : \"\"\"Delete an OSCAL model from repository.\"\"\" logger . debug ( f 'Deleting model { name } of type { model_type . __name__ } .' ) model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) desired_model_dir = self . root_dir / plural_path / name if not desired_model_dir . exists () or not desired_model_dir . is_dir (): raise TrestleError ( f 'Model { name } does not exist.' ) shutil . rmtree ( desired_model_dir ) # remove model from dist directory if it exists dist_model_dir = self . root_dir / const . TRESTLE_DIST_DIR / plural_path file_content_type = FileContentType . path_to_content_type ( dist_model_dir / name ) if file_content_type != FileContentType . UNKNOWN : file_path = pathlib . Path ( dist_model_dir , name + FileContentType . path_to_file_extension ( dist_model_dir / name ) ) logger . debug ( f 'Deleting model { name } from dist directory.' ) os . remove ( file_path ) logger . debug ( f 'Model { name } deleted successfully.' ) return True def assemble_model ( self , model_type : Type [ OscalBaseModel ], name : str , extension = 'json' ) -> bool : \"\"\"Assemble an OSCAL model in repository and publish it to 'dist' directory.\"\"\" logger . debug ( f 'Assembling model { name } of type { model_type . __name__ } .' ) success = False model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) verbose = log . get_current_verbosity_level ( logger ) args = argparse . Namespace ( type = model_alias , name = name , extension = extension , trestle_root = self . root_dir , verbose = verbose ) try : ret = assemblecmd . AssembleCmd () . assemble_model ( model_alias , args ) if ret == 0 : success = True except Exception as e : raise TrestleError ( f 'Error in assembling model: { e } ' ) logger . debug ( f 'Model { name } assembled successfully.' ) return success def validate_model ( self , model_type : Type [ OscalBaseModel ], name : str ) -> bool : \"\"\"Validate an OSCAL model in repository.\"\"\" logger . debug ( f 'Validating model { name } of type { model_type . __name__ } .' ) success = False model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) verbose = log . get_current_verbosity_level ( logger ) args = argparse . Namespace ( type = model_alias , name = name , trestle_root = self . root_dir , verbose = verbose ) try : ret = validatecmd . ValidateCmd () . _run ( args ) if ret == 0 : success = True except Exception as e : raise TrestleError ( f 'Error in validating model: { e } ' ) logger . debug ( f 'Model { name } validated successfully.' ) return success","title":"Repository"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.Repository-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.Repository.__init__","text":"Initialize trestle repository object. Source code in trestle/core/repository.py def __init__ ( self , root_dir : pathlib . Path ) -> None : \"\"\"Initialize trestle repository object.\"\"\" if not file_utils . is_valid_project_root ( root_dir ): raise TrestleError ( f 'Provided root directory { root_dir } is not a valid Trestle root directory.' ) self . root_dir = root_dir","title":"__init__()"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.Repository.assemble_model","text":"Assemble an OSCAL model in repository and publish it to 'dist' directory. Source code in trestle/core/repository.py def assemble_model ( self , model_type : Type [ OscalBaseModel ], name : str , extension = 'json' ) -> bool : \"\"\"Assemble an OSCAL model in repository and publish it to 'dist' directory.\"\"\" logger . debug ( f 'Assembling model { name } of type { model_type . __name__ } .' ) success = False model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) verbose = log . get_current_verbosity_level ( logger ) args = argparse . Namespace ( type = model_alias , name = name , extension = extension , trestle_root = self . root_dir , verbose = verbose ) try : ret = assemblecmd . AssembleCmd () . assemble_model ( model_alias , args ) if ret == 0 : success = True except Exception as e : raise TrestleError ( f 'Error in assembling model: { e } ' ) logger . debug ( f 'Model { name } assembled successfully.' ) return success","title":"assemble_model()"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.Repository.delete_model","text":"Delete an OSCAL model from repository. Source code in trestle/core/repository.py def delete_model ( self , model_type : Type [ OscalBaseModel ], name : str ) -> bool : \"\"\"Delete an OSCAL model from repository.\"\"\" logger . debug ( f 'Deleting model { name } of type { model_type . __name__ } .' ) model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) desired_model_dir = self . root_dir / plural_path / name if not desired_model_dir . exists () or not desired_model_dir . is_dir (): raise TrestleError ( f 'Model { name } does not exist.' ) shutil . rmtree ( desired_model_dir ) # remove model from dist directory if it exists dist_model_dir = self . root_dir / const . TRESTLE_DIST_DIR / plural_path file_content_type = FileContentType . path_to_content_type ( dist_model_dir / name ) if file_content_type != FileContentType . UNKNOWN : file_path = pathlib . Path ( dist_model_dir , name + FileContentType . path_to_file_extension ( dist_model_dir / name ) ) logger . debug ( f 'Deleting model { name } from dist directory.' ) os . remove ( file_path ) logger . debug ( f 'Model { name } deleted successfully.' ) return True","title":"delete_model()"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.Repository.get_model","text":"Get a specific OSCAL model from repository. Source code in trestle/core/repository.py def get_model ( self , model_type : Type [ OscalBaseModel ], name : str ) -> ManagedOSCAL : \"\"\"Get a specific OSCAL model from repository.\"\"\" logger . debug ( f 'Getting model { name } of type { model_type . __name__ } .' ) model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) desired_model_dir = self . root_dir / plural_path / name if not desired_model_dir . exists () or not desired_model_dir . is_dir (): raise TrestleError ( f 'Model { name } does not exist.' ) return ManagedOSCAL ( self . root_dir , model_type , name )","title":"get_model()"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.Repository.import_model","text":"Import OSCAL object into trestle repository. Source code in trestle/core/repository.py def import_model ( self , model : OscalBaseModel , name : str , content_type = 'json' ) -> ManagedOSCAL : \"\"\"Import OSCAL object into trestle repository.\"\"\" logger . debug ( f 'Importing model { name } of type { model . __class__ . __name__ } .' ) model_alias = classname_to_alias ( model . __class__ . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) # Work out output directory and file plural_path = ModelUtils . model_type_to_model_dir ( model_alias ) desired_model_dir = self . root_dir / plural_path desired_model_path = desired_model_dir / name / ( model_alias + '.' + content_type ) desired_model_path = desired_model_path . resolve () if desired_model_path . exists (): raise TrestleError ( f 'OSCAL file to be created here: { desired_model_path } exists.' ) content_type = FileContentType . to_content_type ( pathlib . Path ( desired_model_path ) . suffix ) # Prepare actions top_element = Element ( model ) create_action = CreatePathAction ( desired_model_path , True ) write_action = WriteFileAction ( desired_model_path , top_element , content_type ) # create a plan to create the directory and imported file. import_plan = Plan () import_plan . add_action ( create_action ) import_plan . add_action ( write_action ) import_plan . execute () # Validate the imported file, rollback if unsuccessful success = False errmsg = '' try : success = self . validate_model ( model . __class__ , name ) if not success : errmsg = f 'Validation of model { name } did not pass' logger . error ( errmsg ) except Exception as err : logger . error ( errmsg ) errmsg = f 'Import of model { name } failed. Validation failed with error: { err } ' if not success : # rollback in case of validation error or failure logger . debug ( f 'Rolling back import of model { name } to { desired_model_path } ' ) try : import_plan . rollback () except TrestleError as err : logger . error ( f 'Failed to rollback: { err } . Remove { desired_model_path } to resolve state.' ) else : logger . debug ( f 'Successful rollback of import to { desired_model_path } ' ) # raise trestle error raise TrestleError ( errmsg ) # all well; model was imported and validated successfully logger . debug ( f 'Model { name } of type { model . __class__ . __name__ } imported successfully.' ) return ManagedOSCAL ( self . root_dir , model . __class__ , name )","title":"import_model()"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.Repository.list_models","text":"List models of a given type in trestle repository. Source code in trestle/core/repository.py def list_models ( self , model_type : Type [ OscalBaseModel ]) -> List [ str ]: \"\"\"List models of a given type in trestle repository.\"\"\" logger . debug ( f 'Listing models of type { model_type . __name__ } .' ) model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) models = ModelUtils . get_models_of_type ( model_alias , self . root_dir ) return models","title":"list_models()"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.Repository.load_and_import_model","text":"Load the model at the specified path into trestle with the specified name. Source code in trestle/core/repository.py def load_and_import_model ( self , model_path : pathlib . Path , name : str , content_type = 'json' ) -> ManagedOSCAL : \"\"\"Load the model at the specified path into trestle with the specified name.\"\"\" fetcher = cache . FetcherFactory . get_fetcher ( self . root_dir , str ( model_path )) model , _ = fetcher . get_oscal ( True ) return self . import_model ( model , name , content_type )","title":"load_and_import_model()"},{"location":"api_reference/trestle.core.repository/#trestle.core.repository.Repository.validate_model","text":"Validate an OSCAL model in repository. Source code in trestle/core/repository.py def validate_model ( self , model_type : Type [ OscalBaseModel ], name : str ) -> bool : \"\"\"Validate an OSCAL model in repository.\"\"\" logger . debug ( f 'Validating model { name } of type { model_type . __name__ } .' ) success = False model_alias = classname_to_alias ( model_type . __name__ , AliasMode . JSON ) if parser . to_full_model_name ( model_alias ) is None : raise TrestleError ( f 'Given model { model_alias } is not a top level model.' ) verbose = log . get_current_verbosity_level ( logger ) args = argparse . Namespace ( type = model_alias , name = name , trestle_root = self . root_dir , verbose = verbose ) try : ret = validatecmd . ValidateCmd () . _run ( args ) if ret == 0 : success = True except Exception as e : raise TrestleError ( f 'Error in validating model: { e } ' ) logger . debug ( f 'Model { name } validated successfully.' ) return success handler: python","title":"validate_model()"},{"location":"api_reference/trestle.core.resolver.merge/","text":"trestle.core.resolver.merge \u00a4 Create resolved catalog from profile. CATALOG_EXCLUDE \u00a4 CONTROL_EXCLUDE \u00a4 ID \u00a4 ITEM_EXCLUDE_MAP \u00a4 NAME \u00a4 PARAMETER_EXCLUDE \u00a4 PART_EXCLUDE \u00a4 PROPERTY_EXCLUDE \u00a4 logger \u00a4 Classes \u00a4 Merge ( Filter ) \u00a4 Merge the incoming catalogs according to rules in the profile. The incoming catalogs have already been pruned based on the import. Now the controls must be gathered, merged, and grouped based on the merge settings. Source code in trestle/core/resolver/merge.py class Merge ( Pipeline . Filter ): \"\"\" Merge the incoming catalogs according to rules in the profile. The incoming catalogs have already been pruned based on the import. Now the controls must be gathered, merged, and grouped based on the merge settings. \"\"\" def __init__ ( self , profile : prof . Profile ) -> None : \"\"\"Initialize the class with the profile.\"\"\" logger . debug ( 'merge filter initialize' ) self . _profile = profile def _get_id ( self , item : OBT ) -> Optional [ str ]: id_ = getattr ( item , ID , None ) if id_ is None : id_ = getattr ( item , NAME , None ) return id_ def _merge_lists ( self , dest : List [ OBT ], src : List [ OBT ], merge_method : prof . Method ) -> None : added_items = [] if merge_method == prof . Method . keep : dest . extend ( src ) return for item in src : # if there is an exact copy of this in dest then ignore it if item not in dest : merged = False item_id = self . _get_id ( item ) if item_id is not None : for other in dest : other_id = self . _get_id ( other ) if other_id == item_id : if merge_method == prof . Method . merge : self . _merge_items ( other , item , merge_method ) merged = True break # it isn't already in dest and no match was found for merge, so append if not merged : added_items . append ( item ) dest . extend ( added_items ) def _merge_attrs ( self , dest : Union [ OBT , List [ OBT ]], src : Union [ OBT , List [ OBT ]], attr : str , merge_method : prof . Method ) -> None : \"\"\"Merge this attr of src into the attr of dest.\"\"\" src_attr = getattr ( src , attr , None ) if src_attr is None : return item_type = type ( src ) . __name__ if attr in ITEM_EXCLUDE_MAP . get ( item_type , []): return dest_attr = getattr ( dest , attr , None ) if dest_attr and isinstance ( dest_attr , list ): self . _merge_lists ( dest_attr , src_attr , merge_method ) setattr ( dest , attr , dest_attr ) return if dest_attr and merge_method == prof . Method . use_first : return if dest_attr == src_attr and merge_method != prof . Method . keep : return setattr ( dest , attr , src_attr ) def _merge_items ( self , dest : OBT , src : OBT , merge_method : prof . Method ) -> None : \"\"\"Merge two items recursively.\"\"\" for field in src . __fields_set__ : self . _merge_attrs ( dest , src , field , merge_method ) def _group_contents ( self , group : cat . Group ) -> Tuple [ List [ cat . Control ], List [ common . Parameter ]]: \"\"\"Get flattened content of group and its groups recursively.\"\"\" controls = [] params = [] controls . extend ( as_list ( group . controls )) params . extend ( as_list ( group . params )) if group . groups is not None : for sub_group in group . groups : new_controls , new_params = self . _group_contents ( sub_group ) controls . extend ( new_controls ) params . extend ( new_params ) return controls , params def _flatten_catalog ( self , catalog : cat . Catalog , as_is : bool ) -> cat . Catalog : \"\"\"Flatten the groups of the catalog if as_is is False.\"\"\" if as_is or catalog . groups is None : return catalog # as_is is False so flatten the controls into a single list catalog . controls = as_list ( catalog . controls ) catalog . params = as_list ( catalog . params ) for group in catalog . groups : new_controls , new_params = self . _group_contents ( group ) catalog . controls . extend ( new_controls ) catalog . params . extend ( new_params ) catalog . controls = none_if_empty ( catalog . controls ) catalog . params = none_if_empty ( catalog . params ) catalog . groups = None return catalog def _merge_two_catalogs ( self , dest : cat . Catalog , src : cat . Catalog , merge_method : prof . Method , as_is : bool ) -> cat . Catalog : # merge_method is use_first, merge, or keep # if as_is is false, the result is flattened dest = self . _flatten_catalog ( dest , as_is ) src = self . _flatten_catalog ( src , as_is ) self . _merge_items ( dest , src , merge_method ) return dest def _merge_catalog ( self , merged : Optional [ cat . Catalog ], catalog : cat . Catalog ) -> cat . Catalog : \"\"\"Merge the controls in the catalog into merged catalog.\"\"\" # no merge means keep, including dups # same for merge with no combine # groups are merged only if separate directive such as as-is is given # use-first is a merge combination rule # merge is a merge combination rule for controls. groups are not merged by this rule # merge/as-is and merge/custom are used for merging groups # if neither as-is nor custom is specified - just get single list of controls # unstructured controls should appear after any loose params # make copies to avoid changing input objects local_cat = catalog . copy ( deep = True ) local_merged = merged . copy ( deep = True ) if merged else None merge_method = prof . Method . keep as_is = False if self . _profile . merge is not None : if self . _profile . merge . custom is not None : raise TrestleError ( 'Profile with custom merge is not supported.' ) if self . _profile . merge . as_is is not None : as_is = self . _profile . merge . as_is if self . _profile . merge . combine is None : logger . warning ( 'Profile has merge but no combine so defaulting to combine/merge.' ) merge_method = prof . Method . merge else : merge_combine = self . _profile . merge . combine if merge_combine . method is None : logger . warning ( 'Profile has merge combine but no method. Defaulting to merge.' ) merge_method = prof . Method . merge else : merge_method = merge_combine . method if local_merged is None : return self . _flatten_catalog ( local_cat , as_is ) # merge the incoming catalog with merged based on merge_method and as_is return self . _merge_two_catalogs ( local_merged , local_cat , merge_method , as_is ) def process ( self , pipelines : List [ Pipeline ]) -> Iterator [ cat . Catalog ]: \"\"\" Merge the incoming catalogs. This pulls from import and iterates over the incoming catalogs. The way groups, lists of controls, and controls themselves get merged is specified by the profile. \"\"\" merged : Optional [ cat . Catalog ] = None logger . debug ( f 'merge entering process with { len ( pipelines ) } pipelines' ) for pipeline in pipelines : catalog = next ( pipeline . process ( None )) merged = self . _merge_catalog ( merged , catalog ) yield merged Methods \u00a4 __init__ ( self , profile ) special \u00a4 Initialize the class with the profile. Source code in trestle/core/resolver/merge.py def __init__ ( self , profile : prof . Profile ) -> None : \"\"\"Initialize the class with the profile.\"\"\" logger . debug ( 'merge filter initialize' ) self . _profile = profile process ( self , pipelines ) \u00a4 Merge the incoming catalogs. This pulls from import and iterates over the incoming catalogs. The way groups, lists of controls, and controls themselves get merged is specified by the profile. Source code in trestle/core/resolver/merge.py def process ( self , pipelines : List [ Pipeline ]) -> Iterator [ cat . Catalog ]: \"\"\" Merge the incoming catalogs. This pulls from import and iterates over the incoming catalogs. The way groups, lists of controls, and controls themselves get merged is specified by the profile. \"\"\" merged : Optional [ cat . Catalog ] = None logger . debug ( f 'merge entering process with { len ( pipelines ) } pipelines' ) for pipeline in pipelines : catalog = next ( pipeline . process ( None )) merged = self . _merge_catalog ( merged , catalog ) yield merged handler: python","title":"merge"},{"location":"api_reference/trestle.core.resolver.merge/#trestle.core.resolver.merge","text":"Create resolved catalog from profile.","title":"merge"},{"location":"api_reference/trestle.core.resolver.merge/#trestle.core.resolver.merge.CATALOG_EXCLUDE","text":"","title":"CATALOG_EXCLUDE"},{"location":"api_reference/trestle.core.resolver.merge/#trestle.core.resolver.merge.CONTROL_EXCLUDE","text":"","title":"CONTROL_EXCLUDE"},{"location":"api_reference/trestle.core.resolver.merge/#trestle.core.resolver.merge.ID","text":"","title":"ID"},{"location":"api_reference/trestle.core.resolver.merge/#trestle.core.resolver.merge.ITEM_EXCLUDE_MAP","text":"","title":"ITEM_EXCLUDE_MAP"},{"location":"api_reference/trestle.core.resolver.merge/#trestle.core.resolver.merge.NAME","text":"","title":"NAME"},{"location":"api_reference/trestle.core.resolver.merge/#trestle.core.resolver.merge.PARAMETER_EXCLUDE","text":"","title":"PARAMETER_EXCLUDE"},{"location":"api_reference/trestle.core.resolver.merge/#trestle.core.resolver.merge.PART_EXCLUDE","text":"","title":"PART_EXCLUDE"},{"location":"api_reference/trestle.core.resolver.merge/#trestle.core.resolver.merge.PROPERTY_EXCLUDE","text":"","title":"PROPERTY_EXCLUDE"},{"location":"api_reference/trestle.core.resolver.merge/#trestle.core.resolver.merge.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.resolver.merge/#trestle.core.resolver.merge-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.resolver.merge/#trestle.core.resolver.merge.Merge","text":"Merge the incoming catalogs according to rules in the profile. The incoming catalogs have already been pruned based on the import. Now the controls must be gathered, merged, and grouped based on the merge settings. Source code in trestle/core/resolver/merge.py class Merge ( Pipeline . Filter ): \"\"\" Merge the incoming catalogs according to rules in the profile. The incoming catalogs have already been pruned based on the import. Now the controls must be gathered, merged, and grouped based on the merge settings. \"\"\" def __init__ ( self , profile : prof . Profile ) -> None : \"\"\"Initialize the class with the profile.\"\"\" logger . debug ( 'merge filter initialize' ) self . _profile = profile def _get_id ( self , item : OBT ) -> Optional [ str ]: id_ = getattr ( item , ID , None ) if id_ is None : id_ = getattr ( item , NAME , None ) return id_ def _merge_lists ( self , dest : List [ OBT ], src : List [ OBT ], merge_method : prof . Method ) -> None : added_items = [] if merge_method == prof . Method . keep : dest . extend ( src ) return for item in src : # if there is an exact copy of this in dest then ignore it if item not in dest : merged = False item_id = self . _get_id ( item ) if item_id is not None : for other in dest : other_id = self . _get_id ( other ) if other_id == item_id : if merge_method == prof . Method . merge : self . _merge_items ( other , item , merge_method ) merged = True break # it isn't already in dest and no match was found for merge, so append if not merged : added_items . append ( item ) dest . extend ( added_items ) def _merge_attrs ( self , dest : Union [ OBT , List [ OBT ]], src : Union [ OBT , List [ OBT ]], attr : str , merge_method : prof . Method ) -> None : \"\"\"Merge this attr of src into the attr of dest.\"\"\" src_attr = getattr ( src , attr , None ) if src_attr is None : return item_type = type ( src ) . __name__ if attr in ITEM_EXCLUDE_MAP . get ( item_type , []): return dest_attr = getattr ( dest , attr , None ) if dest_attr and isinstance ( dest_attr , list ): self . _merge_lists ( dest_attr , src_attr , merge_method ) setattr ( dest , attr , dest_attr ) return if dest_attr and merge_method == prof . Method . use_first : return if dest_attr == src_attr and merge_method != prof . Method . keep : return setattr ( dest , attr , src_attr ) def _merge_items ( self , dest : OBT , src : OBT , merge_method : prof . Method ) -> None : \"\"\"Merge two items recursively.\"\"\" for field in src . __fields_set__ : self . _merge_attrs ( dest , src , field , merge_method ) def _group_contents ( self , group : cat . Group ) -> Tuple [ List [ cat . Control ], List [ common . Parameter ]]: \"\"\"Get flattened content of group and its groups recursively.\"\"\" controls = [] params = [] controls . extend ( as_list ( group . controls )) params . extend ( as_list ( group . params )) if group . groups is not None : for sub_group in group . groups : new_controls , new_params = self . _group_contents ( sub_group ) controls . extend ( new_controls ) params . extend ( new_params ) return controls , params def _flatten_catalog ( self , catalog : cat . Catalog , as_is : bool ) -> cat . Catalog : \"\"\"Flatten the groups of the catalog if as_is is False.\"\"\" if as_is or catalog . groups is None : return catalog # as_is is False so flatten the controls into a single list catalog . controls = as_list ( catalog . controls ) catalog . params = as_list ( catalog . params ) for group in catalog . groups : new_controls , new_params = self . _group_contents ( group ) catalog . controls . extend ( new_controls ) catalog . params . extend ( new_params ) catalog . controls = none_if_empty ( catalog . controls ) catalog . params = none_if_empty ( catalog . params ) catalog . groups = None return catalog def _merge_two_catalogs ( self , dest : cat . Catalog , src : cat . Catalog , merge_method : prof . Method , as_is : bool ) -> cat . Catalog : # merge_method is use_first, merge, or keep # if as_is is false, the result is flattened dest = self . _flatten_catalog ( dest , as_is ) src = self . _flatten_catalog ( src , as_is ) self . _merge_items ( dest , src , merge_method ) return dest def _merge_catalog ( self , merged : Optional [ cat . Catalog ], catalog : cat . Catalog ) -> cat . Catalog : \"\"\"Merge the controls in the catalog into merged catalog.\"\"\" # no merge means keep, including dups # same for merge with no combine # groups are merged only if separate directive such as as-is is given # use-first is a merge combination rule # merge is a merge combination rule for controls. groups are not merged by this rule # merge/as-is and merge/custom are used for merging groups # if neither as-is nor custom is specified - just get single list of controls # unstructured controls should appear after any loose params # make copies to avoid changing input objects local_cat = catalog . copy ( deep = True ) local_merged = merged . copy ( deep = True ) if merged else None merge_method = prof . Method . keep as_is = False if self . _profile . merge is not None : if self . _profile . merge . custom is not None : raise TrestleError ( 'Profile with custom merge is not supported.' ) if self . _profile . merge . as_is is not None : as_is = self . _profile . merge . as_is if self . _profile . merge . combine is None : logger . warning ( 'Profile has merge but no combine so defaulting to combine/merge.' ) merge_method = prof . Method . merge else : merge_combine = self . _profile . merge . combine if merge_combine . method is None : logger . warning ( 'Profile has merge combine but no method. Defaulting to merge.' ) merge_method = prof . Method . merge else : merge_method = merge_combine . method if local_merged is None : return self . _flatten_catalog ( local_cat , as_is ) # merge the incoming catalog with merged based on merge_method and as_is return self . _merge_two_catalogs ( local_merged , local_cat , merge_method , as_is ) def process ( self , pipelines : List [ Pipeline ]) -> Iterator [ cat . Catalog ]: \"\"\" Merge the incoming catalogs. This pulls from import and iterates over the incoming catalogs. The way groups, lists of controls, and controls themselves get merged is specified by the profile. \"\"\" merged : Optional [ cat . Catalog ] = None logger . debug ( f 'merge entering process with { len ( pipelines ) } pipelines' ) for pipeline in pipelines : catalog = next ( pipeline . process ( None )) merged = self . _merge_catalog ( merged , catalog ) yield merged","title":"Merge"},{"location":"api_reference/trestle.core.resolver.merge/#trestle.core.resolver.merge.Merge-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.resolver.merge/#trestle.core.resolver.merge.Merge.__init__","text":"Initialize the class with the profile. Source code in trestle/core/resolver/merge.py def __init__ ( self , profile : prof . Profile ) -> None : \"\"\"Initialize the class with the profile.\"\"\" logger . debug ( 'merge filter initialize' ) self . _profile = profile","title":"__init__()"},{"location":"api_reference/trestle.core.resolver.merge/#trestle.core.resolver.merge.Merge.process","text":"Merge the incoming catalogs. This pulls from import and iterates over the incoming catalogs. The way groups, lists of controls, and controls themselves get merged is specified by the profile. Source code in trestle/core/resolver/merge.py def process ( self , pipelines : List [ Pipeline ]) -> Iterator [ cat . Catalog ]: \"\"\" Merge the incoming catalogs. This pulls from import and iterates over the incoming catalogs. The way groups, lists of controls, and controls themselves get merged is specified by the profile. \"\"\" merged : Optional [ cat . Catalog ] = None logger . debug ( f 'merge entering process with { len ( pipelines ) } pipelines' ) for pipeline in pipelines : catalog = next ( pipeline . process ( None )) merged = self . _merge_catalog ( merged , catalog ) yield merged handler: python","title":"process()"},{"location":"api_reference/trestle.core.resolver.modify/","text":"trestle.core.resolver.modify \u00a4 Create resolved catalog from profile. logger \u00a4 Classes \u00a4 Modify ( Filter ) \u00a4 Modify the controls based on the profile. Source code in trestle/core/resolver/modify.py class Modify ( Pipeline . Filter ): \"\"\"Modify the controls based on the profile.\"\"\" def __init__ ( self , profile : prof . Profile , change_prose : bool = False , block_adds : bool = False , block_params : bool = False , params_format : str = None , param_rep : ParameterRep = ParameterRep . VALUE_OR_LABEL_OR_CHOICES ) -> None : \"\"\"Initialize the filter.\"\"\" self . _profile = profile self . _catalog_interface : Optional [ CatalogInterface ] = None self . _block_adds = block_adds self . _block_params = block_params self . _change_prose = change_prose self . _params_format = params_format self . _param_rep = param_rep logger . debug ( f 'modify initialize filter with profile { profile . metadata . title } ' ) @staticmethod def _replace_ids_with_text ( prose : str , param_rep : ParameterRep , param_dict : Dict [ str , common . Parameter ]) -> str : \"\"\"Find all instances of param_ids in prose and replace each with corresponding parameter representation. Need to check all values in dict for a match Reject matches where the string has an adjacent alphanumeric char: param_1 and param_10 or aparam_1 \"\"\" for param in param_dict . values (): if param . id not in prose : continue # create the replacement text for the param_id param_str = ControlIOReader . param_to_str ( param , param_rep ) # non-capturing groups are odd in re.sub so capture all 3 groups and replace the middle one pattern = r '(^|[^a-zA-Z0-9_])' + param . id + r '($|[^a-zA-Z0-9_])' prose = re . sub ( pattern , r '\\1' + param_str + r '\\2' , prose ) return prose @staticmethod def _replace_params ( text : str , param_dict : Dict [ str , common . Parameter ], params_format : Optional [ str ] = None , param_rep : ParameterRep = ParameterRep . VALUE_OR_LABEL_OR_CHOICES ) -> str : \"\"\" Replace params found in moustaches with values from the param_dict. A single line of prose may contain multiple moustaches. \"\"\" # first check if there are any moustache patterns in the text if param_rep == ParameterRep . LEAVE_MOUSTACHE : return text staches : List [ str ] = re . findall ( r '{{.*?}}' , text ) if not staches : return text # now have list of all staches including braces, e.g. ['{{foo}}', '{{bar}}'] # clean the staches so they just have the param ids param_ids = [] for stache in staches : # remove braces so these are just param_ids but may have extra chars stache_contents = stache [ 2 :( - 2 )] param_id = stache_contents . replace ( 'insert: param,' , '' ) . strip () param_ids . append ( param_id ) # now replace original stache text with param values for i , _ in enumerate ( staches ): # A moustache may refer to a param_id not listed in the control's params if param_ids [ i ] not in param_dict : logger . warning ( f 'Control prose references param { param_ids [ i ] } not set in the control: { staches } ' ) elif param_dict [ param_ids [ i ]] is not None : param = param_dict [ param_ids [ i ]] param_str = ControlIOReader . param_to_str ( param , param_rep , False , False , params_format ) text = text . replace ( staches [ i ], param_str , 1 ) . strip () else : logger . warning ( f 'Control prose references param { param_ids [ i ] } with no specified value.' ) return text @staticmethod def _replace_part_prose ( control : cat . Control , part : common . Part , param_dict : Dict [ str , common . Parameter ], params_format : Optional [ str ] = None , param_rep : ParameterRep = ParameterRep . VALUE_OR_LABEL_OR_CHOICES ) -> None : \"\"\"Replace the part prose according to set_param.\"\"\" if part . prose is not None : fixed_prose = Modify . _replace_params ( part . prose , param_dict , params_format , param_rep ) # change the prose in the control itself part . prose = fixed_prose for prt in as_list ( part . parts ): Modify . _replace_part_prose ( control , prt , param_dict , params_format , param_rep ) for sub_control in as_list ( control . controls ): for prt in as_list ( sub_control . parts ): Modify . _replace_part_prose ( sub_control , prt , param_dict , params_format , param_rep ) @staticmethod def _replace_control_prose ( control : cat . Control , param_dict : Dict [ str , common . Parameter ], params_format : Optional [ str ] = None , param_rep : ParameterRep = ParameterRep . VALUE_OR_LABEL_OR_CHOICES ) -> None : \"\"\"Replace the control prose according to set_param.\"\"\" for part in as_list ( control . parts ): if part . prose is not None : fixed_prose = Modify . _replace_params ( part . prose , param_dict , params_format , param_rep ) # change the prose in the control itself part . prose = fixed_prose for prt in as_list ( part . parts ): Modify . _replace_part_prose ( control , prt , param_dict , params_format , param_rep ) for param in as_list ( control . params ): Modify . _replace_param_choices ( param , param_dict ) @staticmethod def _add_contents_as_list ( add : prof . Add ) -> List [ OBT ]: add_list = [] add_list . extend ( as_list ( add . props )) add_list . extend ( as_list ( add . parts )) add_list . extend ( as_list ( add . links )) return add_list @staticmethod def _add_adds_to_part ( part : common . Part , add : prof . Add ) -> None : for attr in [ 'params' , 'props' , 'parts' , 'links' ]: add_list = getattr ( add , attr , None ) if add_list : Modify . _add_attr_to_part ( part , add_list , attr , add . position ) @staticmethod def _add_to_list ( input_list : List [ OBT ], add : prof . Add ) -> bool : \"\"\"Add the contents of the add according to its by_id and position. Return True on success or False if id needed and not found. This is only called when by_id is not None. The add will be inserted if the id is found, or return False if not. This allows a separate recursive routine to search sub-lists for the id. \"\"\" add_list = Modify . _add_contents_as_list ( add ) # Test here for matched by_id attribute. try : for index in range ( len ( input_list )): if input_list [ index ] . id == add . by_id : if add . position == prof . Position . after : for offset , new_item in enumerate ( add_list ): input_list . insert ( index + 1 + offset , new_item ) return True elif add . position == prof . Position . before : for offset , new_item in enumerate ( add_list ): input_list . insert ( index + offset , new_item ) return True # if starting or ending, the adds go directly into this part according to type Modify . _add_adds_to_part ( input_list [ index ], add ) return True except AttributeError : raise TrestleError ( 'Cannot use \"after\" or \"before\" modifications for a list where elements' + ' do not contain the referenced by_id attribute.' ) return False @staticmethod def _add_to_parts ( parts : List [ common . Part ], add : prof . Add ) -> bool : \"\"\" Add the add to the parts. This is only called if add.by_id is not None. \"\"\" if Modify . _add_to_list ( parts , add ): return True for part in parts : if part . parts is not None and Modify . _add_to_parts ( part . parts , add ): return True return False @staticmethod def _add_attr_to_part ( part : common . Part , items : List [ OBT ], attr : str , position : prof . Position ) -> None : attr_list = as_list ( getattr ( part , attr , None )) if position in [ prof . Position . starting , prof . Position . before ]: items . extend ( attr_list ) attr_list = items else : attr_list . extend ( items ) setattr ( part , attr , attr_list ) @staticmethod def _add_attr_to_control ( control : cat . Control , items : List [ OBT ], attr : str , position : prof . Position ) -> None : attr_list = as_list ( getattr ( control , attr , None )) if position in [ prof . Position . starting , prof . Position . before ]: items . extend ( attr_list ) attr_list = items else : attr_list . extend ( items ) setattr ( control , attr , attr_list ) @staticmethod def _add_to_control ( control : cat . Control , add : prof . Add ) -> None : \"\"\"First step in applying Add to control.\"\"\" control . parts = as_list ( control . parts ) if add . by_id is None or add . by_id == control . id : # add contents will be added to the control directly and with no recursion for attr in [ 'params' , 'props' , 'parts' , 'links' ]: add_list = getattr ( add , attr , None ) if add_list : Modify . _add_attr_to_control ( control , add_list , attr , add . position ) return else : # this is only called if by_id is not None if not Modify . _add_to_parts ( control . parts , add ): logger . warning ( f 'Could not find id for add in control { control . id } : { add . by_id } ' ) @staticmethod def _set_overwrite_items ( param : common . Parameter , set_param : prof . SetParameter ) -> None : # these overwrite if set_param . class_ : param . class_ = set_param . class_ if set_param . depends_on : param . depends_on = set_param . depends_on if set_param . label : param . label = set_param . label if set_param . usage : param . usage = set_param . usage if set_param . values : param . values = set_param . values if set_param . select : param . select = set_param . select @staticmethod def _set_appended_items ( param : common . Parameter , set_param : prof . SetParameter ) -> None : # these append if set_param . constraints : if not param . constraints : param . constraints = [] param . constraints . extend ( set_param . constraints ) if set_param . guidelines : if not param . guidelines : param . guidelines = [] param . guidelines . extend ( set_param . guidelines ) @staticmethod def _set_replaced_or_appended_items ( param : common . Parameter , set_param : prof . SetParameter ) -> None : # these replace or append if set_param . props : new_props = as_list ( param . props ) names = [ prop . name for prop in new_props ] for prop in set_param . props : if prop . name in names : new_props [ names . index ( prop . name )] = prop else : new_props . append ( prop ) param . props = new_props if set_param . links : new_links = as_list ( param . links ) hrefs = [ link . href for link in new_links ] for link in set_param . links : if link . href in hrefs : new_links [ hrefs . index ( link . href )] = link else : new_links . append ( link ) param . links = new_links def _set_parameter_in_control_or_loose ( self , set_param : prof . SetParameter ) -> None : \"\"\" Find the control with the param_id in it and set the parameter contents. It modifies controls in the control_dict not the catalog. Parameters are either bound to a control or are 'loose' and bound to the catalog itself. \"\"\" # find the target param in control or the catalog's loose ones, i.e. catalog.params control = self . _catalog_interface . get_control_by_param_id ( set_param . param_id ) loose_param = False if control : control . params = as_list ( control . params ) param_ids = [ param . id for param in control . params ] if set_param . param_id not in param_ids : raise TrestleNotFoundError ( f 'Param id { set_param . param_id } not found in control { control . id } ' ) index = param_ids . index ( set_param . param_id ) param = control . params [ index ] else : param = self . _catalog_interface . loose_param_dict . get ( set_param . param_id , None ) if param : loose_param = True else : logger . warning ( f 'SetParameter for param_id { set_param . param_id } not found in catalog' ) return # rules here follow https://pages.nist.gov/OSCAL/concepts/processing/profile-resolution/ # see 'Modify Phase' and Setting Parameters Modify . _set_overwrite_items ( param , set_param ) Modify . _set_appended_items ( param , set_param ) Modify . _set_replaced_or_appended_items ( param , set_param ) if loose_param : self . _catalog_interface . loose_param_dict [ set_param . param_id ] = param else : control . params [ index ] = param self . _catalog_interface . replace_control ( control ) def _change_prose_with_param_values ( self ): \"\"\"Go through all controls and change prose based on param values.\"\"\" param_dict : Dict [ str , common . Parameter ] = {} # build the full mapping of params to values from the catalog interface for control in self . _catalog_interface . get_all_controls_from_dict (): param_dict . update ( ControlIOReader . get_control_param_dict ( control , False )) param_dict . update ( self . _catalog_interface . loose_param_dict ) # insert param values into prose of all controls for control in self . _catalog_interface . get_all_controls_from_dict (): self . _replace_control_prose ( control , param_dict , self . _params_format , self . _param_rep ) @staticmethod def _replace_param_choices ( param : common . Parameter , param_dict : Dict [ str , common . Parameter ]) -> None : \"\"\"Set values for all choices param that refer to params with values.\"\"\" if param . select : new_choices : List [ str ] = [] for choice in as_list ( param . select . choice ): new_choice = Modify . _replace_params ( choice , param_dict ) new_choices . append ( new_choice ) param . select . choice = new_choices def _modify_controls ( self , catalog : cat . Catalog ) -> cat . Catalog : \"\"\"Modify the controls based on the profile.\"\"\" logger . debug ( f 'modify specify catalog { catalog . metadata . title } for profile { self . _profile . metadata . title } ' ) self . _catalog_interface = CatalogInterface ( catalog ) alters : Optional [ List [ prof . Alter ]] = None # find the modify and alters if self . _profile . modify : # change all parameter values if self . _profile . modify . set_parameters and not self . _block_params : set_param_list = self . _profile . modify . set_parameters for set_param in set_param_list : self . _set_parameter_in_control_or_loose ( set_param ) alters = self . _profile . modify . alters if alters is not None : title = self . _profile . metadata . title for alter in alters : if alter . control_id is None : logger . warning ( f 'Alter must have control id specified in profile { title } .' ) continue id_ = alter . control_id if alter . removes is not None : logger . warning ( f 'Alter not supported for removes in profile { title } control { id_ } ' ) continue # we want a warning about adds even if adds are blocked, as in profile generate if alter . adds is None : logger . warning ( f 'Alter has no adds in profile { title } control { id_ } ' ) continue if not self . _block_adds : for add in alter . adds : if add . position is None and add . parts is not None : msg = f 'Alter/Add position is not specified in profile { title } control { id_ } ' msg += ' when adding part, so defaulting to ending.' logger . warning ( msg ) add . position = prof . Position . ending control = self . _catalog_interface . get_control ( id_ ) if control is None : logger . warning ( f 'Alter/Add refers to control { id_ } but it is not found in the import ' + f 'for profile { self . _profile . metadata . title } ' ) else : self . _add_to_control ( control , add ) self . _catalog_interface . replace_control ( control ) if self . _change_prose : # go through all controls and fix the prose based on param values self . _change_prose_with_param_values () catalog = self . _catalog_interface . get_catalog () # update the original profile metadata with new contents # roles and responsible-parties will be pulled in with new uuid's new_metadata = self . _profile . metadata new_metadata . title = f ' { catalog . metadata . title } : Resolved by profile { self . _profile . metadata . title } ' links : List [ common . Link ] = [] for import_ in self . _profile . imports : links . append ( common . Link ( ** { 'href' : import_ . href , 'rel' : 'resolution-source' })) new_metadata . links = links # move catalog controls from dummy group '' into the catalog for group in as_list ( catalog . groups ): if not group . id : catalog . controls = group . controls catalog . groups . remove ( group ) break catalog . metadata = new_metadata return catalog def process ( self , catalog_iter : Iterator [ cat . Catalog ]) -> Iterator [ cat . Catalog ]: \"\"\"Make the modifications to the controls based on the profile.\"\"\" catalog = next ( catalog_iter ) logger . debug ( f 'modify process with catalog { catalog . metadata . title } using profile { self . _profile . metadata . title } ' ) yield self . _modify_controls ( catalog ) Methods \u00a4 __init__ ( self , profile , change_prose = False , block_adds = False , block_params = False , params_format = None , param_rep =< ParameterRep . VALUE_OR_LABEL_OR_CHOICES : 3 > ) special \u00a4 Initialize the filter. Source code in trestle/core/resolver/modify.py def __init__ ( self , profile : prof . Profile , change_prose : bool = False , block_adds : bool = False , block_params : bool = False , params_format : str = None , param_rep : ParameterRep = ParameterRep . VALUE_OR_LABEL_OR_CHOICES ) -> None : \"\"\"Initialize the filter.\"\"\" self . _profile = profile self . _catalog_interface : Optional [ CatalogInterface ] = None self . _block_adds = block_adds self . _block_params = block_params self . _change_prose = change_prose self . _params_format = params_format self . _param_rep = param_rep logger . debug ( f 'modify initialize filter with profile { profile . metadata . title } ' ) process ( self , catalog_iter ) \u00a4 Make the modifications to the controls based on the profile. Source code in trestle/core/resolver/modify.py def process ( self , catalog_iter : Iterator [ cat . Catalog ]) -> Iterator [ cat . Catalog ]: \"\"\"Make the modifications to the controls based on the profile.\"\"\" catalog = next ( catalog_iter ) logger . debug ( f 'modify process with catalog { catalog . metadata . title } using profile { self . _profile . metadata . title } ' ) yield self . _modify_controls ( catalog ) handler: python","title":"modify"},{"location":"api_reference/trestle.core.resolver.modify/#trestle.core.resolver.modify","text":"Create resolved catalog from profile.","title":"modify"},{"location":"api_reference/trestle.core.resolver.modify/#trestle.core.resolver.modify.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.resolver.modify/#trestle.core.resolver.modify-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.resolver.modify/#trestle.core.resolver.modify.Modify","text":"Modify the controls based on the profile. Source code in trestle/core/resolver/modify.py class Modify ( Pipeline . Filter ): \"\"\"Modify the controls based on the profile.\"\"\" def __init__ ( self , profile : prof . Profile , change_prose : bool = False , block_adds : bool = False , block_params : bool = False , params_format : str = None , param_rep : ParameterRep = ParameterRep . VALUE_OR_LABEL_OR_CHOICES ) -> None : \"\"\"Initialize the filter.\"\"\" self . _profile = profile self . _catalog_interface : Optional [ CatalogInterface ] = None self . _block_adds = block_adds self . _block_params = block_params self . _change_prose = change_prose self . _params_format = params_format self . _param_rep = param_rep logger . debug ( f 'modify initialize filter with profile { profile . metadata . title } ' ) @staticmethod def _replace_ids_with_text ( prose : str , param_rep : ParameterRep , param_dict : Dict [ str , common . Parameter ]) -> str : \"\"\"Find all instances of param_ids in prose and replace each with corresponding parameter representation. Need to check all values in dict for a match Reject matches where the string has an adjacent alphanumeric char: param_1 and param_10 or aparam_1 \"\"\" for param in param_dict . values (): if param . id not in prose : continue # create the replacement text for the param_id param_str = ControlIOReader . param_to_str ( param , param_rep ) # non-capturing groups are odd in re.sub so capture all 3 groups and replace the middle one pattern = r '(^|[^a-zA-Z0-9_])' + param . id + r '($|[^a-zA-Z0-9_])' prose = re . sub ( pattern , r '\\1' + param_str + r '\\2' , prose ) return prose @staticmethod def _replace_params ( text : str , param_dict : Dict [ str , common . Parameter ], params_format : Optional [ str ] = None , param_rep : ParameterRep = ParameterRep . VALUE_OR_LABEL_OR_CHOICES ) -> str : \"\"\" Replace params found in moustaches with values from the param_dict. A single line of prose may contain multiple moustaches. \"\"\" # first check if there are any moustache patterns in the text if param_rep == ParameterRep . LEAVE_MOUSTACHE : return text staches : List [ str ] = re . findall ( r '{{.*?}}' , text ) if not staches : return text # now have list of all staches including braces, e.g. ['{{foo}}', '{{bar}}'] # clean the staches so they just have the param ids param_ids = [] for stache in staches : # remove braces so these are just param_ids but may have extra chars stache_contents = stache [ 2 :( - 2 )] param_id = stache_contents . replace ( 'insert: param,' , '' ) . strip () param_ids . append ( param_id ) # now replace original stache text with param values for i , _ in enumerate ( staches ): # A moustache may refer to a param_id not listed in the control's params if param_ids [ i ] not in param_dict : logger . warning ( f 'Control prose references param { param_ids [ i ] } not set in the control: { staches } ' ) elif param_dict [ param_ids [ i ]] is not None : param = param_dict [ param_ids [ i ]] param_str = ControlIOReader . param_to_str ( param , param_rep , False , False , params_format ) text = text . replace ( staches [ i ], param_str , 1 ) . strip () else : logger . warning ( f 'Control prose references param { param_ids [ i ] } with no specified value.' ) return text @staticmethod def _replace_part_prose ( control : cat . Control , part : common . Part , param_dict : Dict [ str , common . Parameter ], params_format : Optional [ str ] = None , param_rep : ParameterRep = ParameterRep . VALUE_OR_LABEL_OR_CHOICES ) -> None : \"\"\"Replace the part prose according to set_param.\"\"\" if part . prose is not None : fixed_prose = Modify . _replace_params ( part . prose , param_dict , params_format , param_rep ) # change the prose in the control itself part . prose = fixed_prose for prt in as_list ( part . parts ): Modify . _replace_part_prose ( control , prt , param_dict , params_format , param_rep ) for sub_control in as_list ( control . controls ): for prt in as_list ( sub_control . parts ): Modify . _replace_part_prose ( sub_control , prt , param_dict , params_format , param_rep ) @staticmethod def _replace_control_prose ( control : cat . Control , param_dict : Dict [ str , common . Parameter ], params_format : Optional [ str ] = None , param_rep : ParameterRep = ParameterRep . VALUE_OR_LABEL_OR_CHOICES ) -> None : \"\"\"Replace the control prose according to set_param.\"\"\" for part in as_list ( control . parts ): if part . prose is not None : fixed_prose = Modify . _replace_params ( part . prose , param_dict , params_format , param_rep ) # change the prose in the control itself part . prose = fixed_prose for prt in as_list ( part . parts ): Modify . _replace_part_prose ( control , prt , param_dict , params_format , param_rep ) for param in as_list ( control . params ): Modify . _replace_param_choices ( param , param_dict ) @staticmethod def _add_contents_as_list ( add : prof . Add ) -> List [ OBT ]: add_list = [] add_list . extend ( as_list ( add . props )) add_list . extend ( as_list ( add . parts )) add_list . extend ( as_list ( add . links )) return add_list @staticmethod def _add_adds_to_part ( part : common . Part , add : prof . Add ) -> None : for attr in [ 'params' , 'props' , 'parts' , 'links' ]: add_list = getattr ( add , attr , None ) if add_list : Modify . _add_attr_to_part ( part , add_list , attr , add . position ) @staticmethod def _add_to_list ( input_list : List [ OBT ], add : prof . Add ) -> bool : \"\"\"Add the contents of the add according to its by_id and position. Return True on success or False if id needed and not found. This is only called when by_id is not None. The add will be inserted if the id is found, or return False if not. This allows a separate recursive routine to search sub-lists for the id. \"\"\" add_list = Modify . _add_contents_as_list ( add ) # Test here for matched by_id attribute. try : for index in range ( len ( input_list )): if input_list [ index ] . id == add . by_id : if add . position == prof . Position . after : for offset , new_item in enumerate ( add_list ): input_list . insert ( index + 1 + offset , new_item ) return True elif add . position == prof . Position . before : for offset , new_item in enumerate ( add_list ): input_list . insert ( index + offset , new_item ) return True # if starting or ending, the adds go directly into this part according to type Modify . _add_adds_to_part ( input_list [ index ], add ) return True except AttributeError : raise TrestleError ( 'Cannot use \"after\" or \"before\" modifications for a list where elements' + ' do not contain the referenced by_id attribute.' ) return False @staticmethod def _add_to_parts ( parts : List [ common . Part ], add : prof . Add ) -> bool : \"\"\" Add the add to the parts. This is only called if add.by_id is not None. \"\"\" if Modify . _add_to_list ( parts , add ): return True for part in parts : if part . parts is not None and Modify . _add_to_parts ( part . parts , add ): return True return False @staticmethod def _add_attr_to_part ( part : common . Part , items : List [ OBT ], attr : str , position : prof . Position ) -> None : attr_list = as_list ( getattr ( part , attr , None )) if position in [ prof . Position . starting , prof . Position . before ]: items . extend ( attr_list ) attr_list = items else : attr_list . extend ( items ) setattr ( part , attr , attr_list ) @staticmethod def _add_attr_to_control ( control : cat . Control , items : List [ OBT ], attr : str , position : prof . Position ) -> None : attr_list = as_list ( getattr ( control , attr , None )) if position in [ prof . Position . starting , prof . Position . before ]: items . extend ( attr_list ) attr_list = items else : attr_list . extend ( items ) setattr ( control , attr , attr_list ) @staticmethod def _add_to_control ( control : cat . Control , add : prof . Add ) -> None : \"\"\"First step in applying Add to control.\"\"\" control . parts = as_list ( control . parts ) if add . by_id is None or add . by_id == control . id : # add contents will be added to the control directly and with no recursion for attr in [ 'params' , 'props' , 'parts' , 'links' ]: add_list = getattr ( add , attr , None ) if add_list : Modify . _add_attr_to_control ( control , add_list , attr , add . position ) return else : # this is only called if by_id is not None if not Modify . _add_to_parts ( control . parts , add ): logger . warning ( f 'Could not find id for add in control { control . id } : { add . by_id } ' ) @staticmethod def _set_overwrite_items ( param : common . Parameter , set_param : prof . SetParameter ) -> None : # these overwrite if set_param . class_ : param . class_ = set_param . class_ if set_param . depends_on : param . depends_on = set_param . depends_on if set_param . label : param . label = set_param . label if set_param . usage : param . usage = set_param . usage if set_param . values : param . values = set_param . values if set_param . select : param . select = set_param . select @staticmethod def _set_appended_items ( param : common . Parameter , set_param : prof . SetParameter ) -> None : # these append if set_param . constraints : if not param . constraints : param . constraints = [] param . constraints . extend ( set_param . constraints ) if set_param . guidelines : if not param . guidelines : param . guidelines = [] param . guidelines . extend ( set_param . guidelines ) @staticmethod def _set_replaced_or_appended_items ( param : common . Parameter , set_param : prof . SetParameter ) -> None : # these replace or append if set_param . props : new_props = as_list ( param . props ) names = [ prop . name for prop in new_props ] for prop in set_param . props : if prop . name in names : new_props [ names . index ( prop . name )] = prop else : new_props . append ( prop ) param . props = new_props if set_param . links : new_links = as_list ( param . links ) hrefs = [ link . href for link in new_links ] for link in set_param . links : if link . href in hrefs : new_links [ hrefs . index ( link . href )] = link else : new_links . append ( link ) param . links = new_links def _set_parameter_in_control_or_loose ( self , set_param : prof . SetParameter ) -> None : \"\"\" Find the control with the param_id in it and set the parameter contents. It modifies controls in the control_dict not the catalog. Parameters are either bound to a control or are 'loose' and bound to the catalog itself. \"\"\" # find the target param in control or the catalog's loose ones, i.e. catalog.params control = self . _catalog_interface . get_control_by_param_id ( set_param . param_id ) loose_param = False if control : control . params = as_list ( control . params ) param_ids = [ param . id for param in control . params ] if set_param . param_id not in param_ids : raise TrestleNotFoundError ( f 'Param id { set_param . param_id } not found in control { control . id } ' ) index = param_ids . index ( set_param . param_id ) param = control . params [ index ] else : param = self . _catalog_interface . loose_param_dict . get ( set_param . param_id , None ) if param : loose_param = True else : logger . warning ( f 'SetParameter for param_id { set_param . param_id } not found in catalog' ) return # rules here follow https://pages.nist.gov/OSCAL/concepts/processing/profile-resolution/ # see 'Modify Phase' and Setting Parameters Modify . _set_overwrite_items ( param , set_param ) Modify . _set_appended_items ( param , set_param ) Modify . _set_replaced_or_appended_items ( param , set_param ) if loose_param : self . _catalog_interface . loose_param_dict [ set_param . param_id ] = param else : control . params [ index ] = param self . _catalog_interface . replace_control ( control ) def _change_prose_with_param_values ( self ): \"\"\"Go through all controls and change prose based on param values.\"\"\" param_dict : Dict [ str , common . Parameter ] = {} # build the full mapping of params to values from the catalog interface for control in self . _catalog_interface . get_all_controls_from_dict (): param_dict . update ( ControlIOReader . get_control_param_dict ( control , False )) param_dict . update ( self . _catalog_interface . loose_param_dict ) # insert param values into prose of all controls for control in self . _catalog_interface . get_all_controls_from_dict (): self . _replace_control_prose ( control , param_dict , self . _params_format , self . _param_rep ) @staticmethod def _replace_param_choices ( param : common . Parameter , param_dict : Dict [ str , common . Parameter ]) -> None : \"\"\"Set values for all choices param that refer to params with values.\"\"\" if param . select : new_choices : List [ str ] = [] for choice in as_list ( param . select . choice ): new_choice = Modify . _replace_params ( choice , param_dict ) new_choices . append ( new_choice ) param . select . choice = new_choices def _modify_controls ( self , catalog : cat . Catalog ) -> cat . Catalog : \"\"\"Modify the controls based on the profile.\"\"\" logger . debug ( f 'modify specify catalog { catalog . metadata . title } for profile { self . _profile . metadata . title } ' ) self . _catalog_interface = CatalogInterface ( catalog ) alters : Optional [ List [ prof . Alter ]] = None # find the modify and alters if self . _profile . modify : # change all parameter values if self . _profile . modify . set_parameters and not self . _block_params : set_param_list = self . _profile . modify . set_parameters for set_param in set_param_list : self . _set_parameter_in_control_or_loose ( set_param ) alters = self . _profile . modify . alters if alters is not None : title = self . _profile . metadata . title for alter in alters : if alter . control_id is None : logger . warning ( f 'Alter must have control id specified in profile { title } .' ) continue id_ = alter . control_id if alter . removes is not None : logger . warning ( f 'Alter not supported for removes in profile { title } control { id_ } ' ) continue # we want a warning about adds even if adds are blocked, as in profile generate if alter . adds is None : logger . warning ( f 'Alter has no adds in profile { title } control { id_ } ' ) continue if not self . _block_adds : for add in alter . adds : if add . position is None and add . parts is not None : msg = f 'Alter/Add position is not specified in profile { title } control { id_ } ' msg += ' when adding part, so defaulting to ending.' logger . warning ( msg ) add . position = prof . Position . ending control = self . _catalog_interface . get_control ( id_ ) if control is None : logger . warning ( f 'Alter/Add refers to control { id_ } but it is not found in the import ' + f 'for profile { self . _profile . metadata . title } ' ) else : self . _add_to_control ( control , add ) self . _catalog_interface . replace_control ( control ) if self . _change_prose : # go through all controls and fix the prose based on param values self . _change_prose_with_param_values () catalog = self . _catalog_interface . get_catalog () # update the original profile metadata with new contents # roles and responsible-parties will be pulled in with new uuid's new_metadata = self . _profile . metadata new_metadata . title = f ' { catalog . metadata . title } : Resolved by profile { self . _profile . metadata . title } ' links : List [ common . Link ] = [] for import_ in self . _profile . imports : links . append ( common . Link ( ** { 'href' : import_ . href , 'rel' : 'resolution-source' })) new_metadata . links = links # move catalog controls from dummy group '' into the catalog for group in as_list ( catalog . groups ): if not group . id : catalog . controls = group . controls catalog . groups . remove ( group ) break catalog . metadata = new_metadata return catalog def process ( self , catalog_iter : Iterator [ cat . Catalog ]) -> Iterator [ cat . Catalog ]: \"\"\"Make the modifications to the controls based on the profile.\"\"\" catalog = next ( catalog_iter ) logger . debug ( f 'modify process with catalog { catalog . metadata . title } using profile { self . _profile . metadata . title } ' ) yield self . _modify_controls ( catalog )","title":"Modify"},{"location":"api_reference/trestle.core.resolver.modify/#trestle.core.resolver.modify.Modify-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.resolver.modify/#trestle.core.resolver.modify.Modify.__init__","text":"Initialize the filter. Source code in trestle/core/resolver/modify.py def __init__ ( self , profile : prof . Profile , change_prose : bool = False , block_adds : bool = False , block_params : bool = False , params_format : str = None , param_rep : ParameterRep = ParameterRep . VALUE_OR_LABEL_OR_CHOICES ) -> None : \"\"\"Initialize the filter.\"\"\" self . _profile = profile self . _catalog_interface : Optional [ CatalogInterface ] = None self . _block_adds = block_adds self . _block_params = block_params self . _change_prose = change_prose self . _params_format = params_format self . _param_rep = param_rep logger . debug ( f 'modify initialize filter with profile { profile . metadata . title } ' )","title":"__init__()"},{"location":"api_reference/trestle.core.resolver.modify/#trestle.core.resolver.modify.Modify.process","text":"Make the modifications to the controls based on the profile. Source code in trestle/core/resolver/modify.py def process ( self , catalog_iter : Iterator [ cat . Catalog ]) -> Iterator [ cat . Catalog ]: \"\"\"Make the modifications to the controls based on the profile.\"\"\" catalog = next ( catalog_iter ) logger . debug ( f 'modify process with catalog { catalog . metadata . title } using profile { self . _profile . metadata . title } ' ) yield self . _modify_controls ( catalog ) handler: python","title":"process()"},{"location":"api_reference/trestle.core.resolver.prune/","text":"trestle.core.resolver.prune \u00a4 Create resolved catalog from profile. logger \u00a4 Classes \u00a4 Prune ( Filter ) \u00a4 Prune the catalog based on the import include rule. Source code in trestle/core/resolver/prune.py class Prune ( Pipeline . Filter ): \"\"\"Prune the catalog based on the import include rule.\"\"\" def __init__ ( self , import_ : prof . Import , profile : prof . Profile ) -> None : \"\"\" Inject the import. This needs to be created prior to knowing the catalog. The profile itself is only needed for debug messages. The import is one possibly several imports in that profile. \"\"\" self . _import = import_ self . _profile = profile self . _catalog_interface : Optional [ CatalogInterface ] = None self . _catalog : Optional [ cat . Catalog ] = None def _set_catalog ( self , catalog : cat . Catalog ) -> None : \"\"\"Set the catalog used by the catalog interface.\"\"\" self . _catalog_interface = CatalogInterface ( catalog ) self . _catalog = catalog def _find_uuid_refs ( self , control_id : str ) -> Set [ str ]: \"\"\" Find all needed resource refs buried in control links and prose. For any controls retained in the resolved profile catalog, if any prose references a document by uuid, that reference needs to be in backmatter. \"\"\" control = self . _catalog_interface . get_control ( control_id ) refs = set () if control . links is not None : for link in control . links : uuid_str = link . href . replace ( '#' , '' ) refs . add ( uuid_str ) if control . parts is not None : for part in control . parts : if part . prose is not None : # find the two parts, label and ref, in each markdown url # expecting form [label](#uuid) # but if it is a control ref it may be e.g. [CM-7](#cm-7) # for now label is not used # the ref may be a uuid or control id # currently only uuids are used to confirm needed presence in backmatter # note that prose may be multi-line but findall searches all lines matches = re . findall ( MARKDOWN_URL_REGEX , part . prose ) for match in matches : ref = match [ 1 ] if len ( ref ) > 1 and ref [ 0 ] == '#' : uuid_match = re . findall ( UUID_REGEX , ref [ 1 :]) # there should be only one uuid in the parens if uuid_match : refs . add ( uuid_match [ 0 ]) if control . controls is not None : for sub_control in control . controls : refs . update ( self . _find_uuid_refs ( sub_control . id )) return refs def _find_all_uuid_refs ( self , needed_control_ids : List [ str ]) -> Set [ str ]: \"\"\"Find all references needed by controls.\"\"\" refs = set () for control_id in needed_control_ids : refs . update ( self . _find_uuid_refs ( control_id )) return refs def _controls_selected ( self , select_list : Optional [ List [ prof . SelectControlById ]]) -> List [ str ]: control_ids : List [ str ] = [] if select_list is not None : for select_control in select_list : if select_control . matching is not None : raise TrestleError ( 'Profiles with SelectControlById based on matching are not supported.' ) include_children = select_control . with_child_controls == prof . WithChildControls . yes if select_control . with_ids : new_ids = [ withid . __root__ for withid in select_control . with_ids ] for id_ in new_ids : control_ids . append ( id_ ) if include_children : control_ids . extend ( self . _catalog_interface . get_dependent_control_ids ( id_ )) return control_ids def _find_needed_control_ids ( self ) -> List [ str ]: \"\"\"Get list of control_ids needed by profile and corresponding groups.\"\"\" if self . _import . include_controls is not None : include_ids = self . _controls_selected ( self . _import . include_controls ) else : if self . _import . include_all is None : logger . warning ( 'Profile does not specify include-controls, so including all.' ) include_ids = self . _catalog_interface . get_control_ids () exclude_ids = self . _controls_selected ( self . _import . exclude_controls ) if not set ( include_ids ) . issuperset ( set ( exclude_ids )): logger . debug ( f 'include_ids is not a superset of exclude_ids in import { self . _import . href } ' ) return [ id_ for id_ in include_ids if id_ not in exclude_ids ] def _prune_control ( self , needed_ids : List [ str ], control : cat . Control , exclude_ids : List [ str ]) -> cat . Control : \"\"\" Prune the control based on the Import requirements. This is only called if the control is needed Some or all of its sub_controls may not be needed This always returns the original control, possibly with fewer subcontrols \"\"\" if control . controls is None : return control controls = [] for sub_control in control . controls : if sub_control . id in needed_ids and sub_control . id not in exclude_ids : controls . append ( self . _prune_control ( needed_ids , sub_control , exclude_ids )) exclude_ids . append ( sub_control . id ) control . controls = none_if_empty ( controls ) return control def _prune_controls ( self , needed_ids : List [ str ]) -> List [ str ]: loaded_ids = [] final_ids : List [ str ] = [] for control_id in needed_ids : if control_id not in loaded_ids : control = self . _catalog_interface . get_control ( control_id ) if control is None : msg = ( f 'Profile titled \" { self . _profile . metadata . title } \" references control { control_id } ' f 'but it is not in catalog titled \" { self . _catalog . metadata . title } \"' ) raise TrestleError ( msg ) control = self . _prune_control ( needed_ids , control , loaded_ids ) self . _catalog_interface . replace_control ( control ) loaded_ids . append ( control_id ) final_ids . append ( control_id ) return final_ids def _prune_catalog ( self ) -> cat . Catalog : \"\"\"Prune the controls in the current catalog.\"\"\" if self . _import is None : return self . _catalog needed_ids = self . _find_needed_control_ids () # if a control includes controls - only include those that we know are needed final_control_ids = self . _prune_controls ( needed_ids ) cat_controls = [] # build the needed groups of controls group_dict : Dict [ str , cat . Group ] = {} for control_id in final_control_ids : control = self . _catalog_interface . get_control ( control_id ) group_id , group_title , group_class = self . _catalog_interface . get_group_info_by_control ( control_id ) if not group_id : cat_controls . append ( control ) continue group = group_dict . get ( group_id ) if group is None : group = cat . Group ( id = group_id , title = group_title , class_ = group_class , controls = [ control ]) group_dict [ group_id ] = group else : group_dict [ group_id ] . controls . append ( control ) # find all referenced uuids - they should be 1:1 with those in backmatter needed_uuid_refs : Set [ str ] = self . _find_all_uuid_refs ( final_control_ids ) # prune the list of resources to only those that are needed new_resources : Optional [ List [ common . Resource ]] = [] if self . _catalog . back_matter is not None and self . _catalog . back_matter . resources is not None : new_resources = [ res for res in self . _catalog . back_matter . resources if res . uuid in needed_uuid_refs ] new_groups : Optional [ List [ cat . Group ]] = list ( group_dict . values ()) # should avoid empty lists so set to None if empty new_resources = none_if_empty ( new_resources ) new_groups = none_if_empty ( new_groups ) cat_controls = none_if_empty ( cat_controls ) new_params = self . _catalog . params new_cat = cat . Catalog ( uuid = str ( uuid4 ()), metadata = self . _catalog . metadata , back_matter = common . BackMatter ( resources = new_resources ), controls = cat_controls , groups = new_groups , params = new_params ) return new_cat def process ( self , catalog_iter : Iterator [ cat . Catalog ]) -> Iterator [ cat . Catalog ]: \"\"\" Prune the catalog based on the include rule in the import_. This only processes the one catalog yielded by the one import in this pipeline. It must yield in order to have the merge filter loop over available imported catalogs. \"\"\" self . _set_catalog ( next ( catalog_iter )) logger . debug ( f 'prune yielding catalog { self . _catalog . metadata . title } with import { self . _import . href } ' ) yield self . _prune_catalog () Methods \u00a4 __init__ ( self , import_ , profile ) special \u00a4 Inject the import. This needs to be created prior to knowing the catalog. The profile itself is only needed for debug messages. The import is one possibly several imports in that profile. Source code in trestle/core/resolver/prune.py def __init__ ( self , import_ : prof . Import , profile : prof . Profile ) -> None : \"\"\" Inject the import. This needs to be created prior to knowing the catalog. The profile itself is only needed for debug messages. The import is one possibly several imports in that profile. \"\"\" self . _import = import_ self . _profile = profile self . _catalog_interface : Optional [ CatalogInterface ] = None self . _catalog : Optional [ cat . Catalog ] = None process ( self , catalog_iter ) \u00a4 Prune the catalog based on the include rule in the import_. This only processes the one catalog yielded by the one import in this pipeline. It must yield in order to have the merge filter loop over available imported catalogs. Source code in trestle/core/resolver/prune.py def process ( self , catalog_iter : Iterator [ cat . Catalog ]) -> Iterator [ cat . Catalog ]: \"\"\" Prune the catalog based on the include rule in the import_. This only processes the one catalog yielded by the one import in this pipeline. It must yield in order to have the merge filter loop over available imported catalogs. \"\"\" self . _set_catalog ( next ( catalog_iter )) logger . debug ( f 'prune yielding catalog { self . _catalog . metadata . title } with import { self . _import . href } ' ) yield self . _prune_catalog () handler: python","title":"prune"},{"location":"api_reference/trestle.core.resolver.prune/#trestle.core.resolver.prune","text":"Create resolved catalog from profile.","title":"prune"},{"location":"api_reference/trestle.core.resolver.prune/#trestle.core.resolver.prune.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.resolver.prune/#trestle.core.resolver.prune-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.resolver.prune/#trestle.core.resolver.prune.Prune","text":"Prune the catalog based on the import include rule. Source code in trestle/core/resolver/prune.py class Prune ( Pipeline . Filter ): \"\"\"Prune the catalog based on the import include rule.\"\"\" def __init__ ( self , import_ : prof . Import , profile : prof . Profile ) -> None : \"\"\" Inject the import. This needs to be created prior to knowing the catalog. The profile itself is only needed for debug messages. The import is one possibly several imports in that profile. \"\"\" self . _import = import_ self . _profile = profile self . _catalog_interface : Optional [ CatalogInterface ] = None self . _catalog : Optional [ cat . Catalog ] = None def _set_catalog ( self , catalog : cat . Catalog ) -> None : \"\"\"Set the catalog used by the catalog interface.\"\"\" self . _catalog_interface = CatalogInterface ( catalog ) self . _catalog = catalog def _find_uuid_refs ( self , control_id : str ) -> Set [ str ]: \"\"\" Find all needed resource refs buried in control links and prose. For any controls retained in the resolved profile catalog, if any prose references a document by uuid, that reference needs to be in backmatter. \"\"\" control = self . _catalog_interface . get_control ( control_id ) refs = set () if control . links is not None : for link in control . links : uuid_str = link . href . replace ( '#' , '' ) refs . add ( uuid_str ) if control . parts is not None : for part in control . parts : if part . prose is not None : # find the two parts, label and ref, in each markdown url # expecting form [label](#uuid) # but if it is a control ref it may be e.g. [CM-7](#cm-7) # for now label is not used # the ref may be a uuid or control id # currently only uuids are used to confirm needed presence in backmatter # note that prose may be multi-line but findall searches all lines matches = re . findall ( MARKDOWN_URL_REGEX , part . prose ) for match in matches : ref = match [ 1 ] if len ( ref ) > 1 and ref [ 0 ] == '#' : uuid_match = re . findall ( UUID_REGEX , ref [ 1 :]) # there should be only one uuid in the parens if uuid_match : refs . add ( uuid_match [ 0 ]) if control . controls is not None : for sub_control in control . controls : refs . update ( self . _find_uuid_refs ( sub_control . id )) return refs def _find_all_uuid_refs ( self , needed_control_ids : List [ str ]) -> Set [ str ]: \"\"\"Find all references needed by controls.\"\"\" refs = set () for control_id in needed_control_ids : refs . update ( self . _find_uuid_refs ( control_id )) return refs def _controls_selected ( self , select_list : Optional [ List [ prof . SelectControlById ]]) -> List [ str ]: control_ids : List [ str ] = [] if select_list is not None : for select_control in select_list : if select_control . matching is not None : raise TrestleError ( 'Profiles with SelectControlById based on matching are not supported.' ) include_children = select_control . with_child_controls == prof . WithChildControls . yes if select_control . with_ids : new_ids = [ withid . __root__ for withid in select_control . with_ids ] for id_ in new_ids : control_ids . append ( id_ ) if include_children : control_ids . extend ( self . _catalog_interface . get_dependent_control_ids ( id_ )) return control_ids def _find_needed_control_ids ( self ) -> List [ str ]: \"\"\"Get list of control_ids needed by profile and corresponding groups.\"\"\" if self . _import . include_controls is not None : include_ids = self . _controls_selected ( self . _import . include_controls ) else : if self . _import . include_all is None : logger . warning ( 'Profile does not specify include-controls, so including all.' ) include_ids = self . _catalog_interface . get_control_ids () exclude_ids = self . _controls_selected ( self . _import . exclude_controls ) if not set ( include_ids ) . issuperset ( set ( exclude_ids )): logger . debug ( f 'include_ids is not a superset of exclude_ids in import { self . _import . href } ' ) return [ id_ for id_ in include_ids if id_ not in exclude_ids ] def _prune_control ( self , needed_ids : List [ str ], control : cat . Control , exclude_ids : List [ str ]) -> cat . Control : \"\"\" Prune the control based on the Import requirements. This is only called if the control is needed Some or all of its sub_controls may not be needed This always returns the original control, possibly with fewer subcontrols \"\"\" if control . controls is None : return control controls = [] for sub_control in control . controls : if sub_control . id in needed_ids and sub_control . id not in exclude_ids : controls . append ( self . _prune_control ( needed_ids , sub_control , exclude_ids )) exclude_ids . append ( sub_control . id ) control . controls = none_if_empty ( controls ) return control def _prune_controls ( self , needed_ids : List [ str ]) -> List [ str ]: loaded_ids = [] final_ids : List [ str ] = [] for control_id in needed_ids : if control_id not in loaded_ids : control = self . _catalog_interface . get_control ( control_id ) if control is None : msg = ( f 'Profile titled \" { self . _profile . metadata . title } \" references control { control_id } ' f 'but it is not in catalog titled \" { self . _catalog . metadata . title } \"' ) raise TrestleError ( msg ) control = self . _prune_control ( needed_ids , control , loaded_ids ) self . _catalog_interface . replace_control ( control ) loaded_ids . append ( control_id ) final_ids . append ( control_id ) return final_ids def _prune_catalog ( self ) -> cat . Catalog : \"\"\"Prune the controls in the current catalog.\"\"\" if self . _import is None : return self . _catalog needed_ids = self . _find_needed_control_ids () # if a control includes controls - only include those that we know are needed final_control_ids = self . _prune_controls ( needed_ids ) cat_controls = [] # build the needed groups of controls group_dict : Dict [ str , cat . Group ] = {} for control_id in final_control_ids : control = self . _catalog_interface . get_control ( control_id ) group_id , group_title , group_class = self . _catalog_interface . get_group_info_by_control ( control_id ) if not group_id : cat_controls . append ( control ) continue group = group_dict . get ( group_id ) if group is None : group = cat . Group ( id = group_id , title = group_title , class_ = group_class , controls = [ control ]) group_dict [ group_id ] = group else : group_dict [ group_id ] . controls . append ( control ) # find all referenced uuids - they should be 1:1 with those in backmatter needed_uuid_refs : Set [ str ] = self . _find_all_uuid_refs ( final_control_ids ) # prune the list of resources to only those that are needed new_resources : Optional [ List [ common . Resource ]] = [] if self . _catalog . back_matter is not None and self . _catalog . back_matter . resources is not None : new_resources = [ res for res in self . _catalog . back_matter . resources if res . uuid in needed_uuid_refs ] new_groups : Optional [ List [ cat . Group ]] = list ( group_dict . values ()) # should avoid empty lists so set to None if empty new_resources = none_if_empty ( new_resources ) new_groups = none_if_empty ( new_groups ) cat_controls = none_if_empty ( cat_controls ) new_params = self . _catalog . params new_cat = cat . Catalog ( uuid = str ( uuid4 ()), metadata = self . _catalog . metadata , back_matter = common . BackMatter ( resources = new_resources ), controls = cat_controls , groups = new_groups , params = new_params ) return new_cat def process ( self , catalog_iter : Iterator [ cat . Catalog ]) -> Iterator [ cat . Catalog ]: \"\"\" Prune the catalog based on the include rule in the import_. This only processes the one catalog yielded by the one import in this pipeline. It must yield in order to have the merge filter loop over available imported catalogs. \"\"\" self . _set_catalog ( next ( catalog_iter )) logger . debug ( f 'prune yielding catalog { self . _catalog . metadata . title } with import { self . _import . href } ' ) yield self . _prune_catalog ()","title":"Prune"},{"location":"api_reference/trestle.core.resolver.prune/#trestle.core.resolver.prune.Prune-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.resolver.prune/#trestle.core.resolver.prune.Prune.__init__","text":"Inject the import. This needs to be created prior to knowing the catalog. The profile itself is only needed for debug messages. The import is one possibly several imports in that profile. Source code in trestle/core/resolver/prune.py def __init__ ( self , import_ : prof . Import , profile : prof . Profile ) -> None : \"\"\" Inject the import. This needs to be created prior to knowing the catalog. The profile itself is only needed for debug messages. The import is one possibly several imports in that profile. \"\"\" self . _import = import_ self . _profile = profile self . _catalog_interface : Optional [ CatalogInterface ] = None self . _catalog : Optional [ cat . Catalog ] = None","title":"__init__()"},{"location":"api_reference/trestle.core.resolver.prune/#trestle.core.resolver.prune.Prune.process","text":"Prune the catalog based on the include rule in the import_. This only processes the one catalog yielded by the one import in this pipeline. It must yield in order to have the merge filter loop over available imported catalogs. Source code in trestle/core/resolver/prune.py def process ( self , catalog_iter : Iterator [ cat . Catalog ]) -> Iterator [ cat . Catalog ]: \"\"\" Prune the catalog based on the include rule in the import_. This only processes the one catalog yielded by the one import in this pipeline. It must yield in order to have the merge filter loop over available imported catalogs. \"\"\" self . _set_catalog ( next ( catalog_iter )) logger . debug ( f 'prune yielding catalog { self . _catalog . metadata . title } with import { self . _import . href } ' ) yield self . _prune_catalog () handler: python","title":"process()"},{"location":"api_reference/trestle.core.ssp_io/","text":"trestle.core.ssp_io \u00a4 Handle direct IO for writing SSP responses as markdown. logger \u00a4 Classes \u00a4 SSPMarkdownWriter \u00a4 Class to write control responses as markdown. Source code in trestle/core/ssp_io.py class SSPMarkdownWriter (): \"\"\"Class to write control responses as markdown.\"\"\" def __init__ ( self , trestle_root : pathlib . Path ) -> None : \"\"\"Initialize the class.\"\"\" self . _trestle_root = trestle_root self . _ssp : ssp . SystemSecurityPlan = None self . _resolved_catalog : Catalog = None self . _catalog_interface : CatalogInterface = None def set_ssp ( self , ssp : ssp . SystemSecurityPlan ) -> None : \"\"\"Set ssp.\"\"\" self . _ssp = ssp def set_catalog ( self , resolved_catalog : Catalog ) -> None : \"\"\"Set catalog.\"\"\" self . _resolved_catalog = resolved_catalog self . _catalog_interface = catalog_interface . CatalogInterface ( self . _resolved_catalog ) def get_control_statement ( self , control_id : str , level : int ) -> str : \"\"\" Get the control statement for an ssp - to be printed in markdown as a structured list. Args: control_id: The control_id to use. Returns: A markdown blob as a string. \"\"\" if not self . _resolved_catalog : raise TrestleError ( 'Cannot get control statement, set resolved catalog first.' ) writer = ControlIOWriter () control = self . _catalog_interface . get_control ( control_id ) if not control : return '' control_lines = writer . get_control_statement ( control ) return self . _build_tree_and_adjust ( control_lines , level ) def get_control_part ( self , control_id : str , part_name : str , level : int ) -> str : \"\"\"Get control part with given name.\"\"\" control_part = self . _catalog_interface . get_control_part_prose ( control_id , part_name ) md_list = self . _write_str_with_header ( f 'Control Part: { part_name } for control: { control_id } ' , control_part , level ) return self . _build_tree_and_adjust ( md_list . split ( ' \\n ' ), level ) def get_fedramp_control_tables ( self , control_id : str , level : int , label_column = False ) -> str : \"\"\"Get the fedramp metadata as markdown tables, with optional third label column for params. The fedramp metadata has the following elements: - Responsible roles field - Parameter values table - Implementation status field - Control origination field Returns: tables as one coherent markdown blob. \"\"\" resp_roles_table = self . get_responsible_roles_table ( control_id , level ) params_values = self . _parameter_table ( control_id , level , label_column ) impl_status = self . get_fedramp_implementation_status ( control_id , level ) control_orig = self . get_fedramp_control_origination ( control_id , level ) final_output = '' if resp_roles_table : final_output += resp_roles_table if params_values : final_output += ' \\n ' + params_values if impl_status : final_output += ' \\n ' + impl_status if control_orig : final_output += ' \\n ' + control_orig return final_output def get_responsible_roles_table ( self , control_id : str , level : int ) -> str : \"\"\" For each role id - if the role exists in metadata use the title as what gets printed in the roles table. If not (for now) warn and use the role-id as the printed text. \"\"\" if self . _ssp is None : raise TrestleError ( 'Cannot get responsible roles, SSP is not set.' ) for impl_requirement in self . _ssp . control_implementation . implemented_requirements : if impl_requirement . control_id == control_id : if impl_requirement . responsible_roles : resp_roles = as_list ( impl_requirement . responsible_roles ) role_ids = [ role . role_id . replace ( '_' , ' ' ) for role in resp_roles ] # now check if this role exists in the metadata role_titles = dict ( zip ( role_ids , role_ids )) roles = as_list ( self . _ssp . metadata . roles ) for role in roles : if role . id in role_ids : role_titles [ role . id ] = role . title # dictionary to md table md_list = self . _write_table_with_header ( 'Responsible Roles.' , [[ key , role_titles [ key ]] for key in role_titles . keys ()], [ 'Role ID' , 'Title' ], level ) return md_list else : logger . warning ( f 'No responsible roles were found for the control with id: { control_id } in given SSP.' ) return '' return '' def _parameter_table ( self , control_id : str , level : int , label_column = False ) -> str : \"\"\"Print Param_id | ValueOrLabelOrChoices | Optional Label Column.\"\"\" if not self . _ssp : raise TrestleError ( 'Cannot get parameter table, set SSP first.' ) writer = ControlIOWriter () control = self . _catalog_interface . get_control ( control_id ) if not control : return '' params_lines = writer . get_params ( control , label_column ) # need to make sure no params still have moustaches. convert to brackets to avoid jinja complaints clean_lines = [] for line in params_lines : clean_lines . append ( line . replace ( '{{' , '[[' ) . replace ( '}}' , ']]' )) tree = MarkdownNode . build_tree_from_markdown ( clean_lines ) tree . change_header_level_by ( level ) return tree . content . raw_text def get_fedramp_implementation_status ( self , control_id : str , level : int ) -> str : \"\"\" Print implementation status as a list of items, only showing those that are applicable for the control. This is unlike the word document FedRAMP which uses checkboxes on standard set of options. Using a LUT to map between structured data fields, defined by FedRAMP and historical text. \"\"\" if not self . _ssp : raise TrestleError ( 'Cannot get Fedramp implementation status, set SSP first.' ) implementation_statuses : List [ str ] = [] control_impl_req = self . _control_implemented_req ( control_id ) if control_impl_req and control_impl_req . props : for prop in control_impl_req . props : if prop . name == IMPLEMENTATION_STATUS : implementation_statuses . append ( prop . value ) md_list = self . _write_list_with_header ( 'FedRamp Implementation Status.' , implementation_statuses , level ) return md_list def get_fedramp_control_origination ( self , control_id : str , level : int ) -> str : \"\"\" Print control origination, as a list of items, only showing those that are applicable for the control. Using a LUT to map between structured data fields, defined by FedRAMP and historical text. \"\"\" if not self . _ssp : raise TrestleError ( 'Cannot get FedRamp control origination, set SSP first.' ) control_origination = [] control_impl_req = self . _control_implemented_req ( control_id ) if control_impl_req and control_impl_req . props : for prop in control_impl_req . props : if prop . name == CONTROL_ORIGINATION : control_origination . append ( prop . value ) md_list = self . _write_list_with_header ( 'FedRamp Control Origination.' , control_origination , level ) return md_list def get_control_response ( self , control_id : str , level : int , write_empty_responses = False ) -> str : \"\"\" Get the full control implemented requirements, broken down based on the available control responses. For components the following structure is assumed: 'The System' is the default response, and all other components are treated as sub-headings per response item. \"\"\" if not self . _resolved_catalog : raise TrestleError ( 'Cannot get control response, set resolved catalog first.' ) control = self . _catalog_interface . get_control ( control_id ) control_impl_req = self . _control_implemented_req ( control_id ) if not control_impl_req : logger . info ( f 'No implemented requirements found for the control { control_id } ' ) return '' md_writer = MDWriter ( None ) if control_impl_req . statements : for statement in control_impl_req . statements : statement_id = statement . statement_id label = statement_id part_name = None # look up label for this statement if control . parts : found_label , part = self . _catalog_interface . get_statement_label_if_exists ( control_id , statement_id ) if found_label : label = found_label part_name = part . name response_per_component = self . _get_responses_by_components ( statement , write_empty_responses ) if response_per_component or ( not response_per_component and write_empty_responses ): if part_name and part_name == 'item' : # print part header only if subitem header = f 'Part { label } ' md_writer . new_header ( level = 1 , title = header ) for idx , component_key in enumerate ( response_per_component ): if component_key == SSP_MAIN_COMP_NAME and idx == 0 : # special case ignore header but print contents md_writer . new_paragraph () else : md_writer . new_header ( level = 2 , title = component_key ) md_writer . set_indent_level ( - 1 ) md_writer . new_line ( response_per_component [ component_key ]) md_writer . set_indent_level ( - 1 ) lines = md_writer . get_lines () tree = MarkdownNode . build_tree_from_markdown ( lines ) tree . change_header_level_by ( level ) return tree . content . raw_text def _get_responses_by_components ( self , statement : Statement , write_empty_responses : bool ) -> Dict [ str , str ]: \"\"\"Get response per component, substitute component id with title if possible.\"\"\" response_per_component = {} if statement . by_components : for component in statement . by_components : # look up component title subheader = component . component_uuid response = '' if self . _ssp . system_implementation . components : for comp in self . _ssp . system_implementation . components : if comp . uuid == component . component_uuid : title = comp . title if title : subheader = title if component . description : response = component . description if response or ( not response and write_empty_responses ): if subheader : response_per_component [ subheader ] = response return response_per_component def _control_implemented_req ( self , control_id : str ) -> Optional [ ssp . ImplementedRequirement ]: \"\"\"Retrieve control implemented requirement by control-id.\"\"\" requirements = self . _ssp . control_implementation . implemented_requirements for requirement in requirements : if requirement . control_id == control_id : return requirement logger . debug ( f 'No implemented requirement found for control { control_id } ' ) return None def _write_list_with_header ( self , header : str , lines : List [ str ], level : int ) -> str : if lines : md_writer = MDWriter ( None ) md_writer . new_paragraph () md_writer . new_header ( level = 1 , title = header ) md_writer . set_indent_level ( - 1 ) md_writer . new_list ( lines ) md_writer . set_indent_level ( - 1 ) return self . _build_tree_and_adjust ( md_writer . get_lines (), level ) return '' def _write_table_with_header ( self , header : str , values : List [ List [ str ]], table_header : List [ str ], level : int ) -> str : if values and values [ 0 ]: md_writer = MDWriter ( None ) md_writer . new_paragraph () md_writer . new_header ( level = 1 , title = header ) md_writer . set_indent_level ( - 1 ) md_writer . new_table ( values , table_header ) md_writer . set_indent_level ( - 1 ) return self . _build_tree_and_adjust ( md_writer . get_lines (), level ) return '' def _write_str_with_header ( self , header : str , text : str , level : int ) -> str : if text : md_writer = MDWriter ( None ) md_writer . new_paragraph () md_writer . new_header ( level = 1 , title = header ) md_writer . set_indent_level ( - 1 ) md_writer . new_line ( text ) md_writer . set_indent_level ( - 1 ) return self . _build_tree_and_adjust ( md_writer . get_lines (), level ) return '' def _build_tree_and_adjust ( self , lines : List [ str ], level : int ) -> str : tree = MarkdownNode . build_tree_from_markdown ( lines ) tree . change_header_level_by ( level ) return tree . content . raw_text Methods \u00a4 __init__ ( self , trestle_root ) special \u00a4 Initialize the class. Source code in trestle/core/ssp_io.py def __init__ ( self , trestle_root : pathlib . Path ) -> None : \"\"\"Initialize the class.\"\"\" self . _trestle_root = trestle_root self . _ssp : ssp . SystemSecurityPlan = None self . _resolved_catalog : Catalog = None self . _catalog_interface : CatalogInterface = None get_control_part ( self , control_id , part_name , level ) \u00a4 Get control part with given name. Source code in trestle/core/ssp_io.py def get_control_part ( self , control_id : str , part_name : str , level : int ) -> str : \"\"\"Get control part with given name.\"\"\" control_part = self . _catalog_interface . get_control_part_prose ( control_id , part_name ) md_list = self . _write_str_with_header ( f 'Control Part: { part_name } for control: { control_id } ' , control_part , level ) return self . _build_tree_and_adjust ( md_list . split ( ' \\n ' ), level ) get_control_response ( self , control_id , level , write_empty_responses = False ) \u00a4 Get the full control implemented requirements, broken down based on the available control responses. For components the following structure is assumed: 'The System' is the default response, and all other components are treated as sub-headings per response item. Source code in trestle/core/ssp_io.py def get_control_response ( self , control_id : str , level : int , write_empty_responses = False ) -> str : \"\"\" Get the full control implemented requirements, broken down based on the available control responses. For components the following structure is assumed: 'The System' is the default response, and all other components are treated as sub-headings per response item. \"\"\" if not self . _resolved_catalog : raise TrestleError ( 'Cannot get control response, set resolved catalog first.' ) control = self . _catalog_interface . get_control ( control_id ) control_impl_req = self . _control_implemented_req ( control_id ) if not control_impl_req : logger . info ( f 'No implemented requirements found for the control { control_id } ' ) return '' md_writer = MDWriter ( None ) if control_impl_req . statements : for statement in control_impl_req . statements : statement_id = statement . statement_id label = statement_id part_name = None # look up label for this statement if control . parts : found_label , part = self . _catalog_interface . get_statement_label_if_exists ( control_id , statement_id ) if found_label : label = found_label part_name = part . name response_per_component = self . _get_responses_by_components ( statement , write_empty_responses ) if response_per_component or ( not response_per_component and write_empty_responses ): if part_name and part_name == 'item' : # print part header only if subitem header = f 'Part { label } ' md_writer . new_header ( level = 1 , title = header ) for idx , component_key in enumerate ( response_per_component ): if component_key == SSP_MAIN_COMP_NAME and idx == 0 : # special case ignore header but print contents md_writer . new_paragraph () else : md_writer . new_header ( level = 2 , title = component_key ) md_writer . set_indent_level ( - 1 ) md_writer . new_line ( response_per_component [ component_key ]) md_writer . set_indent_level ( - 1 ) lines = md_writer . get_lines () tree = MarkdownNode . build_tree_from_markdown ( lines ) tree . change_header_level_by ( level ) return tree . content . raw_text get_control_statement ( self , control_id , level ) \u00a4 Get the control statement for an ssp - to be printed in markdown as a structured list. Parameters: Name Type Description Default control_id str The control_id to use. required Returns: Type Description str A markdown blob as a string. Source code in trestle/core/ssp_io.py def get_control_statement ( self , control_id : str , level : int ) -> str : \"\"\" Get the control statement for an ssp - to be printed in markdown as a structured list. Args: control_id: The control_id to use. Returns: A markdown blob as a string. \"\"\" if not self . _resolved_catalog : raise TrestleError ( 'Cannot get control statement, set resolved catalog first.' ) writer = ControlIOWriter () control = self . _catalog_interface . get_control ( control_id ) if not control : return '' control_lines = writer . get_control_statement ( control ) return self . _build_tree_and_adjust ( control_lines , level ) get_fedramp_control_origination ( self , control_id , level ) \u00a4 Print control origination, as a list of items, only showing those that are applicable for the control. Using a LUT to map between structured data fields, defined by FedRAMP and historical text. Source code in trestle/core/ssp_io.py def get_fedramp_control_origination ( self , control_id : str , level : int ) -> str : \"\"\" Print control origination, as a list of items, only showing those that are applicable for the control. Using a LUT to map between structured data fields, defined by FedRAMP and historical text. \"\"\" if not self . _ssp : raise TrestleError ( 'Cannot get FedRamp control origination, set SSP first.' ) control_origination = [] control_impl_req = self . _control_implemented_req ( control_id ) if control_impl_req and control_impl_req . props : for prop in control_impl_req . props : if prop . name == CONTROL_ORIGINATION : control_origination . append ( prop . value ) md_list = self . _write_list_with_header ( 'FedRamp Control Origination.' , control_origination , level ) return md_list get_fedramp_control_tables ( self , control_id , level , label_column = False ) \u00a4 Get the fedramp metadata as markdown tables, with optional third label column for params. The fedramp metadata has the following elements: - Responsible roles field - Parameter values table - Implementation status field - Control origination field Returns: Type Description str tables as one coherent markdown blob. Source code in trestle/core/ssp_io.py def get_fedramp_control_tables ( self , control_id : str , level : int , label_column = False ) -> str : \"\"\"Get the fedramp metadata as markdown tables, with optional third label column for params. The fedramp metadata has the following elements: - Responsible roles field - Parameter values table - Implementation status field - Control origination field Returns: tables as one coherent markdown blob. \"\"\" resp_roles_table = self . get_responsible_roles_table ( control_id , level ) params_values = self . _parameter_table ( control_id , level , label_column ) impl_status = self . get_fedramp_implementation_status ( control_id , level ) control_orig = self . get_fedramp_control_origination ( control_id , level ) final_output = '' if resp_roles_table : final_output += resp_roles_table if params_values : final_output += ' \\n ' + params_values if impl_status : final_output += ' \\n ' + impl_status if control_orig : final_output += ' \\n ' + control_orig return final_output get_fedramp_implementation_status ( self , control_id , level ) \u00a4 Print implementation status as a list of items, only showing those that are applicable for the control. This is unlike the word document FedRAMP which uses checkboxes on standard set of options. Using a LUT to map between structured data fields, defined by FedRAMP and historical text. Source code in trestle/core/ssp_io.py def get_fedramp_implementation_status ( self , control_id : str , level : int ) -> str : \"\"\" Print implementation status as a list of items, only showing those that are applicable for the control. This is unlike the word document FedRAMP which uses checkboxes on standard set of options. Using a LUT to map between structured data fields, defined by FedRAMP and historical text. \"\"\" if not self . _ssp : raise TrestleError ( 'Cannot get Fedramp implementation status, set SSP first.' ) implementation_statuses : List [ str ] = [] control_impl_req = self . _control_implemented_req ( control_id ) if control_impl_req and control_impl_req . props : for prop in control_impl_req . props : if prop . name == IMPLEMENTATION_STATUS : implementation_statuses . append ( prop . value ) md_list = self . _write_list_with_header ( 'FedRamp Implementation Status.' , implementation_statuses , level ) return md_list get_responsible_roles_table ( self , control_id , level ) \u00a4 For each role id - if the role exists in metadata use the title as what gets printed in the roles table. If not (for now) warn and use the role-id as the printed text. Source code in trestle/core/ssp_io.py def get_responsible_roles_table ( self , control_id : str , level : int ) -> str : \"\"\" For each role id - if the role exists in metadata use the title as what gets printed in the roles table. If not (for now) warn and use the role-id as the printed text. \"\"\" if self . _ssp is None : raise TrestleError ( 'Cannot get responsible roles, SSP is not set.' ) for impl_requirement in self . _ssp . control_implementation . implemented_requirements : if impl_requirement . control_id == control_id : if impl_requirement . responsible_roles : resp_roles = as_list ( impl_requirement . responsible_roles ) role_ids = [ role . role_id . replace ( '_' , ' ' ) for role in resp_roles ] # now check if this role exists in the metadata role_titles = dict ( zip ( role_ids , role_ids )) roles = as_list ( self . _ssp . metadata . roles ) for role in roles : if role . id in role_ids : role_titles [ role . id ] = role . title # dictionary to md table md_list = self . _write_table_with_header ( 'Responsible Roles.' , [[ key , role_titles [ key ]] for key in role_titles . keys ()], [ 'Role ID' , 'Title' ], level ) return md_list else : logger . warning ( f 'No responsible roles were found for the control with id: { control_id } in given SSP.' ) return '' return '' set_catalog ( self , resolved_catalog ) \u00a4 Set catalog. Source code in trestle/core/ssp_io.py def set_catalog ( self , resolved_catalog : Catalog ) -> None : \"\"\"Set catalog.\"\"\" self . _resolved_catalog = resolved_catalog self . _catalog_interface = catalog_interface . CatalogInterface ( self . _resolved_catalog ) set_ssp ( self , ssp ) \u00a4 Set ssp. Source code in trestle/core/ssp_io.py def set_ssp ( self , ssp : ssp . SystemSecurityPlan ) -> None : \"\"\"Set ssp.\"\"\" self . _ssp = ssp handler: python","title":"ssp_io"},{"location":"api_reference/trestle.core.ssp_io/#trestle.core.ssp_io","text":"Handle direct IO for writing SSP responses as markdown.","title":"ssp_io"},{"location":"api_reference/trestle.core.ssp_io/#trestle.core.ssp_io.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.ssp_io/#trestle.core.ssp_io-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.ssp_io/#trestle.core.ssp_io.SSPMarkdownWriter","text":"Class to write control responses as markdown. Source code in trestle/core/ssp_io.py class SSPMarkdownWriter (): \"\"\"Class to write control responses as markdown.\"\"\" def __init__ ( self , trestle_root : pathlib . Path ) -> None : \"\"\"Initialize the class.\"\"\" self . _trestle_root = trestle_root self . _ssp : ssp . SystemSecurityPlan = None self . _resolved_catalog : Catalog = None self . _catalog_interface : CatalogInterface = None def set_ssp ( self , ssp : ssp . SystemSecurityPlan ) -> None : \"\"\"Set ssp.\"\"\" self . _ssp = ssp def set_catalog ( self , resolved_catalog : Catalog ) -> None : \"\"\"Set catalog.\"\"\" self . _resolved_catalog = resolved_catalog self . _catalog_interface = catalog_interface . CatalogInterface ( self . _resolved_catalog ) def get_control_statement ( self , control_id : str , level : int ) -> str : \"\"\" Get the control statement for an ssp - to be printed in markdown as a structured list. Args: control_id: The control_id to use. Returns: A markdown blob as a string. \"\"\" if not self . _resolved_catalog : raise TrestleError ( 'Cannot get control statement, set resolved catalog first.' ) writer = ControlIOWriter () control = self . _catalog_interface . get_control ( control_id ) if not control : return '' control_lines = writer . get_control_statement ( control ) return self . _build_tree_and_adjust ( control_lines , level ) def get_control_part ( self , control_id : str , part_name : str , level : int ) -> str : \"\"\"Get control part with given name.\"\"\" control_part = self . _catalog_interface . get_control_part_prose ( control_id , part_name ) md_list = self . _write_str_with_header ( f 'Control Part: { part_name } for control: { control_id } ' , control_part , level ) return self . _build_tree_and_adjust ( md_list . split ( ' \\n ' ), level ) def get_fedramp_control_tables ( self , control_id : str , level : int , label_column = False ) -> str : \"\"\"Get the fedramp metadata as markdown tables, with optional third label column for params. The fedramp metadata has the following elements: - Responsible roles field - Parameter values table - Implementation status field - Control origination field Returns: tables as one coherent markdown blob. \"\"\" resp_roles_table = self . get_responsible_roles_table ( control_id , level ) params_values = self . _parameter_table ( control_id , level , label_column ) impl_status = self . get_fedramp_implementation_status ( control_id , level ) control_orig = self . get_fedramp_control_origination ( control_id , level ) final_output = '' if resp_roles_table : final_output += resp_roles_table if params_values : final_output += ' \\n ' + params_values if impl_status : final_output += ' \\n ' + impl_status if control_orig : final_output += ' \\n ' + control_orig return final_output def get_responsible_roles_table ( self , control_id : str , level : int ) -> str : \"\"\" For each role id - if the role exists in metadata use the title as what gets printed in the roles table. If not (for now) warn and use the role-id as the printed text. \"\"\" if self . _ssp is None : raise TrestleError ( 'Cannot get responsible roles, SSP is not set.' ) for impl_requirement in self . _ssp . control_implementation . implemented_requirements : if impl_requirement . control_id == control_id : if impl_requirement . responsible_roles : resp_roles = as_list ( impl_requirement . responsible_roles ) role_ids = [ role . role_id . replace ( '_' , ' ' ) for role in resp_roles ] # now check if this role exists in the metadata role_titles = dict ( zip ( role_ids , role_ids )) roles = as_list ( self . _ssp . metadata . roles ) for role in roles : if role . id in role_ids : role_titles [ role . id ] = role . title # dictionary to md table md_list = self . _write_table_with_header ( 'Responsible Roles.' , [[ key , role_titles [ key ]] for key in role_titles . keys ()], [ 'Role ID' , 'Title' ], level ) return md_list else : logger . warning ( f 'No responsible roles were found for the control with id: { control_id } in given SSP.' ) return '' return '' def _parameter_table ( self , control_id : str , level : int , label_column = False ) -> str : \"\"\"Print Param_id | ValueOrLabelOrChoices | Optional Label Column.\"\"\" if not self . _ssp : raise TrestleError ( 'Cannot get parameter table, set SSP first.' ) writer = ControlIOWriter () control = self . _catalog_interface . get_control ( control_id ) if not control : return '' params_lines = writer . get_params ( control , label_column ) # need to make sure no params still have moustaches. convert to brackets to avoid jinja complaints clean_lines = [] for line in params_lines : clean_lines . append ( line . replace ( '{{' , '[[' ) . replace ( '}}' , ']]' )) tree = MarkdownNode . build_tree_from_markdown ( clean_lines ) tree . change_header_level_by ( level ) return tree . content . raw_text def get_fedramp_implementation_status ( self , control_id : str , level : int ) -> str : \"\"\" Print implementation status as a list of items, only showing those that are applicable for the control. This is unlike the word document FedRAMP which uses checkboxes on standard set of options. Using a LUT to map between structured data fields, defined by FedRAMP and historical text. \"\"\" if not self . _ssp : raise TrestleError ( 'Cannot get Fedramp implementation status, set SSP first.' ) implementation_statuses : List [ str ] = [] control_impl_req = self . _control_implemented_req ( control_id ) if control_impl_req and control_impl_req . props : for prop in control_impl_req . props : if prop . name == IMPLEMENTATION_STATUS : implementation_statuses . append ( prop . value ) md_list = self . _write_list_with_header ( 'FedRamp Implementation Status.' , implementation_statuses , level ) return md_list def get_fedramp_control_origination ( self , control_id : str , level : int ) -> str : \"\"\" Print control origination, as a list of items, only showing those that are applicable for the control. Using a LUT to map between structured data fields, defined by FedRAMP and historical text. \"\"\" if not self . _ssp : raise TrestleError ( 'Cannot get FedRamp control origination, set SSP first.' ) control_origination = [] control_impl_req = self . _control_implemented_req ( control_id ) if control_impl_req and control_impl_req . props : for prop in control_impl_req . props : if prop . name == CONTROL_ORIGINATION : control_origination . append ( prop . value ) md_list = self . _write_list_with_header ( 'FedRamp Control Origination.' , control_origination , level ) return md_list def get_control_response ( self , control_id : str , level : int , write_empty_responses = False ) -> str : \"\"\" Get the full control implemented requirements, broken down based on the available control responses. For components the following structure is assumed: 'The System' is the default response, and all other components are treated as sub-headings per response item. \"\"\" if not self . _resolved_catalog : raise TrestleError ( 'Cannot get control response, set resolved catalog first.' ) control = self . _catalog_interface . get_control ( control_id ) control_impl_req = self . _control_implemented_req ( control_id ) if not control_impl_req : logger . info ( f 'No implemented requirements found for the control { control_id } ' ) return '' md_writer = MDWriter ( None ) if control_impl_req . statements : for statement in control_impl_req . statements : statement_id = statement . statement_id label = statement_id part_name = None # look up label for this statement if control . parts : found_label , part = self . _catalog_interface . get_statement_label_if_exists ( control_id , statement_id ) if found_label : label = found_label part_name = part . name response_per_component = self . _get_responses_by_components ( statement , write_empty_responses ) if response_per_component or ( not response_per_component and write_empty_responses ): if part_name and part_name == 'item' : # print part header only if subitem header = f 'Part { label } ' md_writer . new_header ( level = 1 , title = header ) for idx , component_key in enumerate ( response_per_component ): if component_key == SSP_MAIN_COMP_NAME and idx == 0 : # special case ignore header but print contents md_writer . new_paragraph () else : md_writer . new_header ( level = 2 , title = component_key ) md_writer . set_indent_level ( - 1 ) md_writer . new_line ( response_per_component [ component_key ]) md_writer . set_indent_level ( - 1 ) lines = md_writer . get_lines () tree = MarkdownNode . build_tree_from_markdown ( lines ) tree . change_header_level_by ( level ) return tree . content . raw_text def _get_responses_by_components ( self , statement : Statement , write_empty_responses : bool ) -> Dict [ str , str ]: \"\"\"Get response per component, substitute component id with title if possible.\"\"\" response_per_component = {} if statement . by_components : for component in statement . by_components : # look up component title subheader = component . component_uuid response = '' if self . _ssp . system_implementation . components : for comp in self . _ssp . system_implementation . components : if comp . uuid == component . component_uuid : title = comp . title if title : subheader = title if component . description : response = component . description if response or ( not response and write_empty_responses ): if subheader : response_per_component [ subheader ] = response return response_per_component def _control_implemented_req ( self , control_id : str ) -> Optional [ ssp . ImplementedRequirement ]: \"\"\"Retrieve control implemented requirement by control-id.\"\"\" requirements = self . _ssp . control_implementation . implemented_requirements for requirement in requirements : if requirement . control_id == control_id : return requirement logger . debug ( f 'No implemented requirement found for control { control_id } ' ) return None def _write_list_with_header ( self , header : str , lines : List [ str ], level : int ) -> str : if lines : md_writer = MDWriter ( None ) md_writer . new_paragraph () md_writer . new_header ( level = 1 , title = header ) md_writer . set_indent_level ( - 1 ) md_writer . new_list ( lines ) md_writer . set_indent_level ( - 1 ) return self . _build_tree_and_adjust ( md_writer . get_lines (), level ) return '' def _write_table_with_header ( self , header : str , values : List [ List [ str ]], table_header : List [ str ], level : int ) -> str : if values and values [ 0 ]: md_writer = MDWriter ( None ) md_writer . new_paragraph () md_writer . new_header ( level = 1 , title = header ) md_writer . set_indent_level ( - 1 ) md_writer . new_table ( values , table_header ) md_writer . set_indent_level ( - 1 ) return self . _build_tree_and_adjust ( md_writer . get_lines (), level ) return '' def _write_str_with_header ( self , header : str , text : str , level : int ) -> str : if text : md_writer = MDWriter ( None ) md_writer . new_paragraph () md_writer . new_header ( level = 1 , title = header ) md_writer . set_indent_level ( - 1 ) md_writer . new_line ( text ) md_writer . set_indent_level ( - 1 ) return self . _build_tree_and_adjust ( md_writer . get_lines (), level ) return '' def _build_tree_and_adjust ( self , lines : List [ str ], level : int ) -> str : tree = MarkdownNode . build_tree_from_markdown ( lines ) tree . change_header_level_by ( level ) return tree . content . raw_text","title":"SSPMarkdownWriter"},{"location":"api_reference/trestle.core.ssp_io/#trestle.core.ssp_io.SSPMarkdownWriter-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.ssp_io/#trestle.core.ssp_io.SSPMarkdownWriter.__init__","text":"Initialize the class. Source code in trestle/core/ssp_io.py def __init__ ( self , trestle_root : pathlib . Path ) -> None : \"\"\"Initialize the class.\"\"\" self . _trestle_root = trestle_root self . _ssp : ssp . SystemSecurityPlan = None self . _resolved_catalog : Catalog = None self . _catalog_interface : CatalogInterface = None","title":"__init__()"},{"location":"api_reference/trestle.core.ssp_io/#trestle.core.ssp_io.SSPMarkdownWriter.get_control_part","text":"Get control part with given name. Source code in trestle/core/ssp_io.py def get_control_part ( self , control_id : str , part_name : str , level : int ) -> str : \"\"\"Get control part with given name.\"\"\" control_part = self . _catalog_interface . get_control_part_prose ( control_id , part_name ) md_list = self . _write_str_with_header ( f 'Control Part: { part_name } for control: { control_id } ' , control_part , level ) return self . _build_tree_and_adjust ( md_list . split ( ' \\n ' ), level )","title":"get_control_part()"},{"location":"api_reference/trestle.core.ssp_io/#trestle.core.ssp_io.SSPMarkdownWriter.get_control_response","text":"Get the full control implemented requirements, broken down based on the available control responses. For components the following structure is assumed: 'The System' is the default response, and all other components are treated as sub-headings per response item. Source code in trestle/core/ssp_io.py def get_control_response ( self , control_id : str , level : int , write_empty_responses = False ) -> str : \"\"\" Get the full control implemented requirements, broken down based on the available control responses. For components the following structure is assumed: 'The System' is the default response, and all other components are treated as sub-headings per response item. \"\"\" if not self . _resolved_catalog : raise TrestleError ( 'Cannot get control response, set resolved catalog first.' ) control = self . _catalog_interface . get_control ( control_id ) control_impl_req = self . _control_implemented_req ( control_id ) if not control_impl_req : logger . info ( f 'No implemented requirements found for the control { control_id } ' ) return '' md_writer = MDWriter ( None ) if control_impl_req . statements : for statement in control_impl_req . statements : statement_id = statement . statement_id label = statement_id part_name = None # look up label for this statement if control . parts : found_label , part = self . _catalog_interface . get_statement_label_if_exists ( control_id , statement_id ) if found_label : label = found_label part_name = part . name response_per_component = self . _get_responses_by_components ( statement , write_empty_responses ) if response_per_component or ( not response_per_component and write_empty_responses ): if part_name and part_name == 'item' : # print part header only if subitem header = f 'Part { label } ' md_writer . new_header ( level = 1 , title = header ) for idx , component_key in enumerate ( response_per_component ): if component_key == SSP_MAIN_COMP_NAME and idx == 0 : # special case ignore header but print contents md_writer . new_paragraph () else : md_writer . new_header ( level = 2 , title = component_key ) md_writer . set_indent_level ( - 1 ) md_writer . new_line ( response_per_component [ component_key ]) md_writer . set_indent_level ( - 1 ) lines = md_writer . get_lines () tree = MarkdownNode . build_tree_from_markdown ( lines ) tree . change_header_level_by ( level ) return tree . content . raw_text","title":"get_control_response()"},{"location":"api_reference/trestle.core.ssp_io/#trestle.core.ssp_io.SSPMarkdownWriter.get_control_statement","text":"Get the control statement for an ssp - to be printed in markdown as a structured list. Parameters: Name Type Description Default control_id str The control_id to use. required Returns: Type Description str A markdown blob as a string. Source code in trestle/core/ssp_io.py def get_control_statement ( self , control_id : str , level : int ) -> str : \"\"\" Get the control statement for an ssp - to be printed in markdown as a structured list. Args: control_id: The control_id to use. Returns: A markdown blob as a string. \"\"\" if not self . _resolved_catalog : raise TrestleError ( 'Cannot get control statement, set resolved catalog first.' ) writer = ControlIOWriter () control = self . _catalog_interface . get_control ( control_id ) if not control : return '' control_lines = writer . get_control_statement ( control ) return self . _build_tree_and_adjust ( control_lines , level )","title":"get_control_statement()"},{"location":"api_reference/trestle.core.ssp_io/#trestle.core.ssp_io.SSPMarkdownWriter.get_fedramp_control_origination","text":"Print control origination, as a list of items, only showing those that are applicable for the control. Using a LUT to map between structured data fields, defined by FedRAMP and historical text. Source code in trestle/core/ssp_io.py def get_fedramp_control_origination ( self , control_id : str , level : int ) -> str : \"\"\" Print control origination, as a list of items, only showing those that are applicable for the control. Using a LUT to map between structured data fields, defined by FedRAMP and historical text. \"\"\" if not self . _ssp : raise TrestleError ( 'Cannot get FedRamp control origination, set SSP first.' ) control_origination = [] control_impl_req = self . _control_implemented_req ( control_id ) if control_impl_req and control_impl_req . props : for prop in control_impl_req . props : if prop . name == CONTROL_ORIGINATION : control_origination . append ( prop . value ) md_list = self . _write_list_with_header ( 'FedRamp Control Origination.' , control_origination , level ) return md_list","title":"get_fedramp_control_origination()"},{"location":"api_reference/trestle.core.ssp_io/#trestle.core.ssp_io.SSPMarkdownWriter.get_fedramp_control_tables","text":"Get the fedramp metadata as markdown tables, with optional third label column for params. The fedramp metadata has the following elements: - Responsible roles field - Parameter values table - Implementation status field - Control origination field Returns: Type Description str tables as one coherent markdown blob. Source code in trestle/core/ssp_io.py def get_fedramp_control_tables ( self , control_id : str , level : int , label_column = False ) -> str : \"\"\"Get the fedramp metadata as markdown tables, with optional third label column for params. The fedramp metadata has the following elements: - Responsible roles field - Parameter values table - Implementation status field - Control origination field Returns: tables as one coherent markdown blob. \"\"\" resp_roles_table = self . get_responsible_roles_table ( control_id , level ) params_values = self . _parameter_table ( control_id , level , label_column ) impl_status = self . get_fedramp_implementation_status ( control_id , level ) control_orig = self . get_fedramp_control_origination ( control_id , level ) final_output = '' if resp_roles_table : final_output += resp_roles_table if params_values : final_output += ' \\n ' + params_values if impl_status : final_output += ' \\n ' + impl_status if control_orig : final_output += ' \\n ' + control_orig return final_output","title":"get_fedramp_control_tables()"},{"location":"api_reference/trestle.core.ssp_io/#trestle.core.ssp_io.SSPMarkdownWriter.get_fedramp_implementation_status","text":"Print implementation status as a list of items, only showing those that are applicable for the control. This is unlike the word document FedRAMP which uses checkboxes on standard set of options. Using a LUT to map between structured data fields, defined by FedRAMP and historical text. Source code in trestle/core/ssp_io.py def get_fedramp_implementation_status ( self , control_id : str , level : int ) -> str : \"\"\" Print implementation status as a list of items, only showing those that are applicable for the control. This is unlike the word document FedRAMP which uses checkboxes on standard set of options. Using a LUT to map between structured data fields, defined by FedRAMP and historical text. \"\"\" if not self . _ssp : raise TrestleError ( 'Cannot get Fedramp implementation status, set SSP first.' ) implementation_statuses : List [ str ] = [] control_impl_req = self . _control_implemented_req ( control_id ) if control_impl_req and control_impl_req . props : for prop in control_impl_req . props : if prop . name == IMPLEMENTATION_STATUS : implementation_statuses . append ( prop . value ) md_list = self . _write_list_with_header ( 'FedRamp Implementation Status.' , implementation_statuses , level ) return md_list","title":"get_fedramp_implementation_status()"},{"location":"api_reference/trestle.core.ssp_io/#trestle.core.ssp_io.SSPMarkdownWriter.get_responsible_roles_table","text":"For each role id - if the role exists in metadata use the title as what gets printed in the roles table. If not (for now) warn and use the role-id as the printed text. Source code in trestle/core/ssp_io.py def get_responsible_roles_table ( self , control_id : str , level : int ) -> str : \"\"\" For each role id - if the role exists in metadata use the title as what gets printed in the roles table. If not (for now) warn and use the role-id as the printed text. \"\"\" if self . _ssp is None : raise TrestleError ( 'Cannot get responsible roles, SSP is not set.' ) for impl_requirement in self . _ssp . control_implementation . implemented_requirements : if impl_requirement . control_id == control_id : if impl_requirement . responsible_roles : resp_roles = as_list ( impl_requirement . responsible_roles ) role_ids = [ role . role_id . replace ( '_' , ' ' ) for role in resp_roles ] # now check if this role exists in the metadata role_titles = dict ( zip ( role_ids , role_ids )) roles = as_list ( self . _ssp . metadata . roles ) for role in roles : if role . id in role_ids : role_titles [ role . id ] = role . title # dictionary to md table md_list = self . _write_table_with_header ( 'Responsible Roles.' , [[ key , role_titles [ key ]] for key in role_titles . keys ()], [ 'Role ID' , 'Title' ], level ) return md_list else : logger . warning ( f 'No responsible roles were found for the control with id: { control_id } in given SSP.' ) return '' return ''","title":"get_responsible_roles_table()"},{"location":"api_reference/trestle.core.ssp_io/#trestle.core.ssp_io.SSPMarkdownWriter.set_catalog","text":"Set catalog. Source code in trestle/core/ssp_io.py def set_catalog ( self , resolved_catalog : Catalog ) -> None : \"\"\"Set catalog.\"\"\" self . _resolved_catalog = resolved_catalog self . _catalog_interface = catalog_interface . CatalogInterface ( self . _resolved_catalog )","title":"set_catalog()"},{"location":"api_reference/trestle.core.ssp_io/#trestle.core.ssp_io.SSPMarkdownWriter.set_ssp","text":"Set ssp. Source code in trestle/core/ssp_io.py def set_ssp ( self , ssp : ssp . SystemSecurityPlan ) -> None : \"\"\"Set ssp.\"\"\" self . _ssp = ssp handler: python","title":"set_ssp()"},{"location":"api_reference/trestle.core.trestle_base_model/","text":"trestle.core.trestle_base_model \u00a4 Trestle Base Model. Model \u00a4 Classes \u00a4 TrestleBaseModel ( BaseModel ) pydantic-model \u00a4 Trestle Base Model. Serves as wrapper around BaseModel for overriding methods. Source code in trestle/core/trestle_base_model.py class TrestleBaseModel ( BaseModel ): \"\"\"Trestle Base Model. Serves as wrapper around BaseModel for overriding methods.\"\"\" @classmethod def parse_obj ( cls : Type [ 'Model' ], obj : Any ) -> 'Model' : \"\"\"Parse object to the given class.\"\"\" try : return super () . parse_obj ( obj ) except ValidationError as e : # check if failed due to the wrong OSCAL version: oscal_version_error = False for err in e . errors (): for field in err [ 'loc' ]: if field == 'oscal-version' : message = err [ 'msg' ] oscal_version_error = True break if oscal_version_error : raise TrestleError ( f ' { message } ' ) else : raise Methods \u00a4 parse_obj ( obj ) classmethod \u00a4 Parse object to the given class. Source code in trestle/core/trestle_base_model.py @classmethod def parse_obj ( cls : Type [ 'Model' ], obj : Any ) -> 'Model' : \"\"\"Parse object to the given class.\"\"\" try : return super () . parse_obj ( obj ) except ValidationError as e : # check if failed due to the wrong OSCAL version: oscal_version_error = False for err in e . errors (): for field in err [ 'loc' ]: if field == 'oscal-version' : message = err [ 'msg' ] oscal_version_error = True break if oscal_version_error : raise TrestleError ( f ' { message } ' ) else : raise handler: python","title":"trestle_base_model"},{"location":"api_reference/trestle.core.trestle_base_model/#trestle.core.trestle_base_model","text":"Trestle Base Model.","title":"trestle_base_model"},{"location":"api_reference/trestle.core.trestle_base_model/#trestle.core.trestle_base_model.Model","text":"","title":"Model"},{"location":"api_reference/trestle.core.trestle_base_model/#trestle.core.trestle_base_model-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.trestle_base_model/#trestle.core.trestle_base_model.TrestleBaseModel","text":"Trestle Base Model. Serves as wrapper around BaseModel for overriding methods. Source code in trestle/core/trestle_base_model.py class TrestleBaseModel ( BaseModel ): \"\"\"Trestle Base Model. Serves as wrapper around BaseModel for overriding methods.\"\"\" @classmethod def parse_obj ( cls : Type [ 'Model' ], obj : Any ) -> 'Model' : \"\"\"Parse object to the given class.\"\"\" try : return super () . parse_obj ( obj ) except ValidationError as e : # check if failed due to the wrong OSCAL version: oscal_version_error = False for err in e . errors (): for field in err [ 'loc' ]: if field == 'oscal-version' : message = err [ 'msg' ] oscal_version_error = True break if oscal_version_error : raise TrestleError ( f ' { message } ' ) else : raise","title":"TrestleBaseModel"},{"location":"api_reference/trestle.core.trestle_base_model/#trestle.core.trestle_base_model.TrestleBaseModel-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.trestle_base_model/#trestle.core.trestle_base_model.TrestleBaseModel.parse_obj","text":"Parse object to the given class. Source code in trestle/core/trestle_base_model.py @classmethod def parse_obj ( cls : Type [ 'Model' ], obj : Any ) -> 'Model' : \"\"\"Parse object to the given class.\"\"\" try : return super () . parse_obj ( obj ) except ValidationError as e : # check if failed due to the wrong OSCAL version: oscal_version_error = False for err in e . errors (): for field in err [ 'loc' ]: if field == 'oscal-version' : message = err [ 'msg' ] oscal_version_error = True break if oscal_version_error : raise TrestleError ( f ' { message } ' ) else : raise handler: python","title":"parse_obj()"},{"location":"api_reference/trestle.core.validator/","text":"trestle.core.validator \u00a4 Base class for all validators. logger \u00a4 Classes \u00a4 Validator ( ABC ) \u00a4 Validator base class. Source code in trestle/core/validator.py class Validator ( ABC ): \"\"\"Validator base class.\"\"\" def error_msg ( self ) -> str : \"\"\"Error message used to describe this validator.\"\"\" # subclasses can override as needed return self . __doc__ @abstractmethod def model_is_valid ( self , model : OscalBaseModel ) -> bool : \"\"\" Validate the model. args: model: An Oscal model that can be passed to the validator. returns: Whether or not the model passed this validation test. \"\"\" def validate ( self , args : argparse . Namespace ) -> int : \"\"\"Perform the validation according to user options.\"\"\" trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. # validate by type - all of type or just specified by name if args . type : models = [] if args . name : models = [ args . name ] else : models = ModelUtils . get_models_of_type ( args . type , trestle_root ) models_path = trestle_root / ModelUtils . model_type_to_model_dir ( args . type ) for m in models : model_path = models_path / m try : _ , _ , model = ModelUtils . load_distributed ( model_path , trestle_root ) except TrestleError as e : logger . warning ( f 'File load error { e } ' ) return CmdReturnCodes . OSCAL_VALIDATION_ERROR . value if not self . model_is_valid ( model ): logger . info ( f 'INVALID: Model { model_path } did not pass the { self . error_msg () } ' ) return CmdReturnCodes . OSCAL_VALIDATION_ERROR . value logger . info ( f 'VALID: Model { model_path } passed the { self . error_msg () } ' ) return CmdReturnCodes . SUCCESS . value # validate all if args . all : model_tups = ModelUtils . get_all_models ( trestle_root ) for mt in model_tups : model_dir = trestle_root / ModelUtils . model_type_to_model_dir ( mt [ 0 ]) / mt [ 1 ] extension_type = trestle . common . file_utils . get_contextual_file_type ( model_dir ) model_path = model_dir / f ' { mt [ 0 ] }{ FileContentType . to_file_extension ( extension_type ) } ' _ , _ , model = ModelUtils . load_distributed ( model_path , trestle_root ) if not self . model_is_valid ( model ): logger . info ( f 'INVALID: Model { model_path } did not pass the { self . error_msg () } ' ) return CmdReturnCodes . OSCAL_VALIDATION_ERROR . value logger . info ( f 'VALID: Model { model_path } passed the { self . error_msg () } ' ) return CmdReturnCodes . SUCCESS . value # validate file if args . file : file_path = trestle_root / args . file _ , _ , model = ModelUtils . load_distributed ( file_path , trestle_root ) if not self . model_is_valid ( model ): logger . info ( f 'INVALID: Model { file_path } did not pass the { self . error_msg () } ' ) return CmdReturnCodes . OSCAL_VALIDATION_ERROR . value logger . info ( f 'VALID: Model { file_path } passed the { self . error_msg () } ' ) return CmdReturnCodes . SUCCESS . value Methods \u00a4 error_msg ( self ) \u00a4 Error message used to describe this validator. Source code in trestle/core/validator.py def error_msg ( self ) -> str : \"\"\"Error message used to describe this validator.\"\"\" # subclasses can override as needed return self . __doc__ model_is_valid ( self , model ) \u00a4 Validate the model. Parameters: Name Type Description Default model OscalBaseModel An Oscal model that can be passed to the validator. required Returns: Type Description bool Whether or not the model passed this validation test. Source code in trestle/core/validator.py @abstractmethod def model_is_valid ( self , model : OscalBaseModel ) -> bool : \"\"\" Validate the model. args: model: An Oscal model that can be passed to the validator. returns: Whether or not the model passed this validation test. \"\"\" validate ( self , args ) \u00a4 Perform the validation according to user options. Source code in trestle/core/validator.py def validate ( self , args : argparse . Namespace ) -> int : \"\"\"Perform the validation according to user options.\"\"\" trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. # validate by type - all of type or just specified by name if args . type : models = [] if args . name : models = [ args . name ] else : models = ModelUtils . get_models_of_type ( args . type , trestle_root ) models_path = trestle_root / ModelUtils . model_type_to_model_dir ( args . type ) for m in models : model_path = models_path / m try : _ , _ , model = ModelUtils . load_distributed ( model_path , trestle_root ) except TrestleError as e : logger . warning ( f 'File load error { e } ' ) return CmdReturnCodes . OSCAL_VALIDATION_ERROR . value if not self . model_is_valid ( model ): logger . info ( f 'INVALID: Model { model_path } did not pass the { self . error_msg () } ' ) return CmdReturnCodes . OSCAL_VALIDATION_ERROR . value logger . info ( f 'VALID: Model { model_path } passed the { self . error_msg () } ' ) return CmdReturnCodes . SUCCESS . value # validate all if args . all : model_tups = ModelUtils . get_all_models ( trestle_root ) for mt in model_tups : model_dir = trestle_root / ModelUtils . model_type_to_model_dir ( mt [ 0 ]) / mt [ 1 ] extension_type = trestle . common . file_utils . get_contextual_file_type ( model_dir ) model_path = model_dir / f ' { mt [ 0 ] }{ FileContentType . to_file_extension ( extension_type ) } ' _ , _ , model = ModelUtils . load_distributed ( model_path , trestle_root ) if not self . model_is_valid ( model ): logger . info ( f 'INVALID: Model { model_path } did not pass the { self . error_msg () } ' ) return CmdReturnCodes . OSCAL_VALIDATION_ERROR . value logger . info ( f 'VALID: Model { model_path } passed the { self . error_msg () } ' ) return CmdReturnCodes . SUCCESS . value # validate file if args . file : file_path = trestle_root / args . file _ , _ , model = ModelUtils . load_distributed ( file_path , trestle_root ) if not self . model_is_valid ( model ): logger . info ( f 'INVALID: Model { file_path } did not pass the { self . error_msg () } ' ) return CmdReturnCodes . OSCAL_VALIDATION_ERROR . value logger . info ( f 'VALID: Model { file_path } passed the { self . error_msg () } ' ) return CmdReturnCodes . SUCCESS . value handler: python","title":"validator"},{"location":"api_reference/trestle.core.validator/#trestle.core.validator","text":"Base class for all validators.","title":"validator"},{"location":"api_reference/trestle.core.validator/#trestle.core.validator.logger","text":"","title":"logger"},{"location":"api_reference/trestle.core.validator/#trestle.core.validator-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.core.validator/#trestle.core.validator.Validator","text":"Validator base class. Source code in trestle/core/validator.py class Validator ( ABC ): \"\"\"Validator base class.\"\"\" def error_msg ( self ) -> str : \"\"\"Error message used to describe this validator.\"\"\" # subclasses can override as needed return self . __doc__ @abstractmethod def model_is_valid ( self , model : OscalBaseModel ) -> bool : \"\"\" Validate the model. args: model: An Oscal model that can be passed to the validator. returns: Whether or not the model passed this validation test. \"\"\" def validate ( self , args : argparse . Namespace ) -> int : \"\"\"Perform the validation according to user options.\"\"\" trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. # validate by type - all of type or just specified by name if args . type : models = [] if args . name : models = [ args . name ] else : models = ModelUtils . get_models_of_type ( args . type , trestle_root ) models_path = trestle_root / ModelUtils . model_type_to_model_dir ( args . type ) for m in models : model_path = models_path / m try : _ , _ , model = ModelUtils . load_distributed ( model_path , trestle_root ) except TrestleError as e : logger . warning ( f 'File load error { e } ' ) return CmdReturnCodes . OSCAL_VALIDATION_ERROR . value if not self . model_is_valid ( model ): logger . info ( f 'INVALID: Model { model_path } did not pass the { self . error_msg () } ' ) return CmdReturnCodes . OSCAL_VALIDATION_ERROR . value logger . info ( f 'VALID: Model { model_path } passed the { self . error_msg () } ' ) return CmdReturnCodes . SUCCESS . value # validate all if args . all : model_tups = ModelUtils . get_all_models ( trestle_root ) for mt in model_tups : model_dir = trestle_root / ModelUtils . model_type_to_model_dir ( mt [ 0 ]) / mt [ 1 ] extension_type = trestle . common . file_utils . get_contextual_file_type ( model_dir ) model_path = model_dir / f ' { mt [ 0 ] }{ FileContentType . to_file_extension ( extension_type ) } ' _ , _ , model = ModelUtils . load_distributed ( model_path , trestle_root ) if not self . model_is_valid ( model ): logger . info ( f 'INVALID: Model { model_path } did not pass the { self . error_msg () } ' ) return CmdReturnCodes . OSCAL_VALIDATION_ERROR . value logger . info ( f 'VALID: Model { model_path } passed the { self . error_msg () } ' ) return CmdReturnCodes . SUCCESS . value # validate file if args . file : file_path = trestle_root / args . file _ , _ , model = ModelUtils . load_distributed ( file_path , trestle_root ) if not self . model_is_valid ( model ): logger . info ( f 'INVALID: Model { file_path } did not pass the { self . error_msg () } ' ) return CmdReturnCodes . OSCAL_VALIDATION_ERROR . value logger . info ( f 'VALID: Model { file_path } passed the { self . error_msg () } ' ) return CmdReturnCodes . SUCCESS . value","title":"Validator"},{"location":"api_reference/trestle.core.validator/#trestle.core.validator.Validator-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.core.validator/#trestle.core.validator.Validator.error_msg","text":"Error message used to describe this validator. Source code in trestle/core/validator.py def error_msg ( self ) -> str : \"\"\"Error message used to describe this validator.\"\"\" # subclasses can override as needed return self . __doc__","title":"error_msg()"},{"location":"api_reference/trestle.core.validator/#trestle.core.validator.Validator.model_is_valid","text":"Validate the model. Parameters: Name Type Description Default model OscalBaseModel An Oscal model that can be passed to the validator. required Returns: Type Description bool Whether or not the model passed this validation test. Source code in trestle/core/validator.py @abstractmethod def model_is_valid ( self , model : OscalBaseModel ) -> bool : \"\"\" Validate the model. args: model: An Oscal model that can be passed to the validator. returns: Whether or not the model passed this validation test. \"\"\"","title":"model_is_valid()"},{"location":"api_reference/trestle.core.validator/#trestle.core.validator.Validator.validate","text":"Perform the validation according to user options. Source code in trestle/core/validator.py def validate ( self , args : argparse . Namespace ) -> int : \"\"\"Perform the validation according to user options.\"\"\" trestle_root = args . trestle_root # trestle root is set via command line in args. Default is cwd. # validate by type - all of type or just specified by name if args . type : models = [] if args . name : models = [ args . name ] else : models = ModelUtils . get_models_of_type ( args . type , trestle_root ) models_path = trestle_root / ModelUtils . model_type_to_model_dir ( args . type ) for m in models : model_path = models_path / m try : _ , _ , model = ModelUtils . load_distributed ( model_path , trestle_root ) except TrestleError as e : logger . warning ( f 'File load error { e } ' ) return CmdReturnCodes . OSCAL_VALIDATION_ERROR . value if not self . model_is_valid ( model ): logger . info ( f 'INVALID: Model { model_path } did not pass the { self . error_msg () } ' ) return CmdReturnCodes . OSCAL_VALIDATION_ERROR . value logger . info ( f 'VALID: Model { model_path } passed the { self . error_msg () } ' ) return CmdReturnCodes . SUCCESS . value # validate all if args . all : model_tups = ModelUtils . get_all_models ( trestle_root ) for mt in model_tups : model_dir = trestle_root / ModelUtils . model_type_to_model_dir ( mt [ 0 ]) / mt [ 1 ] extension_type = trestle . common . file_utils . get_contextual_file_type ( model_dir ) model_path = model_dir / f ' { mt [ 0 ] }{ FileContentType . to_file_extension ( extension_type ) } ' _ , _ , model = ModelUtils . load_distributed ( model_path , trestle_root ) if not self . model_is_valid ( model ): logger . info ( f 'INVALID: Model { model_path } did not pass the { self . error_msg () } ' ) return CmdReturnCodes . OSCAL_VALIDATION_ERROR . value logger . info ( f 'VALID: Model { model_path } passed the { self . error_msg () } ' ) return CmdReturnCodes . SUCCESS . value # validate file if args . file : file_path = trestle_root / args . file _ , _ , model = ModelUtils . load_distributed ( file_path , trestle_root ) if not self . model_is_valid ( model ): logger . info ( f 'INVALID: Model { file_path } did not pass the { self . error_msg () } ' ) return CmdReturnCodes . OSCAL_VALIDATION_ERROR . value logger . info ( f 'VALID: Model { file_path } passed the { self . error_msg () } ' ) return CmdReturnCodes . SUCCESS . value handler: python","title":"validate()"},{"location":"api_reference/trestle.core.validator_factory/","text":"trestle.core.validator_factory \u00a4 Register all validators here in the validator_factory. validator_factory : ObjectFactory \u00a4 Functions \u00a4 init_arguments ( cmd ) \u00a4 Feed the arguments to the argument parser. Source code in trestle/core/validator_factory.py def init_arguments ( cmd : Command ) -> None : \"\"\"Feed the arguments to the argument parser.\"\"\" group = cmd . parser . add_mutually_exclusive_group ( required = True ) group . add_argument ( '-f' , '--file' , help = 'Path of file in trestle directory to validate.' ) group . add_argument ( '-t' , '--type' , choices = const . MODEL_TYPE_LIST , help = 'Validate one or all models of this type.' ) group . add_argument ( '-a' , '--all' , action = 'store_true' , help = 'Validate all models in trestle directory.' ) cmd . add_argument ( '-n' , '--name' , help = 'Name of single model to validate (with --type specified).' , required = False ) handler: python","title":"validator_factory"},{"location":"api_reference/trestle.core.validator_factory/#trestle.core.validator_factory","text":"Register all validators here in the validator_factory.","title":"validator_factory"},{"location":"api_reference/trestle.core.validator_factory/#trestle.core.validator_factory.validator_factory","text":"","title":"validator_factory"},{"location":"api_reference/trestle.core.validator_factory/#trestle.core.validator_factory-functions","text":"","title":"Functions"},{"location":"api_reference/trestle.core.validator_factory/#trestle.core.validator_factory.init_arguments","text":"Feed the arguments to the argument parser. Source code in trestle/core/validator_factory.py def init_arguments ( cmd : Command ) -> None : \"\"\"Feed the arguments to the argument parser.\"\"\" group = cmd . parser . add_mutually_exclusive_group ( required = True ) group . add_argument ( '-f' , '--file' , help = 'Path of file in trestle directory to validate.' ) group . add_argument ( '-t' , '--type' , choices = const . MODEL_TYPE_LIST , help = 'Validate one or all models of this type.' ) group . add_argument ( '-a' , '--all' , action = 'store_true' , help = 'Validate all models in trestle directory.' ) cmd . add_argument ( '-n' , '--name' , help = 'Name of single model to validate (with --type specified).' , required = False ) handler: python","title":"init_arguments()"},{"location":"api_reference/trestle.oscal.assessment_plan/","text":"trestle.oscal.assessment_plan \u00a4 Classes \u00a4 Activity ( OscalBaseModel ) pydantic-model \u00a4 Identifies an assessment or related process that can be performed. In the assessment plan, this is an intended activity which may be associated with an assessment task. In the assessment results, this an activity that was actually performed as part of an assessment. Source code in trestle/oscal/assessment_plan.py class Activity ( OscalBaseModel ): \"\"\" Identifies an assessment or related process that can be performed. In the assessment plan, this is an intended activity which may be associated with an assessment task. In the assessment results, this an activity that was actually performed as part of an assessment. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment activity elsewhere in this or other OSCAL instances. The locally defined UUID of the activity can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Activity Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this included activity.' , title = 'Included Activity Title' , ) description : str = Field ( ... , description = 'A human-readable description of this included activity.' , title = 'Included Activity Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) steps : Optional [ List [ Step ]] = Field ( None ) related_controls : Optional [ ReviewedControls ] = Field ( None , alias = 'related-controls' ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A human-readable description of this included activity. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 related_controls : ReviewedControls pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 steps : List [ trestle . oscal . assessment_plan . Step ] pydantic-field \u00a4 title : str pydantic-field \u00a4 The title for this included activity. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment activity elsewhere in this or other OSCAL instances. The locally defined UUID of the activity can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid AssessmentAssets ( OscalBaseModel ) pydantic-model \u00a4 Identifies the assets used to perform this assessment, such as the assessment team, scanning tools, and assumptions. Source code in trestle/oscal/assessment_plan.py class AssessmentAssets ( OscalBaseModel ): \"\"\" Identifies the assets used to perform this assessment, such as the assessment team, scanning tools, and assumptions. \"\"\" class Config : extra = Extra . forbid components : Optional [ List [ SystemComponent ]] = Field ( None ) assessment_platforms : List [ common . AssessmentPlatform ] = Field ( ... , alias = 'assessment-platforms' ) assessment_platforms : List [ trestle . oscal . common . AssessmentPlatform ] pydantic-field required \u00a4 components : List [ trestle . oscal . assessment_plan . SystemComponent ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid AssessmentPlan ( OscalBaseModel ) pydantic-model \u00a4 An assessment plan, such as those provided by a FedRAMP assessor. Source code in trestle/oscal/assessment_plan.py class AssessmentPlan ( OscalBaseModel ): \"\"\" An assessment plan, such as those provided by a FedRAMP assessor. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment plan in this or other OSCAL instances. The locally defined UUID of the assessment plan can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Plan Universally Unique Identifier' , ) metadata : common . Metadata import_ssp : common . ImportSsp = Field ( ... , alias = 'import-ssp' ) local_definitions : Optional [ LocalDefinitions ] = Field ( None , alias = 'local-definitions' , description = 'Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP.' , title = 'Local Definitions' , ) terms_and_conditions : Optional [ TermsAndConditions ] = Field ( None , alias = 'terms-and-conditions' , description = 'Used to define various terms and conditions under which an assessment, described by the plan, can be performed. Each child part defines a different type of term or condition.' , title = 'Assessment Plan Terms and Conditions' , ) reviewed_controls : ReviewedControls = Field ( ... , alias = 'reviewed-controls' ) assessment_subjects : Optional [ List [ common . AssessmentSubject ]] = Field ( None , alias = 'assessment-subjects' ) assessment_assets : Optional [ AssessmentAssets ] = Field ( None , alias = 'assessment-assets' ) tasks : Optional [ List [ common . Task ]] = Field ( None ) back_matter : Optional [ common . BackMatter ] = Field ( None , alias = 'back-matter' ) Attributes \u00a4 assessment_assets : AssessmentAssets pydantic-field \u00a4 assessment_subjects : List [ trestle . oscal . common . AssessmentSubject ] pydantic-field \u00a4 back_matter : BackMatter pydantic-field \u00a4 import_ssp : ImportSsp pydantic-field required \u00a4 local_definitions : LocalDefinitions pydantic-field \u00a4 Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP. metadata : Metadata pydantic-field required \u00a4 reviewed_controls : ReviewedControls pydantic-field required \u00a4 tasks : List [ trestle . oscal . common . Task ] pydantic-field \u00a4 terms_and_conditions : TermsAndConditions pydantic-field \u00a4 Used to define various terms and conditions under which an assessment, described by the plan, can be performed. Each child part defines a different type of term or condition. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment plan in this or other OSCAL instances. The locally defined UUID of the assessment plan can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid Characterization ( OscalBaseModel ) pydantic-model \u00a4 A collection of descriptive data about the containing object from a specific origin. Source code in trestle/oscal/assessment_plan.py class Characterization ( OscalBaseModel ): \"\"\" A collection of descriptive data about the containing object from a specific origin. \"\"\" class Config : extra = Extra . forbid props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) origin : Origin facets : List [ common . Facet ] = Field ( ... ) facets : List [ trestle . oscal . common . Facet ] pydantic-field required \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 origin : Origin pydantic-field required \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid ControlSelection ( OscalBaseModel ) pydantic-model \u00a4 Identifies the controls being assessed. In the assessment plan, these are the planned controls. In the assessment results, these are the actual controls, and reflects any changes from the plan. Source code in trestle/oscal/assessment_plan.py class ControlSelection ( OscalBaseModel ): \"\"\" Identifies the controls being assessed. In the assessment plan, these are the planned controls. In the assessment results, these are the actual controls, and reflects any changes from the plan. \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'A human-readable description of in-scope controls specified for assessment.' , title = 'Assessed Controls Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) include_all : Optional [ common . IncludeAll ] = Field ( None , alias = 'include-all' ) include_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'include-controls' ) exclude_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'exclude-controls' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field \u00a4 A human-readable description of in-scope controls specified for assessment. exclude_controls : List [ trestle . oscal . assessment_plan . SelectControlById ] pydantic-field \u00a4 include_all : IncludeAll pydantic-field \u00a4 include_controls : List [ trestle . oscal . assessment_plan . SelectControlById ] pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid Entry ( OscalBaseModel ) pydantic-model \u00a4 Identifies an individual risk response that occurred as part of managing an identified risk. Source code in trestle/oscal/assessment_plan.py class Entry ( OscalBaseModel ): \"\"\" Identifies an individual risk response that occurred as part of managing an identified risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk log entry elsewhere in this or other OSCAL instances. The locally defined UUID of the risk log entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Risk Log Entry Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this risk log entry.' , title = 'Title' ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of what was done regarding the risk.' , title = 'Risk Task Description' , ) start : datetime = Field ( ... , description = 'Identifies the start date and time of the event.' , title = 'Start' , ) end : Optional [ datetime ] = Field ( None , description = 'Identifies the end date and time of the event. If the event is a point in time, the start and end will be the same date and time.' , title = 'End' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) logged_by : Optional [ List [ common . LoggedBy ]] = Field ( None , alias = 'logged-by' ) status_change : Optional [ common . RiskStatus ] = Field ( None , alias = 'status-change' ) related_responses : Optional [ List [ common . RelatedResponse ]] = Field ( None , alias = 'related-responses' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field \u00a4 A human-readable description of what was done regarding the risk. end : datetime pydantic-field \u00a4 Identifies the end date and time of the event. If the event is a point in time, the start and end will be the same date and time. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 logged_by : List [ trestle . oscal . common . LoggedBy ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 related_responses : List [ trestle . oscal . common . RelatedResponse ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 start : datetime pydantic-field required \u00a4 Identifies the start date and time of the event. status_change : RiskStatus pydantic-field \u00a4 title : str pydantic-field \u00a4 The title for this risk log entry. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk log entry elsewhere in this or other OSCAL instances. The locally defined UUID of the risk log entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid FindingTarget ( OscalBaseModel ) pydantic-model \u00a4 Captures an assessor's conclusions regarding the degree to which an objective is satisfied. Source code in trestle/oscal/assessment_plan.py class FindingTarget ( OscalBaseModel ): \"\"\" Captures an assessor's conclusions regarding the degree to which an objective is satisfied. \"\"\" class Config : extra = Extra . forbid type : common . Type1 = Field ( ... , description = 'Identifies the type of the target.' , title = 'Finding Target Type' , ) target_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'target-id' , description = 'A machine-oriented identifier reference for a specific target qualified by the type.' , title = 'Finding Target Identifier Reference' , ) title : Optional [ str ] = Field ( None , description = 'The title for this objective status.' , title = 'Objective Status Title' , ) description : Optional [ str ] = Field ( None , description = \"A human-readable description of the assessor's conclusions regarding the degree to which an objective is satisfied.\" , title = 'Objective Status Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : Status = Field ( ... , description = 'A determination of if the objective is satisfied or not within a given system.' , title = 'Objective Status' , ) implementation_status : Optional [ common . ImplementationStatus ] = Field ( None , alias = 'implementation-status' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field \u00a4 A human-readable description of the assessor's conclusions regarding the degree to which an objective is satisfied. implementation_status : ImplementationStatus pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 status : Status pydantic-field required \u00a4 A determination of if the objective is satisfied or not within a given system. target_id : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference for a specific target qualified by the type. title : str pydantic-field \u00a4 The title for this objective status. type : Type1 pydantic-field required \u00a4 Identifies the type of the target. Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid LocalDefinitions ( OscalBaseModel ) pydantic-model \u00a4 Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP. Source code in trestle/oscal/assessment_plan.py class LocalDefinitions ( OscalBaseModel ): \"\"\" Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP. \"\"\" class Config : extra = Extra . forbid components : Optional [ List [ SystemComponent ]] = Field ( None ) inventory_items : Optional [ List [ common . InventoryItem ]] = Field ( None , alias = 'inventory-items' ) users : Optional [ List [ common . SystemUser ]] = Field ( None ) objectives_and_methods : Optional [ List [ common . LocalObjective ]] = Field ( None , alias = 'objectives-and-methods' ) activities : Optional [ List [ Activity ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None activities : List [ trestle . oscal . assessment_plan . Activity ] pydantic-field \u00a4 components : List [ trestle . oscal . assessment_plan . SystemComponent ] pydantic-field \u00a4 inventory_items : List [ trestle . oscal . common . InventoryItem ] pydantic-field \u00a4 objectives_and_methods : List [ trestle . oscal . common . LocalObjective ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 users : List [ trestle . oscal . common . SystemUser ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid Method ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/assessment_plan.py class Method ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'Identifies how the observation was made.' , title = 'Observation Method' , ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 Identifies how the observation was made. Model ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/assessment_plan.py class Model ( OscalBaseModel ): assessment_plan : AssessmentPlan = Field ( ... , alias = 'assessment-plan' ) assessment_plan : AssessmentPlan pydantic-field required \u00a4 Observation ( OscalBaseModel ) pydantic-model \u00a4 Describes an individual observation. Source code in trestle/oscal/assessment_plan.py class Observation ( OscalBaseModel ): \"\"\" Describes an individual observation. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this observation elsewhere in this or other OSCAL instances. The locally defined UUID of the observation can be used to reference the data item locally or globally (e.g., in an imorted OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Observation Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this observation.' , title = 'Observation Title' ) description : str = Field ( ... , description = 'A human-readable description of this assessment observation.' , title = 'Observation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) methods : List [ Method ] = Field ( ... ) types : Optional [ List [ common . Type2 ]] = Field ( None ) origins : Optional [ List [ Origin ]] = Field ( None ) subjects : Optional [ List [ common . SubjectReference ]] = Field ( None ) relevant_evidence : Optional [ List [ common . RelevantEvidence ]] = Field ( None , alias = 'relevant-evidence' ) collected : datetime = Field ( ... , description = 'Date/time stamp identifying when the finding information was collected.' , title = 'collected field' , ) expires : Optional [ datetime ] = Field ( None , description = 'Date/time identifying when the finding information is out-of-date and no longer valid. Typically used with continuous assessment scenarios.' , title = 'expires field' , ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 collected : datetime pydantic-field required \u00a4 Date/time stamp identifying when the finding information was collected. description : str pydantic-field required \u00a4 A human-readable description of this assessment observation. expires : datetime pydantic-field \u00a4 Date/time identifying when the finding information is out-of-date and no longer valid. Typically used with continuous assessment scenarios. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 methods : List [ trestle . oscal . assessment_plan . Method ] pydantic-field required \u00a4 origins : List [ trestle . oscal . assessment_plan . Origin ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 relevant_evidence : List [ trestle . oscal . common . RelevantEvidence ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 subjects : List [ trestle . oscal . common . SubjectReference ] pydantic-field \u00a4 title : str pydantic-field \u00a4 The title for this observation. types : List [ trestle . oscal . common . Type2 ] pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this observation elsewhere in this or other OSCAL instances. The locally defined UUID of the observation can be used to reference the data item locally or globally (e.g., in an imorted OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid Origin ( OscalBaseModel ) pydantic-model \u00a4 Identifies the source of the finding, such as a tool, interviewed person, or activity. Source code in trestle/oscal/assessment_plan.py class Origin ( OscalBaseModel ): \"\"\" Identifies the source of the finding, such as a tool, interviewed person, or activity. \"\"\" class Config : extra = Extra . forbid actors : List [ common . OriginActor ] = Field ( ... ) related_tasks : Optional [ List [ common . RelatedTask ]] = Field ( None , alias = 'related-tasks' ) actors : List [ trestle . oscal . common . OriginActor ] pydantic-field required \u00a4 related_tasks : List [ trestle . oscal . common . RelatedTask ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid RelatedObservation ( OscalBaseModel ) pydantic-model \u00a4 Relates the finding to a set of referenced observations that were used to determine the finding. Source code in trestle/oscal/assessment_plan.py class RelatedObservation ( OscalBaseModel ): \"\"\" Relates the finding to a set of referenced observations that were used to determine the finding. \"\"\" class Config : extra = Extra . forbid observation_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'observation-uuid' , description = 'A machine-oriented identifier reference to an observation defined in the list of observations.' , title = 'Observation Universally Unique Identifier Reference' , ) Attributes \u00a4 observation_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to an observation defined in the list of observations. Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid Response ( OscalBaseModel ) pydantic-model \u00a4 Describes either recommended or an actual plan for addressing the risk. Source code in trestle/oscal/assessment_plan.py class Response ( OscalBaseModel ): \"\"\" Describes either recommended or an actual plan for addressing the risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this remediation elsewhere in this or other OSCAL instances. The locally defined UUID of the risk response can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Remediation Universally Unique Identifier' , ) lifecycle : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Identifies whether this is a recommendation, such as from an assessor or tool, or an actual plan accepted by the system owner.' , title = 'Remediation Intent' , ) title : str = Field ( ... , description = 'The title for this response activity.' , title = 'Response Title' ) description : str = Field ( ... , description = 'A human-readable description of this response plan.' , title = 'Response Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) origins : Optional [ List [ Origin ]] = Field ( None ) required_assets : Optional [ List [ common . RequiredAsset ]] = Field ( None , alias = 'required-assets' ) tasks : Optional [ List [ common . Task ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A human-readable description of this response plan. lifecycle : ConstrainedStrValue pydantic-field required \u00a4 Identifies whether this is a recommendation, such as from an assessor or tool, or an actual plan accepted by the system owner. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 origins : List [ trestle . oscal . assessment_plan . Origin ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 required_assets : List [ trestle . oscal . common . RequiredAsset ] pydantic-field \u00a4 tasks : List [ trestle . oscal . common . Task ] pydantic-field \u00a4 title : str pydantic-field required \u00a4 The title for this response activity. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this remediation elsewhere in this or other OSCAL instances. The locally defined UUID of the risk response can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid ReviewedControls ( OscalBaseModel ) pydantic-model \u00a4 Identifies the controls being assessed and their control objectives. Source code in trestle/oscal/assessment_plan.py class ReviewedControls ( OscalBaseModel ): \"\"\" Identifies the controls being assessed and their control objectives. \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'A human-readable description of control objectives.' , title = 'Control Objective Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) control_selections : List [ ControlSelection ] = Field ( ... , alias = 'control-selections' ) control_objective_selections : Optional [ List [ common . ControlObjectiveSelection ]] = Field ( None , alias = 'control-objective-selections' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 control_objective_selections : List [ trestle . oscal . common . ControlObjectiveSelection ] pydantic-field \u00a4 control_selections : List [ trestle . oscal . assessment_plan . ControlSelection ] pydantic-field required \u00a4 description : str pydantic-field \u00a4 A human-readable description of control objectives. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid Risk ( OscalBaseModel ) pydantic-model \u00a4 An identified risk. Source code in trestle/oscal/assessment_plan.py class Risk ( OscalBaseModel ): \"\"\" An identified risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk elsewhere in this or other OSCAL instances. The locally defined UUID of the risk can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Risk Universally Unique Identifier' , ) title : str = Field ( ... , description = 'The title for this risk.' , title = 'Risk Title' ) description : str = Field ( ... , description = 'A human-readable summary of the identified risk, to include a statement of how the risk impacts the system.' , title = 'Risk Description' , ) statement : str = Field ( ... , description = 'An summary of impact for how the risk affects the system.' , title = 'Risk Statement' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : common . RiskStatus origins : Optional [ List [ Origin ]] = Field ( None ) threat_ids : Optional [ List [ common . ThreatId ]] = Field ( None , alias = 'threat-ids' ) characterizations : Optional [ List [ Characterization ]] = Field ( None ) mitigating_factors : Optional [ List [ common . MitigatingFactor ]] = Field ( None , alias = 'mitigating-factors' ) deadline : Optional [ datetime ] = Field ( None , description = 'The date/time by which the risk must be resolved.' , title = 'Risk Resolution Deadline' , ) remediations : Optional [ List [ Response ]] = Field ( None ) risk_log : Optional [ RiskLog ] = Field ( None , alias = 'risk-log' , description = 'A log of all risk-related tasks taken.' , title = 'Risk Log' , ) related_observations : Optional [ List [ RelatedObservation ]] = Field ( None , alias = 'related-observations' ) Attributes \u00a4 characterizations : List [ trestle . oscal . assessment_plan . Characterization ] pydantic-field \u00a4 deadline : datetime pydantic-field \u00a4 The date/time by which the risk must be resolved. description : str pydantic-field required \u00a4 A human-readable summary of the identified risk, to include a statement of how the risk impacts the system. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 mitigating_factors : List [ trestle . oscal . common . MitigatingFactor ] pydantic-field \u00a4 origins : List [ trestle . oscal . assessment_plan . Origin ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 related_observations : List [ trestle . oscal . assessment_plan . RelatedObservation ] pydantic-field \u00a4 remediations : List [ trestle . oscal . assessment_plan . Response ] pydantic-field \u00a4 risk_log : RiskLog pydantic-field \u00a4 A log of all risk-related tasks taken. statement : str pydantic-field required \u00a4 An summary of impact for how the risk affects the system. status : RiskStatus pydantic-field required \u00a4 threat_ids : List [ trestle . oscal . common . ThreatId ] pydantic-field \u00a4 title : str pydantic-field required \u00a4 The title for this risk. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk elsewhere in this or other OSCAL instances. The locally defined UUID of the risk can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid RiskLog ( OscalBaseModel ) pydantic-model \u00a4 A log of all risk-related tasks taken. Source code in trestle/oscal/assessment_plan.py class RiskLog ( OscalBaseModel ): \"\"\" A log of all risk-related tasks taken. \"\"\" class Config : extra = Extra . forbid entries : List [ Entry ] = Field ( ... ) entries : List [ trestle . oscal . assessment_plan . Entry ] pydantic-field required \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid SelectControlById ( OscalBaseModel ) pydantic-model \u00a4 Used to select a control for inclusion/exclusion based on one or more control identifiers. A set of statement identifiers can be used to target the inclusion/exclusion to only specific control statements providing more granularity over the specific statements that are within the asessment scope. Source code in trestle/oscal/assessment_plan.py class SelectControlById ( OscalBaseModel ): \"\"\" Used to select a control for inclusion/exclusion based on one or more control identifiers. A set of statement identifiers can be used to target the inclusion/exclusion to only specific control statements providing more granularity over the specific statements that are within the asessment scope. \"\"\" class Config : extra = Extra . forbid control_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'control-id' , description = 'A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).' , title = 'Control Identifier Reference' , ) statement_ids : Optional [ List [ common . StatementId ]] = Field ( None , alias = 'statement-ids' ) Attributes \u00a4 control_id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference). statement_ids : List [ trestle . oscal . common . StatementId ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid SetParameter ( OscalBaseModel ) pydantic-model \u00a4 Identifies the parameter that will be set by the enclosed value. Source code in trestle/oscal/assessment_plan.py class SetParameter ( OscalBaseModel ): \"\"\" Identifies the parameter that will be set by the enclosed value. \"\"\" class Config : extra = Extra . forbid param_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'param-id' , description = \"A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context.\" , title = 'Parameter ID' , ) values : List [ common . Value ] = Field ( ... ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 param_id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context. remarks : Remarks pydantic-field \u00a4 values : List [ trestle . oscal . common . Value ] pydantic-field required \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid State ( Enum ) \u00a4 An indication as to whether the objective is satisfied or not. Source code in trestle/oscal/assessment_plan.py class State ( Enum ): \"\"\" An indication as to whether the objective is satisfied or not. \"\"\" satisfied = 'satisfied' not_satisfied = 'not-satisfied' not_satisfied \u00a4 satisfied \u00a4 State1 ( Enum ) \u00a4 The operational status. Source code in trestle/oscal/assessment_plan.py class State1 ( Enum ): \"\"\" The operational status. \"\"\" under_development = 'under-development' operational = 'operational' disposition = 'disposition' other = 'other' disposition \u00a4 operational \u00a4 other \u00a4 under_development \u00a4 Status ( OscalBaseModel ) pydantic-model \u00a4 A determination of if the objective is satisfied or not within a given system. Source code in trestle/oscal/assessment_plan.py class Status ( OscalBaseModel ): \"\"\" A determination of if the objective is satisfied or not within a given system. \"\"\" class Config : extra = Extra . forbid state : State = Field ( ... , description = 'An indication as to whether the objective is satisfied or not.' , title = 'Objective Status State' , ) reason : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , description = \"The reason the objective was given it's status.\" , title = 'Objective Status Reason' , ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 reason : ConstrainedStrValue pydantic-field \u00a4 The reason the objective was given it's status. remarks : Remarks pydantic-field \u00a4 state : State pydantic-field required \u00a4 An indication as to whether the objective is satisfied or not. Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid Status1 ( OscalBaseModel ) pydantic-model \u00a4 Describes the operational status of the system component. Source code in trestle/oscal/assessment_plan.py class Status1 ( OscalBaseModel ): \"\"\" Describes the operational status of the system component. \"\"\" class Config : extra = Extra . forbid state : State1 = Field ( ... , description = 'The operational status.' , title = 'State' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 remarks : Remarks pydantic-field \u00a4 state : State1 pydantic-field required \u00a4 The operational status. Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid Step ( OscalBaseModel ) pydantic-model \u00a4 Identifies an individual step in a series of steps related to an activity, such as an assessment test or examination procedure. Source code in trestle/oscal/assessment_plan.py class Step ( OscalBaseModel ): \"\"\" Identifies an individual step in a series of steps related to an activity, such as an assessment test or examination procedure. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this step elsewhere in this or other OSCAL instances. The locally defined UUID of the step (in a series of steps) can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Step Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this step.' , title = 'Step Title' ) description : str = Field ( ... , description = 'A human-readable description of this step.' , title = 'Step Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) reviewed_controls : Optional [ ReviewedControls ] = Field ( None , alias = 'reviewed-controls' ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A human-readable description of this step. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 reviewed_controls : ReviewedControls pydantic-field \u00a4 title : str pydantic-field \u00a4 The title for this step. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this step elsewhere in this or other OSCAL instances. The locally defined UUID of the step (in a series of steps) can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid SystemComponent ( OscalBaseModel ) pydantic-model \u00a4 A defined component that can be part of an implemented system. Source code in trestle/oscal/assessment_plan.py class SystemComponent ( OscalBaseModel ): \"\"\" A defined component that can be part of an implemented system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Component Identifier' , ) type : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A category describing the purpose of the component.' , title = 'Component Type' , ) title : str = Field ( ... , description = 'A human readable name for the system component.' , title = 'Component Title' , ) description : str = Field ( ... , description = 'A description of the component, including information about its function.' , title = 'Component Description' , ) purpose : Optional [ str ] = Field ( None , description = 'A summary of the technological or business purpose of the component.' , title = 'Purpose' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : Status1 = Field ( ... , description = 'Describes the operational status of the system component.' , title = 'Status' , ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) protocols : Optional [ List [ common . Protocol ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A description of the component, including information about its function. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 protocols : List [ trestle . oscal . common . Protocol ] pydantic-field \u00a4 purpose : str pydantic-field \u00a4 A summary of the technological or business purpose of the component. remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 status : Status1 pydantic-field required \u00a4 Describes the operational status of the system component. title : str pydantic-field required \u00a4 A human readable name for the system component. type : ConstrainedStrValue pydantic-field required \u00a4 A category describing the purpose of the component. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid TermsAndConditions ( OscalBaseModel ) pydantic-model \u00a4 Used to define various terms and conditions under which an assessment, described by the plan, can be performed. Each child part defines a different type of term or condition. Source code in trestle/oscal/assessment_plan.py class TermsAndConditions ( OscalBaseModel ): \"\"\" Used to define various terms and conditions under which an assessment, described by the plan, can be performed. Each child part defines a different type of term or condition. \"\"\" class Config : extra = Extra . forbid parts : Optional [ List [ common . AssessmentPart ]] = Field ( None ) parts : List [ trestle . oscal . common . AssessmentPart ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid handler: python","title":"assessment_plan"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan","text":"","title":"assessment_plan"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Activity","text":"Identifies an assessment or related process that can be performed. In the assessment plan, this is an intended activity which may be associated with an assessment task. In the assessment results, this an activity that was actually performed as part of an assessment. Source code in trestle/oscal/assessment_plan.py class Activity ( OscalBaseModel ): \"\"\" Identifies an assessment or related process that can be performed. In the assessment plan, this is an intended activity which may be associated with an assessment task. In the assessment results, this an activity that was actually performed as part of an assessment. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment activity elsewhere in this or other OSCAL instances. The locally defined UUID of the activity can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Activity Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this included activity.' , title = 'Included Activity Title' , ) description : str = Field ( ... , description = 'A human-readable description of this included activity.' , title = 'Included Activity Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) steps : Optional [ List [ Step ]] = Field ( None ) related_controls : Optional [ ReviewedControls ] = Field ( None , alias = 'related-controls' ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None","title":"Activity"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Activity-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Activity.description","text":"A human-readable description of this included activity.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Activity.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Activity.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Activity.related_controls","text":"","title":"related_controls"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Activity.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Activity.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Activity.steps","text":"","title":"steps"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Activity.title","text":"The title for this included activity.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Activity.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment activity elsewhere in this or other OSCAL instances. The locally defined UUID of the activity can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Activity.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.AssessmentAssets","text":"Identifies the assets used to perform this assessment, such as the assessment team, scanning tools, and assumptions. Source code in trestle/oscal/assessment_plan.py class AssessmentAssets ( OscalBaseModel ): \"\"\" Identifies the assets used to perform this assessment, such as the assessment team, scanning tools, and assumptions. \"\"\" class Config : extra = Extra . forbid components : Optional [ List [ SystemComponent ]] = Field ( None ) assessment_platforms : List [ common . AssessmentPlatform ] = Field ( ... , alias = 'assessment-platforms' )","title":"AssessmentAssets"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.AssessmentAssets.assessment_platforms","text":"","title":"assessment_platforms"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.AssessmentAssets.components","text":"","title":"components"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.AssessmentAssets.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.AssessmentPlan","text":"An assessment plan, such as those provided by a FedRAMP assessor. Source code in trestle/oscal/assessment_plan.py class AssessmentPlan ( OscalBaseModel ): \"\"\" An assessment plan, such as those provided by a FedRAMP assessor. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment plan in this or other OSCAL instances. The locally defined UUID of the assessment plan can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Plan Universally Unique Identifier' , ) metadata : common . Metadata import_ssp : common . ImportSsp = Field ( ... , alias = 'import-ssp' ) local_definitions : Optional [ LocalDefinitions ] = Field ( None , alias = 'local-definitions' , description = 'Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP.' , title = 'Local Definitions' , ) terms_and_conditions : Optional [ TermsAndConditions ] = Field ( None , alias = 'terms-and-conditions' , description = 'Used to define various terms and conditions under which an assessment, described by the plan, can be performed. Each child part defines a different type of term or condition.' , title = 'Assessment Plan Terms and Conditions' , ) reviewed_controls : ReviewedControls = Field ( ... , alias = 'reviewed-controls' ) assessment_subjects : Optional [ List [ common . AssessmentSubject ]] = Field ( None , alias = 'assessment-subjects' ) assessment_assets : Optional [ AssessmentAssets ] = Field ( None , alias = 'assessment-assets' ) tasks : Optional [ List [ common . Task ]] = Field ( None ) back_matter : Optional [ common . BackMatter ] = Field ( None , alias = 'back-matter' )","title":"AssessmentPlan"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.AssessmentPlan-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.AssessmentPlan.assessment_assets","text":"","title":"assessment_assets"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.AssessmentPlan.assessment_subjects","text":"","title":"assessment_subjects"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.AssessmentPlan.back_matter","text":"","title":"back_matter"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.AssessmentPlan.import_ssp","text":"","title":"import_ssp"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.AssessmentPlan.local_definitions","text":"Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP.","title":"local_definitions"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.AssessmentPlan.metadata","text":"","title":"metadata"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.AssessmentPlan.reviewed_controls","text":"","title":"reviewed_controls"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.AssessmentPlan.tasks","text":"","title":"tasks"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.AssessmentPlan.terms_and_conditions","text":"Used to define various terms and conditions under which an assessment, described by the plan, can be performed. Each child part defines a different type of term or condition.","title":"terms_and_conditions"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.AssessmentPlan.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment plan in this or other OSCAL instances. The locally defined UUID of the assessment plan can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.AssessmentPlan.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Characterization","text":"A collection of descriptive data about the containing object from a specific origin. Source code in trestle/oscal/assessment_plan.py class Characterization ( OscalBaseModel ): \"\"\" A collection of descriptive data about the containing object from a specific origin. \"\"\" class Config : extra = Extra . forbid props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) origin : Origin facets : List [ common . Facet ] = Field ( ... )","title":"Characterization"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Characterization.facets","text":"","title":"facets"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Characterization.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Characterization.origin","text":"","title":"origin"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Characterization.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Characterization.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ControlSelection","text":"Identifies the controls being assessed. In the assessment plan, these are the planned controls. In the assessment results, these are the actual controls, and reflects any changes from the plan. Source code in trestle/oscal/assessment_plan.py class ControlSelection ( OscalBaseModel ): \"\"\" Identifies the controls being assessed. In the assessment plan, these are the planned controls. In the assessment results, these are the actual controls, and reflects any changes from the plan. \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'A human-readable description of in-scope controls specified for assessment.' , title = 'Assessed Controls Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) include_all : Optional [ common . IncludeAll ] = Field ( None , alias = 'include-all' ) include_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'include-controls' ) exclude_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'exclude-controls' ) remarks : Optional [ common . Remarks ] = None","title":"ControlSelection"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ControlSelection-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ControlSelection.description","text":"A human-readable description of in-scope controls specified for assessment.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ControlSelection.exclude_controls","text":"","title":"exclude_controls"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ControlSelection.include_all","text":"","title":"include_all"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ControlSelection.include_controls","text":"","title":"include_controls"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ControlSelection.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ControlSelection.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ControlSelection.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ControlSelection.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Entry","text":"Identifies an individual risk response that occurred as part of managing an identified risk. Source code in trestle/oscal/assessment_plan.py class Entry ( OscalBaseModel ): \"\"\" Identifies an individual risk response that occurred as part of managing an identified risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk log entry elsewhere in this or other OSCAL instances. The locally defined UUID of the risk log entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Risk Log Entry Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this risk log entry.' , title = 'Title' ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of what was done regarding the risk.' , title = 'Risk Task Description' , ) start : datetime = Field ( ... , description = 'Identifies the start date and time of the event.' , title = 'Start' , ) end : Optional [ datetime ] = Field ( None , description = 'Identifies the end date and time of the event. If the event is a point in time, the start and end will be the same date and time.' , title = 'End' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) logged_by : Optional [ List [ common . LoggedBy ]] = Field ( None , alias = 'logged-by' ) status_change : Optional [ common . RiskStatus ] = Field ( None , alias = 'status-change' ) related_responses : Optional [ List [ common . RelatedResponse ]] = Field ( None , alias = 'related-responses' ) remarks : Optional [ common . Remarks ] = None","title":"Entry"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Entry-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Entry.description","text":"A human-readable description of what was done regarding the risk.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Entry.end","text":"Identifies the end date and time of the event. If the event is a point in time, the start and end will be the same date and time.","title":"end"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Entry.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Entry.logged_by","text":"","title":"logged_by"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Entry.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Entry.related_responses","text":"","title":"related_responses"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Entry.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Entry.start","text":"Identifies the start date and time of the event.","title":"start"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Entry.status_change","text":"","title":"status_change"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Entry.title","text":"The title for this risk log entry.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Entry.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk log entry elsewhere in this or other OSCAL instances. The locally defined UUID of the risk log entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Entry.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.FindingTarget","text":"Captures an assessor's conclusions regarding the degree to which an objective is satisfied. Source code in trestle/oscal/assessment_plan.py class FindingTarget ( OscalBaseModel ): \"\"\" Captures an assessor's conclusions regarding the degree to which an objective is satisfied. \"\"\" class Config : extra = Extra . forbid type : common . Type1 = Field ( ... , description = 'Identifies the type of the target.' , title = 'Finding Target Type' , ) target_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'target-id' , description = 'A machine-oriented identifier reference for a specific target qualified by the type.' , title = 'Finding Target Identifier Reference' , ) title : Optional [ str ] = Field ( None , description = 'The title for this objective status.' , title = 'Objective Status Title' , ) description : Optional [ str ] = Field ( None , description = \"A human-readable description of the assessor's conclusions regarding the degree to which an objective is satisfied.\" , title = 'Objective Status Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : Status = Field ( ... , description = 'A determination of if the objective is satisfied or not within a given system.' , title = 'Objective Status' , ) implementation_status : Optional [ common . ImplementationStatus ] = Field ( None , alias = 'implementation-status' ) remarks : Optional [ common . Remarks ] = None","title":"FindingTarget"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.FindingTarget-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.FindingTarget.description","text":"A human-readable description of the assessor's conclusions regarding the degree to which an objective is satisfied.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.FindingTarget.implementation_status","text":"","title":"implementation_status"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.FindingTarget.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.FindingTarget.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.FindingTarget.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.FindingTarget.status","text":"A determination of if the objective is satisfied or not within a given system.","title":"status"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.FindingTarget.target_id","text":"A machine-oriented identifier reference for a specific target qualified by the type.","title":"target_id"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.FindingTarget.title","text":"The title for this objective status.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.FindingTarget.type","text":"Identifies the type of the target.","title":"type"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.FindingTarget.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.LocalDefinitions","text":"Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP. Source code in trestle/oscal/assessment_plan.py class LocalDefinitions ( OscalBaseModel ): \"\"\" Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP. \"\"\" class Config : extra = Extra . forbid components : Optional [ List [ SystemComponent ]] = Field ( None ) inventory_items : Optional [ List [ common . InventoryItem ]] = Field ( None , alias = 'inventory-items' ) users : Optional [ List [ common . SystemUser ]] = Field ( None ) objectives_and_methods : Optional [ List [ common . LocalObjective ]] = Field ( None , alias = 'objectives-and-methods' ) activities : Optional [ List [ Activity ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None","title":"LocalDefinitions"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.LocalDefinitions.activities","text":"","title":"activities"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.LocalDefinitions.components","text":"","title":"components"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.LocalDefinitions.inventory_items","text":"","title":"inventory_items"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.LocalDefinitions.objectives_and_methods","text":"","title":"objectives_and_methods"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.LocalDefinitions.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.LocalDefinitions.users","text":"","title":"users"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.LocalDefinitions.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Method","text":"Source code in trestle/oscal/assessment_plan.py class Method ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'Identifies how the observation was made.' , title = 'Observation Method' , )","title":"Method"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Method-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Method.__root__","text":"Identifies how the observation was made.","title":"__root__"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Model","text":"Source code in trestle/oscal/assessment_plan.py class Model ( OscalBaseModel ): assessment_plan : AssessmentPlan = Field ( ... , alias = 'assessment-plan' )","title":"Model"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Model.assessment_plan","text":"","title":"assessment_plan"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Observation","text":"Describes an individual observation. Source code in trestle/oscal/assessment_plan.py class Observation ( OscalBaseModel ): \"\"\" Describes an individual observation. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this observation elsewhere in this or other OSCAL instances. The locally defined UUID of the observation can be used to reference the data item locally or globally (e.g., in an imorted OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Observation Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this observation.' , title = 'Observation Title' ) description : str = Field ( ... , description = 'A human-readable description of this assessment observation.' , title = 'Observation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) methods : List [ Method ] = Field ( ... ) types : Optional [ List [ common . Type2 ]] = Field ( None ) origins : Optional [ List [ Origin ]] = Field ( None ) subjects : Optional [ List [ common . SubjectReference ]] = Field ( None ) relevant_evidence : Optional [ List [ common . RelevantEvidence ]] = Field ( None , alias = 'relevant-evidence' ) collected : datetime = Field ( ... , description = 'Date/time stamp identifying when the finding information was collected.' , title = 'collected field' , ) expires : Optional [ datetime ] = Field ( None , description = 'Date/time identifying when the finding information is out-of-date and no longer valid. Typically used with continuous assessment scenarios.' , title = 'expires field' , ) remarks : Optional [ common . Remarks ] = None","title":"Observation"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Observation-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Observation.collected","text":"Date/time stamp identifying when the finding information was collected.","title":"collected"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Observation.description","text":"A human-readable description of this assessment observation.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Observation.expires","text":"Date/time identifying when the finding information is out-of-date and no longer valid. Typically used with continuous assessment scenarios.","title":"expires"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Observation.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Observation.methods","text":"","title":"methods"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Observation.origins","text":"","title":"origins"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Observation.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Observation.relevant_evidence","text":"","title":"relevant_evidence"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Observation.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Observation.subjects","text":"","title":"subjects"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Observation.title","text":"The title for this observation.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Observation.types","text":"","title":"types"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Observation.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this observation elsewhere in this or other OSCAL instances. The locally defined UUID of the observation can be used to reference the data item locally or globally (e.g., in an imorted OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Observation.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Origin","text":"Identifies the source of the finding, such as a tool, interviewed person, or activity. Source code in trestle/oscal/assessment_plan.py class Origin ( OscalBaseModel ): \"\"\" Identifies the source of the finding, such as a tool, interviewed person, or activity. \"\"\" class Config : extra = Extra . forbid actors : List [ common . OriginActor ] = Field ( ... ) related_tasks : Optional [ List [ common . RelatedTask ]] = Field ( None , alias = 'related-tasks' )","title":"Origin"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Origin.actors","text":"","title":"actors"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Origin.related_tasks","text":"","title":"related_tasks"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Origin.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.RelatedObservation","text":"Relates the finding to a set of referenced observations that were used to determine the finding. Source code in trestle/oscal/assessment_plan.py class RelatedObservation ( OscalBaseModel ): \"\"\" Relates the finding to a set of referenced observations that were used to determine the finding. \"\"\" class Config : extra = Extra . forbid observation_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'observation-uuid' , description = 'A machine-oriented identifier reference to an observation defined in the list of observations.' , title = 'Observation Universally Unique Identifier Reference' , )","title":"RelatedObservation"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.RelatedObservation-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.RelatedObservation.observation_uuid","text":"A machine-oriented identifier reference to an observation defined in the list of observations.","title":"observation_uuid"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.RelatedObservation.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Response","text":"Describes either recommended or an actual plan for addressing the risk. Source code in trestle/oscal/assessment_plan.py class Response ( OscalBaseModel ): \"\"\" Describes either recommended or an actual plan for addressing the risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this remediation elsewhere in this or other OSCAL instances. The locally defined UUID of the risk response can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Remediation Universally Unique Identifier' , ) lifecycle : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Identifies whether this is a recommendation, such as from an assessor or tool, or an actual plan accepted by the system owner.' , title = 'Remediation Intent' , ) title : str = Field ( ... , description = 'The title for this response activity.' , title = 'Response Title' ) description : str = Field ( ... , description = 'A human-readable description of this response plan.' , title = 'Response Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) origins : Optional [ List [ Origin ]] = Field ( None ) required_assets : Optional [ List [ common . RequiredAsset ]] = Field ( None , alias = 'required-assets' ) tasks : Optional [ List [ common . Task ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None","title":"Response"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Response-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Response.description","text":"A human-readable description of this response plan.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Response.lifecycle","text":"Identifies whether this is a recommendation, such as from an assessor or tool, or an actual plan accepted by the system owner.","title":"lifecycle"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Response.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Response.origins","text":"","title":"origins"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Response.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Response.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Response.required_assets","text":"","title":"required_assets"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Response.tasks","text":"","title":"tasks"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Response.title","text":"The title for this response activity.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Response.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this remediation elsewhere in this or other OSCAL instances. The locally defined UUID of the risk response can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Response.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ReviewedControls","text":"Identifies the controls being assessed and their control objectives. Source code in trestle/oscal/assessment_plan.py class ReviewedControls ( OscalBaseModel ): \"\"\" Identifies the controls being assessed and their control objectives. \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'A human-readable description of control objectives.' , title = 'Control Objective Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) control_selections : List [ ControlSelection ] = Field ( ... , alias = 'control-selections' ) control_objective_selections : Optional [ List [ common . ControlObjectiveSelection ]] = Field ( None , alias = 'control-objective-selections' ) remarks : Optional [ common . Remarks ] = None","title":"ReviewedControls"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ReviewedControls-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ReviewedControls.control_objective_selections","text":"","title":"control_objective_selections"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ReviewedControls.control_selections","text":"","title":"control_selections"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ReviewedControls.description","text":"A human-readable description of control objectives.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ReviewedControls.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ReviewedControls.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ReviewedControls.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.ReviewedControls.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk","text":"An identified risk. Source code in trestle/oscal/assessment_plan.py class Risk ( OscalBaseModel ): \"\"\" An identified risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk elsewhere in this or other OSCAL instances. The locally defined UUID of the risk can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Risk Universally Unique Identifier' , ) title : str = Field ( ... , description = 'The title for this risk.' , title = 'Risk Title' ) description : str = Field ( ... , description = 'A human-readable summary of the identified risk, to include a statement of how the risk impacts the system.' , title = 'Risk Description' , ) statement : str = Field ( ... , description = 'An summary of impact for how the risk affects the system.' , title = 'Risk Statement' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : common . RiskStatus origins : Optional [ List [ Origin ]] = Field ( None ) threat_ids : Optional [ List [ common . ThreatId ]] = Field ( None , alias = 'threat-ids' ) characterizations : Optional [ List [ Characterization ]] = Field ( None ) mitigating_factors : Optional [ List [ common . MitigatingFactor ]] = Field ( None , alias = 'mitigating-factors' ) deadline : Optional [ datetime ] = Field ( None , description = 'The date/time by which the risk must be resolved.' , title = 'Risk Resolution Deadline' , ) remediations : Optional [ List [ Response ]] = Field ( None ) risk_log : Optional [ RiskLog ] = Field ( None , alias = 'risk-log' , description = 'A log of all risk-related tasks taken.' , title = 'Risk Log' , ) related_observations : Optional [ List [ RelatedObservation ]] = Field ( None , alias = 'related-observations' )","title":"Risk"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk.characterizations","text":"","title":"characterizations"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk.deadline","text":"The date/time by which the risk must be resolved.","title":"deadline"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk.description","text":"A human-readable summary of the identified risk, to include a statement of how the risk impacts the system.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk.mitigating_factors","text":"","title":"mitigating_factors"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk.origins","text":"","title":"origins"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk.related_observations","text":"","title":"related_observations"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk.remediations","text":"","title":"remediations"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk.risk_log","text":"A log of all risk-related tasks taken.","title":"risk_log"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk.statement","text":"An summary of impact for how the risk affects the system.","title":"statement"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk.status","text":"","title":"status"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk.threat_ids","text":"","title":"threat_ids"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk.title","text":"The title for this risk.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk elsewhere in this or other OSCAL instances. The locally defined UUID of the risk can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Risk.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.RiskLog","text":"A log of all risk-related tasks taken. Source code in trestle/oscal/assessment_plan.py class RiskLog ( OscalBaseModel ): \"\"\" A log of all risk-related tasks taken. \"\"\" class Config : extra = Extra . forbid entries : List [ Entry ] = Field ( ... )","title":"RiskLog"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.RiskLog.entries","text":"","title":"entries"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.RiskLog.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SelectControlById","text":"Used to select a control for inclusion/exclusion based on one or more control identifiers. A set of statement identifiers can be used to target the inclusion/exclusion to only specific control statements providing more granularity over the specific statements that are within the asessment scope. Source code in trestle/oscal/assessment_plan.py class SelectControlById ( OscalBaseModel ): \"\"\" Used to select a control for inclusion/exclusion based on one or more control identifiers. A set of statement identifiers can be used to target the inclusion/exclusion to only specific control statements providing more granularity over the specific statements that are within the asessment scope. \"\"\" class Config : extra = Extra . forbid control_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'control-id' , description = 'A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).' , title = 'Control Identifier Reference' , ) statement_ids : Optional [ List [ common . StatementId ]] = Field ( None , alias = 'statement-ids' )","title":"SelectControlById"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SelectControlById-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SelectControlById.control_id","text":"A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).","title":"control_id"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SelectControlById.statement_ids","text":"","title":"statement_ids"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SelectControlById.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SetParameter","text":"Identifies the parameter that will be set by the enclosed value. Source code in trestle/oscal/assessment_plan.py class SetParameter ( OscalBaseModel ): \"\"\" Identifies the parameter that will be set by the enclosed value. \"\"\" class Config : extra = Extra . forbid param_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'param-id' , description = \"A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context.\" , title = 'Parameter ID' , ) values : List [ common . Value ] = Field ( ... ) remarks : Optional [ common . Remarks ] = None","title":"SetParameter"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SetParameter-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SetParameter.param_id","text":"A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context.","title":"param_id"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SetParameter.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SetParameter.values","text":"","title":"values"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SetParameter.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.State","text":"An indication as to whether the objective is satisfied or not. Source code in trestle/oscal/assessment_plan.py class State ( Enum ): \"\"\" An indication as to whether the objective is satisfied or not. \"\"\" satisfied = 'satisfied' not_satisfied = 'not-satisfied'","title":"State"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.State.not_satisfied","text":"","title":"not_satisfied"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.State.satisfied","text":"","title":"satisfied"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.State1","text":"The operational status. Source code in trestle/oscal/assessment_plan.py class State1 ( Enum ): \"\"\" The operational status. \"\"\" under_development = 'under-development' operational = 'operational' disposition = 'disposition' other = 'other'","title":"State1"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.State1.disposition","text":"","title":"disposition"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.State1.operational","text":"","title":"operational"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.State1.other","text":"","title":"other"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.State1.under_development","text":"","title":"under_development"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Status","text":"A determination of if the objective is satisfied or not within a given system. Source code in trestle/oscal/assessment_plan.py class Status ( OscalBaseModel ): \"\"\" A determination of if the objective is satisfied or not within a given system. \"\"\" class Config : extra = Extra . forbid state : State = Field ( ... , description = 'An indication as to whether the objective is satisfied or not.' , title = 'Objective Status State' , ) reason : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , description = \"The reason the objective was given it's status.\" , title = 'Objective Status Reason' , ) remarks : Optional [ common . Remarks ] = None","title":"Status"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Status-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Status.reason","text":"The reason the objective was given it's status.","title":"reason"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Status.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Status.state","text":"An indication as to whether the objective is satisfied or not.","title":"state"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Status.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Status1","text":"Describes the operational status of the system component. Source code in trestle/oscal/assessment_plan.py class Status1 ( OscalBaseModel ): \"\"\" Describes the operational status of the system component. \"\"\" class Config : extra = Extra . forbid state : State1 = Field ( ... , description = 'The operational status.' , title = 'State' ) remarks : Optional [ common . Remarks ] = None","title":"Status1"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Status1-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Status1.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Status1.state","text":"The operational status.","title":"state"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Status1.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Step","text":"Identifies an individual step in a series of steps related to an activity, such as an assessment test or examination procedure. Source code in trestle/oscal/assessment_plan.py class Step ( OscalBaseModel ): \"\"\" Identifies an individual step in a series of steps related to an activity, such as an assessment test or examination procedure. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this step elsewhere in this or other OSCAL instances. The locally defined UUID of the step (in a series of steps) can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Step Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this step.' , title = 'Step Title' ) description : str = Field ( ... , description = 'A human-readable description of this step.' , title = 'Step Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) reviewed_controls : Optional [ ReviewedControls ] = Field ( None , alias = 'reviewed-controls' ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None","title":"Step"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Step-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Step.description","text":"A human-readable description of this step.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Step.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Step.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Step.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Step.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Step.reviewed_controls","text":"","title":"reviewed_controls"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Step.title","text":"The title for this step.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Step.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this step elsewhere in this or other OSCAL instances. The locally defined UUID of the step (in a series of steps) can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.Step.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SystemComponent","text":"A defined component that can be part of an implemented system. Source code in trestle/oscal/assessment_plan.py class SystemComponent ( OscalBaseModel ): \"\"\" A defined component that can be part of an implemented system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Component Identifier' , ) type : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A category describing the purpose of the component.' , title = 'Component Type' , ) title : str = Field ( ... , description = 'A human readable name for the system component.' , title = 'Component Title' , ) description : str = Field ( ... , description = 'A description of the component, including information about its function.' , title = 'Component Description' , ) purpose : Optional [ str ] = Field ( None , description = 'A summary of the technological or business purpose of the component.' , title = 'Purpose' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : Status1 = Field ( ... , description = 'Describes the operational status of the system component.' , title = 'Status' , ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) protocols : Optional [ List [ common . Protocol ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None","title":"SystemComponent"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SystemComponent-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SystemComponent.description","text":"A description of the component, including information about its function.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SystemComponent.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SystemComponent.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SystemComponent.protocols","text":"","title":"protocols"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SystemComponent.purpose","text":"A summary of the technological or business purpose of the component.","title":"purpose"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SystemComponent.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SystemComponent.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SystemComponent.status","text":"Describes the operational status of the system component.","title":"status"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SystemComponent.title","text":"A human readable name for the system component.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SystemComponent.type","text":"A category describing the purpose of the component.","title":"type"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SystemComponent.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.SystemComponent.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.TermsAndConditions","text":"Used to define various terms and conditions under which an assessment, described by the plan, can be performed. Each child part defines a different type of term or condition. Source code in trestle/oscal/assessment_plan.py class TermsAndConditions ( OscalBaseModel ): \"\"\" Used to define various terms and conditions under which an assessment, described by the plan, can be performed. Each child part defines a different type of term or condition. \"\"\" class Config : extra = Extra . forbid parts : Optional [ List [ common . AssessmentPart ]] = Field ( None )","title":"TermsAndConditions"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.TermsAndConditions.parts","text":"","title":"parts"},{"location":"api_reference/trestle.oscal.assessment_plan/#trestle.oscal.assessment_plan.TermsAndConditions.Config","text":"Source code in trestle/oscal/assessment_plan.py class Config : extra = Extra . forbid handler: python","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/","text":"trestle.oscal.assessment_results \u00a4 Classes \u00a4 Activity ( OscalBaseModel ) pydantic-model \u00a4 Identifies an assessment or related process that can be performed. In the assessment plan, this is an intended activity which may be associated with an assessment task. In the assessment results, this an activity that was actually performed as part of an assessment. Source code in trestle/oscal/assessment_results.py class Activity ( OscalBaseModel ): \"\"\" Identifies an assessment or related process that can be performed. In the assessment plan, this is an intended activity which may be associated with an assessment task. In the assessment results, this an activity that was actually performed as part of an assessment. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment activity elsewhere in this or other OSCAL instances. The locally defined UUID of the activity can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Activity Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this included activity.' , title = 'Included Activity Title' , ) description : str = Field ( ... , description = 'A human-readable description of this included activity.' , title = 'Included Activity Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) steps : Optional [ List [ Step ]] = Field ( None ) related_controls : Optional [ ReviewedControls ] = Field ( None , alias = 'related-controls' ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A human-readable description of this included activity. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 related_controls : ReviewedControls pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 steps : List [ trestle . oscal . assessment_results . Step ] pydantic-field \u00a4 title : str pydantic-field \u00a4 The title for this included activity. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment activity elsewhere in this or other OSCAL instances. The locally defined UUID of the activity can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid AssessmentAssets ( OscalBaseModel ) pydantic-model \u00a4 Identifies the assets used to perform this assessment, such as the assessment team, scanning tools, and assumptions. Source code in trestle/oscal/assessment_results.py class AssessmentAssets ( OscalBaseModel ): \"\"\" Identifies the assets used to perform this assessment, such as the assessment team, scanning tools, and assumptions. \"\"\" class Config : extra = Extra . forbid components : Optional [ List [ SystemComponent ]] = Field ( None ) assessment_platforms : List [ common . AssessmentPlatform ] = Field ( ... , alias = 'assessment-platforms' ) assessment_platforms : List [ trestle . oscal . common . AssessmentPlatform ] pydantic-field required \u00a4 components : List [ trestle . oscal . assessment_results . SystemComponent ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid AssessmentLog ( OscalBaseModel ) pydantic-model \u00a4 A log of all assessment-related actions taken. Source code in trestle/oscal/assessment_results.py class AssessmentLog ( OscalBaseModel ): \"\"\" A log of all assessment-related actions taken. \"\"\" class Config : extra = Extra . forbid entries : List [ Entry ] = Field ( ... ) entries : List [ trestle . oscal . assessment_results . Entry ] pydantic-field required \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid AssessmentResults ( OscalBaseModel ) pydantic-model \u00a4 Security assessment results, such as those provided by a FedRAMP assessor in the FedRAMP Security Assessment Report. Source code in trestle/oscal/assessment_results.py class AssessmentResults ( OscalBaseModel ): \"\"\" Security assessment results, such as those provided by a FedRAMP assessor in the FedRAMP Security Assessment Report. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment results instance in this or other OSCAL instances. The locally defined UUID of the assessment result can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Results Universally Unique Identifier' , ) metadata : common . Metadata import_ap : ImportAp = Field ( ... , alias = 'import-ap' ) local_definitions : Optional [ LocalDefinitions ] = Field ( None , alias = 'local-definitions' , description = 'Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP.' , title = 'Local Definitions' , ) results : List [ Result ] = Field ( ... ) back_matter : Optional [ common . BackMatter ] = Field ( None , alias = 'back-matter' ) Attributes \u00a4 back_matter : BackMatter pydantic-field \u00a4 import_ap : ImportAp pydantic-field required \u00a4 local_definitions : LocalDefinitions pydantic-field \u00a4 Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP. metadata : Metadata pydantic-field required \u00a4 results : List [ trestle . oscal . assessment_results . Result ] pydantic-field required \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment results instance in this or other OSCAL instances. The locally defined UUID of the assessment result can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid Attestation ( OscalBaseModel ) pydantic-model \u00a4 A set of textual statements, typically written by the assessor. Source code in trestle/oscal/assessment_results.py class Attestation ( OscalBaseModel ): \"\"\" A set of textual statements, typically written by the assessor. \"\"\" class Config : extra = Extra . forbid responsible_parties : Optional [ List [ common . ResponsibleParty ]] = Field ( None , alias = 'responsible-parties' ) parts : List [ common . AssessmentPart ] = Field ( ... ) parts : List [ trestle . oscal . common . AssessmentPart ] pydantic-field required \u00a4 responsible_parties : List [ trestle . oscal . common . ResponsibleParty ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid Characterization ( OscalBaseModel ) pydantic-model \u00a4 A collection of descriptive data about the containing object from a specific origin. Source code in trestle/oscal/assessment_results.py class Characterization ( OscalBaseModel ): \"\"\" A collection of descriptive data about the containing object from a specific origin. \"\"\" class Config : extra = Extra . forbid props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) origin : Origin facets : List [ common . Facet ] = Field ( ... ) facets : List [ trestle . oscal . common . Facet ] pydantic-field required \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 origin : Origin pydantic-field required \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid ControlSelection ( OscalBaseModel ) pydantic-model \u00a4 Identifies the controls being assessed. In the assessment plan, these are the planned controls. In the assessment results, these are the actual controls, and reflects any changes from the plan. Source code in trestle/oscal/assessment_results.py class ControlSelection ( OscalBaseModel ): \"\"\" Identifies the controls being assessed. In the assessment plan, these are the planned controls. In the assessment results, these are the actual controls, and reflects any changes from the plan. \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'A human-readable description of in-scope controls specified for assessment.' , title = 'Assessed Controls Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) include_all : Optional [ common . IncludeAll ] = Field ( None , alias = 'include-all' ) include_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'include-controls' ) exclude_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'exclude-controls' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field \u00a4 A human-readable description of in-scope controls specified for assessment. exclude_controls : List [ trestle . oscal . assessment_results . SelectControlById ] pydantic-field \u00a4 include_all : IncludeAll pydantic-field \u00a4 include_controls : List [ trestle . oscal . assessment_results . SelectControlById ] pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid Entry ( OscalBaseModel ) pydantic-model \u00a4 Identifies the result of an action and/or task that occurred as part of executing an assessment plan or an assessment event that occurred in producing the assessment results. Source code in trestle/oscal/assessment_results.py class Entry ( OscalBaseModel ): \"\"\" Identifies the result of an action and/or task that occurred as part of executing an assessment plan or an assessment event that occurred in producing the assessment results. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference an assessment event in this or other OSCAL instances. The locally defined UUID of the assessment log entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Log Entry Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this event.' , title = 'Action Title' ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of this event.' , title = 'Action Description' , ) start : datetime = Field ( ... , description = 'Identifies the start date and time of an event.' , title = 'Start' , ) end : Optional [ datetime ] = Field ( None , description = 'Identifies the end date and time of an event. If the event is a point in time, the start and end will be the same date and time.' , title = 'End' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) logged_by : Optional [ List [ common . LoggedBy ]] = Field ( None , alias = 'logged-by' ) related_tasks : Optional [ List [ common . RelatedTask ]] = Field ( None , alias = 'related-tasks' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field \u00a4 A human-readable description of this event. end : datetime pydantic-field \u00a4 Identifies the end date and time of an event. If the event is a point in time, the start and end will be the same date and time. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 logged_by : List [ trestle . oscal . common . LoggedBy ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 related_tasks : List [ trestle . oscal . common . RelatedTask ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 start : datetime pydantic-field required \u00a4 Identifies the start date and time of an event. title : str pydantic-field \u00a4 The title for this event. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference an assessment event in this or other OSCAL instances. The locally defined UUID of the assessment log entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid Entry1 ( OscalBaseModel ) pydantic-model \u00a4 Identifies an individual risk response that occurred as part of managing an identified risk. Source code in trestle/oscal/assessment_results.py class Entry1 ( OscalBaseModel ): \"\"\" Identifies an individual risk response that occurred as part of managing an identified risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk log entry elsewhere in this or other OSCAL instances. The locally defined UUID of the risk log entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Risk Log Entry Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this risk log entry.' , title = 'Title' ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of what was done regarding the risk.' , title = 'Risk Task Description' , ) start : datetime = Field ( ... , description = 'Identifies the start date and time of the event.' , title = 'Start' , ) end : Optional [ datetime ] = Field ( None , description = 'Identifies the end date and time of the event. If the event is a point in time, the start and end will be the same date and time.' , title = 'End' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) logged_by : Optional [ List [ common . LoggedBy ]] = Field ( None , alias = 'logged-by' ) status_change : Optional [ common . RiskStatus ] = Field ( None , alias = 'status-change' ) related_responses : Optional [ List [ common . RelatedResponse ]] = Field ( None , alias = 'related-responses' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field \u00a4 A human-readable description of what was done regarding the risk. end : datetime pydantic-field \u00a4 Identifies the end date and time of the event. If the event is a point in time, the start and end will be the same date and time. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 logged_by : List [ trestle . oscal . common . LoggedBy ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 related_responses : List [ trestle . oscal . common . RelatedResponse ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 start : datetime pydantic-field required \u00a4 Identifies the start date and time of the event. status_change : RiskStatus pydantic-field \u00a4 title : str pydantic-field \u00a4 The title for this risk log entry. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk log entry elsewhere in this or other OSCAL instances. The locally defined UUID of the risk log entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid Finding ( OscalBaseModel ) pydantic-model \u00a4 Describes an individual finding. Source code in trestle/oscal/assessment_results.py class Finding ( OscalBaseModel ): \"\"\" Describes an individual finding. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this finding in this or other OSCAL instances. The locally defined UUID of the finding can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Finding Universally Unique Identifier' , ) title : str = Field ( ... , description = 'The title for this finding.' , title = 'Finding Title' ) description : str = Field ( ... , description = 'A human-readable description of this finding.' , title = 'Finding Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) origins : Optional [ List [ Origin ]] = Field ( None ) target : FindingTarget implementation_statement_uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , alias = 'implementation-statement-uuid' , description = 'A machine-oriented identifier reference to the implementation statement in the SSP to which this finding is related.' , title = 'Implementation Statement UUID' , ) related_observations : Optional [ List [ RelatedObservation ]] = Field ( None , alias = 'related-observations' ) related_risks : Optional [ List [ common . RelatedRisk ]] = Field ( None , alias = 'related-risks' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A human-readable description of this finding. implementation_statement_uuid : ConstrainedStrValue pydantic-field \u00a4 A machine-oriented identifier reference to the implementation statement in the SSP to which this finding is related. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 origins : List [ trestle . oscal . assessment_results . Origin ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 related_observations : List [ trestle . oscal . assessment_results . RelatedObservation ] pydantic-field \u00a4 related_risks : List [ trestle . oscal . common . RelatedRisk ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 target : FindingTarget pydantic-field required \u00a4 title : str pydantic-field required \u00a4 The title for this finding. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this finding in this or other OSCAL instances. The locally defined UUID of the finding can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid FindingTarget ( OscalBaseModel ) pydantic-model \u00a4 Captures an assessor's conclusions regarding the degree to which an objective is satisfied. Source code in trestle/oscal/assessment_results.py class FindingTarget ( OscalBaseModel ): \"\"\" Captures an assessor's conclusions regarding the degree to which an objective is satisfied. \"\"\" class Config : extra = Extra . forbid type : common . Type1 = Field ( ... , description = 'Identifies the type of the target.' , title = 'Finding Target Type' , ) target_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'target-id' , description = 'A machine-oriented identifier reference for a specific target qualified by the type.' , title = 'Finding Target Identifier Reference' , ) title : Optional [ str ] = Field ( None , description = 'The title for this objective status.' , title = 'Objective Status Title' , ) description : Optional [ str ] = Field ( None , description = \"A human-readable description of the assessor's conclusions regarding the degree to which an objective is satisfied.\" , title = 'Objective Status Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : Status = Field ( ... , description = 'A determination of if the objective is satisfied or not within a given system.' , title = 'Objective Status' , ) implementation_status : Optional [ common . ImplementationStatus ] = Field ( None , alias = 'implementation-status' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field \u00a4 A human-readable description of the assessor's conclusions regarding the degree to which an objective is satisfied. implementation_status : ImplementationStatus pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 status : Status pydantic-field required \u00a4 A determination of if the objective is satisfied or not within a given system. target_id : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference for a specific target qualified by the type. title : str pydantic-field \u00a4 The title for this objective status. type : Type1 pydantic-field required \u00a4 Identifies the type of the target. Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid ImportAp ( OscalBaseModel ) pydantic-model \u00a4 Used by assessment-results to import information about the original plan for assessing the system. Source code in trestle/oscal/assessment_results.py class ImportAp ( OscalBaseModel ): \"\"\" Used by assessment-results to import information about the original plan for assessing the system. \"\"\" class Config : extra = Extra . forbid href : str = Field ( ... , description = 'A resolvable URL reference to the assessment plan governing the assessment activities.' , title = 'Assessment Plan Reference' , ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 href : str pydantic-field required \u00a4 A resolvable URL reference to the assessment plan governing the assessment activities. remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid LocalDefinitions ( OscalBaseModel ) pydantic-model \u00a4 Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP. Source code in trestle/oscal/assessment_results.py class LocalDefinitions ( OscalBaseModel ): \"\"\" Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP. \"\"\" class Config : extra = Extra . forbid objectives_and_methods : Optional [ List [ common . LocalObjective ]] = Field ( None , alias = 'objectives-and-methods' ) activities : Optional [ List [ Activity ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None activities : List [ trestle . oscal . assessment_results . Activity ] pydantic-field \u00a4 objectives_and_methods : List [ trestle . oscal . common . LocalObjective ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid LocalDefinitions1 ( OscalBaseModel ) pydantic-model \u00a4 Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP. Source code in trestle/oscal/assessment_results.py class LocalDefinitions1 ( OscalBaseModel ): \"\"\" Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP. \"\"\" class Config : extra = Extra . forbid components : Optional [ List [ SystemComponent ]] = Field ( None ) inventory_items : Optional [ List [ common . InventoryItem ]] = Field ( None , alias = 'inventory-items' ) users : Optional [ List [ common . SystemUser ]] = Field ( None ) assessment_assets : Optional [ AssessmentAssets ] = Field ( None , alias = 'assessment-assets' ) tasks : Optional [ List [ common . Task ]] = Field ( None ) assessment_assets : AssessmentAssets pydantic-field \u00a4 components : List [ trestle . oscal . assessment_results . SystemComponent ] pydantic-field \u00a4 inventory_items : List [ trestle . oscal . common . InventoryItem ] pydantic-field \u00a4 tasks : List [ trestle . oscal . common . Task ] pydantic-field \u00a4 users : List [ trestle . oscal . common . SystemUser ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid Method ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/assessment_results.py class Method ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'Identifies how the observation was made.' , title = 'Observation Method' , ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 Identifies how the observation was made. Model ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/assessment_results.py class Model ( OscalBaseModel ): assessment_results : AssessmentResults = Field ( ... , alias = 'assessment-results' ) assessment_results : AssessmentResults pydantic-field required \u00a4 Observation ( OscalBaseModel ) pydantic-model \u00a4 Describes an individual observation. Source code in trestle/oscal/assessment_results.py class Observation ( OscalBaseModel ): \"\"\" Describes an individual observation. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this observation elsewhere in this or other OSCAL instances. The locally defined UUID of the observation can be used to reference the data item locally or globally (e.g., in an imorted OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Observation Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this observation.' , title = 'Observation Title' ) description : str = Field ( ... , description = 'A human-readable description of this assessment observation.' , title = 'Observation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) methods : List [ Method ] = Field ( ... ) types : Optional [ List [ common . Type2 ]] = Field ( None ) origins : Optional [ List [ Origin ]] = Field ( None ) subjects : Optional [ List [ common . SubjectReference ]] = Field ( None ) relevant_evidence : Optional [ List [ common . RelevantEvidence ]] = Field ( None , alias = 'relevant-evidence' ) collected : datetime = Field ( ... , description = 'Date/time stamp identifying when the finding information was collected.' , title = 'collected field' , ) expires : Optional [ datetime ] = Field ( None , description = 'Date/time identifying when the finding information is out-of-date and no longer valid. Typically used with continuous assessment scenarios.' , title = 'expires field' , ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 collected : datetime pydantic-field required \u00a4 Date/time stamp identifying when the finding information was collected. description : str pydantic-field required \u00a4 A human-readable description of this assessment observation. expires : datetime pydantic-field \u00a4 Date/time identifying when the finding information is out-of-date and no longer valid. Typically used with continuous assessment scenarios. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 methods : List [ trestle . oscal . assessment_results . Method ] pydantic-field required \u00a4 origins : List [ trestle . oscal . assessment_results . Origin ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 relevant_evidence : List [ trestle . oscal . common . RelevantEvidence ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 subjects : List [ trestle . oscal . common . SubjectReference ] pydantic-field \u00a4 title : str pydantic-field \u00a4 The title for this observation. types : List [ trestle . oscal . common . Type2 ] pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this observation elsewhere in this or other OSCAL instances. The locally defined UUID of the observation can be used to reference the data item locally or globally (e.g., in an imorted OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid Origin ( OscalBaseModel ) pydantic-model \u00a4 Identifies the source of the finding, such as a tool, interviewed person, or activity. Source code in trestle/oscal/assessment_results.py class Origin ( OscalBaseModel ): \"\"\" Identifies the source of the finding, such as a tool, interviewed person, or activity. \"\"\" class Config : extra = Extra . forbid actors : List [ common . OriginActor ] = Field ( ... ) related_tasks : Optional [ List [ common . RelatedTask ]] = Field ( None , alias = 'related-tasks' ) actors : List [ trestle . oscal . common . OriginActor ] pydantic-field required \u00a4 related_tasks : List [ trestle . oscal . common . RelatedTask ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid RelatedObservation ( OscalBaseModel ) pydantic-model \u00a4 Relates the finding to a set of referenced observations that were used to determine the finding. Source code in trestle/oscal/assessment_results.py class RelatedObservation ( OscalBaseModel ): \"\"\" Relates the finding to a set of referenced observations that were used to determine the finding. \"\"\" class Config : extra = Extra . forbid observation_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'observation-uuid' , description = 'A machine-oriented identifier reference to an observation defined in the list of observations.' , title = 'Observation Universally Unique Identifier Reference' , ) Attributes \u00a4 observation_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to an observation defined in the list of observations. Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid Response ( OscalBaseModel ) pydantic-model \u00a4 Describes either recommended or an actual plan for addressing the risk. Source code in trestle/oscal/assessment_results.py class Response ( OscalBaseModel ): \"\"\" Describes either recommended or an actual plan for addressing the risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this remediation elsewhere in this or other OSCAL instances. The locally defined UUID of the risk response can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Remediation Universally Unique Identifier' , ) lifecycle : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Identifies whether this is a recommendation, such as from an assessor or tool, or an actual plan accepted by the system owner.' , title = 'Remediation Intent' , ) title : str = Field ( ... , description = 'The title for this response activity.' , title = 'Response Title' ) description : str = Field ( ... , description = 'A human-readable description of this response plan.' , title = 'Response Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) origins : Optional [ List [ Origin ]] = Field ( None ) required_assets : Optional [ List [ common . RequiredAsset ]] = Field ( None , alias = 'required-assets' ) tasks : Optional [ List [ common . Task ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A human-readable description of this response plan. lifecycle : ConstrainedStrValue pydantic-field required \u00a4 Identifies whether this is a recommendation, such as from an assessor or tool, or an actual plan accepted by the system owner. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 origins : List [ trestle . oscal . assessment_results . Origin ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 required_assets : List [ trestle . oscal . common . RequiredAsset ] pydantic-field \u00a4 tasks : List [ trestle . oscal . common . Task ] pydantic-field \u00a4 title : str pydantic-field required \u00a4 The title for this response activity. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this remediation elsewhere in this or other OSCAL instances. The locally defined UUID of the risk response can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid Result ( OscalBaseModel ) pydantic-model \u00a4 Used by the assessment results and POA&M. In the assessment results, this identifies all of the assessment observations and findings, initial and residual risks, deviations, and disposition. In the POA&M, this identifies initial and residual risks, deviations, and disposition. Source code in trestle/oscal/assessment_results.py class Result ( OscalBaseModel ): \"\"\" Used by the assessment results and POA&M. In the assessment results, this identifies all of the assessment observations and findings, initial and residual risks, deviations, and disposition. In the POA&M, this identifies initial and residual risks, deviations, and disposition. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this set of results in this or other OSCAL instances. The locally defined UUID of the assessment result can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Results Universally Unique Identifier' , ) title : str = Field ( ... , description = 'The title for this set of results.' , title = 'Results Title' ) description : str = Field ( ... , description = 'A human-readable description of this set of test results.' , title = 'Results Description' , ) start : datetime = Field ( ... , description = 'Date/time stamp identifying the start of the evidence collection reflected in these results.' , title = 'start field' , ) end : Optional [ datetime ] = Field ( None , description = 'Date/time stamp identifying the end of the evidence collection reflected in these results. In a continuous motoring scenario, this may contain the same value as start if appropriate.' , title = 'end field' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) local_definitions : Optional [ LocalDefinitions1 ] = Field ( None , alias = 'local-definitions' , description = 'Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP.' , title = 'Local Definitions' , ) reviewed_controls : ReviewedControls = Field ( ... , alias = 'reviewed-controls' ) attestations : Optional [ List [ Attestation ]] = Field ( None ) assessment_log : Optional [ AssessmentLog ] = Field ( None , alias = 'assessment-log' , description = 'A log of all assessment-related actions taken.' , title = 'Assessment Log' , ) observations : Optional [ List [ Observation ]] = Field ( None ) risks : Optional [ List [ Risk ]] = Field ( None ) findings : Optional [ List [ Finding ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 assessment_log : AssessmentLog pydantic-field \u00a4 A log of all assessment-related actions taken. attestations : List [ trestle . oscal . assessment_results . Attestation ] pydantic-field \u00a4 description : str pydantic-field required \u00a4 A human-readable description of this set of test results. end : datetime pydantic-field \u00a4 Date/time stamp identifying the end of the evidence collection reflected in these results. In a continuous motoring scenario, this may contain the same value as start if appropriate. findings : List [ trestle . oscal . assessment_results . Finding ] pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 local_definitions : LocalDefinitions1 pydantic-field \u00a4 Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP. observations : List [ trestle . oscal . assessment_results . Observation ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 reviewed_controls : ReviewedControls pydantic-field required \u00a4 risks : List [ trestle . oscal . assessment_results . Risk ] pydantic-field \u00a4 start : datetime pydantic-field required \u00a4 Date/time stamp identifying the start of the evidence collection reflected in these results. title : str pydantic-field required \u00a4 The title for this set of results. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this set of results in this or other OSCAL instances. The locally defined UUID of the assessment result can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid ReviewedControls ( OscalBaseModel ) pydantic-model \u00a4 Identifies the controls being assessed and their control objectives. Source code in trestle/oscal/assessment_results.py class ReviewedControls ( OscalBaseModel ): \"\"\" Identifies the controls being assessed and their control objectives. \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'A human-readable description of control objectives.' , title = 'Control Objective Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) control_selections : List [ ControlSelection ] = Field ( ... , alias = 'control-selections' ) control_objective_selections : Optional [ List [ common . ControlObjectiveSelection ]] = Field ( None , alias = 'control-objective-selections' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 control_objective_selections : List [ trestle . oscal . common . ControlObjectiveSelection ] pydantic-field \u00a4 control_selections : List [ trestle . oscal . assessment_results . ControlSelection ] pydantic-field required \u00a4 description : str pydantic-field \u00a4 A human-readable description of control objectives. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid Risk ( OscalBaseModel ) pydantic-model \u00a4 An identified risk. Source code in trestle/oscal/assessment_results.py class Risk ( OscalBaseModel ): \"\"\" An identified risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk elsewhere in this or other OSCAL instances. The locally defined UUID of the risk can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Risk Universally Unique Identifier' , ) title : str = Field ( ... , description = 'The title for this risk.' , title = 'Risk Title' ) description : str = Field ( ... , description = 'A human-readable summary of the identified risk, to include a statement of how the risk impacts the system.' , title = 'Risk Description' , ) statement : str = Field ( ... , description = 'An summary of impact for how the risk affects the system.' , title = 'Risk Statement' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : common . RiskStatus origins : Optional [ List [ Origin ]] = Field ( None ) threat_ids : Optional [ List [ common . ThreatId ]] = Field ( None , alias = 'threat-ids' ) characterizations : Optional [ List [ Characterization ]] = Field ( None ) mitigating_factors : Optional [ List [ common . MitigatingFactor ]] = Field ( None , alias = 'mitigating-factors' ) deadline : Optional [ datetime ] = Field ( None , description = 'The date/time by which the risk must be resolved.' , title = 'Risk Resolution Deadline' , ) remediations : Optional [ List [ Response ]] = Field ( None ) risk_log : Optional [ RiskLog ] = Field ( None , alias = 'risk-log' , description = 'A log of all risk-related tasks taken.' , title = 'Risk Log' , ) related_observations : Optional [ List [ common . RelatedObservation1 ]] = Field ( None , alias = 'related-observations' ) Attributes \u00a4 characterizations : List [ trestle . oscal . assessment_results . Characterization ] pydantic-field \u00a4 deadline : datetime pydantic-field \u00a4 The date/time by which the risk must be resolved. description : str pydantic-field required \u00a4 A human-readable summary of the identified risk, to include a statement of how the risk impacts the system. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 mitigating_factors : List [ trestle . oscal . common . MitigatingFactor ] pydantic-field \u00a4 origins : List [ trestle . oscal . assessment_results . Origin ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 related_observations : List [ trestle . oscal . common . RelatedObservation1 ] pydantic-field \u00a4 remediations : List [ trestle . oscal . assessment_results . Response ] pydantic-field \u00a4 risk_log : RiskLog pydantic-field \u00a4 A log of all risk-related tasks taken. statement : str pydantic-field required \u00a4 An summary of impact for how the risk affects the system. status : RiskStatus pydantic-field required \u00a4 threat_ids : List [ trestle . oscal . common . ThreatId ] pydantic-field \u00a4 title : str pydantic-field required \u00a4 The title for this risk. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk elsewhere in this or other OSCAL instances. The locally defined UUID of the risk can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid RiskLog ( OscalBaseModel ) pydantic-model \u00a4 A log of all risk-related tasks taken. Source code in trestle/oscal/assessment_results.py class RiskLog ( OscalBaseModel ): \"\"\" A log of all risk-related tasks taken. \"\"\" class Config : extra = Extra . forbid entries : List [ Entry1 ] = Field ( ... ) entries : List [ trestle . oscal . assessment_results . Entry1 ] pydantic-field required \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid SelectControlById ( OscalBaseModel ) pydantic-model \u00a4 Used to select a control for inclusion/exclusion based on one or more control identifiers. A set of statement identifiers can be used to target the inclusion/exclusion to only specific control statements providing more granularity over the specific statements that are within the asessment scope. Source code in trestle/oscal/assessment_results.py class SelectControlById ( OscalBaseModel ): \"\"\" Used to select a control for inclusion/exclusion based on one or more control identifiers. A set of statement identifiers can be used to target the inclusion/exclusion to only specific control statements providing more granularity over the specific statements that are within the asessment scope. \"\"\" class Config : extra = Extra . forbid control_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'control-id' , description = 'A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).' , title = 'Control Identifier Reference' , ) statement_ids : Optional [ List [ common . StatementId ]] = Field ( None , alias = 'statement-ids' ) Attributes \u00a4 control_id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference). statement_ids : List [ trestle . oscal . common . StatementId ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid SetParameter ( OscalBaseModel ) pydantic-model \u00a4 Identifies the parameter that will be set by the enclosed value. Source code in trestle/oscal/assessment_results.py class SetParameter ( OscalBaseModel ): \"\"\" Identifies the parameter that will be set by the enclosed value. \"\"\" class Config : extra = Extra . forbid param_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'param-id' , description = \"A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context.\" , title = 'Parameter ID' , ) values : List [ common . Value ] = Field ( ... ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 param_id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context. remarks : Remarks pydantic-field \u00a4 values : List [ trestle . oscal . common . Value ] pydantic-field required \u00a4 Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid State ( Enum ) \u00a4 An indication as to whether the objective is satisfied or not. Source code in trestle/oscal/assessment_results.py class State ( Enum ): \"\"\" An indication as to whether the objective is satisfied or not. \"\"\" satisfied = 'satisfied' not_satisfied = 'not-satisfied' not_satisfied \u00a4 satisfied \u00a4 State1 ( Enum ) \u00a4 The operational status. Source code in trestle/oscal/assessment_results.py class State1 ( Enum ): \"\"\" The operational status. \"\"\" under_development = 'under-development' operational = 'operational' disposition = 'disposition' other = 'other' disposition \u00a4 operational \u00a4 other \u00a4 under_development \u00a4 Status ( OscalBaseModel ) pydantic-model \u00a4 A determination of if the objective is satisfied or not within a given system. Source code in trestle/oscal/assessment_results.py class Status ( OscalBaseModel ): \"\"\" A determination of if the objective is satisfied or not within a given system. \"\"\" class Config : extra = Extra . forbid state : State = Field ( ... , description = 'An indication as to whether the objective is satisfied or not.' , title = 'Objective Status State' , ) reason : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , description = \"The reason the objective was given it's status.\" , title = 'Objective Status Reason' , ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 reason : ConstrainedStrValue pydantic-field \u00a4 The reason the objective was given it's status. remarks : Remarks pydantic-field \u00a4 state : State pydantic-field required \u00a4 An indication as to whether the objective is satisfied or not. Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid Status1 ( OscalBaseModel ) pydantic-model \u00a4 Describes the operational status of the system component. Source code in trestle/oscal/assessment_results.py class Status1 ( OscalBaseModel ): \"\"\" Describes the operational status of the system component. \"\"\" class Config : extra = Extra . forbid state : State1 = Field ( ... , description = 'The operational status.' , title = 'State' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 remarks : Remarks pydantic-field \u00a4 state : State1 pydantic-field required \u00a4 The operational status. Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid Step ( OscalBaseModel ) pydantic-model \u00a4 Identifies an individual step in a series of steps related to an activity, such as an assessment test or examination procedure. Source code in trestle/oscal/assessment_results.py class Step ( OscalBaseModel ): \"\"\" Identifies an individual step in a series of steps related to an activity, such as an assessment test or examination procedure. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this step elsewhere in this or other OSCAL instances. The locally defined UUID of the step (in a series of steps) can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Step Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this step.' , title = 'Step Title' ) description : str = Field ( ... , description = 'A human-readable description of this step.' , title = 'Step Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) reviewed_controls : Optional [ ReviewedControls ] = Field ( None , alias = 'reviewed-controls' ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A human-readable description of this step. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 reviewed_controls : ReviewedControls pydantic-field \u00a4 title : str pydantic-field \u00a4 The title for this step. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this step elsewhere in this or other OSCAL instances. The locally defined UUID of the step (in a series of steps) can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid SystemComponent ( OscalBaseModel ) pydantic-model \u00a4 A defined component that can be part of an implemented system. Source code in trestle/oscal/assessment_results.py class SystemComponent ( OscalBaseModel ): \"\"\" A defined component that can be part of an implemented system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Component Identifier' , ) type : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A category describing the purpose of the component.' , title = 'Component Type' , ) title : str = Field ( ... , description = 'A human readable name for the system component.' , title = 'Component Title' , ) description : str = Field ( ... , description = 'A description of the component, including information about its function.' , title = 'Component Description' , ) purpose : Optional [ str ] = Field ( None , description = 'A summary of the technological or business purpose of the component.' , title = 'Purpose' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : Status1 = Field ( ... , description = 'Describes the operational status of the system component.' , title = 'Status' , ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) protocols : Optional [ List [ common . Protocol ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A description of the component, including information about its function. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 protocols : List [ trestle . oscal . common . Protocol ] pydantic-field \u00a4 purpose : str pydantic-field \u00a4 A summary of the technological or business purpose of the component. remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 status : Status1 pydantic-field required \u00a4 Describes the operational status of the system component. title : str pydantic-field required \u00a4 A human readable name for the system component. type : ConstrainedStrValue pydantic-field required \u00a4 A category describing the purpose of the component. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid handler: python","title":"assessment_results"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results","text":"","title":"assessment_results"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Activity","text":"Identifies an assessment or related process that can be performed. In the assessment plan, this is an intended activity which may be associated with an assessment task. In the assessment results, this an activity that was actually performed as part of an assessment. Source code in trestle/oscal/assessment_results.py class Activity ( OscalBaseModel ): \"\"\" Identifies an assessment or related process that can be performed. In the assessment plan, this is an intended activity which may be associated with an assessment task. In the assessment results, this an activity that was actually performed as part of an assessment. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment activity elsewhere in this or other OSCAL instances. The locally defined UUID of the activity can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Activity Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this included activity.' , title = 'Included Activity Title' , ) description : str = Field ( ... , description = 'A human-readable description of this included activity.' , title = 'Included Activity Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) steps : Optional [ List [ Step ]] = Field ( None ) related_controls : Optional [ ReviewedControls ] = Field ( None , alias = 'related-controls' ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None","title":"Activity"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Activity-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Activity.description","text":"A human-readable description of this included activity.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Activity.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Activity.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Activity.related_controls","text":"","title":"related_controls"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Activity.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Activity.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Activity.steps","text":"","title":"steps"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Activity.title","text":"The title for this included activity.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Activity.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment activity elsewhere in this or other OSCAL instances. The locally defined UUID of the activity can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Activity.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.AssessmentAssets","text":"Identifies the assets used to perform this assessment, such as the assessment team, scanning tools, and assumptions. Source code in trestle/oscal/assessment_results.py class AssessmentAssets ( OscalBaseModel ): \"\"\" Identifies the assets used to perform this assessment, such as the assessment team, scanning tools, and assumptions. \"\"\" class Config : extra = Extra . forbid components : Optional [ List [ SystemComponent ]] = Field ( None ) assessment_platforms : List [ common . AssessmentPlatform ] = Field ( ... , alias = 'assessment-platforms' )","title":"AssessmentAssets"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.AssessmentAssets.assessment_platforms","text":"","title":"assessment_platforms"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.AssessmentAssets.components","text":"","title":"components"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.AssessmentAssets.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.AssessmentLog","text":"A log of all assessment-related actions taken. Source code in trestle/oscal/assessment_results.py class AssessmentLog ( OscalBaseModel ): \"\"\" A log of all assessment-related actions taken. \"\"\" class Config : extra = Extra . forbid entries : List [ Entry ] = Field ( ... )","title":"AssessmentLog"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.AssessmentLog.entries","text":"","title":"entries"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.AssessmentLog.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.AssessmentResults","text":"Security assessment results, such as those provided by a FedRAMP assessor in the FedRAMP Security Assessment Report. Source code in trestle/oscal/assessment_results.py class AssessmentResults ( OscalBaseModel ): \"\"\" Security assessment results, such as those provided by a FedRAMP assessor in the FedRAMP Security Assessment Report. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment results instance in this or other OSCAL instances. The locally defined UUID of the assessment result can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Results Universally Unique Identifier' , ) metadata : common . Metadata import_ap : ImportAp = Field ( ... , alias = 'import-ap' ) local_definitions : Optional [ LocalDefinitions ] = Field ( None , alias = 'local-definitions' , description = 'Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP.' , title = 'Local Definitions' , ) results : List [ Result ] = Field ( ... ) back_matter : Optional [ common . BackMatter ] = Field ( None , alias = 'back-matter' )","title":"AssessmentResults"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.AssessmentResults-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.AssessmentResults.back_matter","text":"","title":"back_matter"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.AssessmentResults.import_ap","text":"","title":"import_ap"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.AssessmentResults.local_definitions","text":"Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP.","title":"local_definitions"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.AssessmentResults.metadata","text":"","title":"metadata"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.AssessmentResults.results","text":"","title":"results"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.AssessmentResults.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment results instance in this or other OSCAL instances. The locally defined UUID of the assessment result can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.AssessmentResults.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Attestation","text":"A set of textual statements, typically written by the assessor. Source code in trestle/oscal/assessment_results.py class Attestation ( OscalBaseModel ): \"\"\" A set of textual statements, typically written by the assessor. \"\"\" class Config : extra = Extra . forbid responsible_parties : Optional [ List [ common . ResponsibleParty ]] = Field ( None , alias = 'responsible-parties' ) parts : List [ common . AssessmentPart ] = Field ( ... )","title":"Attestation"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Attestation.parts","text":"","title":"parts"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Attestation.responsible_parties","text":"","title":"responsible_parties"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Attestation.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Characterization","text":"A collection of descriptive data about the containing object from a specific origin. Source code in trestle/oscal/assessment_results.py class Characterization ( OscalBaseModel ): \"\"\" A collection of descriptive data about the containing object from a specific origin. \"\"\" class Config : extra = Extra . forbid props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) origin : Origin facets : List [ common . Facet ] = Field ( ... )","title":"Characterization"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Characterization.facets","text":"","title":"facets"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Characterization.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Characterization.origin","text":"","title":"origin"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Characterization.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Characterization.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ControlSelection","text":"Identifies the controls being assessed. In the assessment plan, these are the planned controls. In the assessment results, these are the actual controls, and reflects any changes from the plan. Source code in trestle/oscal/assessment_results.py class ControlSelection ( OscalBaseModel ): \"\"\" Identifies the controls being assessed. In the assessment plan, these are the planned controls. In the assessment results, these are the actual controls, and reflects any changes from the plan. \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'A human-readable description of in-scope controls specified for assessment.' , title = 'Assessed Controls Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) include_all : Optional [ common . IncludeAll ] = Field ( None , alias = 'include-all' ) include_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'include-controls' ) exclude_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'exclude-controls' ) remarks : Optional [ common . Remarks ] = None","title":"ControlSelection"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ControlSelection-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ControlSelection.description","text":"A human-readable description of in-scope controls specified for assessment.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ControlSelection.exclude_controls","text":"","title":"exclude_controls"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ControlSelection.include_all","text":"","title":"include_all"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ControlSelection.include_controls","text":"","title":"include_controls"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ControlSelection.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ControlSelection.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ControlSelection.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ControlSelection.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry","text":"Identifies the result of an action and/or task that occurred as part of executing an assessment plan or an assessment event that occurred in producing the assessment results. Source code in trestle/oscal/assessment_results.py class Entry ( OscalBaseModel ): \"\"\" Identifies the result of an action and/or task that occurred as part of executing an assessment plan or an assessment event that occurred in producing the assessment results. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference an assessment event in this or other OSCAL instances. The locally defined UUID of the assessment log entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Log Entry Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this event.' , title = 'Action Title' ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of this event.' , title = 'Action Description' , ) start : datetime = Field ( ... , description = 'Identifies the start date and time of an event.' , title = 'Start' , ) end : Optional [ datetime ] = Field ( None , description = 'Identifies the end date and time of an event. If the event is a point in time, the start and end will be the same date and time.' , title = 'End' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) logged_by : Optional [ List [ common . LoggedBy ]] = Field ( None , alias = 'logged-by' ) related_tasks : Optional [ List [ common . RelatedTask ]] = Field ( None , alias = 'related-tasks' ) remarks : Optional [ common . Remarks ] = None","title":"Entry"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry.description","text":"A human-readable description of this event.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry.end","text":"Identifies the end date and time of an event. If the event is a point in time, the start and end will be the same date and time.","title":"end"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry.logged_by","text":"","title":"logged_by"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry.related_tasks","text":"","title":"related_tasks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry.start","text":"Identifies the start date and time of an event.","title":"start"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry.title","text":"The title for this event.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference an assessment event in this or other OSCAL instances. The locally defined UUID of the assessment log entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry1","text":"Identifies an individual risk response that occurred as part of managing an identified risk. Source code in trestle/oscal/assessment_results.py class Entry1 ( OscalBaseModel ): \"\"\" Identifies an individual risk response that occurred as part of managing an identified risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk log entry elsewhere in this or other OSCAL instances. The locally defined UUID of the risk log entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Risk Log Entry Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this risk log entry.' , title = 'Title' ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of what was done regarding the risk.' , title = 'Risk Task Description' , ) start : datetime = Field ( ... , description = 'Identifies the start date and time of the event.' , title = 'Start' , ) end : Optional [ datetime ] = Field ( None , description = 'Identifies the end date and time of the event. If the event is a point in time, the start and end will be the same date and time.' , title = 'End' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) logged_by : Optional [ List [ common . LoggedBy ]] = Field ( None , alias = 'logged-by' ) status_change : Optional [ common . RiskStatus ] = Field ( None , alias = 'status-change' ) related_responses : Optional [ List [ common . RelatedResponse ]] = Field ( None , alias = 'related-responses' ) remarks : Optional [ common . Remarks ] = None","title":"Entry1"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry1-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry1.description","text":"A human-readable description of what was done regarding the risk.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry1.end","text":"Identifies the end date and time of the event. If the event is a point in time, the start and end will be the same date and time.","title":"end"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry1.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry1.logged_by","text":"","title":"logged_by"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry1.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry1.related_responses","text":"","title":"related_responses"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry1.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry1.start","text":"Identifies the start date and time of the event.","title":"start"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry1.status_change","text":"","title":"status_change"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry1.title","text":"The title for this risk log entry.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry1.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk log entry elsewhere in this or other OSCAL instances. The locally defined UUID of the risk log entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Entry1.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Finding","text":"Describes an individual finding. Source code in trestle/oscal/assessment_results.py class Finding ( OscalBaseModel ): \"\"\" Describes an individual finding. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this finding in this or other OSCAL instances. The locally defined UUID of the finding can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Finding Universally Unique Identifier' , ) title : str = Field ( ... , description = 'The title for this finding.' , title = 'Finding Title' ) description : str = Field ( ... , description = 'A human-readable description of this finding.' , title = 'Finding Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) origins : Optional [ List [ Origin ]] = Field ( None ) target : FindingTarget implementation_statement_uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , alias = 'implementation-statement-uuid' , description = 'A machine-oriented identifier reference to the implementation statement in the SSP to which this finding is related.' , title = 'Implementation Statement UUID' , ) related_observations : Optional [ List [ RelatedObservation ]] = Field ( None , alias = 'related-observations' ) related_risks : Optional [ List [ common . RelatedRisk ]] = Field ( None , alias = 'related-risks' ) remarks : Optional [ common . Remarks ] = None","title":"Finding"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Finding-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Finding.description","text":"A human-readable description of this finding.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Finding.implementation_statement_uuid","text":"A machine-oriented identifier reference to the implementation statement in the SSP to which this finding is related.","title":"implementation_statement_uuid"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Finding.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Finding.origins","text":"","title":"origins"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Finding.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Finding.related_observations","text":"","title":"related_observations"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Finding.related_risks","text":"","title":"related_risks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Finding.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Finding.target","text":"","title":"target"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Finding.title","text":"The title for this finding.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Finding.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this finding in this or other OSCAL instances. The locally defined UUID of the finding can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Finding.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.FindingTarget","text":"Captures an assessor's conclusions regarding the degree to which an objective is satisfied. Source code in trestle/oscal/assessment_results.py class FindingTarget ( OscalBaseModel ): \"\"\" Captures an assessor's conclusions regarding the degree to which an objective is satisfied. \"\"\" class Config : extra = Extra . forbid type : common . Type1 = Field ( ... , description = 'Identifies the type of the target.' , title = 'Finding Target Type' , ) target_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'target-id' , description = 'A machine-oriented identifier reference for a specific target qualified by the type.' , title = 'Finding Target Identifier Reference' , ) title : Optional [ str ] = Field ( None , description = 'The title for this objective status.' , title = 'Objective Status Title' , ) description : Optional [ str ] = Field ( None , description = \"A human-readable description of the assessor's conclusions regarding the degree to which an objective is satisfied.\" , title = 'Objective Status Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : Status = Field ( ... , description = 'A determination of if the objective is satisfied or not within a given system.' , title = 'Objective Status' , ) implementation_status : Optional [ common . ImplementationStatus ] = Field ( None , alias = 'implementation-status' ) remarks : Optional [ common . Remarks ] = None","title":"FindingTarget"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.FindingTarget-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.FindingTarget.description","text":"A human-readable description of the assessor's conclusions regarding the degree to which an objective is satisfied.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.FindingTarget.implementation_status","text":"","title":"implementation_status"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.FindingTarget.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.FindingTarget.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.FindingTarget.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.FindingTarget.status","text":"A determination of if the objective is satisfied or not within a given system.","title":"status"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.FindingTarget.target_id","text":"A machine-oriented identifier reference for a specific target qualified by the type.","title":"target_id"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.FindingTarget.title","text":"The title for this objective status.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.FindingTarget.type","text":"Identifies the type of the target.","title":"type"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.FindingTarget.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ImportAp","text":"Used by assessment-results to import information about the original plan for assessing the system. Source code in trestle/oscal/assessment_results.py class ImportAp ( OscalBaseModel ): \"\"\" Used by assessment-results to import information about the original plan for assessing the system. \"\"\" class Config : extra = Extra . forbid href : str = Field ( ... , description = 'A resolvable URL reference to the assessment plan governing the assessment activities.' , title = 'Assessment Plan Reference' , ) remarks : Optional [ common . Remarks ] = None","title":"ImportAp"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ImportAp-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ImportAp.href","text":"A resolvable URL reference to the assessment plan governing the assessment activities.","title":"href"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ImportAp.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ImportAp.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.LocalDefinitions","text":"Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP. Source code in trestle/oscal/assessment_results.py class LocalDefinitions ( OscalBaseModel ): \"\"\" Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP. \"\"\" class Config : extra = Extra . forbid objectives_and_methods : Optional [ List [ common . LocalObjective ]] = Field ( None , alias = 'objectives-and-methods' ) activities : Optional [ List [ Activity ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None","title":"LocalDefinitions"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.LocalDefinitions.activities","text":"","title":"activities"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.LocalDefinitions.objectives_and_methods","text":"","title":"objectives_and_methods"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.LocalDefinitions.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.LocalDefinitions.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.LocalDefinitions1","text":"Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP. Source code in trestle/oscal/assessment_results.py class LocalDefinitions1 ( OscalBaseModel ): \"\"\" Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP. \"\"\" class Config : extra = Extra . forbid components : Optional [ List [ SystemComponent ]] = Field ( None ) inventory_items : Optional [ List [ common . InventoryItem ]] = Field ( None , alias = 'inventory-items' ) users : Optional [ List [ common . SystemUser ]] = Field ( None ) assessment_assets : Optional [ AssessmentAssets ] = Field ( None , alias = 'assessment-assets' ) tasks : Optional [ List [ common . Task ]] = Field ( None )","title":"LocalDefinitions1"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.LocalDefinitions1.assessment_assets","text":"","title":"assessment_assets"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.LocalDefinitions1.components","text":"","title":"components"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.LocalDefinitions1.inventory_items","text":"","title":"inventory_items"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.LocalDefinitions1.tasks","text":"","title":"tasks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.LocalDefinitions1.users","text":"","title":"users"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.LocalDefinitions1.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Method","text":"Source code in trestle/oscal/assessment_results.py class Method ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'Identifies how the observation was made.' , title = 'Observation Method' , )","title":"Method"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Method-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Method.__root__","text":"Identifies how the observation was made.","title":"__root__"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Model","text":"Source code in trestle/oscal/assessment_results.py class Model ( OscalBaseModel ): assessment_results : AssessmentResults = Field ( ... , alias = 'assessment-results' )","title":"Model"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Model.assessment_results","text":"","title":"assessment_results"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Observation","text":"Describes an individual observation. Source code in trestle/oscal/assessment_results.py class Observation ( OscalBaseModel ): \"\"\" Describes an individual observation. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this observation elsewhere in this or other OSCAL instances. The locally defined UUID of the observation can be used to reference the data item locally or globally (e.g., in an imorted OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Observation Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this observation.' , title = 'Observation Title' ) description : str = Field ( ... , description = 'A human-readable description of this assessment observation.' , title = 'Observation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) methods : List [ Method ] = Field ( ... ) types : Optional [ List [ common . Type2 ]] = Field ( None ) origins : Optional [ List [ Origin ]] = Field ( None ) subjects : Optional [ List [ common . SubjectReference ]] = Field ( None ) relevant_evidence : Optional [ List [ common . RelevantEvidence ]] = Field ( None , alias = 'relevant-evidence' ) collected : datetime = Field ( ... , description = 'Date/time stamp identifying when the finding information was collected.' , title = 'collected field' , ) expires : Optional [ datetime ] = Field ( None , description = 'Date/time identifying when the finding information is out-of-date and no longer valid. Typically used with continuous assessment scenarios.' , title = 'expires field' , ) remarks : Optional [ common . Remarks ] = None","title":"Observation"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Observation-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Observation.collected","text":"Date/time stamp identifying when the finding information was collected.","title":"collected"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Observation.description","text":"A human-readable description of this assessment observation.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Observation.expires","text":"Date/time identifying when the finding information is out-of-date and no longer valid. Typically used with continuous assessment scenarios.","title":"expires"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Observation.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Observation.methods","text":"","title":"methods"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Observation.origins","text":"","title":"origins"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Observation.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Observation.relevant_evidence","text":"","title":"relevant_evidence"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Observation.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Observation.subjects","text":"","title":"subjects"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Observation.title","text":"The title for this observation.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Observation.types","text":"","title":"types"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Observation.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this observation elsewhere in this or other OSCAL instances. The locally defined UUID of the observation can be used to reference the data item locally or globally (e.g., in an imorted OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Observation.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Origin","text":"Identifies the source of the finding, such as a tool, interviewed person, or activity. Source code in trestle/oscal/assessment_results.py class Origin ( OscalBaseModel ): \"\"\" Identifies the source of the finding, such as a tool, interviewed person, or activity. \"\"\" class Config : extra = Extra . forbid actors : List [ common . OriginActor ] = Field ( ... ) related_tasks : Optional [ List [ common . RelatedTask ]] = Field ( None , alias = 'related-tasks' )","title":"Origin"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Origin.actors","text":"","title":"actors"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Origin.related_tasks","text":"","title":"related_tasks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Origin.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.RelatedObservation","text":"Relates the finding to a set of referenced observations that were used to determine the finding. Source code in trestle/oscal/assessment_results.py class RelatedObservation ( OscalBaseModel ): \"\"\" Relates the finding to a set of referenced observations that were used to determine the finding. \"\"\" class Config : extra = Extra . forbid observation_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'observation-uuid' , description = 'A machine-oriented identifier reference to an observation defined in the list of observations.' , title = 'Observation Universally Unique Identifier Reference' , )","title":"RelatedObservation"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.RelatedObservation-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.RelatedObservation.observation_uuid","text":"A machine-oriented identifier reference to an observation defined in the list of observations.","title":"observation_uuid"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.RelatedObservation.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Response","text":"Describes either recommended or an actual plan for addressing the risk. Source code in trestle/oscal/assessment_results.py class Response ( OscalBaseModel ): \"\"\" Describes either recommended or an actual plan for addressing the risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this remediation elsewhere in this or other OSCAL instances. The locally defined UUID of the risk response can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Remediation Universally Unique Identifier' , ) lifecycle : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Identifies whether this is a recommendation, such as from an assessor or tool, or an actual plan accepted by the system owner.' , title = 'Remediation Intent' , ) title : str = Field ( ... , description = 'The title for this response activity.' , title = 'Response Title' ) description : str = Field ( ... , description = 'A human-readable description of this response plan.' , title = 'Response Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) origins : Optional [ List [ Origin ]] = Field ( None ) required_assets : Optional [ List [ common . RequiredAsset ]] = Field ( None , alias = 'required-assets' ) tasks : Optional [ List [ common . Task ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None","title":"Response"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Response-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Response.description","text":"A human-readable description of this response plan.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Response.lifecycle","text":"Identifies whether this is a recommendation, such as from an assessor or tool, or an actual plan accepted by the system owner.","title":"lifecycle"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Response.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Response.origins","text":"","title":"origins"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Response.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Response.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Response.required_assets","text":"","title":"required_assets"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Response.tasks","text":"","title":"tasks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Response.title","text":"The title for this response activity.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Response.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this remediation elsewhere in this or other OSCAL instances. The locally defined UUID of the risk response can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Response.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result","text":"Used by the assessment results and POA&M. In the assessment results, this identifies all of the assessment observations and findings, initial and residual risks, deviations, and disposition. In the POA&M, this identifies initial and residual risks, deviations, and disposition. Source code in trestle/oscal/assessment_results.py class Result ( OscalBaseModel ): \"\"\" Used by the assessment results and POA&M. In the assessment results, this identifies all of the assessment observations and findings, initial and residual risks, deviations, and disposition. In the POA&M, this identifies initial and residual risks, deviations, and disposition. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this set of results in this or other OSCAL instances. The locally defined UUID of the assessment result can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Results Universally Unique Identifier' , ) title : str = Field ( ... , description = 'The title for this set of results.' , title = 'Results Title' ) description : str = Field ( ... , description = 'A human-readable description of this set of test results.' , title = 'Results Description' , ) start : datetime = Field ( ... , description = 'Date/time stamp identifying the start of the evidence collection reflected in these results.' , title = 'start field' , ) end : Optional [ datetime ] = Field ( None , description = 'Date/time stamp identifying the end of the evidence collection reflected in these results. In a continuous motoring scenario, this may contain the same value as start if appropriate.' , title = 'end field' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) local_definitions : Optional [ LocalDefinitions1 ] = Field ( None , alias = 'local-definitions' , description = 'Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP.' , title = 'Local Definitions' , ) reviewed_controls : ReviewedControls = Field ( ... , alias = 'reviewed-controls' ) attestations : Optional [ List [ Attestation ]] = Field ( None ) assessment_log : Optional [ AssessmentLog ] = Field ( None , alias = 'assessment-log' , description = 'A log of all assessment-related actions taken.' , title = 'Assessment Log' , ) observations : Optional [ List [ Observation ]] = Field ( None ) risks : Optional [ List [ Risk ]] = Field ( None ) findings : Optional [ List [ Finding ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None","title":"Result"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result.assessment_log","text":"A log of all assessment-related actions taken.","title":"assessment_log"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result.attestations","text":"","title":"attestations"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result.description","text":"A human-readable description of this set of test results.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result.end","text":"Date/time stamp identifying the end of the evidence collection reflected in these results. In a continuous motoring scenario, this may contain the same value as start if appropriate.","title":"end"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result.findings","text":"","title":"findings"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result.local_definitions","text":"Used to define data objects that are used in the assessment plan, that do not appear in the referenced SSP.","title":"local_definitions"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result.observations","text":"","title":"observations"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result.reviewed_controls","text":"","title":"reviewed_controls"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result.risks","text":"","title":"risks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result.start","text":"Date/time stamp identifying the start of the evidence collection reflected in these results.","title":"start"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result.title","text":"The title for this set of results.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this set of results in this or other OSCAL instances. The locally defined UUID of the assessment result can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Result.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ReviewedControls","text":"Identifies the controls being assessed and their control objectives. Source code in trestle/oscal/assessment_results.py class ReviewedControls ( OscalBaseModel ): \"\"\" Identifies the controls being assessed and their control objectives. \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'A human-readable description of control objectives.' , title = 'Control Objective Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) control_selections : List [ ControlSelection ] = Field ( ... , alias = 'control-selections' ) control_objective_selections : Optional [ List [ common . ControlObjectiveSelection ]] = Field ( None , alias = 'control-objective-selections' ) remarks : Optional [ common . Remarks ] = None","title":"ReviewedControls"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ReviewedControls-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ReviewedControls.control_objective_selections","text":"","title":"control_objective_selections"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ReviewedControls.control_selections","text":"","title":"control_selections"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ReviewedControls.description","text":"A human-readable description of control objectives.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ReviewedControls.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ReviewedControls.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ReviewedControls.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.ReviewedControls.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk","text":"An identified risk. Source code in trestle/oscal/assessment_results.py class Risk ( OscalBaseModel ): \"\"\" An identified risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk elsewhere in this or other OSCAL instances. The locally defined UUID of the risk can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Risk Universally Unique Identifier' , ) title : str = Field ( ... , description = 'The title for this risk.' , title = 'Risk Title' ) description : str = Field ( ... , description = 'A human-readable summary of the identified risk, to include a statement of how the risk impacts the system.' , title = 'Risk Description' , ) statement : str = Field ( ... , description = 'An summary of impact for how the risk affects the system.' , title = 'Risk Statement' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : common . RiskStatus origins : Optional [ List [ Origin ]] = Field ( None ) threat_ids : Optional [ List [ common . ThreatId ]] = Field ( None , alias = 'threat-ids' ) characterizations : Optional [ List [ Characterization ]] = Field ( None ) mitigating_factors : Optional [ List [ common . MitigatingFactor ]] = Field ( None , alias = 'mitigating-factors' ) deadline : Optional [ datetime ] = Field ( None , description = 'The date/time by which the risk must be resolved.' , title = 'Risk Resolution Deadline' , ) remediations : Optional [ List [ Response ]] = Field ( None ) risk_log : Optional [ RiskLog ] = Field ( None , alias = 'risk-log' , description = 'A log of all risk-related tasks taken.' , title = 'Risk Log' , ) related_observations : Optional [ List [ common . RelatedObservation1 ]] = Field ( None , alias = 'related-observations' )","title":"Risk"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk.characterizations","text":"","title":"characterizations"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk.deadline","text":"The date/time by which the risk must be resolved.","title":"deadline"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk.description","text":"A human-readable summary of the identified risk, to include a statement of how the risk impacts the system.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk.mitigating_factors","text":"","title":"mitigating_factors"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk.origins","text":"","title":"origins"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk.related_observations","text":"","title":"related_observations"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk.remediations","text":"","title":"remediations"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk.risk_log","text":"A log of all risk-related tasks taken.","title":"risk_log"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk.statement","text":"An summary of impact for how the risk affects the system.","title":"statement"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk.status","text":"","title":"status"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk.threat_ids","text":"","title":"threat_ids"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk.title","text":"The title for this risk.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk elsewhere in this or other OSCAL instances. The locally defined UUID of the risk can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Risk.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.RiskLog","text":"A log of all risk-related tasks taken. Source code in trestle/oscal/assessment_results.py class RiskLog ( OscalBaseModel ): \"\"\" A log of all risk-related tasks taken. \"\"\" class Config : extra = Extra . forbid entries : List [ Entry1 ] = Field ( ... )","title":"RiskLog"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.RiskLog.entries","text":"","title":"entries"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.RiskLog.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SelectControlById","text":"Used to select a control for inclusion/exclusion based on one or more control identifiers. A set of statement identifiers can be used to target the inclusion/exclusion to only specific control statements providing more granularity over the specific statements that are within the asessment scope. Source code in trestle/oscal/assessment_results.py class SelectControlById ( OscalBaseModel ): \"\"\" Used to select a control for inclusion/exclusion based on one or more control identifiers. A set of statement identifiers can be used to target the inclusion/exclusion to only specific control statements providing more granularity over the specific statements that are within the asessment scope. \"\"\" class Config : extra = Extra . forbid control_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'control-id' , description = 'A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).' , title = 'Control Identifier Reference' , ) statement_ids : Optional [ List [ common . StatementId ]] = Field ( None , alias = 'statement-ids' )","title":"SelectControlById"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SelectControlById-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SelectControlById.control_id","text":"A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).","title":"control_id"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SelectControlById.statement_ids","text":"","title":"statement_ids"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SelectControlById.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SetParameter","text":"Identifies the parameter that will be set by the enclosed value. Source code in trestle/oscal/assessment_results.py class SetParameter ( OscalBaseModel ): \"\"\" Identifies the parameter that will be set by the enclosed value. \"\"\" class Config : extra = Extra . forbid param_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'param-id' , description = \"A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context.\" , title = 'Parameter ID' , ) values : List [ common . Value ] = Field ( ... ) remarks : Optional [ common . Remarks ] = None","title":"SetParameter"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SetParameter-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SetParameter.param_id","text":"A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context.","title":"param_id"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SetParameter.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SetParameter.values","text":"","title":"values"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SetParameter.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.State","text":"An indication as to whether the objective is satisfied or not. Source code in trestle/oscal/assessment_results.py class State ( Enum ): \"\"\" An indication as to whether the objective is satisfied or not. \"\"\" satisfied = 'satisfied' not_satisfied = 'not-satisfied'","title":"State"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.State.not_satisfied","text":"","title":"not_satisfied"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.State.satisfied","text":"","title":"satisfied"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.State1","text":"The operational status. Source code in trestle/oscal/assessment_results.py class State1 ( Enum ): \"\"\" The operational status. \"\"\" under_development = 'under-development' operational = 'operational' disposition = 'disposition' other = 'other'","title":"State1"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.State1.disposition","text":"","title":"disposition"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.State1.operational","text":"","title":"operational"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.State1.other","text":"","title":"other"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.State1.under_development","text":"","title":"under_development"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Status","text":"A determination of if the objective is satisfied or not within a given system. Source code in trestle/oscal/assessment_results.py class Status ( OscalBaseModel ): \"\"\" A determination of if the objective is satisfied or not within a given system. \"\"\" class Config : extra = Extra . forbid state : State = Field ( ... , description = 'An indication as to whether the objective is satisfied or not.' , title = 'Objective Status State' , ) reason : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , description = \"The reason the objective was given it's status.\" , title = 'Objective Status Reason' , ) remarks : Optional [ common . Remarks ] = None","title":"Status"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Status-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Status.reason","text":"The reason the objective was given it's status.","title":"reason"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Status.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Status.state","text":"An indication as to whether the objective is satisfied or not.","title":"state"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Status.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Status1","text":"Describes the operational status of the system component. Source code in trestle/oscal/assessment_results.py class Status1 ( OscalBaseModel ): \"\"\" Describes the operational status of the system component. \"\"\" class Config : extra = Extra . forbid state : State1 = Field ( ... , description = 'The operational status.' , title = 'State' ) remarks : Optional [ common . Remarks ] = None","title":"Status1"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Status1-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Status1.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Status1.state","text":"The operational status.","title":"state"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Status1.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Step","text":"Identifies an individual step in a series of steps related to an activity, such as an assessment test or examination procedure. Source code in trestle/oscal/assessment_results.py class Step ( OscalBaseModel ): \"\"\" Identifies an individual step in a series of steps related to an activity, such as an assessment test or examination procedure. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this step elsewhere in this or other OSCAL instances. The locally defined UUID of the step (in a series of steps) can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Step Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this step.' , title = 'Step Title' ) description : str = Field ( ... , description = 'A human-readable description of this step.' , title = 'Step Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) reviewed_controls : Optional [ ReviewedControls ] = Field ( None , alias = 'reviewed-controls' ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None","title":"Step"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Step-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Step.description","text":"A human-readable description of this step.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Step.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Step.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Step.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Step.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Step.reviewed_controls","text":"","title":"reviewed_controls"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Step.title","text":"The title for this step.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Step.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this step elsewhere in this or other OSCAL instances. The locally defined UUID of the step (in a series of steps) can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.Step.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SystemComponent","text":"A defined component that can be part of an implemented system. Source code in trestle/oscal/assessment_results.py class SystemComponent ( OscalBaseModel ): \"\"\" A defined component that can be part of an implemented system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Component Identifier' , ) type : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A category describing the purpose of the component.' , title = 'Component Type' , ) title : str = Field ( ... , description = 'A human readable name for the system component.' , title = 'Component Title' , ) description : str = Field ( ... , description = 'A description of the component, including information about its function.' , title = 'Component Description' , ) purpose : Optional [ str ] = Field ( None , description = 'A summary of the technological or business purpose of the component.' , title = 'Purpose' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : Status1 = Field ( ... , description = 'Describes the operational status of the system component.' , title = 'Status' , ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) protocols : Optional [ List [ common . Protocol ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None","title":"SystemComponent"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SystemComponent-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SystemComponent.description","text":"A description of the component, including information about its function.","title":"description"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SystemComponent.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SystemComponent.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SystemComponent.protocols","text":"","title":"protocols"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SystemComponent.purpose","text":"A summary of the technological or business purpose of the component.","title":"purpose"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SystemComponent.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SystemComponent.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SystemComponent.status","text":"Describes the operational status of the system component.","title":"status"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SystemComponent.title","text":"A human readable name for the system component.","title":"title"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SystemComponent.type","text":"A category describing the purpose of the component.","title":"type"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SystemComponent.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.assessment_results/#trestle.oscal.assessment_results.SystemComponent.Config","text":"Source code in trestle/oscal/assessment_results.py class Config : extra = Extra . forbid handler: python","title":"Config"},{"location":"api_reference/trestle.oscal.catalog/","text":"trestle.oscal.catalog \u00a4 Classes \u00a4 Catalog ( OscalBaseModel ) pydantic-model \u00a4 A collection of controls. Source code in trestle/oscal/catalog.py class Catalog ( OscalBaseModel ): \"\"\" A collection of controls. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A globally unique identifier with cross-instance scope for this catalog instance. This UUID should be changed when this document is revised.' , title = 'Catalog Universally Unique Identifier' , ) metadata : common . Metadata params : Optional [ List [ common . Parameter ]] = Field ( None ) controls : Optional [ List [ Control ]] = Field ( None ) groups : Optional [ List [ Group ]] = Field ( None ) back_matter : Optional [ common . BackMatter ] = Field ( None , alias = 'back-matter' ) Attributes \u00a4 back_matter : BackMatter pydantic-field \u00a4 controls : List [ trestle . oscal . catalog . Control ] pydantic-field \u00a4 groups : List [ trestle . oscal . catalog . Group ] pydantic-field \u00a4 metadata : Metadata pydantic-field required \u00a4 params : List [ trestle . oscal . common . Parameter ] pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A globally unique identifier with cross-instance scope for this catalog instance. This UUID should be changed when this document is revised. Config \u00a4 Source code in trestle/oscal/catalog.py class Config : extra = Extra . forbid Control ( OscalBaseModel ) pydantic-model \u00a4 A structured information object representing a security or privacy control. Each security or privacy control within the Catalog is defined by a distinct control instance. Source code in trestle/oscal/catalog.py class Control ( OscalBaseModel ): \"\"\" A structured information object representing a security or privacy control. Each security or privacy control within the Catalog is defined by a distinct control instance. \"\"\" class Config : extra = Extra . forbid id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'A human-oriented, locally unique identifier with instance scope that can be used to reference this control elsewhere in this and other OSCAL instances (e.g., profiles). This id should be assigned per-subject, which means it should be consistently used to identify the same control across revisions of the document.' , title = 'Control Identifier' , ) class_ : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'class' , description = 'A textual label that provides a sub-type or characterization of the control.' , title = 'Control Class' , ) title : str = Field ( ... , description = 'A name given to the control, which may be used by a tool for display and navigation.' , title = 'Control Title' , ) params : Optional [ List [ common . Parameter ]] = Field ( None ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) parts : Optional [ List [ common . Part ]] = Field ( None ) controls : Optional [ List [ Control ]] = None Attributes \u00a4 class_ : ConstrainedStrValue pydantic-field \u00a4 A textual label that provides a sub-type or characterization of the control. controls : List [ trestle . oscal . catalog . Control ] pydantic-field \u00a4 id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented, locally unique identifier with instance scope that can be used to reference this control elsewhere in this and other OSCAL instances (e.g., profiles). This id should be assigned per-subject, which means it should be consistently used to identify the same control across revisions of the document. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 params : List [ trestle . oscal . common . Parameter ] pydantic-field \u00a4 parts : List [ trestle . oscal . common . Part ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 title : str pydantic-field required \u00a4 A name given to the control, which may be used by a tool for display and navigation. Config \u00a4 Source code in trestle/oscal/catalog.py class Config : extra = Extra . forbid Group ( OscalBaseModel ) pydantic-model \u00a4 A group of controls, or of groups of controls. Source code in trestle/oscal/catalog.py class Group ( OscalBaseModel ): \"\"\" A group of controls, or of groups of controls. \"\"\" class Config : extra = Extra . forbid id : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , description = 'A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined group elsewhere in in this and other OSCAL instances (e.g., profiles). This id should be assigned per-subject, which means it should be consistently used to identify the same group across revisions of the document.' , title = 'Group Identifier' , ) class_ : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'class' , description = 'A textual label that provides a sub-type or characterization of the group.' , title = 'Group Class' , ) title : str = Field ( ... , description = 'A name given to the group, which may be used by a tool for display and navigation.' , title = 'Group Title' , ) params : Optional [ List [ common . Parameter ]] = Field ( None ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) parts : Optional [ List [ common . Part ]] = Field ( None ) groups : Optional [ List [ Group ]] = None controls : Optional [ List [ Control ]] = Field ( None ) Attributes \u00a4 class_ : ConstrainedStrValue pydantic-field \u00a4 A textual label that provides a sub-type or characterization of the group. controls : List [ trestle . oscal . catalog . Control ] pydantic-field \u00a4 groups : List [ trestle . oscal . catalog . Group ] pydantic-field \u00a4 id : ConstrainedStrValue pydantic-field \u00a4 A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined group elsewhere in in this and other OSCAL instances (e.g., profiles). This id should be assigned per-subject, which means it should be consistently used to identify the same group across revisions of the document. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 params : List [ trestle . oscal . common . Parameter ] pydantic-field \u00a4 parts : List [ trestle . oscal . common . Part ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 title : str pydantic-field required \u00a4 A name given to the group, which may be used by a tool for display and navigation. Config \u00a4 Source code in trestle/oscal/catalog.py class Config : extra = Extra . forbid Model ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/catalog.py class Model ( OscalBaseModel ): catalog : Catalog catalog : Catalog pydantic-field required \u00a4 handler: python","title":"catalog"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog","text":"","title":"catalog"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Catalog","text":"A collection of controls. Source code in trestle/oscal/catalog.py class Catalog ( OscalBaseModel ): \"\"\" A collection of controls. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A globally unique identifier with cross-instance scope for this catalog instance. This UUID should be changed when this document is revised.' , title = 'Catalog Universally Unique Identifier' , ) metadata : common . Metadata params : Optional [ List [ common . Parameter ]] = Field ( None ) controls : Optional [ List [ Control ]] = Field ( None ) groups : Optional [ List [ Group ]] = Field ( None ) back_matter : Optional [ common . BackMatter ] = Field ( None , alias = 'back-matter' )","title":"Catalog"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Catalog-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Catalog.back_matter","text":"","title":"back_matter"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Catalog.controls","text":"","title":"controls"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Catalog.groups","text":"","title":"groups"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Catalog.metadata","text":"","title":"metadata"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Catalog.params","text":"","title":"params"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Catalog.uuid","text":"A globally unique identifier with cross-instance scope for this catalog instance. This UUID should be changed when this document is revised.","title":"uuid"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Catalog.Config","text":"Source code in trestle/oscal/catalog.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Control","text":"A structured information object representing a security or privacy control. Each security or privacy control within the Catalog is defined by a distinct control instance. Source code in trestle/oscal/catalog.py class Control ( OscalBaseModel ): \"\"\" A structured information object representing a security or privacy control. Each security or privacy control within the Catalog is defined by a distinct control instance. \"\"\" class Config : extra = Extra . forbid id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'A human-oriented, locally unique identifier with instance scope that can be used to reference this control elsewhere in this and other OSCAL instances (e.g., profiles). This id should be assigned per-subject, which means it should be consistently used to identify the same control across revisions of the document.' , title = 'Control Identifier' , ) class_ : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'class' , description = 'A textual label that provides a sub-type or characterization of the control.' , title = 'Control Class' , ) title : str = Field ( ... , description = 'A name given to the control, which may be used by a tool for display and navigation.' , title = 'Control Title' , ) params : Optional [ List [ common . Parameter ]] = Field ( None ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) parts : Optional [ List [ common . Part ]] = Field ( None ) controls : Optional [ List [ Control ]] = None","title":"Control"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Control-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Control.class_","text":"A textual label that provides a sub-type or characterization of the control.","title":"class_"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Control.controls","text":"","title":"controls"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Control.id","text":"A human-oriented, locally unique identifier with instance scope that can be used to reference this control elsewhere in this and other OSCAL instances (e.g., profiles). This id should be assigned per-subject, which means it should be consistently used to identify the same control across revisions of the document.","title":"id"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Control.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Control.params","text":"","title":"params"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Control.parts","text":"","title":"parts"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Control.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Control.title","text":"A name given to the control, which may be used by a tool for display and navigation.","title":"title"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Control.Config","text":"Source code in trestle/oscal/catalog.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Group","text":"A group of controls, or of groups of controls. Source code in trestle/oscal/catalog.py class Group ( OscalBaseModel ): \"\"\" A group of controls, or of groups of controls. \"\"\" class Config : extra = Extra . forbid id : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , description = 'A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined group elsewhere in in this and other OSCAL instances (e.g., profiles). This id should be assigned per-subject, which means it should be consistently used to identify the same group across revisions of the document.' , title = 'Group Identifier' , ) class_ : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'class' , description = 'A textual label that provides a sub-type or characterization of the group.' , title = 'Group Class' , ) title : str = Field ( ... , description = 'A name given to the group, which may be used by a tool for display and navigation.' , title = 'Group Title' , ) params : Optional [ List [ common . Parameter ]] = Field ( None ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) parts : Optional [ List [ common . Part ]] = Field ( None ) groups : Optional [ List [ Group ]] = None controls : Optional [ List [ Control ]] = Field ( None )","title":"Group"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Group-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Group.class_","text":"A textual label that provides a sub-type or characterization of the group.","title":"class_"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Group.controls","text":"","title":"controls"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Group.groups","text":"","title":"groups"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Group.id","text":"A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined group elsewhere in in this and other OSCAL instances (e.g., profiles). This id should be assigned per-subject, which means it should be consistently used to identify the same group across revisions of the document.","title":"id"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Group.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Group.params","text":"","title":"params"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Group.parts","text":"","title":"parts"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Group.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Group.title","text":"A name given to the group, which may be used by a tool for display and navigation.","title":"title"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Group.Config","text":"Source code in trestle/oscal/catalog.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Model","text":"Source code in trestle/oscal/catalog.py class Model ( OscalBaseModel ): catalog : Catalog","title":"Model"},{"location":"api_reference/trestle.oscal.catalog/#trestle.oscal.catalog.Model.catalog","text":"handler: python","title":"catalog"},{"location":"api_reference/trestle.oscal.common/","text":"trestle.oscal.common \u00a4 Classes \u00a4 AddrLine ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/common.py class AddrLine ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A single line of an address.' , title = 'Address line' ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 A single line of an address. Address ( OscalBaseModel ) pydantic-model \u00a4 A postal address for the location. Source code in trestle/oscal/common.py class Address ( OscalBaseModel ): \"\"\" A postal address for the location. \"\"\" class Config : extra = Extra . forbid type : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , description = 'Indicates the type of address.' , title = 'Address Type' ) addr_lines : Optional [ List [ AddrLine ]] = Field ( None , alias = 'addr-lines' ) city : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , description = 'City, town or geographical region for the mailing address.' , title = 'City' , ) state : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , description = 'State, province or analogous geographical region for mailing address' , title = 'State' , ) postal_code : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , alias = 'postal-code' , description = 'Postal or ZIP code for mailing address' , title = 'Postal Code' , ) country : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , description = 'The ISO 3166-1 alpha-2 country code for the mailing address.' , title = 'Country Code' , ) Attributes \u00a4 addr_lines : List [ trestle . oscal . common . AddrLine ] pydantic-field \u00a4 city : ConstrainedStrValue pydantic-field \u00a4 City, town or geographical region for the mailing address. country : ConstrainedStrValue pydantic-field \u00a4 The ISO 3166-1 alpha-2 country code for the mailing address. postal_code : ConstrainedStrValue pydantic-field \u00a4 Postal or ZIP code for mailing address state : ConstrainedStrValue pydantic-field \u00a4 State, province or analogous geographical region for mailing address type : ConstrainedStrValue pydantic-field \u00a4 Indicates the type of address. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid AssessmentMethod ( OscalBaseModel ) pydantic-model \u00a4 A local definition of a control objective. Uses catalog syntax for control objective and assessment activities. Source code in trestle/oscal/common.py class AssessmentMethod ( OscalBaseModel ): \"\"\" A local definition of a control objective. Uses catalog syntax for control objective and assessment activities. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment method elsewhere in this or other OSCAL instances. The locally defined UUID of the assessment method can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Method Universally Unique Identifier' , ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of this assessment method.' , title = 'Assessment Method Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) part : AssessmentPart remarks : Optional [ Remarks ] = None Attributes \u00a4 description : str pydantic-field \u00a4 A human-readable description of this assessment method. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 part : AssessmentPart pydantic-field required \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment method elsewhere in this or other OSCAL instances. The locally defined UUID of the assessment method can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid AssessmentPart ( OscalBaseModel ) pydantic-model \u00a4 A partition of an assessment plan or results or a child of another part. Source code in trestle/oscal/common.py class AssessmentPart ( OscalBaseModel ): \"\"\" A partition of an assessment plan or results or a child of another part. \"\"\" class Config : extra = Extra . forbid uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this part elsewhere in this or other OSCAL instances. The locally defined UUID of the part can be used to reference the data item locally or globally (e.g., in an ported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Part Identifier' , ) name : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = \"A textual label that uniquely identifies the part's semantic type.\" , title = 'Part Name' , ) ns : Optional [ AnyUrl ] = Field ( None , description = \"A namespace qualifying the part's name. This allows different organizations to associate distinct semantics with the same name.\" , title = 'Part Namespace' , ) class_ : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'class' , description = \"A textual label that provides a sub-type or characterization of the part's name. This can be used to further distinguish or discriminate between the semantics of multiple parts of the same control with the same name and ns.\" , title = 'Part Class' , ) title : Optional [ str ] = Field ( None , description = 'A name given to the part, which may be used by a tool for display and navigation.' , title = 'Part Title' , ) props : Optional [ List [ Property ]] = Field ( None ) prose : Optional [ str ] = Field ( None , description = 'Permits multiple paragraphs, lists, tables etc.' , title = 'Part Text' , ) parts : Optional [ List [ AssessmentPart ]] = None links : Optional [ List [ Link ]] = Field ( None ) Attributes \u00a4 class_ : ConstrainedStrValue pydantic-field \u00a4 A textual label that provides a sub-type or characterization of the part's name. This can be used to further distinguish or discriminate between the semantics of multiple parts of the same control with the same name and ns. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 name : ConstrainedStrValue pydantic-field required \u00a4 A textual label that uniquely identifies the part's semantic type. ns : AnyUrl pydantic-field \u00a4 A namespace qualifying the part's name. This allows different organizations to associate distinct semantics with the same name. parts : List [ trestle . oscal . common . AssessmentPart ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 prose : str pydantic-field \u00a4 Permits multiple paragraphs, lists, tables etc. title : str pydantic-field \u00a4 A name given to the part, which may be used by a tool for display and navigation. uuid : ConstrainedStrValue pydantic-field \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this part elsewhere in this or other OSCAL instances. The locally defined UUID of the part can be used to reference the data item locally or globally (e.g., in an ported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid AssessmentPlatform ( OscalBaseModel ) pydantic-model \u00a4 Used to represent the toolset used to perform aspects of the assessment. Source code in trestle/oscal/common.py class AssessmentPlatform ( OscalBaseModel ): \"\"\" Used to represent the toolset used to perform aspects of the assessment. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment platform elsewhere in this or other OSCAL instances. The locally defined UUID of the assessment platform can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Platform Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title or name for the assessment platform.' , title = 'Assessment Platform Title' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) uses_components : Optional [ List [ UsesComponent ]] = Field ( None , alias = 'uses-components' ) remarks : Optional [ Remarks ] = None Attributes \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 title : str pydantic-field \u00a4 The title or name for the assessment platform. uses_components : List [ trestle . oscal . common . UsesComponent ] pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment platform elsewhere in this or other OSCAL instances. The locally defined UUID of the assessment platform can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid AssessmentSubject ( OscalBaseModel ) pydantic-model \u00a4 Identifies system elements being assessed, such as components, inventory items, and locations. In the assessment plan, this identifies a planned assessment subject. In the assessment results this is an actual assessment subject, and reflects any changes from the plan. exactly what will be the focus of this assessment. Any subjects not identified in this way are out-of-scope. Source code in trestle/oscal/common.py class AssessmentSubject ( OscalBaseModel ): \"\"\" Identifies system elements being assessed, such as components, inventory items, and locations. In the assessment plan, this identifies a planned assessment subject. In the assessment results this is an actual assessment subject, and reflects any changes from the plan. exactly what will be the focus of this assessment. Any subjects not identified in this way are out-of-scope. \"\"\" class Config : extra = Extra . forbid type : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Indicates the type of assessment subject, such as a component, inventory, item, location, or party represented by this selection statement.' , title = 'Subject Type' , ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of the collection of subjects being included in this assessment.' , title = 'Include Subjects Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) include_all : Optional [ IncludeAll ] = Field ( None , alias = 'include-all' ) include_subjects : Optional [ List [ SelectSubjectById ]] = Field ( None , alias = 'include-subjects' ) exclude_subjects : Optional [ List [ SelectSubjectById ]] = Field ( None , alias = 'exclude-subjects' ) remarks : Optional [ Remarks ] = None Attributes \u00a4 description : str pydantic-field \u00a4 A human-readable description of the collection of subjects being included in this assessment. exclude_subjects : List [ trestle . oscal . common . SelectSubjectById ] pydantic-field \u00a4 include_all : IncludeAll pydantic-field \u00a4 include_subjects : List [ trestle . oscal . common . SelectSubjectById ] pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 type : ConstrainedStrValue pydantic-field required \u00a4 Indicates the type of assessment subject, such as a component, inventory, item, location, or party represented by this selection statement. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid AssessmentSubjectPlaceholder ( OscalBaseModel ) pydantic-model \u00a4 Used when the assessment subjects will be determined as part of one or more other assessment activities. These assessment subjects will be recorded in the assessment results in the assessment log. Source code in trestle/oscal/common.py class AssessmentSubjectPlaceholder ( OscalBaseModel ): \"\"\" Used when the assessment subjects will be determined as part of one or more other assessment activities. These assessment subjects will be recorded in the assessment results in the assessment log. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier for a set of assessment subjects that will be identified by a task or an activity that is part of a task. The locally defined UUID of the assessment subject placeholder can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Subject Placeholder Universally Unique Identifier' , ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of intent of this assessment subject placeholder.' , title = 'Assessment Subject Placeholder Description' , ) sources : List [ Source ] = Field ( ... ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None Attributes \u00a4 description : str pydantic-field \u00a4 A human-readable description of intent of this assessment subject placeholder. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 sources : List [ trestle . oscal . common . Source ] pydantic-field required \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier for a set of assessment subjects that will be identified by a task or an activity that is part of a task. The locally defined UUID of the assessment subject placeholder can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid AssociatedActivity ( OscalBaseModel ) pydantic-model \u00a4 Identifies an individual activity to be performed as part of a task. Source code in trestle/oscal/common.py class AssociatedActivity ( OscalBaseModel ): \"\"\" Identifies an individual activity to be performed as part of a task. \"\"\" class Config : extra = Extra . forbid activity_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'activity-uuid' , description = 'A machine-oriented identifier reference to an activity defined in the list of activities.' , title = 'Activity Universally Unique Identifier Reference' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) responsible_roles : Optional [ List [ ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) subjects : List [ AssessmentSubject ] = Field ( ... ) remarks : Optional [ Remarks ] = None Attributes \u00a4 activity_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to an activity defined in the list of activities. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 subjects : List [ trestle . oscal . common . AssessmentSubject ] pydantic-field required \u00a4 Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid AtFrequency ( OscalBaseModel ) pydantic-model \u00a4 The task is intended to occur at the specified frequency. Source code in trestle/oscal/common.py class AtFrequency ( OscalBaseModel ): \"\"\" The task is intended to occur at the specified frequency. \"\"\" class Config : extra = Extra . forbid period : conint ( ge = 1 , multiple_of = 1 ) = Field ( ... , description = 'The task must occur after the specified period has elapsed.' , title = 'Period' , ) unit : Unit = Field ( ... , description = 'The unit of time for the period.' , title = 'Time Unit' ) Attributes \u00a4 period : ConstrainedIntValue pydantic-field required \u00a4 The task must occur after the specified period has elapsed. unit : Unit pydantic-field required \u00a4 The unit of time for the period. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid AuthorizedPrivilege ( OscalBaseModel ) pydantic-model \u00a4 Identifies a specific system privilege held by the user, along with an associated description and/or rationale for the privilege. Source code in trestle/oscal/common.py class AuthorizedPrivilege ( OscalBaseModel ): \"\"\" Identifies a specific system privilege held by the user, along with an associated description and/or rationale for the privilege. \"\"\" class Config : extra = Extra . forbid title : str = Field ( ... , description = 'A human readable name for the privilege.' , title = 'Privilege Title' , ) description : Optional [ str ] = Field ( None , description = \"A summary of the privilege's purpose within the system.\" , title = 'Privilege Description' , ) functions_performed : List [ FunctionPerformed ] = Field ( ... , alias = 'functions-performed' ) Attributes \u00a4 description : str pydantic-field \u00a4 A summary of the privilege's purpose within the system. functions_performed : List [ trestle . oscal . common . FunctionPerformed ] pydantic-field required \u00a4 title : str pydantic-field required \u00a4 A human readable name for the privilege. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid BackMatter ( OscalBaseModel ) pydantic-model \u00a4 A collection of resources, which may be included directly or by reference. Source code in trestle/oscal/common.py class BackMatter ( OscalBaseModel ): \"\"\" A collection of resources, which may be included directly or by reference. \"\"\" class Config : extra = Extra . forbid resources : Optional [ List [ Resource ]] = Field ( None ) resources : List [ trestle . oscal . common . Resource ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Base64 ( OscalBaseModel ) pydantic-model \u00a4 The Base64 alphabet in RFC 2045 - aligned with XSD. Source code in trestle/oscal/common.py class Base64 ( OscalBaseModel ): \"\"\" The Base64 alphabet in RFC 2045 - aligned with XSD. \"\"\" class Config : extra = Extra . forbid filename : Optional [ str ] = Field ( None , description = 'Name of the file before it was encoded as Base64 to be embedded in a resource. This is the name that will be assigned to the file when the file is decoded.' , title = 'File Name' , ) media_type : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , alias = 'media-type' , description = 'Specifies a media type as defined by the Internet Assigned Numbers Authority (IANA) Media Types Registry.' , title = 'Media Type' , ) value : str Attributes \u00a4 filename : str pydantic-field \u00a4 Name of the file before it was encoded as Base64 to be embedded in a resource. This is the name that will be assigned to the file when the file is decoded. media_type : ConstrainedStrValue pydantic-field \u00a4 Specifies a media type as defined by the Internet Assigned Numbers Authority (IANA) Media Types Registry. value : str pydantic-field required \u00a4 Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Citation ( OscalBaseModel ) pydantic-model \u00a4 A citation consisting of end note text and optional structured bibliographic data. Source code in trestle/oscal/common.py class Citation ( OscalBaseModel ): \"\"\" A citation consisting of end note text and optional structured bibliographic data. \"\"\" class Config : extra = Extra . forbid text : str = Field ( ... , description = 'A line of citation text.' , title = 'Citation Text' ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) Attributes \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 text : str pydantic-field required \u00a4 A line of citation text. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid ControlObjectiveSelection ( OscalBaseModel ) pydantic-model \u00a4 Identifies the control objectives of the assessment. In the assessment plan, these are the planned objectives. In the assessment results, these are the assessed objectives, and reflects any changes from the plan. Source code in trestle/oscal/common.py class ControlObjectiveSelection ( OscalBaseModel ): \"\"\" Identifies the control objectives of the assessment. In the assessment plan, these are the planned objectives. In the assessment results, these are the assessed objectives, and reflects any changes from the plan. \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'A human-readable description of this collection of control objectives.' , title = 'Control Objectives Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) include_all : Optional [ IncludeAll ] = Field ( None , alias = 'include-all' ) include_objectives : Optional [ List [ SelectObjectiveById ]] = Field ( None , alias = 'include-objectives' ) exclude_objectives : Optional [ List [ SelectObjectiveById ]] = Field ( None , alias = 'exclude-objectives' ) remarks : Optional [ Remarks ] = None Attributes \u00a4 description : str pydantic-field \u00a4 A human-readable description of this collection of control objectives. exclude_objectives : List [ trestle . oscal . common . SelectObjectiveById ] pydantic-field \u00a4 include_all : IncludeAll pydantic-field \u00a4 include_objectives : List [ trestle . oscal . common . SelectObjectiveById ] pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Dependency ( OscalBaseModel ) pydantic-model \u00a4 Used to indicate that a task is dependent on another task. Source code in trestle/oscal/common.py class Dependency ( OscalBaseModel ): \"\"\" Used to indicate that a task is dependent on another task. \"\"\" class Config : extra = Extra . forbid task_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'task-uuid' , description = 'A machine-oriented identifier reference to a unique task.' , title = 'Task Universally Unique Identifier Reference' , ) remarks : Optional [ Remarks ] = None Attributes \u00a4 remarks : Remarks pydantic-field \u00a4 task_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to a unique task. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid DocumentId ( OscalBaseModel ) pydantic-model \u00a4 A document identifier qualified by an identifier scheme. A document identifier provides a globally unique identifier with a cross-instance scope that is used for a group of documents that are to be treated as different versions of the same document. If this element does not appear, or if the value of this element is empty, the value of \"document-id\" is equal to the value of the \"uuid\" flag of the top-level root element. Source code in trestle/oscal/common.py class DocumentId ( OscalBaseModel ): \"\"\" A document identifier qualified by an identifier scheme. A document identifier provides a globally unique identifier with a cross-instance scope that is used for a group of documents that are to be treated as different versions of the same document. If this element does not appear, or if the value of this element is empty, the value of \"document-id\" is equal to the value of the \"uuid\" flag of the top-level root element. \"\"\" class Config : extra = Extra . forbid scheme : Optional [ AnyUrl ] = Field ( None , description = 'Qualifies the kind of document identifier using a URI. If the scheme is not provided the value of the element will be interpreted as a string of characters.' , title = 'Document Identification Scheme' , ) identifier : str Attributes \u00a4 identifier : str pydantic-field required \u00a4 scheme : AnyUrl pydantic-field \u00a4 Qualifies the kind of document identifier using a URI. If the scheme is not provided the value of the element will be interpreted as a string of characters. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid EmailAddress ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/common.py class EmailAddress ( OscalBaseModel ): __root__ : EmailStr = Field ( ... , description = 'An email address as defined by RFC 5322 Section 3.4.1.' , title = 'Email Address' , ) Attributes \u00a4 __root__ : EmailStr pydantic-field required special \u00a4 An email address as defined by RFC 5322 Section 3.4.1. ExternalId ( OscalBaseModel ) pydantic-model \u00a4 An identifier for a person or organization using a designated scheme. e.g. an Open Researcher and Contributor ID (ORCID) Source code in trestle/oscal/common.py class ExternalId ( OscalBaseModel ): \"\"\" An identifier for a person or organization using a designated scheme. e.g. an Open Researcher and Contributor ID (ORCID) \"\"\" class Config : extra = Extra . forbid scheme : AnyUrl = Field ( ... , description = 'Indicates the type of external identifier.' , title = 'External Identifier Schema' , ) id : str Attributes \u00a4 id : str pydantic-field required \u00a4 scheme : AnyUrl pydantic-field required \u00a4 Indicates the type of external identifier. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Facet ( OscalBaseModel ) pydantic-model \u00a4 An individual characteristic that is part of a larger set produced by the same actor. Source code in trestle/oscal/common.py class Facet ( OscalBaseModel ): \"\"\" An individual characteristic that is part of a larger set produced by the same actor. \"\"\" class Config : extra = Extra . forbid name : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'The name of the risk metric within the specified system.' , title = 'Facet Name' , ) system : AnyUrl = Field ( ... , description = 'Specifies the naming system under which this risk metric is organized, which allows for the same names to be used in different systems controlled by different parties. This avoids the potential of a name clash.' , title = 'Naming System' , ) value : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'Indicates the value of the facet.' , title = 'Facet Value' ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None Attributes \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 name : ConstrainedStrValue pydantic-field required \u00a4 The name of the risk metric within the specified system. props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 system : AnyUrl pydantic-field required \u00a4 Specifies the naming system under which this risk metric is organized, which allows for the same names to be used in different systems controlled by different parties. This avoids the potential of a name clash. value : ConstrainedStrValue pydantic-field required \u00a4 Indicates the value of the facet. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid FunctionPerformed ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/common.py class FunctionPerformed ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'Describes a function performed for a given authorized privilege by this user class.' , title = 'Functions Performed' , ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 Describes a function performed for a given authorized privilege by this user class. Hash ( OscalBaseModel ) pydantic-model \u00a4 A representation of a cryptographic digest generated over a resource using a specified hash algorithm. Source code in trestle/oscal/common.py class Hash ( OscalBaseModel ): \"\"\" A representation of a cryptographic digest generated over a resource using a specified hash algorithm. \"\"\" class Config : extra = Extra . forbid algorithm : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'Method by which a hash is derived' , title = 'Hash algorithm' ) value : str Attributes \u00a4 algorithm : ConstrainedStrValue pydantic-field required \u00a4 Method by which a hash is derived value : str pydantic-field required \u00a4 Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid HowMany ( Enum ) \u00a4 Describes the number of selections that must occur. Without this setting, only one value should be assumed to be permitted. Source code in trestle/oscal/common.py class HowMany ( Enum ): \"\"\" Describes the number of selections that must occur. Without this setting, only one value should be assumed to be permitted. \"\"\" one = 'one' one_or_more = 'one-or-more' one \u00a4 one_or_more \u00a4 IdentifiedSubject ( OscalBaseModel ) pydantic-model \u00a4 Used to detail assessment subjects that were identfied by this task. Source code in trestle/oscal/common.py class IdentifiedSubject ( OscalBaseModel ): \"\"\" Used to detail assessment subjects that were identfied by this task. \"\"\" class Config : extra = Extra . forbid subject_placeholder_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'subject-placeholder-uuid' , description = 'A machine-oriented identifier reference to a unique assessment subject placeholder defined by this task.' , title = 'Assessment Subject Placeholder Universally Unique Identifier Reference' , ) subjects : List [ AssessmentSubject ] = Field ( ... ) Attributes \u00a4 subject_placeholder_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to a unique assessment subject placeholder defined by this task. subjects : List [ trestle . oscal . common . AssessmentSubject ] pydantic-field required \u00a4 Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid ImplementationStatus ( OscalBaseModel ) pydantic-model \u00a4 Indicates the degree to which the a given control is implemented. Source code in trestle/oscal/common.py class ImplementationStatus ( OscalBaseModel ): \"\"\" Indicates the degree to which the a given control is implemented. \"\"\" class Config : extra = Extra . forbid state : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Identifies the implementation status of the control or control objective.' , title = 'Implementation State' , ) remarks : Optional [ Remarks ] = None Attributes \u00a4 remarks : Remarks pydantic-field \u00a4 state : ConstrainedStrValue pydantic-field required \u00a4 Identifies the implementation status of the control or control objective. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid ImplementedComponent ( OscalBaseModel ) pydantic-model \u00a4 The set of components that are implemented in a given system inventory item. Source code in trestle/oscal/common.py class ImplementedComponent ( OscalBaseModel ): \"\"\" The set of components that are implemented in a given system inventory item. \"\"\" class Config : extra = Extra . forbid component_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'component-uuid' , description = 'A machine-oriented identifier reference to a component that is implemented as part of an inventory item.' , title = 'Component Universally Unique Identifier Reference' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) responsible_parties : Optional [ List [ ResponsibleParty ]] = Field ( None , alias = 'responsible-parties' ) remarks : Optional [ Remarks ] = None Attributes \u00a4 component_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to a component that is implemented as part of an inventory item. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_parties : List [ trestle . oscal . common . ResponsibleParty ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid ImportSsp ( OscalBaseModel ) pydantic-model \u00a4 Used by the assessment plan and POA&M to import information about the system. Source code in trestle/oscal/common.py class ImportSsp ( OscalBaseModel ): \"\"\" Used by the assessment plan and POA&M to import information about the system. \"\"\" class Config : extra = Extra . forbid href : str = Field ( ... , description = 'A resolvable URL reference to the system security plan for the system being assessed.' , title = 'System Security Plan Reference' , ) remarks : Optional [ Remarks ] = None Attributes \u00a4 href : str pydantic-field required \u00a4 A resolvable URL reference to the system security plan for the system being assessed. remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid IncludeAll ( OscalBaseModel ) pydantic-model \u00a4 Include all controls from the imported catalog or profile resources. Source code in trestle/oscal/common.py class IncludeAll ( OscalBaseModel ): \"\"\" Include all controls from the imported catalog or profile resources. \"\"\" pass class Config : extra = Extra . forbid Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid InventoryItem ( OscalBaseModel ) pydantic-model \u00a4 A single managed inventory item within the system. Source code in trestle/oscal/common.py class InventoryItem ( OscalBaseModel ): \"\"\" A single managed inventory item within the system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this inventory item elsewhere in this or other OSCAL instances. The locally defined UUID of the inventory item can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Inventory Item Universally Unique Identifier' , ) description : str = Field ( ... , description = 'A summary of the inventory item stating its purpose within the system.' , title = 'Inventory Item Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) responsible_parties : Optional [ List [ ResponsibleParty ]] = Field ( None , alias = 'responsible-parties' ) implemented_components : Optional [ List [ ImplementedComponent ]] = Field ( None , alias = 'implemented-components' ) remarks : Optional [ Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A summary of the inventory item stating its purpose within the system. implemented_components : List [ trestle . oscal . common . ImplementedComponent ] pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_parties : List [ trestle . oscal . common . ResponsibleParty ] pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this inventory item elsewhere in this or other OSCAL instances. The locally defined UUID of the inventory item can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid LastModified ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/common.py class LastModified ( OscalBaseModel ): __root__ : datetime = Field ( ... , description = 'The date and time the document was last modified. The date-time value must be formatted according to RFC 3339 with full time and time zone included.' , title = 'Last Modified Timestamp' , ) Attributes \u00a4 __root__ : datetime pydantic-field required special \u00a4 The date and time the document was last modified. The date-time value must be formatted according to RFC 3339 with full time and time zone included. Link ( OscalBaseModel ) pydantic-model \u00a4 A reference to a local or remote resource Source code in trestle/oscal/common.py class Link ( OscalBaseModel ): \"\"\" A reference to a local or remote resource \"\"\" class Config : extra = Extra . forbid href : str = Field ( ... , description = 'A resolvable URL reference to a resource.' , title = 'Hypertext Reference' , ) rel : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , description = \"Describes the type of relationship provided by the link. This can be an indicator of the link's purpose.\" , title = 'Relation' , ) media_type : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , alias = 'media-type' , description = 'Specifies a media type as defined by the Internet Assigned Numbers Authority (IANA) Media Types Registry.' , title = 'Media Type' , ) text : Optional [ str ] = Field ( None , description = 'A textual label to associate with the link, which may be used for presentation in a tool.' , title = 'Link Text' , ) Attributes \u00a4 href : str pydantic-field required \u00a4 A resolvable URL reference to a resource. media_type : ConstrainedStrValue pydantic-field \u00a4 Specifies a media type as defined by the Internet Assigned Numbers Authority (IANA) Media Types Registry. rel : ConstrainedStrValue pydantic-field \u00a4 Describes the type of relationship provided by the link. This can be an indicator of the link's purpose. text : str pydantic-field \u00a4 A textual label to associate with the link, which may be used for presentation in a tool. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid LocalObjective ( OscalBaseModel ) pydantic-model \u00a4 A local definition of a control objective for this assessment. Uses catalog syntax for control objective and assessment actions. Source code in trestle/oscal/common.py class LocalObjective ( OscalBaseModel ): \"\"\" A local definition of a control objective for this assessment. Uses catalog syntax for control objective and assessment actions. \"\"\" class Config : extra = Extra . forbid control_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'control-id' , description = 'A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).' , title = 'Control Identifier Reference' , ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of this control objective.' , title = 'Objective Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) parts : List [ Part ] = Field ( ... ) remarks : Optional [ Remarks ] = None Attributes \u00a4 control_id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference). description : str pydantic-field \u00a4 A human-readable description of this control objective. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 parts : List [ trestle . oscal . common . Part ] pydantic-field required \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Location ( OscalBaseModel ) pydantic-model \u00a4 A location, with associated metadata that can be referenced. Source code in trestle/oscal/common.py class Location ( OscalBaseModel ): \"\"\" A location, with associated metadata that can be referenced. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this defined location elsewhere in this or other OSCAL instances. The locally defined UUID of the location can be used to reference the data item locally or globally (e.g., from an importing OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Location Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'A name given to the location, which may be used by a tool for display and navigation.' , title = 'Location Title' , ) address : Address email_addresses : Optional [ List [ EmailAddress ]] = Field ( None , alias = 'email-addresses' ) telephone_numbers : Optional [ List [ TelephoneNumber ]] = Field ( None , alias = 'telephone-numbers' ) urls : Optional [ List [ AnyUrl ]] = Field ( None ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None Attributes \u00a4 address : Address pydantic-field required \u00a4 email_addresses : List [ trestle . oscal . common . EmailAddress ] pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 telephone_numbers : List [ trestle . oscal . common . TelephoneNumber ] pydantic-field \u00a4 title : str pydantic-field \u00a4 A name given to the location, which may be used by a tool for display and navigation. urls : List [ pydantic . networks . AnyUrl ] pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this defined location elsewhere in this or other OSCAL instances. The locally defined UUID of the location can be used to reference the data item locally or globally (e.g., from an importing OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid LocationUuid ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/common.py class LocationUuid ( OscalBaseModel ): __root__ : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented identifier reference to a location defined in the metadata section of this or another OSCAL instance. The UUID of the location in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance).' , title = 'Location Reference' , ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 A machine-oriented identifier reference to a location defined in the metadata section of this or another OSCAL instance. The UUID of the location in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance). LoggedBy ( OscalBaseModel ) pydantic-model \u00a4 Used to indicate who created a log entry in what role. Source code in trestle/oscal/common.py class LoggedBy ( OscalBaseModel ): \"\"\" Used to indicate who created a log entry in what role. \"\"\" class Config : extra = Extra . forbid party_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'party-uuid' , description = 'A machine-oriented identifier reference to the party who is making the log entry.' , title = 'Party UUID Reference' , ) role_id : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'role-id' , description = 'A point to the role-id of the role in which the party is making the log entry.' , title = 'Actor Role' , ) Attributes \u00a4 party_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to the party who is making the log entry. role_id : ConstrainedStrValue pydantic-field \u00a4 A point to the role-id of the role in which the party is making the log entry. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid MemberOfOrganization ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/common.py class MemberOfOrganization ( OscalBaseModel ): __root__ : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented identifier reference to another party (person or organization) that this subject is associated with. The UUID of the party in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance).' , title = 'Organizational Affiliation' , ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 A machine-oriented identifier reference to another party (person or organization) that this subject is associated with. The UUID of the party in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance). Metadata ( OscalBaseModel ) pydantic-model \u00a4 Provides information about the publication and availability of the containing document. Source code in trestle/oscal/common.py class Metadata ( OscalBaseModel ): \"\"\" Provides information about the publication and availability of the containing document. \"\"\" class Config : extra = Extra . forbid title : str = Field ( ... , description = 'A name given to the document, which may be used by a tool for display and navigation.' , title = 'Document Title' , ) published : Optional [ Published ] = None last_modified : LastModified = Field ( ... , alias = 'last-modified' ) version : Version oscal_version : OscalVersion = Field ( ... , alias = 'oscal-version' ) revisions : Optional [ List [ Revision ]] = Field ( None ) document_ids : Optional [ List [ DocumentId ]] = Field ( None , alias = 'document-ids' ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) roles : Optional [ List [ Role ]] = Field ( None ) locations : Optional [ List [ Location ]] = Field ( None ) parties : Optional [ List [ Party ]] = Field ( None ) responsible_parties : Optional [ List [ ResponsibleParty ]] = Field ( None , alias = 'responsible-parties' ) remarks : Optional [ Remarks ] = None Attributes \u00a4 document_ids : List [ trestle . oscal . common . DocumentId ] pydantic-field \u00a4 last_modified : LastModified pydantic-field required \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 locations : List [ trestle . oscal . common . Location ] pydantic-field \u00a4 oscal_version : OscalVersion pydantic-field required \u00a4 parties : List [ trestle . oscal . common . Party ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 published : Published pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_parties : List [ trestle . oscal . common . ResponsibleParty ] pydantic-field \u00a4 revisions : List [ trestle . oscal . common . Revision ] pydantic-field \u00a4 roles : List [ trestle . oscal . common . Role ] pydantic-field \u00a4 title : str pydantic-field required \u00a4 A name given to the document, which may be used by a tool for display and navigation. version : Version pydantic-field required \u00a4 Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid MitigatingFactor ( OscalBaseModel ) pydantic-model \u00a4 Describes an existing mitigating factor that may affect the overall determination of the risk, with an optional link to an implementation statement in the SSP. Source code in trestle/oscal/common.py class MitigatingFactor ( OscalBaseModel ): \"\"\" Describes an existing mitigating factor that may affect the overall determination of the risk, with an optional link to an implementation statement in the SSP. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this mitigating factor elsewhere in this or other OSCAL instances. The locally defined UUID of the mitigating factor can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Mitigating Factor Universally Unique Identifier' , ) implementation_uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , alias = 'implementation-uuid' , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this implementation statement elsewhere in this or other OSCAL instancess. The locally defined UUID of the implementation statement can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Implementation UUID' , ) description : str = Field ( ... , description = 'A human-readable description of this mitigating factor.' , title = 'Mitigating Factor Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) subjects : Optional [ List [ SubjectReference ]] = Field ( None ) Attributes \u00a4 description : str pydantic-field required \u00a4 A human-readable description of this mitigating factor. implementation_uuid : ConstrainedStrValue pydantic-field \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this implementation statement elsewhere in this or other OSCAL instancess. The locally defined UUID of the implementation statement can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 subjects : List [ trestle . oscal . common . SubjectReference ] pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this mitigating factor elsewhere in this or other OSCAL instances. The locally defined UUID of the mitigating factor can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid OnDate ( OscalBaseModel ) pydantic-model \u00a4 The task is intended to occur on the specified date. Source code in trestle/oscal/common.py class OnDate ( OscalBaseModel ): \"\"\" The task is intended to occur on the specified date. \"\"\" class Config : extra = Extra . forbid date : datetime = Field ( ... , description = 'The task must occur on the specified date.' , title = 'On Date Condition' , ) Attributes \u00a4 date : datetime pydantic-field required \u00a4 The task must occur on the specified date. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid OriginActor ( OscalBaseModel ) pydantic-model \u00a4 The actor that produces an observation, a finding, or a risk. One or more actor type can be used to specify a person that is using a tool. Source code in trestle/oscal/common.py class OriginActor ( OscalBaseModel ): \"\"\" The actor that produces an observation, a finding, or a risk. One or more actor type can be used to specify a person that is using a tool. \"\"\" class Config : extra = Extra . forbid type : Type3 = Field ( ... , description = 'The kind of actor.' , title = 'Actor Type' ) actor_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'actor-uuid' , description = 'A machine-oriented identifier reference to the tool or person based on the associated type.' , title = 'Actor Universally Unique Identifier Reference' , ) role_id : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'role-id' , description = 'For a party, this can optionally be used to specify the role the actor was performing.' , title = 'Actor Role' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) Attributes \u00a4 actor_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to the tool or person based on the associated type. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 role_id : ConstrainedStrValue pydantic-field \u00a4 For a party, this can optionally be used to specify the role the actor was performing. type : Type3 pydantic-field required \u00a4 The kind of actor. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid OscalVersion ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/common.py class OscalVersion ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'The OSCAL model version the document was authored against.' , title = 'OSCAL version' , ) @validator ( '__root__' ) def oscal_version_is_valid ( cls , v ): p = re . compile ( OSCAL_VERSION_REGEX ) matched = p . match ( v ) if matched is None : raise ValueError ( f 'OSCAL version: { v } is not supported, use { OSCAL_VERSION } instead.' ) return v Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 The OSCAL model version the document was authored against. oscal_version_is_valid ( v ) classmethod \u00a4 Source code in trestle/oscal/common.py @validator ( '__root__' ) def oscal_version_is_valid ( cls , v ): p = re . compile ( OSCAL_VERSION_REGEX ) matched = p . match ( v ) if matched is None : raise ValueError ( f 'OSCAL version: { v } is not supported, use { OSCAL_VERSION } instead.' ) return v Parameter ( OscalBaseModel ) pydantic-model \u00a4 Parameters provide a mechanism for the dynamic assignment of value(s) in a control. Source code in trestle/oscal/common.py class Parameter ( OscalBaseModel ): \"\"\" Parameters provide a mechanism for the dynamic assignment of value(s) in a control. \"\"\" class Config : extra = Extra . forbid id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined parameter elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, this identifier must be referenced in the context of the containing resource (e.g., import-profile). This id should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Parameter Identifier' , ) class_ : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'class' , description = 'A textual label that provides a characterization of the parameter.' , title = 'Parameter Class' , ) depends_on : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'depends-on' , description = '**(deprecated)** Another parameter invoking this one. This construct has been deprecated and should not be used.' , title = 'Depends on' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) label : Optional [ str ] = Field ( None , description = 'A short, placeholder name for the parameter, which can be used as a substitute for a value if no value is assigned.' , title = 'Parameter Label' , ) usage : Optional [ str ] = Field ( None , description = 'Describes the purpose and use of a parameter' , title = 'Parameter Usage Description' , ) constraints : Optional [ List [ ParameterConstraint ]] = Field ( None ) guidelines : Optional [ List [ ParameterGuideline ]] = Field ( None ) values : Optional [ List [ ParameterValue ]] = Field ( None ) select : Optional [ ParameterSelection ] = None remarks : Optional [ Remarks ] = None Attributes \u00a4 class_ : ConstrainedStrValue pydantic-field \u00a4 A textual label that provides a characterization of the parameter. constraints : List [ trestle . oscal . common . ParameterConstraint ] pydantic-field \u00a4 depends_on : ConstrainedStrValue pydantic-field \u00a4 (deprecated) Another parameter invoking this one. This construct has been deprecated and should not be used. guidelines : List [ trestle . oscal . common . ParameterGuideline ] pydantic-field \u00a4 id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined parameter elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, this identifier must be referenced in the context of the containing resource (e.g., import-profile). This id should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. label : str pydantic-field \u00a4 A short, placeholder name for the parameter, which can be used as a substitute for a value if no value is assigned. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 select : ParameterSelection pydantic-field \u00a4 usage : str pydantic-field \u00a4 Describes the purpose and use of a parameter values : List [ trestle . oscal . common . ParameterValue ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid ParameterConstraint ( OscalBaseModel ) pydantic-model \u00a4 A formal or informal expression of a constraint or test Source code in trestle/oscal/common.py class ParameterConstraint ( OscalBaseModel ): \"\"\" A formal or informal expression of a constraint or test \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'A textual summary of the constraint to be applied.' , title = 'Constraint Description' , ) tests : Optional [ List [ Test ]] = Field ( None ) Attributes \u00a4 description : str pydantic-field \u00a4 A textual summary of the constraint to be applied. tests : List [ trestle . oscal . common . Test ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid ParameterGuideline ( OscalBaseModel ) pydantic-model \u00a4 A prose statement that provides a recommendation for the use of a parameter. Source code in trestle/oscal/common.py class ParameterGuideline ( OscalBaseModel ): \"\"\" A prose statement that provides a recommendation for the use of a parameter. \"\"\" class Config : extra = Extra . forbid prose : str = Field ( ... , description = 'Prose permits multiple paragraphs, lists, tables etc.' , title = 'Guideline Text' , ) Attributes \u00a4 prose : str pydantic-field required \u00a4 Prose permits multiple paragraphs, lists, tables etc. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid ParameterSelection ( OscalBaseModel ) pydantic-model \u00a4 Presenting a choice among alternatives Source code in trestle/oscal/common.py class ParameterSelection ( OscalBaseModel ): \"\"\" Presenting a choice among alternatives \"\"\" class Config : extra = Extra . forbid how_many : Optional [ HowMany ] = Field ( None , alias = 'how-many' , description = 'Describes the number of selections that must occur. Without this setting, only one value should be assumed to be permitted.' , title = 'Parameter Cardinality' , ) choice : Optional [ List [ str ]] = Field ( None ) Attributes \u00a4 choice : List [ str ] pydantic-field \u00a4 how_many : HowMany pydantic-field \u00a4 Describes the number of selections that must occur. Without this setting, only one value should be assumed to be permitted. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid ParameterValue ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/common.py class ParameterValue ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A parameter value or set of values.' , title = 'Parameter Value' ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 A parameter value or set of values. Part ( OscalBaseModel ) pydantic-model \u00a4 A partition of a control's definition or a child of another part. Source code in trestle/oscal/common.py class Part ( OscalBaseModel ): \"\"\" A partition of a control's definition or a child of another part. \"\"\" class Config : extra = Extra . forbid id : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , description = 'A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined part elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, this identifier must be referenced in the context of the containing resource (e.g., import-profile). This id should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Part Identifier' , ) name : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = \"A textual label that uniquely identifies the part's semantic type.\" , title = 'Part Name' , ) ns : Optional [ AnyUrl ] = Field ( None , description = \"A namespace qualifying the part's name. This allows different organizations to associate distinct semantics with the same name.\" , title = 'Part Namespace' , ) class_ : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'class' , description = \"A textual label that provides a sub-type or characterization of the part's name. This can be used to further distinguish or discriminate between the semantics of multiple parts of the same control with the same name and ns.\" , title = 'Part Class' , ) title : Optional [ str ] = Field ( None , description = 'A name given to the part, which may be used by a tool for display and navigation.' , title = 'Part Title' , ) props : Optional [ List [ Property ]] = Field ( None ) prose : Optional [ str ] = Field ( None , description = 'Permits multiple paragraphs, lists, tables etc.' , title = 'Part Text' , ) parts : Optional [ List [ Part ]] = None links : Optional [ List [ Link ]] = Field ( None ) Attributes \u00a4 class_ : ConstrainedStrValue pydantic-field \u00a4 A textual label that provides a sub-type or characterization of the part's name. This can be used to further distinguish or discriminate between the semantics of multiple parts of the same control with the same name and ns. id : ConstrainedStrValue pydantic-field \u00a4 A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined part elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, this identifier must be referenced in the context of the containing resource (e.g., import-profile). This id should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 name : ConstrainedStrValue pydantic-field required \u00a4 A textual label that uniquely identifies the part's semantic type. ns : AnyUrl pydantic-field \u00a4 A namespace qualifying the part's name. This allows different organizations to associate distinct semantics with the same name. parts : List [ trestle . oscal . common . Part ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 prose : str pydantic-field \u00a4 Permits multiple paragraphs, lists, tables etc. title : str pydantic-field \u00a4 A name given to the part, which may be used by a tool for display and navigation. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Party ( OscalBaseModel ) pydantic-model \u00a4 A responsible entity which is either a person or an organization. Source code in trestle/oscal/common.py class Party ( OscalBaseModel ): \"\"\" A responsible entity which is either a person or an organization. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this defined party elsewhere in this or other OSCAL instances. The locally defined UUID of the party can be used to reference the data item locally or globally (e.g., from an importing OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Party Universally Unique Identifier' , ) type : Type = Field ( ... , description = 'A category describing the kind of party the object describes.' , title = 'Party Type' , ) name : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , description = 'The full name of the party. This is typically the legal name associated with the party.' , title = 'Party Name' , ) short_name : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , alias = 'short-name' , description = 'A short common name, abbreviation, or acronym for the party.' , title = 'Party Short Name' , ) external_ids : Optional [ List [ ExternalId ]] = Field ( None , alias = 'external-ids' ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) email_addresses : Optional [ List [ EmailAddress ]] = Field ( None , alias = 'email-addresses' ) telephone_numbers : Optional [ List [ TelephoneNumber ]] = Field ( None , alias = 'telephone-numbers' ) addresses : Optional [ List [ Address ]] = Field ( None ) location_uuids : Optional [ List [ LocationUuid ]] = Field ( None , alias = 'location-uuids' ) member_of_organizations : Optional [ List [ MemberOfOrganization ]] = Field ( None , alias = 'member-of-organizations' ) remarks : Optional [ Remarks ] = None Attributes \u00a4 addresses : List [ trestle . oscal . common . Address ] pydantic-field \u00a4 email_addresses : List [ trestle . oscal . common . EmailAddress ] pydantic-field \u00a4 external_ids : List [ trestle . oscal . common . ExternalId ] pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 location_uuids : List [ trestle . oscal . common . LocationUuid ] pydantic-field \u00a4 member_of_organizations : List [ trestle . oscal . common . MemberOfOrganization ] pydantic-field \u00a4 name : ConstrainedStrValue pydantic-field \u00a4 The full name of the party. This is typically the legal name associated with the party. props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 short_name : ConstrainedStrValue pydantic-field \u00a4 A short common name, abbreviation, or acronym for the party. telephone_numbers : List [ trestle . oscal . common . TelephoneNumber ] pydantic-field \u00a4 type : Type pydantic-field required \u00a4 A category describing the kind of party the object describes. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this defined party elsewhere in this or other OSCAL instances. The locally defined UUID of the party can be used to reference the data item locally or globally (e.g., from an importing OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid PartyUuid ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/common.py class PartyUuid ( OscalBaseModel ): __root__ : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented identifier reference to another party defined in metadata. The UUID of the party in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance).' , title = 'Party Reference' , ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 A machine-oriented identifier reference to another party defined in metadata. The UUID of the party in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance). PortRange ( OscalBaseModel ) pydantic-model \u00a4 Where applicable this is the IPv4 port range on which the service operates. Source code in trestle/oscal/common.py class PortRange ( OscalBaseModel ): \"\"\" Where applicable this is the IPv4 port range on which the service operates. \"\"\" class Config : extra = Extra . forbid start : Optional [ conint ( ge = 0 , multiple_of = 1 )] = Field ( None , description = 'Indicates the starting port number in a port range' , title = 'Start' , ) end : Optional [ conint ( ge = 0 , multiple_of = 1 )] = Field ( None , description = 'Indicates the ending port number in a port range' , title = 'End' , ) transport : Optional [ Transport ] = Field ( None , description = 'Indicates the transport type.' , title = 'Transport' ) Attributes \u00a4 end : ConstrainedIntValue pydantic-field \u00a4 Indicates the ending port number in a port range start : ConstrainedIntValue pydantic-field \u00a4 Indicates the starting port number in a port range transport : Transport pydantic-field \u00a4 Indicates the transport type. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Property ( OscalBaseModel ) pydantic-model \u00a4 An attribute, characteristic, or quality of the containing object expressed as a namespace qualified name/value pair. The value of a property is a simple scalar value, which may be expressed as a list of values. Source code in trestle/oscal/common.py class Property ( OscalBaseModel ): \"\"\" An attribute, characteristic, or quality of the containing object expressed as a namespace qualified name/value pair. The value of a property is a simple scalar value, which may be expressed as a list of values. \"\"\" class Config : extra = Extra . forbid name : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = \"A textual label that uniquely identifies a specific attribute, characteristic, or quality of the property's containing object.\" , title = 'Property Name' , ) uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this defined property elsewhere in this or other OSCAL instances. This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Property Universally Unique Identifier' , ) ns : Optional [ AnyUrl ] = Field ( None , description = \"A namespace qualifying the property's name. This allows different organizations to associate distinct semantics with the same name.\" , title = 'Property Namespace' , ) value : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'Indicates the value of the attribute, characteristic, or quality.' , title = 'Property Value' , ) class_ : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'class' , description = \"A textual label that provides a sub-type or characterization of the property's name. This can be used to further distinguish or discriminate between the semantics of multiple properties of the same object with the same name and ns.\" , title = 'Property Class' , ) remarks : Optional [ Remarks ] = None Attributes \u00a4 class_ : ConstrainedStrValue pydantic-field \u00a4 A textual label that provides a sub-type or characterization of the property's name. This can be used to further distinguish or discriminate between the semantics of multiple properties of the same object with the same name and ns. name : ConstrainedStrValue pydantic-field required \u00a4 A textual label that uniquely identifies a specific attribute, characteristic, or quality of the property's containing object. ns : AnyUrl pydantic-field \u00a4 A namespace qualifying the property's name. This allows different organizations to associate distinct semantics with the same name. remarks : Remarks pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this defined property elsewhere in this or other OSCAL instances. This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. value : ConstrainedStrValue pydantic-field required \u00a4 Indicates the value of the attribute, characteristic, or quality. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Protocol ( OscalBaseModel ) pydantic-model \u00a4 Information about the protocol used to provide a service. Source code in trestle/oscal/common.py class Protocol ( OscalBaseModel ): \"\"\" Information about the protocol used to provide a service. \"\"\" class Config : extra = Extra . forbid uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this service protocol information elsewhere in this or other OSCAL instances. The locally defined UUID of the service protocol can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Service Protocol Information Universally Unique Identifier' , ) name : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'The common name of the protocol, which should be the appropriate \"service name\" from the IANA Service Name and Transport Protocol Port Number Registry.' , title = 'Protocol Name' , ) title : Optional [ str ] = Field ( None , description = 'A human readable name for the protocol (e.g., Transport Layer Security).' , title = 'Protocol Title' , ) port_ranges : Optional [ List [ PortRange ]] = Field ( None , alias = 'port-ranges' ) Attributes \u00a4 name : ConstrainedStrValue pydantic-field required \u00a4 The common name of the protocol, which should be the appropriate \"service name\" from the IANA Service Name and Transport Protocol Port Number Registry. port_ranges : List [ trestle . oscal . common . PortRange ] pydantic-field \u00a4 title : str pydantic-field \u00a4 A human readable name for the protocol (e.g., Transport Layer Security). uuid : ConstrainedStrValue pydantic-field \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this service protocol information elsewhere in this or other OSCAL instances. The locally defined UUID of the service protocol can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Published ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/common.py class Published ( OscalBaseModel ): __root__ : datetime = Field ( ... , description = 'The date and time the document was published. The date-time value must be formatted according to RFC 3339 with full time and time zone included.' , title = 'Publication Timestamp' , ) Attributes \u00a4 __root__ : datetime pydantic-field required special \u00a4 The date and time the document was published. The date-time value must be formatted according to RFC 3339 with full time and time zone included. RelatedObservation1 ( OscalBaseModel ) pydantic-model \u00a4 Relates the finding to a set of referenced observations that were used to determine the finding. Source code in trestle/oscal/common.py class RelatedObservation1 ( OscalBaseModel ): \"\"\" Relates the finding to a set of referenced observations that were used to determine the finding. \"\"\" class Config : extra = Extra . forbid observation_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'observation-uuid' , description = 'A machine-oriented identifier reference to an observation defined in the list of observations.' , title = 'Observation Universally Unique Identifier Reference' , ) Attributes \u00a4 observation_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to an observation defined in the list of observations. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid RelatedResponse ( OscalBaseModel ) pydantic-model \u00a4 Identifies an individual risk response that this log entry is for. Source code in trestle/oscal/common.py class RelatedResponse ( OscalBaseModel ): \"\"\" Identifies an individual risk response that this log entry is for. \"\"\" class Config : extra = Extra . forbid response_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'response-uuid' , description = 'A machine-oriented identifier reference to a unique risk response.' , title = 'Response Universally Unique Identifier Reference' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) related_tasks : Optional [ List [ RelatedTask ]] = Field ( None , alias = 'related-tasks' ) remarks : Optional [ Remarks ] = None Attributes \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 related_tasks : List [ trestle . oscal . common . RelatedTask ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 response_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to a unique risk response. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid RelatedRisk ( OscalBaseModel ) pydantic-model \u00a4 Relates the finding to a set of referenced risks that were used to determine the finding. Source code in trestle/oscal/common.py class RelatedRisk ( OscalBaseModel ): \"\"\" Relates the finding to a set of referenced risks that were used to determine the finding. \"\"\" class Config : extra = Extra . forbid risk_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'risk-uuid' , description = 'A machine-oriented identifier reference to a risk defined in the list of risks.' , title = 'Risk Universally Unique Identifier Reference' , ) Attributes \u00a4 risk_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to a risk defined in the list of risks. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid RelatedTask ( OscalBaseModel ) pydantic-model \u00a4 Identifies an individual task for which the containing object is a consequence of. Source code in trestle/oscal/common.py class RelatedTask ( OscalBaseModel ): \"\"\" Identifies an individual task for which the containing object is a consequence of. \"\"\" class Config : extra = Extra . forbid task_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'task-uuid' , description = 'A machine-oriented identifier reference to a unique task.' , title = 'Task Universally Unique Identifier Reference' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) responsible_parties : Optional [ List [ ResponsibleParty ]] = Field ( None , alias = 'responsible-parties' ) subjects : Optional [ List [ AssessmentSubject ]] = Field ( None ) identified_subject : Optional [ IdentifiedSubject ] = Field ( None , alias = 'identified-subject' , description = 'Used to detail assessment subjects that were identfied by this task.' , title = 'Identified Subject' , ) remarks : Optional [ Remarks ] = None Attributes \u00a4 identified_subject : IdentifiedSubject pydantic-field \u00a4 Used to detail assessment subjects that were identfied by this task. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_parties : List [ trestle . oscal . common . ResponsibleParty ] pydantic-field \u00a4 subjects : List [ trestle . oscal . common . AssessmentSubject ] pydantic-field \u00a4 task_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to a unique task. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid RelevantEvidence ( OscalBaseModel ) pydantic-model \u00a4 Links this observation to relevant evidence. Source code in trestle/oscal/common.py class RelevantEvidence ( OscalBaseModel ): \"\"\" Links this observation to relevant evidence. \"\"\" class Config : extra = Extra . forbid href : Optional [ str ] = Field ( None , description = 'A resolvable URL reference to relevant evidence.' , title = 'Relevant Evidence Reference' , ) description : str = Field ( ... , description = 'A human-readable description of this evidence.' , title = 'Relevant Evidence Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A human-readable description of this evidence. href : str pydantic-field \u00a4 A resolvable URL reference to relevant evidence. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Remarks ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/common.py class Remarks ( OscalBaseModel ): __root__ : str = Field ( ... , description = 'Additional commentary on the containing object.' , title = 'Remarks' , ) Attributes \u00a4 __root__ : str pydantic-field required special \u00a4 Additional commentary on the containing object. RequiredAsset ( OscalBaseModel ) pydantic-model \u00a4 Identifies an asset required to achieve remediation. Source code in trestle/oscal/common.py class RequiredAsset ( OscalBaseModel ): \"\"\" Identifies an asset required to achieve remediation. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this required asset elsewhere in this or other OSCAL instances. The locally defined UUID of the asset can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Required Universally Unique Identifier' , ) subjects : Optional [ List [ SubjectReference ]] = Field ( None ) title : Optional [ str ] = Field ( None , description = 'The title for this required asset.' , title = 'Title for Required Asset' , ) description : str = Field ( ... , description = 'A human-readable description of this required asset.' , title = 'Description of Required Asset' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A human-readable description of this required asset. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 subjects : List [ trestle . oscal . common . SubjectReference ] pydantic-field \u00a4 title : str pydantic-field \u00a4 The title for this required asset. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this required asset elsewhere in this or other OSCAL instances. The locally defined UUID of the asset can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Resource ( OscalBaseModel ) pydantic-model \u00a4 A resource associated with content in the containing document. A resource may be directly included in the document base64 encoded or may point to one or more equivalent internet resources. Source code in trestle/oscal/common.py class Resource ( OscalBaseModel ): \"\"\" A resource associated with content in the containing document. A resource may be directly included in the document base64 encoded or may point to one or more equivalent internet resources. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this defined resource elsewhere in this or other OSCAL instances. This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Resource Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'A name given to the resource, which may be used by a tool for display and navigation.' , title = 'Resource Title' , ) description : Optional [ str ] = Field ( None , description = 'A short summary of the resource used to indicate the purpose of the resource.' , title = 'Resource Description' , ) props : Optional [ List [ Property ]] = Field ( None ) document_ids : Optional [ List [ DocumentId ]] = Field ( None , alias = 'document-ids' ) citation : Optional [ Citation ] = Field ( None , description = 'A citation consisting of end note text and optional structured bibliographic data.' , title = 'Citation' , ) rlinks : Optional [ List [ Rlink ]] = Field ( None ) base64 : Optional [ Base64 ] = Field ( None , description = 'The Base64 alphabet in RFC 2045 - aligned with XSD.' , title = 'Base64' , ) remarks : Optional [ Remarks ] = None Attributes \u00a4 base64 : Base64 pydantic-field \u00a4 The Base64 alphabet in RFC 2045 - aligned with XSD. citation : Citation pydantic-field \u00a4 A citation consisting of end note text and optional structured bibliographic data. description : str pydantic-field \u00a4 A short summary of the resource used to indicate the purpose of the resource. document_ids : List [ trestle . oscal . common . DocumentId ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 rlinks : List [ trestle . oscal . common . Rlink ] pydantic-field \u00a4 title : str pydantic-field \u00a4 A name given to the resource, which may be used by a tool for display and navigation. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this defined resource elsewhere in this or other OSCAL instances. This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid ResponsibleParty ( OscalBaseModel ) pydantic-model \u00a4 A reference to a set of organizations or persons that have responsibility for performing a referenced role in the context of the containing object. Source code in trestle/oscal/common.py class ResponsibleParty ( OscalBaseModel ): \"\"\" A reference to a set of organizations or persons that have responsibility for performing a referenced role in the context of the containing object. \"\"\" class Config : extra = Extra . forbid role_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'role-id' , description = 'A human-oriented identifier reference to roles served by the user.' , title = 'Responsible Role' , ) party_uuids : List [ PartyUuid ] = Field ( ... , alias = 'party-uuids' ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None Attributes \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 party_uuids : List [ trestle . oscal . common . PartyUuid ] pydantic-field required \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 role_id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented identifier reference to roles served by the user. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid ResponsibleRole ( OscalBaseModel ) pydantic-model \u00a4 A reference to one or more roles with responsibility for performing a function relative to the containing object. Source code in trestle/oscal/common.py class ResponsibleRole ( OscalBaseModel ): \"\"\" A reference to one or more roles with responsibility for performing a function relative to the containing object. \"\"\" class Config : extra = Extra . forbid role_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'role-id' , description = 'A human-oriented identifier reference to roles responsible for the business function.' , title = 'Responsible Role ID' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) party_uuids : Optional [ List [ PartyUuid ]] = Field ( None , alias = 'party-uuids' ) remarks : Optional [ Remarks ] = None Attributes \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 party_uuids : List [ trestle . oscal . common . PartyUuid ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 role_id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented identifier reference to roles responsible for the business function. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Revision ( OscalBaseModel ) pydantic-model \u00a4 An entry in a sequential list of revisions to the containing document in reverse chronological order (i.e., most recent previous revision first). Source code in trestle/oscal/common.py class Revision ( OscalBaseModel ): \"\"\" An entry in a sequential list of revisions to the containing document in reverse chronological order (i.e., most recent previous revision first). \"\"\" class Config : extra = Extra . forbid title : Optional [ str ] = Field ( None , description = 'A name given to the document revision, which may be used by a tool for display and navigation.' , title = 'Document Title' , ) published : Optional [ Published ] = None last_modified : Optional [ LastModified ] = Field ( None , alias = 'last-modified' ) version : Version oscal_version : Optional [ OscalVersion ] = Field ( None , alias = 'oscal-version' ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None Attributes \u00a4 last_modified : LastModified pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 oscal_version : OscalVersion pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 published : Published pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 title : str pydantic-field \u00a4 A name given to the document revision, which may be used by a tool for display and navigation. version : Version pydantic-field required \u00a4 Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid RiskStatus ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/common.py class RiskStatus ( OscalBaseModel ): __root__ : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Describes the status of the associated risk.' , title = 'Risk Status' , ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 Describes the status of the associated risk. Rlink ( OscalBaseModel ) pydantic-model \u00a4 A pointer to an external resource with an optional hash for verification and change detection. Source code in trestle/oscal/common.py class Rlink ( OscalBaseModel ): \"\"\" A pointer to an external resource with an optional hash for verification and change detection. \"\"\" class Config : extra = Extra . forbid href : str = Field ( ... , description = 'A resolvable URI reference to a resource.' , title = 'Hypertext Reference' , ) media_type : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , alias = 'media-type' , description = 'Specifies a media type as defined by the Internet Assigned Numbers Authority (IANA) Media Types Registry.' , title = 'Media Type' , ) hashes : Optional [ List [ Hash ]] = Field ( None ) Attributes \u00a4 hashes : List [ trestle . oscal . common . Hash ] pydantic-field \u00a4 href : str pydantic-field required \u00a4 A resolvable URI reference to a resource. media_type : ConstrainedStrValue pydantic-field \u00a4 Specifies a media type as defined by the Internet Assigned Numbers Authority (IANA) Media Types Registry. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Role ( OscalBaseModel ) pydantic-model \u00a4 Defines a function assumed or expected to be assumed by a party in a specific situation. Source code in trestle/oscal/common.py class Role ( OscalBaseModel ): \"\"\" Defines a function assumed or expected to be assumed by a party in a specific situation. \"\"\" class Config : extra = Extra . forbid id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined role elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, the locally defined ID of the Role from the imported OSCAL instance must be referenced in the context of the containing resource (e.g., import, import-component-definition, import-profile, import-ssp or import-ap). This ID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Role Identifier' , ) title : str = Field ( ... , description = 'A name given to the role, which may be used by a tool for display and navigation.' , title = 'Role Title' , ) short_name : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , alias = 'short-name' , description = 'A short common name, abbreviation, or acronym for the role.' , title = 'Role Short Name' , ) description : Optional [ str ] = Field ( None , description = \"A summary of the role's purpose and associated responsibilities.\" , title = 'Role Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None Attributes \u00a4 description : str pydantic-field \u00a4 A summary of the role's purpose and associated responsibilities. id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined role elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, the locally defined ID of the Role from the imported OSCAL instance must be referenced in the context of the containing resource (e.g., import, import-component-definition, import-profile, import-ssp or import-ap). This ID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 short_name : ConstrainedStrValue pydantic-field \u00a4 A short common name, abbreviation, or acronym for the role. title : str pydantic-field required \u00a4 A name given to the role, which may be used by a tool for display and navigation. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid RoleId ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/common.py class RoleId ( OscalBaseModel ): __root__ : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'A human-oriented identifier reference to roles served by the user.' , title = 'Role Identifier Reference' , ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 A human-oriented identifier reference to roles served by the user. SelectObjectiveById ( OscalBaseModel ) pydantic-model \u00a4 Used to select a control objective for inclusion/exclusion based on the control objective's identifier. Source code in trestle/oscal/common.py class SelectObjectiveById ( OscalBaseModel ): \"\"\" Used to select a control objective for inclusion/exclusion based on the control objective's identifier. \"\"\" class Config : extra = Extra . forbid objective_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'objective-id' , description = 'Points to an assessment objective.' , title = 'Objective ID' , ) Attributes \u00a4 objective_id : ConstrainedStrValue pydantic-field required \u00a4 Points to an assessment objective. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid SelectSubjectById ( OscalBaseModel ) pydantic-model \u00a4 Identifies a set of assessment subjects to include/exclude by UUID. Source code in trestle/oscal/common.py class SelectSubjectById ( OscalBaseModel ): \"\"\" Identifies a set of assessment subjects to include/exclude by UUID. \"\"\" class Config : extra = Extra . forbid subject_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'subject-uuid' , description = \"A machine-oriented identifier reference to a component, inventory-item, location, party, user, or resource using it's UUID.\" , title = 'Subject Universally Unique Identifier Reference' , ) type : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Used to indicate the type of object pointed to by the uuid-ref within a subject.' , title = 'Subject Universally Unique Identifier Reference Type' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None Attributes \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 subject_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to a component, inventory-item, location, party, user, or resource using it's UUID. type : ConstrainedStrValue pydantic-field required \u00a4 Used to indicate the type of object pointed to by the uuid-ref within a subject. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Source ( OscalBaseModel ) pydantic-model \u00a4 Assessment subjects will be identified while conducting the referenced activity-instance. Source code in trestle/oscal/common.py class Source ( OscalBaseModel ): \"\"\" Assessment subjects will be identified while conducting the referenced activity-instance. \"\"\" class Config : extra = Extra . forbid task_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'task-uuid' , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference (in this or other OSCAL instances) an assessment activity to be performed as part of the event. The locally defined UUID of the task can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Task Universally Unique Identifier' , ) Attributes \u00a4 task_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference (in this or other OSCAL instances) an assessment activity to be performed as part of the event. The locally defined UUID of the task can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid StatementId ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/common.py class StatementId ( OscalBaseModel ): __root__ : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Used to constrain the selection to only specificity identified statements.' , title = 'Include Specific Statements' , ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 Used to constrain the selection to only specificity identified statements. SubjectReference ( OscalBaseModel ) pydantic-model \u00a4 A human-oriented identifier reference to a resource. Use type to indicate whether the identified resource is a component, inventory item, location, user, or something else. Source code in trestle/oscal/common.py class SubjectReference ( OscalBaseModel ): \"\"\" A human-oriented identifier reference to a resource. Use type to indicate whether the identified resource is a component, inventory item, location, user, or something else. \"\"\" class Config : extra = Extra . forbid subject_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'subject-uuid' , description = \"A machine-oriented identifier reference to a component, inventory-item, location, party, user, or resource using it's UUID.\" , title = 'Subject Universally Unique Identifier Reference' , ) type : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Used to indicate the type of object pointed to by the uuid-ref within a subject.' , title = 'Subject Universally Unique Identifier Reference Type' , ) title : Optional [ str ] = Field ( None , description = 'The title or name for the referenced subject.' , title = 'Subject Reference Title' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None Attributes \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 subject_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to a component, inventory-item, location, party, user, or resource using it's UUID. title : str pydantic-field \u00a4 The title or name for the referenced subject. type : ConstrainedStrValue pydantic-field required \u00a4 Used to indicate the type of object pointed to by the uuid-ref within a subject. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid SystemId ( OscalBaseModel ) pydantic-model \u00a4 A human-oriented, globally unique identifier with cross-instance scope that can be used to reference this system identification property elsewhere in this or other OSCAL instances. When referencing an externally defined system identification, the system identification must be used in the context of the external / imported OSCAL instance (e.g., uri-reference). This string should be assigned per-subject, which means it should be consistently used to identify the same system across revisions of the document. Source code in trestle/oscal/common.py class SystemId ( OscalBaseModel ): \"\"\" A human-oriented, globally unique identifier with cross-instance scope that can be used to reference this system identification property elsewhere in this or other OSCAL instances. When referencing an externally defined system identification, the system identification must be used in the context of the external / imported OSCAL instance (e.g., uri-reference). This string should be assigned per-subject, which means it should be consistently used to identify the same system across revisions of the document. \"\"\" class Config : extra = Extra . forbid identifier_type : Optional [ AnyUrl ] = Field ( None , alias = 'identifier-type' , description = 'Identifies the identification system from which the provided identifier was assigned.' , title = 'Identification System Type' , ) id : str Attributes \u00a4 id : str pydantic-field required \u00a4 identifier_type : AnyUrl pydantic-field \u00a4 Identifies the identification system from which the provided identifier was assigned. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid SystemUser ( OscalBaseModel ) pydantic-model \u00a4 A type of user that interacts with the system based on an associated role. Source code in trestle/oscal/common.py class SystemUser ( OscalBaseModel ): \"\"\" A type of user that interacts with the system based on an associated role. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this user class elsewhere in this or other OSCAL instances. The locally defined UUID of the system user can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'User Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'A name given to the user, which may be used by a tool for display and navigation.' , title = 'User Title' , ) short_name : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , alias = 'short-name' , description = 'A short common name, abbreviation, or acronym for the user.' , title = 'User Short Name' , ) description : Optional [ str ] = Field ( None , description = \"A summary of the user's purpose within the system.\" , title = 'User Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) role_ids : Optional [ List [ RoleId ]] = Field ( None , alias = 'role-ids' ) authorized_privileges : Optional [ List [ AuthorizedPrivilege ]] = Field ( None , alias = 'authorized-privileges' ) remarks : Optional [ Remarks ] = None Attributes \u00a4 authorized_privileges : List [ trestle . oscal . common . AuthorizedPrivilege ] pydantic-field \u00a4 description : str pydantic-field \u00a4 A summary of the user's purpose within the system. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 role_ids : List [ trestle . oscal . common . RoleId ] pydantic-field \u00a4 short_name : ConstrainedStrValue pydantic-field \u00a4 A short common name, abbreviation, or acronym for the user. title : str pydantic-field \u00a4 A name given to the user, which may be used by a tool for display and navigation. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this user class elsewhere in this or other OSCAL instances. The locally defined UUID of the system user can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Task ( OscalBaseModel ) pydantic-model \u00a4 Represents a scheduled event or milestone, which may be associated with a series of assessment actions. Source code in trestle/oscal/common.py class Task ( OscalBaseModel ): \"\"\" Represents a scheduled event or milestone, which may be associated with a series of assessment actions. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this task elsewhere in this or other OSCAL instances. The locally defined UUID of the task can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Task Universally Unique Identifier' , ) type : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'The type of task.' , title = 'Task Type' ) title : str = Field ( ... , description = 'The title for this task.' , title = 'Task Title' ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of this task.' , title = 'Task Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) timing : Optional [ Timing ] = Field ( None , description = 'The timing under which the task is intended to occur.' , title = 'Event Timing' , ) dependencies : Optional [ List [ Dependency ]] = Field ( None ) tasks : Optional [ List [ Task ]] = None associated_activities : Optional [ List [ AssociatedActivity ]] = Field ( None , alias = 'associated-activities' ) subjects : Optional [ List [ AssessmentSubject ]] = Field ( None ) responsible_roles : Optional [ List [ ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ Remarks ] = None Attributes \u00a4 associated_activities : List [ trestle . oscal . common . AssociatedActivity ] pydantic-field \u00a4 dependencies : List [ trestle . oscal . common . Dependency ] pydantic-field \u00a4 description : str pydantic-field \u00a4 A human-readable description of this task. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 subjects : List [ trestle . oscal . common . AssessmentSubject ] pydantic-field \u00a4 tasks : List [ trestle . oscal . common . Task ] pydantic-field \u00a4 timing : Timing pydantic-field \u00a4 The timing under which the task is intended to occur. title : str pydantic-field required \u00a4 The title for this task. type : ConstrainedStrValue pydantic-field required \u00a4 The type of task. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this task elsewhere in this or other OSCAL instances. The locally defined UUID of the task can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid TelephoneNumber ( OscalBaseModel ) pydantic-model \u00a4 Contact number by telephone. Source code in trestle/oscal/common.py class TelephoneNumber ( OscalBaseModel ): \"\"\" Contact number by telephone. \"\"\" class Config : extra = Extra . forbid type : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , description = 'Indicates the type of phone number.' , title = 'type flag' ) number : str Attributes \u00a4 number : str pydantic-field required \u00a4 type : ConstrainedStrValue pydantic-field \u00a4 Indicates the type of phone number. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Test ( OscalBaseModel ) pydantic-model \u00a4 A test expression which is expected to be evaluated by a tool. Source code in trestle/oscal/common.py class Test ( OscalBaseModel ): \"\"\" A test expression which is expected to be evaluated by a tool. \"\"\" class Config : extra = Extra . forbid expression : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A formal (executable) expression of a constraint' , title = 'Constraint test' , ) remarks : Optional [ Remarks ] = None Attributes \u00a4 expression : ConstrainedStrValue pydantic-field required \u00a4 A formal (executable) expression of a constraint remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid ThreatId ( OscalBaseModel ) pydantic-model \u00a4 A pointer, by ID, to an externally-defined threat. Source code in trestle/oscal/common.py class ThreatId ( OscalBaseModel ): \"\"\" A pointer, by ID, to an externally-defined threat. \"\"\" class Config : extra = Extra . forbid system : AnyUrl = Field ( ... , description = 'Specifies the source of the threat information.' , title = 'Threat Type Identification System' , ) href : Optional [ str ] = Field ( None , description = 'An optional location for the threat data, from which this ID originates.' , title = 'Threat Information Resource Reference' , ) id : str Attributes \u00a4 href : str pydantic-field \u00a4 An optional location for the threat data, from which this ID originates. id : str pydantic-field required \u00a4 system : AnyUrl pydantic-field required \u00a4 Specifies the source of the threat information. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Timing ( OscalBaseModel ) pydantic-model \u00a4 The timing under which the task is intended to occur. Source code in trestle/oscal/common.py class Timing ( OscalBaseModel ): \"\"\" The timing under which the task is intended to occur. \"\"\" class Config : extra = Extra . forbid on_date : Optional [ OnDate ] = Field ( None , alias = 'on-date' , description = 'The task is intended to occur on the specified date.' , title = 'On Date Condition' , ) within_date_range : Optional [ WithinDateRange ] = Field ( None , alias = 'within-date-range' , description = 'The task is intended to occur within the specified date range.' , title = 'On Date Range Condition' , ) at_frequency : Optional [ AtFrequency ] = Field ( None , alias = 'at-frequency' , description = 'The task is intended to occur at the specified frequency.' , title = 'Frequency Condition' , ) Attributes \u00a4 at_frequency : AtFrequency pydantic-field \u00a4 The task is intended to occur at the specified frequency. on_date : OnDate pydantic-field \u00a4 The task is intended to occur on the specified date. within_date_range : WithinDateRange pydantic-field \u00a4 The task is intended to occur within the specified date range. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Transport ( Enum ) \u00a4 Indicates the transport type. Source code in trestle/oscal/common.py class Transport ( Enum ): \"\"\" Indicates the transport type. \"\"\" TCP = 'TCP' UDP = 'UDP' TCP \u00a4 UDP \u00a4 Type ( Enum ) \u00a4 A category describing the kind of party the object describes. Source code in trestle/oscal/common.py class Type ( Enum ): \"\"\" A category describing the kind of party the object describes. \"\"\" person = 'person' organization = 'organization' organization \u00a4 person \u00a4 Type1 ( Enum ) \u00a4 Identifies the type of the target. Source code in trestle/oscal/common.py class Type1 ( Enum ): \"\"\" Identifies the type of the target. \"\"\" statement_id = 'statement-id' objective_id = 'objective-id' objective_id \u00a4 statement_id \u00a4 Type2 ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/common.py class Type2 ( OscalBaseModel ): __root__ : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Identifies the nature of the observation. More than one may be used to further qualify and enable filtering.' , title = 'Observation Type' , ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 Identifies the nature of the observation. More than one may be used to further qualify and enable filtering. Type3 ( Enum ) \u00a4 The kind of actor. Source code in trestle/oscal/common.py class Type3 ( Enum ): \"\"\" The kind of actor. \"\"\" tool = 'tool' assessment_platform = 'assessment-platform' party = 'party' assessment_platform \u00a4 party \u00a4 tool \u00a4 Unit ( Enum ) \u00a4 The unit of time for the period. Source code in trestle/oscal/common.py class Unit ( Enum ): \"\"\" The unit of time for the period. \"\"\" seconds = 'seconds' minutes = 'minutes' hours = 'hours' days = 'days' months = 'months' years = 'years' days \u00a4 hours \u00a4 minutes \u00a4 months \u00a4 seconds \u00a4 years \u00a4 UsesComponent ( OscalBaseModel ) pydantic-model \u00a4 The set of components that are used by the assessment platform. Source code in trestle/oscal/common.py class UsesComponent ( OscalBaseModel ): \"\"\" The set of components that are used by the assessment platform. \"\"\" class Config : extra = Extra . forbid component_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'component-uuid' , description = 'A machine-oriented identifier reference to a component that is implemented as part of an inventory item.' , title = 'Component Universally Unique Identifier Reference' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) responsible_parties : Optional [ List [ ResponsibleParty ]] = Field ( None , alias = 'responsible-parties' ) remarks : Optional [ Remarks ] = None Attributes \u00a4 component_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to a component that is implemented as part of an inventory item. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_parties : List [ trestle . oscal . common . ResponsibleParty ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid Value ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/common.py class Value ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A parameter value or set of values.' , title = 'Parameter Value' ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 A parameter value or set of values. Version ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/common.py class Version ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A string used to distinguish the current version of the document from other previous (and future) versions.' , title = 'Document Version' , ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 A string used to distinguish the current version of the document from other previous (and future) versions. WithinDateRange ( OscalBaseModel ) pydantic-model \u00a4 The task is intended to occur within the specified date range. Source code in trestle/oscal/common.py class WithinDateRange ( OscalBaseModel ): \"\"\" The task is intended to occur within the specified date range. \"\"\" class Config : extra = Extra . forbid start : datetime = Field ( ... , description = 'The task must occur on or after the specified date.' , title = 'Start Date Condition' , ) end : datetime = Field ( ... , description = 'The task must occur on or before the specified date.' , title = 'End Date Condition' , ) Attributes \u00a4 end : datetime pydantic-field required \u00a4 The task must occur on or before the specified date. start : datetime pydantic-field required \u00a4 The task must occur on or after the specified date. Config \u00a4 Source code in trestle/oscal/common.py class Config : extra = Extra . forbid handler: python","title":"common"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common","text":"","title":"common"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AddrLine","text":"Source code in trestle/oscal/common.py class AddrLine ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A single line of an address.' , title = 'Address line' )","title":"AddrLine"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AddrLine-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AddrLine.__root__","text":"A single line of an address.","title":"__root__"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Address","text":"A postal address for the location. Source code in trestle/oscal/common.py class Address ( OscalBaseModel ): \"\"\" A postal address for the location. \"\"\" class Config : extra = Extra . forbid type : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , description = 'Indicates the type of address.' , title = 'Address Type' ) addr_lines : Optional [ List [ AddrLine ]] = Field ( None , alias = 'addr-lines' ) city : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , description = 'City, town or geographical region for the mailing address.' , title = 'City' , ) state : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , description = 'State, province or analogous geographical region for mailing address' , title = 'State' , ) postal_code : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , alias = 'postal-code' , description = 'Postal or ZIP code for mailing address' , title = 'Postal Code' , ) country : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , description = 'The ISO 3166-1 alpha-2 country code for the mailing address.' , title = 'Country Code' , )","title":"Address"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Address-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Address.addr_lines","text":"","title":"addr_lines"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Address.city","text":"City, town or geographical region for the mailing address.","title":"city"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Address.country","text":"The ISO 3166-1 alpha-2 country code for the mailing address.","title":"country"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Address.postal_code","text":"Postal or ZIP code for mailing address","title":"postal_code"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Address.state","text":"State, province or analogous geographical region for mailing address","title":"state"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Address.type","text":"Indicates the type of address.","title":"type"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Address.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentMethod","text":"A local definition of a control objective. Uses catalog syntax for control objective and assessment activities. Source code in trestle/oscal/common.py class AssessmentMethod ( OscalBaseModel ): \"\"\" A local definition of a control objective. Uses catalog syntax for control objective and assessment activities. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment method elsewhere in this or other OSCAL instances. The locally defined UUID of the assessment method can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Method Universally Unique Identifier' , ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of this assessment method.' , title = 'Assessment Method Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) part : AssessmentPart remarks : Optional [ Remarks ] = None","title":"AssessmentMethod"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentMethod-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentMethod.description","text":"A human-readable description of this assessment method.","title":"description"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentMethod.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentMethod.part","text":"","title":"part"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentMethod.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentMethod.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentMethod.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment method elsewhere in this or other OSCAL instances. The locally defined UUID of the assessment method can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentMethod.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPart","text":"A partition of an assessment plan or results or a child of another part. Source code in trestle/oscal/common.py class AssessmentPart ( OscalBaseModel ): \"\"\" A partition of an assessment plan or results or a child of another part. \"\"\" class Config : extra = Extra . forbid uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this part elsewhere in this or other OSCAL instances. The locally defined UUID of the part can be used to reference the data item locally or globally (e.g., in an ported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Part Identifier' , ) name : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = \"A textual label that uniquely identifies the part's semantic type.\" , title = 'Part Name' , ) ns : Optional [ AnyUrl ] = Field ( None , description = \"A namespace qualifying the part's name. This allows different organizations to associate distinct semantics with the same name.\" , title = 'Part Namespace' , ) class_ : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'class' , description = \"A textual label that provides a sub-type or characterization of the part's name. This can be used to further distinguish or discriminate between the semantics of multiple parts of the same control with the same name and ns.\" , title = 'Part Class' , ) title : Optional [ str ] = Field ( None , description = 'A name given to the part, which may be used by a tool for display and navigation.' , title = 'Part Title' , ) props : Optional [ List [ Property ]] = Field ( None ) prose : Optional [ str ] = Field ( None , description = 'Permits multiple paragraphs, lists, tables etc.' , title = 'Part Text' , ) parts : Optional [ List [ AssessmentPart ]] = None links : Optional [ List [ Link ]] = Field ( None )","title":"AssessmentPart"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPart-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPart.class_","text":"A textual label that provides a sub-type or characterization of the part's name. This can be used to further distinguish or discriminate between the semantics of multiple parts of the same control with the same name and ns.","title":"class_"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPart.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPart.name","text":"A textual label that uniquely identifies the part's semantic type.","title":"name"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPart.ns","text":"A namespace qualifying the part's name. This allows different organizations to associate distinct semantics with the same name.","title":"ns"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPart.parts","text":"","title":"parts"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPart.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPart.prose","text":"Permits multiple paragraphs, lists, tables etc.","title":"prose"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPart.title","text":"A name given to the part, which may be used by a tool for display and navigation.","title":"title"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPart.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this part elsewhere in this or other OSCAL instances. The locally defined UUID of the part can be used to reference the data item locally or globally (e.g., in an ported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPart.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPlatform","text":"Used to represent the toolset used to perform aspects of the assessment. Source code in trestle/oscal/common.py class AssessmentPlatform ( OscalBaseModel ): \"\"\" Used to represent the toolset used to perform aspects of the assessment. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment platform elsewhere in this or other OSCAL instances. The locally defined UUID of the assessment platform can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Platform Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title or name for the assessment platform.' , title = 'Assessment Platform Title' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) uses_components : Optional [ List [ UsesComponent ]] = Field ( None , alias = 'uses-components' ) remarks : Optional [ Remarks ] = None","title":"AssessmentPlatform"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPlatform-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPlatform.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPlatform.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPlatform.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPlatform.title","text":"The title or name for the assessment platform.","title":"title"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPlatform.uses_components","text":"","title":"uses_components"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPlatform.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment platform elsewhere in this or other OSCAL instances. The locally defined UUID of the assessment platform can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentPlatform.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubject","text":"Identifies system elements being assessed, such as components, inventory items, and locations. In the assessment plan, this identifies a planned assessment subject. In the assessment results this is an actual assessment subject, and reflects any changes from the plan. exactly what will be the focus of this assessment. Any subjects not identified in this way are out-of-scope. Source code in trestle/oscal/common.py class AssessmentSubject ( OscalBaseModel ): \"\"\" Identifies system elements being assessed, such as components, inventory items, and locations. In the assessment plan, this identifies a planned assessment subject. In the assessment results this is an actual assessment subject, and reflects any changes from the plan. exactly what will be the focus of this assessment. Any subjects not identified in this way are out-of-scope. \"\"\" class Config : extra = Extra . forbid type : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Indicates the type of assessment subject, such as a component, inventory, item, location, or party represented by this selection statement.' , title = 'Subject Type' , ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of the collection of subjects being included in this assessment.' , title = 'Include Subjects Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) include_all : Optional [ IncludeAll ] = Field ( None , alias = 'include-all' ) include_subjects : Optional [ List [ SelectSubjectById ]] = Field ( None , alias = 'include-subjects' ) exclude_subjects : Optional [ List [ SelectSubjectById ]] = Field ( None , alias = 'exclude-subjects' ) remarks : Optional [ Remarks ] = None","title":"AssessmentSubject"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubject-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubject.description","text":"A human-readable description of the collection of subjects being included in this assessment.","title":"description"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubject.exclude_subjects","text":"","title":"exclude_subjects"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubject.include_all","text":"","title":"include_all"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubject.include_subjects","text":"","title":"include_subjects"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubject.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubject.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubject.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubject.type","text":"Indicates the type of assessment subject, such as a component, inventory, item, location, or party represented by this selection statement.","title":"type"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubject.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubjectPlaceholder","text":"Used when the assessment subjects will be determined as part of one or more other assessment activities. These assessment subjects will be recorded in the assessment results in the assessment log. Source code in trestle/oscal/common.py class AssessmentSubjectPlaceholder ( OscalBaseModel ): \"\"\" Used when the assessment subjects will be determined as part of one or more other assessment activities. These assessment subjects will be recorded in the assessment results in the assessment log. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier for a set of assessment subjects that will be identified by a task or an activity that is part of a task. The locally defined UUID of the assessment subject placeholder can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Subject Placeholder Universally Unique Identifier' , ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of intent of this assessment subject placeholder.' , title = 'Assessment Subject Placeholder Description' , ) sources : List [ Source ] = Field ( ... ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None","title":"AssessmentSubjectPlaceholder"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubjectPlaceholder-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubjectPlaceholder.description","text":"A human-readable description of intent of this assessment subject placeholder.","title":"description"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubjectPlaceholder.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubjectPlaceholder.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubjectPlaceholder.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubjectPlaceholder.sources","text":"","title":"sources"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubjectPlaceholder.uuid","text":"A machine-oriented, globally unique identifier for a set of assessment subjects that will be identified by a task or an activity that is part of a task. The locally defined UUID of the assessment subject placeholder can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssessmentSubjectPlaceholder.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssociatedActivity","text":"Identifies an individual activity to be performed as part of a task. Source code in trestle/oscal/common.py class AssociatedActivity ( OscalBaseModel ): \"\"\" Identifies an individual activity to be performed as part of a task. \"\"\" class Config : extra = Extra . forbid activity_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'activity-uuid' , description = 'A machine-oriented identifier reference to an activity defined in the list of activities.' , title = 'Activity Universally Unique Identifier Reference' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) responsible_roles : Optional [ List [ ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) subjects : List [ AssessmentSubject ] = Field ( ... ) remarks : Optional [ Remarks ] = None","title":"AssociatedActivity"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssociatedActivity-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssociatedActivity.activity_uuid","text":"A machine-oriented identifier reference to an activity defined in the list of activities.","title":"activity_uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssociatedActivity.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssociatedActivity.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssociatedActivity.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssociatedActivity.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssociatedActivity.subjects","text":"","title":"subjects"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AssociatedActivity.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AtFrequency","text":"The task is intended to occur at the specified frequency. Source code in trestle/oscal/common.py class AtFrequency ( OscalBaseModel ): \"\"\" The task is intended to occur at the specified frequency. \"\"\" class Config : extra = Extra . forbid period : conint ( ge = 1 , multiple_of = 1 ) = Field ( ... , description = 'The task must occur after the specified period has elapsed.' , title = 'Period' , ) unit : Unit = Field ( ... , description = 'The unit of time for the period.' , title = 'Time Unit' )","title":"AtFrequency"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AtFrequency-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AtFrequency.period","text":"The task must occur after the specified period has elapsed.","title":"period"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AtFrequency.unit","text":"The unit of time for the period.","title":"unit"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AtFrequency.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AuthorizedPrivilege","text":"Identifies a specific system privilege held by the user, along with an associated description and/or rationale for the privilege. Source code in trestle/oscal/common.py class AuthorizedPrivilege ( OscalBaseModel ): \"\"\" Identifies a specific system privilege held by the user, along with an associated description and/or rationale for the privilege. \"\"\" class Config : extra = Extra . forbid title : str = Field ( ... , description = 'A human readable name for the privilege.' , title = 'Privilege Title' , ) description : Optional [ str ] = Field ( None , description = \"A summary of the privilege's purpose within the system.\" , title = 'Privilege Description' , ) functions_performed : List [ FunctionPerformed ] = Field ( ... , alias = 'functions-performed' )","title":"AuthorizedPrivilege"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AuthorizedPrivilege-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AuthorizedPrivilege.description","text":"A summary of the privilege's purpose within the system.","title":"description"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AuthorizedPrivilege.functions_performed","text":"","title":"functions_performed"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AuthorizedPrivilege.title","text":"A human readable name for the privilege.","title":"title"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.AuthorizedPrivilege.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.BackMatter","text":"A collection of resources, which may be included directly or by reference. Source code in trestle/oscal/common.py class BackMatter ( OscalBaseModel ): \"\"\" A collection of resources, which may be included directly or by reference. \"\"\" class Config : extra = Extra . forbid resources : Optional [ List [ Resource ]] = Field ( None )","title":"BackMatter"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.BackMatter.resources","text":"","title":"resources"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.BackMatter.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Base64","text":"The Base64 alphabet in RFC 2045 - aligned with XSD. Source code in trestle/oscal/common.py class Base64 ( OscalBaseModel ): \"\"\" The Base64 alphabet in RFC 2045 - aligned with XSD. \"\"\" class Config : extra = Extra . forbid filename : Optional [ str ] = Field ( None , description = 'Name of the file before it was encoded as Base64 to be embedded in a resource. This is the name that will be assigned to the file when the file is decoded.' , title = 'File Name' , ) media_type : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , alias = 'media-type' , description = 'Specifies a media type as defined by the Internet Assigned Numbers Authority (IANA) Media Types Registry.' , title = 'Media Type' , ) value : str","title":"Base64"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Base64-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Base64.filename","text":"Name of the file before it was encoded as Base64 to be embedded in a resource. This is the name that will be assigned to the file when the file is decoded.","title":"filename"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Base64.media_type","text":"Specifies a media type as defined by the Internet Assigned Numbers Authority (IANA) Media Types Registry.","title":"media_type"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Base64.value","text":"","title":"value"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Base64.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Citation","text":"A citation consisting of end note text and optional structured bibliographic data. Source code in trestle/oscal/common.py class Citation ( OscalBaseModel ): \"\"\" A citation consisting of end note text and optional structured bibliographic data. \"\"\" class Config : extra = Extra . forbid text : str = Field ( ... , description = 'A line of citation text.' , title = 'Citation Text' ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None )","title":"Citation"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Citation-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Citation.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Citation.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Citation.text","text":"A line of citation text.","title":"text"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Citation.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ControlObjectiveSelection","text":"Identifies the control objectives of the assessment. In the assessment plan, these are the planned objectives. In the assessment results, these are the assessed objectives, and reflects any changes from the plan. Source code in trestle/oscal/common.py class ControlObjectiveSelection ( OscalBaseModel ): \"\"\" Identifies the control objectives of the assessment. In the assessment plan, these are the planned objectives. In the assessment results, these are the assessed objectives, and reflects any changes from the plan. \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'A human-readable description of this collection of control objectives.' , title = 'Control Objectives Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) include_all : Optional [ IncludeAll ] = Field ( None , alias = 'include-all' ) include_objectives : Optional [ List [ SelectObjectiveById ]] = Field ( None , alias = 'include-objectives' ) exclude_objectives : Optional [ List [ SelectObjectiveById ]] = Field ( None , alias = 'exclude-objectives' ) remarks : Optional [ Remarks ] = None","title":"ControlObjectiveSelection"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ControlObjectiveSelection-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ControlObjectiveSelection.description","text":"A human-readable description of this collection of control objectives.","title":"description"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ControlObjectiveSelection.exclude_objectives","text":"","title":"exclude_objectives"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ControlObjectiveSelection.include_all","text":"","title":"include_all"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ControlObjectiveSelection.include_objectives","text":"","title":"include_objectives"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ControlObjectiveSelection.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ControlObjectiveSelection.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ControlObjectiveSelection.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ControlObjectiveSelection.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Dependency","text":"Used to indicate that a task is dependent on another task. Source code in trestle/oscal/common.py class Dependency ( OscalBaseModel ): \"\"\" Used to indicate that a task is dependent on another task. \"\"\" class Config : extra = Extra . forbid task_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'task-uuid' , description = 'A machine-oriented identifier reference to a unique task.' , title = 'Task Universally Unique Identifier Reference' , ) remarks : Optional [ Remarks ] = None","title":"Dependency"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Dependency-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Dependency.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Dependency.task_uuid","text":"A machine-oriented identifier reference to a unique task.","title":"task_uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Dependency.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.DocumentId","text":"A document identifier qualified by an identifier scheme. A document identifier provides a globally unique identifier with a cross-instance scope that is used for a group of documents that are to be treated as different versions of the same document. If this element does not appear, or if the value of this element is empty, the value of \"document-id\" is equal to the value of the \"uuid\" flag of the top-level root element. Source code in trestle/oscal/common.py class DocumentId ( OscalBaseModel ): \"\"\" A document identifier qualified by an identifier scheme. A document identifier provides a globally unique identifier with a cross-instance scope that is used for a group of documents that are to be treated as different versions of the same document. If this element does not appear, or if the value of this element is empty, the value of \"document-id\" is equal to the value of the \"uuid\" flag of the top-level root element. \"\"\" class Config : extra = Extra . forbid scheme : Optional [ AnyUrl ] = Field ( None , description = 'Qualifies the kind of document identifier using a URI. If the scheme is not provided the value of the element will be interpreted as a string of characters.' , title = 'Document Identification Scheme' , ) identifier : str","title":"DocumentId"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.DocumentId-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.DocumentId.identifier","text":"","title":"identifier"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.DocumentId.scheme","text":"Qualifies the kind of document identifier using a URI. If the scheme is not provided the value of the element will be interpreted as a string of characters.","title":"scheme"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.DocumentId.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.EmailAddress","text":"Source code in trestle/oscal/common.py class EmailAddress ( OscalBaseModel ): __root__ : EmailStr = Field ( ... , description = 'An email address as defined by RFC 5322 Section 3.4.1.' , title = 'Email Address' , )","title":"EmailAddress"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.EmailAddress-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.EmailAddress.__root__","text":"An email address as defined by RFC 5322 Section 3.4.1.","title":"__root__"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ExternalId","text":"An identifier for a person or organization using a designated scheme. e.g. an Open Researcher and Contributor ID (ORCID) Source code in trestle/oscal/common.py class ExternalId ( OscalBaseModel ): \"\"\" An identifier for a person or organization using a designated scheme. e.g. an Open Researcher and Contributor ID (ORCID) \"\"\" class Config : extra = Extra . forbid scheme : AnyUrl = Field ( ... , description = 'Indicates the type of external identifier.' , title = 'External Identifier Schema' , ) id : str","title":"ExternalId"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ExternalId-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ExternalId.id","text":"","title":"id"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ExternalId.scheme","text":"Indicates the type of external identifier.","title":"scheme"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ExternalId.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Facet","text":"An individual characteristic that is part of a larger set produced by the same actor. Source code in trestle/oscal/common.py class Facet ( OscalBaseModel ): \"\"\" An individual characteristic that is part of a larger set produced by the same actor. \"\"\" class Config : extra = Extra . forbid name : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'The name of the risk metric within the specified system.' , title = 'Facet Name' , ) system : AnyUrl = Field ( ... , description = 'Specifies the naming system under which this risk metric is organized, which allows for the same names to be used in different systems controlled by different parties. This avoids the potential of a name clash.' , title = 'Naming System' , ) value : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'Indicates the value of the facet.' , title = 'Facet Value' ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None","title":"Facet"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Facet-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Facet.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Facet.name","text":"The name of the risk metric within the specified system.","title":"name"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Facet.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Facet.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Facet.system","text":"Specifies the naming system under which this risk metric is organized, which allows for the same names to be used in different systems controlled by different parties. This avoids the potential of a name clash.","title":"system"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Facet.value","text":"Indicates the value of the facet.","title":"value"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Facet.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.FunctionPerformed","text":"Source code in trestle/oscal/common.py class FunctionPerformed ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'Describes a function performed for a given authorized privilege by this user class.' , title = 'Functions Performed' , )","title":"FunctionPerformed"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.FunctionPerformed-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.FunctionPerformed.__root__","text":"Describes a function performed for a given authorized privilege by this user class.","title":"__root__"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Hash","text":"A representation of a cryptographic digest generated over a resource using a specified hash algorithm. Source code in trestle/oscal/common.py class Hash ( OscalBaseModel ): \"\"\" A representation of a cryptographic digest generated over a resource using a specified hash algorithm. \"\"\" class Config : extra = Extra . forbid algorithm : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'Method by which a hash is derived' , title = 'Hash algorithm' ) value : str","title":"Hash"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Hash-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Hash.algorithm","text":"Method by which a hash is derived","title":"algorithm"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Hash.value","text":"","title":"value"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Hash.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.HowMany","text":"Describes the number of selections that must occur. Without this setting, only one value should be assumed to be permitted. Source code in trestle/oscal/common.py class HowMany ( Enum ): \"\"\" Describes the number of selections that must occur. Without this setting, only one value should be assumed to be permitted. \"\"\" one = 'one' one_or_more = 'one-or-more'","title":"HowMany"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.HowMany.one","text":"","title":"one"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.HowMany.one_or_more","text":"","title":"one_or_more"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.IdentifiedSubject","text":"Used to detail assessment subjects that were identfied by this task. Source code in trestle/oscal/common.py class IdentifiedSubject ( OscalBaseModel ): \"\"\" Used to detail assessment subjects that were identfied by this task. \"\"\" class Config : extra = Extra . forbid subject_placeholder_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'subject-placeholder-uuid' , description = 'A machine-oriented identifier reference to a unique assessment subject placeholder defined by this task.' , title = 'Assessment Subject Placeholder Universally Unique Identifier Reference' , ) subjects : List [ AssessmentSubject ] = Field ( ... )","title":"IdentifiedSubject"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.IdentifiedSubject-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.IdentifiedSubject.subject_placeholder_uuid","text":"A machine-oriented identifier reference to a unique assessment subject placeholder defined by this task.","title":"subject_placeholder_uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.IdentifiedSubject.subjects","text":"","title":"subjects"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.IdentifiedSubject.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImplementationStatus","text":"Indicates the degree to which the a given control is implemented. Source code in trestle/oscal/common.py class ImplementationStatus ( OscalBaseModel ): \"\"\" Indicates the degree to which the a given control is implemented. \"\"\" class Config : extra = Extra . forbid state : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Identifies the implementation status of the control or control objective.' , title = 'Implementation State' , ) remarks : Optional [ Remarks ] = None","title":"ImplementationStatus"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImplementationStatus-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImplementationStatus.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImplementationStatus.state","text":"Identifies the implementation status of the control or control objective.","title":"state"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImplementationStatus.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImplementedComponent","text":"The set of components that are implemented in a given system inventory item. Source code in trestle/oscal/common.py class ImplementedComponent ( OscalBaseModel ): \"\"\" The set of components that are implemented in a given system inventory item. \"\"\" class Config : extra = Extra . forbid component_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'component-uuid' , description = 'A machine-oriented identifier reference to a component that is implemented as part of an inventory item.' , title = 'Component Universally Unique Identifier Reference' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) responsible_parties : Optional [ List [ ResponsibleParty ]] = Field ( None , alias = 'responsible-parties' ) remarks : Optional [ Remarks ] = None","title":"ImplementedComponent"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImplementedComponent-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImplementedComponent.component_uuid","text":"A machine-oriented identifier reference to a component that is implemented as part of an inventory item.","title":"component_uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImplementedComponent.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImplementedComponent.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImplementedComponent.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImplementedComponent.responsible_parties","text":"","title":"responsible_parties"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImplementedComponent.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImportSsp","text":"Used by the assessment plan and POA&M to import information about the system. Source code in trestle/oscal/common.py class ImportSsp ( OscalBaseModel ): \"\"\" Used by the assessment plan and POA&M to import information about the system. \"\"\" class Config : extra = Extra . forbid href : str = Field ( ... , description = 'A resolvable URL reference to the system security plan for the system being assessed.' , title = 'System Security Plan Reference' , ) remarks : Optional [ Remarks ] = None","title":"ImportSsp"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImportSsp-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImportSsp.href","text":"A resolvable URL reference to the system security plan for the system being assessed.","title":"href"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImportSsp.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ImportSsp.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.IncludeAll","text":"Include all controls from the imported catalog or profile resources. Source code in trestle/oscal/common.py class IncludeAll ( OscalBaseModel ): \"\"\" Include all controls from the imported catalog or profile resources. \"\"\" pass class Config : extra = Extra . forbid","title":"IncludeAll"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.IncludeAll.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.InventoryItem","text":"A single managed inventory item within the system. Source code in trestle/oscal/common.py class InventoryItem ( OscalBaseModel ): \"\"\" A single managed inventory item within the system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this inventory item elsewhere in this or other OSCAL instances. The locally defined UUID of the inventory item can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Inventory Item Universally Unique Identifier' , ) description : str = Field ( ... , description = 'A summary of the inventory item stating its purpose within the system.' , title = 'Inventory Item Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) responsible_parties : Optional [ List [ ResponsibleParty ]] = Field ( None , alias = 'responsible-parties' ) implemented_components : Optional [ List [ ImplementedComponent ]] = Field ( None , alias = 'implemented-components' ) remarks : Optional [ Remarks ] = None","title":"InventoryItem"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.InventoryItem-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.InventoryItem.description","text":"A summary of the inventory item stating its purpose within the system.","title":"description"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.InventoryItem.implemented_components","text":"","title":"implemented_components"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.InventoryItem.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.InventoryItem.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.InventoryItem.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.InventoryItem.responsible_parties","text":"","title":"responsible_parties"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.InventoryItem.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this inventory item elsewhere in this or other OSCAL instances. The locally defined UUID of the inventory item can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.InventoryItem.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LastModified","text":"Source code in trestle/oscal/common.py class LastModified ( OscalBaseModel ): __root__ : datetime = Field ( ... , description = 'The date and time the document was last modified. The date-time value must be formatted according to RFC 3339 with full time and time zone included.' , title = 'Last Modified Timestamp' , )","title":"LastModified"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LastModified-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LastModified.__root__","text":"The date and time the document was last modified. The date-time value must be formatted according to RFC 3339 with full time and time zone included.","title":"__root__"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Link","text":"A reference to a local or remote resource Source code in trestle/oscal/common.py class Link ( OscalBaseModel ): \"\"\" A reference to a local or remote resource \"\"\" class Config : extra = Extra . forbid href : str = Field ( ... , description = 'A resolvable URL reference to a resource.' , title = 'Hypertext Reference' , ) rel : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , description = \"Describes the type of relationship provided by the link. This can be an indicator of the link's purpose.\" , title = 'Relation' , ) media_type : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , alias = 'media-type' , description = 'Specifies a media type as defined by the Internet Assigned Numbers Authority (IANA) Media Types Registry.' , title = 'Media Type' , ) text : Optional [ str ] = Field ( None , description = 'A textual label to associate with the link, which may be used for presentation in a tool.' , title = 'Link Text' , )","title":"Link"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Link-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Link.href","text":"A resolvable URL reference to a resource.","title":"href"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Link.media_type","text":"Specifies a media type as defined by the Internet Assigned Numbers Authority (IANA) Media Types Registry.","title":"media_type"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Link.rel","text":"Describes the type of relationship provided by the link. This can be an indicator of the link's purpose.","title":"rel"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Link.text","text":"A textual label to associate with the link, which may be used for presentation in a tool.","title":"text"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Link.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LocalObjective","text":"A local definition of a control objective for this assessment. Uses catalog syntax for control objective and assessment actions. Source code in trestle/oscal/common.py class LocalObjective ( OscalBaseModel ): \"\"\" A local definition of a control objective for this assessment. Uses catalog syntax for control objective and assessment actions. \"\"\" class Config : extra = Extra . forbid control_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'control-id' , description = 'A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).' , title = 'Control Identifier Reference' , ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of this control objective.' , title = 'Objective Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) parts : List [ Part ] = Field ( ... ) remarks : Optional [ Remarks ] = None","title":"LocalObjective"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LocalObjective-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LocalObjective.control_id","text":"A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).","title":"control_id"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LocalObjective.description","text":"A human-readable description of this control objective.","title":"description"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LocalObjective.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LocalObjective.parts","text":"","title":"parts"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LocalObjective.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LocalObjective.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LocalObjective.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Location","text":"A location, with associated metadata that can be referenced. Source code in trestle/oscal/common.py class Location ( OscalBaseModel ): \"\"\" A location, with associated metadata that can be referenced. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this defined location elsewhere in this or other OSCAL instances. The locally defined UUID of the location can be used to reference the data item locally or globally (e.g., from an importing OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Location Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'A name given to the location, which may be used by a tool for display and navigation.' , title = 'Location Title' , ) address : Address email_addresses : Optional [ List [ EmailAddress ]] = Field ( None , alias = 'email-addresses' ) telephone_numbers : Optional [ List [ TelephoneNumber ]] = Field ( None , alias = 'telephone-numbers' ) urls : Optional [ List [ AnyUrl ]] = Field ( None ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None","title":"Location"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Location-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Location.address","text":"","title":"address"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Location.email_addresses","text":"","title":"email_addresses"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Location.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Location.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Location.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Location.telephone_numbers","text":"","title":"telephone_numbers"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Location.title","text":"A name given to the location, which may be used by a tool for display and navigation.","title":"title"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Location.urls","text":"","title":"urls"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Location.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this defined location elsewhere in this or other OSCAL instances. The locally defined UUID of the location can be used to reference the data item locally or globally (e.g., from an importing OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Location.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LocationUuid","text":"Source code in trestle/oscal/common.py class LocationUuid ( OscalBaseModel ): __root__ : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented identifier reference to a location defined in the metadata section of this or another OSCAL instance. The UUID of the location in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance).' , title = 'Location Reference' , )","title":"LocationUuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LocationUuid-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LocationUuid.__root__","text":"A machine-oriented identifier reference to a location defined in the metadata section of this or another OSCAL instance. The UUID of the location in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance).","title":"__root__"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LoggedBy","text":"Used to indicate who created a log entry in what role. Source code in trestle/oscal/common.py class LoggedBy ( OscalBaseModel ): \"\"\" Used to indicate who created a log entry in what role. \"\"\" class Config : extra = Extra . forbid party_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'party-uuid' , description = 'A machine-oriented identifier reference to the party who is making the log entry.' , title = 'Party UUID Reference' , ) role_id : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'role-id' , description = 'A point to the role-id of the role in which the party is making the log entry.' , title = 'Actor Role' , )","title":"LoggedBy"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LoggedBy-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LoggedBy.party_uuid","text":"A machine-oriented identifier reference to the party who is making the log entry.","title":"party_uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LoggedBy.role_id","text":"A point to the role-id of the role in which the party is making the log entry.","title":"role_id"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.LoggedBy.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.MemberOfOrganization","text":"Source code in trestle/oscal/common.py class MemberOfOrganization ( OscalBaseModel ): __root__ : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented identifier reference to another party (person or organization) that this subject is associated with. The UUID of the party in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance).' , title = 'Organizational Affiliation' , )","title":"MemberOfOrganization"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.MemberOfOrganization-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.MemberOfOrganization.__root__","text":"A machine-oriented identifier reference to another party (person or organization) that this subject is associated with. The UUID of the party in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance).","title":"__root__"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Metadata","text":"Provides information about the publication and availability of the containing document. Source code in trestle/oscal/common.py class Metadata ( OscalBaseModel ): \"\"\" Provides information about the publication and availability of the containing document. \"\"\" class Config : extra = Extra . forbid title : str = Field ( ... , description = 'A name given to the document, which may be used by a tool for display and navigation.' , title = 'Document Title' , ) published : Optional [ Published ] = None last_modified : LastModified = Field ( ... , alias = 'last-modified' ) version : Version oscal_version : OscalVersion = Field ( ... , alias = 'oscal-version' ) revisions : Optional [ List [ Revision ]] = Field ( None ) document_ids : Optional [ List [ DocumentId ]] = Field ( None , alias = 'document-ids' ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) roles : Optional [ List [ Role ]] = Field ( None ) locations : Optional [ List [ Location ]] = Field ( None ) parties : Optional [ List [ Party ]] = Field ( None ) responsible_parties : Optional [ List [ ResponsibleParty ]] = Field ( None , alias = 'responsible-parties' ) remarks : Optional [ Remarks ] = None","title":"Metadata"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Metadata-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Metadata.document_ids","text":"","title":"document_ids"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Metadata.last_modified","text":"","title":"last_modified"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Metadata.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Metadata.locations","text":"","title":"locations"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Metadata.oscal_version","text":"","title":"oscal_version"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Metadata.parties","text":"","title":"parties"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Metadata.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Metadata.published","text":"","title":"published"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Metadata.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Metadata.responsible_parties","text":"","title":"responsible_parties"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Metadata.revisions","text":"","title":"revisions"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Metadata.roles","text":"","title":"roles"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Metadata.title","text":"A name given to the document, which may be used by a tool for display and navigation.","title":"title"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Metadata.version","text":"","title":"version"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Metadata.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.MitigatingFactor","text":"Describes an existing mitigating factor that may affect the overall determination of the risk, with an optional link to an implementation statement in the SSP. Source code in trestle/oscal/common.py class MitigatingFactor ( OscalBaseModel ): \"\"\" Describes an existing mitigating factor that may affect the overall determination of the risk, with an optional link to an implementation statement in the SSP. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this mitigating factor elsewhere in this or other OSCAL instances. The locally defined UUID of the mitigating factor can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Mitigating Factor Universally Unique Identifier' , ) implementation_uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , alias = 'implementation-uuid' , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this implementation statement elsewhere in this or other OSCAL instancess. The locally defined UUID of the implementation statement can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Implementation UUID' , ) description : str = Field ( ... , description = 'A human-readable description of this mitigating factor.' , title = 'Mitigating Factor Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) subjects : Optional [ List [ SubjectReference ]] = Field ( None )","title":"MitigatingFactor"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.MitigatingFactor-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.MitigatingFactor.description","text":"A human-readable description of this mitigating factor.","title":"description"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.MitigatingFactor.implementation_uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this implementation statement elsewhere in this or other OSCAL instancess. The locally defined UUID of the implementation statement can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"implementation_uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.MitigatingFactor.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.MitigatingFactor.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.MitigatingFactor.subjects","text":"","title":"subjects"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.MitigatingFactor.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this mitigating factor elsewhere in this or other OSCAL instances. The locally defined UUID of the mitigating factor can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.MitigatingFactor.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.OnDate","text":"The task is intended to occur on the specified date. Source code in trestle/oscal/common.py class OnDate ( OscalBaseModel ): \"\"\" The task is intended to occur on the specified date. \"\"\" class Config : extra = Extra . forbid date : datetime = Field ( ... , description = 'The task must occur on the specified date.' , title = 'On Date Condition' , )","title":"OnDate"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.OnDate-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.OnDate.date","text":"The task must occur on the specified date.","title":"date"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.OnDate.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.OriginActor","text":"The actor that produces an observation, a finding, or a risk. One or more actor type can be used to specify a person that is using a tool. Source code in trestle/oscal/common.py class OriginActor ( OscalBaseModel ): \"\"\" The actor that produces an observation, a finding, or a risk. One or more actor type can be used to specify a person that is using a tool. \"\"\" class Config : extra = Extra . forbid type : Type3 = Field ( ... , description = 'The kind of actor.' , title = 'Actor Type' ) actor_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'actor-uuid' , description = 'A machine-oriented identifier reference to the tool or person based on the associated type.' , title = 'Actor Universally Unique Identifier Reference' , ) role_id : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'role-id' , description = 'For a party, this can optionally be used to specify the role the actor was performing.' , title = 'Actor Role' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None )","title":"OriginActor"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.OriginActor-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.OriginActor.actor_uuid","text":"A machine-oriented identifier reference to the tool or person based on the associated type.","title":"actor_uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.OriginActor.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.OriginActor.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.OriginActor.role_id","text":"For a party, this can optionally be used to specify the role the actor was performing.","title":"role_id"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.OriginActor.type","text":"The kind of actor.","title":"type"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.OriginActor.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.OscalVersion","text":"Source code in trestle/oscal/common.py class OscalVersion ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'The OSCAL model version the document was authored against.' , title = 'OSCAL version' , ) @validator ( '__root__' ) def oscal_version_is_valid ( cls , v ): p = re . compile ( OSCAL_VERSION_REGEX ) matched = p . match ( v ) if matched is None : raise ValueError ( f 'OSCAL version: { v } is not supported, use { OSCAL_VERSION } instead.' ) return v","title":"OscalVersion"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.OscalVersion-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.OscalVersion.__root__","text":"The OSCAL model version the document was authored against.","title":"__root__"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.OscalVersion.oscal_version_is_valid","text":"Source code in trestle/oscal/common.py @validator ( '__root__' ) def oscal_version_is_valid ( cls , v ): p = re . compile ( OSCAL_VERSION_REGEX ) matched = p . match ( v ) if matched is None : raise ValueError ( f 'OSCAL version: { v } is not supported, use { OSCAL_VERSION } instead.' ) return v","title":"oscal_version_is_valid()"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Parameter","text":"Parameters provide a mechanism for the dynamic assignment of value(s) in a control. Source code in trestle/oscal/common.py class Parameter ( OscalBaseModel ): \"\"\" Parameters provide a mechanism for the dynamic assignment of value(s) in a control. \"\"\" class Config : extra = Extra . forbid id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined parameter elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, this identifier must be referenced in the context of the containing resource (e.g., import-profile). This id should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Parameter Identifier' , ) class_ : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'class' , description = 'A textual label that provides a characterization of the parameter.' , title = 'Parameter Class' , ) depends_on : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'depends-on' , description = '**(deprecated)** Another parameter invoking this one. This construct has been deprecated and should not be used.' , title = 'Depends on' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) label : Optional [ str ] = Field ( None , description = 'A short, placeholder name for the parameter, which can be used as a substitute for a value if no value is assigned.' , title = 'Parameter Label' , ) usage : Optional [ str ] = Field ( None , description = 'Describes the purpose and use of a parameter' , title = 'Parameter Usage Description' , ) constraints : Optional [ List [ ParameterConstraint ]] = Field ( None ) guidelines : Optional [ List [ ParameterGuideline ]] = Field ( None ) values : Optional [ List [ ParameterValue ]] = Field ( None ) select : Optional [ ParameterSelection ] = None remarks : Optional [ Remarks ] = None","title":"Parameter"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Parameter-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Parameter.class_","text":"A textual label that provides a characterization of the parameter.","title":"class_"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Parameter.constraints","text":"","title":"constraints"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Parameter.depends_on","text":"(deprecated) Another parameter invoking this one. This construct has been deprecated and should not be used.","title":"depends_on"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Parameter.guidelines","text":"","title":"guidelines"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Parameter.id","text":"A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined parameter elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, this identifier must be referenced in the context of the containing resource (e.g., import-profile). This id should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"id"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Parameter.label","text":"A short, placeholder name for the parameter, which can be used as a substitute for a value if no value is assigned.","title":"label"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Parameter.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Parameter.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Parameter.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Parameter.select","text":"","title":"select"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Parameter.usage","text":"Describes the purpose and use of a parameter","title":"usage"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Parameter.values","text":"","title":"values"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Parameter.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ParameterConstraint","text":"A formal or informal expression of a constraint or test Source code in trestle/oscal/common.py class ParameterConstraint ( OscalBaseModel ): \"\"\" A formal or informal expression of a constraint or test \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'A textual summary of the constraint to be applied.' , title = 'Constraint Description' , ) tests : Optional [ List [ Test ]] = Field ( None )","title":"ParameterConstraint"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ParameterConstraint-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ParameterConstraint.description","text":"A textual summary of the constraint to be applied.","title":"description"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ParameterConstraint.tests","text":"","title":"tests"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ParameterConstraint.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ParameterGuideline","text":"A prose statement that provides a recommendation for the use of a parameter. Source code in trestle/oscal/common.py class ParameterGuideline ( OscalBaseModel ): \"\"\" A prose statement that provides a recommendation for the use of a parameter. \"\"\" class Config : extra = Extra . forbid prose : str = Field ( ... , description = 'Prose permits multiple paragraphs, lists, tables etc.' , title = 'Guideline Text' , )","title":"ParameterGuideline"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ParameterGuideline-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ParameterGuideline.prose","text":"Prose permits multiple paragraphs, lists, tables etc.","title":"prose"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ParameterGuideline.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ParameterSelection","text":"Presenting a choice among alternatives Source code in trestle/oscal/common.py class ParameterSelection ( OscalBaseModel ): \"\"\" Presenting a choice among alternatives \"\"\" class Config : extra = Extra . forbid how_many : Optional [ HowMany ] = Field ( None , alias = 'how-many' , description = 'Describes the number of selections that must occur. Without this setting, only one value should be assumed to be permitted.' , title = 'Parameter Cardinality' , ) choice : Optional [ List [ str ]] = Field ( None )","title":"ParameterSelection"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ParameterSelection-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ParameterSelection.choice","text":"","title":"choice"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ParameterSelection.how_many","text":"Describes the number of selections that must occur. Without this setting, only one value should be assumed to be permitted.","title":"how_many"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ParameterSelection.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ParameterValue","text":"Source code in trestle/oscal/common.py class ParameterValue ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A parameter value or set of values.' , title = 'Parameter Value' )","title":"ParameterValue"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ParameterValue-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ParameterValue.__root__","text":"A parameter value or set of values.","title":"__root__"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Part","text":"A partition of a control's definition or a child of another part. Source code in trestle/oscal/common.py class Part ( OscalBaseModel ): \"\"\" A partition of a control's definition or a child of another part. \"\"\" class Config : extra = Extra . forbid id : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , description = 'A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined part elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, this identifier must be referenced in the context of the containing resource (e.g., import-profile). This id should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Part Identifier' , ) name : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = \"A textual label that uniquely identifies the part's semantic type.\" , title = 'Part Name' , ) ns : Optional [ AnyUrl ] = Field ( None , description = \"A namespace qualifying the part's name. This allows different organizations to associate distinct semantics with the same name.\" , title = 'Part Namespace' , ) class_ : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'class' , description = \"A textual label that provides a sub-type or characterization of the part's name. This can be used to further distinguish or discriminate between the semantics of multiple parts of the same control with the same name and ns.\" , title = 'Part Class' , ) title : Optional [ str ] = Field ( None , description = 'A name given to the part, which may be used by a tool for display and navigation.' , title = 'Part Title' , ) props : Optional [ List [ Property ]] = Field ( None ) prose : Optional [ str ] = Field ( None , description = 'Permits multiple paragraphs, lists, tables etc.' , title = 'Part Text' , ) parts : Optional [ List [ Part ]] = None links : Optional [ List [ Link ]] = Field ( None )","title":"Part"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Part-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Part.class_","text":"A textual label that provides a sub-type or characterization of the part's name. This can be used to further distinguish or discriminate between the semantics of multiple parts of the same control with the same name and ns.","title":"class_"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Part.id","text":"A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined part elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, this identifier must be referenced in the context of the containing resource (e.g., import-profile). This id should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"id"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Part.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Part.name","text":"A textual label that uniquely identifies the part's semantic type.","title":"name"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Part.ns","text":"A namespace qualifying the part's name. This allows different organizations to associate distinct semantics with the same name.","title":"ns"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Part.parts","text":"","title":"parts"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Part.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Part.prose","text":"Permits multiple paragraphs, lists, tables etc.","title":"prose"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Part.title","text":"A name given to the part, which may be used by a tool for display and navigation.","title":"title"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Part.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Party","text":"A responsible entity which is either a person or an organization. Source code in trestle/oscal/common.py class Party ( OscalBaseModel ): \"\"\" A responsible entity which is either a person or an organization. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this defined party elsewhere in this or other OSCAL instances. The locally defined UUID of the party can be used to reference the data item locally or globally (e.g., from an importing OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Party Universally Unique Identifier' , ) type : Type = Field ( ... , description = 'A category describing the kind of party the object describes.' , title = 'Party Type' , ) name : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , description = 'The full name of the party. This is typically the legal name associated with the party.' , title = 'Party Name' , ) short_name : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , alias = 'short-name' , description = 'A short common name, abbreviation, or acronym for the party.' , title = 'Party Short Name' , ) external_ids : Optional [ List [ ExternalId ]] = Field ( None , alias = 'external-ids' ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) email_addresses : Optional [ List [ EmailAddress ]] = Field ( None , alias = 'email-addresses' ) telephone_numbers : Optional [ List [ TelephoneNumber ]] = Field ( None , alias = 'telephone-numbers' ) addresses : Optional [ List [ Address ]] = Field ( None ) location_uuids : Optional [ List [ LocationUuid ]] = Field ( None , alias = 'location-uuids' ) member_of_organizations : Optional [ List [ MemberOfOrganization ]] = Field ( None , alias = 'member-of-organizations' ) remarks : Optional [ Remarks ] = None","title":"Party"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Party-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Party.addresses","text":"","title":"addresses"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Party.email_addresses","text":"","title":"email_addresses"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Party.external_ids","text":"","title":"external_ids"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Party.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Party.location_uuids","text":"","title":"location_uuids"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Party.member_of_organizations","text":"","title":"member_of_organizations"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Party.name","text":"The full name of the party. This is typically the legal name associated with the party.","title":"name"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Party.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Party.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Party.short_name","text":"A short common name, abbreviation, or acronym for the party.","title":"short_name"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Party.telephone_numbers","text":"","title":"telephone_numbers"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Party.type","text":"A category describing the kind of party the object describes.","title":"type"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Party.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this defined party elsewhere in this or other OSCAL instances. The locally defined UUID of the party can be used to reference the data item locally or globally (e.g., from an importing OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Party.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.PartyUuid","text":"Source code in trestle/oscal/common.py class PartyUuid ( OscalBaseModel ): __root__ : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented identifier reference to another party defined in metadata. The UUID of the party in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance).' , title = 'Party Reference' , )","title":"PartyUuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.PartyUuid-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.PartyUuid.__root__","text":"A machine-oriented identifier reference to another party defined in metadata. The UUID of the party in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance).","title":"__root__"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.PortRange","text":"Where applicable this is the IPv4 port range on which the service operates. Source code in trestle/oscal/common.py class PortRange ( OscalBaseModel ): \"\"\" Where applicable this is the IPv4 port range on which the service operates. \"\"\" class Config : extra = Extra . forbid start : Optional [ conint ( ge = 0 , multiple_of = 1 )] = Field ( None , description = 'Indicates the starting port number in a port range' , title = 'Start' , ) end : Optional [ conint ( ge = 0 , multiple_of = 1 )] = Field ( None , description = 'Indicates the ending port number in a port range' , title = 'End' , ) transport : Optional [ Transport ] = Field ( None , description = 'Indicates the transport type.' , title = 'Transport' )","title":"PortRange"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.PortRange-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.PortRange.end","text":"Indicates the ending port number in a port range","title":"end"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.PortRange.start","text":"Indicates the starting port number in a port range","title":"start"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.PortRange.transport","text":"Indicates the transport type.","title":"transport"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.PortRange.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Property","text":"An attribute, characteristic, or quality of the containing object expressed as a namespace qualified name/value pair. The value of a property is a simple scalar value, which may be expressed as a list of values. Source code in trestle/oscal/common.py class Property ( OscalBaseModel ): \"\"\" An attribute, characteristic, or quality of the containing object expressed as a namespace qualified name/value pair. The value of a property is a simple scalar value, which may be expressed as a list of values. \"\"\" class Config : extra = Extra . forbid name : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = \"A textual label that uniquely identifies a specific attribute, characteristic, or quality of the property's containing object.\" , title = 'Property Name' , ) uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this defined property elsewhere in this or other OSCAL instances. This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Property Universally Unique Identifier' , ) ns : Optional [ AnyUrl ] = Field ( None , description = \"A namespace qualifying the property's name. This allows different organizations to associate distinct semantics with the same name.\" , title = 'Property Namespace' , ) value : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'Indicates the value of the attribute, characteristic, or quality.' , title = 'Property Value' , ) class_ : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'class' , description = \"A textual label that provides a sub-type or characterization of the property's name. This can be used to further distinguish or discriminate between the semantics of multiple properties of the same object with the same name and ns.\" , title = 'Property Class' , ) remarks : Optional [ Remarks ] = None","title":"Property"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Property-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Property.class_","text":"A textual label that provides a sub-type or characterization of the property's name. This can be used to further distinguish or discriminate between the semantics of multiple properties of the same object with the same name and ns.","title":"class_"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Property.name","text":"A textual label that uniquely identifies a specific attribute, characteristic, or quality of the property's containing object.","title":"name"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Property.ns","text":"A namespace qualifying the property's name. This allows different organizations to associate distinct semantics with the same name.","title":"ns"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Property.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Property.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this defined property elsewhere in this or other OSCAL instances. This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Property.value","text":"Indicates the value of the attribute, characteristic, or quality.","title":"value"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Property.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Protocol","text":"Information about the protocol used to provide a service. Source code in trestle/oscal/common.py class Protocol ( OscalBaseModel ): \"\"\" Information about the protocol used to provide a service. \"\"\" class Config : extra = Extra . forbid uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this service protocol information elsewhere in this or other OSCAL instances. The locally defined UUID of the service protocol can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Service Protocol Information Universally Unique Identifier' , ) name : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'The common name of the protocol, which should be the appropriate \"service name\" from the IANA Service Name and Transport Protocol Port Number Registry.' , title = 'Protocol Name' , ) title : Optional [ str ] = Field ( None , description = 'A human readable name for the protocol (e.g., Transport Layer Security).' , title = 'Protocol Title' , ) port_ranges : Optional [ List [ PortRange ]] = Field ( None , alias = 'port-ranges' )","title":"Protocol"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Protocol-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Protocol.name","text":"The common name of the protocol, which should be the appropriate \"service name\" from the IANA Service Name and Transport Protocol Port Number Registry.","title":"name"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Protocol.port_ranges","text":"","title":"port_ranges"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Protocol.title","text":"A human readable name for the protocol (e.g., Transport Layer Security).","title":"title"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Protocol.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this service protocol information elsewhere in this or other OSCAL instances. The locally defined UUID of the service protocol can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Protocol.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Published","text":"Source code in trestle/oscal/common.py class Published ( OscalBaseModel ): __root__ : datetime = Field ( ... , description = 'The date and time the document was published. The date-time value must be formatted according to RFC 3339 with full time and time zone included.' , title = 'Publication Timestamp' , )","title":"Published"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Published-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Published.__root__","text":"The date and time the document was published. The date-time value must be formatted according to RFC 3339 with full time and time zone included.","title":"__root__"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedObservation1","text":"Relates the finding to a set of referenced observations that were used to determine the finding. Source code in trestle/oscal/common.py class RelatedObservation1 ( OscalBaseModel ): \"\"\" Relates the finding to a set of referenced observations that were used to determine the finding. \"\"\" class Config : extra = Extra . forbid observation_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'observation-uuid' , description = 'A machine-oriented identifier reference to an observation defined in the list of observations.' , title = 'Observation Universally Unique Identifier Reference' , )","title":"RelatedObservation1"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedObservation1-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedObservation1.observation_uuid","text":"A machine-oriented identifier reference to an observation defined in the list of observations.","title":"observation_uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedObservation1.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedResponse","text":"Identifies an individual risk response that this log entry is for. Source code in trestle/oscal/common.py class RelatedResponse ( OscalBaseModel ): \"\"\" Identifies an individual risk response that this log entry is for. \"\"\" class Config : extra = Extra . forbid response_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'response-uuid' , description = 'A machine-oriented identifier reference to a unique risk response.' , title = 'Response Universally Unique Identifier Reference' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) related_tasks : Optional [ List [ RelatedTask ]] = Field ( None , alias = 'related-tasks' ) remarks : Optional [ Remarks ] = None","title":"RelatedResponse"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedResponse-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedResponse.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedResponse.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedResponse.related_tasks","text":"","title":"related_tasks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedResponse.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedResponse.response_uuid","text":"A machine-oriented identifier reference to a unique risk response.","title":"response_uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedResponse.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedRisk","text":"Relates the finding to a set of referenced risks that were used to determine the finding. Source code in trestle/oscal/common.py class RelatedRisk ( OscalBaseModel ): \"\"\" Relates the finding to a set of referenced risks that were used to determine the finding. \"\"\" class Config : extra = Extra . forbid risk_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'risk-uuid' , description = 'A machine-oriented identifier reference to a risk defined in the list of risks.' , title = 'Risk Universally Unique Identifier Reference' , )","title":"RelatedRisk"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedRisk-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedRisk.risk_uuid","text":"A machine-oriented identifier reference to a risk defined in the list of risks.","title":"risk_uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedRisk.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedTask","text":"Identifies an individual task for which the containing object is a consequence of. Source code in trestle/oscal/common.py class RelatedTask ( OscalBaseModel ): \"\"\" Identifies an individual task for which the containing object is a consequence of. \"\"\" class Config : extra = Extra . forbid task_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'task-uuid' , description = 'A machine-oriented identifier reference to a unique task.' , title = 'Task Universally Unique Identifier Reference' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) responsible_parties : Optional [ List [ ResponsibleParty ]] = Field ( None , alias = 'responsible-parties' ) subjects : Optional [ List [ AssessmentSubject ]] = Field ( None ) identified_subject : Optional [ IdentifiedSubject ] = Field ( None , alias = 'identified-subject' , description = 'Used to detail assessment subjects that were identfied by this task.' , title = 'Identified Subject' , ) remarks : Optional [ Remarks ] = None","title":"RelatedTask"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedTask-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedTask.identified_subject","text":"Used to detail assessment subjects that were identfied by this task.","title":"identified_subject"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedTask.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedTask.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedTask.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedTask.responsible_parties","text":"","title":"responsible_parties"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedTask.subjects","text":"","title":"subjects"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedTask.task_uuid","text":"A machine-oriented identifier reference to a unique task.","title":"task_uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelatedTask.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelevantEvidence","text":"Links this observation to relevant evidence. Source code in trestle/oscal/common.py class RelevantEvidence ( OscalBaseModel ): \"\"\" Links this observation to relevant evidence. \"\"\" class Config : extra = Extra . forbid href : Optional [ str ] = Field ( None , description = 'A resolvable URL reference to relevant evidence.' , title = 'Relevant Evidence Reference' , ) description : str = Field ( ... , description = 'A human-readable description of this evidence.' , title = 'Relevant Evidence Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None","title":"RelevantEvidence"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelevantEvidence-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelevantEvidence.description","text":"A human-readable description of this evidence.","title":"description"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelevantEvidence.href","text":"A resolvable URL reference to relevant evidence.","title":"href"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelevantEvidence.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelevantEvidence.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelevantEvidence.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RelevantEvidence.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Remarks","text":"Source code in trestle/oscal/common.py class Remarks ( OscalBaseModel ): __root__ : str = Field ( ... , description = 'Additional commentary on the containing object.' , title = 'Remarks' , )","title":"Remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Remarks-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Remarks.__root__","text":"Additional commentary on the containing object.","title":"__root__"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RequiredAsset","text":"Identifies an asset required to achieve remediation. Source code in trestle/oscal/common.py class RequiredAsset ( OscalBaseModel ): \"\"\" Identifies an asset required to achieve remediation. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this required asset elsewhere in this or other OSCAL instances. The locally defined UUID of the asset can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Required Universally Unique Identifier' , ) subjects : Optional [ List [ SubjectReference ]] = Field ( None ) title : Optional [ str ] = Field ( None , description = 'The title for this required asset.' , title = 'Title for Required Asset' , ) description : str = Field ( ... , description = 'A human-readable description of this required asset.' , title = 'Description of Required Asset' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None","title":"RequiredAsset"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RequiredAsset-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RequiredAsset.description","text":"A human-readable description of this required asset.","title":"description"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RequiredAsset.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RequiredAsset.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RequiredAsset.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RequiredAsset.subjects","text":"","title":"subjects"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RequiredAsset.title","text":"The title for this required asset.","title":"title"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RequiredAsset.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this required asset elsewhere in this or other OSCAL instances. The locally defined UUID of the asset can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RequiredAsset.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Resource","text":"A resource associated with content in the containing document. A resource may be directly included in the document base64 encoded or may point to one or more equivalent internet resources. Source code in trestle/oscal/common.py class Resource ( OscalBaseModel ): \"\"\" A resource associated with content in the containing document. A resource may be directly included in the document base64 encoded or may point to one or more equivalent internet resources. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this defined resource elsewhere in this or other OSCAL instances. This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Resource Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'A name given to the resource, which may be used by a tool for display and navigation.' , title = 'Resource Title' , ) description : Optional [ str ] = Field ( None , description = 'A short summary of the resource used to indicate the purpose of the resource.' , title = 'Resource Description' , ) props : Optional [ List [ Property ]] = Field ( None ) document_ids : Optional [ List [ DocumentId ]] = Field ( None , alias = 'document-ids' ) citation : Optional [ Citation ] = Field ( None , description = 'A citation consisting of end note text and optional structured bibliographic data.' , title = 'Citation' , ) rlinks : Optional [ List [ Rlink ]] = Field ( None ) base64 : Optional [ Base64 ] = Field ( None , description = 'The Base64 alphabet in RFC 2045 - aligned with XSD.' , title = 'Base64' , ) remarks : Optional [ Remarks ] = None","title":"Resource"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Resource-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Resource.base64","text":"The Base64 alphabet in RFC 2045 - aligned with XSD.","title":"base64"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Resource.citation","text":"A citation consisting of end note text and optional structured bibliographic data.","title":"citation"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Resource.description","text":"A short summary of the resource used to indicate the purpose of the resource.","title":"description"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Resource.document_ids","text":"","title":"document_ids"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Resource.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Resource.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Resource.rlinks","text":"","title":"rlinks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Resource.title","text":"A name given to the resource, which may be used by a tool for display and navigation.","title":"title"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Resource.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this defined resource elsewhere in this or other OSCAL instances. This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Resource.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ResponsibleParty","text":"A reference to a set of organizations or persons that have responsibility for performing a referenced role in the context of the containing object. Source code in trestle/oscal/common.py class ResponsibleParty ( OscalBaseModel ): \"\"\" A reference to a set of organizations or persons that have responsibility for performing a referenced role in the context of the containing object. \"\"\" class Config : extra = Extra . forbid role_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'role-id' , description = 'A human-oriented identifier reference to roles served by the user.' , title = 'Responsible Role' , ) party_uuids : List [ PartyUuid ] = Field ( ... , alias = 'party-uuids' ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None","title":"ResponsibleParty"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ResponsibleParty-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ResponsibleParty.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ResponsibleParty.party_uuids","text":"","title":"party_uuids"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ResponsibleParty.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ResponsibleParty.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ResponsibleParty.role_id","text":"A human-oriented identifier reference to roles served by the user.","title":"role_id"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ResponsibleParty.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ResponsibleRole","text":"A reference to one or more roles with responsibility for performing a function relative to the containing object. Source code in trestle/oscal/common.py class ResponsibleRole ( OscalBaseModel ): \"\"\" A reference to one or more roles with responsibility for performing a function relative to the containing object. \"\"\" class Config : extra = Extra . forbid role_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'role-id' , description = 'A human-oriented identifier reference to roles responsible for the business function.' , title = 'Responsible Role ID' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) party_uuids : Optional [ List [ PartyUuid ]] = Field ( None , alias = 'party-uuids' ) remarks : Optional [ Remarks ] = None","title":"ResponsibleRole"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ResponsibleRole-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ResponsibleRole.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ResponsibleRole.party_uuids","text":"","title":"party_uuids"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ResponsibleRole.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ResponsibleRole.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ResponsibleRole.role_id","text":"A human-oriented identifier reference to roles responsible for the business function.","title":"role_id"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ResponsibleRole.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Revision","text":"An entry in a sequential list of revisions to the containing document in reverse chronological order (i.e., most recent previous revision first). Source code in trestle/oscal/common.py class Revision ( OscalBaseModel ): \"\"\" An entry in a sequential list of revisions to the containing document in reverse chronological order (i.e., most recent previous revision first). \"\"\" class Config : extra = Extra . forbid title : Optional [ str ] = Field ( None , description = 'A name given to the document revision, which may be used by a tool for display and navigation.' , title = 'Document Title' , ) published : Optional [ Published ] = None last_modified : Optional [ LastModified ] = Field ( None , alias = 'last-modified' ) version : Version oscal_version : Optional [ OscalVersion ] = Field ( None , alias = 'oscal-version' ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None","title":"Revision"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Revision-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Revision.last_modified","text":"","title":"last_modified"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Revision.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Revision.oscal_version","text":"","title":"oscal_version"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Revision.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Revision.published","text":"","title":"published"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Revision.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Revision.title","text":"A name given to the document revision, which may be used by a tool for display and navigation.","title":"title"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Revision.version","text":"","title":"version"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Revision.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RiskStatus","text":"Source code in trestle/oscal/common.py class RiskStatus ( OscalBaseModel ): __root__ : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Describes the status of the associated risk.' , title = 'Risk Status' , )","title":"RiskStatus"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RiskStatus-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RiskStatus.__root__","text":"Describes the status of the associated risk.","title":"__root__"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Rlink","text":"A pointer to an external resource with an optional hash for verification and change detection. Source code in trestle/oscal/common.py class Rlink ( OscalBaseModel ): \"\"\" A pointer to an external resource with an optional hash for verification and change detection. \"\"\" class Config : extra = Extra . forbid href : str = Field ( ... , description = 'A resolvable URI reference to a resource.' , title = 'Hypertext Reference' , ) media_type : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , alias = 'media-type' , description = 'Specifies a media type as defined by the Internet Assigned Numbers Authority (IANA) Media Types Registry.' , title = 'Media Type' , ) hashes : Optional [ List [ Hash ]] = Field ( None )","title":"Rlink"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Rlink-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Rlink.hashes","text":"","title":"hashes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Rlink.href","text":"A resolvable URI reference to a resource.","title":"href"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Rlink.media_type","text":"Specifies a media type as defined by the Internet Assigned Numbers Authority (IANA) Media Types Registry.","title":"media_type"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Rlink.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Role","text":"Defines a function assumed or expected to be assumed by a party in a specific situation. Source code in trestle/oscal/common.py class Role ( OscalBaseModel ): \"\"\" Defines a function assumed or expected to be assumed by a party in a specific situation. \"\"\" class Config : extra = Extra . forbid id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined role elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, the locally defined ID of the Role from the imported OSCAL instance must be referenced in the context of the containing resource (e.g., import, import-component-definition, import-profile, import-ssp or import-ap). This ID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Role Identifier' , ) title : str = Field ( ... , description = 'A name given to the role, which may be used by a tool for display and navigation.' , title = 'Role Title' , ) short_name : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , alias = 'short-name' , description = 'A short common name, abbreviation, or acronym for the role.' , title = 'Role Short Name' , ) description : Optional [ str ] = Field ( None , description = \"A summary of the role's purpose and associated responsibilities.\" , title = 'Role Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None","title":"Role"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Role-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Role.description","text":"A summary of the role's purpose and associated responsibilities.","title":"description"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Role.id","text":"A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined role elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, the locally defined ID of the Role from the imported OSCAL instance must be referenced in the context of the containing resource (e.g., import, import-component-definition, import-profile, import-ssp or import-ap). This ID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"id"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Role.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Role.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Role.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Role.short_name","text":"A short common name, abbreviation, or acronym for the role.","title":"short_name"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Role.title","text":"A name given to the role, which may be used by a tool for display and navigation.","title":"title"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Role.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RoleId","text":"Source code in trestle/oscal/common.py class RoleId ( OscalBaseModel ): __root__ : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'A human-oriented identifier reference to roles served by the user.' , title = 'Role Identifier Reference' , )","title":"RoleId"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RoleId-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.RoleId.__root__","text":"A human-oriented identifier reference to roles served by the user.","title":"__root__"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SelectObjectiveById","text":"Used to select a control objective for inclusion/exclusion based on the control objective's identifier. Source code in trestle/oscal/common.py class SelectObjectiveById ( OscalBaseModel ): \"\"\" Used to select a control objective for inclusion/exclusion based on the control objective's identifier. \"\"\" class Config : extra = Extra . forbid objective_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'objective-id' , description = 'Points to an assessment objective.' , title = 'Objective ID' , )","title":"SelectObjectiveById"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SelectObjectiveById-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SelectObjectiveById.objective_id","text":"Points to an assessment objective.","title":"objective_id"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SelectObjectiveById.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SelectSubjectById","text":"Identifies a set of assessment subjects to include/exclude by UUID. Source code in trestle/oscal/common.py class SelectSubjectById ( OscalBaseModel ): \"\"\" Identifies a set of assessment subjects to include/exclude by UUID. \"\"\" class Config : extra = Extra . forbid subject_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'subject-uuid' , description = \"A machine-oriented identifier reference to a component, inventory-item, location, party, user, or resource using it's UUID.\" , title = 'Subject Universally Unique Identifier Reference' , ) type : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Used to indicate the type of object pointed to by the uuid-ref within a subject.' , title = 'Subject Universally Unique Identifier Reference Type' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None","title":"SelectSubjectById"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SelectSubjectById-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SelectSubjectById.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SelectSubjectById.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SelectSubjectById.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SelectSubjectById.subject_uuid","text":"A machine-oriented identifier reference to a component, inventory-item, location, party, user, or resource using it's UUID.","title":"subject_uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SelectSubjectById.type","text":"Used to indicate the type of object pointed to by the uuid-ref within a subject.","title":"type"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SelectSubjectById.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Source","text":"Assessment subjects will be identified while conducting the referenced activity-instance. Source code in trestle/oscal/common.py class Source ( OscalBaseModel ): \"\"\" Assessment subjects will be identified while conducting the referenced activity-instance. \"\"\" class Config : extra = Extra . forbid task_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'task-uuid' , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference (in this or other OSCAL instances) an assessment activity to be performed as part of the event. The locally defined UUID of the task can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Task Universally Unique Identifier' , )","title":"Source"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Source-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Source.task_uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference (in this or other OSCAL instances) an assessment activity to be performed as part of the event. The locally defined UUID of the task can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"task_uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Source.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.StatementId","text":"Source code in trestle/oscal/common.py class StatementId ( OscalBaseModel ): __root__ : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Used to constrain the selection to only specificity identified statements.' , title = 'Include Specific Statements' , )","title":"StatementId"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.StatementId-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.StatementId.__root__","text":"Used to constrain the selection to only specificity identified statements.","title":"__root__"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SubjectReference","text":"A human-oriented identifier reference to a resource. Use type to indicate whether the identified resource is a component, inventory item, location, user, or something else. Source code in trestle/oscal/common.py class SubjectReference ( OscalBaseModel ): \"\"\" A human-oriented identifier reference to a resource. Use type to indicate whether the identified resource is a component, inventory item, location, user, or something else. \"\"\" class Config : extra = Extra . forbid subject_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'subject-uuid' , description = \"A machine-oriented identifier reference to a component, inventory-item, location, party, user, or resource using it's UUID.\" , title = 'Subject Universally Unique Identifier Reference' , ) type : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Used to indicate the type of object pointed to by the uuid-ref within a subject.' , title = 'Subject Universally Unique Identifier Reference Type' , ) title : Optional [ str ] = Field ( None , description = 'The title or name for the referenced subject.' , title = 'Subject Reference Title' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) remarks : Optional [ Remarks ] = None","title":"SubjectReference"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SubjectReference-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SubjectReference.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SubjectReference.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SubjectReference.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SubjectReference.subject_uuid","text":"A machine-oriented identifier reference to a component, inventory-item, location, party, user, or resource using it's UUID.","title":"subject_uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SubjectReference.title","text":"The title or name for the referenced subject.","title":"title"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SubjectReference.type","text":"Used to indicate the type of object pointed to by the uuid-ref within a subject.","title":"type"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SubjectReference.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SystemId","text":"A human-oriented, globally unique identifier with cross-instance scope that can be used to reference this system identification property elsewhere in this or other OSCAL instances. When referencing an externally defined system identification, the system identification must be used in the context of the external / imported OSCAL instance (e.g., uri-reference). This string should be assigned per-subject, which means it should be consistently used to identify the same system across revisions of the document. Source code in trestle/oscal/common.py class SystemId ( OscalBaseModel ): \"\"\" A human-oriented, globally unique identifier with cross-instance scope that can be used to reference this system identification property elsewhere in this or other OSCAL instances. When referencing an externally defined system identification, the system identification must be used in the context of the external / imported OSCAL instance (e.g., uri-reference). This string should be assigned per-subject, which means it should be consistently used to identify the same system across revisions of the document. \"\"\" class Config : extra = Extra . forbid identifier_type : Optional [ AnyUrl ] = Field ( None , alias = 'identifier-type' , description = 'Identifies the identification system from which the provided identifier was assigned.' , title = 'Identification System Type' , ) id : str","title":"SystemId"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SystemId-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SystemId.id","text":"","title":"id"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SystemId.identifier_type","text":"Identifies the identification system from which the provided identifier was assigned.","title":"identifier_type"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SystemId.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SystemUser","text":"A type of user that interacts with the system based on an associated role. Source code in trestle/oscal/common.py class SystemUser ( OscalBaseModel ): \"\"\" A type of user that interacts with the system based on an associated role. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this user class elsewhere in this or other OSCAL instances. The locally defined UUID of the system user can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'User Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'A name given to the user, which may be used by a tool for display and navigation.' , title = 'User Title' , ) short_name : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , alias = 'short-name' , description = 'A short common name, abbreviation, or acronym for the user.' , title = 'User Short Name' , ) description : Optional [ str ] = Field ( None , description = \"A summary of the user's purpose within the system.\" , title = 'User Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) role_ids : Optional [ List [ RoleId ]] = Field ( None , alias = 'role-ids' ) authorized_privileges : Optional [ List [ AuthorizedPrivilege ]] = Field ( None , alias = 'authorized-privileges' ) remarks : Optional [ Remarks ] = None","title":"SystemUser"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SystemUser-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SystemUser.authorized_privileges","text":"","title":"authorized_privileges"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SystemUser.description","text":"A summary of the user's purpose within the system.","title":"description"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SystemUser.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SystemUser.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SystemUser.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SystemUser.role_ids","text":"","title":"role_ids"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SystemUser.short_name","text":"A short common name, abbreviation, or acronym for the user.","title":"short_name"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SystemUser.title","text":"A name given to the user, which may be used by a tool for display and navigation.","title":"title"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SystemUser.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this user class elsewhere in this or other OSCAL instances. The locally defined UUID of the system user can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.SystemUser.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Task","text":"Represents a scheduled event or milestone, which may be associated with a series of assessment actions. Source code in trestle/oscal/common.py class Task ( OscalBaseModel ): \"\"\" Represents a scheduled event or milestone, which may be associated with a series of assessment actions. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this task elsewhere in this or other OSCAL instances. The locally defined UUID of the task can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Task Universally Unique Identifier' , ) type : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'The type of task.' , title = 'Task Type' ) title : str = Field ( ... , description = 'The title for this task.' , title = 'Task Title' ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of this task.' , title = 'Task Description' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) timing : Optional [ Timing ] = Field ( None , description = 'The timing under which the task is intended to occur.' , title = 'Event Timing' , ) dependencies : Optional [ List [ Dependency ]] = Field ( None ) tasks : Optional [ List [ Task ]] = None associated_activities : Optional [ List [ AssociatedActivity ]] = Field ( None , alias = 'associated-activities' ) subjects : Optional [ List [ AssessmentSubject ]] = Field ( None ) responsible_roles : Optional [ List [ ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ Remarks ] = None","title":"Task"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Task-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Task.associated_activities","text":"","title":"associated_activities"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Task.dependencies","text":"","title":"dependencies"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Task.description","text":"A human-readable description of this task.","title":"description"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Task.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Task.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Task.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Task.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Task.subjects","text":"","title":"subjects"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Task.tasks","text":"","title":"tasks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Task.timing","text":"The timing under which the task is intended to occur.","title":"timing"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Task.title","text":"The title for this task.","title":"title"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Task.type","text":"The type of task.","title":"type"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Task.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this task elsewhere in this or other OSCAL instances. The locally defined UUID of the task can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Task.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.TelephoneNumber","text":"Contact number by telephone. Source code in trestle/oscal/common.py class TelephoneNumber ( OscalBaseModel ): \"\"\" Contact number by telephone. \"\"\" class Config : extra = Extra . forbid type : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , description = 'Indicates the type of phone number.' , title = 'type flag' ) number : str","title":"TelephoneNumber"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.TelephoneNumber-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.TelephoneNumber.number","text":"","title":"number"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.TelephoneNumber.type","text":"Indicates the type of phone number.","title":"type"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.TelephoneNumber.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Test","text":"A test expression which is expected to be evaluated by a tool. Source code in trestle/oscal/common.py class Test ( OscalBaseModel ): \"\"\" A test expression which is expected to be evaluated by a tool. \"\"\" class Config : extra = Extra . forbid expression : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A formal (executable) expression of a constraint' , title = 'Constraint test' , ) remarks : Optional [ Remarks ] = None","title":"Test"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Test-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Test.expression","text":"A formal (executable) expression of a constraint","title":"expression"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Test.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Test.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ThreatId","text":"A pointer, by ID, to an externally-defined threat. Source code in trestle/oscal/common.py class ThreatId ( OscalBaseModel ): \"\"\" A pointer, by ID, to an externally-defined threat. \"\"\" class Config : extra = Extra . forbid system : AnyUrl = Field ( ... , description = 'Specifies the source of the threat information.' , title = 'Threat Type Identification System' , ) href : Optional [ str ] = Field ( None , description = 'An optional location for the threat data, from which this ID originates.' , title = 'Threat Information Resource Reference' , ) id : str","title":"ThreatId"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ThreatId-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ThreatId.href","text":"An optional location for the threat data, from which this ID originates.","title":"href"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ThreatId.id","text":"","title":"id"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ThreatId.system","text":"Specifies the source of the threat information.","title":"system"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.ThreatId.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Timing","text":"The timing under which the task is intended to occur. Source code in trestle/oscal/common.py class Timing ( OscalBaseModel ): \"\"\" The timing under which the task is intended to occur. \"\"\" class Config : extra = Extra . forbid on_date : Optional [ OnDate ] = Field ( None , alias = 'on-date' , description = 'The task is intended to occur on the specified date.' , title = 'On Date Condition' , ) within_date_range : Optional [ WithinDateRange ] = Field ( None , alias = 'within-date-range' , description = 'The task is intended to occur within the specified date range.' , title = 'On Date Range Condition' , ) at_frequency : Optional [ AtFrequency ] = Field ( None , alias = 'at-frequency' , description = 'The task is intended to occur at the specified frequency.' , title = 'Frequency Condition' , )","title":"Timing"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Timing-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Timing.at_frequency","text":"The task is intended to occur at the specified frequency.","title":"at_frequency"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Timing.on_date","text":"The task is intended to occur on the specified date.","title":"on_date"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Timing.within_date_range","text":"The task is intended to occur within the specified date range.","title":"within_date_range"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Timing.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Transport","text":"Indicates the transport type. Source code in trestle/oscal/common.py class Transport ( Enum ): \"\"\" Indicates the transport type. \"\"\" TCP = 'TCP' UDP = 'UDP'","title":"Transport"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Transport.TCP","text":"","title":"TCP"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Transport.UDP","text":"","title":"UDP"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Type","text":"A category describing the kind of party the object describes. Source code in trestle/oscal/common.py class Type ( Enum ): \"\"\" A category describing the kind of party the object describes. \"\"\" person = 'person' organization = 'organization'","title":"Type"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Type.organization","text":"","title":"organization"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Type.person","text":"","title":"person"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Type1","text":"Identifies the type of the target. Source code in trestle/oscal/common.py class Type1 ( Enum ): \"\"\" Identifies the type of the target. \"\"\" statement_id = 'statement-id' objective_id = 'objective-id'","title":"Type1"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Type1.objective_id","text":"","title":"objective_id"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Type1.statement_id","text":"","title":"statement_id"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Type2","text":"Source code in trestle/oscal/common.py class Type2 ( OscalBaseModel ): __root__ : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Identifies the nature of the observation. More than one may be used to further qualify and enable filtering.' , title = 'Observation Type' , )","title":"Type2"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Type2-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Type2.__root__","text":"Identifies the nature of the observation. More than one may be used to further qualify and enable filtering.","title":"__root__"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Type3","text":"The kind of actor. Source code in trestle/oscal/common.py class Type3 ( Enum ): \"\"\" The kind of actor. \"\"\" tool = 'tool' assessment_platform = 'assessment-platform' party = 'party'","title":"Type3"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Type3.assessment_platform","text":"","title":"assessment_platform"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Type3.party","text":"","title":"party"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Type3.tool","text":"","title":"tool"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Unit","text":"The unit of time for the period. Source code in trestle/oscal/common.py class Unit ( Enum ): \"\"\" The unit of time for the period. \"\"\" seconds = 'seconds' minutes = 'minutes' hours = 'hours' days = 'days' months = 'months' years = 'years'","title":"Unit"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Unit.days","text":"","title":"days"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Unit.hours","text":"","title":"hours"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Unit.minutes","text":"","title":"minutes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Unit.months","text":"","title":"months"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Unit.seconds","text":"","title":"seconds"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Unit.years","text":"","title":"years"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.UsesComponent","text":"The set of components that are used by the assessment platform. Source code in trestle/oscal/common.py class UsesComponent ( OscalBaseModel ): \"\"\" The set of components that are used by the assessment platform. \"\"\" class Config : extra = Extra . forbid component_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'component-uuid' , description = 'A machine-oriented identifier reference to a component that is implemented as part of an inventory item.' , title = 'Component Universally Unique Identifier Reference' , ) props : Optional [ List [ Property ]] = Field ( None ) links : Optional [ List [ Link ]] = Field ( None ) responsible_parties : Optional [ List [ ResponsibleParty ]] = Field ( None , alias = 'responsible-parties' ) remarks : Optional [ Remarks ] = None","title":"UsesComponent"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.UsesComponent-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.UsesComponent.component_uuid","text":"A machine-oriented identifier reference to a component that is implemented as part of an inventory item.","title":"component_uuid"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.UsesComponent.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.UsesComponent.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.UsesComponent.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.UsesComponent.responsible_parties","text":"","title":"responsible_parties"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.UsesComponent.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Value","text":"Source code in trestle/oscal/common.py class Value ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A parameter value or set of values.' , title = 'Parameter Value' )","title":"Value"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Value-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Value.__root__","text":"A parameter value or set of values.","title":"__root__"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Version","text":"Source code in trestle/oscal/common.py class Version ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A string used to distinguish the current version of the document from other previous (and future) versions.' , title = 'Document Version' , )","title":"Version"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Version-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.Version.__root__","text":"A string used to distinguish the current version of the document from other previous (and future) versions.","title":"__root__"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.WithinDateRange","text":"The task is intended to occur within the specified date range. Source code in trestle/oscal/common.py class WithinDateRange ( OscalBaseModel ): \"\"\" The task is intended to occur within the specified date range. \"\"\" class Config : extra = Extra . forbid start : datetime = Field ( ... , description = 'The task must occur on or after the specified date.' , title = 'Start Date Condition' , ) end : datetime = Field ( ... , description = 'The task must occur on or before the specified date.' , title = 'End Date Condition' , )","title":"WithinDateRange"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.WithinDateRange-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.WithinDateRange.end","text":"The task must occur on or before the specified date.","title":"end"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.WithinDateRange.start","text":"The task must occur on or after the specified date.","title":"start"},{"location":"api_reference/trestle.oscal.common/#trestle.oscal.common.WithinDateRange.Config","text":"Source code in trestle/oscal/common.py class Config : extra = Extra . forbid handler: python","title":"Config"},{"location":"api_reference/trestle.oscal.component/","text":"trestle.oscal.component \u00a4 Classes \u00a4 Capability ( OscalBaseModel ) pydantic-model \u00a4 A grouping of other components and/or capabilities. Source code in trestle/oscal/component.py class Capability ( OscalBaseModel ): \"\"\" A grouping of other components and/or capabilities. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this capability elsewhere in this or other OSCAL instances. The locally defined UUID of the capability can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance).This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Capability Identifier' , ) name : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = \"The capability's human-readable name.\" , title = 'Capability Name' , ) description : str = Field ( ... , description = 'A summary of the capability.' , title = 'Capability Description' ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) incorporates_components : Optional [ List [ IncorporatesComponent ]] = Field ( None , alias = 'incorporates-components' ) control_implementations : Optional [ List [ ControlImplementation ]] = Field ( None , alias = 'control-implementations' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 control_implementations : List [ trestle . oscal . component . ControlImplementation ] pydantic-field \u00a4 description : str pydantic-field required \u00a4 A summary of the capability. incorporates_components : List [ trestle . oscal . component . IncorporatesComponent ] pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 name : ConstrainedStrValue pydantic-field required \u00a4 The capability's human-readable name. props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this capability elsewhere in this or other OSCAL instances. The locally defined UUID of the capability can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance).This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/component.py class Config : extra = Extra . forbid ComponentDefinition ( OscalBaseModel ) pydantic-model \u00a4 A collection of component descriptions, which may optionally be grouped by capability. Source code in trestle/oscal/component.py class ComponentDefinition ( OscalBaseModel ): \"\"\" A collection of component descriptions, which may optionally be grouped by capability. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component definition elsewhere in this or other OSCAL instances. The locally defined UUID of the component definition can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Component Definition Universally Unique Identifier' , ) metadata : common . Metadata import_component_definitions : Optional [ List [ ImportComponentDefinition ]] = Field ( None , alias = 'import-component-definitions' ) components : Optional [ List [ DefinedComponent ]] = Field ( None ) capabilities : Optional [ List [ Capability ]] = Field ( None ) back_matter : Optional [ common . BackMatter ] = Field ( None , alias = 'back-matter' ) Attributes \u00a4 back_matter : BackMatter pydantic-field \u00a4 capabilities : List [ trestle . oscal . component . Capability ] pydantic-field \u00a4 components : List [ trestle . oscal . component . DefinedComponent ] pydantic-field \u00a4 import_component_definitions : List [ trestle . oscal . component . ImportComponentDefinition ] pydantic-field \u00a4 metadata : Metadata pydantic-field required \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component definition elsewhere in this or other OSCAL instances. The locally defined UUID of the component definition can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/component.py class Config : extra = Extra . forbid ControlImplementation ( OscalBaseModel ) pydantic-model \u00a4 Defines how the component or capability supports a set of controls. Source code in trestle/oscal/component.py class ControlImplementation ( OscalBaseModel ): \"\"\" Defines how the component or capability supports a set of controls. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference a set of implemented controls elsewhere in this or other OSCAL instances. The locally defined UUID of the control implementation set can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Control Implementation Set Identifier' , ) source : str = Field ( ... , description = 'A reference to an OSCAL catalog or profile providing the referenced control or subcontrol definition.' , title = 'Source Resource Reference' , ) description : str = Field ( ... , description = 'A description of how the specified set of controls are implemented for the containing component or capability.' , title = 'Control Implementation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) set_parameters : Optional [ List [ SetParameter ]] = Field ( None , alias = 'set-parameters' ) implemented_requirements : List [ ImplementedRequirement ] = Field ( ... , alias = 'implemented-requirements' ) Attributes \u00a4 description : str pydantic-field required \u00a4 A description of how the specified set of controls are implemented for the containing component or capability. implemented_requirements : List [ trestle . oscal . component . ImplementedRequirement ] pydantic-field required \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 set_parameters : List [ trestle . oscal . component . SetParameter ] pydantic-field \u00a4 source : str pydantic-field required \u00a4 A reference to an OSCAL catalog or profile providing the referenced control or subcontrol definition. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference a set of implemented controls elsewhere in this or other OSCAL instances. The locally defined UUID of the control implementation set can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/component.py class Config : extra = Extra . forbid DefinedComponent ( OscalBaseModel ) pydantic-model \u00a4 A defined component that can be part of an implemented system. Source code in trestle/oscal/component.py class DefinedComponent ( OscalBaseModel ): \"\"\" A defined component that can be part of an implemented system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Component Identifier' , ) type : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A category describing the purpose of the component.' , title = 'Component Type' , ) title : str = Field ( ... , description = 'A human readable name for the component.' , title = 'Component Title' , ) description : str = Field ( ... , description = 'A description of the component, including information about its function.' , title = 'Component Description' , ) purpose : Optional [ str ] = Field ( None , description = 'A summary of the technological or business purpose of the component.' , title = 'Purpose' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) protocols : Optional [ List [ common . Protocol ]] = Field ( None ) control_implementations : Optional [ List [ ControlImplementation ]] = Field ( None , alias = 'control-implementations' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 control_implementations : List [ trestle . oscal . component . ControlImplementation ] pydantic-field \u00a4 description : str pydantic-field required \u00a4 A description of the component, including information about its function. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 protocols : List [ trestle . oscal . common . Protocol ] pydantic-field \u00a4 purpose : str pydantic-field \u00a4 A summary of the technological or business purpose of the component. remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 title : str pydantic-field required \u00a4 A human readable name for the component. type : ConstrainedStrValue pydantic-field required \u00a4 A category describing the purpose of the component. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/component.py class Config : extra = Extra . forbid ImplementedRequirement ( OscalBaseModel ) pydantic-model \u00a4 Describes how the containing component or capability implements an individual control. Source code in trestle/oscal/component.py class ImplementedRequirement ( OscalBaseModel ): \"\"\" Describes how the containing component or capability implements an individual control. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference a specific control implementation elsewhere in this or other OSCAL instances. The locally defined UUID of the control implementation can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance).This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Control Implementation Identifier' , ) control_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'control-id' , description = 'A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).' , title = 'Control Identifier Reference' , ) description : str = Field ( ... , description = 'A description of how the specified control is implemented for the containing component or capability.' , title = 'Control Implementation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) set_parameters : Optional [ List [ SetParameter ]] = Field ( None , alias = 'set-parameters' ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) statements : Optional [ List [ Statement ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 control_id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference). description : str pydantic-field required \u00a4 A description of how the specified control is implemented for the containing component or capability. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 set_parameters : List [ trestle . oscal . component . SetParameter ] pydantic-field \u00a4 statements : List [ trestle . oscal . component . Statement ] pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference a specific control implementation elsewhere in this or other OSCAL instances. The locally defined UUID of the control implementation can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance).This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/component.py class Config : extra = Extra . forbid ImportComponentDefinition ( OscalBaseModel ) pydantic-model \u00a4 Loads a component definition from another resource. Source code in trestle/oscal/component.py class ImportComponentDefinition ( OscalBaseModel ): \"\"\" Loads a component definition from another resource. \"\"\" class Config : extra = Extra . forbid href : str = Field ( ... , description = 'A link to a resource that defines a set of components and/or capabilities to import into this collection.' , title = 'Hyperlink Reference' , ) Attributes \u00a4 href : str pydantic-field required \u00a4 A link to a resource that defines a set of components and/or capabilities to import into this collection. Config \u00a4 Source code in trestle/oscal/component.py class Config : extra = Extra . forbid IncorporatesComponent ( OscalBaseModel ) pydantic-model \u00a4 TBD Source code in trestle/oscal/component.py class IncorporatesComponent ( OscalBaseModel ): \"\"\" TBD \"\"\" class Config : extra = Extra . forbid component_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'component-uuid' , description = 'A machine-oriented identifier reference to a component.' , title = 'Component Reference' , ) description : str = Field ( ... , description = 'A description of the component, including information about its function.' , title = 'Component Description' , ) Attributes \u00a4 component_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to a component. description : str pydantic-field required \u00a4 A description of the component, including information about its function. Config \u00a4 Source code in trestle/oscal/component.py class Config : extra = Extra . forbid Model ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/component.py class Model ( OscalBaseModel ): component_definition : ComponentDefinition = Field ( ... , alias = 'component-definition' ) component_definition : ComponentDefinition pydantic-field required \u00a4 SetParameter ( OscalBaseModel ) pydantic-model \u00a4 Identifies the parameter that will be set by the enclosed value. Source code in trestle/oscal/component.py class SetParameter ( OscalBaseModel ): \"\"\" Identifies the parameter that will be set by the enclosed value. \"\"\" class Config : extra = Extra . forbid param_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'param-id' , description = \"A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context.\" , title = 'Parameter ID' , ) values : List [ common . Value ] = Field ( ... ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 param_id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context. remarks : Remarks pydantic-field \u00a4 values : List [ trestle . oscal . common . Value ] pydantic-field required \u00a4 Config \u00a4 Source code in trestle/oscal/component.py class Config : extra = Extra . forbid State ( Enum ) \u00a4 The operational status. Source code in trestle/oscal/component.py class State ( Enum ): \"\"\" The operational status. \"\"\" under_development = 'under-development' operational = 'operational' disposition = 'disposition' other = 'other' disposition \u00a4 operational \u00a4 other \u00a4 under_development \u00a4 Statement ( OscalBaseModel ) pydantic-model \u00a4 Identifies which statements within a control are addressed. Source code in trestle/oscal/component.py class Statement ( OscalBaseModel ): \"\"\" Identifies which statements within a control are addressed. \"\"\" class Config : extra = Extra . forbid statement_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'statement-id' , description = 'A human-oriented identifier reference to a control statement.' , title = 'Control Statement Reference' , ) uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this control statement elsewhere in this or other OSCAL instances. The UUID of the control statement in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance).' , title = 'Control Statement Reference Universally Unique Identifier' , ) description : str = Field ( ... , description = 'A summary of how the containing control statement is implemented by the component or capability.' , title = 'Statement Implementation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A summary of how the containing control statement is implemented by the component or capability. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 statement_id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented identifier reference to a control statement. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this control statement elsewhere in this or other OSCAL instances. The UUID of the control statement in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance). Config \u00a4 Source code in trestle/oscal/component.py class Config : extra = Extra . forbid Status ( OscalBaseModel ) pydantic-model \u00a4 Describes the operational status of the system component. Source code in trestle/oscal/component.py class Status ( OscalBaseModel ): \"\"\" Describes the operational status of the system component. \"\"\" class Config : extra = Extra . forbid state : State = Field ( ... , description = 'The operational status.' , title = 'State' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 remarks : Remarks pydantic-field \u00a4 state : State pydantic-field required \u00a4 The operational status. Config \u00a4 Source code in trestle/oscal/component.py class Config : extra = Extra . forbid SystemComponent ( OscalBaseModel ) pydantic-model \u00a4 A defined component that can be part of an implemented system. Source code in trestle/oscal/component.py class SystemComponent ( OscalBaseModel ): \"\"\" A defined component that can be part of an implemented system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Component Identifier' , ) type : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A category describing the purpose of the component.' , title = 'Component Type' , ) title : str = Field ( ... , description = 'A human readable name for the system component.' , title = 'Component Title' , ) description : str = Field ( ... , description = 'A description of the component, including information about its function.' , title = 'Component Description' , ) purpose : Optional [ str ] = Field ( None , description = 'A summary of the technological or business purpose of the component.' , title = 'Purpose' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : Status = Field ( ... , description = 'Describes the operational status of the system component.' , title = 'Status' , ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) protocols : Optional [ List [ common . Protocol ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A description of the component, including information about its function. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 protocols : List [ trestle . oscal . common . Protocol ] pydantic-field \u00a4 purpose : str pydantic-field \u00a4 A summary of the technological or business purpose of the component. remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 status : Status pydantic-field required \u00a4 Describes the operational status of the system component. title : str pydantic-field required \u00a4 A human readable name for the system component. type : ConstrainedStrValue pydantic-field required \u00a4 A category describing the purpose of the component. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/component.py class Config : extra = Extra . forbid handler: python","title":"component"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component","text":"","title":"component"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Capability","text":"A grouping of other components and/or capabilities. Source code in trestle/oscal/component.py class Capability ( OscalBaseModel ): \"\"\" A grouping of other components and/or capabilities. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this capability elsewhere in this or other OSCAL instances. The locally defined UUID of the capability can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance).This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Capability Identifier' , ) name : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = \"The capability's human-readable name.\" , title = 'Capability Name' , ) description : str = Field ( ... , description = 'A summary of the capability.' , title = 'Capability Description' ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) incorporates_components : Optional [ List [ IncorporatesComponent ]] = Field ( None , alias = 'incorporates-components' ) control_implementations : Optional [ List [ ControlImplementation ]] = Field ( None , alias = 'control-implementations' ) remarks : Optional [ common . Remarks ] = None","title":"Capability"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Capability-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Capability.control_implementations","text":"","title":"control_implementations"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Capability.description","text":"A summary of the capability.","title":"description"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Capability.incorporates_components","text":"","title":"incorporates_components"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Capability.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Capability.name","text":"The capability's human-readable name.","title":"name"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Capability.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Capability.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Capability.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this capability elsewhere in this or other OSCAL instances. The locally defined UUID of the capability can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance).This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Capability.Config","text":"Source code in trestle/oscal/component.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ComponentDefinition","text":"A collection of component descriptions, which may optionally be grouped by capability. Source code in trestle/oscal/component.py class ComponentDefinition ( OscalBaseModel ): \"\"\" A collection of component descriptions, which may optionally be grouped by capability. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component definition elsewhere in this or other OSCAL instances. The locally defined UUID of the component definition can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Component Definition Universally Unique Identifier' , ) metadata : common . Metadata import_component_definitions : Optional [ List [ ImportComponentDefinition ]] = Field ( None , alias = 'import-component-definitions' ) components : Optional [ List [ DefinedComponent ]] = Field ( None ) capabilities : Optional [ List [ Capability ]] = Field ( None ) back_matter : Optional [ common . BackMatter ] = Field ( None , alias = 'back-matter' )","title":"ComponentDefinition"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ComponentDefinition-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ComponentDefinition.back_matter","text":"","title":"back_matter"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ComponentDefinition.capabilities","text":"","title":"capabilities"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ComponentDefinition.components","text":"","title":"components"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ComponentDefinition.import_component_definitions","text":"","title":"import_component_definitions"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ComponentDefinition.metadata","text":"","title":"metadata"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ComponentDefinition.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component definition elsewhere in this or other OSCAL instances. The locally defined UUID of the component definition can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ComponentDefinition.Config","text":"Source code in trestle/oscal/component.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ControlImplementation","text":"Defines how the component or capability supports a set of controls. Source code in trestle/oscal/component.py class ControlImplementation ( OscalBaseModel ): \"\"\" Defines how the component or capability supports a set of controls. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference a set of implemented controls elsewhere in this or other OSCAL instances. The locally defined UUID of the control implementation set can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Control Implementation Set Identifier' , ) source : str = Field ( ... , description = 'A reference to an OSCAL catalog or profile providing the referenced control or subcontrol definition.' , title = 'Source Resource Reference' , ) description : str = Field ( ... , description = 'A description of how the specified set of controls are implemented for the containing component or capability.' , title = 'Control Implementation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) set_parameters : Optional [ List [ SetParameter ]] = Field ( None , alias = 'set-parameters' ) implemented_requirements : List [ ImplementedRequirement ] = Field ( ... , alias = 'implemented-requirements' )","title":"ControlImplementation"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ControlImplementation-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ControlImplementation.description","text":"A description of how the specified set of controls are implemented for the containing component or capability.","title":"description"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ControlImplementation.implemented_requirements","text":"","title":"implemented_requirements"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ControlImplementation.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ControlImplementation.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ControlImplementation.set_parameters","text":"","title":"set_parameters"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ControlImplementation.source","text":"A reference to an OSCAL catalog or profile providing the referenced control or subcontrol definition.","title":"source"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ControlImplementation.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference a set of implemented controls elsewhere in this or other OSCAL instances. The locally defined UUID of the control implementation set can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ControlImplementation.Config","text":"Source code in trestle/oscal/component.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.DefinedComponent","text":"A defined component that can be part of an implemented system. Source code in trestle/oscal/component.py class DefinedComponent ( OscalBaseModel ): \"\"\" A defined component that can be part of an implemented system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Component Identifier' , ) type : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A category describing the purpose of the component.' , title = 'Component Type' , ) title : str = Field ( ... , description = 'A human readable name for the component.' , title = 'Component Title' , ) description : str = Field ( ... , description = 'A description of the component, including information about its function.' , title = 'Component Description' , ) purpose : Optional [ str ] = Field ( None , description = 'A summary of the technological or business purpose of the component.' , title = 'Purpose' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) protocols : Optional [ List [ common . Protocol ]] = Field ( None ) control_implementations : Optional [ List [ ControlImplementation ]] = Field ( None , alias = 'control-implementations' ) remarks : Optional [ common . Remarks ] = None","title":"DefinedComponent"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.DefinedComponent-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.DefinedComponent.control_implementations","text":"","title":"control_implementations"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.DefinedComponent.description","text":"A description of the component, including information about its function.","title":"description"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.DefinedComponent.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.DefinedComponent.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.DefinedComponent.protocols","text":"","title":"protocols"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.DefinedComponent.purpose","text":"A summary of the technological or business purpose of the component.","title":"purpose"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.DefinedComponent.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.DefinedComponent.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.DefinedComponent.title","text":"A human readable name for the component.","title":"title"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.DefinedComponent.type","text":"A category describing the purpose of the component.","title":"type"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.DefinedComponent.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.DefinedComponent.Config","text":"Source code in trestle/oscal/component.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ImplementedRequirement","text":"Describes how the containing component or capability implements an individual control. Source code in trestle/oscal/component.py class ImplementedRequirement ( OscalBaseModel ): \"\"\" Describes how the containing component or capability implements an individual control. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference a specific control implementation elsewhere in this or other OSCAL instances. The locally defined UUID of the control implementation can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance).This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Control Implementation Identifier' , ) control_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'control-id' , description = 'A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).' , title = 'Control Identifier Reference' , ) description : str = Field ( ... , description = 'A description of how the specified control is implemented for the containing component or capability.' , title = 'Control Implementation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) set_parameters : Optional [ List [ SetParameter ]] = Field ( None , alias = 'set-parameters' ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) statements : Optional [ List [ Statement ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None","title":"ImplementedRequirement"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ImplementedRequirement-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ImplementedRequirement.control_id","text":"A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).","title":"control_id"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ImplementedRequirement.description","text":"A description of how the specified control is implemented for the containing component or capability.","title":"description"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ImplementedRequirement.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ImplementedRequirement.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ImplementedRequirement.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ImplementedRequirement.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ImplementedRequirement.set_parameters","text":"","title":"set_parameters"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ImplementedRequirement.statements","text":"","title":"statements"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ImplementedRequirement.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference a specific control implementation elsewhere in this or other OSCAL instances. The locally defined UUID of the control implementation can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance).This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ImplementedRequirement.Config","text":"Source code in trestle/oscal/component.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ImportComponentDefinition","text":"Loads a component definition from another resource. Source code in trestle/oscal/component.py class ImportComponentDefinition ( OscalBaseModel ): \"\"\" Loads a component definition from another resource. \"\"\" class Config : extra = Extra . forbid href : str = Field ( ... , description = 'A link to a resource that defines a set of components and/or capabilities to import into this collection.' , title = 'Hyperlink Reference' , )","title":"ImportComponentDefinition"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ImportComponentDefinition-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ImportComponentDefinition.href","text":"A link to a resource that defines a set of components and/or capabilities to import into this collection.","title":"href"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.ImportComponentDefinition.Config","text":"Source code in trestle/oscal/component.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.IncorporatesComponent","text":"TBD Source code in trestle/oscal/component.py class IncorporatesComponent ( OscalBaseModel ): \"\"\" TBD \"\"\" class Config : extra = Extra . forbid component_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'component-uuid' , description = 'A machine-oriented identifier reference to a component.' , title = 'Component Reference' , ) description : str = Field ( ... , description = 'A description of the component, including information about its function.' , title = 'Component Description' , )","title":"IncorporatesComponent"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.IncorporatesComponent-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.IncorporatesComponent.component_uuid","text":"A machine-oriented identifier reference to a component.","title":"component_uuid"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.IncorporatesComponent.description","text":"A description of the component, including information about its function.","title":"description"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.IncorporatesComponent.Config","text":"Source code in trestle/oscal/component.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Model","text":"Source code in trestle/oscal/component.py class Model ( OscalBaseModel ): component_definition : ComponentDefinition = Field ( ... , alias = 'component-definition' )","title":"Model"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Model.component_definition","text":"","title":"component_definition"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SetParameter","text":"Identifies the parameter that will be set by the enclosed value. Source code in trestle/oscal/component.py class SetParameter ( OscalBaseModel ): \"\"\" Identifies the parameter that will be set by the enclosed value. \"\"\" class Config : extra = Extra . forbid param_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'param-id' , description = \"A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context.\" , title = 'Parameter ID' , ) values : List [ common . Value ] = Field ( ... ) remarks : Optional [ common . Remarks ] = None","title":"SetParameter"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SetParameter-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SetParameter.param_id","text":"A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context.","title":"param_id"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SetParameter.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SetParameter.values","text":"","title":"values"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SetParameter.Config","text":"Source code in trestle/oscal/component.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.State","text":"The operational status. Source code in trestle/oscal/component.py class State ( Enum ): \"\"\" The operational status. \"\"\" under_development = 'under-development' operational = 'operational' disposition = 'disposition' other = 'other'","title":"State"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.State.disposition","text":"","title":"disposition"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.State.operational","text":"","title":"operational"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.State.other","text":"","title":"other"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.State.under_development","text":"","title":"under_development"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Statement","text":"Identifies which statements within a control are addressed. Source code in trestle/oscal/component.py class Statement ( OscalBaseModel ): \"\"\" Identifies which statements within a control are addressed. \"\"\" class Config : extra = Extra . forbid statement_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'statement-id' , description = 'A human-oriented identifier reference to a control statement.' , title = 'Control Statement Reference' , ) uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this control statement elsewhere in this or other OSCAL instances. The UUID of the control statement in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance).' , title = 'Control Statement Reference Universally Unique Identifier' , ) description : str = Field ( ... , description = 'A summary of how the containing control statement is implemented by the component or capability.' , title = 'Statement Implementation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None","title":"Statement"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Statement-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Statement.description","text":"A summary of how the containing control statement is implemented by the component or capability.","title":"description"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Statement.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Statement.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Statement.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Statement.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Statement.statement_id","text":"A human-oriented identifier reference to a control statement.","title":"statement_id"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Statement.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this control statement elsewhere in this or other OSCAL instances. The UUID of the control statement in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance).","title":"uuid"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Statement.Config","text":"Source code in trestle/oscal/component.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Status","text":"Describes the operational status of the system component. Source code in trestle/oscal/component.py class Status ( OscalBaseModel ): \"\"\" Describes the operational status of the system component. \"\"\" class Config : extra = Extra . forbid state : State = Field ( ... , description = 'The operational status.' , title = 'State' ) remarks : Optional [ common . Remarks ] = None","title":"Status"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Status-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Status.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Status.state","text":"The operational status.","title":"state"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.Status.Config","text":"Source code in trestle/oscal/component.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SystemComponent","text":"A defined component that can be part of an implemented system. Source code in trestle/oscal/component.py class SystemComponent ( OscalBaseModel ): \"\"\" A defined component that can be part of an implemented system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Component Identifier' , ) type : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A category describing the purpose of the component.' , title = 'Component Type' , ) title : str = Field ( ... , description = 'A human readable name for the system component.' , title = 'Component Title' , ) description : str = Field ( ... , description = 'A description of the component, including information about its function.' , title = 'Component Description' , ) purpose : Optional [ str ] = Field ( None , description = 'A summary of the technological or business purpose of the component.' , title = 'Purpose' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : Status = Field ( ... , description = 'Describes the operational status of the system component.' , title = 'Status' , ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) protocols : Optional [ List [ common . Protocol ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None","title":"SystemComponent"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SystemComponent-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SystemComponent.description","text":"A description of the component, including information about its function.","title":"description"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SystemComponent.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SystemComponent.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SystemComponent.protocols","text":"","title":"protocols"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SystemComponent.purpose","text":"A summary of the technological or business purpose of the component.","title":"purpose"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SystemComponent.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SystemComponent.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SystemComponent.status","text":"Describes the operational status of the system component.","title":"status"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SystemComponent.title","text":"A human readable name for the system component.","title":"title"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SystemComponent.type","text":"A category describing the purpose of the component.","title":"type"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SystemComponent.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.component/#trestle.oscal.component.SystemComponent.Config","text":"Source code in trestle/oscal/component.py class Config : extra = Extra . forbid handler: python","title":"Config"},{"location":"api_reference/trestle.oscal.poam/","text":"trestle.oscal.poam \u00a4 Classes \u00a4 Activity ( OscalBaseModel ) pydantic-model \u00a4 Identifies an assessment or related process that can be performed. In the assessment plan, this is an intended activity which may be associated with an assessment task. In the assessment results, this an activity that was actually performed as part of an assessment. Source code in trestle/oscal/poam.py class Activity ( OscalBaseModel ): \"\"\" Identifies an assessment or related process that can be performed. In the assessment plan, this is an intended activity which may be associated with an assessment task. In the assessment results, this an activity that was actually performed as part of an assessment. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment activity elsewhere in this or other OSCAL instances. The locally defined UUID of the activity can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Activity Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this included activity.' , title = 'Included Activity Title' , ) description : str = Field ( ... , description = 'A human-readable description of this included activity.' , title = 'Included Activity Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) steps : Optional [ List [ Step ]] = Field ( None ) related_controls : Optional [ ReviewedControls ] = Field ( None , alias = 'related-controls' ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A human-readable description of this included activity. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 related_controls : ReviewedControls pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 steps : List [ trestle . oscal . poam . Step ] pydantic-field \u00a4 title : str pydantic-field \u00a4 The title for this included activity. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment activity elsewhere in this or other OSCAL instances. The locally defined UUID of the activity can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid AssessmentAssets ( OscalBaseModel ) pydantic-model \u00a4 Identifies the assets used to perform this assessment, such as the assessment team, scanning tools, and assumptions. Source code in trestle/oscal/poam.py class AssessmentAssets ( OscalBaseModel ): \"\"\" Identifies the assets used to perform this assessment, such as the assessment team, scanning tools, and assumptions. \"\"\" class Config : extra = Extra . forbid components : Optional [ List [ SystemComponent ]] = Field ( None ) assessment_platforms : List [ common . AssessmentPlatform ] = Field ( ... , alias = 'assessment-platforms' ) assessment_platforms : List [ trestle . oscal . common . AssessmentPlatform ] pydantic-field required \u00a4 components : List [ trestle . oscal . poam . SystemComponent ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid Characterization ( OscalBaseModel ) pydantic-model \u00a4 A collection of descriptive data about the containing object from a specific origin. Source code in trestle/oscal/poam.py class Characterization ( OscalBaseModel ): \"\"\" A collection of descriptive data about the containing object from a specific origin. \"\"\" class Config : extra = Extra . forbid props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) origin : Origin1 facets : List [ common . Facet ] = Field ( ... ) facets : List [ trestle . oscal . common . Facet ] pydantic-field required \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 origin : Origin1 pydantic-field required \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid ControlSelection ( OscalBaseModel ) pydantic-model \u00a4 Identifies the controls being assessed. In the assessment plan, these are the planned controls. In the assessment results, these are the actual controls, and reflects any changes from the plan. Source code in trestle/oscal/poam.py class ControlSelection ( OscalBaseModel ): \"\"\" Identifies the controls being assessed. In the assessment plan, these are the planned controls. In the assessment results, these are the actual controls, and reflects any changes from the plan. \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'A human-readable description of in-scope controls specified for assessment.' , title = 'Assessed Controls Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) include_all : Optional [ common . IncludeAll ] = Field ( None , alias = 'include-all' ) include_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'include-controls' ) exclude_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'exclude-controls' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field \u00a4 A human-readable description of in-scope controls specified for assessment. exclude_controls : List [ trestle . oscal . poam . SelectControlById ] pydantic-field \u00a4 include_all : IncludeAll pydantic-field \u00a4 include_controls : List [ trestle . oscal . poam . SelectControlById ] pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid Entry ( OscalBaseModel ) pydantic-model \u00a4 Identifies an individual risk response that occurred as part of managing an identified risk. Source code in trestle/oscal/poam.py class Entry ( OscalBaseModel ): \"\"\" Identifies an individual risk response that occurred as part of managing an identified risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk log entry elsewhere in this or other OSCAL instances. The locally defined UUID of the risk log entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Risk Log Entry Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this risk log entry.' , title = 'Title' ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of what was done regarding the risk.' , title = 'Risk Task Description' , ) start : datetime = Field ( ... , description = 'Identifies the start date and time of the event.' , title = 'Start' , ) end : Optional [ datetime ] = Field ( None , description = 'Identifies the end date and time of the event. If the event is a point in time, the start and end will be the same date and time.' , title = 'End' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) logged_by : Optional [ List [ common . LoggedBy ]] = Field ( None , alias = 'logged-by' ) status_change : Optional [ common . RiskStatus ] = Field ( None , alias = 'status-change' ) related_responses : Optional [ List [ common . RelatedResponse ]] = Field ( None , alias = 'related-responses' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field \u00a4 A human-readable description of what was done regarding the risk. end : datetime pydantic-field \u00a4 Identifies the end date and time of the event. If the event is a point in time, the start and end will be the same date and time. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 logged_by : List [ trestle . oscal . common . LoggedBy ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 related_responses : List [ trestle . oscal . common . RelatedResponse ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 start : datetime pydantic-field required \u00a4 Identifies the start date and time of the event. status_change : RiskStatus pydantic-field \u00a4 title : str pydantic-field \u00a4 The title for this risk log entry. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk log entry elsewhere in this or other OSCAL instances. The locally defined UUID of the risk log entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid FindingTarget ( OscalBaseModel ) pydantic-model \u00a4 Captures an assessor's conclusions regarding the degree to which an objective is satisfied. Source code in trestle/oscal/poam.py class FindingTarget ( OscalBaseModel ): \"\"\" Captures an assessor's conclusions regarding the degree to which an objective is satisfied. \"\"\" class Config : extra = Extra . forbid type : common . Type1 = Field ( ... , description = 'Identifies the type of the target.' , title = 'Finding Target Type' , ) target_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'target-id' , description = 'A machine-oriented identifier reference for a specific target qualified by the type.' , title = 'Finding Target Identifier Reference' , ) title : Optional [ str ] = Field ( None , description = 'The title for this objective status.' , title = 'Objective Status Title' , ) description : Optional [ str ] = Field ( None , description = \"A human-readable description of the assessor's conclusions regarding the degree to which an objective is satisfied.\" , title = 'Objective Status Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : Status1 = Field ( ... , description = 'A determination of if the objective is satisfied or not within a given system.' , title = 'Objective Status' , ) implementation_status : Optional [ common . ImplementationStatus ] = Field ( None , alias = 'implementation-status' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field \u00a4 A human-readable description of the assessor's conclusions regarding the degree to which an objective is satisfied. implementation_status : ImplementationStatus pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 status : Status1 pydantic-field required \u00a4 A determination of if the objective is satisfied or not within a given system. target_id : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference for a specific target qualified by the type. title : str pydantic-field \u00a4 The title for this objective status. type : Type1 pydantic-field required \u00a4 Identifies the type of the target. Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid LocalDefinitions ( OscalBaseModel ) pydantic-model \u00a4 Allows components, and inventory-items to be defined within the POA&M for circumstances where no OSCAL-based SSP exists, or is not delivered with the POA&M. Source code in trestle/oscal/poam.py class LocalDefinitions ( OscalBaseModel ): \"\"\" Allows components, and inventory-items to be defined within the POA&M for circumstances where no OSCAL-based SSP exists, or is not delivered with the POA&M. \"\"\" class Config : extra = Extra . forbid components : Optional [ List [ SystemComponent ]] = Field ( None ) inventory_items : Optional [ List [ common . InventoryItem ]] = Field ( None , alias = 'inventory-items' ) remarks : Optional [ common . Remarks ] = None components : List [ trestle . oscal . poam . SystemComponent ] pydantic-field \u00a4 inventory_items : List [ trestle . oscal . common . InventoryItem ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid Method ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/poam.py class Method ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'Identifies how the observation was made.' , title = 'Observation Method' , ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 Identifies how the observation was made. Model ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/poam.py class Model ( OscalBaseModel ): plan_of_action_and_milestones : PlanOfActionAndMilestones = Field ( ... , alias = 'plan-of-action-and-milestones' ) plan_of_action_and_milestones : PlanOfActionAndMilestones pydantic-field required \u00a4 Observation ( OscalBaseModel ) pydantic-model \u00a4 Describes an individual observation. Source code in trestle/oscal/poam.py class Observation ( OscalBaseModel ): \"\"\" Describes an individual observation. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this observation elsewhere in this or other OSCAL instances. The locally defined UUID of the observation can be used to reference the data item locally or globally (e.g., in an imorted OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Observation Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this observation.' , title = 'Observation Title' ) description : str = Field ( ... , description = 'A human-readable description of this assessment observation.' , title = 'Observation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) methods : List [ Method ] = Field ( ... ) types : Optional [ List [ common . Type2 ]] = Field ( None ) origins : Optional [ List [ Origin1 ]] = Field ( None ) subjects : Optional [ List [ common . SubjectReference ]] = Field ( None ) relevant_evidence : Optional [ List [ common . RelevantEvidence ]] = Field ( None , alias = 'relevant-evidence' ) collected : datetime = Field ( ... , description = 'Date/time stamp identifying when the finding information was collected.' , title = 'collected field' , ) expires : Optional [ datetime ] = Field ( None , description = 'Date/time identifying when the finding information is out-of-date and no longer valid. Typically used with continuous assessment scenarios.' , title = 'expires field' , ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 collected : datetime pydantic-field required \u00a4 Date/time stamp identifying when the finding information was collected. description : str pydantic-field required \u00a4 A human-readable description of this assessment observation. expires : datetime pydantic-field \u00a4 Date/time identifying when the finding information is out-of-date and no longer valid. Typically used with continuous assessment scenarios. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 methods : List [ trestle . oscal . poam . Method ] pydantic-field required \u00a4 origins : List [ trestle . oscal . poam . Origin1 ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 relevant_evidence : List [ trestle . oscal . common . RelevantEvidence ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 subjects : List [ trestle . oscal . common . SubjectReference ] pydantic-field \u00a4 title : str pydantic-field \u00a4 The title for this observation. types : List [ trestle . oscal . common . Type2 ] pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this observation elsewhere in this or other OSCAL instances. The locally defined UUID of the observation can be used to reference the data item locally or globally (e.g., in an imorted OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid Origin ( OscalBaseModel ) pydantic-model \u00a4 Identifies the source of the finding, such as a tool or person. Source code in trestle/oscal/poam.py class Origin ( OscalBaseModel ): \"\"\" Identifies the source of the finding, such as a tool or person. \"\"\" class Config : extra = Extra . forbid actors : List [ common . OriginActor ] = Field ( ... ) actors : List [ trestle . oscal . common . OriginActor ] pydantic-field required \u00a4 Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid Origin1 ( OscalBaseModel ) pydantic-model \u00a4 Identifies the source of the finding, such as a tool, interviewed person, or activity. Source code in trestle/oscal/poam.py class Origin1 ( OscalBaseModel ): \"\"\" Identifies the source of the finding, such as a tool, interviewed person, or activity. \"\"\" class Config : extra = Extra . forbid actors : List [ common . OriginActor ] = Field ( ... ) related_tasks : Optional [ List [ common . RelatedTask ]] = Field ( None , alias = 'related-tasks' ) actors : List [ trestle . oscal . common . OriginActor ] pydantic-field required \u00a4 related_tasks : List [ trestle . oscal . common . RelatedTask ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid PlanOfActionAndMilestones ( OscalBaseModel ) pydantic-model \u00a4 A plan of action and milestones which identifies initial and residual risks, deviations, and disposition, such as those required by FedRAMP. Source code in trestle/oscal/poam.py class PlanOfActionAndMilestones ( OscalBaseModel ): \"\"\" A plan of action and milestones which identifies initial and residual risks, deviations, and disposition, such as those required by FedRAMP. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with instancescope that can be used to reference this POA&M instance in this OSCAL instance. This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'POA&M Universally Unique Identifier' , ) metadata : common . Metadata import_ssp : Optional [ common . ImportSsp ] = Field ( None , alias = 'import-ssp' ) system_id : Optional [ common . SystemId ] = Field ( None , alias = 'system-id' ) local_definitions : Optional [ LocalDefinitions ] = Field ( None , alias = 'local-definitions' ) observations : Optional [ List [ Observation ]] = Field ( None ) risks : Optional [ List [ Risk ]] = Field ( None ) poam_items : List [ PoamItem ] = Field ( ... , alias = 'poam-items' ) back_matter : Optional [ common . BackMatter ] = Field ( None , alias = 'back-matter' ) Attributes \u00a4 back_matter : BackMatter pydantic-field \u00a4 import_ssp : ImportSsp pydantic-field \u00a4 local_definitions : LocalDefinitions pydantic-field \u00a4 metadata : Metadata pydantic-field required \u00a4 observations : List [ trestle . oscal . poam . Observation ] pydantic-field \u00a4 poam_items : List [ trestle . oscal . poam . PoamItem ] pydantic-field required \u00a4 risks : List [ trestle . oscal . poam . Risk ] pydantic-field \u00a4 system_id : SystemId pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with instancescope that can be used to reference this POA&M instance in this OSCAL instance. This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid PoamItem ( OscalBaseModel ) pydantic-model \u00a4 Describes an individual POA&M item. Source code in trestle/oscal/poam.py class PoamItem ( OscalBaseModel ): \"\"\" Describes an individual POA&M item. \"\"\" class Config : extra = Extra . forbid uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , description = 'A machine-oriented, globally unique identifier with instance scope that can be used to reference this POA&M item entry in this OSCAL instance. This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'POA&M Item Universally Unique Identifier' , ) title : str = Field ( ... , description = 'The title or name for this POA&M item .' , title = 'POA&M Item Title' , ) description : str = Field ( ... , description = 'A human-readable description of POA&M item.' , title = 'POA&M Item Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) origins : Optional [ List [ Origin ]] = Field ( None ) related_observations : Optional [ List [ RelatedObservation ]] = Field ( None , alias = 'related-observations' ) related_risks : Optional [ List [ common . RelatedRisk ]] = Field ( None , alias = 'related-risks' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A human-readable description of POA&M item. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 origins : List [ trestle . oscal . poam . Origin ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 related_observations : List [ trestle . oscal . poam . RelatedObservation ] pydantic-field \u00a4 related_risks : List [ trestle . oscal . common . RelatedRisk ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 title : str pydantic-field required \u00a4 The title or name for this POA&M item . uuid : ConstrainedStrValue pydantic-field \u00a4 A machine-oriented, globally unique identifier with instance scope that can be used to reference this POA&M item entry in this OSCAL instance. This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid RelatedObservation ( OscalBaseModel ) pydantic-model \u00a4 Relates the poam-item to a set of referenced observations that were used to determine the finding. Source code in trestle/oscal/poam.py class RelatedObservation ( OscalBaseModel ): \"\"\" Relates the poam-item to a set of referenced observations that were used to determine the finding. \"\"\" class Config : extra = Extra . forbid observation_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'observation-uuid' , description = 'A machine-oriented identifier reference to an observation defined in the list of observations.' , title = 'Observation Universally Unique Identifier Reference' , ) Attributes \u00a4 observation_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to an observation defined in the list of observations. Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid Response ( OscalBaseModel ) pydantic-model \u00a4 Describes either recommended or an actual plan for addressing the risk. Source code in trestle/oscal/poam.py class Response ( OscalBaseModel ): \"\"\" Describes either recommended or an actual plan for addressing the risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this remediation elsewhere in this or other OSCAL instances. The locally defined UUID of the risk response can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Remediation Universally Unique Identifier' , ) lifecycle : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Identifies whether this is a recommendation, such as from an assessor or tool, or an actual plan accepted by the system owner.' , title = 'Remediation Intent' , ) title : str = Field ( ... , description = 'The title for this response activity.' , title = 'Response Title' ) description : str = Field ( ... , description = 'A human-readable description of this response plan.' , title = 'Response Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) origins : Optional [ List [ Origin1 ]] = Field ( None ) required_assets : Optional [ List [ common . RequiredAsset ]] = Field ( None , alias = 'required-assets' ) tasks : Optional [ List [ common . Task ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A human-readable description of this response plan. lifecycle : ConstrainedStrValue pydantic-field required \u00a4 Identifies whether this is a recommendation, such as from an assessor or tool, or an actual plan accepted by the system owner. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 origins : List [ trestle . oscal . poam . Origin1 ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 required_assets : List [ trestle . oscal . common . RequiredAsset ] pydantic-field \u00a4 tasks : List [ trestle . oscal . common . Task ] pydantic-field \u00a4 title : str pydantic-field required \u00a4 The title for this response activity. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this remediation elsewhere in this or other OSCAL instances. The locally defined UUID of the risk response can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid ReviewedControls ( OscalBaseModel ) pydantic-model \u00a4 Identifies the controls being assessed and their control objectives. Source code in trestle/oscal/poam.py class ReviewedControls ( OscalBaseModel ): \"\"\" Identifies the controls being assessed and their control objectives. \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'A human-readable description of control objectives.' , title = 'Control Objective Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) control_selections : List [ ControlSelection ] = Field ( ... , alias = 'control-selections' ) control_objective_selections : Optional [ List [ common . ControlObjectiveSelection ]] = Field ( None , alias = 'control-objective-selections' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 control_objective_selections : List [ trestle . oscal . common . ControlObjectiveSelection ] pydantic-field \u00a4 control_selections : List [ trestle . oscal . poam . ControlSelection ] pydantic-field required \u00a4 description : str pydantic-field \u00a4 A human-readable description of control objectives. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid Risk ( OscalBaseModel ) pydantic-model \u00a4 An identified risk. Source code in trestle/oscal/poam.py class Risk ( OscalBaseModel ): \"\"\" An identified risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk elsewhere in this or other OSCAL instances. The locally defined UUID of the risk can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Risk Universally Unique Identifier' , ) title : str = Field ( ... , description = 'The title for this risk.' , title = 'Risk Title' ) description : str = Field ( ... , description = 'A human-readable summary of the identified risk, to include a statement of how the risk impacts the system.' , title = 'Risk Description' , ) statement : str = Field ( ... , description = 'An summary of impact for how the risk affects the system.' , title = 'Risk Statement' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : common . RiskStatus origins : Optional [ List [ Origin1 ]] = Field ( None ) threat_ids : Optional [ List [ common . ThreatId ]] = Field ( None , alias = 'threat-ids' ) characterizations : Optional [ List [ Characterization ]] = Field ( None ) mitigating_factors : Optional [ List [ common . MitigatingFactor ]] = Field ( None , alias = 'mitigating-factors' ) deadline : Optional [ datetime ] = Field ( None , description = 'The date/time by which the risk must be resolved.' , title = 'Risk Resolution Deadline' , ) remediations : Optional [ List [ Response ]] = Field ( None ) risk_log : Optional [ RiskLog ] = Field ( None , alias = 'risk-log' , description = 'A log of all risk-related tasks taken.' , title = 'Risk Log' , ) related_observations : Optional [ List [ common . RelatedObservation1 ]] = Field ( None , alias = 'related-observations' ) Attributes \u00a4 characterizations : List [ trestle . oscal . poam . Characterization ] pydantic-field \u00a4 deadline : datetime pydantic-field \u00a4 The date/time by which the risk must be resolved. description : str pydantic-field required \u00a4 A human-readable summary of the identified risk, to include a statement of how the risk impacts the system. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 mitigating_factors : List [ trestle . oscal . common . MitigatingFactor ] pydantic-field \u00a4 origins : List [ trestle . oscal . poam . Origin1 ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 related_observations : List [ trestle . oscal . common . RelatedObservation1 ] pydantic-field \u00a4 remediations : List [ trestle . oscal . poam . Response ] pydantic-field \u00a4 risk_log : RiskLog pydantic-field \u00a4 A log of all risk-related tasks taken. statement : str pydantic-field required \u00a4 An summary of impact for how the risk affects the system. status : RiskStatus pydantic-field required \u00a4 threat_ids : List [ trestle . oscal . common . ThreatId ] pydantic-field \u00a4 title : str pydantic-field required \u00a4 The title for this risk. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk elsewhere in this or other OSCAL instances. The locally defined UUID of the risk can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid RiskLog ( OscalBaseModel ) pydantic-model \u00a4 A log of all risk-related tasks taken. Source code in trestle/oscal/poam.py class RiskLog ( OscalBaseModel ): \"\"\" A log of all risk-related tasks taken. \"\"\" class Config : extra = Extra . forbid entries : List [ Entry ] = Field ( ... ) entries : List [ trestle . oscal . poam . Entry ] pydantic-field required \u00a4 Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid SelectControlById ( OscalBaseModel ) pydantic-model \u00a4 Used to select a control for inclusion/exclusion based on one or more control identifiers. A set of statement identifiers can be used to target the inclusion/exclusion to only specific control statements providing more granularity over the specific statements that are within the asessment scope. Source code in trestle/oscal/poam.py class SelectControlById ( OscalBaseModel ): \"\"\" Used to select a control for inclusion/exclusion based on one or more control identifiers. A set of statement identifiers can be used to target the inclusion/exclusion to only specific control statements providing more granularity over the specific statements that are within the asessment scope. \"\"\" class Config : extra = Extra . forbid control_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'control-id' , description = 'A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).' , title = 'Control Identifier Reference' , ) statement_ids : Optional [ List [ common . StatementId ]] = Field ( None , alias = 'statement-ids' ) Attributes \u00a4 control_id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference). statement_ids : List [ trestle . oscal . common . StatementId ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid SetParameter ( OscalBaseModel ) pydantic-model \u00a4 Identifies the parameter that will be set by the enclosed value. Source code in trestle/oscal/poam.py class SetParameter ( OscalBaseModel ): \"\"\" Identifies the parameter that will be set by the enclosed value. \"\"\" class Config : extra = Extra . forbid param_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'param-id' , description = \"A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context.\" , title = 'Parameter ID' , ) values : List [ common . Value ] = Field ( ... ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 param_id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context. remarks : Remarks pydantic-field \u00a4 values : List [ trestle . oscal . common . Value ] pydantic-field required \u00a4 Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid State ( Enum ) \u00a4 The operational status. Source code in trestle/oscal/poam.py class State ( Enum ): \"\"\" The operational status. \"\"\" under_development = 'under-development' operational = 'operational' disposition = 'disposition' other = 'other' disposition \u00a4 operational \u00a4 other \u00a4 under_development \u00a4 State1 ( Enum ) \u00a4 An indication as to whether the objective is satisfied or not. Source code in trestle/oscal/poam.py class State1 ( Enum ): \"\"\" An indication as to whether the objective is satisfied or not. \"\"\" satisfied = 'satisfied' not_satisfied = 'not-satisfied' not_satisfied \u00a4 satisfied \u00a4 Status ( OscalBaseModel ) pydantic-model \u00a4 Describes the operational status of the system component. Source code in trestle/oscal/poam.py class Status ( OscalBaseModel ): \"\"\" Describes the operational status of the system component. \"\"\" class Config : extra = Extra . forbid state : State = Field ( ... , description = 'The operational status.' , title = 'State' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 remarks : Remarks pydantic-field \u00a4 state : State pydantic-field required \u00a4 The operational status. Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid Status1 ( OscalBaseModel ) pydantic-model \u00a4 A determination of if the objective is satisfied or not within a given system. Source code in trestle/oscal/poam.py class Status1 ( OscalBaseModel ): \"\"\" A determination of if the objective is satisfied or not within a given system. \"\"\" class Config : extra = Extra . forbid state : State1 = Field ( ... , description = 'An indication as to whether the objective is satisfied or not.' , title = 'Objective Status State' , ) reason : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , description = \"The reason the objective was given it's status.\" , title = 'Objective Status Reason' , ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 reason : ConstrainedStrValue pydantic-field \u00a4 The reason the objective was given it's status. remarks : Remarks pydantic-field \u00a4 state : State1 pydantic-field required \u00a4 An indication as to whether the objective is satisfied or not. Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid Step ( OscalBaseModel ) pydantic-model \u00a4 Identifies an individual step in a series of steps related to an activity, such as an assessment test or examination procedure. Source code in trestle/oscal/poam.py class Step ( OscalBaseModel ): \"\"\" Identifies an individual step in a series of steps related to an activity, such as an assessment test or examination procedure. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this step elsewhere in this or other OSCAL instances. The locally defined UUID of the step (in a series of steps) can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Step Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this step.' , title = 'Step Title' ) description : str = Field ( ... , description = 'A human-readable description of this step.' , title = 'Step Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) reviewed_controls : Optional [ ReviewedControls ] = Field ( None , alias = 'reviewed-controls' ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A human-readable description of this step. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 reviewed_controls : ReviewedControls pydantic-field \u00a4 title : str pydantic-field \u00a4 The title for this step. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this step elsewhere in this or other OSCAL instances. The locally defined UUID of the step (in a series of steps) can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid SystemComponent ( OscalBaseModel ) pydantic-model \u00a4 A defined component that can be part of an implemented system. Source code in trestle/oscal/poam.py class SystemComponent ( OscalBaseModel ): \"\"\" A defined component that can be part of an implemented system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Component Identifier' , ) type : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A category describing the purpose of the component.' , title = 'Component Type' , ) title : str = Field ( ... , description = 'A human readable name for the system component.' , title = 'Component Title' , ) description : str = Field ( ... , description = 'A description of the component, including information about its function.' , title = 'Component Description' , ) purpose : Optional [ str ] = Field ( None , description = 'A summary of the technological or business purpose of the component.' , title = 'Purpose' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : Status = Field ( ... , description = 'Describes the operational status of the system component.' , title = 'Status' , ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) protocols : Optional [ List [ common . Protocol ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A description of the component, including information about its function. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 protocols : List [ trestle . oscal . common . Protocol ] pydantic-field \u00a4 purpose : str pydantic-field \u00a4 A summary of the technological or business purpose of the component. remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 status : Status pydantic-field required \u00a4 Describes the operational status of the system component. title : str pydantic-field required \u00a4 A human readable name for the system component. type : ConstrainedStrValue pydantic-field required \u00a4 A category describing the purpose of the component. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid handler: python","title":"poam"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam","text":"","title":"poam"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Activity","text":"Identifies an assessment or related process that can be performed. In the assessment plan, this is an intended activity which may be associated with an assessment task. In the assessment results, this an activity that was actually performed as part of an assessment. Source code in trestle/oscal/poam.py class Activity ( OscalBaseModel ): \"\"\" Identifies an assessment or related process that can be performed. In the assessment plan, this is an intended activity which may be associated with an assessment task. In the assessment results, this an activity that was actually performed as part of an assessment. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment activity elsewhere in this or other OSCAL instances. The locally defined UUID of the activity can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Assessment Activity Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this included activity.' , title = 'Included Activity Title' , ) description : str = Field ( ... , description = 'A human-readable description of this included activity.' , title = 'Included Activity Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) steps : Optional [ List [ Step ]] = Field ( None ) related_controls : Optional [ ReviewedControls ] = Field ( None , alias = 'related-controls' ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None","title":"Activity"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Activity-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Activity.description","text":"A human-readable description of this included activity.","title":"description"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Activity.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Activity.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Activity.related_controls","text":"","title":"related_controls"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Activity.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Activity.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Activity.steps","text":"","title":"steps"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Activity.title","text":"The title for this included activity.","title":"title"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Activity.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this assessment activity elsewhere in this or other OSCAL instances. The locally defined UUID of the activity can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Activity.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.AssessmentAssets","text":"Identifies the assets used to perform this assessment, such as the assessment team, scanning tools, and assumptions. Source code in trestle/oscal/poam.py class AssessmentAssets ( OscalBaseModel ): \"\"\" Identifies the assets used to perform this assessment, such as the assessment team, scanning tools, and assumptions. \"\"\" class Config : extra = Extra . forbid components : Optional [ List [ SystemComponent ]] = Field ( None ) assessment_platforms : List [ common . AssessmentPlatform ] = Field ( ... , alias = 'assessment-platforms' )","title":"AssessmentAssets"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.AssessmentAssets.assessment_platforms","text":"","title":"assessment_platforms"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.AssessmentAssets.components","text":"","title":"components"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.AssessmentAssets.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Characterization","text":"A collection of descriptive data about the containing object from a specific origin. Source code in trestle/oscal/poam.py class Characterization ( OscalBaseModel ): \"\"\" A collection of descriptive data about the containing object from a specific origin. \"\"\" class Config : extra = Extra . forbid props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) origin : Origin1 facets : List [ common . Facet ] = Field ( ... )","title":"Characterization"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Characterization.facets","text":"","title":"facets"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Characterization.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Characterization.origin","text":"","title":"origin"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Characterization.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Characterization.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ControlSelection","text":"Identifies the controls being assessed. In the assessment plan, these are the planned controls. In the assessment results, these are the actual controls, and reflects any changes from the plan. Source code in trestle/oscal/poam.py class ControlSelection ( OscalBaseModel ): \"\"\" Identifies the controls being assessed. In the assessment plan, these are the planned controls. In the assessment results, these are the actual controls, and reflects any changes from the plan. \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'A human-readable description of in-scope controls specified for assessment.' , title = 'Assessed Controls Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) include_all : Optional [ common . IncludeAll ] = Field ( None , alias = 'include-all' ) include_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'include-controls' ) exclude_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'exclude-controls' ) remarks : Optional [ common . Remarks ] = None","title":"ControlSelection"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ControlSelection-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ControlSelection.description","text":"A human-readable description of in-scope controls specified for assessment.","title":"description"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ControlSelection.exclude_controls","text":"","title":"exclude_controls"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ControlSelection.include_all","text":"","title":"include_all"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ControlSelection.include_controls","text":"","title":"include_controls"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ControlSelection.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ControlSelection.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ControlSelection.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ControlSelection.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Entry","text":"Identifies an individual risk response that occurred as part of managing an identified risk. Source code in trestle/oscal/poam.py class Entry ( OscalBaseModel ): \"\"\" Identifies an individual risk response that occurred as part of managing an identified risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk log entry elsewhere in this or other OSCAL instances. The locally defined UUID of the risk log entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Risk Log Entry Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this risk log entry.' , title = 'Title' ) description : Optional [ str ] = Field ( None , description = 'A human-readable description of what was done regarding the risk.' , title = 'Risk Task Description' , ) start : datetime = Field ( ... , description = 'Identifies the start date and time of the event.' , title = 'Start' , ) end : Optional [ datetime ] = Field ( None , description = 'Identifies the end date and time of the event. If the event is a point in time, the start and end will be the same date and time.' , title = 'End' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) logged_by : Optional [ List [ common . LoggedBy ]] = Field ( None , alias = 'logged-by' ) status_change : Optional [ common . RiskStatus ] = Field ( None , alias = 'status-change' ) related_responses : Optional [ List [ common . RelatedResponse ]] = Field ( None , alias = 'related-responses' ) remarks : Optional [ common . Remarks ] = None","title":"Entry"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Entry-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Entry.description","text":"A human-readable description of what was done regarding the risk.","title":"description"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Entry.end","text":"Identifies the end date and time of the event. If the event is a point in time, the start and end will be the same date and time.","title":"end"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Entry.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Entry.logged_by","text":"","title":"logged_by"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Entry.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Entry.related_responses","text":"","title":"related_responses"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Entry.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Entry.start","text":"Identifies the start date and time of the event.","title":"start"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Entry.status_change","text":"","title":"status_change"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Entry.title","text":"The title for this risk log entry.","title":"title"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Entry.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk log entry elsewhere in this or other OSCAL instances. The locally defined UUID of the risk log entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Entry.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.FindingTarget","text":"Captures an assessor's conclusions regarding the degree to which an objective is satisfied. Source code in trestle/oscal/poam.py class FindingTarget ( OscalBaseModel ): \"\"\" Captures an assessor's conclusions regarding the degree to which an objective is satisfied. \"\"\" class Config : extra = Extra . forbid type : common . Type1 = Field ( ... , description = 'Identifies the type of the target.' , title = 'Finding Target Type' , ) target_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'target-id' , description = 'A machine-oriented identifier reference for a specific target qualified by the type.' , title = 'Finding Target Identifier Reference' , ) title : Optional [ str ] = Field ( None , description = 'The title for this objective status.' , title = 'Objective Status Title' , ) description : Optional [ str ] = Field ( None , description = \"A human-readable description of the assessor's conclusions regarding the degree to which an objective is satisfied.\" , title = 'Objective Status Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : Status1 = Field ( ... , description = 'A determination of if the objective is satisfied or not within a given system.' , title = 'Objective Status' , ) implementation_status : Optional [ common . ImplementationStatus ] = Field ( None , alias = 'implementation-status' ) remarks : Optional [ common . Remarks ] = None","title":"FindingTarget"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.FindingTarget-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.FindingTarget.description","text":"A human-readable description of the assessor's conclusions regarding the degree to which an objective is satisfied.","title":"description"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.FindingTarget.implementation_status","text":"","title":"implementation_status"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.FindingTarget.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.FindingTarget.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.FindingTarget.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.FindingTarget.status","text":"A determination of if the objective is satisfied or not within a given system.","title":"status"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.FindingTarget.target_id","text":"A machine-oriented identifier reference for a specific target qualified by the type.","title":"target_id"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.FindingTarget.title","text":"The title for this objective status.","title":"title"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.FindingTarget.type","text":"Identifies the type of the target.","title":"type"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.FindingTarget.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.LocalDefinitions","text":"Allows components, and inventory-items to be defined within the POA&M for circumstances where no OSCAL-based SSP exists, or is not delivered with the POA&M. Source code in trestle/oscal/poam.py class LocalDefinitions ( OscalBaseModel ): \"\"\" Allows components, and inventory-items to be defined within the POA&M for circumstances where no OSCAL-based SSP exists, or is not delivered with the POA&M. \"\"\" class Config : extra = Extra . forbid components : Optional [ List [ SystemComponent ]] = Field ( None ) inventory_items : Optional [ List [ common . InventoryItem ]] = Field ( None , alias = 'inventory-items' ) remarks : Optional [ common . Remarks ] = None","title":"LocalDefinitions"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.LocalDefinitions.components","text":"","title":"components"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.LocalDefinitions.inventory_items","text":"","title":"inventory_items"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.LocalDefinitions.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.LocalDefinitions.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Method","text":"Source code in trestle/oscal/poam.py class Method ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'Identifies how the observation was made.' , title = 'Observation Method' , )","title":"Method"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Method-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Method.__root__","text":"Identifies how the observation was made.","title":"__root__"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Model","text":"Source code in trestle/oscal/poam.py class Model ( OscalBaseModel ): plan_of_action_and_milestones : PlanOfActionAndMilestones = Field ( ... , alias = 'plan-of-action-and-milestones' )","title":"Model"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Model.plan_of_action_and_milestones","text":"","title":"plan_of_action_and_milestones"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Observation","text":"Describes an individual observation. Source code in trestle/oscal/poam.py class Observation ( OscalBaseModel ): \"\"\" Describes an individual observation. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this observation elsewhere in this or other OSCAL instances. The locally defined UUID of the observation can be used to reference the data item locally or globally (e.g., in an imorted OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Observation Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this observation.' , title = 'Observation Title' ) description : str = Field ( ... , description = 'A human-readable description of this assessment observation.' , title = 'Observation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) methods : List [ Method ] = Field ( ... ) types : Optional [ List [ common . Type2 ]] = Field ( None ) origins : Optional [ List [ Origin1 ]] = Field ( None ) subjects : Optional [ List [ common . SubjectReference ]] = Field ( None ) relevant_evidence : Optional [ List [ common . RelevantEvidence ]] = Field ( None , alias = 'relevant-evidence' ) collected : datetime = Field ( ... , description = 'Date/time stamp identifying when the finding information was collected.' , title = 'collected field' , ) expires : Optional [ datetime ] = Field ( None , description = 'Date/time identifying when the finding information is out-of-date and no longer valid. Typically used with continuous assessment scenarios.' , title = 'expires field' , ) remarks : Optional [ common . Remarks ] = None","title":"Observation"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Observation-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Observation.collected","text":"Date/time stamp identifying when the finding information was collected.","title":"collected"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Observation.description","text":"A human-readable description of this assessment observation.","title":"description"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Observation.expires","text":"Date/time identifying when the finding information is out-of-date and no longer valid. Typically used with continuous assessment scenarios.","title":"expires"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Observation.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Observation.methods","text":"","title":"methods"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Observation.origins","text":"","title":"origins"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Observation.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Observation.relevant_evidence","text":"","title":"relevant_evidence"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Observation.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Observation.subjects","text":"","title":"subjects"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Observation.title","text":"The title for this observation.","title":"title"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Observation.types","text":"","title":"types"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Observation.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this observation elsewhere in this or other OSCAL instances. The locally defined UUID of the observation can be used to reference the data item locally or globally (e.g., in an imorted OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Observation.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Origin","text":"Identifies the source of the finding, such as a tool or person. Source code in trestle/oscal/poam.py class Origin ( OscalBaseModel ): \"\"\" Identifies the source of the finding, such as a tool or person. \"\"\" class Config : extra = Extra . forbid actors : List [ common . OriginActor ] = Field ( ... )","title":"Origin"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Origin.actors","text":"","title":"actors"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Origin.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Origin1","text":"Identifies the source of the finding, such as a tool, interviewed person, or activity. Source code in trestle/oscal/poam.py class Origin1 ( OscalBaseModel ): \"\"\" Identifies the source of the finding, such as a tool, interviewed person, or activity. \"\"\" class Config : extra = Extra . forbid actors : List [ common . OriginActor ] = Field ( ... ) related_tasks : Optional [ List [ common . RelatedTask ]] = Field ( None , alias = 'related-tasks' )","title":"Origin1"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Origin1.actors","text":"","title":"actors"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Origin1.related_tasks","text":"","title":"related_tasks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Origin1.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PlanOfActionAndMilestones","text":"A plan of action and milestones which identifies initial and residual risks, deviations, and disposition, such as those required by FedRAMP. Source code in trestle/oscal/poam.py class PlanOfActionAndMilestones ( OscalBaseModel ): \"\"\" A plan of action and milestones which identifies initial and residual risks, deviations, and disposition, such as those required by FedRAMP. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with instancescope that can be used to reference this POA&M instance in this OSCAL instance. This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'POA&M Universally Unique Identifier' , ) metadata : common . Metadata import_ssp : Optional [ common . ImportSsp ] = Field ( None , alias = 'import-ssp' ) system_id : Optional [ common . SystemId ] = Field ( None , alias = 'system-id' ) local_definitions : Optional [ LocalDefinitions ] = Field ( None , alias = 'local-definitions' ) observations : Optional [ List [ Observation ]] = Field ( None ) risks : Optional [ List [ Risk ]] = Field ( None ) poam_items : List [ PoamItem ] = Field ( ... , alias = 'poam-items' ) back_matter : Optional [ common . BackMatter ] = Field ( None , alias = 'back-matter' )","title":"PlanOfActionAndMilestones"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PlanOfActionAndMilestones-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PlanOfActionAndMilestones.back_matter","text":"","title":"back_matter"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PlanOfActionAndMilestones.import_ssp","text":"","title":"import_ssp"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PlanOfActionAndMilestones.local_definitions","text":"","title":"local_definitions"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PlanOfActionAndMilestones.metadata","text":"","title":"metadata"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PlanOfActionAndMilestones.observations","text":"","title":"observations"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PlanOfActionAndMilestones.poam_items","text":"","title":"poam_items"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PlanOfActionAndMilestones.risks","text":"","title":"risks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PlanOfActionAndMilestones.system_id","text":"","title":"system_id"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PlanOfActionAndMilestones.uuid","text":"A machine-oriented, globally unique identifier with instancescope that can be used to reference this POA&M instance in this OSCAL instance. This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PlanOfActionAndMilestones.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PoamItem","text":"Describes an individual POA&M item. Source code in trestle/oscal/poam.py class PoamItem ( OscalBaseModel ): \"\"\" Describes an individual POA&M item. \"\"\" class Config : extra = Extra . forbid uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , description = 'A machine-oriented, globally unique identifier with instance scope that can be used to reference this POA&M item entry in this OSCAL instance. This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'POA&M Item Universally Unique Identifier' , ) title : str = Field ( ... , description = 'The title or name for this POA&M item .' , title = 'POA&M Item Title' , ) description : str = Field ( ... , description = 'A human-readable description of POA&M item.' , title = 'POA&M Item Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) origins : Optional [ List [ Origin ]] = Field ( None ) related_observations : Optional [ List [ RelatedObservation ]] = Field ( None , alias = 'related-observations' ) related_risks : Optional [ List [ common . RelatedRisk ]] = Field ( None , alias = 'related-risks' ) remarks : Optional [ common . Remarks ] = None","title":"PoamItem"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PoamItem-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PoamItem.description","text":"A human-readable description of POA&M item.","title":"description"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PoamItem.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PoamItem.origins","text":"","title":"origins"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PoamItem.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PoamItem.related_observations","text":"","title":"related_observations"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PoamItem.related_risks","text":"","title":"related_risks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PoamItem.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PoamItem.title","text":"The title or name for this POA&M item .","title":"title"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PoamItem.uuid","text":"A machine-oriented, globally unique identifier with instance scope that can be used to reference this POA&M item entry in this OSCAL instance. This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.PoamItem.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.RelatedObservation","text":"Relates the poam-item to a set of referenced observations that were used to determine the finding. Source code in trestle/oscal/poam.py class RelatedObservation ( OscalBaseModel ): \"\"\" Relates the poam-item to a set of referenced observations that were used to determine the finding. \"\"\" class Config : extra = Extra . forbid observation_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'observation-uuid' , description = 'A machine-oriented identifier reference to an observation defined in the list of observations.' , title = 'Observation Universally Unique Identifier Reference' , )","title":"RelatedObservation"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.RelatedObservation-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.RelatedObservation.observation_uuid","text":"A machine-oriented identifier reference to an observation defined in the list of observations.","title":"observation_uuid"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.RelatedObservation.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Response","text":"Describes either recommended or an actual plan for addressing the risk. Source code in trestle/oscal/poam.py class Response ( OscalBaseModel ): \"\"\" Describes either recommended or an actual plan for addressing the risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this remediation elsewhere in this or other OSCAL instances. The locally defined UUID of the risk response can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Remediation Universally Unique Identifier' , ) lifecycle : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = 'Identifies whether this is a recommendation, such as from an assessor or tool, or an actual plan accepted by the system owner.' , title = 'Remediation Intent' , ) title : str = Field ( ... , description = 'The title for this response activity.' , title = 'Response Title' ) description : str = Field ( ... , description = 'A human-readable description of this response plan.' , title = 'Response Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) origins : Optional [ List [ Origin1 ]] = Field ( None ) required_assets : Optional [ List [ common . RequiredAsset ]] = Field ( None , alias = 'required-assets' ) tasks : Optional [ List [ common . Task ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None","title":"Response"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Response-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Response.description","text":"A human-readable description of this response plan.","title":"description"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Response.lifecycle","text":"Identifies whether this is a recommendation, such as from an assessor or tool, or an actual plan accepted by the system owner.","title":"lifecycle"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Response.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Response.origins","text":"","title":"origins"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Response.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Response.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Response.required_assets","text":"","title":"required_assets"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Response.tasks","text":"","title":"tasks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Response.title","text":"The title for this response activity.","title":"title"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Response.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this remediation elsewhere in this or other OSCAL instances. The locally defined UUID of the risk response can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Response.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ReviewedControls","text":"Identifies the controls being assessed and their control objectives. Source code in trestle/oscal/poam.py class ReviewedControls ( OscalBaseModel ): \"\"\" Identifies the controls being assessed and their control objectives. \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'A human-readable description of control objectives.' , title = 'Control Objective Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) control_selections : List [ ControlSelection ] = Field ( ... , alias = 'control-selections' ) control_objective_selections : Optional [ List [ common . ControlObjectiveSelection ]] = Field ( None , alias = 'control-objective-selections' ) remarks : Optional [ common . Remarks ] = None","title":"ReviewedControls"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ReviewedControls-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ReviewedControls.control_objective_selections","text":"","title":"control_objective_selections"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ReviewedControls.control_selections","text":"","title":"control_selections"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ReviewedControls.description","text":"A human-readable description of control objectives.","title":"description"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ReviewedControls.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ReviewedControls.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ReviewedControls.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.ReviewedControls.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk","text":"An identified risk. Source code in trestle/oscal/poam.py class Risk ( OscalBaseModel ): \"\"\" An identified risk. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk elsewhere in this or other OSCAL instances. The locally defined UUID of the risk can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Risk Universally Unique Identifier' , ) title : str = Field ( ... , description = 'The title for this risk.' , title = 'Risk Title' ) description : str = Field ( ... , description = 'A human-readable summary of the identified risk, to include a statement of how the risk impacts the system.' , title = 'Risk Description' , ) statement : str = Field ( ... , description = 'An summary of impact for how the risk affects the system.' , title = 'Risk Statement' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : common . RiskStatus origins : Optional [ List [ Origin1 ]] = Field ( None ) threat_ids : Optional [ List [ common . ThreatId ]] = Field ( None , alias = 'threat-ids' ) characterizations : Optional [ List [ Characterization ]] = Field ( None ) mitigating_factors : Optional [ List [ common . MitigatingFactor ]] = Field ( None , alias = 'mitigating-factors' ) deadline : Optional [ datetime ] = Field ( None , description = 'The date/time by which the risk must be resolved.' , title = 'Risk Resolution Deadline' , ) remediations : Optional [ List [ Response ]] = Field ( None ) risk_log : Optional [ RiskLog ] = Field ( None , alias = 'risk-log' , description = 'A log of all risk-related tasks taken.' , title = 'Risk Log' , ) related_observations : Optional [ List [ common . RelatedObservation1 ]] = Field ( None , alias = 'related-observations' )","title":"Risk"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk.characterizations","text":"","title":"characterizations"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk.deadline","text":"The date/time by which the risk must be resolved.","title":"deadline"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk.description","text":"A human-readable summary of the identified risk, to include a statement of how the risk impacts the system.","title":"description"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk.mitigating_factors","text":"","title":"mitigating_factors"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk.origins","text":"","title":"origins"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk.related_observations","text":"","title":"related_observations"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk.remediations","text":"","title":"remediations"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk.risk_log","text":"A log of all risk-related tasks taken.","title":"risk_log"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk.statement","text":"An summary of impact for how the risk affects the system.","title":"statement"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk.status","text":"","title":"status"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk.threat_ids","text":"","title":"threat_ids"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk.title","text":"The title for this risk.","title":"title"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this risk elsewhere in this or other OSCAL instances. The locally defined UUID of the risk can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Risk.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.RiskLog","text":"A log of all risk-related tasks taken. Source code in trestle/oscal/poam.py class RiskLog ( OscalBaseModel ): \"\"\" A log of all risk-related tasks taken. \"\"\" class Config : extra = Extra . forbid entries : List [ Entry ] = Field ( ... )","title":"RiskLog"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.RiskLog.entries","text":"","title":"entries"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.RiskLog.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SelectControlById","text":"Used to select a control for inclusion/exclusion based on one or more control identifiers. A set of statement identifiers can be used to target the inclusion/exclusion to only specific control statements providing more granularity over the specific statements that are within the asessment scope. Source code in trestle/oscal/poam.py class SelectControlById ( OscalBaseModel ): \"\"\" Used to select a control for inclusion/exclusion based on one or more control identifiers. A set of statement identifiers can be used to target the inclusion/exclusion to only specific control statements providing more granularity over the specific statements that are within the asessment scope. \"\"\" class Config : extra = Extra . forbid control_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'control-id' , description = 'A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).' , title = 'Control Identifier Reference' , ) statement_ids : Optional [ List [ common . StatementId ]] = Field ( None , alias = 'statement-ids' )","title":"SelectControlById"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SelectControlById-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SelectControlById.control_id","text":"A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).","title":"control_id"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SelectControlById.statement_ids","text":"","title":"statement_ids"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SelectControlById.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SetParameter","text":"Identifies the parameter that will be set by the enclosed value. Source code in trestle/oscal/poam.py class SetParameter ( OscalBaseModel ): \"\"\" Identifies the parameter that will be set by the enclosed value. \"\"\" class Config : extra = Extra . forbid param_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'param-id' , description = \"A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context.\" , title = 'Parameter ID' , ) values : List [ common . Value ] = Field ( ... ) remarks : Optional [ common . Remarks ] = None","title":"SetParameter"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SetParameter-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SetParameter.param_id","text":"A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context.","title":"param_id"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SetParameter.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SetParameter.values","text":"","title":"values"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SetParameter.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.State","text":"The operational status. Source code in trestle/oscal/poam.py class State ( Enum ): \"\"\" The operational status. \"\"\" under_development = 'under-development' operational = 'operational' disposition = 'disposition' other = 'other'","title":"State"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.State.disposition","text":"","title":"disposition"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.State.operational","text":"","title":"operational"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.State.other","text":"","title":"other"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.State.under_development","text":"","title":"under_development"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.State1","text":"An indication as to whether the objective is satisfied or not. Source code in trestle/oscal/poam.py class State1 ( Enum ): \"\"\" An indication as to whether the objective is satisfied or not. \"\"\" satisfied = 'satisfied' not_satisfied = 'not-satisfied'","title":"State1"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.State1.not_satisfied","text":"","title":"not_satisfied"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.State1.satisfied","text":"","title":"satisfied"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Status","text":"Describes the operational status of the system component. Source code in trestle/oscal/poam.py class Status ( OscalBaseModel ): \"\"\" Describes the operational status of the system component. \"\"\" class Config : extra = Extra . forbid state : State = Field ( ... , description = 'The operational status.' , title = 'State' ) remarks : Optional [ common . Remarks ] = None","title":"Status"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Status-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Status.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Status.state","text":"The operational status.","title":"state"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Status.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Status1","text":"A determination of if the objective is satisfied or not within a given system. Source code in trestle/oscal/poam.py class Status1 ( OscalBaseModel ): \"\"\" A determination of if the objective is satisfied or not within a given system. \"\"\" class Config : extra = Extra . forbid state : State1 = Field ( ... , description = 'An indication as to whether the objective is satisfied or not.' , title = 'Objective Status State' , ) reason : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , description = \"The reason the objective was given it's status.\" , title = 'Objective Status Reason' , ) remarks : Optional [ common . Remarks ] = None","title":"Status1"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Status1-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Status1.reason","text":"The reason the objective was given it's status.","title":"reason"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Status1.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Status1.state","text":"An indication as to whether the objective is satisfied or not.","title":"state"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Status1.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Step","text":"Identifies an individual step in a series of steps related to an activity, such as an assessment test or examination procedure. Source code in trestle/oscal/poam.py class Step ( OscalBaseModel ): \"\"\" Identifies an individual step in a series of steps related to an activity, such as an assessment test or examination procedure. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this step elsewhere in this or other OSCAL instances. The locally defined UUID of the step (in a series of steps) can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Step Universally Unique Identifier' , ) title : Optional [ str ] = Field ( None , description = 'The title for this step.' , title = 'Step Title' ) description : str = Field ( ... , description = 'A human-readable description of this step.' , title = 'Step Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) reviewed_controls : Optional [ ReviewedControls ] = Field ( None , alias = 'reviewed-controls' ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None","title":"Step"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Step-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Step.description","text":"A human-readable description of this step.","title":"description"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Step.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Step.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Step.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Step.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Step.reviewed_controls","text":"","title":"reviewed_controls"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Step.title","text":"The title for this step.","title":"title"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Step.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this step elsewhere in this or other OSCAL instances. The locally defined UUID of the step (in a series of steps) can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.Step.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SystemComponent","text":"A defined component that can be part of an implemented system. Source code in trestle/oscal/poam.py class SystemComponent ( OscalBaseModel ): \"\"\" A defined component that can be part of an implemented system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Component Identifier' , ) type : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A category describing the purpose of the component.' , title = 'Component Type' , ) title : str = Field ( ... , description = 'A human readable name for the system component.' , title = 'Component Title' , ) description : str = Field ( ... , description = 'A description of the component, including information about its function.' , title = 'Component Description' , ) purpose : Optional [ str ] = Field ( None , description = 'A summary of the technological or business purpose of the component.' , title = 'Purpose' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : Status = Field ( ... , description = 'Describes the operational status of the system component.' , title = 'Status' , ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) protocols : Optional [ List [ common . Protocol ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None","title":"SystemComponent"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SystemComponent-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SystemComponent.description","text":"A description of the component, including information about its function.","title":"description"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SystemComponent.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SystemComponent.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SystemComponent.protocols","text":"","title":"protocols"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SystemComponent.purpose","text":"A summary of the technological or business purpose of the component.","title":"purpose"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SystemComponent.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SystemComponent.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SystemComponent.status","text":"Describes the operational status of the system component.","title":"status"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SystemComponent.title","text":"A human readable name for the system component.","title":"title"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SystemComponent.type","text":"A category describing the purpose of the component.","title":"type"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SystemComponent.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.poam/#trestle.oscal.poam.SystemComponent.Config","text":"Source code in trestle/oscal/poam.py class Config : extra = Extra . forbid handler: python","title":"Config"},{"location":"api_reference/trestle.oscal.profile/","text":"trestle.oscal.profile \u00a4 Classes \u00a4 Add ( OscalBaseModel ) pydantic-model \u00a4 Specifies contents to be added into controls, in resolution Source code in trestle/oscal/profile.py class Add ( OscalBaseModel ): \"\"\" Specifies contents to be added into controls, in resolution \"\"\" class Config : extra = Extra . forbid position : Optional [ Position ] = Field ( None , description = 'Where to add the new content with respect to the targeted element (beside it or inside it)' , title = 'Position' , ) by_id : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'by-id' , description = 'Target location of the addition.' , title = 'Reference by ID' , ) title : Optional [ str ] = Field ( None , description = 'A name given to the control, which may be used by a tool for display and navigation.' , title = 'Title Change' , ) params : Optional [ List [ common . Parameter ]] = Field ( None ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) parts : Optional [ List [ common . Part ]] = Field ( None ) Attributes \u00a4 by_id : ConstrainedStrValue pydantic-field \u00a4 Target location of the addition. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 params : List [ trestle . oscal . common . Parameter ] pydantic-field \u00a4 parts : List [ trestle . oscal . common . Part ] pydantic-field \u00a4 position : Position pydantic-field \u00a4 Where to add the new content with respect to the targeted element (beside it or inside it) props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 title : str pydantic-field \u00a4 A name given to the control, which may be used by a tool for display and navigation. Config \u00a4 Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid Alter ( OscalBaseModel ) pydantic-model \u00a4 An Alter element specifies changes to be made to an included control when a profile is resolved. Source code in trestle/oscal/profile.py class Alter ( OscalBaseModel ): \"\"\" An Alter element specifies changes to be made to an included control when a profile is resolved. \"\"\" class Config : extra = Extra . forbid control_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'control-id' , description = 'A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).' , title = 'Control Identifier Reference' , ) removes : Optional [ List [ Remove ]] = Field ( None ) adds : Optional [ List [ Add ]] = Field ( None ) Attributes \u00a4 adds : List [ trestle . oscal . profile . Add ] pydantic-field \u00a4 control_id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference). removes : List [ trestle . oscal . profile . Remove ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid Combine ( OscalBaseModel ) pydantic-model \u00a4 A Combine element defines how to combine multiple (competing) versions of the same control. Source code in trestle/oscal/profile.py class Combine ( OscalBaseModel ): \"\"\" A Combine element defines how to combine multiple (competing) versions of the same control. \"\"\" class Config : extra = Extra . forbid method : Optional [ Method ] = Field ( None , description = 'How clashing controls should be handled' , title = 'Combination method' , ) Attributes \u00a4 method : Method pydantic-field \u00a4 How clashing controls should be handled Config \u00a4 Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid Custom ( OscalBaseModel ) pydantic-model \u00a4 A Custom element frames a structure for embedding represented controls in resolution. Source code in trestle/oscal/profile.py class Custom ( OscalBaseModel ): \"\"\" A Custom element frames a structure for embedding represented controls in resolution. \"\"\" class Config : extra = Extra . forbid groups : Optional [ List [ Group ]] = Field ( None ) insert_controls : Optional [ List [ InsertControls ]] = Field ( None , alias = 'insert-controls' ) groups : List [ trestle . oscal . profile . Group ] pydantic-field \u00a4 insert_controls : List [ trestle . oscal . profile . InsertControls ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid Group ( OscalBaseModel ) pydantic-model \u00a4 A group of (selected) controls or of groups of controls Source code in trestle/oscal/profile.py class Group ( OscalBaseModel ): \"\"\" A group of (selected) controls or of groups of controls \"\"\" class Config : extra = Extra . forbid id : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , description = 'A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined group elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, this identifier must be referenced in the context of the containing resource (e.g., import-profile). This id should be assigned per-subject, which means it should be consistently used to identify the same group across revisions of the document.' , title = 'Group Identifier' , ) class_ : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'class' , description = 'A textual label that provides a sub-type or characterization of the group.' , title = 'Group Class' , ) title : str = Field ( ... , description = 'A name given to the group, which may be used by a tool for display and navigation.' , title = 'Group Title' , ) params : Optional [ List [ common . Parameter ]] = Field ( None ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) parts : Optional [ List [ common . Part ]] = Field ( None ) groups : Optional [ List [ Group ]] = None insert_controls : Optional [ List [ InsertControls ]] = Field ( None , alias = 'insert-controls' ) Attributes \u00a4 class_ : ConstrainedStrValue pydantic-field \u00a4 A textual label that provides a sub-type or characterization of the group. groups : List [ trestle . oscal . profile . Group ] pydantic-field \u00a4 id : ConstrainedStrValue pydantic-field \u00a4 A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined group elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, this identifier must be referenced in the context of the containing resource (e.g., import-profile). This id should be assigned per-subject, which means it should be consistently used to identify the same group across revisions of the document. insert_controls : List [ trestle . oscal . profile . InsertControls ] pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 params : List [ trestle . oscal . common . Parameter ] pydantic-field \u00a4 parts : List [ trestle . oscal . common . Part ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 title : str pydantic-field required \u00a4 A name given to the group, which may be used by a tool for display and navigation. Config \u00a4 Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid Import ( OscalBaseModel ) pydantic-model \u00a4 The import designates a catalog or profile to be included (referenced and potentially modified) by this profile. The import also identifies which controls to select using the include-all, include-controls, and exclude-controls directives. Source code in trestle/oscal/profile.py class Import ( OscalBaseModel ): \"\"\" The import designates a catalog or profile to be included (referenced and potentially modified) by this profile. The import also identifies which controls to select using the include-all, include-controls, and exclude-controls directives. \"\"\" class Config : extra = Extra . forbid href : str = Field ( ... , description = 'A resolvable URL reference to the base catalog or profile that this profile is tailoring.' , title = 'Catalog or Profile Reference' , ) include_all : Optional [ common . IncludeAll ] = Field ( None , alias = 'include-all' ) include_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'include-controls' ) exclude_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'exclude-controls' ) Attributes \u00a4 exclude_controls : List [ trestle . oscal . profile . SelectControlById ] pydantic-field \u00a4 href : str pydantic-field required \u00a4 A resolvable URL reference to the base catalog or profile that this profile is tailoring. include_all : IncludeAll pydantic-field \u00a4 include_controls : List [ trestle . oscal . profile . SelectControlById ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid InsertControls ( OscalBaseModel ) pydantic-model \u00a4 Specifies which controls to use in the containing context. Source code in trestle/oscal/profile.py class InsertControls ( OscalBaseModel ): \"\"\" Specifies which controls to use in the containing context. \"\"\" class Config : extra = Extra . forbid order : Optional [ Order ] = Field ( None , description = 'A designation of how a selection of controls in a profile is to be ordered.' , title = 'Order' , ) include_all : Optional [ common . IncludeAll ] = Field ( None , alias = 'include-all' ) include_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'include-controls' ) exclude_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'exclude-controls' ) Attributes \u00a4 exclude_controls : List [ trestle . oscal . profile . SelectControlById ] pydantic-field \u00a4 include_all : IncludeAll pydantic-field \u00a4 include_controls : List [ trestle . oscal . profile . SelectControlById ] pydantic-field \u00a4 order : Order pydantic-field \u00a4 A designation of how a selection of controls in a profile is to be ordered. Config \u00a4 Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid Matching ( OscalBaseModel ) pydantic-model \u00a4 Select controls by (regular expression) match on ID Source code in trestle/oscal/profile.py class Matching ( OscalBaseModel ): \"\"\" Select controls by (regular expression) match on ID \"\"\" class Config : extra = Extra . forbid pattern : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , description = 'A glob expression matching the IDs of one or more controls to be selected.' , title = 'Pattern' , ) Attributes \u00a4 pattern : ConstrainedStrValue pydantic-field \u00a4 A glob expression matching the IDs of one or more controls to be selected. Config \u00a4 Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid Merge ( OscalBaseModel ) pydantic-model \u00a4 A Merge element provides structuring directives that drive how controls are organized after resolution. Source code in trestle/oscal/profile.py class Merge ( OscalBaseModel ): \"\"\" A Merge element provides structuring directives that drive how controls are organized after resolution. \"\"\" class Config : extra = Extra . forbid combine : Optional [ Combine ] = Field ( None , description = 'A Combine element defines how to combine multiple (competing) versions of the same control.' , title = 'Combination rule' , ) flat : Optional [ Dict [ str , Any ]] = Field ( None , description = 'Use the flat structuring method.' , title = 'Flat' ) as_is : Optional [ bool ] = Field ( None , alias = 'as-is' , description = 'An As-is element indicates that the controls should be structured in resolution as they are structured in their source catalogs. It does not contain any elements or attributes.' , title = 'As-Is Structuring Directive' , ) custom : Optional [ Custom ] = Field ( None , description = 'A Custom element frames a structure for embedding represented controls in resolution.' , title = 'Custom grouping' , ) Attributes \u00a4 as_is : bool pydantic-field \u00a4 An As-is element indicates that the controls should be structured in resolution as they are structured in their source catalogs. It does not contain any elements or attributes. combine : Combine pydantic-field \u00a4 A Combine element defines how to combine multiple (competing) versions of the same control. custom : Custom pydantic-field \u00a4 A Custom element frames a structure for embedding represented controls in resolution. flat : Dict [ str , Any ] pydantic-field \u00a4 Use the flat structuring method. Config \u00a4 Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid Method ( Enum ) \u00a4 How clashing controls should be handled Source code in trestle/oscal/profile.py class Method ( Enum ): \"\"\" How clashing controls should be handled \"\"\" use_first = 'use-first' merge = 'merge' keep = 'keep' keep \u00a4 merge \u00a4 use_first \u00a4 Model ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/profile.py class Model ( OscalBaseModel ): profile : Profile profile : Profile pydantic-field required \u00a4 Modify ( OscalBaseModel ) pydantic-model \u00a4 Set parameters or amend controls in resolution Source code in trestle/oscal/profile.py class Modify ( OscalBaseModel ): \"\"\" Set parameters or amend controls in resolution \"\"\" class Config : extra = Extra . forbid set_parameters : Optional [ List [ SetParameter ]] = Field ( None , alias = 'set-parameters' ) alters : Optional [ List [ Alter ]] = Field ( None ) alters : List [ trestle . oscal . profile . Alter ] pydantic-field \u00a4 set_parameters : List [ trestle . oscal . profile . SetParameter ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid Order ( Enum ) \u00a4 A designation of how a selection of controls in a profile is to be ordered. Source code in trestle/oscal/profile.py class Order ( Enum ): \"\"\" A designation of how a selection of controls in a profile is to be ordered. \"\"\" keep = 'keep' ascending = 'ascending' descending = 'descending' ascending \u00a4 descending \u00a4 keep \u00a4 Position ( Enum ) \u00a4 Where to add the new content with respect to the targeted element (beside it or inside it) Source code in trestle/oscal/profile.py class Position ( Enum ): \"\"\" Where to add the new content with respect to the targeted element (beside it or inside it) \"\"\" before = 'before' after = 'after' starting = 'starting' ending = 'ending' after \u00a4 before \u00a4 ending \u00a4 starting \u00a4 Profile ( OscalBaseModel ) pydantic-model \u00a4 Each OSCAL profile is defined by a Profile element Source code in trestle/oscal/profile.py class Profile ( OscalBaseModel ): \"\"\" Each OSCAL profile is defined by a Profile element \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this profile elsewhere in this or other OSCAL instances. The locally defined UUID of the profile can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance).This identifier should be assigned per-subject, which means it should be consistently used to identify the same profile across revisions of the document.' , title = 'Profile Universally Unique Identifier' , ) metadata : common . Metadata imports : List [ Import ] = Field ( ... ) merge : Optional [ Merge ] = None modify : Optional [ Modify ] = None back_matter : Optional [ common . BackMatter ] = Field ( None , alias = 'back-matter' ) Attributes \u00a4 back_matter : BackMatter pydantic-field \u00a4 imports : List [ trestle . oscal . profile . Import ] pydantic-field required \u00a4 merge : Merge pydantic-field \u00a4 metadata : Metadata pydantic-field required \u00a4 modify : Modify pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this profile elsewhere in this or other OSCAL instances. The locally defined UUID of the profile can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance).This identifier should be assigned per-subject, which means it should be consistently used to identify the same profile across revisions of the document. Config \u00a4 Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid Remove ( OscalBaseModel ) pydantic-model \u00a4 Specifies objects to be removed from a control based on specific aspects of the object that must all match. Source code in trestle/oscal/profile.py class Remove ( OscalBaseModel ): \"\"\" Specifies objects to be removed from a control based on specific aspects of the object that must all match. \"\"\" class Config : extra = Extra . forbid by_name : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'by-name' , description = 'Identify items to remove by matching their assigned name' , title = 'Reference by (assigned) name' , ) by_class : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'by-class' , description = 'Identify items to remove by matching their class.' , title = 'Reference by class' , ) by_id : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'by-id' , description = 'Identify items to remove indicated by their id.' , title = 'Reference by ID' , ) by_item_name : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'by-item-name' , description = \"Identify items to remove by the name of the item's information element name, e.g. title or prop\" , title = 'Item Name Reference' , ) by_ns : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'by-ns' , description = \"Identify items to remove by the item's ns, which is the namespace associated with a part, or prop.\" , title = 'Item Namespace Reference' , ) Attributes \u00a4 by_class : ConstrainedStrValue pydantic-field \u00a4 Identify items to remove by matching their class. by_id : ConstrainedStrValue pydantic-field \u00a4 Identify items to remove indicated by their id. by_item_name : ConstrainedStrValue pydantic-field \u00a4 Identify items to remove by the name of the item's information element name, e.g. title or prop by_name : ConstrainedStrValue pydantic-field \u00a4 Identify items to remove by matching their assigned name by_ns : ConstrainedStrValue pydantic-field \u00a4 Identify items to remove by the item's ns, which is the namespace associated with a part, or prop. Config \u00a4 Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid SelectControlById ( OscalBaseModel ) pydantic-model \u00a4 Call a control by its ID Source code in trestle/oscal/profile.py class SelectControlById ( OscalBaseModel ): \"\"\" Call a control by its ID \"\"\" class Config : extra = Extra . forbid with_child_controls : Optional [ WithChildControls ] = Field ( None , alias = 'with-child-controls' , description = 'When a control is included, whether its child (dependent) controls are also included.' , title = 'Include contained controls with control' , ) with_ids : Optional [ List [ WithId ]] = Field ( None , alias = 'with-ids' ) matching : Optional [ List [ Matching ]] = Field ( None ) Attributes \u00a4 matching : List [ trestle . oscal . profile . Matching ] pydantic-field \u00a4 with_child_controls : WithChildControls pydantic-field \u00a4 When a control is included, whether its child (dependent) controls are also included. with_ids : List [ trestle . oscal . profile . WithId ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid SetParameter ( OscalBaseModel ) pydantic-model \u00a4 A parameter setting, to be propagated to points of insertion Source code in trestle/oscal/profile.py class SetParameter ( OscalBaseModel ): \"\"\" A parameter setting, to be propagated to points of insertion \"\"\" class Config : extra = Extra . forbid param_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'param-id' , description = 'A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined parameter elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, this identifier must be referenced in the context of the containing resource (e.g., import-profile). This id should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Parameter ID' , ) class_ : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'class' , description = 'A textual label that provides a characterization of the parameter.' , title = 'Parameter Class' , ) depends_on : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'depends-on' , description = '**(deprecated)** Another parameter invoking this one. This construct has been deprecated and should not be used.' , title = 'Depends on' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) label : Optional [ str ] = Field ( None , description = 'A short, placeholder name for the parameter, which can be used as a substitute for a value if no value is assigned.' , title = 'Parameter Label' , ) usage : Optional [ str ] = Field ( None , description = 'Describes the purpose and use of a parameter' , title = 'Parameter Usage Description' , ) constraints : Optional [ List [ common . ParameterConstraint ]] = Field ( None ) guidelines : Optional [ List [ common . ParameterGuideline ]] = Field ( None ) values : Optional [ List [ common . ParameterValue ]] = Field ( None ) select : Optional [ common . ParameterSelection ] = None Attributes \u00a4 class_ : ConstrainedStrValue pydantic-field \u00a4 A textual label that provides a characterization of the parameter. constraints : List [ trestle . oscal . common . ParameterConstraint ] pydantic-field \u00a4 depends_on : ConstrainedStrValue pydantic-field \u00a4 (deprecated) Another parameter invoking this one. This construct has been deprecated and should not be used. guidelines : List [ trestle . oscal . common . ParameterGuideline ] pydantic-field \u00a4 label : str pydantic-field \u00a4 A short, placeholder name for the parameter, which can be used as a substitute for a value if no value is assigned. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 param_id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined parameter elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, this identifier must be referenced in the context of the containing resource (e.g., import-profile). This id should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 select : ParameterSelection pydantic-field \u00a4 usage : str pydantic-field \u00a4 Describes the purpose and use of a parameter values : List [ trestle . oscal . common . ParameterValue ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid WithChildControls ( Enum ) \u00a4 When a control is included, whether its child (dependent) controls are also included. Source code in trestle/oscal/profile.py class WithChildControls ( Enum ): \"\"\" When a control is included, whether its child (dependent) controls are also included. \"\"\" yes = 'yes' no = 'no' no \u00a4 yes \u00a4 WithId ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/profile.py class WithId ( OscalBaseModel ): __root__ : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = '' , title = 'Match Controls by Identifier' ) __root__ : ConstrainedStrValue pydantic-field required special \u00a4 handler: python","title":"profile"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile","text":"","title":"profile"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Add","text":"Specifies contents to be added into controls, in resolution Source code in trestle/oscal/profile.py class Add ( OscalBaseModel ): \"\"\" Specifies contents to be added into controls, in resolution \"\"\" class Config : extra = Extra . forbid position : Optional [ Position ] = Field ( None , description = 'Where to add the new content with respect to the targeted element (beside it or inside it)' , title = 'Position' , ) by_id : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'by-id' , description = 'Target location of the addition.' , title = 'Reference by ID' , ) title : Optional [ str ] = Field ( None , description = 'A name given to the control, which may be used by a tool for display and navigation.' , title = 'Title Change' , ) params : Optional [ List [ common . Parameter ]] = Field ( None ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) parts : Optional [ List [ common . Part ]] = Field ( None )","title":"Add"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Add-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Add.by_id","text":"Target location of the addition.","title":"by_id"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Add.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Add.params","text":"","title":"params"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Add.parts","text":"","title":"parts"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Add.position","text":"Where to add the new content with respect to the targeted element (beside it or inside it)","title":"position"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Add.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Add.title","text":"A name given to the control, which may be used by a tool for display and navigation.","title":"title"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Add.Config","text":"Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Alter","text":"An Alter element specifies changes to be made to an included control when a profile is resolved. Source code in trestle/oscal/profile.py class Alter ( OscalBaseModel ): \"\"\" An Alter element specifies changes to be made to an included control when a profile is resolved. \"\"\" class Config : extra = Extra . forbid control_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'control-id' , description = 'A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).' , title = 'Control Identifier Reference' , ) removes : Optional [ List [ Remove ]] = Field ( None ) adds : Optional [ List [ Add ]] = Field ( None )","title":"Alter"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Alter-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Alter.adds","text":"","title":"adds"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Alter.control_id","text":"A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).","title":"control_id"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Alter.removes","text":"","title":"removes"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Alter.Config","text":"Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Combine","text":"A Combine element defines how to combine multiple (competing) versions of the same control. Source code in trestle/oscal/profile.py class Combine ( OscalBaseModel ): \"\"\" A Combine element defines how to combine multiple (competing) versions of the same control. \"\"\" class Config : extra = Extra . forbid method : Optional [ Method ] = Field ( None , description = 'How clashing controls should be handled' , title = 'Combination method' , )","title":"Combine"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Combine-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Combine.method","text":"How clashing controls should be handled","title":"method"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Combine.Config","text":"Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Custom","text":"A Custom element frames a structure for embedding represented controls in resolution. Source code in trestle/oscal/profile.py class Custom ( OscalBaseModel ): \"\"\" A Custom element frames a structure for embedding represented controls in resolution. \"\"\" class Config : extra = Extra . forbid groups : Optional [ List [ Group ]] = Field ( None ) insert_controls : Optional [ List [ InsertControls ]] = Field ( None , alias = 'insert-controls' )","title":"Custom"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Custom.groups","text":"","title":"groups"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Custom.insert_controls","text":"","title":"insert_controls"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Custom.Config","text":"Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Group","text":"A group of (selected) controls or of groups of controls Source code in trestle/oscal/profile.py class Group ( OscalBaseModel ): \"\"\" A group of (selected) controls or of groups of controls \"\"\" class Config : extra = Extra . forbid id : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , description = 'A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined group elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, this identifier must be referenced in the context of the containing resource (e.g., import-profile). This id should be assigned per-subject, which means it should be consistently used to identify the same group across revisions of the document.' , title = 'Group Identifier' , ) class_ : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'class' , description = 'A textual label that provides a sub-type or characterization of the group.' , title = 'Group Class' , ) title : str = Field ( ... , description = 'A name given to the group, which may be used by a tool for display and navigation.' , title = 'Group Title' , ) params : Optional [ List [ common . Parameter ]] = Field ( None ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) parts : Optional [ List [ common . Part ]] = Field ( None ) groups : Optional [ List [ Group ]] = None insert_controls : Optional [ List [ InsertControls ]] = Field ( None , alias = 'insert-controls' )","title":"Group"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Group-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Group.class_","text":"A textual label that provides a sub-type or characterization of the group.","title":"class_"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Group.groups","text":"","title":"groups"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Group.id","text":"A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined group elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, this identifier must be referenced in the context of the containing resource (e.g., import-profile). This id should be assigned per-subject, which means it should be consistently used to identify the same group across revisions of the document.","title":"id"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Group.insert_controls","text":"","title":"insert_controls"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Group.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Group.params","text":"","title":"params"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Group.parts","text":"","title":"parts"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Group.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Group.title","text":"A name given to the group, which may be used by a tool for display and navigation.","title":"title"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Group.Config","text":"Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Import","text":"The import designates a catalog or profile to be included (referenced and potentially modified) by this profile. The import also identifies which controls to select using the include-all, include-controls, and exclude-controls directives. Source code in trestle/oscal/profile.py class Import ( OscalBaseModel ): \"\"\" The import designates a catalog or profile to be included (referenced and potentially modified) by this profile. The import also identifies which controls to select using the include-all, include-controls, and exclude-controls directives. \"\"\" class Config : extra = Extra . forbid href : str = Field ( ... , description = 'A resolvable URL reference to the base catalog or profile that this profile is tailoring.' , title = 'Catalog or Profile Reference' , ) include_all : Optional [ common . IncludeAll ] = Field ( None , alias = 'include-all' ) include_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'include-controls' ) exclude_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'exclude-controls' )","title":"Import"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Import-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Import.exclude_controls","text":"","title":"exclude_controls"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Import.href","text":"A resolvable URL reference to the base catalog or profile that this profile is tailoring.","title":"href"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Import.include_all","text":"","title":"include_all"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Import.include_controls","text":"","title":"include_controls"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Import.Config","text":"Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.InsertControls","text":"Specifies which controls to use in the containing context. Source code in trestle/oscal/profile.py class InsertControls ( OscalBaseModel ): \"\"\" Specifies which controls to use in the containing context. \"\"\" class Config : extra = Extra . forbid order : Optional [ Order ] = Field ( None , description = 'A designation of how a selection of controls in a profile is to be ordered.' , title = 'Order' , ) include_all : Optional [ common . IncludeAll ] = Field ( None , alias = 'include-all' ) include_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'include-controls' ) exclude_controls : Optional [ List [ SelectControlById ]] = Field ( None , alias = 'exclude-controls' )","title":"InsertControls"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.InsertControls-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.InsertControls.exclude_controls","text":"","title":"exclude_controls"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.InsertControls.include_all","text":"","title":"include_all"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.InsertControls.include_controls","text":"","title":"include_controls"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.InsertControls.order","text":"A designation of how a selection of controls in a profile is to be ordered.","title":"order"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.InsertControls.Config","text":"Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Matching","text":"Select controls by (regular expression) match on ID Source code in trestle/oscal/profile.py class Matching ( OscalBaseModel ): \"\"\" Select controls by (regular expression) match on ID \"\"\" class Config : extra = Extra . forbid pattern : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , description = 'A glob expression matching the IDs of one or more controls to be selected.' , title = 'Pattern' , )","title":"Matching"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Matching-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Matching.pattern","text":"A glob expression matching the IDs of one or more controls to be selected.","title":"pattern"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Matching.Config","text":"Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Merge","text":"A Merge element provides structuring directives that drive how controls are organized after resolution. Source code in trestle/oscal/profile.py class Merge ( OscalBaseModel ): \"\"\" A Merge element provides structuring directives that drive how controls are organized after resolution. \"\"\" class Config : extra = Extra . forbid combine : Optional [ Combine ] = Field ( None , description = 'A Combine element defines how to combine multiple (competing) versions of the same control.' , title = 'Combination rule' , ) flat : Optional [ Dict [ str , Any ]] = Field ( None , description = 'Use the flat structuring method.' , title = 'Flat' ) as_is : Optional [ bool ] = Field ( None , alias = 'as-is' , description = 'An As-is element indicates that the controls should be structured in resolution as they are structured in their source catalogs. It does not contain any elements or attributes.' , title = 'As-Is Structuring Directive' , ) custom : Optional [ Custom ] = Field ( None , description = 'A Custom element frames a structure for embedding represented controls in resolution.' , title = 'Custom grouping' , )","title":"Merge"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Merge-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Merge.as_is","text":"An As-is element indicates that the controls should be structured in resolution as they are structured in their source catalogs. It does not contain any elements or attributes.","title":"as_is"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Merge.combine","text":"A Combine element defines how to combine multiple (competing) versions of the same control.","title":"combine"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Merge.custom","text":"A Custom element frames a structure for embedding represented controls in resolution.","title":"custom"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Merge.flat","text":"Use the flat structuring method.","title":"flat"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Merge.Config","text":"Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Method","text":"How clashing controls should be handled Source code in trestle/oscal/profile.py class Method ( Enum ): \"\"\" How clashing controls should be handled \"\"\" use_first = 'use-first' merge = 'merge' keep = 'keep'","title":"Method"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Method.keep","text":"","title":"keep"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Method.merge","text":"","title":"merge"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Method.use_first","text":"","title":"use_first"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Model","text":"Source code in trestle/oscal/profile.py class Model ( OscalBaseModel ): profile : Profile","title":"Model"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Model.profile","text":"","title":"profile"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Modify","text":"Set parameters or amend controls in resolution Source code in trestle/oscal/profile.py class Modify ( OscalBaseModel ): \"\"\" Set parameters or amend controls in resolution \"\"\" class Config : extra = Extra . forbid set_parameters : Optional [ List [ SetParameter ]] = Field ( None , alias = 'set-parameters' ) alters : Optional [ List [ Alter ]] = Field ( None )","title":"Modify"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Modify.alters","text":"","title":"alters"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Modify.set_parameters","text":"","title":"set_parameters"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Modify.Config","text":"Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Order","text":"A designation of how a selection of controls in a profile is to be ordered. Source code in trestle/oscal/profile.py class Order ( Enum ): \"\"\" A designation of how a selection of controls in a profile is to be ordered. \"\"\" keep = 'keep' ascending = 'ascending' descending = 'descending'","title":"Order"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Order.ascending","text":"","title":"ascending"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Order.descending","text":"","title":"descending"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Order.keep","text":"","title":"keep"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Position","text":"Where to add the new content with respect to the targeted element (beside it or inside it) Source code in trestle/oscal/profile.py class Position ( Enum ): \"\"\" Where to add the new content with respect to the targeted element (beside it or inside it) \"\"\" before = 'before' after = 'after' starting = 'starting' ending = 'ending'","title":"Position"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Position.after","text":"","title":"after"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Position.before","text":"","title":"before"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Position.ending","text":"","title":"ending"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Position.starting","text":"","title":"starting"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Profile","text":"Each OSCAL profile is defined by a Profile element Source code in trestle/oscal/profile.py class Profile ( OscalBaseModel ): \"\"\" Each OSCAL profile is defined by a Profile element \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this profile elsewhere in this or other OSCAL instances. The locally defined UUID of the profile can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance).This identifier should be assigned per-subject, which means it should be consistently used to identify the same profile across revisions of the document.' , title = 'Profile Universally Unique Identifier' , ) metadata : common . Metadata imports : List [ Import ] = Field ( ... ) merge : Optional [ Merge ] = None modify : Optional [ Modify ] = None back_matter : Optional [ common . BackMatter ] = Field ( None , alias = 'back-matter' )","title":"Profile"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Profile-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Profile.back_matter","text":"","title":"back_matter"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Profile.imports","text":"","title":"imports"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Profile.merge","text":"","title":"merge"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Profile.metadata","text":"","title":"metadata"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Profile.modify","text":"","title":"modify"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Profile.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this profile elsewhere in this or other OSCAL instances. The locally defined UUID of the profile can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance).This identifier should be assigned per-subject, which means it should be consistently used to identify the same profile across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Profile.Config","text":"Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Remove","text":"Specifies objects to be removed from a control based on specific aspects of the object that must all match. Source code in trestle/oscal/profile.py class Remove ( OscalBaseModel ): \"\"\" Specifies objects to be removed from a control based on specific aspects of the object that must all match. \"\"\" class Config : extra = Extra . forbid by_name : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'by-name' , description = 'Identify items to remove by matching their assigned name' , title = 'Reference by (assigned) name' , ) by_class : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'by-class' , description = 'Identify items to remove by matching their class.' , title = 'Reference by class' , ) by_id : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'by-id' , description = 'Identify items to remove indicated by their id.' , title = 'Reference by ID' , ) by_item_name : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'by-item-name' , description = \"Identify items to remove by the name of the item's information element name, e.g. title or prop\" , title = 'Item Name Reference' , ) by_ns : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'by-ns' , description = \"Identify items to remove by the item's ns, which is the namespace associated with a part, or prop.\" , title = 'Item Namespace Reference' , )","title":"Remove"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Remove-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Remove.by_class","text":"Identify items to remove by matching their class.","title":"by_class"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Remove.by_id","text":"Identify items to remove indicated by their id.","title":"by_id"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Remove.by_item_name","text":"Identify items to remove by the name of the item's information element name, e.g. title or prop","title":"by_item_name"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Remove.by_name","text":"Identify items to remove by matching their assigned name","title":"by_name"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Remove.by_ns","text":"Identify items to remove by the item's ns, which is the namespace associated with a part, or prop.","title":"by_ns"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.Remove.Config","text":"Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SelectControlById","text":"Call a control by its ID Source code in trestle/oscal/profile.py class SelectControlById ( OscalBaseModel ): \"\"\" Call a control by its ID \"\"\" class Config : extra = Extra . forbid with_child_controls : Optional [ WithChildControls ] = Field ( None , alias = 'with-child-controls' , description = 'When a control is included, whether its child (dependent) controls are also included.' , title = 'Include contained controls with control' , ) with_ids : Optional [ List [ WithId ]] = Field ( None , alias = 'with-ids' ) matching : Optional [ List [ Matching ]] = Field ( None )","title":"SelectControlById"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SelectControlById-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SelectControlById.matching","text":"","title":"matching"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SelectControlById.with_child_controls","text":"When a control is included, whether its child (dependent) controls are also included.","title":"with_child_controls"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SelectControlById.with_ids","text":"","title":"with_ids"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SelectControlById.Config","text":"Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SetParameter","text":"A parameter setting, to be propagated to points of insertion Source code in trestle/oscal/profile.py class SetParameter ( OscalBaseModel ): \"\"\" A parameter setting, to be propagated to points of insertion \"\"\" class Config : extra = Extra . forbid param_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'param-id' , description = 'A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined parameter elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, this identifier must be referenced in the context of the containing resource (e.g., import-profile). This id should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Parameter ID' , ) class_ : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'class' , description = 'A textual label that provides a characterization of the parameter.' , title = 'Parameter Class' , ) depends_on : Optional [ constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' )] = Field ( None , alias = 'depends-on' , description = '**(deprecated)** Another parameter invoking this one. This construct has been deprecated and should not be used.' , title = 'Depends on' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) label : Optional [ str ] = Field ( None , description = 'A short, placeholder name for the parameter, which can be used as a substitute for a value if no value is assigned.' , title = 'Parameter Label' , ) usage : Optional [ str ] = Field ( None , description = 'Describes the purpose and use of a parameter' , title = 'Parameter Usage Description' , ) constraints : Optional [ List [ common . ParameterConstraint ]] = Field ( None ) guidelines : Optional [ List [ common . ParameterGuideline ]] = Field ( None ) values : Optional [ List [ common . ParameterValue ]] = Field ( None ) select : Optional [ common . ParameterSelection ] = None","title":"SetParameter"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SetParameter-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SetParameter.class_","text":"A textual label that provides a characterization of the parameter.","title":"class_"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SetParameter.constraints","text":"","title":"constraints"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SetParameter.depends_on","text":"(deprecated) Another parameter invoking this one. This construct has been deprecated and should not be used.","title":"depends_on"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SetParameter.guidelines","text":"","title":"guidelines"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SetParameter.label","text":"A short, placeholder name for the parameter, which can be used as a substitute for a value if no value is assigned.","title":"label"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SetParameter.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SetParameter.param_id","text":"A human-oriented, locally unique identifier with cross-instance scope that can be used to reference this defined parameter elsewhere in this or other OSCAL instances. When referenced from another OSCAL instance, this identifier must be referenced in the context of the containing resource (e.g., import-profile). This id should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"param_id"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SetParameter.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SetParameter.select","text":"","title":"select"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SetParameter.usage","text":"Describes the purpose and use of a parameter","title":"usage"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SetParameter.values","text":"","title":"values"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.SetParameter.Config","text":"Source code in trestle/oscal/profile.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.WithChildControls","text":"When a control is included, whether its child (dependent) controls are also included. Source code in trestle/oscal/profile.py class WithChildControls ( Enum ): \"\"\" When a control is included, whether its child (dependent) controls are also included. \"\"\" yes = 'yes' no = 'no'","title":"WithChildControls"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.WithChildControls.no","text":"","title":"no"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.WithChildControls.yes","text":"","title":"yes"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.WithId","text":"Source code in trestle/oscal/profile.py class WithId ( OscalBaseModel ): __root__ : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , description = '' , title = 'Match Controls by Identifier' )","title":"WithId"},{"location":"api_reference/trestle.oscal.profile/#trestle.oscal.profile.WithId.__root__","text":"handler: python","title":"__root__"},{"location":"api_reference/trestle.oscal.ssp/","text":"trestle.oscal.ssp \u00a4 Classes \u00a4 AdjustmentJustification ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/ssp.py class AdjustmentJustification ( OscalBaseModel ): __root__ : str = Field ( ... , description = 'If the selected security level is different from the base security level, this contains the justification for the change.' , title = 'Adjustment Justification' , ) Attributes \u00a4 __root__ : str pydantic-field required special \u00a4 If the selected security level is different from the base security level, this contains the justification for the change. AuthorizationBoundary ( OscalBaseModel ) pydantic-model \u00a4 A description of this system's authorization boundary, optionally supplemented by diagrams that illustrate the authorization boundary. Source code in trestle/oscal/ssp.py class AuthorizationBoundary ( OscalBaseModel ): \"\"\" A description of this system's authorization boundary, optionally supplemented by diagrams that illustrate the authorization boundary. \"\"\" class Config : extra = Extra . forbid description : str = Field ( ... , description = \"A summary of the system's authorization boundary.\" , title = 'Authorization Boundary Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) diagrams : Optional [ List [ Diagram ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A summary of the system's authorization boundary. diagrams : List [ trestle . oscal . ssp . Diagram ] pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid AvailabilityImpact ( OscalBaseModel ) pydantic-model \u00a4 The expected level of impact resulting from the disruption of access to or use of the described information or the information system. Source code in trestle/oscal/ssp.py class AvailabilityImpact ( OscalBaseModel ): \"\"\" The expected level of impact resulting from the disruption of access to or use of the described information or the information system. \"\"\" class Config : extra = Extra . forbid props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) base : Base selected : Optional [ Selected ] = None adjustment_justification : Optional [ AdjustmentJustification ] = Field ( None , alias = 'adjustment-justification' ) adjustment_justification : AdjustmentJustification pydantic-field \u00a4 base : Base pydantic-field required \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 selected : Selected pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid Base ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/ssp.py class Base ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'The prescribed base (Confidentiality, Integrity, or Availability) security impact level.' , title = 'Base Level (Confidentiality, Integrity, or Availability)' , ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 The prescribed base (Confidentiality, Integrity, or Availability) security impact level. ByComponent ( OscalBaseModel ) pydantic-model \u00a4 Defines how the referenced component implements a set of controls. Source code in trestle/oscal/ssp.py class ByComponent ( OscalBaseModel ): \"\"\" Defines how the referenced component implements a set of controls. \"\"\" class Config : extra = Extra . forbid component_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'component-uuid' , description = 'A machine-oriented identifier reference to the component that is implemeting a given control.' , title = 'Component Universally Unique Identifier Reference' , ) uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this by-component entry elsewhere in this or other OSCAL instances. The locally defined UUID of the by-component entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'By-Component Universally Unique Identifier' , ) description : str = Field ( ... , description = 'An implementation statement that describes how a control or a control statement is implemented within the referenced system component.' , title = 'Control Implementation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) set_parameters : Optional [ List [ SetParameter ]] = Field ( None , alias = 'set-parameters' ) implementation_status : Optional [ common . ImplementationStatus ] = Field ( None , alias = 'implementation-status' ) export : Optional [ Export ] = Field ( None , description = 'Identifies content intended for external consumption, such as with leveraged organizations.' , title = 'Export' , ) inherited : Optional [ List [ Inherited ]] = Field ( None ) satisfied : Optional [ List [ Satisfied ]] = Field ( None ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 component_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to the component that is implemeting a given control. description : str pydantic-field required \u00a4 An implementation statement that describes how a control or a control statement is implemented within the referenced system component. export : Export pydantic-field \u00a4 Identifies content intended for external consumption, such as with leveraged organizations. implementation_status : ImplementationStatus pydantic-field \u00a4 inherited : List [ trestle . oscal . ssp . Inherited ] pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 satisfied : List [ trestle . oscal . ssp . Satisfied ] pydantic-field \u00a4 set_parameters : List [ trestle . oscal . ssp . SetParameter ] pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this by-component entry elsewhere in this or other OSCAL instances. The locally defined UUID of the by-component entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid Categorization ( OscalBaseModel ) pydantic-model \u00a4 A set of information type identifiers qualified by the given identification system used, such as NIST SP 800-60. Source code in trestle/oscal/ssp.py class Categorization ( OscalBaseModel ): \"\"\" A set of information type identifiers qualified by the given identification system used, such as NIST SP 800-60. \"\"\" class Config : extra = Extra . forbid system : AnyUrl = Field ( ... , description = 'Specifies the information type identification system used.' , title = 'Information Type Identification System' , ) information_type_ids : Optional [ List [ InformationTypeId ]] = Field ( None , alias = 'information-type-ids' ) Attributes \u00a4 information_type_ids : List [ trestle . oscal . ssp . InformationTypeId ] pydantic-field \u00a4 system : AnyUrl pydantic-field required \u00a4 Specifies the information type identification system used. Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid ConfidentialityImpact ( OscalBaseModel ) pydantic-model \u00a4 The expected level of impact resulting from the unauthorized disclosure of the described information. Source code in trestle/oscal/ssp.py class ConfidentialityImpact ( OscalBaseModel ): \"\"\" The expected level of impact resulting from the unauthorized disclosure of the described information. \"\"\" class Config : extra = Extra . forbid props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) base : Base selected : Optional [ Selected ] = None adjustment_justification : Optional [ AdjustmentJustification ] = Field ( None , alias = 'adjustment-justification' ) adjustment_justification : AdjustmentJustification pydantic-field \u00a4 base : Base pydantic-field required \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 selected : Selected pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid ControlImplementation ( OscalBaseModel ) pydantic-model \u00a4 Describes how the system satisfies a set of controls. Source code in trestle/oscal/ssp.py class ControlImplementation ( OscalBaseModel ): \"\"\" Describes how the system satisfies a set of controls. \"\"\" class Config : extra = Extra . forbid description : str = Field ( ... , description = 'A statement describing important things to know about how this set of control satisfaction documentation is approached.' , title = 'Control Implementation Description' , ) set_parameters : Optional [ List [ SetParameter ]] = Field ( None , alias = 'set-parameters' ) implemented_requirements : List [ ImplementedRequirement ] = Field ( ... , alias = 'implemented-requirements' ) Attributes \u00a4 description : str pydantic-field required \u00a4 A statement describing important things to know about how this set of control satisfaction documentation is approached. implemented_requirements : List [ trestle . oscal . ssp . ImplementedRequirement ] pydantic-field required \u00a4 set_parameters : List [ trestle . oscal . ssp . SetParameter ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid DataFlow ( OscalBaseModel ) pydantic-model \u00a4 A description of the logical flow of information within the system and across its boundaries, optionally supplemented by diagrams that illustrate these flows. Source code in trestle/oscal/ssp.py class DataFlow ( OscalBaseModel ): \"\"\" A description of the logical flow of information within the system and across its boundaries, optionally supplemented by diagrams that illustrate these flows. \"\"\" class Config : extra = Extra . forbid description : str = Field ( ... , description = \"A summary of the system's data flow.\" , title = 'Data Flow Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) diagrams : Optional [ List [ Diagram ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A summary of the system's data flow. diagrams : List [ trestle . oscal . ssp . Diagram ] pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid DateAuthorized ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/ssp.py class DateAuthorized ( OscalBaseModel ): __root__ : constr ( regex = r '^((2000|2400|2800|(19|2[0-9](0[48]|[2468][048]|[13579][26])))-02-29)|(((19|2[0-9])[0-9] {2} )-02-(0[1-9]|1[0-9]|2[0-8]))|(((19|2[0-9])[0-9] {2} )-(0[13578]|10|12)-(0[1-9]|[12][0-9]|3[01]))|(((19|2[0-9])[0-9] {2} )-(0[469]|11)-(0[1-9]|[12][0-9]|30))(Z|[+-][0-9] {2} :[0-9] {2} )?$' ) = Field ( ... , description = 'The date the system received its authorization.' , title = 'System Authorization Date' , ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 The date the system received its authorization. Diagram ( OscalBaseModel ) pydantic-model \u00a4 A graphic that provides a visual representation the system, or some aspect of it. Source code in trestle/oscal/ssp.py class Diagram ( OscalBaseModel ): \"\"\" A graphic that provides a visual representation the system, or some aspect of it. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this diagram elsewhere in this or other OSCAL instances. The locally defined UUID of the diagram can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Diagram ID' , ) description : Optional [ str ] = Field ( None , description = 'A summary of the diagram.' , title = 'Diagram Description' ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) caption : Optional [ str ] = Field ( None , description = 'A brief caption to annotate the diagram.' , title = 'Caption' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 caption : str pydantic-field \u00a4 A brief caption to annotate the diagram. description : str pydantic-field \u00a4 A summary of the diagram. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this diagram elsewhere in this or other OSCAL instances. The locally defined UUID of the diagram can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid Export ( OscalBaseModel ) pydantic-model \u00a4 Identifies content intended for external consumption, such as with leveraged organizations. Source code in trestle/oscal/ssp.py class Export ( OscalBaseModel ): \"\"\" Identifies content intended for external consumption, such as with leveraged organizations. \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'An implementation statement that describes the aspects of the control or control statement implementation that can be available to another system leveraging this system.' , title = 'Control Implementation Export Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) provided : Optional [ List [ Provided ]] = Field ( None ) responsibilities : Optional [ List [ Responsibility ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field \u00a4 An implementation statement that describes the aspects of the control or control statement implementation that can be available to another system leveraging this system. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 provided : List [ trestle . oscal . ssp . Provided ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsibilities : List [ trestle . oscal . ssp . Responsibility ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid ImplementedRequirement ( OscalBaseModel ) pydantic-model \u00a4 Describes how the system satisfies an individual control. Source code in trestle/oscal/ssp.py class ImplementedRequirement ( OscalBaseModel ): \"\"\" Describes how the system satisfies an individual control. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this control requirement elsewhere in this or other OSCAL instances. The locally defined UUID of the control requirement can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Control Requirement Universally Unique Identifier' , ) control_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'control-id' , description = 'A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).' , title = 'Control Identifier Reference' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) set_parameters : Optional [ List [ SetParameter ]] = Field ( None , alias = 'set-parameters' ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) statements : Optional [ List [ Statement ]] = Field ( None ) by_components : Optional [ List [ ByComponent ]] = Field ( None , alias = 'by-components' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 by_components : List [ trestle . oscal . ssp . ByComponent ] pydantic-field \u00a4 control_id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference). links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 set_parameters : List [ trestle . oscal . ssp . SetParameter ] pydantic-field \u00a4 statements : List [ trestle . oscal . ssp . Statement ] pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this control requirement elsewhere in this or other OSCAL instances. The locally defined UUID of the control requirement can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid ImportProfile ( OscalBaseModel ) pydantic-model \u00a4 Used to import the OSCAL profile representing the system's control baseline. Source code in trestle/oscal/ssp.py class ImportProfile ( OscalBaseModel ): \"\"\" Used to import the OSCAL profile representing the system's control baseline. \"\"\" class Config : extra = Extra . forbid href : str = Field ( ... , description = \"A resolvable URL reference to the profile to use as the system's control baseline.\" , title = 'Profile Reference' , ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 href : str pydantic-field required \u00a4 A resolvable URL reference to the profile to use as the system's control baseline. remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid InformationType ( OscalBaseModel ) pydantic-model \u00a4 Contains details about one information type that is stored, processed, or transmitted by the system, such as privacy information, and those defined in NIST SP 800-60. Source code in trestle/oscal/ssp.py class InformationType ( OscalBaseModel ): \"\"\" Contains details about one information type that is stored, processed, or transmitted by the system, such as privacy information, and those defined in NIST SP 800-60. \"\"\" class Config : extra = Extra . forbid uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this information type elsewhere in this or other OSCAL instances. The locally defined UUID of the information type can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Information Type Universally Unique Identifier' , ) title : str = Field ( ... , description = 'A human readable name for the information type. This title should be meaningful within the context of the system.' , title = 'title field' , ) description : str = Field ( ... , description = 'A summary of how this information type is used within the system.' , title = 'Information Type Description' , ) categorizations : Optional [ List [ Categorization ]] = Field ( None ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) confidentiality_impact : ConfidentialityImpact = Field ( ... , alias = 'confidentiality-impact' , description = 'The expected level of impact resulting from the unauthorized disclosure of the described information.' , title = 'Confidentiality Impact Level' , ) integrity_impact : IntegrityImpact = Field ( ... , alias = 'integrity-impact' , description = 'The expected level of impact resulting from the unauthorized modification of the described information.' , title = 'Integrity Impact Level' , ) availability_impact : AvailabilityImpact = Field ( ... , alias = 'availability-impact' , description = 'The expected level of impact resulting from the disruption of access to or use of the described information or the information system.' , title = 'Availability Impact Level' , ) Attributes \u00a4 availability_impact : AvailabilityImpact pydantic-field required \u00a4 The expected level of impact resulting from the disruption of access to or use of the described information or the information system. categorizations : List [ trestle . oscal . ssp . Categorization ] pydantic-field \u00a4 confidentiality_impact : ConfidentialityImpact pydantic-field required \u00a4 The expected level of impact resulting from the unauthorized disclosure of the described information. description : str pydantic-field required \u00a4 A summary of how this information type is used within the system. integrity_impact : IntegrityImpact pydantic-field required \u00a4 The expected level of impact resulting from the unauthorized modification of the described information. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 title : str pydantic-field required \u00a4 A human readable name for the information type. This title should be meaningful within the context of the system. uuid : ConstrainedStrValue pydantic-field \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this information type elsewhere in this or other OSCAL instances. The locally defined UUID of the information type can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid InformationTypeId ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/ssp.py class InformationTypeId ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A human-oriented, globally unique identifier qualified by the given identification system used, such as NIST SP 800-60. This identifier has cross-instance scope and can be used to reference this system elsewhere in this or other OSCAL instances. This id should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Information Type Systematized Identifier' , ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 A human-oriented, globally unique identifier qualified by the given identification system used, such as NIST SP 800-60. This identifier has cross-instance scope and can be used to reference this system elsewhere in this or other OSCAL instances. This id should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Inherited ( OscalBaseModel ) pydantic-model \u00a4 Describes a control implementation inherited by a leveraging system. Source code in trestle/oscal/ssp.py class Inherited ( OscalBaseModel ): \"\"\" Describes a control implementation inherited by a leveraging system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this inherited entry elsewhere in this or other OSCAL instances. The locally defined UUID of the inherited control implementation can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Inherited Universally Unique Identifier' , ) provided_uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , alias = 'provided-uuid' , description = 'A machine-oriented identifier reference to an inherited control implementation that a leveraging system is inheriting from a leveraged system.' , title = 'Provided UUID' , ) description : str = Field ( ... , description = 'An implementation statement that describes the aspects of a control or control statement implementation that a leveraging system is inheriting from a leveraged system.' , title = 'Inherited Control Implementation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) Attributes \u00a4 description : str pydantic-field required \u00a4 An implementation statement that describes the aspects of a control or control statement implementation that a leveraging system is inheriting from a leveraged system. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 provided_uuid : ConstrainedStrValue pydantic-field \u00a4 A machine-oriented identifier reference to an inherited control implementation that a leveraging system is inheriting from a leveraged system. responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this inherited entry elsewhere in this or other OSCAL instances. The locally defined UUID of the inherited control implementation can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid IntegrityImpact ( OscalBaseModel ) pydantic-model \u00a4 The expected level of impact resulting from the unauthorized modification of the described information. Source code in trestle/oscal/ssp.py class IntegrityImpact ( OscalBaseModel ): \"\"\" The expected level of impact resulting from the unauthorized modification of the described information. \"\"\" class Config : extra = Extra . forbid props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) base : Base selected : Optional [ Selected ] = None adjustment_justification : Optional [ AdjustmentJustification ] = Field ( None , alias = 'adjustment-justification' ) adjustment_justification : AdjustmentJustification pydantic-field \u00a4 base : Base pydantic-field required \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 selected : Selected pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid LeveragedAuthorization ( OscalBaseModel ) pydantic-model \u00a4 A description of another authorized system from which this system inherits capabilities that satisfy security requirements. Another term for this concept is a common control provider. Source code in trestle/oscal/ssp.py class LeveragedAuthorization ( OscalBaseModel ): \"\"\" A description of another authorized system from which this system inherits capabilities that satisfy security requirements. Another term for this concept is a common control provider. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope and can be used to reference this leveraged authorization elsewhere in this or other OSCAL instances. The locally defined UUID of the leveraged authorization can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Leveraged Authorization Universally Unique Identifier' , ) title : str = Field ( ... , description = 'A human readable name for the leveraged authorization in the context of the system.' , title = 'title field' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) party_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'party-uuid' , description = 'A machine-oriented identifier reference to the party that manages the leveraged system.' , title = 'party-uuid field' , ) date_authorized : DateAuthorized = Field ( ... , alias = 'date-authorized' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 date_authorized : DateAuthorized pydantic-field required \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 party_uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented identifier reference to the party that manages the leveraged system. props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 title : str pydantic-field required \u00a4 A human readable name for the leveraged authorization in the context of the system. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope and can be used to reference this leveraged authorization elsewhere in this or other OSCAL instances. The locally defined UUID of the leveraged authorization can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid Model ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/ssp.py class Model ( OscalBaseModel ): system_security_plan : SystemSecurityPlan = Field ( ... , alias = 'system-security-plan' ) system_security_plan : SystemSecurityPlan pydantic-field required \u00a4 NetworkArchitecture ( OscalBaseModel ) pydantic-model \u00a4 A description of the system's network architecture, optionally supplemented by diagrams that illustrate the network architecture. Source code in trestle/oscal/ssp.py class NetworkArchitecture ( OscalBaseModel ): \"\"\" A description of the system's network architecture, optionally supplemented by diagrams that illustrate the network architecture. \"\"\" class Config : extra = Extra . forbid description : str = Field ( ... , description = \"A summary of the system's network architecture.\" , title = 'Network Architecture Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) diagrams : Optional [ List [ Diagram ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A summary of the system's network architecture. diagrams : List [ trestle . oscal . ssp . Diagram ] pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid Provided ( OscalBaseModel ) pydantic-model \u00a4 Describes a capability which may be inherited by a leveraging system. Source code in trestle/oscal/ssp.py class Provided ( OscalBaseModel ): \"\"\" Describes a capability which may be inherited by a leveraging system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this provided entry elsewhere in this or other OSCAL instances. The locally defined UUID of the provided entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Provided Universally Unique Identifier' , ) description : str = Field ( ... , description = 'An implementation statement that describes the aspects of the control or control statement implementation that can be provided to another system leveraging this system.' , title = 'Provided Control Implementation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 An implementation statement that describes the aspects of the control or control statement implementation that can be provided to another system leveraging this system. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this provided entry elsewhere in this or other OSCAL instances. The locally defined UUID of the provided entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid Responsibility ( OscalBaseModel ) pydantic-model \u00a4 Describes a control implementation responsibility imposed on a leveraging system. Source code in trestle/oscal/ssp.py class Responsibility ( OscalBaseModel ): \"\"\" Describes a control implementation responsibility imposed on a leveraging system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this responsibility elsewhere in this or other OSCAL instances. The locally defined UUID of the responsibility can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Responsibility Universally Unique Identifier' , ) provided_uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , alias = 'provided-uuid' , description = 'A machine-oriented identifier reference to an inherited control implementation that a leveraging system is inheriting from a leveraged system.' , title = 'Provided UUID' , ) description : str = Field ( ... , description = 'An implementation statement that describes the aspects of the control or control statement implementation that a leveraging system must implement to satisfy the control provided by a leveraged system.' , title = 'Control Implementation Responsibility Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 An implementation statement that describes the aspects of the control or control statement implementation that a leveraging system must implement to satisfy the control provided by a leveraged system. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 provided_uuid : ConstrainedStrValue pydantic-field \u00a4 A machine-oriented identifier reference to an inherited control implementation that a leveraging system is inheriting from a leveraged system. remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this responsibility elsewhere in this or other OSCAL instances. The locally defined UUID of the responsibility can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid Satisfied ( OscalBaseModel ) pydantic-model \u00a4 Describes how this system satisfies a responsibility imposed by a leveraged system. Source code in trestle/oscal/ssp.py class Satisfied ( OscalBaseModel ): \"\"\" Describes how this system satisfies a responsibility imposed by a leveraged system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this satisfied control implementation entry elsewhere in this or other OSCAL instances. The locally defined UUID of the control implementation can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Satisfied Universally Unique Identifier' , ) responsibility_uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , alias = 'responsibility-uuid' , description = 'A machine-oriented identifier reference to a control implementation that satisfies a responsibility imposed by a leveraged system.' , title = 'Responsibility UUID' , ) description : str = Field ( ... , description = 'An implementation statement that describes the aspects of a control or control statement implementation that a leveraging system is implementing based on a requirement from a leveraged system.' , title = 'Satisfied Control Implementation Responsibility Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 An implementation statement that describes the aspects of a control or control statement implementation that a leveraging system is implementing based on a requirement from a leveraged system. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsibility_uuid : ConstrainedStrValue pydantic-field \u00a4 A machine-oriented identifier reference to a control implementation that satisfies a responsibility imposed by a leveraged system. responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this satisfied control implementation entry elsewhere in this or other OSCAL instances. The locally defined UUID of the control implementation can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid SecurityImpactLevel ( OscalBaseModel ) pydantic-model \u00a4 The overall level of expected impact resulting from unauthorized disclosure, modification, or loss of access to information. Source code in trestle/oscal/ssp.py class SecurityImpactLevel ( OscalBaseModel ): \"\"\" The overall level of expected impact resulting from unauthorized disclosure, modification, or loss of access to information. \"\"\" class Config : extra = Extra . forbid security_objective_confidentiality : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , alias = 'security-objective-confidentiality' , description = 'A target-level of confidentiality for the system, based on the sensitivity of information within the system.' , title = 'Security Objective: Confidentiality' , ) security_objective_integrity : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , alias = 'security-objective-integrity' , description = 'A target-level of integrity for the system, based on the sensitivity of information within the system.' , title = 'Security Objective: Integrity' , ) security_objective_availability : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , alias = 'security-objective-availability' , description = 'A target-level of availability for the system, based on the sensitivity of information within the system.' , title = 'Security Objective: Availability' , ) Attributes \u00a4 security_objective_availability : ConstrainedStrValue pydantic-field required \u00a4 A target-level of availability for the system, based on the sensitivity of information within the system. security_objective_confidentiality : ConstrainedStrValue pydantic-field required \u00a4 A target-level of confidentiality for the system, based on the sensitivity of information within the system. security_objective_integrity : ConstrainedStrValue pydantic-field required \u00a4 A target-level of integrity for the system, based on the sensitivity of information within the system. Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid Selected ( OscalBaseModel ) pydantic-model \u00a4 Source code in trestle/oscal/ssp.py class Selected ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'The selected (Confidentiality, Integrity, or Availability) security impact level.' , title = 'Selected Level (Confidentiality, Integrity, or Availability)' , ) Attributes \u00a4 __root__ : ConstrainedStrValue pydantic-field required special \u00a4 The selected (Confidentiality, Integrity, or Availability) security impact level. SetParameter ( OscalBaseModel ) pydantic-model \u00a4 Identifies the parameter that will be set by the enclosed value. Source code in trestle/oscal/ssp.py class SetParameter ( OscalBaseModel ): \"\"\" Identifies the parameter that will be set by the enclosed value. \"\"\" class Config : extra = Extra . forbid param_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'param-id' , description = \"A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context.\" , title = 'Parameter ID' , ) values : List [ common . Value ] = Field ( ... ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 param_id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context. remarks : Remarks pydantic-field \u00a4 values : List [ trestle . oscal . common . Value ] pydantic-field required \u00a4 Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid State ( Enum ) \u00a4 The current operating status. Source code in trestle/oscal/ssp.py class State ( Enum ): \"\"\" The current operating status. \"\"\" operational = 'operational' under_development = 'under-development' under_major_modification = 'under-major-modification' disposition = 'disposition' other = 'other' disposition \u00a4 operational \u00a4 other \u00a4 under_development \u00a4 under_major_modification \u00a4 State1 ( Enum ) \u00a4 The operational status. Source code in trestle/oscal/ssp.py class State1 ( Enum ): \"\"\" The operational status. \"\"\" under_development = 'under-development' operational = 'operational' disposition = 'disposition' other = 'other' disposition \u00a4 operational \u00a4 other \u00a4 under_development \u00a4 Statement ( OscalBaseModel ) pydantic-model \u00a4 Identifies which statements within a control are addressed. Source code in trestle/oscal/ssp.py class Statement ( OscalBaseModel ): \"\"\" Identifies which statements within a control are addressed. \"\"\" class Config : extra = Extra . forbid statement_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'statement-id' , description = 'A human-oriented identifier reference to a control statement.' , title = 'Control Statement Reference' , ) uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this control statement elsewhere in this or other OSCAL instances. The UUID of the control statement in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance).' , title = 'Control Statement Reference Universally Unique Identifier' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) by_components : Optional [ List [ ByComponent ]] = Field ( None , alias = 'by-components' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 by_components : List [ trestle . oscal . ssp . ByComponent ] pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 statement_id : ConstrainedStrValue pydantic-field required \u00a4 A human-oriented identifier reference to a control statement. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this control statement elsewhere in this or other OSCAL instances. The UUID of the control statement in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance). Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid Status ( OscalBaseModel ) pydantic-model \u00a4 Describes the operational status of the system component. Source code in trestle/oscal/ssp.py class Status ( OscalBaseModel ): \"\"\" Describes the operational status of the system component. \"\"\" class Config : extra = Extra . forbid state : State1 = Field ( ... , description = 'The operational status.' , title = 'State' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 remarks : Remarks pydantic-field \u00a4 state : State1 pydantic-field required \u00a4 The operational status. Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid Status1 ( OscalBaseModel ) pydantic-model \u00a4 Describes the operational status of the system. Source code in trestle/oscal/ssp.py class Status1 ( OscalBaseModel ): \"\"\" Describes the operational status of the system. \"\"\" class Config : extra = Extra . forbid state : State = Field ( ... , description = 'The current operating status.' , title = 'State' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 remarks : Remarks pydantic-field \u00a4 state : State pydantic-field required \u00a4 The current operating status. Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid SystemCharacteristics ( OscalBaseModel ) pydantic-model \u00a4 Contains the characteristics of the system, such as its name, purpose, and security impact level. Source code in trestle/oscal/ssp.py class SystemCharacteristics ( OscalBaseModel ): \"\"\" Contains the characteristics of the system, such as its name, purpose, and security impact level. \"\"\" class Config : extra = Extra . forbid system_ids : List [ common . SystemId ] = Field ( ... , alias = 'system-ids' ) system_name : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , alias = 'system-name' , description = 'The full name of the system.' , title = 'System Name - Full' , ) system_name_short : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , alias = 'system-name-short' , description = 'A short name for the system, such as an acronym, that is suitable for display in a data table or summary list.' , title = 'System Name - Short' , ) description : str = Field ( ... , description = 'A summary of the system.' , title = 'System Description' ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) date_authorized : Optional [ DateAuthorized ] = Field ( None , alias = 'date-authorized' ) security_sensitivity_level : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , alias = 'security-sensitivity-level' , description = 'The overall information system sensitivity categorization, such as defined by FIPS-199.' , title = 'Security Sensitivity Level' , ) system_information : SystemInformation = Field ( ... , alias = 'system-information' ) security_impact_level : SecurityImpactLevel = Field ( ... , alias = 'security-impact-level' ) status : Status1 authorization_boundary : AuthorizationBoundary = Field ( ... , alias = 'authorization-boundary' ) network_architecture : Optional [ NetworkArchitecture ] = Field ( None , alias = 'network-architecture' ) data_flow : Optional [ DataFlow ] = Field ( None , alias = 'data-flow' ) responsible_parties : Optional [ List [ common . ResponsibleParty ]] = Field ( None , alias = 'responsible-parties' ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 authorization_boundary : AuthorizationBoundary pydantic-field required \u00a4 data_flow : DataFlow pydantic-field \u00a4 date_authorized : DateAuthorized pydantic-field \u00a4 description : str pydantic-field required \u00a4 A summary of the system. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 network_architecture : NetworkArchitecture pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 responsible_parties : List [ trestle . oscal . common . ResponsibleParty ] pydantic-field \u00a4 security_impact_level : SecurityImpactLevel pydantic-field required \u00a4 security_sensitivity_level : ConstrainedStrValue pydantic-field required \u00a4 The overall information system sensitivity categorization, such as defined by FIPS-199. status : Status1 pydantic-field required \u00a4 system_ids : List [ trestle . oscal . common . SystemId ] pydantic-field required \u00a4 system_information : SystemInformation pydantic-field required \u00a4 system_name : ConstrainedStrValue pydantic-field required \u00a4 The full name of the system. system_name_short : ConstrainedStrValue pydantic-field \u00a4 A short name for the system, such as an acronym, that is suitable for display in a data table or summary list. Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid SystemComponent ( OscalBaseModel ) pydantic-model \u00a4 A defined component that can be part of an implemented system. Source code in trestle/oscal/ssp.py class SystemComponent ( OscalBaseModel ): \"\"\" A defined component that can be part of an implemented system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Component Identifier' , ) type : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A category describing the purpose of the component.' , title = 'Component Type' , ) title : str = Field ( ... , description = 'A human readable name for the system component.' , title = 'Component Title' , ) description : str = Field ( ... , description = 'A description of the component, including information about its function.' , title = 'Component Description' , ) purpose : Optional [ str ] = Field ( None , description = 'A summary of the technological or business purpose of the component.' , title = 'Purpose' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : Status = Field ( ... , description = 'Describes the operational status of the system component.' , title = 'Status' , ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) protocols : Optional [ List [ common . Protocol ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None Attributes \u00a4 description : str pydantic-field required \u00a4 A description of the component, including information about its function. links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 protocols : List [ trestle . oscal . common . Protocol ] pydantic-field \u00a4 purpose : str pydantic-field \u00a4 A summary of the technological or business purpose of the component. remarks : Remarks pydantic-field \u00a4 responsible_roles : List [ trestle . oscal . common . ResponsibleRole ] pydantic-field \u00a4 status : Status pydantic-field required \u00a4 Describes the operational status of the system component. title : str pydantic-field required \u00a4 A human readable name for the system component. type : ConstrainedStrValue pydantic-field required \u00a4 A category describing the purpose of the component. uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid SystemImplementation ( OscalBaseModel ) pydantic-model \u00a4 Provides information as to how the system is implemented. Source code in trestle/oscal/ssp.py class SystemImplementation ( OscalBaseModel ): \"\"\" Provides information as to how the system is implemented. \"\"\" class Config : extra = Extra . forbid props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) leveraged_authorizations : Optional [ List [ LeveragedAuthorization ]] = Field ( None , alias = 'leveraged-authorizations' ) users : List [ common . SystemUser ] = Field ( ... ) components : List [ SystemComponent ] = Field ( ... ) inventory_items : Optional [ List [ common . InventoryItem ]] = Field ( None , alias = 'inventory-items' ) remarks : Optional [ common . Remarks ] = None components : List [ trestle . oscal . ssp . SystemComponent ] pydantic-field required \u00a4 inventory_items : List [ trestle . oscal . common . InventoryItem ] pydantic-field \u00a4 leveraged_authorizations : List [ trestle . oscal . ssp . LeveragedAuthorization ] pydantic-field \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 remarks : Remarks pydantic-field \u00a4 users : List [ trestle . oscal . common . SystemUser ] pydantic-field required \u00a4 Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid SystemInformation ( OscalBaseModel ) pydantic-model \u00a4 Contains details about all information types that are stored, processed, or transmitted by the system, such as privacy information, and those defined in NIST SP 800-60. Source code in trestle/oscal/ssp.py class SystemInformation ( OscalBaseModel ): \"\"\" Contains details about all information types that are stored, processed, or transmitted by the system, such as privacy information, and those defined in NIST SP 800-60. \"\"\" class Config : extra = Extra . forbid props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) information_types : List [ InformationType ] = Field ( ... , alias = 'information-types' ) information_types : List [ trestle . oscal . ssp . InformationType ] pydantic-field required \u00a4 links : List [ trestle . oscal . common . Link ] pydantic-field \u00a4 props : List [ trestle . oscal . common . Property ] pydantic-field \u00a4 Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid SystemSecurityPlan ( OscalBaseModel ) pydantic-model \u00a4 A system security plan, such as those described in NIST SP 800-18 Source code in trestle/oscal/ssp.py class SystemSecurityPlan ( OscalBaseModel ): \"\"\" A system security plan, such as those described in NIST SP 800-18 \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this system security plan (SSP) elsewhere in this or other OSCAL instances. The locally defined UUID of the SSP can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance).This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'System Security Plan Universally Unique Identifier' , ) metadata : common . Metadata import_profile : ImportProfile = Field ( ... , alias = 'import-profile' ) system_characteristics : SystemCharacteristics = Field ( ... , alias = 'system-characteristics' ) system_implementation : SystemImplementation = Field ( ... , alias = 'system-implementation' ) control_implementation : ControlImplementation = Field ( ... , alias = 'control-implementation' ) back_matter : Optional [ common . BackMatter ] = Field ( None , alias = 'back-matter' ) Attributes \u00a4 back_matter : BackMatter pydantic-field \u00a4 control_implementation : ControlImplementation pydantic-field required \u00a4 import_profile : ImportProfile pydantic-field required \u00a4 metadata : Metadata pydantic-field required \u00a4 system_characteristics : SystemCharacteristics pydantic-field required \u00a4 system_implementation : SystemImplementation pydantic-field required \u00a4 uuid : ConstrainedStrValue pydantic-field required \u00a4 A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this system security plan (SSP) elsewhere in this or other OSCAL instances. The locally defined UUID of the SSP can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance).This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document. Config \u00a4 Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid handler: python","title":"ssp"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp","text":"","title":"ssp"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AdjustmentJustification","text":"Source code in trestle/oscal/ssp.py class AdjustmentJustification ( OscalBaseModel ): __root__ : str = Field ( ... , description = 'If the selected security level is different from the base security level, this contains the justification for the change.' , title = 'Adjustment Justification' , )","title":"AdjustmentJustification"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AdjustmentJustification-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AdjustmentJustification.__root__","text":"If the selected security level is different from the base security level, this contains the justification for the change.","title":"__root__"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AuthorizationBoundary","text":"A description of this system's authorization boundary, optionally supplemented by diagrams that illustrate the authorization boundary. Source code in trestle/oscal/ssp.py class AuthorizationBoundary ( OscalBaseModel ): \"\"\" A description of this system's authorization boundary, optionally supplemented by diagrams that illustrate the authorization boundary. \"\"\" class Config : extra = Extra . forbid description : str = Field ( ... , description = \"A summary of the system's authorization boundary.\" , title = 'Authorization Boundary Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) diagrams : Optional [ List [ Diagram ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None","title":"AuthorizationBoundary"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AuthorizationBoundary-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AuthorizationBoundary.description","text":"A summary of the system's authorization boundary.","title":"description"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AuthorizationBoundary.diagrams","text":"","title":"diagrams"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AuthorizationBoundary.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AuthorizationBoundary.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AuthorizationBoundary.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AuthorizationBoundary.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AvailabilityImpact","text":"The expected level of impact resulting from the disruption of access to or use of the described information or the information system. Source code in trestle/oscal/ssp.py class AvailabilityImpact ( OscalBaseModel ): \"\"\" The expected level of impact resulting from the disruption of access to or use of the described information or the information system. \"\"\" class Config : extra = Extra . forbid props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) base : Base selected : Optional [ Selected ] = None adjustment_justification : Optional [ AdjustmentJustification ] = Field ( None , alias = 'adjustment-justification' )","title":"AvailabilityImpact"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AvailabilityImpact.adjustment_justification","text":"","title":"adjustment_justification"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AvailabilityImpact.base","text":"","title":"base"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AvailabilityImpact.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AvailabilityImpact.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AvailabilityImpact.selected","text":"","title":"selected"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.AvailabilityImpact.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Base","text":"Source code in trestle/oscal/ssp.py class Base ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'The prescribed base (Confidentiality, Integrity, or Availability) security impact level.' , title = 'Base Level (Confidentiality, Integrity, or Availability)' , )","title":"Base"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Base-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Base.__root__","text":"The prescribed base (Confidentiality, Integrity, or Availability) security impact level.","title":"__root__"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ByComponent","text":"Defines how the referenced component implements a set of controls. Source code in trestle/oscal/ssp.py class ByComponent ( OscalBaseModel ): \"\"\" Defines how the referenced component implements a set of controls. \"\"\" class Config : extra = Extra . forbid component_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'component-uuid' , description = 'A machine-oriented identifier reference to the component that is implemeting a given control.' , title = 'Component Universally Unique Identifier Reference' , ) uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this by-component entry elsewhere in this or other OSCAL instances. The locally defined UUID of the by-component entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'By-Component Universally Unique Identifier' , ) description : str = Field ( ... , description = 'An implementation statement that describes how a control or a control statement is implemented within the referenced system component.' , title = 'Control Implementation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) set_parameters : Optional [ List [ SetParameter ]] = Field ( None , alias = 'set-parameters' ) implementation_status : Optional [ common . ImplementationStatus ] = Field ( None , alias = 'implementation-status' ) export : Optional [ Export ] = Field ( None , description = 'Identifies content intended for external consumption, such as with leveraged organizations.' , title = 'Export' , ) inherited : Optional [ List [ Inherited ]] = Field ( None ) satisfied : Optional [ List [ Satisfied ]] = Field ( None ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None","title":"ByComponent"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ByComponent-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ByComponent.component_uuid","text":"A machine-oriented identifier reference to the component that is implemeting a given control.","title":"component_uuid"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ByComponent.description","text":"An implementation statement that describes how a control or a control statement is implemented within the referenced system component.","title":"description"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ByComponent.export","text":"Identifies content intended for external consumption, such as with leveraged organizations.","title":"export"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ByComponent.implementation_status","text":"","title":"implementation_status"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ByComponent.inherited","text":"","title":"inherited"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ByComponent.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ByComponent.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ByComponent.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ByComponent.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ByComponent.satisfied","text":"","title":"satisfied"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ByComponent.set_parameters","text":"","title":"set_parameters"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ByComponent.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this by-component entry elsewhere in this or other OSCAL instances. The locally defined UUID of the by-component entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ByComponent.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Categorization","text":"A set of information type identifiers qualified by the given identification system used, such as NIST SP 800-60. Source code in trestle/oscal/ssp.py class Categorization ( OscalBaseModel ): \"\"\" A set of information type identifiers qualified by the given identification system used, such as NIST SP 800-60. \"\"\" class Config : extra = Extra . forbid system : AnyUrl = Field ( ... , description = 'Specifies the information type identification system used.' , title = 'Information Type Identification System' , ) information_type_ids : Optional [ List [ InformationTypeId ]] = Field ( None , alias = 'information-type-ids' )","title":"Categorization"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Categorization-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Categorization.information_type_ids","text":"","title":"information_type_ids"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Categorization.system","text":"Specifies the information type identification system used.","title":"system"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Categorization.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ConfidentialityImpact","text":"The expected level of impact resulting from the unauthorized disclosure of the described information. Source code in trestle/oscal/ssp.py class ConfidentialityImpact ( OscalBaseModel ): \"\"\" The expected level of impact resulting from the unauthorized disclosure of the described information. \"\"\" class Config : extra = Extra . forbid props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) base : Base selected : Optional [ Selected ] = None adjustment_justification : Optional [ AdjustmentJustification ] = Field ( None , alias = 'adjustment-justification' )","title":"ConfidentialityImpact"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ConfidentialityImpact.adjustment_justification","text":"","title":"adjustment_justification"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ConfidentialityImpact.base","text":"","title":"base"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ConfidentialityImpact.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ConfidentialityImpact.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ConfidentialityImpact.selected","text":"","title":"selected"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ConfidentialityImpact.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ControlImplementation","text":"Describes how the system satisfies a set of controls. Source code in trestle/oscal/ssp.py class ControlImplementation ( OscalBaseModel ): \"\"\" Describes how the system satisfies a set of controls. \"\"\" class Config : extra = Extra . forbid description : str = Field ( ... , description = 'A statement describing important things to know about how this set of control satisfaction documentation is approached.' , title = 'Control Implementation Description' , ) set_parameters : Optional [ List [ SetParameter ]] = Field ( None , alias = 'set-parameters' ) implemented_requirements : List [ ImplementedRequirement ] = Field ( ... , alias = 'implemented-requirements' )","title":"ControlImplementation"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ControlImplementation-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ControlImplementation.description","text":"A statement describing important things to know about how this set of control satisfaction documentation is approached.","title":"description"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ControlImplementation.implemented_requirements","text":"","title":"implemented_requirements"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ControlImplementation.set_parameters","text":"","title":"set_parameters"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ControlImplementation.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.DataFlow","text":"A description of the logical flow of information within the system and across its boundaries, optionally supplemented by diagrams that illustrate these flows. Source code in trestle/oscal/ssp.py class DataFlow ( OscalBaseModel ): \"\"\" A description of the logical flow of information within the system and across its boundaries, optionally supplemented by diagrams that illustrate these flows. \"\"\" class Config : extra = Extra . forbid description : str = Field ( ... , description = \"A summary of the system's data flow.\" , title = 'Data Flow Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) diagrams : Optional [ List [ Diagram ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None","title":"DataFlow"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.DataFlow-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.DataFlow.description","text":"A summary of the system's data flow.","title":"description"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.DataFlow.diagrams","text":"","title":"diagrams"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.DataFlow.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.DataFlow.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.DataFlow.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.DataFlow.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.DateAuthorized","text":"Source code in trestle/oscal/ssp.py class DateAuthorized ( OscalBaseModel ): __root__ : constr ( regex = r '^((2000|2400|2800|(19|2[0-9](0[48]|[2468][048]|[13579][26])))-02-29)|(((19|2[0-9])[0-9] {2} )-02-(0[1-9]|1[0-9]|2[0-8]))|(((19|2[0-9])[0-9] {2} )-(0[13578]|10|12)-(0[1-9]|[12][0-9]|3[01]))|(((19|2[0-9])[0-9] {2} )-(0[469]|11)-(0[1-9]|[12][0-9]|30))(Z|[+-][0-9] {2} :[0-9] {2} )?$' ) = Field ( ... , description = 'The date the system received its authorization.' , title = 'System Authorization Date' , )","title":"DateAuthorized"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.DateAuthorized-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.DateAuthorized.__root__","text":"The date the system received its authorization.","title":"__root__"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Diagram","text":"A graphic that provides a visual representation the system, or some aspect of it. Source code in trestle/oscal/ssp.py class Diagram ( OscalBaseModel ): \"\"\" A graphic that provides a visual representation the system, or some aspect of it. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this diagram elsewhere in this or other OSCAL instances. The locally defined UUID of the diagram can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Diagram ID' , ) description : Optional [ str ] = Field ( None , description = 'A summary of the diagram.' , title = 'Diagram Description' ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) caption : Optional [ str ] = Field ( None , description = 'A brief caption to annotate the diagram.' , title = 'Caption' ) remarks : Optional [ common . Remarks ] = None","title":"Diagram"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Diagram-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Diagram.caption","text":"A brief caption to annotate the diagram.","title":"caption"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Diagram.description","text":"A summary of the diagram.","title":"description"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Diagram.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Diagram.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Diagram.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Diagram.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this diagram elsewhere in this or other OSCAL instances. The locally defined UUID of the diagram can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Diagram.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Export","text":"Identifies content intended for external consumption, such as with leveraged organizations. Source code in trestle/oscal/ssp.py class Export ( OscalBaseModel ): \"\"\" Identifies content intended for external consumption, such as with leveraged organizations. \"\"\" class Config : extra = Extra . forbid description : Optional [ str ] = Field ( None , description = 'An implementation statement that describes the aspects of the control or control statement implementation that can be available to another system leveraging this system.' , title = 'Control Implementation Export Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) provided : Optional [ List [ Provided ]] = Field ( None ) responsibilities : Optional [ List [ Responsibility ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None","title":"Export"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Export-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Export.description","text":"An implementation statement that describes the aspects of the control or control statement implementation that can be available to another system leveraging this system.","title":"description"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Export.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Export.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Export.provided","text":"","title":"provided"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Export.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Export.responsibilities","text":"","title":"responsibilities"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Export.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ImplementedRequirement","text":"Describes how the system satisfies an individual control. Source code in trestle/oscal/ssp.py class ImplementedRequirement ( OscalBaseModel ): \"\"\" Describes how the system satisfies an individual control. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this control requirement elsewhere in this or other OSCAL instances. The locally defined UUID of the control requirement can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Control Requirement Universally Unique Identifier' , ) control_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'control-id' , description = 'A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).' , title = 'Control Identifier Reference' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) set_parameters : Optional [ List [ SetParameter ]] = Field ( None , alias = 'set-parameters' ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) statements : Optional [ List [ Statement ]] = Field ( None ) by_components : Optional [ List [ ByComponent ]] = Field ( None , alias = 'by-components' ) remarks : Optional [ common . Remarks ] = None","title":"ImplementedRequirement"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ImplementedRequirement-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ImplementedRequirement.by_components","text":"","title":"by_components"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ImplementedRequirement.control_id","text":"A human-oriented identifier reference to a control with a corresponding id value. When referencing an externally defined control, the Control Identifier Reference must be used in the context of the external / imported OSCAL instance (e.g., uri-reference).","title":"control_id"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ImplementedRequirement.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ImplementedRequirement.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ImplementedRequirement.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ImplementedRequirement.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ImplementedRequirement.set_parameters","text":"","title":"set_parameters"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ImplementedRequirement.statements","text":"","title":"statements"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ImplementedRequirement.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this control requirement elsewhere in this or other OSCAL instances. The locally defined UUID of the control requirement can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ImplementedRequirement.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ImportProfile","text":"Used to import the OSCAL profile representing the system's control baseline. Source code in trestle/oscal/ssp.py class ImportProfile ( OscalBaseModel ): \"\"\" Used to import the OSCAL profile representing the system's control baseline. \"\"\" class Config : extra = Extra . forbid href : str = Field ( ... , description = \"A resolvable URL reference to the profile to use as the system's control baseline.\" , title = 'Profile Reference' , ) remarks : Optional [ common . Remarks ] = None","title":"ImportProfile"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ImportProfile-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ImportProfile.href","text":"A resolvable URL reference to the profile to use as the system's control baseline.","title":"href"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ImportProfile.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.ImportProfile.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.InformationType","text":"Contains details about one information type that is stored, processed, or transmitted by the system, such as privacy information, and those defined in NIST SP 800-60. Source code in trestle/oscal/ssp.py class InformationType ( OscalBaseModel ): \"\"\" Contains details about one information type that is stored, processed, or transmitted by the system, such as privacy information, and those defined in NIST SP 800-60. \"\"\" class Config : extra = Extra . forbid uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this information type elsewhere in this or other OSCAL instances. The locally defined UUID of the information type can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Information Type Universally Unique Identifier' , ) title : str = Field ( ... , description = 'A human readable name for the information type. This title should be meaningful within the context of the system.' , title = 'title field' , ) description : str = Field ( ... , description = 'A summary of how this information type is used within the system.' , title = 'Information Type Description' , ) categorizations : Optional [ List [ Categorization ]] = Field ( None ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) confidentiality_impact : ConfidentialityImpact = Field ( ... , alias = 'confidentiality-impact' , description = 'The expected level of impact resulting from the unauthorized disclosure of the described information.' , title = 'Confidentiality Impact Level' , ) integrity_impact : IntegrityImpact = Field ( ... , alias = 'integrity-impact' , description = 'The expected level of impact resulting from the unauthorized modification of the described information.' , title = 'Integrity Impact Level' , ) availability_impact : AvailabilityImpact = Field ( ... , alias = 'availability-impact' , description = 'The expected level of impact resulting from the disruption of access to or use of the described information or the information system.' , title = 'Availability Impact Level' , )","title":"InformationType"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.InformationType-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.InformationType.availability_impact","text":"The expected level of impact resulting from the disruption of access to or use of the described information or the information system.","title":"availability_impact"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.InformationType.categorizations","text":"","title":"categorizations"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.InformationType.confidentiality_impact","text":"The expected level of impact resulting from the unauthorized disclosure of the described information.","title":"confidentiality_impact"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.InformationType.description","text":"A summary of how this information type is used within the system.","title":"description"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.InformationType.integrity_impact","text":"The expected level of impact resulting from the unauthorized modification of the described information.","title":"integrity_impact"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.InformationType.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.InformationType.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.InformationType.title","text":"A human readable name for the information type. This title should be meaningful within the context of the system.","title":"title"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.InformationType.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this information type elsewhere in this or other OSCAL instances. The locally defined UUID of the information type can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.InformationType.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.InformationTypeId","text":"Source code in trestle/oscal/ssp.py class InformationTypeId ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A human-oriented, globally unique identifier qualified by the given identification system used, such as NIST SP 800-60. This identifier has cross-instance scope and can be used to reference this system elsewhere in this or other OSCAL instances. This id should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Information Type Systematized Identifier' , )","title":"InformationTypeId"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.InformationTypeId-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.InformationTypeId.__root__","text":"A human-oriented, globally unique identifier qualified by the given identification system used, such as NIST SP 800-60. This identifier has cross-instance scope and can be used to reference this system elsewhere in this or other OSCAL instances. This id should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"__root__"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Inherited","text":"Describes a control implementation inherited by a leveraging system. Source code in trestle/oscal/ssp.py class Inherited ( OscalBaseModel ): \"\"\" Describes a control implementation inherited by a leveraging system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this inherited entry elsewhere in this or other OSCAL instances. The locally defined UUID of the inherited control implementation can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Inherited Universally Unique Identifier' , ) provided_uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , alias = 'provided-uuid' , description = 'A machine-oriented identifier reference to an inherited control implementation that a leveraging system is inheriting from a leveraged system.' , title = 'Provided UUID' , ) description : str = Field ( ... , description = 'An implementation statement that describes the aspects of a control or control statement implementation that a leveraging system is inheriting from a leveraged system.' , title = 'Inherited Control Implementation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' )","title":"Inherited"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Inherited-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Inherited.description","text":"An implementation statement that describes the aspects of a control or control statement implementation that a leveraging system is inheriting from a leveraged system.","title":"description"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Inherited.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Inherited.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Inherited.provided_uuid","text":"A machine-oriented identifier reference to an inherited control implementation that a leveraging system is inheriting from a leveraged system.","title":"provided_uuid"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Inherited.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Inherited.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this inherited entry elsewhere in this or other OSCAL instances. The locally defined UUID of the inherited control implementation can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Inherited.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.IntegrityImpact","text":"The expected level of impact resulting from the unauthorized modification of the described information. Source code in trestle/oscal/ssp.py class IntegrityImpact ( OscalBaseModel ): \"\"\" The expected level of impact resulting from the unauthorized modification of the described information. \"\"\" class Config : extra = Extra . forbid props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) base : Base selected : Optional [ Selected ] = None adjustment_justification : Optional [ AdjustmentJustification ] = Field ( None , alias = 'adjustment-justification' )","title":"IntegrityImpact"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.IntegrityImpact.adjustment_justification","text":"","title":"adjustment_justification"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.IntegrityImpact.base","text":"","title":"base"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.IntegrityImpact.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.IntegrityImpact.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.IntegrityImpact.selected","text":"","title":"selected"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.IntegrityImpact.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.LeveragedAuthorization","text":"A description of another authorized system from which this system inherits capabilities that satisfy security requirements. Another term for this concept is a common control provider. Source code in trestle/oscal/ssp.py class LeveragedAuthorization ( OscalBaseModel ): \"\"\" A description of another authorized system from which this system inherits capabilities that satisfy security requirements. Another term for this concept is a common control provider. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope and can be used to reference this leveraged authorization elsewhere in this or other OSCAL instances. The locally defined UUID of the leveraged authorization can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Leveraged Authorization Universally Unique Identifier' , ) title : str = Field ( ... , description = 'A human readable name for the leveraged authorization in the context of the system.' , title = 'title field' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) party_uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , alias = 'party-uuid' , description = 'A machine-oriented identifier reference to the party that manages the leveraged system.' , title = 'party-uuid field' , ) date_authorized : DateAuthorized = Field ( ... , alias = 'date-authorized' ) remarks : Optional [ common . Remarks ] = None","title":"LeveragedAuthorization"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.LeveragedAuthorization-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.LeveragedAuthorization.date_authorized","text":"","title":"date_authorized"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.LeveragedAuthorization.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.LeveragedAuthorization.party_uuid","text":"A machine-oriented identifier reference to the party that manages the leveraged system.","title":"party_uuid"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.LeveragedAuthorization.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.LeveragedAuthorization.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.LeveragedAuthorization.title","text":"A human readable name for the leveraged authorization in the context of the system.","title":"title"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.LeveragedAuthorization.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope and can be used to reference this leveraged authorization elsewhere in this or other OSCAL instances. The locally defined UUID of the leveraged authorization can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.LeveragedAuthorization.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Model","text":"Source code in trestle/oscal/ssp.py class Model ( OscalBaseModel ): system_security_plan : SystemSecurityPlan = Field ( ... , alias = 'system-security-plan' )","title":"Model"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Model.system_security_plan","text":"","title":"system_security_plan"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.NetworkArchitecture","text":"A description of the system's network architecture, optionally supplemented by diagrams that illustrate the network architecture. Source code in trestle/oscal/ssp.py class NetworkArchitecture ( OscalBaseModel ): \"\"\" A description of the system's network architecture, optionally supplemented by diagrams that illustrate the network architecture. \"\"\" class Config : extra = Extra . forbid description : str = Field ( ... , description = \"A summary of the system's network architecture.\" , title = 'Network Architecture Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) diagrams : Optional [ List [ Diagram ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None","title":"NetworkArchitecture"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.NetworkArchitecture-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.NetworkArchitecture.description","text":"A summary of the system's network architecture.","title":"description"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.NetworkArchitecture.diagrams","text":"","title":"diagrams"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.NetworkArchitecture.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.NetworkArchitecture.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.NetworkArchitecture.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.NetworkArchitecture.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Provided","text":"Describes a capability which may be inherited by a leveraging system. Source code in trestle/oscal/ssp.py class Provided ( OscalBaseModel ): \"\"\" Describes a capability which may be inherited by a leveraging system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this provided entry elsewhere in this or other OSCAL instances. The locally defined UUID of the provided entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Provided Universally Unique Identifier' , ) description : str = Field ( ... , description = 'An implementation statement that describes the aspects of the control or control statement implementation that can be provided to another system leveraging this system.' , title = 'Provided Control Implementation Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None","title":"Provided"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Provided-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Provided.description","text":"An implementation statement that describes the aspects of the control or control statement implementation that can be provided to another system leveraging this system.","title":"description"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Provided.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Provided.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Provided.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Provided.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Provided.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this provided entry elsewhere in this or other OSCAL instances. The locally defined UUID of the provided entry can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Provided.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Responsibility","text":"Describes a control implementation responsibility imposed on a leveraging system. Source code in trestle/oscal/ssp.py class Responsibility ( OscalBaseModel ): \"\"\" Describes a control implementation responsibility imposed on a leveraging system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this responsibility elsewhere in this or other OSCAL instances. The locally defined UUID of the responsibility can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Responsibility Universally Unique Identifier' , ) provided_uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , alias = 'provided-uuid' , description = 'A machine-oriented identifier reference to an inherited control implementation that a leveraging system is inheriting from a leveraged system.' , title = 'Provided UUID' , ) description : str = Field ( ... , description = 'An implementation statement that describes the aspects of the control or control statement implementation that a leveraging system must implement to satisfy the control provided by a leveraged system.' , title = 'Control Implementation Responsibility Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None","title":"Responsibility"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Responsibility-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Responsibility.description","text":"An implementation statement that describes the aspects of the control or control statement implementation that a leveraging system must implement to satisfy the control provided by a leveraged system.","title":"description"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Responsibility.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Responsibility.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Responsibility.provided_uuid","text":"A machine-oriented identifier reference to an inherited control implementation that a leveraging system is inheriting from a leveraged system.","title":"provided_uuid"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Responsibility.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Responsibility.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Responsibility.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this responsibility elsewhere in this or other OSCAL instances. The locally defined UUID of the responsibility can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Responsibility.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Satisfied","text":"Describes how this system satisfies a responsibility imposed by a leveraged system. Source code in trestle/oscal/ssp.py class Satisfied ( OscalBaseModel ): \"\"\" Describes how this system satisfies a responsibility imposed by a leveraged system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this satisfied control implementation entry elsewhere in this or other OSCAL instances. The locally defined UUID of the control implementation can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Satisfied Universally Unique Identifier' , ) responsibility_uuid : Optional [ constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' )] = Field ( None , alias = 'responsibility-uuid' , description = 'A machine-oriented identifier reference to a control implementation that satisfies a responsibility imposed by a leveraged system.' , title = 'Responsibility UUID' , ) description : str = Field ( ... , description = 'An implementation statement that describes the aspects of a control or control statement implementation that a leveraging system is implementing based on a requirement from a leveraged system.' , title = 'Satisfied Control Implementation Responsibility Description' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) remarks : Optional [ common . Remarks ] = None","title":"Satisfied"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Satisfied-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Satisfied.description","text":"An implementation statement that describes the aspects of a control or control statement implementation that a leveraging system is implementing based on a requirement from a leveraged system.","title":"description"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Satisfied.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Satisfied.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Satisfied.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Satisfied.responsibility_uuid","text":"A machine-oriented identifier reference to a control implementation that satisfies a responsibility imposed by a leveraged system.","title":"responsibility_uuid"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Satisfied.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Satisfied.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this satisfied control implementation entry elsewhere in this or other OSCAL instances. The locally defined UUID of the control implementation can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Satisfied.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SecurityImpactLevel","text":"The overall level of expected impact resulting from unauthorized disclosure, modification, or loss of access to information. Source code in trestle/oscal/ssp.py class SecurityImpactLevel ( OscalBaseModel ): \"\"\" The overall level of expected impact resulting from unauthorized disclosure, modification, or loss of access to information. \"\"\" class Config : extra = Extra . forbid security_objective_confidentiality : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , alias = 'security-objective-confidentiality' , description = 'A target-level of confidentiality for the system, based on the sensitivity of information within the system.' , title = 'Security Objective: Confidentiality' , ) security_objective_integrity : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , alias = 'security-objective-integrity' , description = 'A target-level of integrity for the system, based on the sensitivity of information within the system.' , title = 'Security Objective: Integrity' , ) security_objective_availability : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , alias = 'security-objective-availability' , description = 'A target-level of availability for the system, based on the sensitivity of information within the system.' , title = 'Security Objective: Availability' , )","title":"SecurityImpactLevel"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SecurityImpactLevel-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SecurityImpactLevel.security_objective_availability","text":"A target-level of availability for the system, based on the sensitivity of information within the system.","title":"security_objective_availability"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SecurityImpactLevel.security_objective_confidentiality","text":"A target-level of confidentiality for the system, based on the sensitivity of information within the system.","title":"security_objective_confidentiality"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SecurityImpactLevel.security_objective_integrity","text":"A target-level of integrity for the system, based on the sensitivity of information within the system.","title":"security_objective_integrity"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SecurityImpactLevel.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Selected","text":"Source code in trestle/oscal/ssp.py class Selected ( OscalBaseModel ): __root__ : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'The selected (Confidentiality, Integrity, or Availability) security impact level.' , title = 'Selected Level (Confidentiality, Integrity, or Availability)' , )","title":"Selected"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Selected-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Selected.__root__","text":"The selected (Confidentiality, Integrity, or Availability) security impact level.","title":"__root__"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SetParameter","text":"Identifies the parameter that will be set by the enclosed value. Source code in trestle/oscal/ssp.py class SetParameter ( OscalBaseModel ): \"\"\" Identifies the parameter that will be set by the enclosed value. \"\"\" class Config : extra = Extra . forbid param_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'param-id' , description = \"A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context.\" , title = 'Parameter ID' , ) values : List [ common . Value ] = Field ( ... ) remarks : Optional [ common . Remarks ] = None","title":"SetParameter"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SetParameter-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SetParameter.param_id","text":"A human-oriented reference to a parameter within a control, who's catalog has been imported into the current implementation context.","title":"param_id"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SetParameter.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SetParameter.values","text":"","title":"values"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SetParameter.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.State","text":"The current operating status. Source code in trestle/oscal/ssp.py class State ( Enum ): \"\"\" The current operating status. \"\"\" operational = 'operational' under_development = 'under-development' under_major_modification = 'under-major-modification' disposition = 'disposition' other = 'other'","title":"State"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.State.disposition","text":"","title":"disposition"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.State.operational","text":"","title":"operational"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.State.other","text":"","title":"other"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.State.under_development","text":"","title":"under_development"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.State.under_major_modification","text":"","title":"under_major_modification"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.State1","text":"The operational status. Source code in trestle/oscal/ssp.py class State1 ( Enum ): \"\"\" The operational status. \"\"\" under_development = 'under-development' operational = 'operational' disposition = 'disposition' other = 'other'","title":"State1"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.State1.disposition","text":"","title":"disposition"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.State1.operational","text":"","title":"operational"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.State1.other","text":"","title":"other"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.State1.under_development","text":"","title":"under_development"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Statement","text":"Identifies which statements within a control are addressed. Source code in trestle/oscal/ssp.py class Statement ( OscalBaseModel ): \"\"\" Identifies which statements within a control are addressed. \"\"\" class Config : extra = Extra . forbid statement_id : constr ( regex = r '^[_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][_A-Za-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-\\.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$' ) = Field ( ... , alias = 'statement-id' , description = 'A human-oriented identifier reference to a control statement.' , title = 'Control Statement Reference' , ) uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this control statement elsewhere in this or other OSCAL instances. The UUID of the control statement in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance).' , title = 'Control Statement Reference Universally Unique Identifier' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) by_components : Optional [ List [ ByComponent ]] = Field ( None , alias = 'by-components' ) remarks : Optional [ common . Remarks ] = None","title":"Statement"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Statement-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Statement.by_components","text":"","title":"by_components"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Statement.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Statement.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Statement.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Statement.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Statement.statement_id","text":"A human-oriented identifier reference to a control statement.","title":"statement_id"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Statement.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this control statement elsewhere in this or other OSCAL instances. The UUID of the control statement in the source OSCAL instance is sufficient to reference the data item locally or globally (e.g., in an imported OSCAL instance).","title":"uuid"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Statement.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Status","text":"Describes the operational status of the system component. Source code in trestle/oscal/ssp.py class Status ( OscalBaseModel ): \"\"\" Describes the operational status of the system component. \"\"\" class Config : extra = Extra . forbid state : State1 = Field ( ... , description = 'The operational status.' , title = 'State' ) remarks : Optional [ common . Remarks ] = None","title":"Status"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Status-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Status.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Status.state","text":"The operational status.","title":"state"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Status.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Status1","text":"Describes the operational status of the system. Source code in trestle/oscal/ssp.py class Status1 ( OscalBaseModel ): \"\"\" Describes the operational status of the system. \"\"\" class Config : extra = Extra . forbid state : State = Field ( ... , description = 'The current operating status.' , title = 'State' ) remarks : Optional [ common . Remarks ] = None","title":"Status1"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Status1-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Status1.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Status1.state","text":"The current operating status.","title":"state"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.Status1.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics","text":"Contains the characteristics of the system, such as its name, purpose, and security impact level. Source code in trestle/oscal/ssp.py class SystemCharacteristics ( OscalBaseModel ): \"\"\" Contains the characteristics of the system, such as its name, purpose, and security impact level. \"\"\" class Config : extra = Extra . forbid system_ids : List [ common . SystemId ] = Field ( ... , alias = 'system-ids' ) system_name : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , alias = 'system-name' , description = 'The full name of the system.' , title = 'System Name - Full' , ) system_name_short : Optional [ constr ( regex = r '^\\S(.*\\S)?$' )] = Field ( None , alias = 'system-name-short' , description = 'A short name for the system, such as an acronym, that is suitable for display in a data table or summary list.' , title = 'System Name - Short' , ) description : str = Field ( ... , description = 'A summary of the system.' , title = 'System Description' ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) date_authorized : Optional [ DateAuthorized ] = Field ( None , alias = 'date-authorized' ) security_sensitivity_level : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , alias = 'security-sensitivity-level' , description = 'The overall information system sensitivity categorization, such as defined by FIPS-199.' , title = 'Security Sensitivity Level' , ) system_information : SystemInformation = Field ( ... , alias = 'system-information' ) security_impact_level : SecurityImpactLevel = Field ( ... , alias = 'security-impact-level' ) status : Status1 authorization_boundary : AuthorizationBoundary = Field ( ... , alias = 'authorization-boundary' ) network_architecture : Optional [ NetworkArchitecture ] = Field ( None , alias = 'network-architecture' ) data_flow : Optional [ DataFlow ] = Field ( None , alias = 'data-flow' ) responsible_parties : Optional [ List [ common . ResponsibleParty ]] = Field ( None , alias = 'responsible-parties' ) remarks : Optional [ common . Remarks ] = None","title":"SystemCharacteristics"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics.authorization_boundary","text":"","title":"authorization_boundary"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics.data_flow","text":"","title":"data_flow"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics.date_authorized","text":"","title":"date_authorized"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics.description","text":"A summary of the system.","title":"description"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics.network_architecture","text":"","title":"network_architecture"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics.responsible_parties","text":"","title":"responsible_parties"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics.security_impact_level","text":"","title":"security_impact_level"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics.security_sensitivity_level","text":"The overall information system sensitivity categorization, such as defined by FIPS-199.","title":"security_sensitivity_level"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics.status","text":"","title":"status"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics.system_ids","text":"","title":"system_ids"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics.system_information","text":"","title":"system_information"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics.system_name","text":"The full name of the system.","title":"system_name"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics.system_name_short","text":"A short name for the system, such as an acronym, that is suitable for display in a data table or summary list.","title":"system_name_short"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemCharacteristics.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemComponent","text":"A defined component that can be part of an implemented system. Source code in trestle/oscal/ssp.py class SystemComponent ( OscalBaseModel ): \"\"\" A defined component that can be part of an implemented system. \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'Component Identifier' , ) type : constr ( regex = r '^\\S(.*\\S)?$' ) = Field ( ... , description = 'A category describing the purpose of the component.' , title = 'Component Type' , ) title : str = Field ( ... , description = 'A human readable name for the system component.' , title = 'Component Title' , ) description : str = Field ( ... , description = 'A description of the component, including information about its function.' , title = 'Component Description' , ) purpose : Optional [ str ] = Field ( None , description = 'A summary of the technological or business purpose of the component.' , title = 'Purpose' , ) props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) status : Status = Field ( ... , description = 'Describes the operational status of the system component.' , title = 'Status' , ) responsible_roles : Optional [ List [ common . ResponsibleRole ]] = Field ( None , alias = 'responsible-roles' ) protocols : Optional [ List [ common . Protocol ]] = Field ( None ) remarks : Optional [ common . Remarks ] = None","title":"SystemComponent"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemComponent-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemComponent.description","text":"A description of the component, including information about its function.","title":"description"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemComponent.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemComponent.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemComponent.protocols","text":"","title":"protocols"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemComponent.purpose","text":"A summary of the technological or business purpose of the component.","title":"purpose"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemComponent.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemComponent.responsible_roles","text":"","title":"responsible_roles"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemComponent.status","text":"Describes the operational status of the system component.","title":"status"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemComponent.title","text":"A human readable name for the system component.","title":"title"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemComponent.type","text":"A category describing the purpose of the component.","title":"type"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemComponent.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this component elsewhere in this or other OSCAL instances. The locally defined UUID of the component can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance). This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemComponent.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemImplementation","text":"Provides information as to how the system is implemented. Source code in trestle/oscal/ssp.py class SystemImplementation ( OscalBaseModel ): \"\"\" Provides information as to how the system is implemented. \"\"\" class Config : extra = Extra . forbid props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) leveraged_authorizations : Optional [ List [ LeveragedAuthorization ]] = Field ( None , alias = 'leveraged-authorizations' ) users : List [ common . SystemUser ] = Field ( ... ) components : List [ SystemComponent ] = Field ( ... ) inventory_items : Optional [ List [ common . InventoryItem ]] = Field ( None , alias = 'inventory-items' ) remarks : Optional [ common . Remarks ] = None","title":"SystemImplementation"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemImplementation.components","text":"","title":"components"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemImplementation.inventory_items","text":"","title":"inventory_items"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemImplementation.leveraged_authorizations","text":"","title":"leveraged_authorizations"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemImplementation.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemImplementation.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemImplementation.remarks","text":"","title":"remarks"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemImplementation.users","text":"","title":"users"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemImplementation.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemInformation","text":"Contains details about all information types that are stored, processed, or transmitted by the system, such as privacy information, and those defined in NIST SP 800-60. Source code in trestle/oscal/ssp.py class SystemInformation ( OscalBaseModel ): \"\"\" Contains details about all information types that are stored, processed, or transmitted by the system, such as privacy information, and those defined in NIST SP 800-60. \"\"\" class Config : extra = Extra . forbid props : Optional [ List [ common . Property ]] = Field ( None ) links : Optional [ List [ common . Link ]] = Field ( None ) information_types : List [ InformationType ] = Field ( ... , alias = 'information-types' )","title":"SystemInformation"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemInformation.information_types","text":"","title":"information_types"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemInformation.links","text":"","title":"links"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemInformation.props","text":"","title":"props"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemInformation.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid","title":"Config"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemSecurityPlan","text":"A system security plan, such as those described in NIST SP 800-18 Source code in trestle/oscal/ssp.py class SystemSecurityPlan ( OscalBaseModel ): \"\"\" A system security plan, such as those described in NIST SP 800-18 \"\"\" class Config : extra = Extra . forbid uuid : constr ( regex = r '^[0-9A-Fa-f] {8} -[0-9A-Fa-f] {4} -4[0-9A-Fa-f] {3} -[89ABab][0-9A-Fa-f] {3} -[0-9A-Fa-f] {12} $' ) = Field ( ... , description = 'A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this system security plan (SSP) elsewhere in this or other OSCAL instances. The locally defined UUID of the SSP can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance).This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.' , title = 'System Security Plan Universally Unique Identifier' , ) metadata : common . Metadata import_profile : ImportProfile = Field ( ... , alias = 'import-profile' ) system_characteristics : SystemCharacteristics = Field ( ... , alias = 'system-characteristics' ) system_implementation : SystemImplementation = Field ( ... , alias = 'system-implementation' ) control_implementation : ControlImplementation = Field ( ... , alias = 'control-implementation' ) back_matter : Optional [ common . BackMatter ] = Field ( None , alias = 'back-matter' )","title":"SystemSecurityPlan"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemSecurityPlan-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemSecurityPlan.back_matter","text":"","title":"back_matter"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemSecurityPlan.control_implementation","text":"","title":"control_implementation"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemSecurityPlan.import_profile","text":"","title":"import_profile"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemSecurityPlan.metadata","text":"","title":"metadata"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemSecurityPlan.system_characteristics","text":"","title":"system_characteristics"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemSecurityPlan.system_implementation","text":"","title":"system_implementation"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemSecurityPlan.uuid","text":"A machine-oriented, globally unique identifier with cross-instance scope that can be used to reference this system security plan (SSP) elsewhere in this or other OSCAL instances. The locally defined UUID of the SSP can be used to reference the data item locally or globally (e.g., in an imported OSCAL instance).This UUID should be assigned per-subject, which means it should be consistently used to identify the same subject across revisions of the document.","title":"uuid"},{"location":"api_reference/trestle.oscal.ssp/#trestle.oscal.ssp.SystemSecurityPlan.Config","text":"Source code in trestle/oscal/ssp.py class Config : extra = Extra . forbid handler: python","title":"Config"},{"location":"api_reference/trestle.tasks.base_task/","text":"trestle.tasks.base_task \u00a4 Trestle tasks base templating. logger \u00a4 Classes \u00a4 PassFail ( TaskBase ) \u00a4 Holding pattern template for a task which does nothing and always passes. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/base_task.py class PassFail ( TaskBase ): \"\"\" Holding pattern template for a task which does nothing and always passes. Attributes: name: Name of the task. \"\"\" name = 'pass-fail' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task pass-fail. Attributes: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( 'This is a template task which reports pass fail depending on the specific configuration.' ) logger . info ( 'In this case if no config section is provided the task will fail. This a a task specific behavior.' ) logger . info ( 'Configuration flags sit under [task.pass-fail]' ) logger . info ( 'with two boolean flags' ) logger . info ( 'execute_status = True/False with a default pass' ) logger . info ( 'simulate_status = True/False with a default fail' ) logger . info ( 'Note that if the config file does not have the appropriate section this should fail.' ) logger . info ( 'The princple goal is a simple development example.' ) def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" if self . _config : outcome = self . _config . getboolean ( 'simulate_status' , fallback = True ) if outcome : return TaskOutcome ( 'simulated-success' ) return TaskOutcome ( 'simulated-failure' ) def execute ( self ) -> TaskOutcome : \"\"\"Provide a actual outcome.\"\"\" if self . _config : outcome = self . _config . getboolean ( 'execute_status' , fallback = True ) if outcome : return TaskOutcome ( 'success' ) return TaskOutcome ( 'failure' ) name : str \u00a4 Methods \u00a4 __init__ ( self , config_object ) special \u00a4 Initialize trestle task pass-fail. Attributes: Name Type Description config_object Config section associated with the task. Source code in trestle/tasks/base_task.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task pass-fail. Attributes: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) execute ( self ) \u00a4 Provide a actual outcome. Source code in trestle/tasks/base_task.py def execute ( self ) -> TaskOutcome : \"\"\"Provide a actual outcome.\"\"\" if self . _config : outcome = self . _config . getboolean ( 'execute_status' , fallback = True ) if outcome : return TaskOutcome ( 'success' ) return TaskOutcome ( 'failure' ) print_info ( self ) \u00a4 Print the help string. Source code in trestle/tasks/base_task.py def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( 'This is a template task which reports pass fail depending on the specific configuration.' ) logger . info ( 'In this case if no config section is provided the task will fail. This a a task specific behavior.' ) logger . info ( 'Configuration flags sit under [task.pass-fail]' ) logger . info ( 'with two boolean flags' ) logger . info ( 'execute_status = True/False with a default pass' ) logger . info ( 'simulate_status = True/False with a default fail' ) logger . info ( 'Note that if the config file does not have the appropriate section this should fail.' ) logger . info ( 'The princple goal is a simple development example.' ) simulate ( self ) \u00a4 Provide a simulated outcome. Source code in trestle/tasks/base_task.py def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" if self . _config : outcome = self . _config . getboolean ( 'simulate_status' , fallback = True ) if outcome : return TaskOutcome ( 'simulated-success' ) return TaskOutcome ( 'simulated-failure' ) TaskBase ( ABC ) \u00a4 Abstract base class for tasks. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/base_task.py class TaskBase ( ABC ): \"\"\" Abstract base class for tasks. Attributes: name: Name of the task. \"\"\" name : str = 'base' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\"Initialize task base and store config.\"\"\" self . _config = config_object @abstractmethod def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" @abstractmethod def execute ( self ) -> TaskOutcome : \"\"\"Execute the task including potential rollback.\"\"\" @abstractmethod def simulate ( self ) -> TaskOutcome : \"\"\"Simulate the task and report task outcome.\"\"\" name : str \u00a4 Methods \u00a4 __init__ ( self , config_object ) special \u00a4 Initialize task base and store config. Source code in trestle/tasks/base_task.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\"Initialize task base and store config.\"\"\" self . _config = config_object execute ( self ) \u00a4 Execute the task including potential rollback. Source code in trestle/tasks/base_task.py @abstractmethod def execute ( self ) -> TaskOutcome : \"\"\"Execute the task including potential rollback.\"\"\" print_info ( self ) \u00a4 Print the help string. Source code in trestle/tasks/base_task.py @abstractmethod def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" simulate ( self ) \u00a4 Simulate the task and report task outcome. Source code in trestle/tasks/base_task.py @abstractmethod def simulate ( self ) -> TaskOutcome : \"\"\"Simulate the task and report task outcome.\"\"\" TaskOutcome ( Enum ) \u00a4 Enum describing possible task outcomes. Source code in trestle/tasks/base_task.py class TaskOutcome ( Enum ): \"\"\"Enum describing possible task outcomes.\"\"\" SUCCESS = 'success' FAILURE = 'failure' ROLLEDBACK = 'rolledback' SIM_SUCCESS = 'simulated-success' SIM_FAILURE = 'simulated-failure' NOT_IMPLEMENTED = 'not-implemented' FAILURE \u00a4 NOT_IMPLEMENTED \u00a4 ROLLEDBACK \u00a4 SIM_FAILURE \u00a4 SIM_SUCCESS \u00a4 SUCCESS \u00a4 handler: python","title":"base_task"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task","text":"Trestle tasks base templating.","title":"base_task"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.logger","text":"","title":"logger"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.PassFail","text":"Holding pattern template for a task which does nothing and always passes. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/base_task.py class PassFail ( TaskBase ): \"\"\" Holding pattern template for a task which does nothing and always passes. Attributes: name: Name of the task. \"\"\" name = 'pass-fail' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task pass-fail. Attributes: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( 'This is a template task which reports pass fail depending on the specific configuration.' ) logger . info ( 'In this case if no config section is provided the task will fail. This a a task specific behavior.' ) logger . info ( 'Configuration flags sit under [task.pass-fail]' ) logger . info ( 'with two boolean flags' ) logger . info ( 'execute_status = True/False with a default pass' ) logger . info ( 'simulate_status = True/False with a default fail' ) logger . info ( 'Note that if the config file does not have the appropriate section this should fail.' ) logger . info ( 'The princple goal is a simple development example.' ) def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" if self . _config : outcome = self . _config . getboolean ( 'simulate_status' , fallback = True ) if outcome : return TaskOutcome ( 'simulated-success' ) return TaskOutcome ( 'simulated-failure' ) def execute ( self ) -> TaskOutcome : \"\"\"Provide a actual outcome.\"\"\" if self . _config : outcome = self . _config . getboolean ( 'execute_status' , fallback = True ) if outcome : return TaskOutcome ( 'success' ) return TaskOutcome ( 'failure' )","title":"PassFail"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.PassFail.name","text":"","title":"name"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.PassFail-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.PassFail.__init__","text":"Initialize trestle task pass-fail. Attributes: Name Type Description config_object Config section associated with the task. Source code in trestle/tasks/base_task.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task pass-fail. Attributes: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object )","title":"__init__()"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.PassFail.execute","text":"Provide a actual outcome. Source code in trestle/tasks/base_task.py def execute ( self ) -> TaskOutcome : \"\"\"Provide a actual outcome.\"\"\" if self . _config : outcome = self . _config . getboolean ( 'execute_status' , fallback = True ) if outcome : return TaskOutcome ( 'success' ) return TaskOutcome ( 'failure' )","title":"execute()"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.PassFail.print_info","text":"Print the help string. Source code in trestle/tasks/base_task.py def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( 'This is a template task which reports pass fail depending on the specific configuration.' ) logger . info ( 'In this case if no config section is provided the task will fail. This a a task specific behavior.' ) logger . info ( 'Configuration flags sit under [task.pass-fail]' ) logger . info ( 'with two boolean flags' ) logger . info ( 'execute_status = True/False with a default pass' ) logger . info ( 'simulate_status = True/False with a default fail' ) logger . info ( 'Note that if the config file does not have the appropriate section this should fail.' ) logger . info ( 'The princple goal is a simple development example.' )","title":"print_info()"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.PassFail.simulate","text":"Provide a simulated outcome. Source code in trestle/tasks/base_task.py def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" if self . _config : outcome = self . _config . getboolean ( 'simulate_status' , fallback = True ) if outcome : return TaskOutcome ( 'simulated-success' ) return TaskOutcome ( 'simulated-failure' )","title":"simulate()"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.TaskBase","text":"Abstract base class for tasks. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/base_task.py class TaskBase ( ABC ): \"\"\" Abstract base class for tasks. Attributes: name: Name of the task. \"\"\" name : str = 'base' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\"Initialize task base and store config.\"\"\" self . _config = config_object @abstractmethod def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" @abstractmethod def execute ( self ) -> TaskOutcome : \"\"\"Execute the task including potential rollback.\"\"\" @abstractmethod def simulate ( self ) -> TaskOutcome : \"\"\"Simulate the task and report task outcome.\"\"\"","title":"TaskBase"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.TaskBase.name","text":"","title":"name"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.TaskBase-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.TaskBase.__init__","text":"Initialize task base and store config. Source code in trestle/tasks/base_task.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\"Initialize task base and store config.\"\"\" self . _config = config_object","title":"__init__()"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.TaskBase.execute","text":"Execute the task including potential rollback. Source code in trestle/tasks/base_task.py @abstractmethod def execute ( self ) -> TaskOutcome : \"\"\"Execute the task including potential rollback.\"\"\"","title":"execute()"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.TaskBase.print_info","text":"Print the help string. Source code in trestle/tasks/base_task.py @abstractmethod def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\"","title":"print_info()"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.TaskBase.simulate","text":"Simulate the task and report task outcome. Source code in trestle/tasks/base_task.py @abstractmethod def simulate ( self ) -> TaskOutcome : \"\"\"Simulate the task and report task outcome.\"\"\"","title":"simulate()"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.TaskOutcome","text":"Enum describing possible task outcomes. Source code in trestle/tasks/base_task.py class TaskOutcome ( Enum ): \"\"\"Enum describing possible task outcomes.\"\"\" SUCCESS = 'success' FAILURE = 'failure' ROLLEDBACK = 'rolledback' SIM_SUCCESS = 'simulated-success' SIM_FAILURE = 'simulated-failure' NOT_IMPLEMENTED = 'not-implemented'","title":"TaskOutcome"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.TaskOutcome.FAILURE","text":"","title":"FAILURE"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.TaskOutcome.NOT_IMPLEMENTED","text":"","title":"NOT_IMPLEMENTED"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.TaskOutcome.ROLLEDBACK","text":"","title":"ROLLEDBACK"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.TaskOutcome.SIM_FAILURE","text":"","title":"SIM_FAILURE"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.TaskOutcome.SIM_SUCCESS","text":"","title":"SIM_SUCCESS"},{"location":"api_reference/trestle.tasks.base_task/#trestle.tasks.base_task.TaskOutcome.SUCCESS","text":"handler: python","title":"SUCCESS"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_catalog/","text":"trestle.tasks.ocp4_cis_profile_to_oscal_catalog \u00a4 OSCAL transformation tasks. logger \u00a4 Classes \u00a4 Node ( BaseModel ) pydantic-model \u00a4 Representation of CIS profile entry. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_catalog.py class Node ( BaseModel ): \"\"\"Representation of CIS profile entry.\"\"\" name : Optional [ str ] = Field ( None ) description : Optional [ str ] = Field ( None ) description : str pydantic-field \u00a4 name : str pydantic-field \u00a4 Ocp4CisProfileToOscalCatalog ( TaskBase ) \u00a4 Task to transform OCP4 CIS profile to OSCAL catalog. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_catalog.py class Ocp4CisProfileToOscalCatalog ( TaskBase ): \"\"\" Task to transform OCP4 CIS profile to OSCAL catalog. Attributes: name: Name of the task. \"\"\" name = 'ocp4-cis-profile-to-oscal-catalog' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task ocp4-cis-profile-to-oscal-catalog. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) self . _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat () def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Create catalog from standard (e.g. CIS benchmark).' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.ocp4-cis-profile-to-oscal-catalog]:' ) text1 = ' input-dir = ' text2 = '(required) location to read the compliance-as-code profile files.' logger . info ( text1 + text2 ) text1 = ' output-dir = ' text2 = '(required) location to write the generated catalog.json file.' logger . info ( text1 + text2 ) text1 = ' output-overwrite = ' text2 = '(optional) true [default] or false; replace existing output when true.' logger . info ( text1 + text2 ) def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" try : return self . _execute () except Exception : logger . info ( traceback . format_exc ()) return TaskOutcome ( 'failure' ) def _execute ( self ) -> TaskOutcome : \"\"\"Wrap the execute for exception handling.\"\"\" if not self . _config : logger . warning ( 'config missing' ) return TaskOutcome ( 'failure' ) try : idir = self . _config [ 'input-dir' ] odir = self . _config [ 'output-dir' ] except KeyError as e : logger . info ( f 'key { e . args [ 0 ] } missing' ) return TaskOutcome ( 'failure' ) # verbosity quiet = self . _config . get ( 'quiet' , False ) verbose = not quiet # output overwrite = self . _config . getboolean ( 'output-overwrite' , True ) opth = pathlib . Path ( odir ) # insure output dir exists opth . mkdir ( exist_ok = True , parents = True ) # calculate output file name & check writability oname = 'catalog.json' ofile = opth / oname if not overwrite and pathlib . Path ( ofile ) . exists (): logger . warning ( f 'output: { ofile } already exists' ) return TaskOutcome ( 'failure' ) # metadata links (optional) metadata_links = self . _config . get ( 'metadata-links' ) # get list or <name>.profile files filelist = self . _get_filelist ( idir ) if len ( filelist ) < 1 : logger . warning ( f 'input: { idir } no .profile file found' ) return TaskOutcome ( 'failure' ) # initialize node list self . _node_map = {} # process files for fp in filelist : lines = self . _get_content ( fp ) self . _parse ( lines ) # get root nodes root_nodes = self . _get_root_nodes () # groups and controls root = Group ( title = 'root' , groups = []) for node in root_nodes : group = Group ( title = f ' { node . name } { node . description } ' ) root . groups . append ( group ) depth = self . _depth ( node . name ) if depth == 3 : self . _add_groups ( group , node . name , depth ) if depth == 2 : self . _add_controls ( group , node . name , depth ) # metadata metadata = Metadata ( title = self . _title , last_modified = self . _timestamp , oscal_version = OSCAL_VERSION , version = trestle . __version__ ) # metadata links if metadata_links is not None : metadata . links = [] for item in metadata_links . split (): link = Link ( href = item ) metadata . links . append ( link ) # catalog catalog = Catalog ( uuid = _uuid (), metadata = metadata , groups = root . groups ) # write OSCAL ComponentDefinition to file if verbose : logger . info ( f 'output: { ofile } ' ) catalog . oscal_write ( pathlib . Path ( ofile )) return TaskOutcome ( 'success' ) def _get_filelist ( self , idir : str ) -> List [ pathlib . Path ]: \"\"\"Get filelist.\"\"\" return [ x for x in pathlib . Path ( idir ) . iterdir () if x . is_file () and x . suffix == '.profile' ] def _get_content ( self , fp : pathlib . Path ) -> List [ str ]: \"\"\"Fetch content from file.\"\"\" content = None try : f = fp . open ( 'r' , encoding = const . FILE_ENCODING ) content = f . readlines () f . close () return content except Exception as e : logger . warning ( f 'unable to process { fp . name } ' ) raise e def _parse ( self , lines : List [ str ]) -> None : \"\"\"Parse lines to build data structure.\"\"\" for line in lines : line = line . strip () if line . startswith ( 'title: ' ) and \"'\" in line : self . _title = line . split ( \"'\" )[ 1 ] continue line_parts = line . split ( None , 2 ) # must be 3 parts exactly if len ( line_parts ) < 3 : continue # normalized name and description name = line_parts [ 1 ] . rstrip ( '.' ) description = line_parts [ 2 ] # name must be numbers and decimal points if not set ( name ) <= set ( '0123456789.' ): continue # derive desired sortable key from name key = self . _get_key ( name ) self . _node_map [ key ] = Node ( name = name , description = description ) def _get_key ( self , name : str ) -> ( int , int , int ): \"\"\"Convert name to desired sortable key.\"\"\" parts = name . split ( '.' ) if len ( parts ) == 1 : key = ( int ( parts [ 0 ]), 0 , 0 ) elif len ( parts ) == 2 : key = ( int ( parts [ 0 ]), int ( parts [ 1 ]), 0 ) elif len ( parts ) == 3 : key = ( int ( parts [ 0 ]), int ( parts [ 1 ]), int ( parts [ 2 ])) else : text = f 'Unexpected value: { name } ' raise RuntimeError ( text ) return key def _get_root_nodes ( self ) -> ValuesView [ Node ]: \"\"\"Get root nodes.\"\"\" root_nodes = {} for node in self . _node_map . values (): if len ( node . name ) == 1 : root_nodes [ node . name ] = node return root_nodes . values () def _depth ( self , prefix : str ) -> int : \"\"\"Get maximum depth for prefix.\"\"\" depth = 0 for node in self . _node_map . values (): name = node . name if not name . startswith ( prefix ): continue dots = name . split ( '.' ) if len ( dots ) <= depth : continue depth = len ( dots ) return depth def _add_controls ( self , group : Group , prefix : str , depth : int ): \"\"\"Add controls to group.\"\"\" controls = [] for key in sorted ( self . _node_map . keys ()): node = self . _node_map [ key ] name = node . name if name . startswith ( prefix ): dots = name . split ( '.' ) if len ( dots ) == depth : id_ = f 'CIS- { node . name } ' title = f ' { node . name } { node . description } ' control = Control ( id = id_ , title = title ) controls . append ( control ) if len ( controls ) > 0 : group . controls = controls def _add_groups ( self , group : Group , prefix : str , depth : int ): \"\"\"Add sub-groups to group.\"\"\" groups = [] for key in sorted ( self . _node_map . keys ()): node = self . _node_map [ key ] name = node . name if not name . startswith ( prefix ): continue if name == prefix : continue dots = name . split ( '.' ) if len ( dots ) != depth - 1 : continue title = f ' { node . name } { node . description } ' sub_group = Group ( title = title ) groups . append ( sub_group ) sub_prefix = node . name self . _add_controls ( sub_group , sub_prefix , depth ) if len ( groups ) > 0 : group . groups = groups name : str \u00a4 Methods \u00a4 __init__ ( self , config_object ) special \u00a4 Initialize trestle task ocp4-cis-profile-to-oscal-catalog. Parameters: Name Type Description Default config_object Optional[configparser.SectionProxy] Config section associated with the task. required Source code in trestle/tasks/ocp4_cis_profile_to_oscal_catalog.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task ocp4-cis-profile-to-oscal-catalog. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) self . _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat () execute ( self ) \u00a4 Provide an actual outcome. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_catalog.py def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" try : return self . _execute () except Exception : logger . info ( traceback . format_exc ()) return TaskOutcome ( 'failure' ) print_info ( self ) \u00a4 Print the help string. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_catalog.py def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Create catalog from standard (e.g. CIS benchmark).' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.ocp4-cis-profile-to-oscal-catalog]:' ) text1 = ' input-dir = ' text2 = '(required) location to read the compliance-as-code profile files.' logger . info ( text1 + text2 ) text1 = ' output-dir = ' text2 = '(required) location to write the generated catalog.json file.' logger . info ( text1 + text2 ) text1 = ' output-overwrite = ' text2 = '(optional) true [default] or false; replace existing output when true.' logger . info ( text1 + text2 ) simulate ( self ) \u00a4 Provide a simulated outcome. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_catalog.py def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) handler: python","title":"ocp4_cis_profile_to_oscal_catalog"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_catalog/#trestle.tasks.ocp4_cis_profile_to_oscal_catalog","text":"OSCAL transformation tasks.","title":"ocp4_cis_profile_to_oscal_catalog"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_catalog/#trestle.tasks.ocp4_cis_profile_to_oscal_catalog.logger","text":"","title":"logger"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_catalog/#trestle.tasks.ocp4_cis_profile_to_oscal_catalog-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_catalog/#trestle.tasks.ocp4_cis_profile_to_oscal_catalog.Node","text":"Representation of CIS profile entry. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_catalog.py class Node ( BaseModel ): \"\"\"Representation of CIS profile entry.\"\"\" name : Optional [ str ] = Field ( None ) description : Optional [ str ] = Field ( None )","title":"Node"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_catalog/#trestle.tasks.ocp4_cis_profile_to_oscal_catalog.Node.description","text":"","title":"description"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_catalog/#trestle.tasks.ocp4_cis_profile_to_oscal_catalog.Node.name","text":"","title":"name"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_catalog/#trestle.tasks.ocp4_cis_profile_to_oscal_catalog.Ocp4CisProfileToOscalCatalog","text":"Task to transform OCP4 CIS profile to OSCAL catalog. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_catalog.py class Ocp4CisProfileToOscalCatalog ( TaskBase ): \"\"\" Task to transform OCP4 CIS profile to OSCAL catalog. Attributes: name: Name of the task. \"\"\" name = 'ocp4-cis-profile-to-oscal-catalog' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task ocp4-cis-profile-to-oscal-catalog. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) self . _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat () def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Create catalog from standard (e.g. CIS benchmark).' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.ocp4-cis-profile-to-oscal-catalog]:' ) text1 = ' input-dir = ' text2 = '(required) location to read the compliance-as-code profile files.' logger . info ( text1 + text2 ) text1 = ' output-dir = ' text2 = '(required) location to write the generated catalog.json file.' logger . info ( text1 + text2 ) text1 = ' output-overwrite = ' text2 = '(optional) true [default] or false; replace existing output when true.' logger . info ( text1 + text2 ) def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" try : return self . _execute () except Exception : logger . info ( traceback . format_exc ()) return TaskOutcome ( 'failure' ) def _execute ( self ) -> TaskOutcome : \"\"\"Wrap the execute for exception handling.\"\"\" if not self . _config : logger . warning ( 'config missing' ) return TaskOutcome ( 'failure' ) try : idir = self . _config [ 'input-dir' ] odir = self . _config [ 'output-dir' ] except KeyError as e : logger . info ( f 'key { e . args [ 0 ] } missing' ) return TaskOutcome ( 'failure' ) # verbosity quiet = self . _config . get ( 'quiet' , False ) verbose = not quiet # output overwrite = self . _config . getboolean ( 'output-overwrite' , True ) opth = pathlib . Path ( odir ) # insure output dir exists opth . mkdir ( exist_ok = True , parents = True ) # calculate output file name & check writability oname = 'catalog.json' ofile = opth / oname if not overwrite and pathlib . Path ( ofile ) . exists (): logger . warning ( f 'output: { ofile } already exists' ) return TaskOutcome ( 'failure' ) # metadata links (optional) metadata_links = self . _config . get ( 'metadata-links' ) # get list or <name>.profile files filelist = self . _get_filelist ( idir ) if len ( filelist ) < 1 : logger . warning ( f 'input: { idir } no .profile file found' ) return TaskOutcome ( 'failure' ) # initialize node list self . _node_map = {} # process files for fp in filelist : lines = self . _get_content ( fp ) self . _parse ( lines ) # get root nodes root_nodes = self . _get_root_nodes () # groups and controls root = Group ( title = 'root' , groups = []) for node in root_nodes : group = Group ( title = f ' { node . name } { node . description } ' ) root . groups . append ( group ) depth = self . _depth ( node . name ) if depth == 3 : self . _add_groups ( group , node . name , depth ) if depth == 2 : self . _add_controls ( group , node . name , depth ) # metadata metadata = Metadata ( title = self . _title , last_modified = self . _timestamp , oscal_version = OSCAL_VERSION , version = trestle . __version__ ) # metadata links if metadata_links is not None : metadata . links = [] for item in metadata_links . split (): link = Link ( href = item ) metadata . links . append ( link ) # catalog catalog = Catalog ( uuid = _uuid (), metadata = metadata , groups = root . groups ) # write OSCAL ComponentDefinition to file if verbose : logger . info ( f 'output: { ofile } ' ) catalog . oscal_write ( pathlib . Path ( ofile )) return TaskOutcome ( 'success' ) def _get_filelist ( self , idir : str ) -> List [ pathlib . Path ]: \"\"\"Get filelist.\"\"\" return [ x for x in pathlib . Path ( idir ) . iterdir () if x . is_file () and x . suffix == '.profile' ] def _get_content ( self , fp : pathlib . Path ) -> List [ str ]: \"\"\"Fetch content from file.\"\"\" content = None try : f = fp . open ( 'r' , encoding = const . FILE_ENCODING ) content = f . readlines () f . close () return content except Exception as e : logger . warning ( f 'unable to process { fp . name } ' ) raise e def _parse ( self , lines : List [ str ]) -> None : \"\"\"Parse lines to build data structure.\"\"\" for line in lines : line = line . strip () if line . startswith ( 'title: ' ) and \"'\" in line : self . _title = line . split ( \"'\" )[ 1 ] continue line_parts = line . split ( None , 2 ) # must be 3 parts exactly if len ( line_parts ) < 3 : continue # normalized name and description name = line_parts [ 1 ] . rstrip ( '.' ) description = line_parts [ 2 ] # name must be numbers and decimal points if not set ( name ) <= set ( '0123456789.' ): continue # derive desired sortable key from name key = self . _get_key ( name ) self . _node_map [ key ] = Node ( name = name , description = description ) def _get_key ( self , name : str ) -> ( int , int , int ): \"\"\"Convert name to desired sortable key.\"\"\" parts = name . split ( '.' ) if len ( parts ) == 1 : key = ( int ( parts [ 0 ]), 0 , 0 ) elif len ( parts ) == 2 : key = ( int ( parts [ 0 ]), int ( parts [ 1 ]), 0 ) elif len ( parts ) == 3 : key = ( int ( parts [ 0 ]), int ( parts [ 1 ]), int ( parts [ 2 ])) else : text = f 'Unexpected value: { name } ' raise RuntimeError ( text ) return key def _get_root_nodes ( self ) -> ValuesView [ Node ]: \"\"\"Get root nodes.\"\"\" root_nodes = {} for node in self . _node_map . values (): if len ( node . name ) == 1 : root_nodes [ node . name ] = node return root_nodes . values () def _depth ( self , prefix : str ) -> int : \"\"\"Get maximum depth for prefix.\"\"\" depth = 0 for node in self . _node_map . values (): name = node . name if not name . startswith ( prefix ): continue dots = name . split ( '.' ) if len ( dots ) <= depth : continue depth = len ( dots ) return depth def _add_controls ( self , group : Group , prefix : str , depth : int ): \"\"\"Add controls to group.\"\"\" controls = [] for key in sorted ( self . _node_map . keys ()): node = self . _node_map [ key ] name = node . name if name . startswith ( prefix ): dots = name . split ( '.' ) if len ( dots ) == depth : id_ = f 'CIS- { node . name } ' title = f ' { node . name } { node . description } ' control = Control ( id = id_ , title = title ) controls . append ( control ) if len ( controls ) > 0 : group . controls = controls def _add_groups ( self , group : Group , prefix : str , depth : int ): \"\"\"Add sub-groups to group.\"\"\" groups = [] for key in sorted ( self . _node_map . keys ()): node = self . _node_map [ key ] name = node . name if not name . startswith ( prefix ): continue if name == prefix : continue dots = name . split ( '.' ) if len ( dots ) != depth - 1 : continue title = f ' { node . name } { node . description } ' sub_group = Group ( title = title ) groups . append ( sub_group ) sub_prefix = node . name self . _add_controls ( sub_group , sub_prefix , depth ) if len ( groups ) > 0 : group . groups = groups","title":"Ocp4CisProfileToOscalCatalog"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_catalog/#trestle.tasks.ocp4_cis_profile_to_oscal_catalog.Ocp4CisProfileToOscalCatalog.name","text":"","title":"name"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_catalog/#trestle.tasks.ocp4_cis_profile_to_oscal_catalog.Ocp4CisProfileToOscalCatalog-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_catalog/#trestle.tasks.ocp4_cis_profile_to_oscal_catalog.Ocp4CisProfileToOscalCatalog.__init__","text":"Initialize trestle task ocp4-cis-profile-to-oscal-catalog. Parameters: Name Type Description Default config_object Optional[configparser.SectionProxy] Config section associated with the task. required Source code in trestle/tasks/ocp4_cis_profile_to_oscal_catalog.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task ocp4-cis-profile-to-oscal-catalog. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) self . _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat ()","title":"__init__()"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_catalog/#trestle.tasks.ocp4_cis_profile_to_oscal_catalog.Ocp4CisProfileToOscalCatalog.execute","text":"Provide an actual outcome. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_catalog.py def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" try : return self . _execute () except Exception : logger . info ( traceback . format_exc ()) return TaskOutcome ( 'failure' )","title":"execute()"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_catalog/#trestle.tasks.ocp4_cis_profile_to_oscal_catalog.Ocp4CisProfileToOscalCatalog.print_info","text":"Print the help string. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_catalog.py def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Create catalog from standard (e.g. CIS benchmark).' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.ocp4-cis-profile-to-oscal-catalog]:' ) text1 = ' input-dir = ' text2 = '(required) location to read the compliance-as-code profile files.' logger . info ( text1 + text2 ) text1 = ' output-dir = ' text2 = '(required) location to write the generated catalog.json file.' logger . info ( text1 + text2 ) text1 = ' output-overwrite = ' text2 = '(optional) true [default] or false; replace existing output when true.' logger . info ( text1 + text2 )","title":"print_info()"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_catalog/#trestle.tasks.ocp4_cis_profile_to_oscal_catalog.Ocp4CisProfileToOscalCatalog.simulate","text":"Provide a simulated outcome. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_catalog.py def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) handler: python","title":"simulate()"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_cd/","text":"trestle.tasks.ocp4_cis_profile_to_oscal_cd \u00a4 OSCAL transformation tasks. logger \u00a4 Classes \u00a4 Ocp4CisProfileToOscalCD ( TaskBase ) \u00a4 Task to transform OCP4 CIS profile to OSCAL component-definition. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_cd.py class Ocp4CisProfileToOscalCD ( TaskBase ): \"\"\" Task to transform OCP4 CIS profile to OSCAL component-definition. Attributes: name: Name of the task. \"\"\" name = 'ocp4-cis-profile-to-oscal-cd' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task ocp4-cis-profile-to-oscal-cd. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) self . _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat () def set_timestamp ( self , timestamp : str ) -> None : \"\"\"Set the timestamp.\"\"\" self . _timestamp = timestamp def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Create component definition from standard (e.g. CIS benchmark).' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.ocp4-cis-profile-to-oscal-cd]:' ) text1 = ' component-name = ' text2 = 'component name, e.g. OSCO.' logger . info ( text1 + text2 ) text1 = ' org-name = ' text2 = 'organization name, e.g. International Business Machines.' logger . info ( text1 + text2 ) text1 = ' org-remarks = ' text2 = 'organization remarks, e.g. IBM.' logger . info ( text1 + text2 ) text1 = ' folder-cac = ' text2 = 'folder containing compliance-as-code artifacts, e.g adjunct-data/cis-benchmarks/content.' logger . info ( text1 + text2 ) text1 = ' output-dir = ' text2 = 'location to write the generated component-definition.json file.' logger . info ( text1 + text2 ) # text1 = ' profile-name = ' text2 = 'profile name, e.g. OCP4 CIS-benchmark v4.' logger . info ( text1 + text2 ) text1 = ' profile-mnemonic = ' text2 = 'profile mnemonic, e.g. ocp4-cis-node.' logger . info ( text1 + text2 ) text1 = ' profile-ns = ' text2 = 'profile ns, e.g. https://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud.' logger . info ( text1 + text2 ) text1 = ' profile-version = ' text2 = 'profile version, e.g. 1.1.' logger . info ( text1 + text2 ) text1 = ' profile-check-version = ' text2 = 'profile check version, e.g. 0.1.58.' logger . info ( text1 + text2 ) # text1 = ' profile-type = ' text2 = 'profile type, e.g. OCP4.' logger . info ( text1 + text2 ) text1 = ' profile-list = ' text2 = 'profile list is blank separated list of \"<suffix>\" for config entries: ' logger . info ( text1 + text2 ) text1 = ' profile-file.<suffix>, profile-title.<suffix>, profile-url.<suffix>' text2 = ', e.g. cis cis-node.' logger . info ( text1 + text2 ) text1 = ' profile-file.<suffix> = ' text2 = 'path of the profile file to ingest' text3 = ', e.g. ${folder-cac}/products/ocp4/profiles/cis-node.profile.' # noqa logger . info ( text1 + text2 + text3 ) text1 = ' profile-title.<suffix> = ' text2 = 'title of the profile' text3 = ', e.g. CIS Red Hat OpenShift Container Platform 4 Benchmark.' logger . info ( text1 + text2 + text3 ) text1 = ' profile-url.<suffix> = ' text2 = 'URL of the profile' text3 = ', e.g. https://github.com/ComplianceAsCode/content/blob/master/products/ocp4/profiles/cis.profile.' logger . info ( text1 + text2 + text3 ) text1 = ' rule-to-parameters-map = ' text2 = 'map file for set-parameters, e.g. ' text3 = 'adjunct-data/task-files/rule2var.json.' logger . info ( text1 + text2 + text3 ) text1 = ' selected-rules = ' text2 = 'file with list of selected rules, e.g. ' text3 = 'adjunct-data/task-files/selected_rules.json.' logger . info ( text1 + text2 + text3 ) text1 = ' enabled-rules = ' text2 = 'file with list of enabled rules, e.g. ' text3 = 'adjunct-data/task-files/enabled_rules.json.' logger . info ( text1 + text2 + text3 ) # text = '' logger . info ( text ) text = 'Notes:' logger . info ( text ) text = '1. If a control has selected rules but no enabled rules, then all those selected are included.' logger . info ( text ) text = '2. If a control has selected and enabled rules, then only those enabled are included.' logger . info ( text ) text = '3. If a control has no selected rules, then none are included regardless of enabled.' logger . info ( text ) def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" try : return self . _execute () except Exception : logger . info ( traceback . format_exc ()) return TaskOutcome ( 'failure' ) def _execute ( self ) -> TaskOutcome : if not self . _config : logger . warning ( 'config missing' ) return TaskOutcome ( 'failure' ) try : component_name = self . _config [ 'component-name' ] org_name = self . _config [ 'org-name' ] org_remarks = self . _config [ 'org-remarks' ] self . _folder_cac = self . _config [ 'folder-cac' ] profile_check_version = self . _config [ 'profile-check-version' ] profile_type = self . _config [ 'profile-type' ] profile_mnemonic = self . _config [ 'profile-mnemonic' ] profile_name = self . _config [ 'profile-name' ] profile_ns = self . _config [ 'profile-ns' ] profile_version = self . _config [ 'profile-version' ] profile_sets = {} profile_list = self . _config [ 'profile-list' ] . split () for profile in profile_list : profile_sets [ profile ] = {} profile_sets [ profile ][ 'profile-file' ] = self . _config [ f 'profile-file. { profile } ' ] profile_sets [ profile ][ 'profile-url' ] = self . _config [ f 'profile-url. { profile } ' ] profile_sets [ profile ][ 'profile-title' ] = self . _config [ f 'profile-title. { profile } ' ] profile_sets [ profile ][ 'profile-ns' ] = profile_ns profile_sets [ profile ][ 'component-name' ] = component_name odir = self . _config [ 'output-dir' ] except KeyError as e : logger . info ( f 'key { e . args [ 0 ] } missing' ) return TaskOutcome ( 'failure' ) # selected rules self . _selected_rules = self . _get_filter_rules ( 'selected-rules' , 'selected' ) # enabled rules self . _enabled_rules = self . _get_filter_rules ( 'enabled-rules' , 'enabled' ) # verbosity quiet = self . _config . get ( 'quiet' , False ) verbose = not quiet # output overwrite = self . _config . getboolean ( 'output-overwrite' , True ) opth = pathlib . Path ( odir ) # insure output dir exists opth . mkdir ( exist_ok = True , parents = True ) # calculate output file name & check writability oname = 'component-definition.json' ofile = opth / oname if not overwrite and pathlib . Path ( ofile ) . exists (): logger . warning ( f 'output: { ofile } already exists' ) return TaskOutcome ( 'failure' ) # fetch rule to parameters map self . _rule_to_parm_map = self . _get_parameters_map ( 'rule-to-parameters-map' ) # roles, responsible_roles, parties, responsible parties party_uuid_01 = str ( uuid . uuid4 ()) party_uuid_02 = str ( uuid . uuid4 ()) party_uuid_03 = str ( uuid . uuid4 ()) roles = self . _build_roles () responsible_roles = self . _build_responsible_roles ( party_uuid_01 , party_uuid_02 , party_uuid_03 ) parties = self . _build_parties ( org_name , org_remarks , party_uuid_01 , party_uuid_02 , party_uuid_03 ) responsible_parties = self . _build_responsible_parties ( party_uuid_01 , party_uuid_02 , party_uuid_03 ) # metadata metadata = Metadata ( title = f 'Component definition for { profile_type } profiles' , last_modified = self . _timestamp , oscal_version = OSCAL_VERSION , version = trestle . __version__ , roles = roles , parties = parties , responsible_parties = responsible_parties ) # defined component component_title = component_name component_description = component_name defined_component = DefinedComponent ( uuid = str ( uuid . uuid4 ()), description = component_description , title = component_title , type = 'Service' , ) # add control implementation per profile prop1 = Property ( name = 'profile_name' , value = profile_name , class_ = 'scc_profile_name' , ns = profile_ns , ) prop2 = Property ( name = 'profile_mnemonic' , value = profile_mnemonic , class_ = 'scc_profile_mnemonic' , ns = profile_ns , ) prop3 = Property ( name = 'profile_version' , value = profile_version , class_ = 'scc_profile_version' , ns = profile_ns , ) prop4 = Property ( name = 'profile_check_version' , value = profile_check_version , ) props = [ prop1 , prop2 , prop3 , prop4 ] for profile in profile_list : profile_set = profile_sets [ profile ] control_implementation = self . _build_control_implementation ( profile_set , responsible_roles , props ) if control_implementation is not None : if defined_component . control_implementations is None : defined_component . control_implementations = [ control_implementation ] else : defined_component . control_implementations . append ( control_implementation ) # defined components defined_components = [ defined_component ] # component definition component_definition = ComponentDefinition ( uuid = str ( uuid . uuid4 ()), metadata = metadata , components = defined_components , ) # write OSCAL ComponentDefinition to file if verbose : logger . info ( f 'output: { ofile } ' ) component_definition . oscal_write ( pathlib . Path ( ofile )) return TaskOutcome ( 'success' ) def _get_set_parameter ( self , rule : str ) -> SetParameter : \"\"\"Get set parameter.\"\"\" set_parameter = None for key in self . _rule_to_parm_map . keys (): logger . debug ( f ' { key } { rule } ' ) if key == rule : value = self . _rule_to_parm_map [ key ] remarks = value [ 'description' ] options = value [ 'options' ] default_value = options [ 'default' ] logger . debug ( f 'key: { key } options: { options } ' ) set_parameter = SetParameter ( param_id = rule , values = [ f ' { default_value } ' ], remarks = remarks , ) return set_parameter def _get_controls ( self , rules : Dict [ str , Tuple [ str , str , str ]]) -> Dict [ str , List [ str ]]: \"\"\"Get controls.\"\"\" controls = {} for rule in rules . keys (): control = rules [ rule ][ 1 ] if control not in controls . keys (): controls [ control ] = [ rule ] else : controls [ control ] = controls [ control ] + [ rule ] # trim rules associated with control with respect to enabled rules for control in controls : controls [ control ] = self . _get_trimmed_rules ( control , controls [ control ]) logger . debug ( f ' { control } { controls [ control ] } ' ) return controls # determine if trim is needed for the control, and if so then # for the associated set of rules drop those that are not enabled def _get_trimmed_rules ( self , control : str , rules_for_control : List [ str ]) -> List [ str ]: \"\"\"Trim rules if any rule for control appears in enabled rules list.\"\"\" retval = rules_for_control if self . _is_trim_needed ( rules_for_control ): retval = [] for rule in rules_for_control : if rule in self . _enabled_rules : retval = retval + [ rule ] logger . debug ( f 'keep { control } { rule } ' ) else : logger . debug ( f 'drop { control } { rule } ' ) return retval # if any rule in the set of rules for the control appears in the enabled list, # then trim is needed def _is_trim_needed ( self , rules_for_control : List [ str ]) -> bool : \"\"\"Check if trim is needed.\"\"\" retval = False for rule in rules_for_control : if rule in self . _enabled_rules : retval = True break return retval # fetch the set of rules that will be included/excluded from the CIS rules def _get_parameters_map ( self , config_key : str ) -> List [ str ]: \"\"\"Get parameters map.\"\"\" try : fp = pathlib . Path ( self . _config [ config_key ]) f = fp . open ( 'r' , encoding = const . FILE_ENCODING ) jdata = json . load ( f ) parameters_map = jdata f . close () except KeyError as e : logger . debug ( f 'key { e . args [ 0 ] } missing' ) parameters_map = {} except Exception : logger . warning ( f 'unable to process { self . _config [ config_key ] } ' ) parameters_map = {} return parameters_map # fetch the set of rules that will be included/excluded from the CIS rules def _get_filter_rules ( self , config_key : str , file_key : str ) -> List [ str ]: \"\"\"Get filter rules.\"\"\" try : fp = pathlib . Path ( self . _config [ config_key ]) f = fp . open ( 'r' , encoding = const . FILE_ENCODING ) jdata = json . load ( f ) try : filter_rules = jdata [ file_key ] except Exception : filter_rules = jdata f . close () except KeyError as e : logger . debug ( f 'key { e . args [ 0 ] } missing' ) filter_rules = [] except Exception : logger . warning ( f 'unable to process { self . _config [ config_key ] } ' ) filter_rules = [] return filter_rules # create map from file: # key is rule # value is tuple comprising [ category, control, description ] def _get_cis_rules ( self , filename : str ) -> Dict [ str , Tuple [ str , str , str ]]: \"\"\"Get CIS rules.\"\"\" try : fp = pathlib . Path ( filename ) f = fp . open ( 'r' , encoding = const . FILE_ENCODING ) content = f . readlines () rules = self . _parse_cis_rules ( content ) f . close () except Exception : logger . warning ( f 'unable to process { filename } ' ) rules = {} return rules def _parse_cis_rules ( self , content : List [ str ]) -> Dict [ str , Tuple [ str , str , str ]]: \"\"\"Parse CIS rules.\"\"\" rules = {} lineno = 0 for line in content : lineno += 1 line = line . replace ( ' \\n ' , '' ) if line . startswith ( ' #### ' ): category = line . split ( ' #### ' )[ 1 ] logger . debug ( f ' { lineno } category: { category } ' ) elif line . startswith ( ' # ' ): text = line . split ( ' # ' )[ 1 ] . split ( ' ' , 1 ) if '.' in text [ 0 ]: control = text [ 0 ] desc = text [ 1 ] logger . debug ( f ' { lineno } control: { control } description: { desc } ' ) else : logger . debug ( f ' { lineno } skip: { line } ' ) elif line . startswith ( ' - ' ): rule = line . split ( ' - ' )[ 1 ] logger . debug ( f ' { lineno } rule: { rule } ' ) if not self . _is_selected ( rule ): logger . debug ( f 'not selected rule: { rule } ' ) elif rule in rules . keys (): logger . info ( f 'duplicate rule: { rule } ' ) else : rules [ rule ] = [ category , control , desc ] else : logger . debug ( f ' { lineno } skip: { line } ' ) return rules # rule is selected if: # a) the selected rules file is not specified or is empty or # b) the rule appears in the list of selected rules from the file def _is_selected ( self , rule : str ) -> bool : \"\"\"Check if rule is selected.\"\"\" retval = True if len ( self . _selected_rules ) > 0 and rule not in self . _selected_rules : retval = False logger . debug ( f ' { retval } { rule } ' ) return retval # rule is excluded if it does not appear in the list of trimmed rules # for the control def _is_excluded ( self , rule : str , control : str , controls : Dict [ str , List [ str ]]) -> bool : \"\"\"Check if rule is excluded.\"\"\" retval = False if rule not in controls [ control ]: logger . debug ( f 'exclude { rule } { control } ' ) retval = True return retval def _build_roles ( self ) -> List [ Role ]: \"\"\"Build roles.\"\"\" value = [ Role ( id = 'prepared-by' , title = 'Indicates the organization that created this content.' ), Role ( id = 'prepared-for' , title = 'Indicates the organization for which this content was created..' ), Role ( id = 'content-approver' , title = 'Indicates the organization responsible for all content represented in the \"document\".' ), ] return value def _build_control_implementation ( self , profile_set : Dict [ str , str ], responsible_roles : List [ ResponsibleRole ], props : List [ Property ] ) -> ControlImplementation : \"\"\"Build control implementation.\"\"\" implemented_requirements = self . _build_implemented_requirements ( profile_set , responsible_roles ) if len ( implemented_requirements ) == 0 : control_implementation = None else : control_implementation = ControlImplementation ( uuid = str ( uuid . uuid4 ()), source = profile_set [ 'profile-url' ], description = f ' { profile_set [ \"component-name\" ] } implemented controls for { profile_set [ \"profile-title\" ] } .' , implemented_requirements = implemented_requirements , props = props , ) return control_implementation def _get_title ( self , dir_name : str , root : str ) -> str : \"\"\"Extract rule title from compliance-as-code rule.yml.\"\"\" \"\"\" Operation: Given is a dir_name and a root directory. We walk the directory tree looking for a directory named dir_name. Once found, we read the content of the rule.yml file in that directory. It is likely that we read each rule.yml file exactly once, since each rule appears exactly once in the one or more profiles, e.g. cis-node.profile, which drive the search. From the content, we find the title and return its corresponding value. \"\"\" title = None for path , dirs , _files in os . walk ( root ): if dir_name in dirs : folder = os . path . join ( path , dir_name ) tpath = pathlib . Path ( folder ) / 'rule.yml' fp = pathlib . Path ( tpath ) f = fp . open ( 'r' , encoding = const . FILE_ENCODING ) content = f . readlines () f . close () for line in content : if line . startswith ( 'title:' ): title = line . split ( 'title:' )[ 1 ] break if title is None : msg = f 'unable to find \" { dir_name } \"' logger . warning ( msg ) title = 'no title' title = title . strip () . strip ( \"'\" ) . strip ( '\"' ) logger . debug ( f ' { title } ' ) return title def _build_implemented_requirements ( self , profile_set : Dict [ str , str ], responsible_roles : List [ ResponsibleRole ]) -> List [ ImplementedRequirement ]: \"\"\"Build implemented requirements.\"\"\" implemented_requirements = [] profile_file = profile_set [ 'profile-file' ] rules = self . _get_cis_rules ( profile_file ) controls = self . _get_controls ( rules ) rule_prefix = 'xccdf_org.ssgproject.content_rule_' cac_openshift = f ' { self . _folder_cac } /applications/openshift' for rule in rules : if self . _is_excluded ( rule , rules [ rule ][ 1 ], controls ): continue remarks = self . _get_title ( rule , cac_openshift ) prop = Property ( class_ = 'scc_goal_name_id' , ns = profile_set [ 'profile-ns' ], name = 'XCCDF_rule' , value = f ' { rule_prefix }{ rule } ' , remarks = f ' { remarks } ' ) props = [ prop ] implemented_requirement = ImplementedRequirement ( uuid = f ' { str ( uuid . uuid4 ()) } ' , control_id = f 'CIS- { rules [ rule ][ 1 ] } ' , description = f ' { rules [ rule ][ 2 ] } ' , props = props , responsible_roles = responsible_roles , ) set_parameter = self . _get_set_parameter ( rule ) if set_parameter is not None : implemented_requirement . set_parameters = [ set_parameter ] implemented_requirements . append ( implemented_requirement ) return implemented_requirements def _build_responsible_roles ( self , party_uuid_01 : str , party_uuid_02 : str , party_uuid_03 : str ) -> List [ ResponsibleRole ]: \"\"\"Build responsible roles.\"\"\" role_prepared_by = ResponsibleRole ( role_id = 'prepared-by' , party_uuids = [ party_uuid_01 ]) role_prepared_for = ResponsibleRole ( role_id = 'prepared-for' , party_uuids = [ party_uuid_02 , party_uuid_03 ]) role_content_approver = ResponsibleRole ( role_id = 'content-approver' , party_uuids = [ party_uuid_01 ]) value = [ role_prepared_by , role_prepared_for , role_content_approver , ] return value def _build_parties ( self , org_name : str , org_remarks : str , party_uuid_01 : str , party_uuid_02 : str , party_uuid_03 : str ) -> List [ Party ]: \"\"\"Build parties.\"\"\" value = [ Party ( uuid = party_uuid_01 , type = 'organization' , name = org_name , remarks = org_remarks ), Party ( uuid = party_uuid_02 , type = 'organization' , name = 'Customer' , remarks = 'organization to be customized at account creation only for their Component Definition' ), Party ( uuid = party_uuid_03 , type = 'organization' , name = 'ISV' , remarks = 'organization to be customized at ISV subscription only for their Component Definition' ), ] return value def _build_responsible_parties ( self , party_uuid_01 : str , party_uuid_02 : str , party_uuid_03 : str ) -> List [ ResponsibleParty ]: \"\"\"Build responsible parties.\"\"\" prepared_by = ResponsibleParty ( role_id = 'prepared-by' , party_uuids = [ party_uuid_01 ]) prepared_for = ResponsibleParty ( role_id = 'prepared-for' , party_uuids = [ party_uuid_02 , party_uuid_03 ]) content_approver = ResponsibleParty ( role_id = 'content-approver' , party_uuids = [ party_uuid_01 ]) value = [ prepared_by , prepared_for , content_approver , ] return value name : str \u00a4 Methods \u00a4 __init__ ( self , config_object ) special \u00a4 Initialize trestle task ocp4-cis-profile-to-oscal-cd. Parameters: Name Type Description Default config_object Optional[configparser.SectionProxy] Config section associated with the task. required Source code in trestle/tasks/ocp4_cis_profile_to_oscal_cd.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task ocp4-cis-profile-to-oscal-cd. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) self . _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat () execute ( self ) \u00a4 Provide an actual outcome. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_cd.py def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" try : return self . _execute () except Exception : logger . info ( traceback . format_exc ()) return TaskOutcome ( 'failure' ) print_info ( self ) \u00a4 Print the help string. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_cd.py def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Create component definition from standard (e.g. CIS benchmark).' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.ocp4-cis-profile-to-oscal-cd]:' ) text1 = ' component-name = ' text2 = 'component name, e.g. OSCO.' logger . info ( text1 + text2 ) text1 = ' org-name = ' text2 = 'organization name, e.g. International Business Machines.' logger . info ( text1 + text2 ) text1 = ' org-remarks = ' text2 = 'organization remarks, e.g. IBM.' logger . info ( text1 + text2 ) text1 = ' folder-cac = ' text2 = 'folder containing compliance-as-code artifacts, e.g adjunct-data/cis-benchmarks/content.' logger . info ( text1 + text2 ) text1 = ' output-dir = ' text2 = 'location to write the generated component-definition.json file.' logger . info ( text1 + text2 ) # text1 = ' profile-name = ' text2 = 'profile name, e.g. OCP4 CIS-benchmark v4.' logger . info ( text1 + text2 ) text1 = ' profile-mnemonic = ' text2 = 'profile mnemonic, e.g. ocp4-cis-node.' logger . info ( text1 + text2 ) text1 = ' profile-ns = ' text2 = 'profile ns, e.g. https://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud.' logger . info ( text1 + text2 ) text1 = ' profile-version = ' text2 = 'profile version, e.g. 1.1.' logger . info ( text1 + text2 ) text1 = ' profile-check-version = ' text2 = 'profile check version, e.g. 0.1.58.' logger . info ( text1 + text2 ) # text1 = ' profile-type = ' text2 = 'profile type, e.g. OCP4.' logger . info ( text1 + text2 ) text1 = ' profile-list = ' text2 = 'profile list is blank separated list of \"<suffix>\" for config entries: ' logger . info ( text1 + text2 ) text1 = ' profile-file.<suffix>, profile-title.<suffix>, profile-url.<suffix>' text2 = ', e.g. cis cis-node.' logger . info ( text1 + text2 ) text1 = ' profile-file.<suffix> = ' text2 = 'path of the profile file to ingest' text3 = ', e.g. ${folder-cac}/products/ocp4/profiles/cis-node.profile.' # noqa logger . info ( text1 + text2 + text3 ) text1 = ' profile-title.<suffix> = ' text2 = 'title of the profile' text3 = ', e.g. CIS Red Hat OpenShift Container Platform 4 Benchmark.' logger . info ( text1 + text2 + text3 ) text1 = ' profile-url.<suffix> = ' text2 = 'URL of the profile' text3 = ', e.g. https://github.com/ComplianceAsCode/content/blob/master/products/ocp4/profiles/cis.profile.' logger . info ( text1 + text2 + text3 ) text1 = ' rule-to-parameters-map = ' text2 = 'map file for set-parameters, e.g. ' text3 = 'adjunct-data/task-files/rule2var.json.' logger . info ( text1 + text2 + text3 ) text1 = ' selected-rules = ' text2 = 'file with list of selected rules, e.g. ' text3 = 'adjunct-data/task-files/selected_rules.json.' logger . info ( text1 + text2 + text3 ) text1 = ' enabled-rules = ' text2 = 'file with list of enabled rules, e.g. ' text3 = 'adjunct-data/task-files/enabled_rules.json.' logger . info ( text1 + text2 + text3 ) # text = '' logger . info ( text ) text = 'Notes:' logger . info ( text ) text = '1. If a control has selected rules but no enabled rules, then all those selected are included.' logger . info ( text ) text = '2. If a control has selected and enabled rules, then only those enabled are included.' logger . info ( text ) text = '3. If a control has no selected rules, then none are included regardless of enabled.' logger . info ( text ) set_timestamp ( self , timestamp ) \u00a4 Set the timestamp. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_cd.py def set_timestamp ( self , timestamp : str ) -> None : \"\"\"Set the timestamp.\"\"\" self . _timestamp = timestamp simulate ( self ) \u00a4 Provide a simulated outcome. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_cd.py def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) handler: python","title":"ocp4_cis_profile_to_oscal_cd"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_cd/#trestle.tasks.ocp4_cis_profile_to_oscal_cd","text":"OSCAL transformation tasks.","title":"ocp4_cis_profile_to_oscal_cd"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_cd/#trestle.tasks.ocp4_cis_profile_to_oscal_cd.logger","text":"","title":"logger"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_cd/#trestle.tasks.ocp4_cis_profile_to_oscal_cd-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_cd/#trestle.tasks.ocp4_cis_profile_to_oscal_cd.Ocp4CisProfileToOscalCD","text":"Task to transform OCP4 CIS profile to OSCAL component-definition. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_cd.py class Ocp4CisProfileToOscalCD ( TaskBase ): \"\"\" Task to transform OCP4 CIS profile to OSCAL component-definition. Attributes: name: Name of the task. \"\"\" name = 'ocp4-cis-profile-to-oscal-cd' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task ocp4-cis-profile-to-oscal-cd. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) self . _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat () def set_timestamp ( self , timestamp : str ) -> None : \"\"\"Set the timestamp.\"\"\" self . _timestamp = timestamp def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Create component definition from standard (e.g. CIS benchmark).' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.ocp4-cis-profile-to-oscal-cd]:' ) text1 = ' component-name = ' text2 = 'component name, e.g. OSCO.' logger . info ( text1 + text2 ) text1 = ' org-name = ' text2 = 'organization name, e.g. International Business Machines.' logger . info ( text1 + text2 ) text1 = ' org-remarks = ' text2 = 'organization remarks, e.g. IBM.' logger . info ( text1 + text2 ) text1 = ' folder-cac = ' text2 = 'folder containing compliance-as-code artifacts, e.g adjunct-data/cis-benchmarks/content.' logger . info ( text1 + text2 ) text1 = ' output-dir = ' text2 = 'location to write the generated component-definition.json file.' logger . info ( text1 + text2 ) # text1 = ' profile-name = ' text2 = 'profile name, e.g. OCP4 CIS-benchmark v4.' logger . info ( text1 + text2 ) text1 = ' profile-mnemonic = ' text2 = 'profile mnemonic, e.g. ocp4-cis-node.' logger . info ( text1 + text2 ) text1 = ' profile-ns = ' text2 = 'profile ns, e.g. https://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud.' logger . info ( text1 + text2 ) text1 = ' profile-version = ' text2 = 'profile version, e.g. 1.1.' logger . info ( text1 + text2 ) text1 = ' profile-check-version = ' text2 = 'profile check version, e.g. 0.1.58.' logger . info ( text1 + text2 ) # text1 = ' profile-type = ' text2 = 'profile type, e.g. OCP4.' logger . info ( text1 + text2 ) text1 = ' profile-list = ' text2 = 'profile list is blank separated list of \"<suffix>\" for config entries: ' logger . info ( text1 + text2 ) text1 = ' profile-file.<suffix>, profile-title.<suffix>, profile-url.<suffix>' text2 = ', e.g. cis cis-node.' logger . info ( text1 + text2 ) text1 = ' profile-file.<suffix> = ' text2 = 'path of the profile file to ingest' text3 = ', e.g. ${folder-cac}/products/ocp4/profiles/cis-node.profile.' # noqa logger . info ( text1 + text2 + text3 ) text1 = ' profile-title.<suffix> = ' text2 = 'title of the profile' text3 = ', e.g. CIS Red Hat OpenShift Container Platform 4 Benchmark.' logger . info ( text1 + text2 + text3 ) text1 = ' profile-url.<suffix> = ' text2 = 'URL of the profile' text3 = ', e.g. https://github.com/ComplianceAsCode/content/blob/master/products/ocp4/profiles/cis.profile.' logger . info ( text1 + text2 + text3 ) text1 = ' rule-to-parameters-map = ' text2 = 'map file for set-parameters, e.g. ' text3 = 'adjunct-data/task-files/rule2var.json.' logger . info ( text1 + text2 + text3 ) text1 = ' selected-rules = ' text2 = 'file with list of selected rules, e.g. ' text3 = 'adjunct-data/task-files/selected_rules.json.' logger . info ( text1 + text2 + text3 ) text1 = ' enabled-rules = ' text2 = 'file with list of enabled rules, e.g. ' text3 = 'adjunct-data/task-files/enabled_rules.json.' logger . info ( text1 + text2 + text3 ) # text = '' logger . info ( text ) text = 'Notes:' logger . info ( text ) text = '1. If a control has selected rules but no enabled rules, then all those selected are included.' logger . info ( text ) text = '2. If a control has selected and enabled rules, then only those enabled are included.' logger . info ( text ) text = '3. If a control has no selected rules, then none are included regardless of enabled.' logger . info ( text ) def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" try : return self . _execute () except Exception : logger . info ( traceback . format_exc ()) return TaskOutcome ( 'failure' ) def _execute ( self ) -> TaskOutcome : if not self . _config : logger . warning ( 'config missing' ) return TaskOutcome ( 'failure' ) try : component_name = self . _config [ 'component-name' ] org_name = self . _config [ 'org-name' ] org_remarks = self . _config [ 'org-remarks' ] self . _folder_cac = self . _config [ 'folder-cac' ] profile_check_version = self . _config [ 'profile-check-version' ] profile_type = self . _config [ 'profile-type' ] profile_mnemonic = self . _config [ 'profile-mnemonic' ] profile_name = self . _config [ 'profile-name' ] profile_ns = self . _config [ 'profile-ns' ] profile_version = self . _config [ 'profile-version' ] profile_sets = {} profile_list = self . _config [ 'profile-list' ] . split () for profile in profile_list : profile_sets [ profile ] = {} profile_sets [ profile ][ 'profile-file' ] = self . _config [ f 'profile-file. { profile } ' ] profile_sets [ profile ][ 'profile-url' ] = self . _config [ f 'profile-url. { profile } ' ] profile_sets [ profile ][ 'profile-title' ] = self . _config [ f 'profile-title. { profile } ' ] profile_sets [ profile ][ 'profile-ns' ] = profile_ns profile_sets [ profile ][ 'component-name' ] = component_name odir = self . _config [ 'output-dir' ] except KeyError as e : logger . info ( f 'key { e . args [ 0 ] } missing' ) return TaskOutcome ( 'failure' ) # selected rules self . _selected_rules = self . _get_filter_rules ( 'selected-rules' , 'selected' ) # enabled rules self . _enabled_rules = self . _get_filter_rules ( 'enabled-rules' , 'enabled' ) # verbosity quiet = self . _config . get ( 'quiet' , False ) verbose = not quiet # output overwrite = self . _config . getboolean ( 'output-overwrite' , True ) opth = pathlib . Path ( odir ) # insure output dir exists opth . mkdir ( exist_ok = True , parents = True ) # calculate output file name & check writability oname = 'component-definition.json' ofile = opth / oname if not overwrite and pathlib . Path ( ofile ) . exists (): logger . warning ( f 'output: { ofile } already exists' ) return TaskOutcome ( 'failure' ) # fetch rule to parameters map self . _rule_to_parm_map = self . _get_parameters_map ( 'rule-to-parameters-map' ) # roles, responsible_roles, parties, responsible parties party_uuid_01 = str ( uuid . uuid4 ()) party_uuid_02 = str ( uuid . uuid4 ()) party_uuid_03 = str ( uuid . uuid4 ()) roles = self . _build_roles () responsible_roles = self . _build_responsible_roles ( party_uuid_01 , party_uuid_02 , party_uuid_03 ) parties = self . _build_parties ( org_name , org_remarks , party_uuid_01 , party_uuid_02 , party_uuid_03 ) responsible_parties = self . _build_responsible_parties ( party_uuid_01 , party_uuid_02 , party_uuid_03 ) # metadata metadata = Metadata ( title = f 'Component definition for { profile_type } profiles' , last_modified = self . _timestamp , oscal_version = OSCAL_VERSION , version = trestle . __version__ , roles = roles , parties = parties , responsible_parties = responsible_parties ) # defined component component_title = component_name component_description = component_name defined_component = DefinedComponent ( uuid = str ( uuid . uuid4 ()), description = component_description , title = component_title , type = 'Service' , ) # add control implementation per profile prop1 = Property ( name = 'profile_name' , value = profile_name , class_ = 'scc_profile_name' , ns = profile_ns , ) prop2 = Property ( name = 'profile_mnemonic' , value = profile_mnemonic , class_ = 'scc_profile_mnemonic' , ns = profile_ns , ) prop3 = Property ( name = 'profile_version' , value = profile_version , class_ = 'scc_profile_version' , ns = profile_ns , ) prop4 = Property ( name = 'profile_check_version' , value = profile_check_version , ) props = [ prop1 , prop2 , prop3 , prop4 ] for profile in profile_list : profile_set = profile_sets [ profile ] control_implementation = self . _build_control_implementation ( profile_set , responsible_roles , props ) if control_implementation is not None : if defined_component . control_implementations is None : defined_component . control_implementations = [ control_implementation ] else : defined_component . control_implementations . append ( control_implementation ) # defined components defined_components = [ defined_component ] # component definition component_definition = ComponentDefinition ( uuid = str ( uuid . uuid4 ()), metadata = metadata , components = defined_components , ) # write OSCAL ComponentDefinition to file if verbose : logger . info ( f 'output: { ofile } ' ) component_definition . oscal_write ( pathlib . Path ( ofile )) return TaskOutcome ( 'success' ) def _get_set_parameter ( self , rule : str ) -> SetParameter : \"\"\"Get set parameter.\"\"\" set_parameter = None for key in self . _rule_to_parm_map . keys (): logger . debug ( f ' { key } { rule } ' ) if key == rule : value = self . _rule_to_parm_map [ key ] remarks = value [ 'description' ] options = value [ 'options' ] default_value = options [ 'default' ] logger . debug ( f 'key: { key } options: { options } ' ) set_parameter = SetParameter ( param_id = rule , values = [ f ' { default_value } ' ], remarks = remarks , ) return set_parameter def _get_controls ( self , rules : Dict [ str , Tuple [ str , str , str ]]) -> Dict [ str , List [ str ]]: \"\"\"Get controls.\"\"\" controls = {} for rule in rules . keys (): control = rules [ rule ][ 1 ] if control not in controls . keys (): controls [ control ] = [ rule ] else : controls [ control ] = controls [ control ] + [ rule ] # trim rules associated with control with respect to enabled rules for control in controls : controls [ control ] = self . _get_trimmed_rules ( control , controls [ control ]) logger . debug ( f ' { control } { controls [ control ] } ' ) return controls # determine if trim is needed for the control, and if so then # for the associated set of rules drop those that are not enabled def _get_trimmed_rules ( self , control : str , rules_for_control : List [ str ]) -> List [ str ]: \"\"\"Trim rules if any rule for control appears in enabled rules list.\"\"\" retval = rules_for_control if self . _is_trim_needed ( rules_for_control ): retval = [] for rule in rules_for_control : if rule in self . _enabled_rules : retval = retval + [ rule ] logger . debug ( f 'keep { control } { rule } ' ) else : logger . debug ( f 'drop { control } { rule } ' ) return retval # if any rule in the set of rules for the control appears in the enabled list, # then trim is needed def _is_trim_needed ( self , rules_for_control : List [ str ]) -> bool : \"\"\"Check if trim is needed.\"\"\" retval = False for rule in rules_for_control : if rule in self . _enabled_rules : retval = True break return retval # fetch the set of rules that will be included/excluded from the CIS rules def _get_parameters_map ( self , config_key : str ) -> List [ str ]: \"\"\"Get parameters map.\"\"\" try : fp = pathlib . Path ( self . _config [ config_key ]) f = fp . open ( 'r' , encoding = const . FILE_ENCODING ) jdata = json . load ( f ) parameters_map = jdata f . close () except KeyError as e : logger . debug ( f 'key { e . args [ 0 ] } missing' ) parameters_map = {} except Exception : logger . warning ( f 'unable to process { self . _config [ config_key ] } ' ) parameters_map = {} return parameters_map # fetch the set of rules that will be included/excluded from the CIS rules def _get_filter_rules ( self , config_key : str , file_key : str ) -> List [ str ]: \"\"\"Get filter rules.\"\"\" try : fp = pathlib . Path ( self . _config [ config_key ]) f = fp . open ( 'r' , encoding = const . FILE_ENCODING ) jdata = json . load ( f ) try : filter_rules = jdata [ file_key ] except Exception : filter_rules = jdata f . close () except KeyError as e : logger . debug ( f 'key { e . args [ 0 ] } missing' ) filter_rules = [] except Exception : logger . warning ( f 'unable to process { self . _config [ config_key ] } ' ) filter_rules = [] return filter_rules # create map from file: # key is rule # value is tuple comprising [ category, control, description ] def _get_cis_rules ( self , filename : str ) -> Dict [ str , Tuple [ str , str , str ]]: \"\"\"Get CIS rules.\"\"\" try : fp = pathlib . Path ( filename ) f = fp . open ( 'r' , encoding = const . FILE_ENCODING ) content = f . readlines () rules = self . _parse_cis_rules ( content ) f . close () except Exception : logger . warning ( f 'unable to process { filename } ' ) rules = {} return rules def _parse_cis_rules ( self , content : List [ str ]) -> Dict [ str , Tuple [ str , str , str ]]: \"\"\"Parse CIS rules.\"\"\" rules = {} lineno = 0 for line in content : lineno += 1 line = line . replace ( ' \\n ' , '' ) if line . startswith ( ' #### ' ): category = line . split ( ' #### ' )[ 1 ] logger . debug ( f ' { lineno } category: { category } ' ) elif line . startswith ( ' # ' ): text = line . split ( ' # ' )[ 1 ] . split ( ' ' , 1 ) if '.' in text [ 0 ]: control = text [ 0 ] desc = text [ 1 ] logger . debug ( f ' { lineno } control: { control } description: { desc } ' ) else : logger . debug ( f ' { lineno } skip: { line } ' ) elif line . startswith ( ' - ' ): rule = line . split ( ' - ' )[ 1 ] logger . debug ( f ' { lineno } rule: { rule } ' ) if not self . _is_selected ( rule ): logger . debug ( f 'not selected rule: { rule } ' ) elif rule in rules . keys (): logger . info ( f 'duplicate rule: { rule } ' ) else : rules [ rule ] = [ category , control , desc ] else : logger . debug ( f ' { lineno } skip: { line } ' ) return rules # rule is selected if: # a) the selected rules file is not specified or is empty or # b) the rule appears in the list of selected rules from the file def _is_selected ( self , rule : str ) -> bool : \"\"\"Check if rule is selected.\"\"\" retval = True if len ( self . _selected_rules ) > 0 and rule not in self . _selected_rules : retval = False logger . debug ( f ' { retval } { rule } ' ) return retval # rule is excluded if it does not appear in the list of trimmed rules # for the control def _is_excluded ( self , rule : str , control : str , controls : Dict [ str , List [ str ]]) -> bool : \"\"\"Check if rule is excluded.\"\"\" retval = False if rule not in controls [ control ]: logger . debug ( f 'exclude { rule } { control } ' ) retval = True return retval def _build_roles ( self ) -> List [ Role ]: \"\"\"Build roles.\"\"\" value = [ Role ( id = 'prepared-by' , title = 'Indicates the organization that created this content.' ), Role ( id = 'prepared-for' , title = 'Indicates the organization for which this content was created..' ), Role ( id = 'content-approver' , title = 'Indicates the organization responsible for all content represented in the \"document\".' ), ] return value def _build_control_implementation ( self , profile_set : Dict [ str , str ], responsible_roles : List [ ResponsibleRole ], props : List [ Property ] ) -> ControlImplementation : \"\"\"Build control implementation.\"\"\" implemented_requirements = self . _build_implemented_requirements ( profile_set , responsible_roles ) if len ( implemented_requirements ) == 0 : control_implementation = None else : control_implementation = ControlImplementation ( uuid = str ( uuid . uuid4 ()), source = profile_set [ 'profile-url' ], description = f ' { profile_set [ \"component-name\" ] } implemented controls for { profile_set [ \"profile-title\" ] } .' , implemented_requirements = implemented_requirements , props = props , ) return control_implementation def _get_title ( self , dir_name : str , root : str ) -> str : \"\"\"Extract rule title from compliance-as-code rule.yml.\"\"\" \"\"\" Operation: Given is a dir_name and a root directory. We walk the directory tree looking for a directory named dir_name. Once found, we read the content of the rule.yml file in that directory. It is likely that we read each rule.yml file exactly once, since each rule appears exactly once in the one or more profiles, e.g. cis-node.profile, which drive the search. From the content, we find the title and return its corresponding value. \"\"\" title = None for path , dirs , _files in os . walk ( root ): if dir_name in dirs : folder = os . path . join ( path , dir_name ) tpath = pathlib . Path ( folder ) / 'rule.yml' fp = pathlib . Path ( tpath ) f = fp . open ( 'r' , encoding = const . FILE_ENCODING ) content = f . readlines () f . close () for line in content : if line . startswith ( 'title:' ): title = line . split ( 'title:' )[ 1 ] break if title is None : msg = f 'unable to find \" { dir_name } \"' logger . warning ( msg ) title = 'no title' title = title . strip () . strip ( \"'\" ) . strip ( '\"' ) logger . debug ( f ' { title } ' ) return title def _build_implemented_requirements ( self , profile_set : Dict [ str , str ], responsible_roles : List [ ResponsibleRole ]) -> List [ ImplementedRequirement ]: \"\"\"Build implemented requirements.\"\"\" implemented_requirements = [] profile_file = profile_set [ 'profile-file' ] rules = self . _get_cis_rules ( profile_file ) controls = self . _get_controls ( rules ) rule_prefix = 'xccdf_org.ssgproject.content_rule_' cac_openshift = f ' { self . _folder_cac } /applications/openshift' for rule in rules : if self . _is_excluded ( rule , rules [ rule ][ 1 ], controls ): continue remarks = self . _get_title ( rule , cac_openshift ) prop = Property ( class_ = 'scc_goal_name_id' , ns = profile_set [ 'profile-ns' ], name = 'XCCDF_rule' , value = f ' { rule_prefix }{ rule } ' , remarks = f ' { remarks } ' ) props = [ prop ] implemented_requirement = ImplementedRequirement ( uuid = f ' { str ( uuid . uuid4 ()) } ' , control_id = f 'CIS- { rules [ rule ][ 1 ] } ' , description = f ' { rules [ rule ][ 2 ] } ' , props = props , responsible_roles = responsible_roles , ) set_parameter = self . _get_set_parameter ( rule ) if set_parameter is not None : implemented_requirement . set_parameters = [ set_parameter ] implemented_requirements . append ( implemented_requirement ) return implemented_requirements def _build_responsible_roles ( self , party_uuid_01 : str , party_uuid_02 : str , party_uuid_03 : str ) -> List [ ResponsibleRole ]: \"\"\"Build responsible roles.\"\"\" role_prepared_by = ResponsibleRole ( role_id = 'prepared-by' , party_uuids = [ party_uuid_01 ]) role_prepared_for = ResponsibleRole ( role_id = 'prepared-for' , party_uuids = [ party_uuid_02 , party_uuid_03 ]) role_content_approver = ResponsibleRole ( role_id = 'content-approver' , party_uuids = [ party_uuid_01 ]) value = [ role_prepared_by , role_prepared_for , role_content_approver , ] return value def _build_parties ( self , org_name : str , org_remarks : str , party_uuid_01 : str , party_uuid_02 : str , party_uuid_03 : str ) -> List [ Party ]: \"\"\"Build parties.\"\"\" value = [ Party ( uuid = party_uuid_01 , type = 'organization' , name = org_name , remarks = org_remarks ), Party ( uuid = party_uuid_02 , type = 'organization' , name = 'Customer' , remarks = 'organization to be customized at account creation only for their Component Definition' ), Party ( uuid = party_uuid_03 , type = 'organization' , name = 'ISV' , remarks = 'organization to be customized at ISV subscription only for their Component Definition' ), ] return value def _build_responsible_parties ( self , party_uuid_01 : str , party_uuid_02 : str , party_uuid_03 : str ) -> List [ ResponsibleParty ]: \"\"\"Build responsible parties.\"\"\" prepared_by = ResponsibleParty ( role_id = 'prepared-by' , party_uuids = [ party_uuid_01 ]) prepared_for = ResponsibleParty ( role_id = 'prepared-for' , party_uuids = [ party_uuid_02 , party_uuid_03 ]) content_approver = ResponsibleParty ( role_id = 'content-approver' , party_uuids = [ party_uuid_01 ]) value = [ prepared_by , prepared_for , content_approver , ] return value","title":"Ocp4CisProfileToOscalCD"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_cd/#trestle.tasks.ocp4_cis_profile_to_oscal_cd.Ocp4CisProfileToOscalCD.name","text":"","title":"name"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_cd/#trestle.tasks.ocp4_cis_profile_to_oscal_cd.Ocp4CisProfileToOscalCD-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_cd/#trestle.tasks.ocp4_cis_profile_to_oscal_cd.Ocp4CisProfileToOscalCD.__init__","text":"Initialize trestle task ocp4-cis-profile-to-oscal-cd. Parameters: Name Type Description Default config_object Optional[configparser.SectionProxy] Config section associated with the task. required Source code in trestle/tasks/ocp4_cis_profile_to_oscal_cd.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task ocp4-cis-profile-to-oscal-cd. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) self . _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat ()","title":"__init__()"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_cd/#trestle.tasks.ocp4_cis_profile_to_oscal_cd.Ocp4CisProfileToOscalCD.execute","text":"Provide an actual outcome. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_cd.py def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" try : return self . _execute () except Exception : logger . info ( traceback . format_exc ()) return TaskOutcome ( 'failure' )","title":"execute()"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_cd/#trestle.tasks.ocp4_cis_profile_to_oscal_cd.Ocp4CisProfileToOscalCD.print_info","text":"Print the help string. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_cd.py def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Create component definition from standard (e.g. CIS benchmark).' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.ocp4-cis-profile-to-oscal-cd]:' ) text1 = ' component-name = ' text2 = 'component name, e.g. OSCO.' logger . info ( text1 + text2 ) text1 = ' org-name = ' text2 = 'organization name, e.g. International Business Machines.' logger . info ( text1 + text2 ) text1 = ' org-remarks = ' text2 = 'organization remarks, e.g. IBM.' logger . info ( text1 + text2 ) text1 = ' folder-cac = ' text2 = 'folder containing compliance-as-code artifacts, e.g adjunct-data/cis-benchmarks/content.' logger . info ( text1 + text2 ) text1 = ' output-dir = ' text2 = 'location to write the generated component-definition.json file.' logger . info ( text1 + text2 ) # text1 = ' profile-name = ' text2 = 'profile name, e.g. OCP4 CIS-benchmark v4.' logger . info ( text1 + text2 ) text1 = ' profile-mnemonic = ' text2 = 'profile mnemonic, e.g. ocp4-cis-node.' logger . info ( text1 + text2 ) text1 = ' profile-ns = ' text2 = 'profile ns, e.g. https://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud.' logger . info ( text1 + text2 ) text1 = ' profile-version = ' text2 = 'profile version, e.g. 1.1.' logger . info ( text1 + text2 ) text1 = ' profile-check-version = ' text2 = 'profile check version, e.g. 0.1.58.' logger . info ( text1 + text2 ) # text1 = ' profile-type = ' text2 = 'profile type, e.g. OCP4.' logger . info ( text1 + text2 ) text1 = ' profile-list = ' text2 = 'profile list is blank separated list of \"<suffix>\" for config entries: ' logger . info ( text1 + text2 ) text1 = ' profile-file.<suffix>, profile-title.<suffix>, profile-url.<suffix>' text2 = ', e.g. cis cis-node.' logger . info ( text1 + text2 ) text1 = ' profile-file.<suffix> = ' text2 = 'path of the profile file to ingest' text3 = ', e.g. ${folder-cac}/products/ocp4/profiles/cis-node.profile.' # noqa logger . info ( text1 + text2 + text3 ) text1 = ' profile-title.<suffix> = ' text2 = 'title of the profile' text3 = ', e.g. CIS Red Hat OpenShift Container Platform 4 Benchmark.' logger . info ( text1 + text2 + text3 ) text1 = ' profile-url.<suffix> = ' text2 = 'URL of the profile' text3 = ', e.g. https://github.com/ComplianceAsCode/content/blob/master/products/ocp4/profiles/cis.profile.' logger . info ( text1 + text2 + text3 ) text1 = ' rule-to-parameters-map = ' text2 = 'map file for set-parameters, e.g. ' text3 = 'adjunct-data/task-files/rule2var.json.' logger . info ( text1 + text2 + text3 ) text1 = ' selected-rules = ' text2 = 'file with list of selected rules, e.g. ' text3 = 'adjunct-data/task-files/selected_rules.json.' logger . info ( text1 + text2 + text3 ) text1 = ' enabled-rules = ' text2 = 'file with list of enabled rules, e.g. ' text3 = 'adjunct-data/task-files/enabled_rules.json.' logger . info ( text1 + text2 + text3 ) # text = '' logger . info ( text ) text = 'Notes:' logger . info ( text ) text = '1. If a control has selected rules but no enabled rules, then all those selected are included.' logger . info ( text ) text = '2. If a control has selected and enabled rules, then only those enabled are included.' logger . info ( text ) text = '3. If a control has no selected rules, then none are included regardless of enabled.' logger . info ( text )","title":"print_info()"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_cd/#trestle.tasks.ocp4_cis_profile_to_oscal_cd.Ocp4CisProfileToOscalCD.set_timestamp","text":"Set the timestamp. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_cd.py def set_timestamp ( self , timestamp : str ) -> None : \"\"\"Set the timestamp.\"\"\" self . _timestamp = timestamp","title":"set_timestamp()"},{"location":"api_reference/trestle.tasks.ocp4_cis_profile_to_oscal_cd/#trestle.tasks.ocp4_cis_profile_to_oscal_cd.Ocp4CisProfileToOscalCD.simulate","text":"Provide a simulated outcome. Source code in trestle/tasks/ocp4_cis_profile_to_oscal_cd.py def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) handler: python","title":"simulate()"},{"location":"api_reference/trestle.tasks.oscal_profile_to_osco_profile/","text":"trestle.tasks.oscal_profile_to_osco_profile \u00a4 OSCAL transformation tasks. logger \u00a4 Classes \u00a4 ProfileToOsco ( TaskBase ) \u00a4 Task to convert Profile to OSC yaml. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/oscal_profile_to_osco_profile.py class ProfileToOsco ( TaskBase ): \"\"\" Task to convert Profile to OSC yaml. Attributes: name: Name of the task. \"\"\" name = 'oscal-profile-to-osco-profile' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task oscal-profile-to-osco-profile. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Transform Open Security Controls Assessment Language (OSCAL) Profile ' + 'into Open Shift Compliance Operator (OSCO) .yaml file.' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.oscal-profile-to-osco-profile]:' ) logger . info ( ' input-file = (required) path of the input file comprising OSCAL profile.' ) logger . info ( ' output-dir = (required) path of the output directory comprising synthesized .yaml file.' ) logger . info ( ' output-name = (optional) name of created file in output directory, default is osco-profile.yaml.' ) logger . info ( ' output-overwrite = (optional) true [default] or false; replace existing output when true.' ) logger . info ( ' quiet = (optional) true or false [default]; display file creations and rules analysis when false.' ) logger . info ( '' ) logger . info ( 'Operation: The specified input profile is transformed into OSCO .yaml.' ) logger . info ( '' ) logger . info ( 'Notes:' ) note11 = '[1] The input-file OSCAL profile should specify a metadata property with' note12 = 'name \"osco_version\" and value of the form \"0.1.46\".' note13 = 'The value corresponds with the OpenShift Compliance Operator (OSCO) version' note14 = 'and affects the format of the emitted yaml.' note15 = 'If not specified, the default is \"0.1.46\".' logger . info ( f ' { note11 } { note12 } { note13 } { note14 } { note15 } ' ) note21 = '[2] For OSCO version \"0.1.39\" and prior no \"description\" is emitted for \"spec\".' logger . info ( f ' { note21 } ' ) def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" try : return self . _execute () except Exception : logger . warning ( traceback . format_exc ()) return TaskOutcome ( 'failure' ) def _execute ( self ) -> TaskOutcome : \"\"\"Perform transformation.\"\"\" # check config if not self . _config : logger . warning ( 'config missing' ) return TaskOutcome ( 'failure' ) # input-file input_file = self . _config . get ( 'input-file' ) if input_file is None : logger . warning ( 'config missing \"input-file\"' ) return TaskOutcome ( 'failure' ) logger . info ( f 'input-file: { input_file } ' ) input_path = pathlib . Path ( input_file ) # output-dir output_dir = self . _config . get ( 'output-dir' ) if output_dir is None : logger . warning ( 'config missing \"output-dir\"' ) return TaskOutcome ( 'failure' ) output_path = pathlib . Path ( output_dir ) # insure output dir exists output_path . mkdir ( exist_ok = True , parents = True ) # output file path output_name = self . _config . get ( 'output-name' , 'osco-profile.yaml' ) output_filepath = pathlib . Path ( output_dir , output_name ) logger . info ( f 'output-file: { output_filepath } ' ) # overwrite overwrite = self . _config . getboolean ( 'output-overwrite' , True ) if not overwrite and pathlib . Path ( output_filepath ) . exists (): logger . warning ( f 'output-file: { output_filepath } already exists' ) return TaskOutcome ( 'failure' ) # read input profile = Profile . oscal_read ( input_path ) # transform transformer = OscalProfileToOscoProfileTransformer () ydata = json . loads ( transformer . transform ( profile )) # write output yaml = YAML ( typ = 'safe' ) yaml . default_flow_style = False with open ( output_filepath , 'w' ) as outfile : yaml . dump ( ydata , outfile ) # success return TaskOutcome ( 'success' ) name : str \u00a4 Methods \u00a4 __init__ ( self , config_object ) special \u00a4 Initialize trestle task oscal-profile-to-osco-profile. Parameters: Name Type Description Default config_object Optional[configparser.SectionProxy] Config section associated with the task. required Source code in trestle/tasks/oscal_profile_to_osco_profile.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task oscal-profile-to-osco-profile. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) execute ( self ) \u00a4 Provide an actual outcome. Source code in trestle/tasks/oscal_profile_to_osco_profile.py def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" try : return self . _execute () except Exception : logger . warning ( traceback . format_exc ()) return TaskOutcome ( 'failure' ) print_info ( self ) \u00a4 Print the help string. Source code in trestle/tasks/oscal_profile_to_osco_profile.py def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Transform Open Security Controls Assessment Language (OSCAL) Profile ' + 'into Open Shift Compliance Operator (OSCO) .yaml file.' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.oscal-profile-to-osco-profile]:' ) logger . info ( ' input-file = (required) path of the input file comprising OSCAL profile.' ) logger . info ( ' output-dir = (required) path of the output directory comprising synthesized .yaml file.' ) logger . info ( ' output-name = (optional) name of created file in output directory, default is osco-profile.yaml.' ) logger . info ( ' output-overwrite = (optional) true [default] or false; replace existing output when true.' ) logger . info ( ' quiet = (optional) true or false [default]; display file creations and rules analysis when false.' ) logger . info ( '' ) logger . info ( 'Operation: The specified input profile is transformed into OSCO .yaml.' ) logger . info ( '' ) logger . info ( 'Notes:' ) note11 = '[1] The input-file OSCAL profile should specify a metadata property with' note12 = 'name \"osco_version\" and value of the form \"0.1.46\".' note13 = 'The value corresponds with the OpenShift Compliance Operator (OSCO) version' note14 = 'and affects the format of the emitted yaml.' note15 = 'If not specified, the default is \"0.1.46\".' logger . info ( f ' { note11 } { note12 } { note13 } { note14 } { note15 } ' ) note21 = '[2] For OSCO version \"0.1.39\" and prior no \"description\" is emitted for \"spec\".' logger . info ( f ' { note21 } ' ) simulate ( self ) \u00a4 Provide a simulated outcome. Source code in trestle/tasks/oscal_profile_to_osco_profile.py def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) handler: python","title":"oscal_profile_to_osco_profile"},{"location":"api_reference/trestle.tasks.oscal_profile_to_osco_profile/#trestle.tasks.oscal_profile_to_osco_profile","text":"OSCAL transformation tasks.","title":"oscal_profile_to_osco_profile"},{"location":"api_reference/trestle.tasks.oscal_profile_to_osco_profile/#trestle.tasks.oscal_profile_to_osco_profile.logger","text":"","title":"logger"},{"location":"api_reference/trestle.tasks.oscal_profile_to_osco_profile/#trestle.tasks.oscal_profile_to_osco_profile-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.tasks.oscal_profile_to_osco_profile/#trestle.tasks.oscal_profile_to_osco_profile.ProfileToOsco","text":"Task to convert Profile to OSC yaml. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/oscal_profile_to_osco_profile.py class ProfileToOsco ( TaskBase ): \"\"\" Task to convert Profile to OSC yaml. Attributes: name: Name of the task. \"\"\" name = 'oscal-profile-to-osco-profile' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task oscal-profile-to-osco-profile. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Transform Open Security Controls Assessment Language (OSCAL) Profile ' + 'into Open Shift Compliance Operator (OSCO) .yaml file.' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.oscal-profile-to-osco-profile]:' ) logger . info ( ' input-file = (required) path of the input file comprising OSCAL profile.' ) logger . info ( ' output-dir = (required) path of the output directory comprising synthesized .yaml file.' ) logger . info ( ' output-name = (optional) name of created file in output directory, default is osco-profile.yaml.' ) logger . info ( ' output-overwrite = (optional) true [default] or false; replace existing output when true.' ) logger . info ( ' quiet = (optional) true or false [default]; display file creations and rules analysis when false.' ) logger . info ( '' ) logger . info ( 'Operation: The specified input profile is transformed into OSCO .yaml.' ) logger . info ( '' ) logger . info ( 'Notes:' ) note11 = '[1] The input-file OSCAL profile should specify a metadata property with' note12 = 'name \"osco_version\" and value of the form \"0.1.46\".' note13 = 'The value corresponds with the OpenShift Compliance Operator (OSCO) version' note14 = 'and affects the format of the emitted yaml.' note15 = 'If not specified, the default is \"0.1.46\".' logger . info ( f ' { note11 } { note12 } { note13 } { note14 } { note15 } ' ) note21 = '[2] For OSCO version \"0.1.39\" and prior no \"description\" is emitted for \"spec\".' logger . info ( f ' { note21 } ' ) def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" try : return self . _execute () except Exception : logger . warning ( traceback . format_exc ()) return TaskOutcome ( 'failure' ) def _execute ( self ) -> TaskOutcome : \"\"\"Perform transformation.\"\"\" # check config if not self . _config : logger . warning ( 'config missing' ) return TaskOutcome ( 'failure' ) # input-file input_file = self . _config . get ( 'input-file' ) if input_file is None : logger . warning ( 'config missing \"input-file\"' ) return TaskOutcome ( 'failure' ) logger . info ( f 'input-file: { input_file } ' ) input_path = pathlib . Path ( input_file ) # output-dir output_dir = self . _config . get ( 'output-dir' ) if output_dir is None : logger . warning ( 'config missing \"output-dir\"' ) return TaskOutcome ( 'failure' ) output_path = pathlib . Path ( output_dir ) # insure output dir exists output_path . mkdir ( exist_ok = True , parents = True ) # output file path output_name = self . _config . get ( 'output-name' , 'osco-profile.yaml' ) output_filepath = pathlib . Path ( output_dir , output_name ) logger . info ( f 'output-file: { output_filepath } ' ) # overwrite overwrite = self . _config . getboolean ( 'output-overwrite' , True ) if not overwrite and pathlib . Path ( output_filepath ) . exists (): logger . warning ( f 'output-file: { output_filepath } already exists' ) return TaskOutcome ( 'failure' ) # read input profile = Profile . oscal_read ( input_path ) # transform transformer = OscalProfileToOscoProfileTransformer () ydata = json . loads ( transformer . transform ( profile )) # write output yaml = YAML ( typ = 'safe' ) yaml . default_flow_style = False with open ( output_filepath , 'w' ) as outfile : yaml . dump ( ydata , outfile ) # success return TaskOutcome ( 'success' )","title":"ProfileToOsco"},{"location":"api_reference/trestle.tasks.oscal_profile_to_osco_profile/#trestle.tasks.oscal_profile_to_osco_profile.ProfileToOsco.name","text":"","title":"name"},{"location":"api_reference/trestle.tasks.oscal_profile_to_osco_profile/#trestle.tasks.oscal_profile_to_osco_profile.ProfileToOsco-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.tasks.oscal_profile_to_osco_profile/#trestle.tasks.oscal_profile_to_osco_profile.ProfileToOsco.__init__","text":"Initialize trestle task oscal-profile-to-osco-profile. Parameters: Name Type Description Default config_object Optional[configparser.SectionProxy] Config section associated with the task. required Source code in trestle/tasks/oscal_profile_to_osco_profile.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task oscal-profile-to-osco-profile. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object )","title":"__init__()"},{"location":"api_reference/trestle.tasks.oscal_profile_to_osco_profile/#trestle.tasks.oscal_profile_to_osco_profile.ProfileToOsco.execute","text":"Provide an actual outcome. Source code in trestle/tasks/oscal_profile_to_osco_profile.py def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" try : return self . _execute () except Exception : logger . warning ( traceback . format_exc ()) return TaskOutcome ( 'failure' )","title":"execute()"},{"location":"api_reference/trestle.tasks.oscal_profile_to_osco_profile/#trestle.tasks.oscal_profile_to_osco_profile.ProfileToOsco.print_info","text":"Print the help string. Source code in trestle/tasks/oscal_profile_to_osco_profile.py def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Transform Open Security Controls Assessment Language (OSCAL) Profile ' + 'into Open Shift Compliance Operator (OSCO) .yaml file.' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.oscal-profile-to-osco-profile]:' ) logger . info ( ' input-file = (required) path of the input file comprising OSCAL profile.' ) logger . info ( ' output-dir = (required) path of the output directory comprising synthesized .yaml file.' ) logger . info ( ' output-name = (optional) name of created file in output directory, default is osco-profile.yaml.' ) logger . info ( ' output-overwrite = (optional) true [default] or false; replace existing output when true.' ) logger . info ( ' quiet = (optional) true or false [default]; display file creations and rules analysis when false.' ) logger . info ( '' ) logger . info ( 'Operation: The specified input profile is transformed into OSCO .yaml.' ) logger . info ( '' ) logger . info ( 'Notes:' ) note11 = '[1] The input-file OSCAL profile should specify a metadata property with' note12 = 'name \"osco_version\" and value of the form \"0.1.46\".' note13 = 'The value corresponds with the OpenShift Compliance Operator (OSCO) version' note14 = 'and affects the format of the emitted yaml.' note15 = 'If not specified, the default is \"0.1.46\".' logger . info ( f ' { note11 } { note12 } { note13 } { note14 } { note15 } ' ) note21 = '[2] For OSCO version \"0.1.39\" and prior no \"description\" is emitted for \"spec\".' logger . info ( f ' { note21 } ' )","title":"print_info()"},{"location":"api_reference/trestle.tasks.oscal_profile_to_osco_profile/#trestle.tasks.oscal_profile_to_osco_profile.ProfileToOsco.simulate","text":"Provide a simulated outcome. Source code in trestle/tasks/oscal_profile_to_osco_profile.py def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) handler: python","title":"simulate()"},{"location":"api_reference/trestle.tasks.osco_result_to_oscal_ar/","text":"trestle.tasks.osco_result_to_oscal_ar \u00a4 OSCAL transformation tasks. logger \u00a4 Classes \u00a4 OscoResultToOscalAR ( TaskBase ) \u00a4 Task to convert Osco result to OSCAL json. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/osco_result_to_oscal_ar.py class OscoResultToOscalAR ( TaskBase ): \"\"\" Task to convert Osco result to OSCAL json. Attributes: name: Name of the task. \"\"\" name = 'osco-result-to-oscal-ar' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task osco-result-to-oscal-ar. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Transform Osco files into Open Security Controls Assessment Language (OSCAL) ' + 'partial results files.' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.osco-result-to-oscal-ar]:' ) logger . info ( ' checking = (optional) True indicates perform strict checking of OSCAL properties, default is False.' ) logger . info ( ' input-dir = (required) the path of the input directory comprising Osco results.' ) logger . info ( ' output-dir = (required) the path of the output directory comprising synthesized OSCAL .json files.' ) logger . info ( ' output-overwrite = (optional) true [default] or false; replace existing output when true.' ) logger . info ( ' quiet = (optional) true or false [default]; display file creations and rules analysis when false.' ) logger . info ( ' timestamp = (optional) timestamp for the Observations in ISO 8601 format, such as ' + ' 2021-01-04T00:05:23+04:00 for example; if not specified then value for \"Timestamp\" key in the Osco ' + ' result is used if present, otherwise current time is used.' ) logger . info ( '' ) logger . info ( 'Operation: A transformation is performed on one or more Osco input files to produce output in OSCAL ' + 'partial results format.' ) def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" self . _simulate = True return self . _transform () def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" self . _simulate = False return self . _transform () def _transform ( self ) -> TaskOutcome : \"\"\"Perform transformation.\"\"\" try : return self . _transform_work () except Exception : logger . debug ( traceback . format_exc ()) mode = '' if self . _simulate : mode = 'simulated-' return TaskOutcome ( mode + 'failure' ) def _transform_work ( self ) -> TaskOutcome : \"\"\" Perform transformation work steps. Work steps: read input, process, write output, display analysis \"\"\" mode = '' if self . _simulate : mode = 'simulated-' if not self . _config : logger . warning ( 'config missing' ) return TaskOutcome ( mode + 'failure' ) # config required input & output dirs try : idir = self . _config [ 'input-dir' ] ipth = pathlib . Path ( idir ) odir = self . _config [ 'output-dir' ] opth = pathlib . Path ( odir ) except KeyError as e : logger . debug ( f 'key { e . args [ 0 ] } missing' ) return TaskOutcome ( mode + 'failure' ) # config optional overwrite & quiet self . _overwrite = self . _config . getboolean ( 'output-overwrite' , True ) quiet = self . _config . get ( 'quiet' , False ) self . _verbose = not self . _simulate and not quiet # config optional timestamp timestamp = self . _config . get ( 'timestamp' ) if timestamp is not None : try : OscoTransformer . set_timestamp ( timestamp ) except Exception : logger . warning ( 'config invalid \"timestamp\"' ) return TaskOutcome ( mode + 'failure' ) # config optional performance modes = { 'checking' : self . _config . getboolean ( 'checking' , False ), } # insure output dir exists opth . mkdir ( exist_ok = True , parents = True ) # process for ifile in sorted ( ipth . iterdir ()): if ifile . suffix not in [ '.json' , '.jsn' , '.yaml' , '.yml' , '.xml' ]: continue blob = self . _read_file ( ifile ) osco_transformer = OscoTransformer () osco_transformer . set_modes ( modes ) results = osco_transformer . transform ( blob ) oname = ifile . stem + '.oscal' + '.json' ofile = opth / oname if not self . _overwrite and pathlib . Path ( ofile ) . exists (): logger . warning ( f 'output: { ofile } already exists' ) return TaskOutcome ( mode + 'failure' ) self . _write_file ( results , ofile ) self . _show_analysis ( osco_transformer ) return TaskOutcome ( mode + 'success' ) def _read_file ( self , ifile : str ) -> str : \"\"\"Read raw input file.\"\"\" if not self . _simulate and self . _verbose : logger . info ( f 'input: { ifile } ' ) with open ( ifile , encoding = const . FILE_ENCODING ) as fp : blob = fp . read () return blob def _write_file ( self , result : str , ofile : str ) -> None : \"\"\"Write oscal results file.\"\"\" if not self . _simulate : if self . _verbose : logger . info ( f 'output: { ofile } ' ) result . oscal_write ( pathlib . Path ( ofile )) def _show_analysis ( self , osco_transformer : OscoTransformer ) -> None : \"\"\"Show analysis.\"\"\" if not self . _simulate and self . _verbose : analysis = osco_transformer . analysis for line in analysis : logger . info ( line ) name : str \u00a4 Methods \u00a4 __init__ ( self , config_object ) special \u00a4 Initialize trestle task osco-result-to-oscal-ar. Parameters: Name Type Description Default config_object Optional[configparser.SectionProxy] Config section associated with the task. required Source code in trestle/tasks/osco_result_to_oscal_ar.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task osco-result-to-oscal-ar. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) execute ( self ) \u00a4 Provide an actual outcome. Source code in trestle/tasks/osco_result_to_oscal_ar.py def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" self . _simulate = False return self . _transform () print_info ( self ) \u00a4 Print the help string. Source code in trestle/tasks/osco_result_to_oscal_ar.py def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Transform Osco files into Open Security Controls Assessment Language (OSCAL) ' + 'partial results files.' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.osco-result-to-oscal-ar]:' ) logger . info ( ' checking = (optional) True indicates perform strict checking of OSCAL properties, default is False.' ) logger . info ( ' input-dir = (required) the path of the input directory comprising Osco results.' ) logger . info ( ' output-dir = (required) the path of the output directory comprising synthesized OSCAL .json files.' ) logger . info ( ' output-overwrite = (optional) true [default] or false; replace existing output when true.' ) logger . info ( ' quiet = (optional) true or false [default]; display file creations and rules analysis when false.' ) logger . info ( ' timestamp = (optional) timestamp for the Observations in ISO 8601 format, such as ' + ' 2021-01-04T00:05:23+04:00 for example; if not specified then value for \"Timestamp\" key in the Osco ' + ' result is used if present, otherwise current time is used.' ) logger . info ( '' ) logger . info ( 'Operation: A transformation is performed on one or more Osco input files to produce output in OSCAL ' + 'partial results format.' ) simulate ( self ) \u00a4 Provide a simulated outcome. Source code in trestle/tasks/osco_result_to_oscal_ar.py def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" self . _simulate = True return self . _transform () handler: python","title":"osco_result_to_oscal_ar"},{"location":"api_reference/trestle.tasks.osco_result_to_oscal_ar/#trestle.tasks.osco_result_to_oscal_ar","text":"OSCAL transformation tasks.","title":"osco_result_to_oscal_ar"},{"location":"api_reference/trestle.tasks.osco_result_to_oscal_ar/#trestle.tasks.osco_result_to_oscal_ar.logger","text":"","title":"logger"},{"location":"api_reference/trestle.tasks.osco_result_to_oscal_ar/#trestle.tasks.osco_result_to_oscal_ar-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.tasks.osco_result_to_oscal_ar/#trestle.tasks.osco_result_to_oscal_ar.OscoResultToOscalAR","text":"Task to convert Osco result to OSCAL json. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/osco_result_to_oscal_ar.py class OscoResultToOscalAR ( TaskBase ): \"\"\" Task to convert Osco result to OSCAL json. Attributes: name: Name of the task. \"\"\" name = 'osco-result-to-oscal-ar' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task osco-result-to-oscal-ar. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Transform Osco files into Open Security Controls Assessment Language (OSCAL) ' + 'partial results files.' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.osco-result-to-oscal-ar]:' ) logger . info ( ' checking = (optional) True indicates perform strict checking of OSCAL properties, default is False.' ) logger . info ( ' input-dir = (required) the path of the input directory comprising Osco results.' ) logger . info ( ' output-dir = (required) the path of the output directory comprising synthesized OSCAL .json files.' ) logger . info ( ' output-overwrite = (optional) true [default] or false; replace existing output when true.' ) logger . info ( ' quiet = (optional) true or false [default]; display file creations and rules analysis when false.' ) logger . info ( ' timestamp = (optional) timestamp for the Observations in ISO 8601 format, such as ' + ' 2021-01-04T00:05:23+04:00 for example; if not specified then value for \"Timestamp\" key in the Osco ' + ' result is used if present, otherwise current time is used.' ) logger . info ( '' ) logger . info ( 'Operation: A transformation is performed on one or more Osco input files to produce output in OSCAL ' + 'partial results format.' ) def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" self . _simulate = True return self . _transform () def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" self . _simulate = False return self . _transform () def _transform ( self ) -> TaskOutcome : \"\"\"Perform transformation.\"\"\" try : return self . _transform_work () except Exception : logger . debug ( traceback . format_exc ()) mode = '' if self . _simulate : mode = 'simulated-' return TaskOutcome ( mode + 'failure' ) def _transform_work ( self ) -> TaskOutcome : \"\"\" Perform transformation work steps. Work steps: read input, process, write output, display analysis \"\"\" mode = '' if self . _simulate : mode = 'simulated-' if not self . _config : logger . warning ( 'config missing' ) return TaskOutcome ( mode + 'failure' ) # config required input & output dirs try : idir = self . _config [ 'input-dir' ] ipth = pathlib . Path ( idir ) odir = self . _config [ 'output-dir' ] opth = pathlib . Path ( odir ) except KeyError as e : logger . debug ( f 'key { e . args [ 0 ] } missing' ) return TaskOutcome ( mode + 'failure' ) # config optional overwrite & quiet self . _overwrite = self . _config . getboolean ( 'output-overwrite' , True ) quiet = self . _config . get ( 'quiet' , False ) self . _verbose = not self . _simulate and not quiet # config optional timestamp timestamp = self . _config . get ( 'timestamp' ) if timestamp is not None : try : OscoTransformer . set_timestamp ( timestamp ) except Exception : logger . warning ( 'config invalid \"timestamp\"' ) return TaskOutcome ( mode + 'failure' ) # config optional performance modes = { 'checking' : self . _config . getboolean ( 'checking' , False ), } # insure output dir exists opth . mkdir ( exist_ok = True , parents = True ) # process for ifile in sorted ( ipth . iterdir ()): if ifile . suffix not in [ '.json' , '.jsn' , '.yaml' , '.yml' , '.xml' ]: continue blob = self . _read_file ( ifile ) osco_transformer = OscoTransformer () osco_transformer . set_modes ( modes ) results = osco_transformer . transform ( blob ) oname = ifile . stem + '.oscal' + '.json' ofile = opth / oname if not self . _overwrite and pathlib . Path ( ofile ) . exists (): logger . warning ( f 'output: { ofile } already exists' ) return TaskOutcome ( mode + 'failure' ) self . _write_file ( results , ofile ) self . _show_analysis ( osco_transformer ) return TaskOutcome ( mode + 'success' ) def _read_file ( self , ifile : str ) -> str : \"\"\"Read raw input file.\"\"\" if not self . _simulate and self . _verbose : logger . info ( f 'input: { ifile } ' ) with open ( ifile , encoding = const . FILE_ENCODING ) as fp : blob = fp . read () return blob def _write_file ( self , result : str , ofile : str ) -> None : \"\"\"Write oscal results file.\"\"\" if not self . _simulate : if self . _verbose : logger . info ( f 'output: { ofile } ' ) result . oscal_write ( pathlib . Path ( ofile )) def _show_analysis ( self , osco_transformer : OscoTransformer ) -> None : \"\"\"Show analysis.\"\"\" if not self . _simulate and self . _verbose : analysis = osco_transformer . analysis for line in analysis : logger . info ( line )","title":"OscoResultToOscalAR"},{"location":"api_reference/trestle.tasks.osco_result_to_oscal_ar/#trestle.tasks.osco_result_to_oscal_ar.OscoResultToOscalAR.name","text":"","title":"name"},{"location":"api_reference/trestle.tasks.osco_result_to_oscal_ar/#trestle.tasks.osco_result_to_oscal_ar.OscoResultToOscalAR-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.tasks.osco_result_to_oscal_ar/#trestle.tasks.osco_result_to_oscal_ar.OscoResultToOscalAR.__init__","text":"Initialize trestle task osco-result-to-oscal-ar. Parameters: Name Type Description Default config_object Optional[configparser.SectionProxy] Config section associated with the task. required Source code in trestle/tasks/osco_result_to_oscal_ar.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task osco-result-to-oscal-ar. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object )","title":"__init__()"},{"location":"api_reference/trestle.tasks.osco_result_to_oscal_ar/#trestle.tasks.osco_result_to_oscal_ar.OscoResultToOscalAR.execute","text":"Provide an actual outcome. Source code in trestle/tasks/osco_result_to_oscal_ar.py def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" self . _simulate = False return self . _transform ()","title":"execute()"},{"location":"api_reference/trestle.tasks.osco_result_to_oscal_ar/#trestle.tasks.osco_result_to_oscal_ar.OscoResultToOscalAR.print_info","text":"Print the help string. Source code in trestle/tasks/osco_result_to_oscal_ar.py def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Transform Osco files into Open Security Controls Assessment Language (OSCAL) ' + 'partial results files.' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.osco-result-to-oscal-ar]:' ) logger . info ( ' checking = (optional) True indicates perform strict checking of OSCAL properties, default is False.' ) logger . info ( ' input-dir = (required) the path of the input directory comprising Osco results.' ) logger . info ( ' output-dir = (required) the path of the output directory comprising synthesized OSCAL .json files.' ) logger . info ( ' output-overwrite = (optional) true [default] or false; replace existing output when true.' ) logger . info ( ' quiet = (optional) true or false [default]; display file creations and rules analysis when false.' ) logger . info ( ' timestamp = (optional) timestamp for the Observations in ISO 8601 format, such as ' + ' 2021-01-04T00:05:23+04:00 for example; if not specified then value for \"Timestamp\" key in the Osco ' + ' result is used if present, otherwise current time is used.' ) logger . info ( '' ) logger . info ( 'Operation: A transformation is performed on one or more Osco input files to produce output in OSCAL ' + 'partial results format.' )","title":"print_info()"},{"location":"api_reference/trestle.tasks.osco_result_to_oscal_ar/#trestle.tasks.osco_result_to_oscal_ar.OscoResultToOscalAR.simulate","text":"Provide a simulated outcome. Source code in trestle/tasks/osco_result_to_oscal_ar.py def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" self . _simulate = True return self . _transform () handler: python","title":"simulate()"},{"location":"api_reference/trestle.tasks.tanium_result_to_oscal_ar/","text":"trestle.tasks.tanium_result_to_oscal_ar \u00a4 OSCAL transformation tasks. logger \u00a4 Classes \u00a4 TaniumResultToOscalAR ( TaskBase ) \u00a4 Task to convert Tanium result to OSCAL json. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/tanium_result_to_oscal_ar.py class TaniumResultToOscalAR ( TaskBase ): \"\"\" Task to convert Tanium result to OSCAL json. Attributes: name: Name of the task. \"\"\" name = 'tanium-result-to-oscal-ar' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task tanium-result-to-oscal-ar. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Transform Tanium files into Open Security Controls Assessment Language (OSCAL) results objects' + 'and serialize to a file.' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.tanium-result-to-oscal-ar]:' ) logger . info ( ' blocksize = (optional) the desired number Tanuim result input lines to process per CPU.' ) logger . info ( ' cpus-max = (optional) the desired maximum number of CPUs to employ, default is 1.' ) logger . info ( ' cpus-min = (optional) the desired minimum number of CPUs to employ.' ) logger . info ( ' aggregate = (optional) True indicates employ properties aggregation, default is True.' ) logger . info ( ' caching = (optional) True indicates employ object caching, default is True.' ) logger . info ( ' checking = (optional) True indicates perform strict checking of OSCAL properties, default is False.' ) logger . info ( ' input-dir = (required) the path of the input directory comprising Tanium results.' ) logger . info ( ' output-dir = (required) the path of the output directory comprising synthesized OSCAL .json files.' ) logger . info ( ' output-overwrite = (optional) true [default] or false; replace existing output when true.' ) logger . info ( ' quiet = (optional) true or false [default]; display file creations and rules analysis when false.' ) logger . info ( ' timestamp = (optional) timestamp for the Observations in ISO 8601 format, such as ' + '2021-01-04T00:05:23+04:00 for example; if not specified then value for \"Timestamp\" key in the Tanium ' + 'result is used if present, otherwise current time is used.' ) logger . info ( '' ) logger . info ( 'Operation: A transformation is performed on one or more Tanium input files to produce output in ' + 'OSCAL partial results format.' ) def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" self . _simulate = True return self . _transform () def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" self . _simulate = False return self . _transform () def _transform ( self ) -> TaskOutcome : \"\"\"Perform transformation.\"\"\" try : return self . _transform_work () except Exception : logger . info ( traceback . format_exc ()) mode = '' if self . _simulate : mode = 'simulated-' return TaskOutcome ( mode + 'failure' ) def _transform_work ( self ) -> TaskOutcome : \"\"\" Perform the transformation work. Transformation work steps: read input, process, write output, display analysis. \"\"\" mode = '' if self . _simulate : mode = 'simulated-' if not self . _config : logger . warning ( 'Config missing' ) return TaskOutcome ( mode + 'failure' ) # config required input & output dirs try : idir = self . _config [ 'input-dir' ] ipth = pathlib . Path ( idir ) odir = self . _config [ 'output-dir' ] opth = pathlib . Path ( odir ) except KeyError as e : logger . debug ( f 'key { e . args [ 0 ] } missing' ) return TaskOutcome ( mode + 'failure' ) # config optional overwrite & quiet self . _overwrite = self . _config . getboolean ( 'output-overwrite' , True ) quiet = self . _config . get ( 'quiet' , False ) self . _verbose = not self . _simulate and not quiet # config optional timestamp timestamp = self . _config . get ( 'timestamp' ) if timestamp is not None : try : TaniumTransformer . set_timestamp ( timestamp ) except Exception : logger . warning ( 'config invalid \"timestamp\"' ) return TaskOutcome ( mode + 'failure' ) # config optional performance modes = { 'blocksize' : self . _config . getint ( 'blocksize' , 10000 ), 'cpus_max' : self . _config . getint ( 'cpus-max' , 1 ), 'cpus_min' : self . _config . getint ( 'cpus-min' , 1 ), 'aggregate' : self . _config . getboolean ( 'aggregate' , True ), 'caching' : self . _config . getboolean ( 'caching' , True ), 'checking' : self . _config . getboolean ( 'checking' , False ), } # insure output dir exists opth . mkdir ( exist_ok = True , parents = True ) # process for ifile in sorted ( ipth . iterdir ()): blob = self . _read_file ( ifile ) tanium_transformer = TaniumTransformer () tanium_transformer . set_modes ( modes ) results = tanium_transformer . transform ( blob ) oname = ifile . stem + '.oscal' + '.json' ofile = opth / oname if not self . _overwrite and pathlib . Path ( ofile ) . exists (): logger . warning ( f 'output: { ofile } already exists' ) return TaskOutcome ( mode + 'failure' ) self . _write_file ( results , ofile ) self . _show_analysis ( tanium_transformer ) return TaskOutcome ( mode + 'success' ) def _read_file ( self , ifile : str ) -> str : \"\"\"Read raw input file.\"\"\" if not self . _simulate and self . _verbose : logger . info ( f 'input: { ifile } ' ) with open ( ifile , 'r' , encoding = const . FILE_ENCODING ) as fp : blob = fp . read () return blob def _write_file ( self , result : str , ofile : str ) -> None : \"\"\"Write oscal results file.\"\"\" if not self . _simulate : if self . _verbose : logger . info ( f 'output: { ofile } ' ) result . oscal_write ( pathlib . Path ( ofile )) def _show_analysis ( self , tanium_transformer : TaniumTransformer ) -> None : \"\"\"Show analysis.\"\"\" if not self . _simulate and self . _verbose : analysis = tanium_transformer . analysis for line in analysis : logger . info ( line ) name : str \u00a4 Methods \u00a4 __init__ ( self , config_object ) special \u00a4 Initialize trestle task tanium-result-to-oscal-ar. Parameters: Name Type Description Default config_object Optional[configparser.SectionProxy] Config section associated with the task. required Source code in trestle/tasks/tanium_result_to_oscal_ar.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task tanium-result-to-oscal-ar. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) execute ( self ) \u00a4 Provide an actual outcome. Source code in trestle/tasks/tanium_result_to_oscal_ar.py def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" self . _simulate = False return self . _transform () print_info ( self ) \u00a4 Print the help string. Source code in trestle/tasks/tanium_result_to_oscal_ar.py def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Transform Tanium files into Open Security Controls Assessment Language (OSCAL) results objects' + 'and serialize to a file.' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.tanium-result-to-oscal-ar]:' ) logger . info ( ' blocksize = (optional) the desired number Tanuim result input lines to process per CPU.' ) logger . info ( ' cpus-max = (optional) the desired maximum number of CPUs to employ, default is 1.' ) logger . info ( ' cpus-min = (optional) the desired minimum number of CPUs to employ.' ) logger . info ( ' aggregate = (optional) True indicates employ properties aggregation, default is True.' ) logger . info ( ' caching = (optional) True indicates employ object caching, default is True.' ) logger . info ( ' checking = (optional) True indicates perform strict checking of OSCAL properties, default is False.' ) logger . info ( ' input-dir = (required) the path of the input directory comprising Tanium results.' ) logger . info ( ' output-dir = (required) the path of the output directory comprising synthesized OSCAL .json files.' ) logger . info ( ' output-overwrite = (optional) true [default] or false; replace existing output when true.' ) logger . info ( ' quiet = (optional) true or false [default]; display file creations and rules analysis when false.' ) logger . info ( ' timestamp = (optional) timestamp for the Observations in ISO 8601 format, such as ' + '2021-01-04T00:05:23+04:00 for example; if not specified then value for \"Timestamp\" key in the Tanium ' + 'result is used if present, otherwise current time is used.' ) logger . info ( '' ) logger . info ( 'Operation: A transformation is performed on one or more Tanium input files to produce output in ' + 'OSCAL partial results format.' ) simulate ( self ) \u00a4 Provide a simulated outcome. Source code in trestle/tasks/tanium_result_to_oscal_ar.py def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" self . _simulate = True return self . _transform () handler: python","title":"tanium_result_to_oscal_ar"},{"location":"api_reference/trestle.tasks.tanium_result_to_oscal_ar/#trestle.tasks.tanium_result_to_oscal_ar","text":"OSCAL transformation tasks.","title":"tanium_result_to_oscal_ar"},{"location":"api_reference/trestle.tasks.tanium_result_to_oscal_ar/#trestle.tasks.tanium_result_to_oscal_ar.logger","text":"","title":"logger"},{"location":"api_reference/trestle.tasks.tanium_result_to_oscal_ar/#trestle.tasks.tanium_result_to_oscal_ar-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.tasks.tanium_result_to_oscal_ar/#trestle.tasks.tanium_result_to_oscal_ar.TaniumResultToOscalAR","text":"Task to convert Tanium result to OSCAL json. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/tanium_result_to_oscal_ar.py class TaniumResultToOscalAR ( TaskBase ): \"\"\" Task to convert Tanium result to OSCAL json. Attributes: name: Name of the task. \"\"\" name = 'tanium-result-to-oscal-ar' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task tanium-result-to-oscal-ar. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Transform Tanium files into Open Security Controls Assessment Language (OSCAL) results objects' + 'and serialize to a file.' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.tanium-result-to-oscal-ar]:' ) logger . info ( ' blocksize = (optional) the desired number Tanuim result input lines to process per CPU.' ) logger . info ( ' cpus-max = (optional) the desired maximum number of CPUs to employ, default is 1.' ) logger . info ( ' cpus-min = (optional) the desired minimum number of CPUs to employ.' ) logger . info ( ' aggregate = (optional) True indicates employ properties aggregation, default is True.' ) logger . info ( ' caching = (optional) True indicates employ object caching, default is True.' ) logger . info ( ' checking = (optional) True indicates perform strict checking of OSCAL properties, default is False.' ) logger . info ( ' input-dir = (required) the path of the input directory comprising Tanium results.' ) logger . info ( ' output-dir = (required) the path of the output directory comprising synthesized OSCAL .json files.' ) logger . info ( ' output-overwrite = (optional) true [default] or false; replace existing output when true.' ) logger . info ( ' quiet = (optional) true or false [default]; display file creations and rules analysis when false.' ) logger . info ( ' timestamp = (optional) timestamp for the Observations in ISO 8601 format, such as ' + '2021-01-04T00:05:23+04:00 for example; if not specified then value for \"Timestamp\" key in the Tanium ' + 'result is used if present, otherwise current time is used.' ) logger . info ( '' ) logger . info ( 'Operation: A transformation is performed on one or more Tanium input files to produce output in ' + 'OSCAL partial results format.' ) def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" self . _simulate = True return self . _transform () def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" self . _simulate = False return self . _transform () def _transform ( self ) -> TaskOutcome : \"\"\"Perform transformation.\"\"\" try : return self . _transform_work () except Exception : logger . info ( traceback . format_exc ()) mode = '' if self . _simulate : mode = 'simulated-' return TaskOutcome ( mode + 'failure' ) def _transform_work ( self ) -> TaskOutcome : \"\"\" Perform the transformation work. Transformation work steps: read input, process, write output, display analysis. \"\"\" mode = '' if self . _simulate : mode = 'simulated-' if not self . _config : logger . warning ( 'Config missing' ) return TaskOutcome ( mode + 'failure' ) # config required input & output dirs try : idir = self . _config [ 'input-dir' ] ipth = pathlib . Path ( idir ) odir = self . _config [ 'output-dir' ] opth = pathlib . Path ( odir ) except KeyError as e : logger . debug ( f 'key { e . args [ 0 ] } missing' ) return TaskOutcome ( mode + 'failure' ) # config optional overwrite & quiet self . _overwrite = self . _config . getboolean ( 'output-overwrite' , True ) quiet = self . _config . get ( 'quiet' , False ) self . _verbose = not self . _simulate and not quiet # config optional timestamp timestamp = self . _config . get ( 'timestamp' ) if timestamp is not None : try : TaniumTransformer . set_timestamp ( timestamp ) except Exception : logger . warning ( 'config invalid \"timestamp\"' ) return TaskOutcome ( mode + 'failure' ) # config optional performance modes = { 'blocksize' : self . _config . getint ( 'blocksize' , 10000 ), 'cpus_max' : self . _config . getint ( 'cpus-max' , 1 ), 'cpus_min' : self . _config . getint ( 'cpus-min' , 1 ), 'aggregate' : self . _config . getboolean ( 'aggregate' , True ), 'caching' : self . _config . getboolean ( 'caching' , True ), 'checking' : self . _config . getboolean ( 'checking' , False ), } # insure output dir exists opth . mkdir ( exist_ok = True , parents = True ) # process for ifile in sorted ( ipth . iterdir ()): blob = self . _read_file ( ifile ) tanium_transformer = TaniumTransformer () tanium_transformer . set_modes ( modes ) results = tanium_transformer . transform ( blob ) oname = ifile . stem + '.oscal' + '.json' ofile = opth / oname if not self . _overwrite and pathlib . Path ( ofile ) . exists (): logger . warning ( f 'output: { ofile } already exists' ) return TaskOutcome ( mode + 'failure' ) self . _write_file ( results , ofile ) self . _show_analysis ( tanium_transformer ) return TaskOutcome ( mode + 'success' ) def _read_file ( self , ifile : str ) -> str : \"\"\"Read raw input file.\"\"\" if not self . _simulate and self . _verbose : logger . info ( f 'input: { ifile } ' ) with open ( ifile , 'r' , encoding = const . FILE_ENCODING ) as fp : blob = fp . read () return blob def _write_file ( self , result : str , ofile : str ) -> None : \"\"\"Write oscal results file.\"\"\" if not self . _simulate : if self . _verbose : logger . info ( f 'output: { ofile } ' ) result . oscal_write ( pathlib . Path ( ofile )) def _show_analysis ( self , tanium_transformer : TaniumTransformer ) -> None : \"\"\"Show analysis.\"\"\" if not self . _simulate and self . _verbose : analysis = tanium_transformer . analysis for line in analysis : logger . info ( line )","title":"TaniumResultToOscalAR"},{"location":"api_reference/trestle.tasks.tanium_result_to_oscal_ar/#trestle.tasks.tanium_result_to_oscal_ar.TaniumResultToOscalAR.name","text":"","title":"name"},{"location":"api_reference/trestle.tasks.tanium_result_to_oscal_ar/#trestle.tasks.tanium_result_to_oscal_ar.TaniumResultToOscalAR-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.tasks.tanium_result_to_oscal_ar/#trestle.tasks.tanium_result_to_oscal_ar.TaniumResultToOscalAR.__init__","text":"Initialize trestle task tanium-result-to-oscal-ar. Parameters: Name Type Description Default config_object Optional[configparser.SectionProxy] Config section associated with the task. required Source code in trestle/tasks/tanium_result_to_oscal_ar.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task tanium-result-to-oscal-ar. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object )","title":"__init__()"},{"location":"api_reference/trestle.tasks.tanium_result_to_oscal_ar/#trestle.tasks.tanium_result_to_oscal_ar.TaniumResultToOscalAR.execute","text":"Provide an actual outcome. Source code in trestle/tasks/tanium_result_to_oscal_ar.py def execute ( self ) -> TaskOutcome : \"\"\"Provide an actual outcome.\"\"\" self . _simulate = False return self . _transform ()","title":"execute()"},{"location":"api_reference/trestle.tasks.tanium_result_to_oscal_ar/#trestle.tasks.tanium_result_to_oscal_ar.TaniumResultToOscalAR.print_info","text":"Print the help string. Source code in trestle/tasks/tanium_result_to_oscal_ar.py def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { self . name } task.' ) logger . info ( '' ) logger . info ( 'Purpose: Transform Tanium files into Open Security Controls Assessment Language (OSCAL) results objects' + 'and serialize to a file.' ) logger . info ( '' ) logger . info ( 'Configuration flags sit under [task.tanium-result-to-oscal-ar]:' ) logger . info ( ' blocksize = (optional) the desired number Tanuim result input lines to process per CPU.' ) logger . info ( ' cpus-max = (optional) the desired maximum number of CPUs to employ, default is 1.' ) logger . info ( ' cpus-min = (optional) the desired minimum number of CPUs to employ.' ) logger . info ( ' aggregate = (optional) True indicates employ properties aggregation, default is True.' ) logger . info ( ' caching = (optional) True indicates employ object caching, default is True.' ) logger . info ( ' checking = (optional) True indicates perform strict checking of OSCAL properties, default is False.' ) logger . info ( ' input-dir = (required) the path of the input directory comprising Tanium results.' ) logger . info ( ' output-dir = (required) the path of the output directory comprising synthesized OSCAL .json files.' ) logger . info ( ' output-overwrite = (optional) true [default] or false; replace existing output when true.' ) logger . info ( ' quiet = (optional) true or false [default]; display file creations and rules analysis when false.' ) logger . info ( ' timestamp = (optional) timestamp for the Observations in ISO 8601 format, such as ' + '2021-01-04T00:05:23+04:00 for example; if not specified then value for \"Timestamp\" key in the Tanium ' + 'result is used if present, otherwise current time is used.' ) logger . info ( '' ) logger . info ( 'Operation: A transformation is performed on one or more Tanium input files to produce output in ' + 'OSCAL partial results format.' )","title":"print_info()"},{"location":"api_reference/trestle.tasks.tanium_result_to_oscal_ar/#trestle.tasks.tanium_result_to_oscal_ar.TaniumResultToOscalAR.simulate","text":"Provide a simulated outcome. Source code in trestle/tasks/tanium_result_to_oscal_ar.py def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" self . _simulate = True return self . _transform () handler: python","title":"simulate()"},{"location":"api_reference/trestle.tasks.transform/","text":"trestle.tasks.transform \u00a4 OSCAL transformation tasks. handler: python","title":"transform"},{"location":"api_reference/trestle.tasks.transform/#trestle.tasks.transform","text":"OSCAL transformation tasks. handler: python","title":"transform"},{"location":"api_reference/trestle.tasks.xlsx_helper/","text":"trestle.tasks.xlsx_helper \u00a4 XLSX utilities. logger \u00a4 Classes \u00a4 Column \u00a4 Spread sheet columns. Source code in trestle/tasks/xlsx_helper.py class Column (): \"\"\"Spread sheet columns.\"\"\" control_id = 'ControlId' control_text = 'ControlText' goal_name_id = 'goal_name_id' goal_version = 'goal_version' rule_name_id = 'rule_name_id' rule_version = 'rule_version' nist_mappings = 'NIST Mappings' resource_title = 'ResourceTitle' parameter_opt_parm = 'Parameter [optional parameter]' values_alternatives = 'Values default , [alternatives]' filter_column = None tokens_nist_mappings = nist_mappings . split () tokens_parameter_opt_parm = parameter_opt_parm . split () rename_parameter_opt_parm = 'ParameterName' tokens_values_alternatives = values_alternatives . split () rename_values_alternatives = 'ParameterValue' help_list = [] text1 = ' ' text2 = f 'column \" { control_id } \" contains control ID.' help_list . append ( text1 + text2 ) text2 = f 'column \" { control_text } \" contains control text.' help_list . append ( text1 + text2 ) text2 = f 'columns \" { nist_mappings } \" contain NIST control mappings.' help_list . append ( text1 + text2 ) text2 = f 'column \" { resource_title } \" contains component name.' help_list . append ( text1 + text2 ) text2 = f 'column \" { goal_name_id } \" contains goal name.' help_list . append ( text1 + text2 ) text2 = f 'column \" { goal_version } \" contains goal version.' help_list . append ( text1 + text2 ) text2 = f 'column \" { rule_name_id } \" contains rule name.' help_list . append ( text1 + text2 ) text2 = f 'column \" { rule_version } \" contains rule version.' help_list . append ( text1 + text2 ) text2 = f 'column \" { parameter_opt_parm } \" contains parameter name + description, separated by newline.' help_list . append ( text1 + text2 ) text2 = f 'column \" { values_alternatives } \" contains parameter values.' help_list . append ( text1 + text2 ) control_id \u00a4 control_text \u00a4 filter_column \u00a4 goal_name_id \u00a4 goal_version \u00a4 help_list \u00a4 nist_mappings \u00a4 parameter_opt_parm \u00a4 rename_parameter_opt_parm \u00a4 rename_values_alternatives \u00a4 resource_title \u00a4 rule_name_id \u00a4 rule_version \u00a4 text1 \u00a4 text2 \u00a4 tokens_nist_mappings \u00a4 tokens_parameter_opt_parm \u00a4 tokens_values_alternatives \u00a4 values_alternatives \u00a4 XlsxHelper \u00a4 Xlsx Helper common functions and assistance navigating spread sheet. Source code in trestle/tasks/xlsx_helper.py class XlsxHelper : \"\"\"Xlsx Helper common functions and assistance navigating spread sheet.\"\"\" by_goal = 'by-goal' by_rule = 'by-rule' by_control = 'by-control' by_check = 'by-check' profile_types = [ by_goal , by_rule , by_control , by_check ] def __init__ ( self ) -> None : \"\"\"Initialize.\"\"\" self . _column = Column () def print_info ( self , name , oscal_name ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { name } task.' ) logger . info ( '' ) logger . info ( f 'Purpose: From spread sheet and catalog produce OSCAL { oscal_name } file.' ) logger . info ( '' ) logger . info ( f 'Configuration flags sit under [task. { name } ]:' ) if oscal_name == 'component_definition' : text1 = ' catalog-file = ' text2 = '(required) the path of the OSCAL catalog file.' logger . info ( text1 + text2 ) text1 = ' spread-sheet-file = ' text2 = '(required) the path of the spread sheet file.' logger . info ( text1 + text2 ) text1 = ' work-sheet-name = ' text2 = '(required) the name of the work sheet in the spread sheet file.' logger . info ( text1 + text2 ) for line in self . _column . help_list : logger . info ( line ) text1 = ' output-dir = ' text2 = '(required) the path of the output directory for synthesized OSCAL .json files.' logger . info ( text1 + text2 ) text1 = ' output-overwrite = ' text2 = '(optional) true [default] or false; replace existing output when true.' logger . info ( text1 + text2 ) text1 = ' filter-column = ' text2 = '(optional) column heading of yes/no values; process only \"yes\" rows.' logger . info ( text1 + text2 ) text1 = ' profile-type = ' text2 = f '(optional) one of { self . profile_types } ' logger . info ( text1 + text2 ) @property def profile_type ( self ) -> str : \"\"\"Profile type.\"\"\" return self . _profile_type def configure ( self , task : TaskBase ) -> bool : \"\"\"Configure.\"\"\" if not task . _config : logger . warning ( 'config missing' ) return False # config verbosity quiet = task . _config . get ( 'quiet' , False ) task . _verbose = not quiet # required for component-definition if not self . configure_cd ( task ): return False # required for profile if not self . configure_profile ( task ): return False # optional self . _column . filter_column = task . _config . get ( 'filter-column' , None ) # config spread sheet spread_sheet = task . _config . get ( 'spread-sheet-file' ) if spread_sheet is None : logger . warning ( 'config missing \"spread-sheet\"' ) return False if not pathlib . Path ( spread_sheet ) . exists (): logger . warning ( '\"spread-sheet\" not found' ) return False sheet_name = task . _config . get ( 'work-sheet-name' ) if sheet_name is None : logger . warning ( 'config missing \"work-sheet-name\"' ) return False # announce spreadsheet if task . _verbose : logger . info ( f 'input: { spread_sheet } ' ) # get profile type if task . name == 'xlsx-to-oscal-profile' : self . _profile_type = task . _config . get ( 'profile-type' , self . profile_types [ 0 ]) if self . _profile_type not in self . profile_types : logger . warning ( f 'invalid \"profile-type\" { self . _profile_type } ' ) return False else : self . _profile_type = None # load spread sheet self . load ( spread_sheet , sheet_name ) return True def configure_cd ( self , task : TaskBase ) -> bool : \"\"\"Configure cd.\"\"\" if task . name == 'xlsx-to-oscal-cd' : catalog_file = task . _config . get ( 'catalog-file' ) if catalog_file is None : logger . warning ( 'config missing \"catalog-file\"' ) return False try : catalog = Catalog . oscal_read ( pathlib . Path ( catalog_file )) logger . debug ( f 'catalog: { catalog_file } ' ) except Exception as e : # pragma: no cover raise TrestleError ( f 'Error loading catalog { catalog_file } : { e } ' ) task . catalog_interface = CatalogInterface ( catalog ) return True def configure_profile ( self , task : TaskBase ) -> bool : \"\"\"Configure profile.\"\"\" if task . name == 'xlsx-to-oscal-profile' : profile_title = task . _config . get ( 'profile-title' ) if profile_title is None : logger . warning ( 'config missing \"profile-title\"' ) return False spread_sheet_url = task . _config . get ( 'spread-sheet-url' ) if spread_sheet_url is None : logger . warning ( 'config missing \"spread-sheet-url\"' ) return False return True def load ( self , spread_sheet : str , sheet_name : str ) -> None : \"\"\"Load.\"\"\" self . _spread_sheet = spread_sheet self . _sheet_name = sheet_name self . _wb = load_workbook ( self . _spread_sheet ) self . _work_sheet = self . _wb [ self . _sheet_name ] self . _map_name_to_letters = {} # accumulators self . rows_missing_control_id = [] self . rows_missing_goal_name_id = [] self . rows_invalid_goal_name_id = [] self . rows_missing_rule_name_id = [] self . rows_invalid_rule_name_id = [] self . rows_invalid_parameter_name = [] self . rows_missing_controls = [] self . rows_missing_parameters = [] self . rows_missing_parameters_values = [] self . rows_filtered = [] # map columns self . _map_columns () def row_generator ( self ) -> Iterator [ int ]: \"\"\"Generate rows until control_id is None.\"\"\" row = 1 rows_skipped_consecutive = 0 # assume no more data when 100 consecutve rows no control id rows_skipped_consecutive_limit = 100 while True : row = row + 1 control_id = self . _get_control_id ( row ) goal_id = self . get_goal_name_id ( row ) if control_id is None and goal_id is None : rows_skipped_consecutive += 1 if rows_skipped_consecutive < rows_skipped_consecutive_limit : continue logger . debug ( f 'break: { row } { rows_skipped_consecutive } ' ) break if control_id is None : self . _add_row ( row , self . rows_missing_control_id ) continue if goal_id is None : self . _add_row ( row , self . rows_missing_goal_name_id ) continue if self . _is_filtered ( row ): continue yield row rows_skipped_consecutive = 0 def _is_filtered ( self , row ) -> bool : \"\"\"Return True if row is to be skipped.\"\"\" if self . _column . filter_column is None : return False col = self . _get_column_letter ( self . _column . filter_column ) value = self . _work_sheet [ col + str ( row )] . value if value is None : return False if value . lower () != 'yes' : return False self . _add_row ( row , self . rows_filtered ) return True def get_goal_name_id ( self , row : int , strict : bool = True ) -> str : \"\"\"Get goal_name_id from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . goal_name_id ) value = self . _work_sheet [ col + str ( row )] . value if value is None : self . _add_row ( row , self . rows_missing_goal_name_id ) else : value = str ( value ) . strip () if strict : svalue = str ( value ) . strip () value = '' . join ( str ( svalue ) . split ()) if value != svalue : self . _add_row ( row , self . rows_invalid_goal_name_id ) return value def get_check_name_id ( self , row : int , strict : bool = False ) -> str : \"\"\"Get check_name_id from work_sheet.\"\"\" return self . get_goal_name_id ( row , strict ) def get_rule_name_id ( self , row : int , strict : bool = False ) -> str : \"\"\"Get rule_name_id from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . rule_name_id ) value = self . _work_sheet [ col + str ( row )] . value if value is None : self . _add_row ( row , self . rows_missing_rule_name_id ) else : value = str ( value ) . strip () if strict : svalue = str ( value ) . strip () value = '' . join ( str ( svalue ) . split ()) if value != svalue : self . _add_row ( row , self . rows_invalid_rule_name_id ) return value def get_parameter_usage ( self , row : int ) -> str : \"\"\"Get parameter_usage from work_sheet.\"\"\" return self . get_goal_remarks ( row ) def get_parameter_value_default ( self , row : int ) -> str : \"\"\"Get parameter_value_default from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . rename_values_alternatives ) value = self . _work_sheet [ col + str ( row )] . value if value is not None : value = str ( value ) . split ( ',' )[ 0 ] . strip () return value def get_parameter_values ( self , row : int ) -> str : \"\"\"Get parameter_values from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . rename_values_alternatives ) value = self . _work_sheet [ col + str ( row )] . value if value is None and self . get_parameter_name ( row ) is not None : self . _add_row ( row , self . rows_missing_parameters_values ) # massage into comma separated list of values else : value = str ( value ) . strip () . replace ( ' ' , '' ) value = value . replace ( ',[]' , '' ) value = value . replace ( '[' , '' ) value = value . replace ( ']' , '' ) value = value . split ( ',' ) return value def _get_goal_text ( self , row : int ) -> str : \"\"\"Get goal_text from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . control_text ) goal_text = self . _work_sheet [ col + str ( row )] . value # normalize & tokenize value = goal_text . replace ( ' \\t ' , ' ' ) return value def _get_goal_text_tokens ( self , row : int ) -> List [ str ]: \"\"\"Get goal_text tokens from work_sheet.\"\"\" goal_text = self . _get_goal_text ( row ) tokens = goal_text . split () return tokens def get_goal_remarks ( self , row : int ) -> str : \"\"\"Get goal_remarks from work_sheet.\"\"\" tokens = self . _get_goal_text_tokens ( row ) # replace \"Check whether\" with \"Ensure\", if present if tokens : if tokens [ 0 ] == 'Check' : if len ( tokens ) > 1 : if tokens [ 1 ] == 'whether' : tokens . pop ( 0 ) tokens [ 0 ] = 'Ensure' value = ' ' . join ( tokens ) return value def get_controls ( self , row : int ) -> Dict [ str , List [ str ]]: \"\"\"Produce dict of controls mapped to statements. Example: {'au-2': ['(a)', '(d)'], 'au-12': [], 'si-4': ['(a)', '(b)', '(c)']} \"\"\" value = {} for col in self . _get_column_letter ( self . _column . nist_mappings ): control = self . _work_sheet [ col + str ( row )] . value if control is None : continue # remove blanks control = '' . join ( control . split ()) if len ( control ) < 1 or control . lower () == 'none' : continue # remove rhs of : inclusive if ':' in control : control = control . split ( ':' )[ 0 ] # remove alphabet parts of control & accumulate in statements control , statements = self . _normalize_control ( control ) # skip bogus control made up if dashes only if len ( control . replace ( '-' , '' )) == 0 : continue if control not in value . keys (): value [ control ] = statements if len ( value . keys ()) == 0 : self . _add_row ( row , self . rows_missing_controls ) logger . debug ( f 'row: { row } controls { value } ' ) return value def get_component_name ( self , row : int ) -> str : \"\"\"Get component_name from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . resource_title ) value = self . _work_sheet [ col + str ( row )] . value if value is None : raise RuntimeError ( f 'row { row } col { col } missing component name' ) return value . strip () def get_parameter_name ( self , row : int ) -> Tuple [ str , str ]: \"\"\"Get parameter_name from work_sheet.\"\"\" return self . get_parameter_name_and_description ( row )[ 0 ] def get_parameter_name_and_description ( self , row : int ) -> Tuple [ str , str ]: \"\"\"Get parameter_name and description from work_sheet.\"\"\" name = None description = None col = self . _get_column_letter ( self . _column . rename_parameter_opt_parm ) combined_values = self . _work_sheet [ col + str ( row )] . value if combined_values is not None : if ' \\n ' in combined_values : parameter_parts = combined_values . split ( ' \\n ' ) elif ' ' in combined_values : parameter_parts = combined_values . split ( ' ' , 1 ) else : parameter_parts = combined_values if len ( parameter_parts ) == 2 : name = parameter_parts [ 1 ] . strip () description = parameter_parts [ 0 ] . strip () sname = str ( name ) . strip () name = sname . replace ( ' ' , '_' ) if name != sname : self . _add_row ( row , self . rows_invalid_parameter_name ) else : logger . info ( f 'row { row } col { col } invalid value' ) if name is None and self . get_parameter_value_default ( row ) is not None : self . _add_row ( row , self . rows_missing_parameters ) value = name , description return value def _get_control_id ( self , row : int ) -> int : \"\"\"Get control_id from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . control_id ) value = self . _work_sheet [ col + str ( row )] . value return value def _get_column_letter ( self , name : str ) -> str : \"\"\"Get column letter.\"\"\" value = self . map_name_to_letters [ name ] if len ( value ) == 1 : value = value [ 0 ] return value def _map_columns ( self ) -> None : \"\"\"Map columns.\"\"\" self . map_name_to_letters = {} columns = self . _work_sheet . max_column for column in range ( 1 , columns + 1 ): cell_value = self . _cell_value ( 1 , column ) if cell_value is None : continue cell_tokens = cell_value . split () normalized_cell_value = ' ' . join ( cell_tokens ) # find columns of interest if self . _column . control_id in cell_tokens : self . _add_column ( self . _column . control_id , column , 1 ) elif self . _column . control_text in cell_tokens : self . _add_column ( self . _column . control_text , column , 1 ) elif self . _column . goal_name_id in cell_tokens : self . _add_column ( self . _column . goal_name_id , column , 1 ) elif self . _column . goal_version in cell_tokens : self . _add_column ( self . _column . goal_version , column , 1 ) elif self . _column . rule_name_id in cell_tokens : self . _add_column ( self . _column . rule_name_id , column , 1 ) elif self . _column . rule_version in cell_tokens : self . _add_column ( self . _column . rule_version , column , 1 ) # parameters and alternatives (exact tokens match) elif cell_tokens == self . _column . tokens_parameter_opt_parm : self . _add_column ( self . _column . rename_parameter_opt_parm , column , 1 ) elif cell_tokens == self . _column . tokens_values_alternatives : self . _add_column ( self . _column . rename_values_alternatives , column , 1 ) # filter column (exact string match) elif self . _column . filter_column == normalized_cell_value : self . _add_column ( self . _column . filter_column , column , 1 ) # nist mappings and resource title (multiple columns match) elif is_ordered_sublist ( self . _column . tokens_nist_mappings , cell_tokens ): self . _add_column ( self . _column . nist_mappings , column , 0 ) elif self . _column . resource_title in cell_tokens : self . _add_column ( self . _column . resource_title , column , 0 ) # insure expected columns found for name in [ self . _column . control_id , self . _column . control_text , self . _column . rule_name_id , self . _column . rule_version , self . _column . goal_name_id , self . _column . goal_version , self . _column . nist_mappings , self . _column . resource_title , self . _column . rename_parameter_opt_parm , self . _column . rename_values_alternatives ]: if name not in self . map_name_to_letters . keys (): raise RuntimeError ( f 'missing column { name } ' ) def _add_column ( self , name : str , column : int , limit : int ) -> None : \"\"\"Add column.\"\"\" if name not in self . map_name_to_letters : self . map_name_to_letters [ name ] = [] if limit > 0 and len ( self . map_name_to_letters [ name ]) == limit : raise RuntimeError ( f 'duplicate column { name } { get_column_letter ( column ) } ' ) self . map_name_to_letters [ name ] . append ( get_column_letter ( column )) def _cell_value ( self , row : int , col : int ) -> Any : \"\"\"Get value for cell, adjusting for merged cells.\"\"\" cell = self . _work_sheet . cell ( row , col ) retval = cell . value if isinstance ( cell , MergedCell ): # cell is merged for mc_range in self . _work_sheet . merged_cells . ranges : coord = get_column_letter ( col ) + str ( row ) if coord in mc_range : retval = mc_range . start_cell . value return retval def _normalize_control ( self , control : str ) -> Tuple [ str , List [ str ]]: \"\"\"Remove parenthesized characters from controls.\"\"\" statements = [] for i in string . ascii_lowercase : needle = '(' + i + ')' if needle in control : statements . append ( needle ) control = control . replace ( needle , '' ) control = control . lower () return control , statements def _add_row ( self , row : int , account : List [ int ]) -> None : \"\"\"Add row to accounting list of rows.\"\"\" if row not in account : account . append ( row ) def report_issues ( self ) -> None : \"\"\"Report issues.\"\"\" if self . rows_missing_control_id : logger . info ( f 'rows missing control_id: { self . rows_missing_control_id } ' ) if self . rows_invalid_goal_name_id : logger . info ( f 'rows invalid goal_name_id: { self . rows_invalid_goal_name_id } ' ) if self . rows_missing_rule_name_id : logger . info ( f 'rows missing rule_name_id: { self . rows_missing_rule_name_id } ' ) if self . rows_invalid_rule_name_id : logger . info ( f 'rows invalid rule_name_id: { self . rows_invalid_rule_name_id } ' ) if self . rows_invalid_parameter_name : logger . info ( f 'rows invalid parameter_name: { self . rows_invalid_parameter_name } ' ) if self . rows_missing_controls : logger . info ( f 'rows missing controls: { self . rows_missing_controls } ' ) if self . rows_missing_parameters : logger . info ( f 'rows missing parameters: { self . rows_missing_parameters } ' ) if self . rows_missing_parameters_values : logger . info ( f 'rows missing parameters values: { self . rows_missing_parameters_values } ' ) if self . rows_filtered : logger . info ( f 'rows filtered: { self . rows_filtered } ' ) Attributes \u00a4 by_check \u00a4 by_control \u00a4 by_goal \u00a4 by_rule \u00a4 profile_type : str property readonly \u00a4 Profile type. profile_types \u00a4 Methods \u00a4 __init__ ( self ) special \u00a4 Initialize. Source code in trestle/tasks/xlsx_helper.py def __init__ ( self ) -> None : \"\"\"Initialize.\"\"\" self . _column = Column () configure ( self , task ) \u00a4 Configure. Source code in trestle/tasks/xlsx_helper.py def configure ( self , task : TaskBase ) -> bool : \"\"\"Configure.\"\"\" if not task . _config : logger . warning ( 'config missing' ) return False # config verbosity quiet = task . _config . get ( 'quiet' , False ) task . _verbose = not quiet # required for component-definition if not self . configure_cd ( task ): return False # required for profile if not self . configure_profile ( task ): return False # optional self . _column . filter_column = task . _config . get ( 'filter-column' , None ) # config spread sheet spread_sheet = task . _config . get ( 'spread-sheet-file' ) if spread_sheet is None : logger . warning ( 'config missing \"spread-sheet\"' ) return False if not pathlib . Path ( spread_sheet ) . exists (): logger . warning ( '\"spread-sheet\" not found' ) return False sheet_name = task . _config . get ( 'work-sheet-name' ) if sheet_name is None : logger . warning ( 'config missing \"work-sheet-name\"' ) return False # announce spreadsheet if task . _verbose : logger . info ( f 'input: { spread_sheet } ' ) # get profile type if task . name == 'xlsx-to-oscal-profile' : self . _profile_type = task . _config . get ( 'profile-type' , self . profile_types [ 0 ]) if self . _profile_type not in self . profile_types : logger . warning ( f 'invalid \"profile-type\" { self . _profile_type } ' ) return False else : self . _profile_type = None # load spread sheet self . load ( spread_sheet , sheet_name ) return True configure_cd ( self , task ) \u00a4 Configure cd. Source code in trestle/tasks/xlsx_helper.py def configure_cd ( self , task : TaskBase ) -> bool : \"\"\"Configure cd.\"\"\" if task . name == 'xlsx-to-oscal-cd' : catalog_file = task . _config . get ( 'catalog-file' ) if catalog_file is None : logger . warning ( 'config missing \"catalog-file\"' ) return False try : catalog = Catalog . oscal_read ( pathlib . Path ( catalog_file )) logger . debug ( f 'catalog: { catalog_file } ' ) except Exception as e : # pragma: no cover raise TrestleError ( f 'Error loading catalog { catalog_file } : { e } ' ) task . catalog_interface = CatalogInterface ( catalog ) return True configure_profile ( self , task ) \u00a4 Configure profile. Source code in trestle/tasks/xlsx_helper.py def configure_profile ( self , task : TaskBase ) -> bool : \"\"\"Configure profile.\"\"\" if task . name == 'xlsx-to-oscal-profile' : profile_title = task . _config . get ( 'profile-title' ) if profile_title is None : logger . warning ( 'config missing \"profile-title\"' ) return False spread_sheet_url = task . _config . get ( 'spread-sheet-url' ) if spread_sheet_url is None : logger . warning ( 'config missing \"spread-sheet-url\"' ) return False return True get_check_name_id ( self , row , strict = False ) \u00a4 Get check_name_id from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_check_name_id ( self , row : int , strict : bool = False ) -> str : \"\"\"Get check_name_id from work_sheet.\"\"\" return self . get_goal_name_id ( row , strict ) get_component_name ( self , row ) \u00a4 Get component_name from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_component_name ( self , row : int ) -> str : \"\"\"Get component_name from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . resource_title ) value = self . _work_sheet [ col + str ( row )] . value if value is None : raise RuntimeError ( f 'row { row } col { col } missing component name' ) return value . strip () get_controls ( self , row ) \u00a4 Produce dict of controls mapped to statements. Example: {'au-2': ['(a)', '(d)'], 'au-12': [], 'si-4': ['(a)', '(b)', '(c)']} Source code in trestle/tasks/xlsx_helper.py def get_controls ( self , row : int ) -> Dict [ str , List [ str ]]: \"\"\"Produce dict of controls mapped to statements. Example: {'au-2': ['(a)', '(d)'], 'au-12': [], 'si-4': ['(a)', '(b)', '(c)']} \"\"\" value = {} for col in self . _get_column_letter ( self . _column . nist_mappings ): control = self . _work_sheet [ col + str ( row )] . value if control is None : continue # remove blanks control = '' . join ( control . split ()) if len ( control ) < 1 or control . lower () == 'none' : continue # remove rhs of : inclusive if ':' in control : control = control . split ( ':' )[ 0 ] # remove alphabet parts of control & accumulate in statements control , statements = self . _normalize_control ( control ) # skip bogus control made up if dashes only if len ( control . replace ( '-' , '' )) == 0 : continue if control not in value . keys (): value [ control ] = statements if len ( value . keys ()) == 0 : self . _add_row ( row , self . rows_missing_controls ) logger . debug ( f 'row: { row } controls { value } ' ) return value get_goal_name_id ( self , row , strict = True ) \u00a4 Get goal_name_id from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_goal_name_id ( self , row : int , strict : bool = True ) -> str : \"\"\"Get goal_name_id from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . goal_name_id ) value = self . _work_sheet [ col + str ( row )] . value if value is None : self . _add_row ( row , self . rows_missing_goal_name_id ) else : value = str ( value ) . strip () if strict : svalue = str ( value ) . strip () value = '' . join ( str ( svalue ) . split ()) if value != svalue : self . _add_row ( row , self . rows_invalid_goal_name_id ) return value get_goal_remarks ( self , row ) \u00a4 Get goal_remarks from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_goal_remarks ( self , row : int ) -> str : \"\"\"Get goal_remarks from work_sheet.\"\"\" tokens = self . _get_goal_text_tokens ( row ) # replace \"Check whether\" with \"Ensure\", if present if tokens : if tokens [ 0 ] == 'Check' : if len ( tokens ) > 1 : if tokens [ 1 ] == 'whether' : tokens . pop ( 0 ) tokens [ 0 ] = 'Ensure' value = ' ' . join ( tokens ) return value get_parameter_name ( self , row ) \u00a4 Get parameter_name from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_parameter_name ( self , row : int ) -> Tuple [ str , str ]: \"\"\"Get parameter_name from work_sheet.\"\"\" return self . get_parameter_name_and_description ( row )[ 0 ] get_parameter_name_and_description ( self , row ) \u00a4 Get parameter_name and description from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_parameter_name_and_description ( self , row : int ) -> Tuple [ str , str ]: \"\"\"Get parameter_name and description from work_sheet.\"\"\" name = None description = None col = self . _get_column_letter ( self . _column . rename_parameter_opt_parm ) combined_values = self . _work_sheet [ col + str ( row )] . value if combined_values is not None : if ' \\n ' in combined_values : parameter_parts = combined_values . split ( ' \\n ' ) elif ' ' in combined_values : parameter_parts = combined_values . split ( ' ' , 1 ) else : parameter_parts = combined_values if len ( parameter_parts ) == 2 : name = parameter_parts [ 1 ] . strip () description = parameter_parts [ 0 ] . strip () sname = str ( name ) . strip () name = sname . replace ( ' ' , '_' ) if name != sname : self . _add_row ( row , self . rows_invalid_parameter_name ) else : logger . info ( f 'row { row } col { col } invalid value' ) if name is None and self . get_parameter_value_default ( row ) is not None : self . _add_row ( row , self . rows_missing_parameters ) value = name , description return value get_parameter_usage ( self , row ) \u00a4 Get parameter_usage from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_parameter_usage ( self , row : int ) -> str : \"\"\"Get parameter_usage from work_sheet.\"\"\" return self . get_goal_remarks ( row ) get_parameter_value_default ( self , row ) \u00a4 Get parameter_value_default from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_parameter_value_default ( self , row : int ) -> str : \"\"\"Get parameter_value_default from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . rename_values_alternatives ) value = self . _work_sheet [ col + str ( row )] . value if value is not None : value = str ( value ) . split ( ',' )[ 0 ] . strip () return value get_parameter_values ( self , row ) \u00a4 Get parameter_values from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_parameter_values ( self , row : int ) -> str : \"\"\"Get parameter_values from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . rename_values_alternatives ) value = self . _work_sheet [ col + str ( row )] . value if value is None and self . get_parameter_name ( row ) is not None : self . _add_row ( row , self . rows_missing_parameters_values ) # massage into comma separated list of values else : value = str ( value ) . strip () . replace ( ' ' , '' ) value = value . replace ( ',[]' , '' ) value = value . replace ( '[' , '' ) value = value . replace ( ']' , '' ) value = value . split ( ',' ) return value get_rule_name_id ( self , row , strict = False ) \u00a4 Get rule_name_id from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_rule_name_id ( self , row : int , strict : bool = False ) -> str : \"\"\"Get rule_name_id from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . rule_name_id ) value = self . _work_sheet [ col + str ( row )] . value if value is None : self . _add_row ( row , self . rows_missing_rule_name_id ) else : value = str ( value ) . strip () if strict : svalue = str ( value ) . strip () value = '' . join ( str ( svalue ) . split ()) if value != svalue : self . _add_row ( row , self . rows_invalid_rule_name_id ) return value load ( self , spread_sheet , sheet_name ) \u00a4 Load. Source code in trestle/tasks/xlsx_helper.py def load ( self , spread_sheet : str , sheet_name : str ) -> None : \"\"\"Load.\"\"\" self . _spread_sheet = spread_sheet self . _sheet_name = sheet_name self . _wb = load_workbook ( self . _spread_sheet ) self . _work_sheet = self . _wb [ self . _sheet_name ] self . _map_name_to_letters = {} # accumulators self . rows_missing_control_id = [] self . rows_missing_goal_name_id = [] self . rows_invalid_goal_name_id = [] self . rows_missing_rule_name_id = [] self . rows_invalid_rule_name_id = [] self . rows_invalid_parameter_name = [] self . rows_missing_controls = [] self . rows_missing_parameters = [] self . rows_missing_parameters_values = [] self . rows_filtered = [] # map columns self . _map_columns () print_info ( self , name , oscal_name ) \u00a4 Print the help string. Source code in trestle/tasks/xlsx_helper.py def print_info ( self , name , oscal_name ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { name } task.' ) logger . info ( '' ) logger . info ( f 'Purpose: From spread sheet and catalog produce OSCAL { oscal_name } file.' ) logger . info ( '' ) logger . info ( f 'Configuration flags sit under [task. { name } ]:' ) if oscal_name == 'component_definition' : text1 = ' catalog-file = ' text2 = '(required) the path of the OSCAL catalog file.' logger . info ( text1 + text2 ) text1 = ' spread-sheet-file = ' text2 = '(required) the path of the spread sheet file.' logger . info ( text1 + text2 ) text1 = ' work-sheet-name = ' text2 = '(required) the name of the work sheet in the spread sheet file.' logger . info ( text1 + text2 ) for line in self . _column . help_list : logger . info ( line ) text1 = ' output-dir = ' text2 = '(required) the path of the output directory for synthesized OSCAL .json files.' logger . info ( text1 + text2 ) text1 = ' output-overwrite = ' text2 = '(optional) true [default] or false; replace existing output when true.' logger . info ( text1 + text2 ) text1 = ' filter-column = ' text2 = '(optional) column heading of yes/no values; process only \"yes\" rows.' logger . info ( text1 + text2 ) text1 = ' profile-type = ' text2 = f '(optional) one of { self . profile_types } ' logger . info ( text1 + text2 ) report_issues ( self ) \u00a4 Report issues. Source code in trestle/tasks/xlsx_helper.py def report_issues ( self ) -> None : \"\"\"Report issues.\"\"\" if self . rows_missing_control_id : logger . info ( f 'rows missing control_id: { self . rows_missing_control_id } ' ) if self . rows_invalid_goal_name_id : logger . info ( f 'rows invalid goal_name_id: { self . rows_invalid_goal_name_id } ' ) if self . rows_missing_rule_name_id : logger . info ( f 'rows missing rule_name_id: { self . rows_missing_rule_name_id } ' ) if self . rows_invalid_rule_name_id : logger . info ( f 'rows invalid rule_name_id: { self . rows_invalid_rule_name_id } ' ) if self . rows_invalid_parameter_name : logger . info ( f 'rows invalid parameter_name: { self . rows_invalid_parameter_name } ' ) if self . rows_missing_controls : logger . info ( f 'rows missing controls: { self . rows_missing_controls } ' ) if self . rows_missing_parameters : logger . info ( f 'rows missing parameters: { self . rows_missing_parameters } ' ) if self . rows_missing_parameters_values : logger . info ( f 'rows missing parameters values: { self . rows_missing_parameters_values } ' ) if self . rows_filtered : logger . info ( f 'rows filtered: { self . rows_filtered } ' ) row_generator ( self ) \u00a4 Generate rows until control_id is None. Source code in trestle/tasks/xlsx_helper.py def row_generator ( self ) -> Iterator [ int ]: \"\"\"Generate rows until control_id is None.\"\"\" row = 1 rows_skipped_consecutive = 0 # assume no more data when 100 consecutve rows no control id rows_skipped_consecutive_limit = 100 while True : row = row + 1 control_id = self . _get_control_id ( row ) goal_id = self . get_goal_name_id ( row ) if control_id is None and goal_id is None : rows_skipped_consecutive += 1 if rows_skipped_consecutive < rows_skipped_consecutive_limit : continue logger . debug ( f 'break: { row } { rows_skipped_consecutive } ' ) break if control_id is None : self . _add_row ( row , self . rows_missing_control_id ) continue if goal_id is None : self . _add_row ( row , self . rows_missing_goal_name_id ) continue if self . _is_filtered ( row ): continue yield row rows_skipped_consecutive = 0 Functions \u00a4 get_trestle_version () \u00a4 Get trestle version wrapper. Source code in trestle/tasks/xlsx_helper.py def get_trestle_version () -> str : \"\"\"Get trestle version wrapper.\"\"\" return __version__ handler: python","title":"xlsx_helper"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper","text":"XLSX utilities.","title":"xlsx_helper"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.logger","text":"","title":"logger"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column","text":"Spread sheet columns. Source code in trestle/tasks/xlsx_helper.py class Column (): \"\"\"Spread sheet columns.\"\"\" control_id = 'ControlId' control_text = 'ControlText' goal_name_id = 'goal_name_id' goal_version = 'goal_version' rule_name_id = 'rule_name_id' rule_version = 'rule_version' nist_mappings = 'NIST Mappings' resource_title = 'ResourceTitle' parameter_opt_parm = 'Parameter [optional parameter]' values_alternatives = 'Values default , [alternatives]' filter_column = None tokens_nist_mappings = nist_mappings . split () tokens_parameter_opt_parm = parameter_opt_parm . split () rename_parameter_opt_parm = 'ParameterName' tokens_values_alternatives = values_alternatives . split () rename_values_alternatives = 'ParameterValue' help_list = [] text1 = ' ' text2 = f 'column \" { control_id } \" contains control ID.' help_list . append ( text1 + text2 ) text2 = f 'column \" { control_text } \" contains control text.' help_list . append ( text1 + text2 ) text2 = f 'columns \" { nist_mappings } \" contain NIST control mappings.' help_list . append ( text1 + text2 ) text2 = f 'column \" { resource_title } \" contains component name.' help_list . append ( text1 + text2 ) text2 = f 'column \" { goal_name_id } \" contains goal name.' help_list . append ( text1 + text2 ) text2 = f 'column \" { goal_version } \" contains goal version.' help_list . append ( text1 + text2 ) text2 = f 'column \" { rule_name_id } \" contains rule name.' help_list . append ( text1 + text2 ) text2 = f 'column \" { rule_version } \" contains rule version.' help_list . append ( text1 + text2 ) text2 = f 'column \" { parameter_opt_parm } \" contains parameter name + description, separated by newline.' help_list . append ( text1 + text2 ) text2 = f 'column \" { values_alternatives } \" contains parameter values.' help_list . append ( text1 + text2 )","title":"Column"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.control_id","text":"","title":"control_id"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.control_text","text":"","title":"control_text"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.filter_column","text":"","title":"filter_column"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.goal_name_id","text":"","title":"goal_name_id"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.goal_version","text":"","title":"goal_version"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.help_list","text":"","title":"help_list"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.nist_mappings","text":"","title":"nist_mappings"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.parameter_opt_parm","text":"","title":"parameter_opt_parm"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.rename_parameter_opt_parm","text":"","title":"rename_parameter_opt_parm"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.rename_values_alternatives","text":"","title":"rename_values_alternatives"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.resource_title","text":"","title":"resource_title"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.rule_name_id","text":"","title":"rule_name_id"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.rule_version","text":"","title":"rule_version"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.text1","text":"","title":"text1"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.text2","text":"","title":"text2"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.tokens_nist_mappings","text":"","title":"tokens_nist_mappings"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.tokens_parameter_opt_parm","text":"","title":"tokens_parameter_opt_parm"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.tokens_values_alternatives","text":"","title":"tokens_values_alternatives"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.Column.values_alternatives","text":"","title":"values_alternatives"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper","text":"Xlsx Helper common functions and assistance navigating spread sheet. Source code in trestle/tasks/xlsx_helper.py class XlsxHelper : \"\"\"Xlsx Helper common functions and assistance navigating spread sheet.\"\"\" by_goal = 'by-goal' by_rule = 'by-rule' by_control = 'by-control' by_check = 'by-check' profile_types = [ by_goal , by_rule , by_control , by_check ] def __init__ ( self ) -> None : \"\"\"Initialize.\"\"\" self . _column = Column () def print_info ( self , name , oscal_name ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { name } task.' ) logger . info ( '' ) logger . info ( f 'Purpose: From spread sheet and catalog produce OSCAL { oscal_name } file.' ) logger . info ( '' ) logger . info ( f 'Configuration flags sit under [task. { name } ]:' ) if oscal_name == 'component_definition' : text1 = ' catalog-file = ' text2 = '(required) the path of the OSCAL catalog file.' logger . info ( text1 + text2 ) text1 = ' spread-sheet-file = ' text2 = '(required) the path of the spread sheet file.' logger . info ( text1 + text2 ) text1 = ' work-sheet-name = ' text2 = '(required) the name of the work sheet in the spread sheet file.' logger . info ( text1 + text2 ) for line in self . _column . help_list : logger . info ( line ) text1 = ' output-dir = ' text2 = '(required) the path of the output directory for synthesized OSCAL .json files.' logger . info ( text1 + text2 ) text1 = ' output-overwrite = ' text2 = '(optional) true [default] or false; replace existing output when true.' logger . info ( text1 + text2 ) text1 = ' filter-column = ' text2 = '(optional) column heading of yes/no values; process only \"yes\" rows.' logger . info ( text1 + text2 ) text1 = ' profile-type = ' text2 = f '(optional) one of { self . profile_types } ' logger . info ( text1 + text2 ) @property def profile_type ( self ) -> str : \"\"\"Profile type.\"\"\" return self . _profile_type def configure ( self , task : TaskBase ) -> bool : \"\"\"Configure.\"\"\" if not task . _config : logger . warning ( 'config missing' ) return False # config verbosity quiet = task . _config . get ( 'quiet' , False ) task . _verbose = not quiet # required for component-definition if not self . configure_cd ( task ): return False # required for profile if not self . configure_profile ( task ): return False # optional self . _column . filter_column = task . _config . get ( 'filter-column' , None ) # config spread sheet spread_sheet = task . _config . get ( 'spread-sheet-file' ) if spread_sheet is None : logger . warning ( 'config missing \"spread-sheet\"' ) return False if not pathlib . Path ( spread_sheet ) . exists (): logger . warning ( '\"spread-sheet\" not found' ) return False sheet_name = task . _config . get ( 'work-sheet-name' ) if sheet_name is None : logger . warning ( 'config missing \"work-sheet-name\"' ) return False # announce spreadsheet if task . _verbose : logger . info ( f 'input: { spread_sheet } ' ) # get profile type if task . name == 'xlsx-to-oscal-profile' : self . _profile_type = task . _config . get ( 'profile-type' , self . profile_types [ 0 ]) if self . _profile_type not in self . profile_types : logger . warning ( f 'invalid \"profile-type\" { self . _profile_type } ' ) return False else : self . _profile_type = None # load spread sheet self . load ( spread_sheet , sheet_name ) return True def configure_cd ( self , task : TaskBase ) -> bool : \"\"\"Configure cd.\"\"\" if task . name == 'xlsx-to-oscal-cd' : catalog_file = task . _config . get ( 'catalog-file' ) if catalog_file is None : logger . warning ( 'config missing \"catalog-file\"' ) return False try : catalog = Catalog . oscal_read ( pathlib . Path ( catalog_file )) logger . debug ( f 'catalog: { catalog_file } ' ) except Exception as e : # pragma: no cover raise TrestleError ( f 'Error loading catalog { catalog_file } : { e } ' ) task . catalog_interface = CatalogInterface ( catalog ) return True def configure_profile ( self , task : TaskBase ) -> bool : \"\"\"Configure profile.\"\"\" if task . name == 'xlsx-to-oscal-profile' : profile_title = task . _config . get ( 'profile-title' ) if profile_title is None : logger . warning ( 'config missing \"profile-title\"' ) return False spread_sheet_url = task . _config . get ( 'spread-sheet-url' ) if spread_sheet_url is None : logger . warning ( 'config missing \"spread-sheet-url\"' ) return False return True def load ( self , spread_sheet : str , sheet_name : str ) -> None : \"\"\"Load.\"\"\" self . _spread_sheet = spread_sheet self . _sheet_name = sheet_name self . _wb = load_workbook ( self . _spread_sheet ) self . _work_sheet = self . _wb [ self . _sheet_name ] self . _map_name_to_letters = {} # accumulators self . rows_missing_control_id = [] self . rows_missing_goal_name_id = [] self . rows_invalid_goal_name_id = [] self . rows_missing_rule_name_id = [] self . rows_invalid_rule_name_id = [] self . rows_invalid_parameter_name = [] self . rows_missing_controls = [] self . rows_missing_parameters = [] self . rows_missing_parameters_values = [] self . rows_filtered = [] # map columns self . _map_columns () def row_generator ( self ) -> Iterator [ int ]: \"\"\"Generate rows until control_id is None.\"\"\" row = 1 rows_skipped_consecutive = 0 # assume no more data when 100 consecutve rows no control id rows_skipped_consecutive_limit = 100 while True : row = row + 1 control_id = self . _get_control_id ( row ) goal_id = self . get_goal_name_id ( row ) if control_id is None and goal_id is None : rows_skipped_consecutive += 1 if rows_skipped_consecutive < rows_skipped_consecutive_limit : continue logger . debug ( f 'break: { row } { rows_skipped_consecutive } ' ) break if control_id is None : self . _add_row ( row , self . rows_missing_control_id ) continue if goal_id is None : self . _add_row ( row , self . rows_missing_goal_name_id ) continue if self . _is_filtered ( row ): continue yield row rows_skipped_consecutive = 0 def _is_filtered ( self , row ) -> bool : \"\"\"Return True if row is to be skipped.\"\"\" if self . _column . filter_column is None : return False col = self . _get_column_letter ( self . _column . filter_column ) value = self . _work_sheet [ col + str ( row )] . value if value is None : return False if value . lower () != 'yes' : return False self . _add_row ( row , self . rows_filtered ) return True def get_goal_name_id ( self , row : int , strict : bool = True ) -> str : \"\"\"Get goal_name_id from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . goal_name_id ) value = self . _work_sheet [ col + str ( row )] . value if value is None : self . _add_row ( row , self . rows_missing_goal_name_id ) else : value = str ( value ) . strip () if strict : svalue = str ( value ) . strip () value = '' . join ( str ( svalue ) . split ()) if value != svalue : self . _add_row ( row , self . rows_invalid_goal_name_id ) return value def get_check_name_id ( self , row : int , strict : bool = False ) -> str : \"\"\"Get check_name_id from work_sheet.\"\"\" return self . get_goal_name_id ( row , strict ) def get_rule_name_id ( self , row : int , strict : bool = False ) -> str : \"\"\"Get rule_name_id from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . rule_name_id ) value = self . _work_sheet [ col + str ( row )] . value if value is None : self . _add_row ( row , self . rows_missing_rule_name_id ) else : value = str ( value ) . strip () if strict : svalue = str ( value ) . strip () value = '' . join ( str ( svalue ) . split ()) if value != svalue : self . _add_row ( row , self . rows_invalid_rule_name_id ) return value def get_parameter_usage ( self , row : int ) -> str : \"\"\"Get parameter_usage from work_sheet.\"\"\" return self . get_goal_remarks ( row ) def get_parameter_value_default ( self , row : int ) -> str : \"\"\"Get parameter_value_default from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . rename_values_alternatives ) value = self . _work_sheet [ col + str ( row )] . value if value is not None : value = str ( value ) . split ( ',' )[ 0 ] . strip () return value def get_parameter_values ( self , row : int ) -> str : \"\"\"Get parameter_values from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . rename_values_alternatives ) value = self . _work_sheet [ col + str ( row )] . value if value is None and self . get_parameter_name ( row ) is not None : self . _add_row ( row , self . rows_missing_parameters_values ) # massage into comma separated list of values else : value = str ( value ) . strip () . replace ( ' ' , '' ) value = value . replace ( ',[]' , '' ) value = value . replace ( '[' , '' ) value = value . replace ( ']' , '' ) value = value . split ( ',' ) return value def _get_goal_text ( self , row : int ) -> str : \"\"\"Get goal_text from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . control_text ) goal_text = self . _work_sheet [ col + str ( row )] . value # normalize & tokenize value = goal_text . replace ( ' \\t ' , ' ' ) return value def _get_goal_text_tokens ( self , row : int ) -> List [ str ]: \"\"\"Get goal_text tokens from work_sheet.\"\"\" goal_text = self . _get_goal_text ( row ) tokens = goal_text . split () return tokens def get_goal_remarks ( self , row : int ) -> str : \"\"\"Get goal_remarks from work_sheet.\"\"\" tokens = self . _get_goal_text_tokens ( row ) # replace \"Check whether\" with \"Ensure\", if present if tokens : if tokens [ 0 ] == 'Check' : if len ( tokens ) > 1 : if tokens [ 1 ] == 'whether' : tokens . pop ( 0 ) tokens [ 0 ] = 'Ensure' value = ' ' . join ( tokens ) return value def get_controls ( self , row : int ) -> Dict [ str , List [ str ]]: \"\"\"Produce dict of controls mapped to statements. Example: {'au-2': ['(a)', '(d)'], 'au-12': [], 'si-4': ['(a)', '(b)', '(c)']} \"\"\" value = {} for col in self . _get_column_letter ( self . _column . nist_mappings ): control = self . _work_sheet [ col + str ( row )] . value if control is None : continue # remove blanks control = '' . join ( control . split ()) if len ( control ) < 1 or control . lower () == 'none' : continue # remove rhs of : inclusive if ':' in control : control = control . split ( ':' )[ 0 ] # remove alphabet parts of control & accumulate in statements control , statements = self . _normalize_control ( control ) # skip bogus control made up if dashes only if len ( control . replace ( '-' , '' )) == 0 : continue if control not in value . keys (): value [ control ] = statements if len ( value . keys ()) == 0 : self . _add_row ( row , self . rows_missing_controls ) logger . debug ( f 'row: { row } controls { value } ' ) return value def get_component_name ( self , row : int ) -> str : \"\"\"Get component_name from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . resource_title ) value = self . _work_sheet [ col + str ( row )] . value if value is None : raise RuntimeError ( f 'row { row } col { col } missing component name' ) return value . strip () def get_parameter_name ( self , row : int ) -> Tuple [ str , str ]: \"\"\"Get parameter_name from work_sheet.\"\"\" return self . get_parameter_name_and_description ( row )[ 0 ] def get_parameter_name_and_description ( self , row : int ) -> Tuple [ str , str ]: \"\"\"Get parameter_name and description from work_sheet.\"\"\" name = None description = None col = self . _get_column_letter ( self . _column . rename_parameter_opt_parm ) combined_values = self . _work_sheet [ col + str ( row )] . value if combined_values is not None : if ' \\n ' in combined_values : parameter_parts = combined_values . split ( ' \\n ' ) elif ' ' in combined_values : parameter_parts = combined_values . split ( ' ' , 1 ) else : parameter_parts = combined_values if len ( parameter_parts ) == 2 : name = parameter_parts [ 1 ] . strip () description = parameter_parts [ 0 ] . strip () sname = str ( name ) . strip () name = sname . replace ( ' ' , '_' ) if name != sname : self . _add_row ( row , self . rows_invalid_parameter_name ) else : logger . info ( f 'row { row } col { col } invalid value' ) if name is None and self . get_parameter_value_default ( row ) is not None : self . _add_row ( row , self . rows_missing_parameters ) value = name , description return value def _get_control_id ( self , row : int ) -> int : \"\"\"Get control_id from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . control_id ) value = self . _work_sheet [ col + str ( row )] . value return value def _get_column_letter ( self , name : str ) -> str : \"\"\"Get column letter.\"\"\" value = self . map_name_to_letters [ name ] if len ( value ) == 1 : value = value [ 0 ] return value def _map_columns ( self ) -> None : \"\"\"Map columns.\"\"\" self . map_name_to_letters = {} columns = self . _work_sheet . max_column for column in range ( 1 , columns + 1 ): cell_value = self . _cell_value ( 1 , column ) if cell_value is None : continue cell_tokens = cell_value . split () normalized_cell_value = ' ' . join ( cell_tokens ) # find columns of interest if self . _column . control_id in cell_tokens : self . _add_column ( self . _column . control_id , column , 1 ) elif self . _column . control_text in cell_tokens : self . _add_column ( self . _column . control_text , column , 1 ) elif self . _column . goal_name_id in cell_tokens : self . _add_column ( self . _column . goal_name_id , column , 1 ) elif self . _column . goal_version in cell_tokens : self . _add_column ( self . _column . goal_version , column , 1 ) elif self . _column . rule_name_id in cell_tokens : self . _add_column ( self . _column . rule_name_id , column , 1 ) elif self . _column . rule_version in cell_tokens : self . _add_column ( self . _column . rule_version , column , 1 ) # parameters and alternatives (exact tokens match) elif cell_tokens == self . _column . tokens_parameter_opt_parm : self . _add_column ( self . _column . rename_parameter_opt_parm , column , 1 ) elif cell_tokens == self . _column . tokens_values_alternatives : self . _add_column ( self . _column . rename_values_alternatives , column , 1 ) # filter column (exact string match) elif self . _column . filter_column == normalized_cell_value : self . _add_column ( self . _column . filter_column , column , 1 ) # nist mappings and resource title (multiple columns match) elif is_ordered_sublist ( self . _column . tokens_nist_mappings , cell_tokens ): self . _add_column ( self . _column . nist_mappings , column , 0 ) elif self . _column . resource_title in cell_tokens : self . _add_column ( self . _column . resource_title , column , 0 ) # insure expected columns found for name in [ self . _column . control_id , self . _column . control_text , self . _column . rule_name_id , self . _column . rule_version , self . _column . goal_name_id , self . _column . goal_version , self . _column . nist_mappings , self . _column . resource_title , self . _column . rename_parameter_opt_parm , self . _column . rename_values_alternatives ]: if name not in self . map_name_to_letters . keys (): raise RuntimeError ( f 'missing column { name } ' ) def _add_column ( self , name : str , column : int , limit : int ) -> None : \"\"\"Add column.\"\"\" if name not in self . map_name_to_letters : self . map_name_to_letters [ name ] = [] if limit > 0 and len ( self . map_name_to_letters [ name ]) == limit : raise RuntimeError ( f 'duplicate column { name } { get_column_letter ( column ) } ' ) self . map_name_to_letters [ name ] . append ( get_column_letter ( column )) def _cell_value ( self , row : int , col : int ) -> Any : \"\"\"Get value for cell, adjusting for merged cells.\"\"\" cell = self . _work_sheet . cell ( row , col ) retval = cell . value if isinstance ( cell , MergedCell ): # cell is merged for mc_range in self . _work_sheet . merged_cells . ranges : coord = get_column_letter ( col ) + str ( row ) if coord in mc_range : retval = mc_range . start_cell . value return retval def _normalize_control ( self , control : str ) -> Tuple [ str , List [ str ]]: \"\"\"Remove parenthesized characters from controls.\"\"\" statements = [] for i in string . ascii_lowercase : needle = '(' + i + ')' if needle in control : statements . append ( needle ) control = control . replace ( needle , '' ) control = control . lower () return control , statements def _add_row ( self , row : int , account : List [ int ]) -> None : \"\"\"Add row to accounting list of rows.\"\"\" if row not in account : account . append ( row ) def report_issues ( self ) -> None : \"\"\"Report issues.\"\"\" if self . rows_missing_control_id : logger . info ( f 'rows missing control_id: { self . rows_missing_control_id } ' ) if self . rows_invalid_goal_name_id : logger . info ( f 'rows invalid goal_name_id: { self . rows_invalid_goal_name_id } ' ) if self . rows_missing_rule_name_id : logger . info ( f 'rows missing rule_name_id: { self . rows_missing_rule_name_id } ' ) if self . rows_invalid_rule_name_id : logger . info ( f 'rows invalid rule_name_id: { self . rows_invalid_rule_name_id } ' ) if self . rows_invalid_parameter_name : logger . info ( f 'rows invalid parameter_name: { self . rows_invalid_parameter_name } ' ) if self . rows_missing_controls : logger . info ( f 'rows missing controls: { self . rows_missing_controls } ' ) if self . rows_missing_parameters : logger . info ( f 'rows missing parameters: { self . rows_missing_parameters } ' ) if self . rows_missing_parameters_values : logger . info ( f 'rows missing parameters values: { self . rows_missing_parameters_values } ' ) if self . rows_filtered : logger . info ( f 'rows filtered: { self . rows_filtered } ' )","title":"XlsxHelper"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.by_check","text":"","title":"by_check"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.by_control","text":"","title":"by_control"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.by_goal","text":"","title":"by_goal"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.by_rule","text":"","title":"by_rule"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.profile_type","text":"Profile type.","title":"profile_type"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.profile_types","text":"","title":"profile_types"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.__init__","text":"Initialize. Source code in trestle/tasks/xlsx_helper.py def __init__ ( self ) -> None : \"\"\"Initialize.\"\"\" self . _column = Column ()","title":"__init__()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.configure","text":"Configure. Source code in trestle/tasks/xlsx_helper.py def configure ( self , task : TaskBase ) -> bool : \"\"\"Configure.\"\"\" if not task . _config : logger . warning ( 'config missing' ) return False # config verbosity quiet = task . _config . get ( 'quiet' , False ) task . _verbose = not quiet # required for component-definition if not self . configure_cd ( task ): return False # required for profile if not self . configure_profile ( task ): return False # optional self . _column . filter_column = task . _config . get ( 'filter-column' , None ) # config spread sheet spread_sheet = task . _config . get ( 'spread-sheet-file' ) if spread_sheet is None : logger . warning ( 'config missing \"spread-sheet\"' ) return False if not pathlib . Path ( spread_sheet ) . exists (): logger . warning ( '\"spread-sheet\" not found' ) return False sheet_name = task . _config . get ( 'work-sheet-name' ) if sheet_name is None : logger . warning ( 'config missing \"work-sheet-name\"' ) return False # announce spreadsheet if task . _verbose : logger . info ( f 'input: { spread_sheet } ' ) # get profile type if task . name == 'xlsx-to-oscal-profile' : self . _profile_type = task . _config . get ( 'profile-type' , self . profile_types [ 0 ]) if self . _profile_type not in self . profile_types : logger . warning ( f 'invalid \"profile-type\" { self . _profile_type } ' ) return False else : self . _profile_type = None # load spread sheet self . load ( spread_sheet , sheet_name ) return True","title":"configure()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.configure_cd","text":"Configure cd. Source code in trestle/tasks/xlsx_helper.py def configure_cd ( self , task : TaskBase ) -> bool : \"\"\"Configure cd.\"\"\" if task . name == 'xlsx-to-oscal-cd' : catalog_file = task . _config . get ( 'catalog-file' ) if catalog_file is None : logger . warning ( 'config missing \"catalog-file\"' ) return False try : catalog = Catalog . oscal_read ( pathlib . Path ( catalog_file )) logger . debug ( f 'catalog: { catalog_file } ' ) except Exception as e : # pragma: no cover raise TrestleError ( f 'Error loading catalog { catalog_file } : { e } ' ) task . catalog_interface = CatalogInterface ( catalog ) return True","title":"configure_cd()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.configure_profile","text":"Configure profile. Source code in trestle/tasks/xlsx_helper.py def configure_profile ( self , task : TaskBase ) -> bool : \"\"\"Configure profile.\"\"\" if task . name == 'xlsx-to-oscal-profile' : profile_title = task . _config . get ( 'profile-title' ) if profile_title is None : logger . warning ( 'config missing \"profile-title\"' ) return False spread_sheet_url = task . _config . get ( 'spread-sheet-url' ) if spread_sheet_url is None : logger . warning ( 'config missing \"spread-sheet-url\"' ) return False return True","title":"configure_profile()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.get_check_name_id","text":"Get check_name_id from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_check_name_id ( self , row : int , strict : bool = False ) -> str : \"\"\"Get check_name_id from work_sheet.\"\"\" return self . get_goal_name_id ( row , strict )","title":"get_check_name_id()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.get_component_name","text":"Get component_name from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_component_name ( self , row : int ) -> str : \"\"\"Get component_name from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . resource_title ) value = self . _work_sheet [ col + str ( row )] . value if value is None : raise RuntimeError ( f 'row { row } col { col } missing component name' ) return value . strip ()","title":"get_component_name()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.get_controls","text":"Produce dict of controls mapped to statements. Example: {'au-2': ['(a)', '(d)'], 'au-12': [], 'si-4': ['(a)', '(b)', '(c)']} Source code in trestle/tasks/xlsx_helper.py def get_controls ( self , row : int ) -> Dict [ str , List [ str ]]: \"\"\"Produce dict of controls mapped to statements. Example: {'au-2': ['(a)', '(d)'], 'au-12': [], 'si-4': ['(a)', '(b)', '(c)']} \"\"\" value = {} for col in self . _get_column_letter ( self . _column . nist_mappings ): control = self . _work_sheet [ col + str ( row )] . value if control is None : continue # remove blanks control = '' . join ( control . split ()) if len ( control ) < 1 or control . lower () == 'none' : continue # remove rhs of : inclusive if ':' in control : control = control . split ( ':' )[ 0 ] # remove alphabet parts of control & accumulate in statements control , statements = self . _normalize_control ( control ) # skip bogus control made up if dashes only if len ( control . replace ( '-' , '' )) == 0 : continue if control not in value . keys (): value [ control ] = statements if len ( value . keys ()) == 0 : self . _add_row ( row , self . rows_missing_controls ) logger . debug ( f 'row: { row } controls { value } ' ) return value","title":"get_controls()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.get_goal_name_id","text":"Get goal_name_id from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_goal_name_id ( self , row : int , strict : bool = True ) -> str : \"\"\"Get goal_name_id from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . goal_name_id ) value = self . _work_sheet [ col + str ( row )] . value if value is None : self . _add_row ( row , self . rows_missing_goal_name_id ) else : value = str ( value ) . strip () if strict : svalue = str ( value ) . strip () value = '' . join ( str ( svalue ) . split ()) if value != svalue : self . _add_row ( row , self . rows_invalid_goal_name_id ) return value","title":"get_goal_name_id()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.get_goal_remarks","text":"Get goal_remarks from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_goal_remarks ( self , row : int ) -> str : \"\"\"Get goal_remarks from work_sheet.\"\"\" tokens = self . _get_goal_text_tokens ( row ) # replace \"Check whether\" with \"Ensure\", if present if tokens : if tokens [ 0 ] == 'Check' : if len ( tokens ) > 1 : if tokens [ 1 ] == 'whether' : tokens . pop ( 0 ) tokens [ 0 ] = 'Ensure' value = ' ' . join ( tokens ) return value","title":"get_goal_remarks()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.get_parameter_name","text":"Get parameter_name from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_parameter_name ( self , row : int ) -> Tuple [ str , str ]: \"\"\"Get parameter_name from work_sheet.\"\"\" return self . get_parameter_name_and_description ( row )[ 0 ]","title":"get_parameter_name()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.get_parameter_name_and_description","text":"Get parameter_name and description from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_parameter_name_and_description ( self , row : int ) -> Tuple [ str , str ]: \"\"\"Get parameter_name and description from work_sheet.\"\"\" name = None description = None col = self . _get_column_letter ( self . _column . rename_parameter_opt_parm ) combined_values = self . _work_sheet [ col + str ( row )] . value if combined_values is not None : if ' \\n ' in combined_values : parameter_parts = combined_values . split ( ' \\n ' ) elif ' ' in combined_values : parameter_parts = combined_values . split ( ' ' , 1 ) else : parameter_parts = combined_values if len ( parameter_parts ) == 2 : name = parameter_parts [ 1 ] . strip () description = parameter_parts [ 0 ] . strip () sname = str ( name ) . strip () name = sname . replace ( ' ' , '_' ) if name != sname : self . _add_row ( row , self . rows_invalid_parameter_name ) else : logger . info ( f 'row { row } col { col } invalid value' ) if name is None and self . get_parameter_value_default ( row ) is not None : self . _add_row ( row , self . rows_missing_parameters ) value = name , description return value","title":"get_parameter_name_and_description()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.get_parameter_usage","text":"Get parameter_usage from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_parameter_usage ( self , row : int ) -> str : \"\"\"Get parameter_usage from work_sheet.\"\"\" return self . get_goal_remarks ( row )","title":"get_parameter_usage()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.get_parameter_value_default","text":"Get parameter_value_default from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_parameter_value_default ( self , row : int ) -> str : \"\"\"Get parameter_value_default from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . rename_values_alternatives ) value = self . _work_sheet [ col + str ( row )] . value if value is not None : value = str ( value ) . split ( ',' )[ 0 ] . strip () return value","title":"get_parameter_value_default()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.get_parameter_values","text":"Get parameter_values from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_parameter_values ( self , row : int ) -> str : \"\"\"Get parameter_values from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . rename_values_alternatives ) value = self . _work_sheet [ col + str ( row )] . value if value is None and self . get_parameter_name ( row ) is not None : self . _add_row ( row , self . rows_missing_parameters_values ) # massage into comma separated list of values else : value = str ( value ) . strip () . replace ( ' ' , '' ) value = value . replace ( ',[]' , '' ) value = value . replace ( '[' , '' ) value = value . replace ( ']' , '' ) value = value . split ( ',' ) return value","title":"get_parameter_values()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.get_rule_name_id","text":"Get rule_name_id from work_sheet. Source code in trestle/tasks/xlsx_helper.py def get_rule_name_id ( self , row : int , strict : bool = False ) -> str : \"\"\"Get rule_name_id from work_sheet.\"\"\" col = self . _get_column_letter ( self . _column . rule_name_id ) value = self . _work_sheet [ col + str ( row )] . value if value is None : self . _add_row ( row , self . rows_missing_rule_name_id ) else : value = str ( value ) . strip () if strict : svalue = str ( value ) . strip () value = '' . join ( str ( svalue ) . split ()) if value != svalue : self . _add_row ( row , self . rows_invalid_rule_name_id ) return value","title":"get_rule_name_id()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.load","text":"Load. Source code in trestle/tasks/xlsx_helper.py def load ( self , spread_sheet : str , sheet_name : str ) -> None : \"\"\"Load.\"\"\" self . _spread_sheet = spread_sheet self . _sheet_name = sheet_name self . _wb = load_workbook ( self . _spread_sheet ) self . _work_sheet = self . _wb [ self . _sheet_name ] self . _map_name_to_letters = {} # accumulators self . rows_missing_control_id = [] self . rows_missing_goal_name_id = [] self . rows_invalid_goal_name_id = [] self . rows_missing_rule_name_id = [] self . rows_invalid_rule_name_id = [] self . rows_invalid_parameter_name = [] self . rows_missing_controls = [] self . rows_missing_parameters = [] self . rows_missing_parameters_values = [] self . rows_filtered = [] # map columns self . _map_columns ()","title":"load()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.print_info","text":"Print the help string. Source code in trestle/tasks/xlsx_helper.py def print_info ( self , name , oscal_name ) -> None : \"\"\"Print the help string.\"\"\" logger . info ( f 'Help information for { name } task.' ) logger . info ( '' ) logger . info ( f 'Purpose: From spread sheet and catalog produce OSCAL { oscal_name } file.' ) logger . info ( '' ) logger . info ( f 'Configuration flags sit under [task. { name } ]:' ) if oscal_name == 'component_definition' : text1 = ' catalog-file = ' text2 = '(required) the path of the OSCAL catalog file.' logger . info ( text1 + text2 ) text1 = ' spread-sheet-file = ' text2 = '(required) the path of the spread sheet file.' logger . info ( text1 + text2 ) text1 = ' work-sheet-name = ' text2 = '(required) the name of the work sheet in the spread sheet file.' logger . info ( text1 + text2 ) for line in self . _column . help_list : logger . info ( line ) text1 = ' output-dir = ' text2 = '(required) the path of the output directory for synthesized OSCAL .json files.' logger . info ( text1 + text2 ) text1 = ' output-overwrite = ' text2 = '(optional) true [default] or false; replace existing output when true.' logger . info ( text1 + text2 ) text1 = ' filter-column = ' text2 = '(optional) column heading of yes/no values; process only \"yes\" rows.' logger . info ( text1 + text2 ) text1 = ' profile-type = ' text2 = f '(optional) one of { self . profile_types } ' logger . info ( text1 + text2 )","title":"print_info()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.report_issues","text":"Report issues. Source code in trestle/tasks/xlsx_helper.py def report_issues ( self ) -> None : \"\"\"Report issues.\"\"\" if self . rows_missing_control_id : logger . info ( f 'rows missing control_id: { self . rows_missing_control_id } ' ) if self . rows_invalid_goal_name_id : logger . info ( f 'rows invalid goal_name_id: { self . rows_invalid_goal_name_id } ' ) if self . rows_missing_rule_name_id : logger . info ( f 'rows missing rule_name_id: { self . rows_missing_rule_name_id } ' ) if self . rows_invalid_rule_name_id : logger . info ( f 'rows invalid rule_name_id: { self . rows_invalid_rule_name_id } ' ) if self . rows_invalid_parameter_name : logger . info ( f 'rows invalid parameter_name: { self . rows_invalid_parameter_name } ' ) if self . rows_missing_controls : logger . info ( f 'rows missing controls: { self . rows_missing_controls } ' ) if self . rows_missing_parameters : logger . info ( f 'rows missing parameters: { self . rows_missing_parameters } ' ) if self . rows_missing_parameters_values : logger . info ( f 'rows missing parameters values: { self . rows_missing_parameters_values } ' ) if self . rows_filtered : logger . info ( f 'rows filtered: { self . rows_filtered } ' )","title":"report_issues()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.XlsxHelper.row_generator","text":"Generate rows until control_id is None. Source code in trestle/tasks/xlsx_helper.py def row_generator ( self ) -> Iterator [ int ]: \"\"\"Generate rows until control_id is None.\"\"\" row = 1 rows_skipped_consecutive = 0 # assume no more data when 100 consecutve rows no control id rows_skipped_consecutive_limit = 100 while True : row = row + 1 control_id = self . _get_control_id ( row ) goal_id = self . get_goal_name_id ( row ) if control_id is None and goal_id is None : rows_skipped_consecutive += 1 if rows_skipped_consecutive < rows_skipped_consecutive_limit : continue logger . debug ( f 'break: { row } { rows_skipped_consecutive } ' ) break if control_id is None : self . _add_row ( row , self . rows_missing_control_id ) continue if goal_id is None : self . _add_row ( row , self . rows_missing_goal_name_id ) continue if self . _is_filtered ( row ): continue yield row rows_skipped_consecutive = 0","title":"row_generator()"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper-functions","text":"","title":"Functions"},{"location":"api_reference/trestle.tasks.xlsx_helper/#trestle.tasks.xlsx_helper.get_trestle_version","text":"Get trestle version wrapper. Source code in trestle/tasks/xlsx_helper.py def get_trestle_version () -> str : \"\"\"Get trestle version wrapper.\"\"\" return __version__ handler: python","title":"get_trestle_version()"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_cd/","text":"trestle.tasks.xlsx_to_oscal_cd \u00a4 OSCAL transformation tasks. key_sep \u00a4 logger \u00a4 sep \u00a4 Classes \u00a4 XlsxToOscalComponentDefinition ( TaskBase ) \u00a4 Task to create OSCAL ComponentDefinition json. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/xlsx_to_oscal_cd.py class XlsxToOscalComponentDefinition ( TaskBase ): \"\"\" Task to create OSCAL ComponentDefinition json. Attributes: name: Name of the task. \"\"\" name = 'xlsx-to-oscal-cd' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task xlsx-to-oscal-cd. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) self . xlsx_helper = XlsxHelper () self . _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat () def set_timestamp ( self , timestamp : str ) -> None : \"\"\"Set the timestamp.\"\"\" self . _timestamp = timestamp def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" self . xlsx_helper . print_info ( self . name , 'component_definition' ) def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) def execute ( self ) -> TaskOutcome : \"\"\"Provide an executed outcome.\"\"\" try : return self . _execute () except Exception : logger . info ( traceback . format_exc ()) return TaskOutcome ( 'failure' ) def _execute ( self ) -> TaskOutcome : \"\"\"Execute path core.\"\"\" if not self . xlsx_helper . configure ( self ): return TaskOutcome ( 'failure' ) # config output odir = self . _config . get ( 'output-dir' ) opth = pathlib . Path ( odir ) self . _overwrite = self . _config . getboolean ( 'output-overwrite' , True ) # insure output dir exists opth . mkdir ( exist_ok = True , parents = True ) # calculate output file name & check writability oname = 'component-definition.json' ofile = opth / oname if not self . _overwrite and pathlib . Path ( ofile ) . exists (): logger . warning ( f 'output: { ofile } already exists' ) return TaskOutcome ( 'failure' ) # initialize self . defined_components = {} # roles, responsible_roles, parties, responsible parties party_uuid_01 = str ( uuid . uuid4 ()) party_uuid_02 = str ( uuid . uuid4 ()) party_uuid_03 = str ( uuid . uuid4 ()) roles = self . _build_roles () responsible_roles = self . _build_responsible_roles ( party_uuid_01 , party_uuid_02 , party_uuid_03 ) parties = self . _build_parties ( party_uuid_01 , party_uuid_02 , party_uuid_03 ) responsible_parties = self . _build_responsible_parties ( party_uuid_01 , party_uuid_02 , party_uuid_03 ) # process each row of spread sheet self . _process_rows ( responsible_roles ) # create OSCAL ComponentDefinition metadata = Metadata ( title = 'Component definition for ' + self . _get_catalog_title () + ' profiles' , last_modified = self . _timestamp , oscal_version = OSCAL_VERSION , version = get_trestle_version (), roles = roles , parties = parties , responsible_parties = responsible_parties ) component_definition = ComponentDefinition ( uuid = str ( uuid . uuid4 ()), metadata = metadata , components = list ( self . defined_components . values ()), ) # write OSCAL ComponentDefinition to file if self . _verbose : logger . info ( f 'output: { ofile } ' ) component_definition . oscal_write ( pathlib . Path ( ofile )) # issues self . _report_issues () return TaskOutcome ( 'success' ) def _process_rows ( self , responsible_roles : List [ ResponsibleRole ]) -> None : \"\"\"Process spread sheet rows.\"\"\" ci_map = {} for row in self . xlsx_helper . row_generator (): # quit when first row with no goal_id encountered goal_name_id = self . xlsx_helper . get_goal_name_id ( row ) controls = self . xlsx_helper . get_controls ( row ) if len ( controls . keys ()) == 0 : continue # component component_name = self . xlsx_helper . get_component_name ( row ) component_type = 'Service' defined_component = self . _get_defined_component ( component_name , component_type ) # parameter parameter_name , parameter_description = self . xlsx_helper . get_parameter_name_and_description ( row ) # control implementations source = self . _get_catalog_url () description = component_name + ' implemented controls for ' + self . _get_catalog_title ( ) + '. It includes assessment asset configuration for CICD.' key = source + key_sep + description control_implementation = ci_map . get ( key ) if not control_implementation : ci_map [ key ] = ControlImplementation ( uuid = str ( uuid . uuid4 ()), source = source , description = description , implemented_requirements = [], ) control_implementation = ci_map [ key ] if defined_component . control_implementations is None : defined_component . control_implementations = [] defined_component . control_implementations . append ( control_implementation ) # implemented requirements self . _add_implemented_requirements ( row , control_implementation , controls , component_name , parameter_name , responsible_roles , goal_name_id ) # keep alternative parameter values at control implementation level parameter_values = self . xlsx_helper . get_parameter_values ( row ) self . _add_set_parameter_values ( parameter_name , parameter_values , control_implementation ) def _add_implemented_requirements ( self , row : int , control_implementation : ControlImplementation , controls : Dict [ str , List [ str ]], component_name : str , parameter_name : str , responsible_roles : List [ ResponsibleRole ], goal_name_id : str ) -> None : \"\"\"Add implemented requirements.\"\"\" goal_remarks = self . xlsx_helper . get_goal_remarks ( row ) parameter_value_default = self . xlsx_helper . get_parameter_value_default ( row ) for control in controls . keys (): control_uuid = str ( uuid . uuid4 ()) prop1 = Property ( name = 'goal_name_id' , class_ = self . _get_class_for_property_name ( 'goal_name_id' ), value = goal_name_id , ns = self . _get_namespace (), remarks = Remarks ( __root__ = str ( goal_remarks )) ) prop2 = Property ( name = 'goal_version' , class_ = self . _get_class_for_property_name ( 'goal_version' ), value = self . _get_goal_version (), ns = self . _get_namespace (), remarks = Remarks ( __root__ = str ( goal_name_id )) ) props = [ prop1 , prop2 ] control_id , _ = self . catalog_interface . get_control_id_and_status ( control ) if not control_id : logger . info ( f 'row { row } control { control } not found in catalog' ) control_id = control # implemented_requirement implemented_requirement = ImplementedRequirement ( uuid = control_uuid , description = control , props = props , control_id = control_id , responsible_roles = responsible_roles , ) # add statements self . _add_statements ( row , control , controls , component_name , implemented_requirement ) # add set_parameter self . _add_set_parameter_default ( parameter_name , parameter_value_default , implemented_requirement ) # implemented_requirements control_implementation . implemented_requirements . append ( implemented_requirement ) def _add_statements ( self , row : int , control : str , controls : Dict [ str , List [ str ]], component_name : str , implemented_requirement : ImplementedRequirement ) -> None : \"\"\"Add statements.\"\"\" control_statements = controls [ control ] if control_statements : statements = [] for control_statement in control_statements : statement_id = control + control_statement if any ( i in control for i in '()' ): control = control . replace ( '(' , '_' ) control = control . replace ( ')' , '' ) logger . info ( f 'row { row } control { control } edited to remove parentheses' ) statement = Statement ( statement_id = control , uuid = str ( uuid . uuid4 ()), description = f ' { component_name } implements { statement_id } ' ) statements . append ( statement ) implemented_requirement . statements = statements def _add_set_parameter_values ( self , parameter_name : str , parameter_values : str , control_implementation : ControlImplementation ) -> None : \"\"\"Add set parameter values (the set of choices).\"\"\" if parameter_name is not None : parameter_name = parameter_name . replace ( ' ' , '_' ) if parameter_values is not None : set_parameters = [ SetParameter ( param_id = parameter_name , values = parameter_values )] if control_implementation . set_parameters is None : control_implementation . set_parameters = [] # set_parameters is a list control_implementation . set_parameters . extend ( set_parameters ) def _add_set_parameter_default ( self , parameter_name : str , parameter_value_default : str , implemented_requirement : ImplementedRequirement ) -> None : \"\"\"Add set parameter default (the \"recommended\" value).\"\"\" if parameter_name is not None : parameter_name = parameter_name . replace ( ' ' , '_' ) if parameter_value_default is not None : if implemented_requirement . set_parameters is None : implemented_requirement . set_parameters = [] values = [ parameter_value_default ] set_parameter = SetParameter ( param_id = parameter_name , values = values ) set_parameters = [ set_parameter ] # set_parameters is a list implemented_requirement . set_parameters . extend ( set_parameters ) def _get_defined_component ( self , component_name : str , component_type : str ) -> DefinedComponent : \"\"\"Get defined component.\"\"\" key = component_name + key_sep + component_type defined_component = self . defined_components . get ( key ) if not defined_component : # create new component component_title = component_name component_description = component_name defined_component = DefinedComponent ( uuid = str ( uuid . uuid4 ()), description = component_description , title = component_title , type = component_type , ) self . defined_components [ key ] = defined_component return defined_component def _build_roles ( self ) -> List [ Role ]: \"\"\"Build roles.\"\"\" value = [ Role ( id = 'prepared-by' , title = 'Indicates the organization that created this content.' ), Role ( id = 'prepared-for' , title = 'Indicates the organization for which this content was created..' ), Role ( id = 'content-approver' , title = 'Indicates the organization responsible for all content represented in the \"document\".' ), ] return value def _build_responsible_roles ( self , party_uuid_01 : str , party_uuid_02 : str , party_uuid_03 : str ) -> List [ ResponsibleRole ]: \"\"\"Build responsible roles.\"\"\" role_prepared_by = ResponsibleRole ( role_id = 'prepared-by' , party_uuids = [ party_uuid_01 ]) role_prepared_for = ResponsibleRole ( role_id = 'prepared-for' , party_uuids = [ party_uuid_02 , party_uuid_03 ]) role_content_approver = ResponsibleRole ( role_id = 'content-approver' , party_uuids = [ party_uuid_01 ]) value = [ role_prepared_by , role_prepared_for , role_content_approver , ] return value def _build_parties ( self , party_uuid_01 : str , party_uuid_02 : str , party_uuid_03 : str ) -> List [ Party ]: \"\"\"Build parties.\"\"\" value = [ Party ( uuid = party_uuid_01 , type = 'organization' , name = self . _get_org_name (), remarks = self . _get_org_remarks ()), Party ( uuid = party_uuid_02 , type = 'organization' , name = 'Customer' , remarks = 'organization to be customized at account creation only for their Component Definition' ), Party ( uuid = party_uuid_03 , type = 'organization' , name = 'ISV' , remarks = 'organization to be customized at ISV subscription only for their Component Definition' ), ] return value def _build_responsible_parties ( self , party_uuid_01 : str , party_uuid_02 : str , party_uuid_03 : str ) -> List [ ResponsibleParty ]: \"\"\"Build responsible parties.\"\"\" prepared_by = ResponsibleParty ( role_id = 'prepared-by' , party_uuids = [ party_uuid_01 ]) prepared_for = ResponsibleParty ( role_id = 'prepared-for' , party_uuids = [ party_uuid_02 , party_uuid_03 ]) content_approver = ResponsibleParty ( role_id = 'content-approver' , party_uuids = [ party_uuid_01 ]) value = [ prepared_by , prepared_for , content_approver , ] return value def _report_issues ( self ) -> None : \"\"\"Report issues.\"\"\" self . xlsx_helper . report_issues () def _get_org_name ( self ) -> str : \"\"\"Get org-name from config.\"\"\" value = self . _config . get ( 'org-name' ) logger . debug ( f 'org-name: { value } ' ) return value def _get_org_remarks ( self ) -> str : \"\"\"Get org-remarks from config.\"\"\" value = self . _config . get ( 'org-remarks' ) logger . debug ( f 'org-remarks: { value } ' ) return value def _get_class_for_property_name ( self , property_name : str ) -> str : \"\"\"Get class for property-name from config.\"\"\" value = None data = self . _config . get ( 'property-name-to-class' ) if data is not None : for item in data . split ( ',' ): item = item . strip () parts = item . split ( ':' ) if len ( parts ) != 2 or parts [ 0 ] != property_name : continue value = parts [ 1 ] break logger . debug ( f 'property-name-to-class: { property_name } -> { value } ' ) return value def _get_namespace ( self ) -> str : \"\"\"Get namespace from config.\"\"\" value = self . _config . get ( 'namespace' ) logger . debug ( f 'namespace: { value } ' ) return value def _get_catalog_url ( self ) -> str : \"\"\"Get catalog url from config.\"\"\" value = self . _config . get ( 'catalog-url' ) logger . debug ( f 'catalog-url: { value } ' ) return value def _get_catalog_title ( self ) -> str : \"\"\"Get catalog title from config.\"\"\" value = self . _config . get ( 'catalog-title' ) logger . debug ( f 'catalog-title: { value } ' ) return value def _get_goal_version ( self ) -> str : \"\"\"Fix goal_version at 1.0.\"\"\" return '1.0' name : str \u00a4 Methods \u00a4 __init__ ( self , config_object ) special \u00a4 Initialize trestle task xlsx-to-oscal-cd. Parameters: Name Type Description Default config_object Optional[configparser.SectionProxy] Config section associated with the task. required Source code in trestle/tasks/xlsx_to_oscal_cd.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task xlsx-to-oscal-cd. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) self . xlsx_helper = XlsxHelper () self . _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat () execute ( self ) \u00a4 Provide an executed outcome. Source code in trestle/tasks/xlsx_to_oscal_cd.py def execute ( self ) -> TaskOutcome : \"\"\"Provide an executed outcome.\"\"\" try : return self . _execute () except Exception : logger . info ( traceback . format_exc ()) return TaskOutcome ( 'failure' ) print_info ( self ) \u00a4 Print the help string. Source code in trestle/tasks/xlsx_to_oscal_cd.py def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" self . xlsx_helper . print_info ( self . name , 'component_definition' ) set_timestamp ( self , timestamp ) \u00a4 Set the timestamp. Source code in trestle/tasks/xlsx_to_oscal_cd.py def set_timestamp ( self , timestamp : str ) -> None : \"\"\"Set the timestamp.\"\"\" self . _timestamp = timestamp simulate ( self ) \u00a4 Provide a simulated outcome. Source code in trestle/tasks/xlsx_to_oscal_cd.py def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) handler: python","title":"xlsx_to_oscal_cd"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_cd/#trestle.tasks.xlsx_to_oscal_cd","text":"OSCAL transformation tasks.","title":"xlsx_to_oscal_cd"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_cd/#trestle.tasks.xlsx_to_oscal_cd.key_sep","text":"","title":"key_sep"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_cd/#trestle.tasks.xlsx_to_oscal_cd.logger","text":"","title":"logger"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_cd/#trestle.tasks.xlsx_to_oscal_cd.sep","text":"","title":"sep"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_cd/#trestle.tasks.xlsx_to_oscal_cd-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_cd/#trestle.tasks.xlsx_to_oscal_cd.XlsxToOscalComponentDefinition","text":"Task to create OSCAL ComponentDefinition json. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/xlsx_to_oscal_cd.py class XlsxToOscalComponentDefinition ( TaskBase ): \"\"\" Task to create OSCAL ComponentDefinition json. Attributes: name: Name of the task. \"\"\" name = 'xlsx-to-oscal-cd' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task xlsx-to-oscal-cd. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) self . xlsx_helper = XlsxHelper () self . _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat () def set_timestamp ( self , timestamp : str ) -> None : \"\"\"Set the timestamp.\"\"\" self . _timestamp = timestamp def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" self . xlsx_helper . print_info ( self . name , 'component_definition' ) def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) def execute ( self ) -> TaskOutcome : \"\"\"Provide an executed outcome.\"\"\" try : return self . _execute () except Exception : logger . info ( traceback . format_exc ()) return TaskOutcome ( 'failure' ) def _execute ( self ) -> TaskOutcome : \"\"\"Execute path core.\"\"\" if not self . xlsx_helper . configure ( self ): return TaskOutcome ( 'failure' ) # config output odir = self . _config . get ( 'output-dir' ) opth = pathlib . Path ( odir ) self . _overwrite = self . _config . getboolean ( 'output-overwrite' , True ) # insure output dir exists opth . mkdir ( exist_ok = True , parents = True ) # calculate output file name & check writability oname = 'component-definition.json' ofile = opth / oname if not self . _overwrite and pathlib . Path ( ofile ) . exists (): logger . warning ( f 'output: { ofile } already exists' ) return TaskOutcome ( 'failure' ) # initialize self . defined_components = {} # roles, responsible_roles, parties, responsible parties party_uuid_01 = str ( uuid . uuid4 ()) party_uuid_02 = str ( uuid . uuid4 ()) party_uuid_03 = str ( uuid . uuid4 ()) roles = self . _build_roles () responsible_roles = self . _build_responsible_roles ( party_uuid_01 , party_uuid_02 , party_uuid_03 ) parties = self . _build_parties ( party_uuid_01 , party_uuid_02 , party_uuid_03 ) responsible_parties = self . _build_responsible_parties ( party_uuid_01 , party_uuid_02 , party_uuid_03 ) # process each row of spread sheet self . _process_rows ( responsible_roles ) # create OSCAL ComponentDefinition metadata = Metadata ( title = 'Component definition for ' + self . _get_catalog_title () + ' profiles' , last_modified = self . _timestamp , oscal_version = OSCAL_VERSION , version = get_trestle_version (), roles = roles , parties = parties , responsible_parties = responsible_parties ) component_definition = ComponentDefinition ( uuid = str ( uuid . uuid4 ()), metadata = metadata , components = list ( self . defined_components . values ()), ) # write OSCAL ComponentDefinition to file if self . _verbose : logger . info ( f 'output: { ofile } ' ) component_definition . oscal_write ( pathlib . Path ( ofile )) # issues self . _report_issues () return TaskOutcome ( 'success' ) def _process_rows ( self , responsible_roles : List [ ResponsibleRole ]) -> None : \"\"\"Process spread sheet rows.\"\"\" ci_map = {} for row in self . xlsx_helper . row_generator (): # quit when first row with no goal_id encountered goal_name_id = self . xlsx_helper . get_goal_name_id ( row ) controls = self . xlsx_helper . get_controls ( row ) if len ( controls . keys ()) == 0 : continue # component component_name = self . xlsx_helper . get_component_name ( row ) component_type = 'Service' defined_component = self . _get_defined_component ( component_name , component_type ) # parameter parameter_name , parameter_description = self . xlsx_helper . get_parameter_name_and_description ( row ) # control implementations source = self . _get_catalog_url () description = component_name + ' implemented controls for ' + self . _get_catalog_title ( ) + '. It includes assessment asset configuration for CICD.' key = source + key_sep + description control_implementation = ci_map . get ( key ) if not control_implementation : ci_map [ key ] = ControlImplementation ( uuid = str ( uuid . uuid4 ()), source = source , description = description , implemented_requirements = [], ) control_implementation = ci_map [ key ] if defined_component . control_implementations is None : defined_component . control_implementations = [] defined_component . control_implementations . append ( control_implementation ) # implemented requirements self . _add_implemented_requirements ( row , control_implementation , controls , component_name , parameter_name , responsible_roles , goal_name_id ) # keep alternative parameter values at control implementation level parameter_values = self . xlsx_helper . get_parameter_values ( row ) self . _add_set_parameter_values ( parameter_name , parameter_values , control_implementation ) def _add_implemented_requirements ( self , row : int , control_implementation : ControlImplementation , controls : Dict [ str , List [ str ]], component_name : str , parameter_name : str , responsible_roles : List [ ResponsibleRole ], goal_name_id : str ) -> None : \"\"\"Add implemented requirements.\"\"\" goal_remarks = self . xlsx_helper . get_goal_remarks ( row ) parameter_value_default = self . xlsx_helper . get_parameter_value_default ( row ) for control in controls . keys (): control_uuid = str ( uuid . uuid4 ()) prop1 = Property ( name = 'goal_name_id' , class_ = self . _get_class_for_property_name ( 'goal_name_id' ), value = goal_name_id , ns = self . _get_namespace (), remarks = Remarks ( __root__ = str ( goal_remarks )) ) prop2 = Property ( name = 'goal_version' , class_ = self . _get_class_for_property_name ( 'goal_version' ), value = self . _get_goal_version (), ns = self . _get_namespace (), remarks = Remarks ( __root__ = str ( goal_name_id )) ) props = [ prop1 , prop2 ] control_id , _ = self . catalog_interface . get_control_id_and_status ( control ) if not control_id : logger . info ( f 'row { row } control { control } not found in catalog' ) control_id = control # implemented_requirement implemented_requirement = ImplementedRequirement ( uuid = control_uuid , description = control , props = props , control_id = control_id , responsible_roles = responsible_roles , ) # add statements self . _add_statements ( row , control , controls , component_name , implemented_requirement ) # add set_parameter self . _add_set_parameter_default ( parameter_name , parameter_value_default , implemented_requirement ) # implemented_requirements control_implementation . implemented_requirements . append ( implemented_requirement ) def _add_statements ( self , row : int , control : str , controls : Dict [ str , List [ str ]], component_name : str , implemented_requirement : ImplementedRequirement ) -> None : \"\"\"Add statements.\"\"\" control_statements = controls [ control ] if control_statements : statements = [] for control_statement in control_statements : statement_id = control + control_statement if any ( i in control for i in '()' ): control = control . replace ( '(' , '_' ) control = control . replace ( ')' , '' ) logger . info ( f 'row { row } control { control } edited to remove parentheses' ) statement = Statement ( statement_id = control , uuid = str ( uuid . uuid4 ()), description = f ' { component_name } implements { statement_id } ' ) statements . append ( statement ) implemented_requirement . statements = statements def _add_set_parameter_values ( self , parameter_name : str , parameter_values : str , control_implementation : ControlImplementation ) -> None : \"\"\"Add set parameter values (the set of choices).\"\"\" if parameter_name is not None : parameter_name = parameter_name . replace ( ' ' , '_' ) if parameter_values is not None : set_parameters = [ SetParameter ( param_id = parameter_name , values = parameter_values )] if control_implementation . set_parameters is None : control_implementation . set_parameters = [] # set_parameters is a list control_implementation . set_parameters . extend ( set_parameters ) def _add_set_parameter_default ( self , parameter_name : str , parameter_value_default : str , implemented_requirement : ImplementedRequirement ) -> None : \"\"\"Add set parameter default (the \"recommended\" value).\"\"\" if parameter_name is not None : parameter_name = parameter_name . replace ( ' ' , '_' ) if parameter_value_default is not None : if implemented_requirement . set_parameters is None : implemented_requirement . set_parameters = [] values = [ parameter_value_default ] set_parameter = SetParameter ( param_id = parameter_name , values = values ) set_parameters = [ set_parameter ] # set_parameters is a list implemented_requirement . set_parameters . extend ( set_parameters ) def _get_defined_component ( self , component_name : str , component_type : str ) -> DefinedComponent : \"\"\"Get defined component.\"\"\" key = component_name + key_sep + component_type defined_component = self . defined_components . get ( key ) if not defined_component : # create new component component_title = component_name component_description = component_name defined_component = DefinedComponent ( uuid = str ( uuid . uuid4 ()), description = component_description , title = component_title , type = component_type , ) self . defined_components [ key ] = defined_component return defined_component def _build_roles ( self ) -> List [ Role ]: \"\"\"Build roles.\"\"\" value = [ Role ( id = 'prepared-by' , title = 'Indicates the organization that created this content.' ), Role ( id = 'prepared-for' , title = 'Indicates the organization for which this content was created..' ), Role ( id = 'content-approver' , title = 'Indicates the organization responsible for all content represented in the \"document\".' ), ] return value def _build_responsible_roles ( self , party_uuid_01 : str , party_uuid_02 : str , party_uuid_03 : str ) -> List [ ResponsibleRole ]: \"\"\"Build responsible roles.\"\"\" role_prepared_by = ResponsibleRole ( role_id = 'prepared-by' , party_uuids = [ party_uuid_01 ]) role_prepared_for = ResponsibleRole ( role_id = 'prepared-for' , party_uuids = [ party_uuid_02 , party_uuid_03 ]) role_content_approver = ResponsibleRole ( role_id = 'content-approver' , party_uuids = [ party_uuid_01 ]) value = [ role_prepared_by , role_prepared_for , role_content_approver , ] return value def _build_parties ( self , party_uuid_01 : str , party_uuid_02 : str , party_uuid_03 : str ) -> List [ Party ]: \"\"\"Build parties.\"\"\" value = [ Party ( uuid = party_uuid_01 , type = 'organization' , name = self . _get_org_name (), remarks = self . _get_org_remarks ()), Party ( uuid = party_uuid_02 , type = 'organization' , name = 'Customer' , remarks = 'organization to be customized at account creation only for their Component Definition' ), Party ( uuid = party_uuid_03 , type = 'organization' , name = 'ISV' , remarks = 'organization to be customized at ISV subscription only for their Component Definition' ), ] return value def _build_responsible_parties ( self , party_uuid_01 : str , party_uuid_02 : str , party_uuid_03 : str ) -> List [ ResponsibleParty ]: \"\"\"Build responsible parties.\"\"\" prepared_by = ResponsibleParty ( role_id = 'prepared-by' , party_uuids = [ party_uuid_01 ]) prepared_for = ResponsibleParty ( role_id = 'prepared-for' , party_uuids = [ party_uuid_02 , party_uuid_03 ]) content_approver = ResponsibleParty ( role_id = 'content-approver' , party_uuids = [ party_uuid_01 ]) value = [ prepared_by , prepared_for , content_approver , ] return value def _report_issues ( self ) -> None : \"\"\"Report issues.\"\"\" self . xlsx_helper . report_issues () def _get_org_name ( self ) -> str : \"\"\"Get org-name from config.\"\"\" value = self . _config . get ( 'org-name' ) logger . debug ( f 'org-name: { value } ' ) return value def _get_org_remarks ( self ) -> str : \"\"\"Get org-remarks from config.\"\"\" value = self . _config . get ( 'org-remarks' ) logger . debug ( f 'org-remarks: { value } ' ) return value def _get_class_for_property_name ( self , property_name : str ) -> str : \"\"\"Get class for property-name from config.\"\"\" value = None data = self . _config . get ( 'property-name-to-class' ) if data is not None : for item in data . split ( ',' ): item = item . strip () parts = item . split ( ':' ) if len ( parts ) != 2 or parts [ 0 ] != property_name : continue value = parts [ 1 ] break logger . debug ( f 'property-name-to-class: { property_name } -> { value } ' ) return value def _get_namespace ( self ) -> str : \"\"\"Get namespace from config.\"\"\" value = self . _config . get ( 'namespace' ) logger . debug ( f 'namespace: { value } ' ) return value def _get_catalog_url ( self ) -> str : \"\"\"Get catalog url from config.\"\"\" value = self . _config . get ( 'catalog-url' ) logger . debug ( f 'catalog-url: { value } ' ) return value def _get_catalog_title ( self ) -> str : \"\"\"Get catalog title from config.\"\"\" value = self . _config . get ( 'catalog-title' ) logger . debug ( f 'catalog-title: { value } ' ) return value def _get_goal_version ( self ) -> str : \"\"\"Fix goal_version at 1.0.\"\"\" return '1.0'","title":"XlsxToOscalComponentDefinition"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_cd/#trestle.tasks.xlsx_to_oscal_cd.XlsxToOscalComponentDefinition.name","text":"","title":"name"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_cd/#trestle.tasks.xlsx_to_oscal_cd.XlsxToOscalComponentDefinition-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_cd/#trestle.tasks.xlsx_to_oscal_cd.XlsxToOscalComponentDefinition.__init__","text":"Initialize trestle task xlsx-to-oscal-cd. Parameters: Name Type Description Default config_object Optional[configparser.SectionProxy] Config section associated with the task. required Source code in trestle/tasks/xlsx_to_oscal_cd.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task xlsx-to-oscal-cd. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) self . xlsx_helper = XlsxHelper () self . _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat ()","title":"__init__()"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_cd/#trestle.tasks.xlsx_to_oscal_cd.XlsxToOscalComponentDefinition.execute","text":"Provide an executed outcome. Source code in trestle/tasks/xlsx_to_oscal_cd.py def execute ( self ) -> TaskOutcome : \"\"\"Provide an executed outcome.\"\"\" try : return self . _execute () except Exception : logger . info ( traceback . format_exc ()) return TaskOutcome ( 'failure' )","title":"execute()"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_cd/#trestle.tasks.xlsx_to_oscal_cd.XlsxToOscalComponentDefinition.print_info","text":"Print the help string. Source code in trestle/tasks/xlsx_to_oscal_cd.py def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" self . xlsx_helper . print_info ( self . name , 'component_definition' )","title":"print_info()"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_cd/#trestle.tasks.xlsx_to_oscal_cd.XlsxToOscalComponentDefinition.set_timestamp","text":"Set the timestamp. Source code in trestle/tasks/xlsx_to_oscal_cd.py def set_timestamp ( self , timestamp : str ) -> None : \"\"\"Set the timestamp.\"\"\" self . _timestamp = timestamp","title":"set_timestamp()"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_cd/#trestle.tasks.xlsx_to_oscal_cd.XlsxToOscalComponentDefinition.simulate","text":"Provide a simulated outcome. Source code in trestle/tasks/xlsx_to_oscal_cd.py def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) handler: python","title":"simulate()"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_profile/","text":"trestle.tasks.xlsx_to_oscal_profile \u00a4 OSCAL transformation tasks. logger \u00a4 Classes \u00a4 XlsxToOscalProfile ( TaskBase ) \u00a4 Task to create OSCAL Profile json. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/xlsx_to_oscal_profile.py class XlsxToOscalProfile ( TaskBase ): \"\"\" Task to create OSCAL Profile json. Attributes: name: Name of the task. \"\"\" name = 'xlsx-to-oscal-profile' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task xlsx-to-oscal-profile. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) self . xlsx_helper = XlsxHelper () self . _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat () def set_timestamp ( self , timestamp : str ) -> None : \"\"\"Set the timestamp.\"\"\" self . _timestamp = timestamp def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" self . xlsx_helper . print_info ( self . name , 'profile' ) def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) def execute ( self ) -> TaskOutcome : \"\"\"Provide an executed outcome.\"\"\" try : return self . _execute () except Exception : logger . info ( traceback . format_exc ()) return TaskOutcome ( 'failure' ) def _execute ( self ) -> TaskOutcome : \"\"\"Execute path core.\"\"\" if not self . xlsx_helper . configure ( self ): return TaskOutcome ( 'failure' ) # config output odir = self . _config . get ( 'output-dir' ) opth = pathlib . Path ( odir ) self . _overwrite = self . _config . getboolean ( 'output-overwrite' , True ) # insure output dir exists opth . mkdir ( exist_ok = True , parents = True ) # calculate output file name & check writability oname = 'profile.json' ofile = opth / oname if not self . _overwrite and pathlib . Path ( ofile ) . exists (): logger . error ( f 'output: { ofile } already exists' ) return TaskOutcome ( 'failure' ) # create OSCAL Profile metadata = Metadata ( title = 'Profile for ' + self . _get_profile_title (), last_modified = self . _timestamp , oscal_version = OSCAL_VERSION , version = get_trestle_version (), ) if self . xlsx_helper . profile_type == self . xlsx_helper . by_control : imports = self . _get_imports_by_control () profile = Profile ( uuid = str ( uuid . uuid4 ()), metadata = metadata , imports = imports , ) else : if self . xlsx_helper . profile_type == self . xlsx_helper . by_rule : imports = self . _get_imports_by_rule () elif self . xlsx_helper . profile_type == self . xlsx_helper . by_check : imports = self . _get_imports_by_check () else : imports = self . _get_imports_by_goal () set_parameters = self . _get_set_parameters () modify = Modify ( set_parameters = set_parameters ) profile = Profile ( uuid = str ( uuid . uuid4 ()), metadata = metadata , imports = imports , modify = modify , ) # write OSCAL Profile to file if self . _verbose : logger . info ( f 'output: { ofile } ' ) profile . oscal_write ( pathlib . Path ( ofile )) # issues self . _report_issues () return TaskOutcome ( 'success' ) def _get_imports_by_goal ( self ) -> List [ Import ]: \"\"\"Get imports by goal.\"\"\" return self . _get_imports_by_check () def _get_imports_by_control ( self ) -> List [ Import ]: \"\"\"Get imports by control.\"\"\" import_ = Import ( href = self . _get_spread_sheet_url (), include_controls = [ SelectControlById ( with_ids = self . _get_with_ids_by_control ())], ) imports = [ import_ ] return imports def _get_imports_by_rule ( self ) -> List [ Import ]: \"\"\"Get imports by rule.\"\"\" import_ = Import ( href = self . _get_spread_sheet_url (), include_controls = [ SelectControlById ( with_ids = self . _get_with_ids_by_rule ())], ) imports = [ import_ ] return imports def _get_imports_by_check ( self ) -> List [ Import ]: \"\"\"Get imports by check.\"\"\" import_ = Import ( href = self . _get_spread_sheet_url (), include_controls = [ SelectControlById ( with_ids = self . _get_with_ids_by_check ())], ) imports = [ import_ ] return imports def _get_with_ids_by_control ( self ) -> List [ str ]: \"\"\"Get controls from spread sheet.\"\"\" control_list = [] for row in self . xlsx_helper . row_generator (): # quit when first row with no goal_id encountered controls = self . xlsx_helper . get_controls ( row ) if controls is not None : for control in controls : control = self . _oscal_namify ( control ) if control in control_list : continue control_list . append ( control ) return sorted ( control_list , key = self . _control_sort_key ) def _get_with_ids_by_rule ( self ) -> List [ str ]: \"\"\"Get rules from spread sheet.\"\"\" rule_name_id_list = [] for row in self . xlsx_helper . row_generator (): # quit when first row with no goal_id encountered rule_name_id = self . xlsx_helper . get_rule_name_id ( row , strict = True ) if rule_name_id is not None : if rule_name_id in rule_name_id_list : continue rule_name_id_list . append ( rule_name_id ) return sorted ( rule_name_id_list ) def _get_with_ids_by_check ( self ) -> List [ str ]: \"\"\"Get check from spread sheet.\"\"\" check_name_id_list = [] for row in self . xlsx_helper . row_generator (): # quit when first row with no goal_id encountered check_name_id = self . xlsx_helper . get_check_name_id ( row , strict = True ) if check_name_id is not None : if check_name_id in check_name_id_list : continue check_name_id_list . append ( check_name_id ) return sorted ( check_name_id_list ) def _control_sort_key ( self , control : str ) -> ( str , int , int ): \"\"\"Fabricate sort key.\"\"\" k1 = control . split ( '-' )[ 0 ] k2 = int ( control . split ( '-' )[ 1 ] . split ( '.' )[ 0 ]) if '.' in control : k3 = int ( control . split ( '-' )[ 1 ] . split ( '.' )[ 1 ]) else : k3 = 0 return ( k1 , k2 , k3 ) def _oscal_namify ( self , control : str ) -> str : \"\"\"Rectify parenthesized numbers in controls.\"\"\" control = control . replace ( '(' , '.' ) control = control . replace ( ')' , '' ) return control def _get_set_parameters ( self ) -> List [ SetParameter ]: \"\"\"Get set parameters from spread sheet.\"\"\" set_parameters = [] for row in self . xlsx_helper . row_generator (): # quit when first row with no goal_id encountered param_id , label = self . xlsx_helper . get_parameter_name_and_description ( row ) usage = self . xlsx_helper . get_parameter_usage ( row ) values = self . xlsx_helper . get_parameter_values ( row ) if param_id is None : continue set_parameter = SetParameter ( param_id = param_id , label = label , usage = usage , ) if values is not None : set_parameter . values = values set_parameters . append ( set_parameter ) return set_parameters def _get_profile_title ( self ) -> str : \"\"\"Get profile title from config.\"\"\" value = self . _config . get ( 'profile-title' ) logger . debug ( f 'profile-title: { value } ' ) return value def _get_spread_sheet_url ( self ) -> str : \"\"\"Get spread sheet url from config.\"\"\" value = self . _config . get ( 'spread-sheet-url' ) logger . debug ( f 'spread-sheet-url: { value } ' ) return value def _report_issues ( self ) -> None : \"\"\"Report issues.\"\"\" self . xlsx_helper . report_issues () name : str \u00a4 Methods \u00a4 __init__ ( self , config_object ) special \u00a4 Initialize trestle task xlsx-to-oscal-profile. Parameters: Name Type Description Default config_object Optional[configparser.SectionProxy] Config section associated with the task. required Source code in trestle/tasks/xlsx_to_oscal_profile.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task xlsx-to-oscal-profile. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) self . xlsx_helper = XlsxHelper () self . _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat () execute ( self ) \u00a4 Provide an executed outcome. Source code in trestle/tasks/xlsx_to_oscal_profile.py def execute ( self ) -> TaskOutcome : \"\"\"Provide an executed outcome.\"\"\" try : return self . _execute () except Exception : logger . info ( traceback . format_exc ()) return TaskOutcome ( 'failure' ) print_info ( self ) \u00a4 Print the help string. Source code in trestle/tasks/xlsx_to_oscal_profile.py def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" self . xlsx_helper . print_info ( self . name , 'profile' ) set_timestamp ( self , timestamp ) \u00a4 Set the timestamp. Source code in trestle/tasks/xlsx_to_oscal_profile.py def set_timestamp ( self , timestamp : str ) -> None : \"\"\"Set the timestamp.\"\"\" self . _timestamp = timestamp simulate ( self ) \u00a4 Provide a simulated outcome. Source code in trestle/tasks/xlsx_to_oscal_profile.py def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) handler: python","title":"xlsx_to_oscal_profile"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_profile/#trestle.tasks.xlsx_to_oscal_profile","text":"OSCAL transformation tasks.","title":"xlsx_to_oscal_profile"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_profile/#trestle.tasks.xlsx_to_oscal_profile.logger","text":"","title":"logger"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_profile/#trestle.tasks.xlsx_to_oscal_profile-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_profile/#trestle.tasks.xlsx_to_oscal_profile.XlsxToOscalProfile","text":"Task to create OSCAL Profile json. Attributes: Name Type Description name str Name of the task. Source code in trestle/tasks/xlsx_to_oscal_profile.py class XlsxToOscalProfile ( TaskBase ): \"\"\" Task to create OSCAL Profile json. Attributes: name: Name of the task. \"\"\" name = 'xlsx-to-oscal-profile' def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task xlsx-to-oscal-profile. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) self . xlsx_helper = XlsxHelper () self . _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat () def set_timestamp ( self , timestamp : str ) -> None : \"\"\"Set the timestamp.\"\"\" self . _timestamp = timestamp def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" self . xlsx_helper . print_info ( self . name , 'profile' ) def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) def execute ( self ) -> TaskOutcome : \"\"\"Provide an executed outcome.\"\"\" try : return self . _execute () except Exception : logger . info ( traceback . format_exc ()) return TaskOutcome ( 'failure' ) def _execute ( self ) -> TaskOutcome : \"\"\"Execute path core.\"\"\" if not self . xlsx_helper . configure ( self ): return TaskOutcome ( 'failure' ) # config output odir = self . _config . get ( 'output-dir' ) opth = pathlib . Path ( odir ) self . _overwrite = self . _config . getboolean ( 'output-overwrite' , True ) # insure output dir exists opth . mkdir ( exist_ok = True , parents = True ) # calculate output file name & check writability oname = 'profile.json' ofile = opth / oname if not self . _overwrite and pathlib . Path ( ofile ) . exists (): logger . error ( f 'output: { ofile } already exists' ) return TaskOutcome ( 'failure' ) # create OSCAL Profile metadata = Metadata ( title = 'Profile for ' + self . _get_profile_title (), last_modified = self . _timestamp , oscal_version = OSCAL_VERSION , version = get_trestle_version (), ) if self . xlsx_helper . profile_type == self . xlsx_helper . by_control : imports = self . _get_imports_by_control () profile = Profile ( uuid = str ( uuid . uuid4 ()), metadata = metadata , imports = imports , ) else : if self . xlsx_helper . profile_type == self . xlsx_helper . by_rule : imports = self . _get_imports_by_rule () elif self . xlsx_helper . profile_type == self . xlsx_helper . by_check : imports = self . _get_imports_by_check () else : imports = self . _get_imports_by_goal () set_parameters = self . _get_set_parameters () modify = Modify ( set_parameters = set_parameters ) profile = Profile ( uuid = str ( uuid . uuid4 ()), metadata = metadata , imports = imports , modify = modify , ) # write OSCAL Profile to file if self . _verbose : logger . info ( f 'output: { ofile } ' ) profile . oscal_write ( pathlib . Path ( ofile )) # issues self . _report_issues () return TaskOutcome ( 'success' ) def _get_imports_by_goal ( self ) -> List [ Import ]: \"\"\"Get imports by goal.\"\"\" return self . _get_imports_by_check () def _get_imports_by_control ( self ) -> List [ Import ]: \"\"\"Get imports by control.\"\"\" import_ = Import ( href = self . _get_spread_sheet_url (), include_controls = [ SelectControlById ( with_ids = self . _get_with_ids_by_control ())], ) imports = [ import_ ] return imports def _get_imports_by_rule ( self ) -> List [ Import ]: \"\"\"Get imports by rule.\"\"\" import_ = Import ( href = self . _get_spread_sheet_url (), include_controls = [ SelectControlById ( with_ids = self . _get_with_ids_by_rule ())], ) imports = [ import_ ] return imports def _get_imports_by_check ( self ) -> List [ Import ]: \"\"\"Get imports by check.\"\"\" import_ = Import ( href = self . _get_spread_sheet_url (), include_controls = [ SelectControlById ( with_ids = self . _get_with_ids_by_check ())], ) imports = [ import_ ] return imports def _get_with_ids_by_control ( self ) -> List [ str ]: \"\"\"Get controls from spread sheet.\"\"\" control_list = [] for row in self . xlsx_helper . row_generator (): # quit when first row with no goal_id encountered controls = self . xlsx_helper . get_controls ( row ) if controls is not None : for control in controls : control = self . _oscal_namify ( control ) if control in control_list : continue control_list . append ( control ) return sorted ( control_list , key = self . _control_sort_key ) def _get_with_ids_by_rule ( self ) -> List [ str ]: \"\"\"Get rules from spread sheet.\"\"\" rule_name_id_list = [] for row in self . xlsx_helper . row_generator (): # quit when first row with no goal_id encountered rule_name_id = self . xlsx_helper . get_rule_name_id ( row , strict = True ) if rule_name_id is not None : if rule_name_id in rule_name_id_list : continue rule_name_id_list . append ( rule_name_id ) return sorted ( rule_name_id_list ) def _get_with_ids_by_check ( self ) -> List [ str ]: \"\"\"Get check from spread sheet.\"\"\" check_name_id_list = [] for row in self . xlsx_helper . row_generator (): # quit when first row with no goal_id encountered check_name_id = self . xlsx_helper . get_check_name_id ( row , strict = True ) if check_name_id is not None : if check_name_id in check_name_id_list : continue check_name_id_list . append ( check_name_id ) return sorted ( check_name_id_list ) def _control_sort_key ( self , control : str ) -> ( str , int , int ): \"\"\"Fabricate sort key.\"\"\" k1 = control . split ( '-' )[ 0 ] k2 = int ( control . split ( '-' )[ 1 ] . split ( '.' )[ 0 ]) if '.' in control : k3 = int ( control . split ( '-' )[ 1 ] . split ( '.' )[ 1 ]) else : k3 = 0 return ( k1 , k2 , k3 ) def _oscal_namify ( self , control : str ) -> str : \"\"\"Rectify parenthesized numbers in controls.\"\"\" control = control . replace ( '(' , '.' ) control = control . replace ( ')' , '' ) return control def _get_set_parameters ( self ) -> List [ SetParameter ]: \"\"\"Get set parameters from spread sheet.\"\"\" set_parameters = [] for row in self . xlsx_helper . row_generator (): # quit when first row with no goal_id encountered param_id , label = self . xlsx_helper . get_parameter_name_and_description ( row ) usage = self . xlsx_helper . get_parameter_usage ( row ) values = self . xlsx_helper . get_parameter_values ( row ) if param_id is None : continue set_parameter = SetParameter ( param_id = param_id , label = label , usage = usage , ) if values is not None : set_parameter . values = values set_parameters . append ( set_parameter ) return set_parameters def _get_profile_title ( self ) -> str : \"\"\"Get profile title from config.\"\"\" value = self . _config . get ( 'profile-title' ) logger . debug ( f 'profile-title: { value } ' ) return value def _get_spread_sheet_url ( self ) -> str : \"\"\"Get spread sheet url from config.\"\"\" value = self . _config . get ( 'spread-sheet-url' ) logger . debug ( f 'spread-sheet-url: { value } ' ) return value def _report_issues ( self ) -> None : \"\"\"Report issues.\"\"\" self . xlsx_helper . report_issues ()","title":"XlsxToOscalProfile"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_profile/#trestle.tasks.xlsx_to_oscal_profile.XlsxToOscalProfile.name","text":"","title":"name"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_profile/#trestle.tasks.xlsx_to_oscal_profile.XlsxToOscalProfile-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_profile/#trestle.tasks.xlsx_to_oscal_profile.XlsxToOscalProfile.__init__","text":"Initialize trestle task xlsx-to-oscal-profile. Parameters: Name Type Description Default config_object Optional[configparser.SectionProxy] Config section associated with the task. required Source code in trestle/tasks/xlsx_to_oscal_profile.py def __init__ ( self , config_object : Optional [ configparser . SectionProxy ]) -> None : \"\"\" Initialize trestle task xlsx-to-oscal-profile. Args: config_object: Config section associated with the task. \"\"\" super () . __init__ ( config_object ) self . xlsx_helper = XlsxHelper () self . _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat ()","title":"__init__()"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_profile/#trestle.tasks.xlsx_to_oscal_profile.XlsxToOscalProfile.execute","text":"Provide an executed outcome. Source code in trestle/tasks/xlsx_to_oscal_profile.py def execute ( self ) -> TaskOutcome : \"\"\"Provide an executed outcome.\"\"\" try : return self . _execute () except Exception : logger . info ( traceback . format_exc ()) return TaskOutcome ( 'failure' )","title":"execute()"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_profile/#trestle.tasks.xlsx_to_oscal_profile.XlsxToOscalProfile.print_info","text":"Print the help string. Source code in trestle/tasks/xlsx_to_oscal_profile.py def print_info ( self ) -> None : \"\"\"Print the help string.\"\"\" self . xlsx_helper . print_info ( self . name , 'profile' )","title":"print_info()"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_profile/#trestle.tasks.xlsx_to_oscal_profile.XlsxToOscalProfile.set_timestamp","text":"Set the timestamp. Source code in trestle/tasks/xlsx_to_oscal_profile.py def set_timestamp ( self , timestamp : str ) -> None : \"\"\"Set the timestamp.\"\"\" self . _timestamp = timestamp","title":"set_timestamp()"},{"location":"api_reference/trestle.tasks.xlsx_to_oscal_profile/#trestle.tasks.xlsx_to_oscal_profile.XlsxToOscalProfile.simulate","text":"Provide a simulated outcome. Source code in trestle/tasks/xlsx_to_oscal_profile.py def simulate ( self ) -> TaskOutcome : \"\"\"Provide a simulated outcome.\"\"\" return TaskOutcome ( 'simulated-success' ) handler: python","title":"simulate()"},{"location":"api_reference/trestle.transforms.implementations.osco/","text":"trestle.transforms.implementations.osco \u00a4 Facilitate OSCAL-OSCO transformation. logger \u00a4 Classes \u00a4 ComplianceOperatorResult \u00a4 Represents one result of OSCO data. Source code in trestle/transforms/implementations/osco.py class ComplianceOperatorResult (): \"\"\"Represents one result of OSCO data.\"\"\" def __init__ ( self , osco_xml : str ) -> None : \"\"\"Initialize given specified args.\"\"\" self . osco_xml = osco_xml def _get_version ( self , root : Element ) -> str : \"\"\"Extract version from the XML.\"\"\" value = None for key , val in root . attrib . items (): if key == 'version' : value = val break return value def _get_id ( self , root : Element ) -> str : \"\"\"Extract id from the XML.\"\"\" value = None for key , val in root . attrib . items (): if key == 'id' : value = val break return value def _get_target ( self , root : Element ) -> str : \"\"\"Extract target from the XML.\"\"\" value = None for lev1 in root : tag = _remove_namespace ( lev1 . tag ) if tag == 'target' : value = root . find ( lev1 . tag ) . text break return value def _get_target_type ( self , root : Element ) -> str : \"\"\"Extract target_type from the XML.\"\"\" value = None benchmark_href = self . _get_benchmark_href ( root ) if benchmark_href is not None and '-' in benchmark_href : value = benchmark_href . split ( '-' )[ 1 ] return value def _get_benchmark ( self , root : Element , kw ) -> str : \"\"\"Extract benchmark from the XML.\"\"\" value = None for lev1 in root : tag = _remove_namespace ( lev1 . tag ) if tag == 'benchmark' : value = lev1 . get ( kw ) break return value def _get_benchmark_href ( self , root : Element ) -> str : \"\"\"Extract benchmark.href from the XML.\"\"\" return self . _get_benchmark ( root , 'href' ) def _get_benchmark_id ( self , root : Element ) -> str : \"\"\"Extract benchmark.id from the XML.\"\"\" return self . _get_benchmark ( root , 'id' ) def _get_fact ( self , lev1 : Element , kw : str ) -> str : \"\"\"Extract fact from the XML.\"\"\" value = None for lev2 in lev1 : tag = _remove_namespace ( lev2 . tag ) if tag == 'fact' : name = lev2 . get ( 'name' ) if name == kw : value = lev2 . text break return value def _get_scanner_name ( self , root : Element ) -> str : \"\"\"Extract scanner:name from the XML.\"\"\" value = None for lev1 in root : tag = _remove_namespace ( lev1 . tag ) if tag == 'target-facts' : value = self . _get_fact ( lev1 , 'urn:xccdf:fact:scanner:name' ) break return value def _get_scanner_version ( self , root : Element ) -> str : \"\"\"Extract scanner:version from the XML.\"\"\" value = None for lev1 in root : tag = _remove_namespace ( lev1 . tag ) if tag == 'target-facts' : value = self . _get_fact ( lev1 , 'urn:xccdf:fact:scanner:version' ) break return value def _get_host_name ( self , root : Element ) -> str : \"\"\"Extract asset:identifier:host_name from the XML.\"\"\" value = None for lev1 in root : tag = _remove_namespace ( lev1 . tag ) if tag == 'target-facts' : value = self . _get_fact ( lev1 , 'urn:xccdf:fact:asset:identifier:host_name' ) break return value def _get_result ( self , lev1 : Element ) -> str : \"\"\"Extract result from the XML.\"\"\" value = None for lev2 in lev1 : tag = _remove_namespace ( lev2 . tag ) if tag == 'result' : value = lev1 . find ( lev2 . tag ) . text break return value def _parse_xml ( self ) -> Iterator [ RuleUse ]: \"\"\"Parse the stringified XML.\"\"\" results = self . osco_xml root = ElementTree . fromstring ( results , forbid_dtd = True ) version = self . _get_version ( root ) id_ = self . _get_id ( root ) target = self . _get_target ( root ) target_type = self . _get_target_type ( root ) host_name = self . _get_host_name ( root ) benchmark_href = self . _get_benchmark_href ( root ) benchmark_id = self . _get_benchmark_id ( root ) scanner_name = self . _get_scanner_name ( root ) scanner_version = self . _get_scanner_version ( root ) for lev1 in root : tag = _remove_namespace ( lev1 . tag ) if tag == 'rule-result' : idref = lev1 . get ( 'idref' ) time = lev1 . get ( 'time' ) severity = lev1 . get ( 'severity' ) weight = lev1 . get ( 'weight' ) result = self . _get_result ( lev1 ) args = { 'id_' : id_ , 'target' : target , 'target_type' : target_type , 'host_name' : host_name , 'benchmark_href' : benchmark_href , 'benchmark_id' : benchmark_id , 'scanner_name' : scanner_name , 'scanner_version' : scanner_version , 'idref' : idref , 'version' : version , 'time' : time , 'result' : result , 'severity' : severity , 'weight' : weight } rule_use = RuleUse ( args ) yield rule_use def rule_use_generator ( self ) -> Iterator [ RuleUse ]: \"\"\"Generate RuleUses by way of parsing the embedded XML.\"\"\" return self . _parse_xml () Methods \u00a4 __init__ ( self , osco_xml ) special \u00a4 Initialize given specified args. Source code in trestle/transforms/implementations/osco.py def __init__ ( self , osco_xml : str ) -> None : \"\"\"Initialize given specified args.\"\"\" self . osco_xml = osco_xml rule_use_generator ( self ) \u00a4 Generate RuleUses by way of parsing the embedded XML. Source code in trestle/transforms/implementations/osco.py def rule_use_generator ( self ) -> Iterator [ RuleUse ]: \"\"\"Generate RuleUses by way of parsing the embedded XML.\"\"\" return self . _parse_xml () OscalProfileToOscoProfileTransformer ( FromOscalTransformer ) \u00a4 Interface for Oscal Profile to Osco Profile transformer. Source code in trestle/transforms/implementations/osco.py class OscalProfileToOscoProfileTransformer ( FromOscalTransformer ): \"\"\"Interface for Oscal Profile to Osco Profile transformer.\"\"\" def __init__ ( self , extends = 'ocp4-cis-node' , api_version = 'compliance.openshift.io/v1alpha1' , kind = 'TailoredProfile' , name = 'customized-tailored-profile' , namespace = 'openshift-compliance' , ) -> None : \"\"\"Initialize.\"\"\" self . _extends = extends self . _api_version = api_version self . _kind = kind self . _name = name self . _namespace = namespace def transform ( self , profile : Profile ) -> str : \"\"\"Transform the Profile into a OSCO yaml.\"\"\" self . _profile = profile self . _osco_version = self . _get_normalized_version ( 'osco_version' , '0.1.46' ) # set values set_values = self . _get_set_values () # spec if self . _osco_version < ( 0 , 1 , 40 ): # for versions prior to 0.1.40, exclude 'description' spec = { 'extends' : self . _get_metadata_prop_value ( 'base_profile_mnemonic' , self . _extends ), 'title' : self . _profile . metadata . title , 'setValues' : set_values , } else : # for versions 0.1.40 and beyond, include 'description' spec = { 'description' : self . _get_metadata_prop_value ( 'profile_mnemonic' , self . _name ), 'extends' : self . _get_metadata_prop_value ( 'base_profile_mnemonic' , self . _extends ), 'title' : self . _profile . metadata . title , 'setValues' : set_values , } disable_rules = self . _get_disable_rules () if disable_rules : spec [ 'disableRules' ] = disable_rules # yaml data ydata = { 'apiVersion' : self . _api_version , 'kind' : self . _kind , 'metadata' : { 'name' : self . _get_metadata_prop_value ( 'profile_mnemonic' , self . _name ), 'namespace' : self . _namespace , }, 'spec' : spec , } return json . dumps ( ydata ) def _get_normalized_version ( self , prop_name , prop_default ) -> Tuple [ int , int , int ]: \"\"\"Get normalized version. Normalize the \"x.y.z\" string value to an integer: 1,000,000*x + 1,000*y + z. \"\"\" try : vparts = self . _get_metadata_prop_value ( prop_name , prop_default ) . split ( '.' ) normalized_version = ( int ( vparts [ 0 ]), int ( vparts [ 1 ]), int ( vparts [ 2 ])) except Exception : logger . warning ( f 'metadata prop name= { prop_name } value error' ) vparts = prop_default . split ( '.' ) normalized_version = ( int ( vparts [ 0 ]), int ( vparts [ 1 ]), int ( vparts [ 2 ])) return normalized_version def _get_set_values ( self ) -> List [ Dict ]: \"\"\"Extract set_paramater name/value pairs from profile.\"\"\" set_values = [] # for check versions prior to 0.1.59 include parameters # for later versions parameters should not be specified, caveat emptor if self . _profile . modify is not None : for set_parameter in as_list ( self . _profile . modify . set_parameters ): name = self . _format_osco_rule_name ( set_parameter . param_id ) parameter_value = set_parameter . values [ 0 ] value = parameter_value . __root__ rationale = self . _get_rationale_for_set_value () set_value = { 'name' : name , 'value' : value , 'rationale' : rationale } set_values . append ( set_value ) return set_values def _format_osco_rule_name ( self , name : str ) -> str : \"\"\"Format for OSCO. 1. remove prefix xccdf_org.ssgproject.content_rule_ 2. change underscores to dashes 3. add prefix ocp4- \"\"\" normalized_name = name . replace ( 'xccdf_org.ssgproject.content_rule_' , '' ) . replace ( '_' , '-' ) if not normalized_name . startswith ( 'ocp4-' ): normalized_name = f 'ocp4- { normalized_name } ' return normalized_name def _get_metadata_prop_value ( self , name : str , default_ : str ) -> str : \"\"\"Extract metadata prop or else default if not present.\"\"\" for prop in as_list ( self . _profile . metadata . props ): if prop . name == name : return prop . value logger . info ( f 'using default: { name } = { default_ } ' ) return default_ def _get_disable_rules ( self ) -> List [ str ]: \"\"\"Extract disabled rules.\"\"\" value = [] for _import in as_list ( self . _profile . imports ): for control in as_list ( _import . exclude_controls ): self . _add_disable_rules_for_control ( value , control ) return value def _add_disable_rules_for_control ( self , value , control ): \"\"\"Extract disabled rules for control.\"\"\" for with_id in as_list ( control . with_ids ): name = self . _format_osco_rule_name ( with_id . __root__ ) rationale = self . _get_rationale_for_disable_rule () entry = { 'name' : name , 'rationale' : rationale } value . append ( entry ) def _get_rationale_for_set_value ( self ) -> str : \"\"\"Rationale for set value.\"\"\" return 'not determinable from specification' def _get_rationale_for_disable_rule ( self ) -> str : \"\"\"Rationale for disable rule.\"\"\" return 'not determinable from specification' Methods \u00a4 __init__ ( self , extends = 'ocp4-cis-node' , api_version = 'compliance.openshift.io/v1alpha1' , kind = 'TailoredProfile' , name = 'customized-tailored-profile' , namespace = 'openshift-compliance' ) special \u00a4 Initialize. Source code in trestle/transforms/implementations/osco.py def __init__ ( self , extends = 'ocp4-cis-node' , api_version = 'compliance.openshift.io/v1alpha1' , kind = 'TailoredProfile' , name = 'customized-tailored-profile' , namespace = 'openshift-compliance' , ) -> None : \"\"\"Initialize.\"\"\" self . _extends = extends self . _api_version = api_version self . _kind = kind self . _name = name self . _namespace = namespace transform ( self , profile ) \u00a4 Transform the Profile into a OSCO yaml. Source code in trestle/transforms/implementations/osco.py def transform ( self , profile : Profile ) -> str : \"\"\"Transform the Profile into a OSCO yaml.\"\"\" self . _profile = profile self . _osco_version = self . _get_normalized_version ( 'osco_version' , '0.1.46' ) # set values set_values = self . _get_set_values () # spec if self . _osco_version < ( 0 , 1 , 40 ): # for versions prior to 0.1.40, exclude 'description' spec = { 'extends' : self . _get_metadata_prop_value ( 'base_profile_mnemonic' , self . _extends ), 'title' : self . _profile . metadata . title , 'setValues' : set_values , } else : # for versions 0.1.40 and beyond, include 'description' spec = { 'description' : self . _get_metadata_prop_value ( 'profile_mnemonic' , self . _name ), 'extends' : self . _get_metadata_prop_value ( 'base_profile_mnemonic' , self . _extends ), 'title' : self . _profile . metadata . title , 'setValues' : set_values , } disable_rules = self . _get_disable_rules () if disable_rules : spec [ 'disableRules' ] = disable_rules # yaml data ydata = { 'apiVersion' : self . _api_version , 'kind' : self . _kind , 'metadata' : { 'name' : self . _get_metadata_prop_value ( 'profile_mnemonic' , self . _name ), 'namespace' : self . _namespace , }, 'spec' : spec , } return json . dumps ( ydata ) OscalResultsFactory \u00a4 Build OSCO OSCAL entities. Source code in trestle/transforms/implementations/osco.py class OscalResultsFactory (): \"\"\"Build OSCO OSCAL entities.\"\"\" default_timestamp = ResultsTransformer . get_timestamp () def __init__ ( self , timestamp : str = default_timestamp , checking : bool = False ) -> None : \"\"\"Initialize.\"\"\" self . _timestamp = timestamp self . _observation_list : List [ Observation ] = [] self . _result_properties_list : List [ Property ] = [] self . _component_map : Dict [ str , SystemComponent ] = {} self . _inventory_map : Dict [ str , InventoryItem ] = {} self . _ns = 'https://ibm.github.io/compliance-trestle/schemas/oscal/ar/osco' self . _checking = checking @property def components ( self ) -> List [ SystemComponent ]: \"\"\"OSCAL components.\"\"\" return list ( self . _component_map . values ()) @property def control_selections ( self ) -> List [ ControlSelection ]: \"\"\"OSCAL control selections.\"\"\" prop = [] prop . append ( ControlSelection ()) return prop @property def inventory ( self ) -> ValuesView [ InventoryItem ]: \"\"\"OSCAL inventory.\"\"\" return self . _inventory_map . values () @property def local_definitions ( self ) -> LocalDefinitions1 : \"\"\"OSCAL local definitions.\"\"\" prop = LocalDefinitions1 () prop . components = self . components prop . inventory_items = list ( self . inventory ) return prop @property def observations ( self ) -> List [ Observation ]: \"\"\"OSCAL observations.\"\"\" return self . _observation_list @property def result_properties ( self ) -> List [ Property ]: \"\"\"OSCAL result properties.\"\"\" return self . _result_properties_list @property def reviewed_controls ( self ) -> ReviewedControls : \"\"\"OSCAL reviewed controls.\"\"\" prop = ReviewedControls ( control_selections = self . control_selections ) return prop @property def result ( self ) -> Result : \"\"\"OSCAL result.\"\"\" # perform result properties aggregation if self . observations : self . _result_properties_list = TransformerHelper () . remove_common_observation_properties ( self . observations ) # produce result prop = Result ( uuid = str ( uuid . uuid4 ()), title = 'OpenShift Compliance Operator' , description = 'OpenShift Compliance Operator Scan Results' , start = self . _timestamp , end = self . _timestamp , reviewed_controls = self . reviewed_controls , ) if self . result_properties : prop . props = self . result_properties if self . inventory : prop . local_definitions = self . local_definitions if self . observations : prop . observations = self . observations return prop @property def analysis ( self ) -> List [ str ]: \"\"\"OSCAL statistics.\"\"\" analysis = [] analysis . append ( f 'inventory: { len ( self . inventory ) } ' ) analysis . append ( f 'observations: { len ( self . observations ) } ' ) return analysis def _component_extract ( self , rule_use : RuleUse ) -> None : \"\"\"Extract component from RuleUse.\"\"\" _type = 'Service' _title = f 'Red Hat OpenShift Kubernetes Service Compliance Operator for { rule_use . target_type } ' _desc = _title for component in self . _component_map . values (): if component . type == _type and component . title == _title and component . description == _desc : return component_ref = str ( uuid . uuid4 ()) status = Status1 ( state = 'operational' ) component = SystemComponent ( uuid = component_ref , type = _type , title = _title , description = _desc , status = status ) self . _component_map [ component_ref ] = component def _get_component_ref ( self , rule_use : RuleUse ) -> str : \"\"\"Get component reference for specified RuleUse.\"\"\" uuid = None for component_ref , component in self . _component_map . items (): if component . title . endswith ( rule_use . target_type ): uuid = component_ref return uuid def _inventory_extract ( self , rule_use : RuleUse ) -> None : \"\"\"Extract inventory from RuleUse.\"\"\" if rule_use . inventory_key in self . _inventory_map : return inventory = InventoryItem ( uuid = str ( uuid . uuid4 ()), description = 'inventory' ) inventory . props = self . _get_inventory_properties ( rule_use ) inventory . implemented_components = [ ImplementedComponent ( component_uuid = self . _get_component_ref ( rule_use ))] self . _inventory_map [ rule_use . inventory_key ] = inventory def _get_inventory_properties ( self , rule_use ): \"\"\"Get inventory properties.\"\"\" if self . _checking : return self . _get_inventory_properties_checked ( rule_use ) else : return self . _get_inventory_properties_unchecked ( rule_use ) def _get_inventory_properties_checked ( self , rule_use ): \"\"\"Get inventory properties, with checking.\"\"\" props = [] if rule_use . host_name is None : props . append ( Property ( name = 'target' , value = rule_use . target , ns = self . _ns , class_ = 'scc_inventory_item_id' )) props . append ( Property ( name = 'target_type' , value = rule_use . target_type , ns = self . _ns )) else : props . append ( Property ( name = 'target' , value = rule_use . target , ns = self . _ns )) props . append ( Property ( name = 'target_type' , value = rule_use . target_type , ns = self . _ns )) props . append ( Property ( name = 'host_name' , value = rule_use . host_name , ns = self . _ns , class_ = 'scc_inventory_item_id' ) ) return props def _get_inventory_properties_unchecked ( self , rule_use ): \"\"\"Get observation properties, without checking.\"\"\" props = [] if rule_use . host_name is None : props . append ( Property . construct ( name = 'target' , value = rule_use . target , ns = self . _ns , class_ = 'scc_inventory_item_id' ) ) props . append ( Property . construct ( name = 'target_type' , value = rule_use . target_type , ns = self . _ns )) else : props . append ( Property . construct ( name = 'target' , value = rule_use . target , ns = self . _ns )) props . append ( Property . construct ( name = 'target_type' , value = rule_use . target_type , ns = self . _ns )) props . append ( Property . construct ( name = 'host_name' , value = rule_use . host_name , ns = self . _ns , class_ = 'scc_inventory_item_id' ) ) return props def _get_inventory_ref ( self , rule_use : RuleUse ) -> str : \"\"\"Get inventory reference for specified RuleUse.\"\"\" return self . _inventory_map [ rule_use . inventory_key ] . uuid def _observation_extract ( self , rule_use : RuleUse ) -> None : \"\"\"Extract observation from RuleUse.\"\"\" observation = Observation ( uuid = str ( uuid . uuid4 ()), description = rule_use . idref , methods = [ 'TEST-AUTOMATED' ], collected = self . _timestamp ) subject_reference = SubjectReference ( subject_uuid = self . _get_inventory_ref ( rule_use ), type = 'inventory-item' ) observation . subjects = [ subject_reference ] observation . props = self . _get_observation_properties ( rule_use ) self . _observation_list . append ( observation ) rule_use . observation = observation def _get_observation_properties ( self , rule_use ): \"\"\"Get observation properties.\"\"\" if self . _checking : return self . _get_observation_properties_checked ( rule_use ) else : return self . _get_observation_properties_unchecked ( rule_use ) def _get_observation_properties_checked ( self , rule_use ): \"\"\"Get observation properties, with checking.\"\"\" props = [] props . append ( Property ( name = 'scanner_name' , value = rule_use . scanner_name , ns = self . _ns )) props . append ( Property ( name = 'scanner_version' , value = rule_use . scanner_version , ns = self . _ns )) props . append ( Property ( name = 'idref' , value = rule_use . idref , ns = self . _ns , class_ = 'scc_check_name_id' )) props . append ( Property ( name = 'version' , value = rule_use . version , ns = self . _ns , class_ = 'scc_check_version' )) props . append ( Property ( name = 'result' , value = rule_use . result , ns = self . _ns , class_ = 'scc_result' )) props . append ( Property ( name = 'time' , value = rule_use . time , ns = self . _ns , class_ = 'scc_timestamp' )) props . append ( Property ( name = 'severity' , value = rule_use . severity , ns = self . _ns , class_ = 'scc_check_severity' )) props . append ( Property ( name = 'weight' , value = rule_use . weight , ns = self . _ns )) props . append ( Property ( name = 'benchmark_id' , value = rule_use . benchmark_id , ns = self . _ns )) props . append ( Property ( name = 'benchmark_href' , value = rule_use . benchmark_href , ns = self . _ns )) props . append ( Property ( name = 'id' , value = rule_use . id_ , ns = self . _ns , class_ = 'scc_predefined_profile' )) return props def _get_observation_properties_unchecked ( self , rule_use ): \"\"\"Get observation properties, without checking.\"\"\" props = [] props . append ( Property . construct ( name = 'scanner_name' , value = rule_use . scanner_name , ns = self . _ns )) props . append ( Property . construct ( name = 'scanner_version' , value = rule_use . scanner_version , ns = self . _ns )) props . append ( Property . construct ( name = 'idref' , value = rule_use . idref , ns = self . _ns , class_ = 'scc_check_name_id' )) props . append ( Property . construct ( name = 'version' , value = rule_use . version , ns = self . _ns , class_ = 'scc_check_version' ) ) props . append ( Property . construct ( name = 'result' , value = rule_use . result , ns = self . _ns , class_ = 'scc_result' )) props . append ( Property . construct ( name = 'time' , value = rule_use . time , ns = self . _ns , class_ = 'scc_timestamp' )) props . append ( Property . construct ( name = 'severity' , value = rule_use . severity , ns = self . _ns , class_ = 'scc_check_severity' ) ) props . append ( Property . construct ( name = 'weight' , value = rule_use . weight , ns = self . _ns )) props . append ( Property . construct ( name = 'benchmark_id' , value = rule_use . benchmark_id , ns = self . _ns )) props . append ( Property . construct ( name = 'benchmark_href' , value = rule_use . benchmark_href , ns = self . _ns )) props . append ( Property . construct ( name = 'id' , value = rule_use . id_ , ns = self . _ns , class_ = 'scc_predefined_profile' )) return props def _process ( self , co_result : ComplianceOperatorResult ) -> None : \"\"\"Process ingested data.\"\"\" rule_use_generator = co_result . rule_use_generator () for rule_use in rule_use_generator : self . _component_extract ( rule_use ) self . _inventory_extract ( rule_use ) self . _observation_extract ( rule_use ) def ingest ( self , osco_data : Dict [ str , Any ]) -> None : \"\"\"Process OSCO json.\"\"\" if 'data' not in osco_data . keys (): return if 'results' not in osco_data [ 'data' ]: return results = osco_data [ 'data' ][ 'results' ] self . ingest_xml ( results ) def ingest_xml ( self , osco_xml : str ) -> None : \"\"\"Process OSCO xml.\"\"\" if not osco_xml . startswith ( '<?xml' ): osco_xml = bz2 . decompress ( base64 . b64decode ( osco_xml )) co_result = ComplianceOperatorResult ( osco_xml ) self . _process ( co_result ) Attributes \u00a4 analysis : List [ str ] property readonly \u00a4 OSCAL statistics. components : List [ trestle . oscal . assessment_results . SystemComponent ] property readonly \u00a4 OSCAL components. control_selections : List [ trestle . oscal . assessment_results . ControlSelection ] property readonly \u00a4 OSCAL control selections. default_timestamp \u00a4 inventory : ValuesView [ trestle . oscal . common . InventoryItem ] property readonly \u00a4 OSCAL inventory. local_definitions : LocalDefinitions1 property readonly \u00a4 OSCAL local definitions. observations : List [ trestle . oscal . assessment_results . Observation ] property readonly \u00a4 OSCAL observations. result : Result property readonly \u00a4 OSCAL result. result_properties : List [ trestle . oscal . common . Property ] property readonly \u00a4 OSCAL result properties. reviewed_controls : ReviewedControls property readonly \u00a4 OSCAL reviewed controls. Methods \u00a4 __init__ ( self , timestamp = '2022-04-27T04:12:26+00:00' , checking = False ) special \u00a4 Initialize. Source code in trestle/transforms/implementations/osco.py def __init__ ( self , timestamp : str = default_timestamp , checking : bool = False ) -> None : \"\"\"Initialize.\"\"\" self . _timestamp = timestamp self . _observation_list : List [ Observation ] = [] self . _result_properties_list : List [ Property ] = [] self . _component_map : Dict [ str , SystemComponent ] = {} self . _inventory_map : Dict [ str , InventoryItem ] = {} self . _ns = 'https://ibm.github.io/compliance-trestle/schemas/oscal/ar/osco' self . _checking = checking ingest ( self , osco_data ) \u00a4 Process OSCO json. Source code in trestle/transforms/implementations/osco.py def ingest ( self , osco_data : Dict [ str , Any ]) -> None : \"\"\"Process OSCO json.\"\"\" if 'data' not in osco_data . keys (): return if 'results' not in osco_data [ 'data' ]: return results = osco_data [ 'data' ][ 'results' ] self . ingest_xml ( results ) ingest_xml ( self , osco_xml ) \u00a4 Process OSCO xml. Source code in trestle/transforms/implementations/osco.py def ingest_xml ( self , osco_xml : str ) -> None : \"\"\"Process OSCO xml.\"\"\" if not osco_xml . startswith ( '<?xml' ): osco_xml = bz2 . decompress ( base64 . b64decode ( osco_xml )) co_result = ComplianceOperatorResult ( osco_xml ) self . _process ( co_result ) OscoResultToOscalARTransformer ( ResultsTransformer ) \u00a4 Interface for Osco transformer. Source code in trestle/transforms/implementations/osco.py class OscoResultToOscalARTransformer ( ResultsTransformer ): \"\"\"Interface for Osco transformer.\"\"\" def __init__ ( self ) -> None : \"\"\"Initialize.\"\"\" self . _modes = {} @property def analysis ( self ) -> List [ str ]: \"\"\"Analysis.\"\"\" return self . _results_factory . analysis @property def checking ( self ): \"\"\"Return checking.\"\"\" return self . _modes . get ( 'checking' , False ) def set_modes ( self , modes : Dict [ str , Any ]) -> None : \"\"\"Keep modes info.\"\"\" if modes is not None : self . _modes = modes def transform ( self , blob : str ) -> Results : \"\"\"Transform the blob into a Results. The expected blob is a string that is one of: - data from OpenShift Compliance Operator (json, yaml, xml) - data from Auditree OSCO fetcher/check (json) \"\"\" results = None self . _results_factory = OscalResultsFactory ( self . get_timestamp (), self . checking ) if results is None : results = self . _ingest_xml ( blob ) if results is None : results = self . _ingest_json ( blob ) if results is None : results = self . _ingest_yaml ( blob ) return results def _ingest_xml ( self , blob : str ) -> Results : \"\"\"Ingest xml data.\"\"\" # ?xml data if blob . startswith ( '<?xml' ): resource = blob self . _results_factory . ingest_xml ( resource ) else : return None results = Results () results . __root__ . append ( self . _results_factory . result ) return results def _ingest_json ( self , blob : str ) -> Results : \"\"\"Ingest json data.\"\"\" try : # ? configmaps or auditree data jdata = json . loads ( blob ) # https://docs.openshift.com/container-platform/3.7/rest_api/api/v1.ConfigMap.html#Get-api-v1-namespaces-namespace-configmaps-name if 'kind' in jdata . keys () and jdata [ 'kind' ] == 'ConfigMapList' and 'items' in jdata . keys (): items = jdata [ 'items' ] for item in items : if 'data' in item . keys (): data = item [ 'data' ] if 'results' in data : resource = item self . _results_factory . ingest ( resource ) # https://github.com/ComplianceAsCode/auditree-arboretum/blob/main/arboretum/kubernetes/fetchers/fetch_cluster_resource.py else : for key in jdata . keys (): for group in jdata [ key ]: for cluster in jdata [ key ][ group ]: if 'resources' in cluster : for resource in cluster [ 'resources' ]: self . _results_factory . ingest ( resource ) except json . decoder . JSONDecodeError : return None results = Results () results . __root__ . append ( self . _results_factory . result ) return results def _ingest_yaml ( self , blob : str ) -> Results : \"\"\"Ingest yaml data.\"\"\" try : # ? yaml data yaml = YAML ( typ = 'safe' ) resource = yaml . load ( blob ) self . _results_factory . ingest ( resource ) except Exception as e : raise e results = Results () results . __root__ . append ( self . _results_factory . result ) return results Attributes \u00a4 analysis : List [ str ] property readonly \u00a4 Analysis. checking property readonly \u00a4 Return checking. Methods \u00a4 __init__ ( self ) special \u00a4 Initialize. Source code in trestle/transforms/implementations/osco.py def __init__ ( self ) -> None : \"\"\"Initialize.\"\"\" self . _modes = {} set_modes ( self , modes ) \u00a4 Keep modes info. Source code in trestle/transforms/implementations/osco.py def set_modes ( self , modes : Dict [ str , Any ]) -> None : \"\"\"Keep modes info.\"\"\" if modes is not None : self . _modes = modes transform ( self , blob ) \u00a4 Transform the blob into a Results. The expected blob is a string that is one of: - data from OpenShift Compliance Operator (json, yaml, xml) - data from Auditree OSCO fetcher/check (json) Source code in trestle/transforms/implementations/osco.py def transform ( self , blob : str ) -> Results : \"\"\"Transform the blob into a Results. The expected blob is a string that is one of: - data from OpenShift Compliance Operator (json, yaml, xml) - data from Auditree OSCO fetcher/check (json) \"\"\" results = None self . _results_factory = OscalResultsFactory ( self . get_timestamp (), self . checking ) if results is None : results = self . _ingest_xml ( blob ) if results is None : results = self . _ingest_json ( blob ) if results is None : results = self . _ingest_yaml ( blob ) return results OscoTransformer ( OscoResultToOscalARTransformer ) \u00a4 Legacy class name. Source code in trestle/transforms/implementations/osco.py class OscoTransformer ( OscoResultToOscalARTransformer ): \"\"\"Legacy class name.\"\"\" RuleUse \u00a4 Represents one rule of OSCO data. Source code in trestle/transforms/implementations/osco.py class RuleUse (): \"\"\"Represents one rule of OSCO data.\"\"\" def __init__ ( self , args : Dict [ str , str ]) -> None : \"\"\"Initialize given specified args.\"\"\" self . id_ = args [ 'id_' ] self . target = args [ 'target' ] self . target_type = args [ 'target_type' ] self . host_name = args [ 'host_name' ] self . benchmark_href = args [ 'benchmark_href' ] self . benchmark_id = args [ 'benchmark_id' ] self . scanner_name = args [ 'scanner_name' ] self . scanner_version = args [ 'scanner_version' ] self . idref = args [ 'idref' ] self . version = args [ 'version' ] self . time = args [ 'time' ] self . result = args [ 'result' ] self . severity = args [ 'severity' ] self . weight = args [ 'weight' ] @property def inventory_key ( self ): \"\"\"Derive inventory key.\"\"\" if self . host_name is None : # OpenScap 1.3.3 rval = self . target + ':' + self . target_type else : # OpenScap 1.3.5 rval = self . host_name + ':' + self . target_type return rval Attributes \u00a4 inventory_key property readonly \u00a4 Derive inventory key. Methods \u00a4 __init__ ( self , args ) special \u00a4 Initialize given specified args. Source code in trestle/transforms/implementations/osco.py def __init__ ( self , args : Dict [ str , str ]) -> None : \"\"\"Initialize given specified args.\"\"\" self . id_ = args [ 'id_' ] self . target = args [ 'target' ] self . target_type = args [ 'target_type' ] self . host_name = args [ 'host_name' ] self . benchmark_href = args [ 'benchmark_href' ] self . benchmark_id = args [ 'benchmark_id' ] self . scanner_name = args [ 'scanner_name' ] self . scanner_version = args [ 'scanner_version' ] self . idref = args [ 'idref' ] self . version = args [ 'version' ] self . time = args [ 'time' ] self . result = args [ 'result' ] self . severity = args [ 'severity' ] self . weight = args [ 'weight' ] handler: python","title":"osco"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco","text":"Facilitate OSCAL-OSCO transformation.","title":"osco"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.logger","text":"","title":"logger"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.ComplianceOperatorResult","text":"Represents one result of OSCO data. Source code in trestle/transforms/implementations/osco.py class ComplianceOperatorResult (): \"\"\"Represents one result of OSCO data.\"\"\" def __init__ ( self , osco_xml : str ) -> None : \"\"\"Initialize given specified args.\"\"\" self . osco_xml = osco_xml def _get_version ( self , root : Element ) -> str : \"\"\"Extract version from the XML.\"\"\" value = None for key , val in root . attrib . items (): if key == 'version' : value = val break return value def _get_id ( self , root : Element ) -> str : \"\"\"Extract id from the XML.\"\"\" value = None for key , val in root . attrib . items (): if key == 'id' : value = val break return value def _get_target ( self , root : Element ) -> str : \"\"\"Extract target from the XML.\"\"\" value = None for lev1 in root : tag = _remove_namespace ( lev1 . tag ) if tag == 'target' : value = root . find ( lev1 . tag ) . text break return value def _get_target_type ( self , root : Element ) -> str : \"\"\"Extract target_type from the XML.\"\"\" value = None benchmark_href = self . _get_benchmark_href ( root ) if benchmark_href is not None and '-' in benchmark_href : value = benchmark_href . split ( '-' )[ 1 ] return value def _get_benchmark ( self , root : Element , kw ) -> str : \"\"\"Extract benchmark from the XML.\"\"\" value = None for lev1 in root : tag = _remove_namespace ( lev1 . tag ) if tag == 'benchmark' : value = lev1 . get ( kw ) break return value def _get_benchmark_href ( self , root : Element ) -> str : \"\"\"Extract benchmark.href from the XML.\"\"\" return self . _get_benchmark ( root , 'href' ) def _get_benchmark_id ( self , root : Element ) -> str : \"\"\"Extract benchmark.id from the XML.\"\"\" return self . _get_benchmark ( root , 'id' ) def _get_fact ( self , lev1 : Element , kw : str ) -> str : \"\"\"Extract fact from the XML.\"\"\" value = None for lev2 in lev1 : tag = _remove_namespace ( lev2 . tag ) if tag == 'fact' : name = lev2 . get ( 'name' ) if name == kw : value = lev2 . text break return value def _get_scanner_name ( self , root : Element ) -> str : \"\"\"Extract scanner:name from the XML.\"\"\" value = None for lev1 in root : tag = _remove_namespace ( lev1 . tag ) if tag == 'target-facts' : value = self . _get_fact ( lev1 , 'urn:xccdf:fact:scanner:name' ) break return value def _get_scanner_version ( self , root : Element ) -> str : \"\"\"Extract scanner:version from the XML.\"\"\" value = None for lev1 in root : tag = _remove_namespace ( lev1 . tag ) if tag == 'target-facts' : value = self . _get_fact ( lev1 , 'urn:xccdf:fact:scanner:version' ) break return value def _get_host_name ( self , root : Element ) -> str : \"\"\"Extract asset:identifier:host_name from the XML.\"\"\" value = None for lev1 in root : tag = _remove_namespace ( lev1 . tag ) if tag == 'target-facts' : value = self . _get_fact ( lev1 , 'urn:xccdf:fact:asset:identifier:host_name' ) break return value def _get_result ( self , lev1 : Element ) -> str : \"\"\"Extract result from the XML.\"\"\" value = None for lev2 in lev1 : tag = _remove_namespace ( lev2 . tag ) if tag == 'result' : value = lev1 . find ( lev2 . tag ) . text break return value def _parse_xml ( self ) -> Iterator [ RuleUse ]: \"\"\"Parse the stringified XML.\"\"\" results = self . osco_xml root = ElementTree . fromstring ( results , forbid_dtd = True ) version = self . _get_version ( root ) id_ = self . _get_id ( root ) target = self . _get_target ( root ) target_type = self . _get_target_type ( root ) host_name = self . _get_host_name ( root ) benchmark_href = self . _get_benchmark_href ( root ) benchmark_id = self . _get_benchmark_id ( root ) scanner_name = self . _get_scanner_name ( root ) scanner_version = self . _get_scanner_version ( root ) for lev1 in root : tag = _remove_namespace ( lev1 . tag ) if tag == 'rule-result' : idref = lev1 . get ( 'idref' ) time = lev1 . get ( 'time' ) severity = lev1 . get ( 'severity' ) weight = lev1 . get ( 'weight' ) result = self . _get_result ( lev1 ) args = { 'id_' : id_ , 'target' : target , 'target_type' : target_type , 'host_name' : host_name , 'benchmark_href' : benchmark_href , 'benchmark_id' : benchmark_id , 'scanner_name' : scanner_name , 'scanner_version' : scanner_version , 'idref' : idref , 'version' : version , 'time' : time , 'result' : result , 'severity' : severity , 'weight' : weight } rule_use = RuleUse ( args ) yield rule_use def rule_use_generator ( self ) -> Iterator [ RuleUse ]: \"\"\"Generate RuleUses by way of parsing the embedded XML.\"\"\" return self . _parse_xml ()","title":"ComplianceOperatorResult"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.ComplianceOperatorResult-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.ComplianceOperatorResult.__init__","text":"Initialize given specified args. Source code in trestle/transforms/implementations/osco.py def __init__ ( self , osco_xml : str ) -> None : \"\"\"Initialize given specified args.\"\"\" self . osco_xml = osco_xml","title":"__init__()"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.ComplianceOperatorResult.rule_use_generator","text":"Generate RuleUses by way of parsing the embedded XML. Source code in trestle/transforms/implementations/osco.py def rule_use_generator ( self ) -> Iterator [ RuleUse ]: \"\"\"Generate RuleUses by way of parsing the embedded XML.\"\"\" return self . _parse_xml ()","title":"rule_use_generator()"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalProfileToOscoProfileTransformer","text":"Interface for Oscal Profile to Osco Profile transformer. Source code in trestle/transforms/implementations/osco.py class OscalProfileToOscoProfileTransformer ( FromOscalTransformer ): \"\"\"Interface for Oscal Profile to Osco Profile transformer.\"\"\" def __init__ ( self , extends = 'ocp4-cis-node' , api_version = 'compliance.openshift.io/v1alpha1' , kind = 'TailoredProfile' , name = 'customized-tailored-profile' , namespace = 'openshift-compliance' , ) -> None : \"\"\"Initialize.\"\"\" self . _extends = extends self . _api_version = api_version self . _kind = kind self . _name = name self . _namespace = namespace def transform ( self , profile : Profile ) -> str : \"\"\"Transform the Profile into a OSCO yaml.\"\"\" self . _profile = profile self . _osco_version = self . _get_normalized_version ( 'osco_version' , '0.1.46' ) # set values set_values = self . _get_set_values () # spec if self . _osco_version < ( 0 , 1 , 40 ): # for versions prior to 0.1.40, exclude 'description' spec = { 'extends' : self . _get_metadata_prop_value ( 'base_profile_mnemonic' , self . _extends ), 'title' : self . _profile . metadata . title , 'setValues' : set_values , } else : # for versions 0.1.40 and beyond, include 'description' spec = { 'description' : self . _get_metadata_prop_value ( 'profile_mnemonic' , self . _name ), 'extends' : self . _get_metadata_prop_value ( 'base_profile_mnemonic' , self . _extends ), 'title' : self . _profile . metadata . title , 'setValues' : set_values , } disable_rules = self . _get_disable_rules () if disable_rules : spec [ 'disableRules' ] = disable_rules # yaml data ydata = { 'apiVersion' : self . _api_version , 'kind' : self . _kind , 'metadata' : { 'name' : self . _get_metadata_prop_value ( 'profile_mnemonic' , self . _name ), 'namespace' : self . _namespace , }, 'spec' : spec , } return json . dumps ( ydata ) def _get_normalized_version ( self , prop_name , prop_default ) -> Tuple [ int , int , int ]: \"\"\"Get normalized version. Normalize the \"x.y.z\" string value to an integer: 1,000,000*x + 1,000*y + z. \"\"\" try : vparts = self . _get_metadata_prop_value ( prop_name , prop_default ) . split ( '.' ) normalized_version = ( int ( vparts [ 0 ]), int ( vparts [ 1 ]), int ( vparts [ 2 ])) except Exception : logger . warning ( f 'metadata prop name= { prop_name } value error' ) vparts = prop_default . split ( '.' ) normalized_version = ( int ( vparts [ 0 ]), int ( vparts [ 1 ]), int ( vparts [ 2 ])) return normalized_version def _get_set_values ( self ) -> List [ Dict ]: \"\"\"Extract set_paramater name/value pairs from profile.\"\"\" set_values = [] # for check versions prior to 0.1.59 include parameters # for later versions parameters should not be specified, caveat emptor if self . _profile . modify is not None : for set_parameter in as_list ( self . _profile . modify . set_parameters ): name = self . _format_osco_rule_name ( set_parameter . param_id ) parameter_value = set_parameter . values [ 0 ] value = parameter_value . __root__ rationale = self . _get_rationale_for_set_value () set_value = { 'name' : name , 'value' : value , 'rationale' : rationale } set_values . append ( set_value ) return set_values def _format_osco_rule_name ( self , name : str ) -> str : \"\"\"Format for OSCO. 1. remove prefix xccdf_org.ssgproject.content_rule_ 2. change underscores to dashes 3. add prefix ocp4- \"\"\" normalized_name = name . replace ( 'xccdf_org.ssgproject.content_rule_' , '' ) . replace ( '_' , '-' ) if not normalized_name . startswith ( 'ocp4-' ): normalized_name = f 'ocp4- { normalized_name } ' return normalized_name def _get_metadata_prop_value ( self , name : str , default_ : str ) -> str : \"\"\"Extract metadata prop or else default if not present.\"\"\" for prop in as_list ( self . _profile . metadata . props ): if prop . name == name : return prop . value logger . info ( f 'using default: { name } = { default_ } ' ) return default_ def _get_disable_rules ( self ) -> List [ str ]: \"\"\"Extract disabled rules.\"\"\" value = [] for _import in as_list ( self . _profile . imports ): for control in as_list ( _import . exclude_controls ): self . _add_disable_rules_for_control ( value , control ) return value def _add_disable_rules_for_control ( self , value , control ): \"\"\"Extract disabled rules for control.\"\"\" for with_id in as_list ( control . with_ids ): name = self . _format_osco_rule_name ( with_id . __root__ ) rationale = self . _get_rationale_for_disable_rule () entry = { 'name' : name , 'rationale' : rationale } value . append ( entry ) def _get_rationale_for_set_value ( self ) -> str : \"\"\"Rationale for set value.\"\"\" return 'not determinable from specification' def _get_rationale_for_disable_rule ( self ) -> str : \"\"\"Rationale for disable rule.\"\"\" return 'not determinable from specification'","title":"OscalProfileToOscoProfileTransformer"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalProfileToOscoProfileTransformer-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalProfileToOscoProfileTransformer.__init__","text":"Initialize. Source code in trestle/transforms/implementations/osco.py def __init__ ( self , extends = 'ocp4-cis-node' , api_version = 'compliance.openshift.io/v1alpha1' , kind = 'TailoredProfile' , name = 'customized-tailored-profile' , namespace = 'openshift-compliance' , ) -> None : \"\"\"Initialize.\"\"\" self . _extends = extends self . _api_version = api_version self . _kind = kind self . _name = name self . _namespace = namespace","title":"__init__()"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalProfileToOscoProfileTransformer.transform","text":"Transform the Profile into a OSCO yaml. Source code in trestle/transforms/implementations/osco.py def transform ( self , profile : Profile ) -> str : \"\"\"Transform the Profile into a OSCO yaml.\"\"\" self . _profile = profile self . _osco_version = self . _get_normalized_version ( 'osco_version' , '0.1.46' ) # set values set_values = self . _get_set_values () # spec if self . _osco_version < ( 0 , 1 , 40 ): # for versions prior to 0.1.40, exclude 'description' spec = { 'extends' : self . _get_metadata_prop_value ( 'base_profile_mnemonic' , self . _extends ), 'title' : self . _profile . metadata . title , 'setValues' : set_values , } else : # for versions 0.1.40 and beyond, include 'description' spec = { 'description' : self . _get_metadata_prop_value ( 'profile_mnemonic' , self . _name ), 'extends' : self . _get_metadata_prop_value ( 'base_profile_mnemonic' , self . _extends ), 'title' : self . _profile . metadata . title , 'setValues' : set_values , } disable_rules = self . _get_disable_rules () if disable_rules : spec [ 'disableRules' ] = disable_rules # yaml data ydata = { 'apiVersion' : self . _api_version , 'kind' : self . _kind , 'metadata' : { 'name' : self . _get_metadata_prop_value ( 'profile_mnemonic' , self . _name ), 'namespace' : self . _namespace , }, 'spec' : spec , } return json . dumps ( ydata )","title":"transform()"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalResultsFactory","text":"Build OSCO OSCAL entities. Source code in trestle/transforms/implementations/osco.py class OscalResultsFactory (): \"\"\"Build OSCO OSCAL entities.\"\"\" default_timestamp = ResultsTransformer . get_timestamp () def __init__ ( self , timestamp : str = default_timestamp , checking : bool = False ) -> None : \"\"\"Initialize.\"\"\" self . _timestamp = timestamp self . _observation_list : List [ Observation ] = [] self . _result_properties_list : List [ Property ] = [] self . _component_map : Dict [ str , SystemComponent ] = {} self . _inventory_map : Dict [ str , InventoryItem ] = {} self . _ns = 'https://ibm.github.io/compliance-trestle/schemas/oscal/ar/osco' self . _checking = checking @property def components ( self ) -> List [ SystemComponent ]: \"\"\"OSCAL components.\"\"\" return list ( self . _component_map . values ()) @property def control_selections ( self ) -> List [ ControlSelection ]: \"\"\"OSCAL control selections.\"\"\" prop = [] prop . append ( ControlSelection ()) return prop @property def inventory ( self ) -> ValuesView [ InventoryItem ]: \"\"\"OSCAL inventory.\"\"\" return self . _inventory_map . values () @property def local_definitions ( self ) -> LocalDefinitions1 : \"\"\"OSCAL local definitions.\"\"\" prop = LocalDefinitions1 () prop . components = self . components prop . inventory_items = list ( self . inventory ) return prop @property def observations ( self ) -> List [ Observation ]: \"\"\"OSCAL observations.\"\"\" return self . _observation_list @property def result_properties ( self ) -> List [ Property ]: \"\"\"OSCAL result properties.\"\"\" return self . _result_properties_list @property def reviewed_controls ( self ) -> ReviewedControls : \"\"\"OSCAL reviewed controls.\"\"\" prop = ReviewedControls ( control_selections = self . control_selections ) return prop @property def result ( self ) -> Result : \"\"\"OSCAL result.\"\"\" # perform result properties aggregation if self . observations : self . _result_properties_list = TransformerHelper () . remove_common_observation_properties ( self . observations ) # produce result prop = Result ( uuid = str ( uuid . uuid4 ()), title = 'OpenShift Compliance Operator' , description = 'OpenShift Compliance Operator Scan Results' , start = self . _timestamp , end = self . _timestamp , reviewed_controls = self . reviewed_controls , ) if self . result_properties : prop . props = self . result_properties if self . inventory : prop . local_definitions = self . local_definitions if self . observations : prop . observations = self . observations return prop @property def analysis ( self ) -> List [ str ]: \"\"\"OSCAL statistics.\"\"\" analysis = [] analysis . append ( f 'inventory: { len ( self . inventory ) } ' ) analysis . append ( f 'observations: { len ( self . observations ) } ' ) return analysis def _component_extract ( self , rule_use : RuleUse ) -> None : \"\"\"Extract component from RuleUse.\"\"\" _type = 'Service' _title = f 'Red Hat OpenShift Kubernetes Service Compliance Operator for { rule_use . target_type } ' _desc = _title for component in self . _component_map . values (): if component . type == _type and component . title == _title and component . description == _desc : return component_ref = str ( uuid . uuid4 ()) status = Status1 ( state = 'operational' ) component = SystemComponent ( uuid = component_ref , type = _type , title = _title , description = _desc , status = status ) self . _component_map [ component_ref ] = component def _get_component_ref ( self , rule_use : RuleUse ) -> str : \"\"\"Get component reference for specified RuleUse.\"\"\" uuid = None for component_ref , component in self . _component_map . items (): if component . title . endswith ( rule_use . target_type ): uuid = component_ref return uuid def _inventory_extract ( self , rule_use : RuleUse ) -> None : \"\"\"Extract inventory from RuleUse.\"\"\" if rule_use . inventory_key in self . _inventory_map : return inventory = InventoryItem ( uuid = str ( uuid . uuid4 ()), description = 'inventory' ) inventory . props = self . _get_inventory_properties ( rule_use ) inventory . implemented_components = [ ImplementedComponent ( component_uuid = self . _get_component_ref ( rule_use ))] self . _inventory_map [ rule_use . inventory_key ] = inventory def _get_inventory_properties ( self , rule_use ): \"\"\"Get inventory properties.\"\"\" if self . _checking : return self . _get_inventory_properties_checked ( rule_use ) else : return self . _get_inventory_properties_unchecked ( rule_use ) def _get_inventory_properties_checked ( self , rule_use ): \"\"\"Get inventory properties, with checking.\"\"\" props = [] if rule_use . host_name is None : props . append ( Property ( name = 'target' , value = rule_use . target , ns = self . _ns , class_ = 'scc_inventory_item_id' )) props . append ( Property ( name = 'target_type' , value = rule_use . target_type , ns = self . _ns )) else : props . append ( Property ( name = 'target' , value = rule_use . target , ns = self . _ns )) props . append ( Property ( name = 'target_type' , value = rule_use . target_type , ns = self . _ns )) props . append ( Property ( name = 'host_name' , value = rule_use . host_name , ns = self . _ns , class_ = 'scc_inventory_item_id' ) ) return props def _get_inventory_properties_unchecked ( self , rule_use ): \"\"\"Get observation properties, without checking.\"\"\" props = [] if rule_use . host_name is None : props . append ( Property . construct ( name = 'target' , value = rule_use . target , ns = self . _ns , class_ = 'scc_inventory_item_id' ) ) props . append ( Property . construct ( name = 'target_type' , value = rule_use . target_type , ns = self . _ns )) else : props . append ( Property . construct ( name = 'target' , value = rule_use . target , ns = self . _ns )) props . append ( Property . construct ( name = 'target_type' , value = rule_use . target_type , ns = self . _ns )) props . append ( Property . construct ( name = 'host_name' , value = rule_use . host_name , ns = self . _ns , class_ = 'scc_inventory_item_id' ) ) return props def _get_inventory_ref ( self , rule_use : RuleUse ) -> str : \"\"\"Get inventory reference for specified RuleUse.\"\"\" return self . _inventory_map [ rule_use . inventory_key ] . uuid def _observation_extract ( self , rule_use : RuleUse ) -> None : \"\"\"Extract observation from RuleUse.\"\"\" observation = Observation ( uuid = str ( uuid . uuid4 ()), description = rule_use . idref , methods = [ 'TEST-AUTOMATED' ], collected = self . _timestamp ) subject_reference = SubjectReference ( subject_uuid = self . _get_inventory_ref ( rule_use ), type = 'inventory-item' ) observation . subjects = [ subject_reference ] observation . props = self . _get_observation_properties ( rule_use ) self . _observation_list . append ( observation ) rule_use . observation = observation def _get_observation_properties ( self , rule_use ): \"\"\"Get observation properties.\"\"\" if self . _checking : return self . _get_observation_properties_checked ( rule_use ) else : return self . _get_observation_properties_unchecked ( rule_use ) def _get_observation_properties_checked ( self , rule_use ): \"\"\"Get observation properties, with checking.\"\"\" props = [] props . append ( Property ( name = 'scanner_name' , value = rule_use . scanner_name , ns = self . _ns )) props . append ( Property ( name = 'scanner_version' , value = rule_use . scanner_version , ns = self . _ns )) props . append ( Property ( name = 'idref' , value = rule_use . idref , ns = self . _ns , class_ = 'scc_check_name_id' )) props . append ( Property ( name = 'version' , value = rule_use . version , ns = self . _ns , class_ = 'scc_check_version' )) props . append ( Property ( name = 'result' , value = rule_use . result , ns = self . _ns , class_ = 'scc_result' )) props . append ( Property ( name = 'time' , value = rule_use . time , ns = self . _ns , class_ = 'scc_timestamp' )) props . append ( Property ( name = 'severity' , value = rule_use . severity , ns = self . _ns , class_ = 'scc_check_severity' )) props . append ( Property ( name = 'weight' , value = rule_use . weight , ns = self . _ns )) props . append ( Property ( name = 'benchmark_id' , value = rule_use . benchmark_id , ns = self . _ns )) props . append ( Property ( name = 'benchmark_href' , value = rule_use . benchmark_href , ns = self . _ns )) props . append ( Property ( name = 'id' , value = rule_use . id_ , ns = self . _ns , class_ = 'scc_predefined_profile' )) return props def _get_observation_properties_unchecked ( self , rule_use ): \"\"\"Get observation properties, without checking.\"\"\" props = [] props . append ( Property . construct ( name = 'scanner_name' , value = rule_use . scanner_name , ns = self . _ns )) props . append ( Property . construct ( name = 'scanner_version' , value = rule_use . scanner_version , ns = self . _ns )) props . append ( Property . construct ( name = 'idref' , value = rule_use . idref , ns = self . _ns , class_ = 'scc_check_name_id' )) props . append ( Property . construct ( name = 'version' , value = rule_use . version , ns = self . _ns , class_ = 'scc_check_version' ) ) props . append ( Property . construct ( name = 'result' , value = rule_use . result , ns = self . _ns , class_ = 'scc_result' )) props . append ( Property . construct ( name = 'time' , value = rule_use . time , ns = self . _ns , class_ = 'scc_timestamp' )) props . append ( Property . construct ( name = 'severity' , value = rule_use . severity , ns = self . _ns , class_ = 'scc_check_severity' ) ) props . append ( Property . construct ( name = 'weight' , value = rule_use . weight , ns = self . _ns )) props . append ( Property . construct ( name = 'benchmark_id' , value = rule_use . benchmark_id , ns = self . _ns )) props . append ( Property . construct ( name = 'benchmark_href' , value = rule_use . benchmark_href , ns = self . _ns )) props . append ( Property . construct ( name = 'id' , value = rule_use . id_ , ns = self . _ns , class_ = 'scc_predefined_profile' )) return props def _process ( self , co_result : ComplianceOperatorResult ) -> None : \"\"\"Process ingested data.\"\"\" rule_use_generator = co_result . rule_use_generator () for rule_use in rule_use_generator : self . _component_extract ( rule_use ) self . _inventory_extract ( rule_use ) self . _observation_extract ( rule_use ) def ingest ( self , osco_data : Dict [ str , Any ]) -> None : \"\"\"Process OSCO json.\"\"\" if 'data' not in osco_data . keys (): return if 'results' not in osco_data [ 'data' ]: return results = osco_data [ 'data' ][ 'results' ] self . ingest_xml ( results ) def ingest_xml ( self , osco_xml : str ) -> None : \"\"\"Process OSCO xml.\"\"\" if not osco_xml . startswith ( '<?xml' ): osco_xml = bz2 . decompress ( base64 . b64decode ( osco_xml )) co_result = ComplianceOperatorResult ( osco_xml ) self . _process ( co_result )","title":"OscalResultsFactory"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalResultsFactory-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalResultsFactory.analysis","text":"OSCAL statistics.","title":"analysis"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalResultsFactory.components","text":"OSCAL components.","title":"components"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalResultsFactory.control_selections","text":"OSCAL control selections.","title":"control_selections"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalResultsFactory.default_timestamp","text":"","title":"default_timestamp"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalResultsFactory.inventory","text":"OSCAL inventory.","title":"inventory"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalResultsFactory.local_definitions","text":"OSCAL local definitions.","title":"local_definitions"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalResultsFactory.observations","text":"OSCAL observations.","title":"observations"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalResultsFactory.result","text":"OSCAL result.","title":"result"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalResultsFactory.result_properties","text":"OSCAL result properties.","title":"result_properties"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalResultsFactory.reviewed_controls","text":"OSCAL reviewed controls.","title":"reviewed_controls"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalResultsFactory-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalResultsFactory.__init__","text":"Initialize. Source code in trestle/transforms/implementations/osco.py def __init__ ( self , timestamp : str = default_timestamp , checking : bool = False ) -> None : \"\"\"Initialize.\"\"\" self . _timestamp = timestamp self . _observation_list : List [ Observation ] = [] self . _result_properties_list : List [ Property ] = [] self . _component_map : Dict [ str , SystemComponent ] = {} self . _inventory_map : Dict [ str , InventoryItem ] = {} self . _ns = 'https://ibm.github.io/compliance-trestle/schemas/oscal/ar/osco' self . _checking = checking","title":"__init__()"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalResultsFactory.ingest","text":"Process OSCO json. Source code in trestle/transforms/implementations/osco.py def ingest ( self , osco_data : Dict [ str , Any ]) -> None : \"\"\"Process OSCO json.\"\"\" if 'data' not in osco_data . keys (): return if 'results' not in osco_data [ 'data' ]: return results = osco_data [ 'data' ][ 'results' ] self . ingest_xml ( results )","title":"ingest()"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscalResultsFactory.ingest_xml","text":"Process OSCO xml. Source code in trestle/transforms/implementations/osco.py def ingest_xml ( self , osco_xml : str ) -> None : \"\"\"Process OSCO xml.\"\"\" if not osco_xml . startswith ( '<?xml' ): osco_xml = bz2 . decompress ( base64 . b64decode ( osco_xml )) co_result = ComplianceOperatorResult ( osco_xml ) self . _process ( co_result )","title":"ingest_xml()"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscoResultToOscalARTransformer","text":"Interface for Osco transformer. Source code in trestle/transforms/implementations/osco.py class OscoResultToOscalARTransformer ( ResultsTransformer ): \"\"\"Interface for Osco transformer.\"\"\" def __init__ ( self ) -> None : \"\"\"Initialize.\"\"\" self . _modes = {} @property def analysis ( self ) -> List [ str ]: \"\"\"Analysis.\"\"\" return self . _results_factory . analysis @property def checking ( self ): \"\"\"Return checking.\"\"\" return self . _modes . get ( 'checking' , False ) def set_modes ( self , modes : Dict [ str , Any ]) -> None : \"\"\"Keep modes info.\"\"\" if modes is not None : self . _modes = modes def transform ( self , blob : str ) -> Results : \"\"\"Transform the blob into a Results. The expected blob is a string that is one of: - data from OpenShift Compliance Operator (json, yaml, xml) - data from Auditree OSCO fetcher/check (json) \"\"\" results = None self . _results_factory = OscalResultsFactory ( self . get_timestamp (), self . checking ) if results is None : results = self . _ingest_xml ( blob ) if results is None : results = self . _ingest_json ( blob ) if results is None : results = self . _ingest_yaml ( blob ) return results def _ingest_xml ( self , blob : str ) -> Results : \"\"\"Ingest xml data.\"\"\" # ?xml data if blob . startswith ( '<?xml' ): resource = blob self . _results_factory . ingest_xml ( resource ) else : return None results = Results () results . __root__ . append ( self . _results_factory . result ) return results def _ingest_json ( self , blob : str ) -> Results : \"\"\"Ingest json data.\"\"\" try : # ? configmaps or auditree data jdata = json . loads ( blob ) # https://docs.openshift.com/container-platform/3.7/rest_api/api/v1.ConfigMap.html#Get-api-v1-namespaces-namespace-configmaps-name if 'kind' in jdata . keys () and jdata [ 'kind' ] == 'ConfigMapList' and 'items' in jdata . keys (): items = jdata [ 'items' ] for item in items : if 'data' in item . keys (): data = item [ 'data' ] if 'results' in data : resource = item self . _results_factory . ingest ( resource ) # https://github.com/ComplianceAsCode/auditree-arboretum/blob/main/arboretum/kubernetes/fetchers/fetch_cluster_resource.py else : for key in jdata . keys (): for group in jdata [ key ]: for cluster in jdata [ key ][ group ]: if 'resources' in cluster : for resource in cluster [ 'resources' ]: self . _results_factory . ingest ( resource ) except json . decoder . JSONDecodeError : return None results = Results () results . __root__ . append ( self . _results_factory . result ) return results def _ingest_yaml ( self , blob : str ) -> Results : \"\"\"Ingest yaml data.\"\"\" try : # ? yaml data yaml = YAML ( typ = 'safe' ) resource = yaml . load ( blob ) self . _results_factory . ingest ( resource ) except Exception as e : raise e results = Results () results . __root__ . append ( self . _results_factory . result ) return results","title":"OscoResultToOscalARTransformer"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscoResultToOscalARTransformer-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscoResultToOscalARTransformer.analysis","text":"Analysis.","title":"analysis"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscoResultToOscalARTransformer.checking","text":"Return checking.","title":"checking"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscoResultToOscalARTransformer-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscoResultToOscalARTransformer.__init__","text":"Initialize. Source code in trestle/transforms/implementations/osco.py def __init__ ( self ) -> None : \"\"\"Initialize.\"\"\" self . _modes = {}","title":"__init__()"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscoResultToOscalARTransformer.set_modes","text":"Keep modes info. Source code in trestle/transforms/implementations/osco.py def set_modes ( self , modes : Dict [ str , Any ]) -> None : \"\"\"Keep modes info.\"\"\" if modes is not None : self . _modes = modes","title":"set_modes()"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscoResultToOscalARTransformer.transform","text":"Transform the blob into a Results. The expected blob is a string that is one of: - data from OpenShift Compliance Operator (json, yaml, xml) - data from Auditree OSCO fetcher/check (json) Source code in trestle/transforms/implementations/osco.py def transform ( self , blob : str ) -> Results : \"\"\"Transform the blob into a Results. The expected blob is a string that is one of: - data from OpenShift Compliance Operator (json, yaml, xml) - data from Auditree OSCO fetcher/check (json) \"\"\" results = None self . _results_factory = OscalResultsFactory ( self . get_timestamp (), self . checking ) if results is None : results = self . _ingest_xml ( blob ) if results is None : results = self . _ingest_json ( blob ) if results is None : results = self . _ingest_yaml ( blob ) return results","title":"transform()"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.OscoTransformer","text":"Legacy class name. Source code in trestle/transforms/implementations/osco.py class OscoTransformer ( OscoResultToOscalARTransformer ): \"\"\"Legacy class name.\"\"\"","title":"OscoTransformer"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.RuleUse","text":"Represents one rule of OSCO data. Source code in trestle/transforms/implementations/osco.py class RuleUse (): \"\"\"Represents one rule of OSCO data.\"\"\" def __init__ ( self , args : Dict [ str , str ]) -> None : \"\"\"Initialize given specified args.\"\"\" self . id_ = args [ 'id_' ] self . target = args [ 'target' ] self . target_type = args [ 'target_type' ] self . host_name = args [ 'host_name' ] self . benchmark_href = args [ 'benchmark_href' ] self . benchmark_id = args [ 'benchmark_id' ] self . scanner_name = args [ 'scanner_name' ] self . scanner_version = args [ 'scanner_version' ] self . idref = args [ 'idref' ] self . version = args [ 'version' ] self . time = args [ 'time' ] self . result = args [ 'result' ] self . severity = args [ 'severity' ] self . weight = args [ 'weight' ] @property def inventory_key ( self ): \"\"\"Derive inventory key.\"\"\" if self . host_name is None : # OpenScap 1.3.3 rval = self . target + ':' + self . target_type else : # OpenScap 1.3.5 rval = self . host_name + ':' + self . target_type return rval","title":"RuleUse"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.RuleUse-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.RuleUse.inventory_key","text":"Derive inventory key.","title":"inventory_key"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.RuleUse-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.transforms.implementations.osco/#trestle.transforms.implementations.osco.RuleUse.__init__","text":"Initialize given specified args. Source code in trestle/transforms/implementations/osco.py def __init__ ( self , args : Dict [ str , str ]) -> None : \"\"\"Initialize given specified args.\"\"\" self . id_ = args [ 'id_' ] self . target = args [ 'target' ] self . target_type = args [ 'target_type' ] self . host_name = args [ 'host_name' ] self . benchmark_href = args [ 'benchmark_href' ] self . benchmark_id = args [ 'benchmark_id' ] self . scanner_name = args [ 'scanner_name' ] self . scanner_version = args [ 'scanner_version' ] self . idref = args [ 'idref' ] self . version = args [ 'version' ] self . time = args [ 'time' ] self . result = args [ 'result' ] self . severity = args [ 'severity' ] self . weight = args [ 'weight' ] handler: python","title":"__init__()"},{"location":"api_reference/trestle.transforms.implementations.tanium/","text":"trestle.transforms.implementations.tanium \u00a4 Facilitate Tanium result to NIST OSCAL transformation. logger \u00a4 Classes \u00a4 RuleUse \u00a4 Represents one row of Tanium data. Source code in trestle/transforms/implementations/tanium.py class RuleUse (): \"\"\"Represents one row of Tanium data.\"\"\" def __init__ ( self , tanium_row : Dict [ str , Any ], comply : Dict [ str , str ], default_timestamp : str ) -> None : \"\"\"Initialize given specified args.\"\"\" logger . debug ( f 'tanium-row: { tanium_row } ' ) try : # level 1 keys self . computer_name = tanium_row [ 'Computer Name' ] self . tanium_client_ip_address = tanium_row [ 'Tanium Client IP Address' ] self . ip_address = str ( tanium_row [ 'IP Address' ]) self . count = str ( tanium_row [ 'Count' ]) # comply keys self . check_id = comply [ 'Check ID' ] self . rule_id = comply [ 'Rule ID' ] self . state = comply [ 'State' ] # defaults no_results = '[no results]' self . check_id_level = no_results self . check_id_version = no_results self . check_id_benchmark = no_results self . component = no_results self . component_type = no_results # parse if ';' in self . check_id : items = self . check_id . split ( ';' ) if len ( items ) > 2 : self . check_id_level = items [ 2 ] if len ( items ) > 1 : self . check_id_version = items [ 1 ] if len ( items ) > 0 : self . check_id_benchmark = items [ 0 ] self . component = items [ 0 ] if self . component . startswith ( 'CIS ' ): self . component = self . component [ len ( 'CIS ' ):] if self . component . endswith ( ' Benchmark' ): self . component = self . component [: - len ( ' Benchmark' )] self . component_type = 'Operating System' # timestamp self . timestamp = comply . get ( 'Timestamp' , default_timestamp ) # collected self . collected = default_timestamp except Exception as e : logger . debug ( f 'tanium-row: { tanium_row } ' ) logger . debug ( e ) logger . debug ( traceback . format_exc ()) raise e Methods \u00a4 __init__ ( self , tanium_row , comply , default_timestamp ) special \u00a4 Initialize given specified args. Source code in trestle/transforms/implementations/tanium.py def __init__ ( self , tanium_row : Dict [ str , Any ], comply : Dict [ str , str ], default_timestamp : str ) -> None : \"\"\"Initialize given specified args.\"\"\" logger . debug ( f 'tanium-row: { tanium_row } ' ) try : # level 1 keys self . computer_name = tanium_row [ 'Computer Name' ] self . tanium_client_ip_address = tanium_row [ 'Tanium Client IP Address' ] self . ip_address = str ( tanium_row [ 'IP Address' ]) self . count = str ( tanium_row [ 'Count' ]) # comply keys self . check_id = comply [ 'Check ID' ] self . rule_id = comply [ 'Rule ID' ] self . state = comply [ 'State' ] # defaults no_results = '[no results]' self . check_id_level = no_results self . check_id_version = no_results self . check_id_benchmark = no_results self . component = no_results self . component_type = no_results # parse if ';' in self . check_id : items = self . check_id . split ( ';' ) if len ( items ) > 2 : self . check_id_level = items [ 2 ] if len ( items ) > 1 : self . check_id_version = items [ 1 ] if len ( items ) > 0 : self . check_id_benchmark = items [ 0 ] self . component = items [ 0 ] if self . component . startswith ( 'CIS ' ): self . component = self . component [ len ( 'CIS ' ):] if self . component . endswith ( ' Benchmark' ): self . component = self . component [: - len ( ' Benchmark' )] self . component_type = 'Operating System' # timestamp self . timestamp = comply . get ( 'Timestamp' , default_timestamp ) # collected self . collected = default_timestamp except Exception as e : logger . debug ( f 'tanium-row: { tanium_row } ' ) logger . debug ( e ) logger . debug ( traceback . format_exc ()) raise e RuleUseFactory \u00a4 Build RuleUse list. Source code in trestle/transforms/implementations/tanium.py class RuleUseFactory (): \"\"\"Build RuleUse list.\"\"\" def __init__ ( self , timestamp : str ) -> None : \"\"\"Initialize given specified args.\"\"\" self . _timestamp = timestamp def _make_sublist ( self , tanium_row : Dict [ str , Any ]) -> List [ RuleUse ]: \"\"\"Build RuleUse sublist from input data item.\"\"\" retval = [] keys = tanium_row for key in keys : if key . startswith ( 'Comply' ): break comply_list = tanium_row [ key ] for comply in comply_list : rule_use = RuleUse ( tanium_row , comply , self . _timestamp ) retval . append ( rule_use ) return retval def make_list ( self , blob : str ) -> List [ RuleUse ]: \"\"\"Build RuleUse list from input data.\"\"\" retval = [] lines = blob . splitlines () for line in lines : line = line . strip () if line : jdata = json . loads ( line ) if type ( jdata ) is list : for item in jdata : logger . debug ( f 'item: { item } ' ) retval += self . _make_sublist ( item ) else : logger . debug ( f 'jdata: { jdata } ' ) retval += self . _make_sublist ( jdata ) logger . debug ( f 'ru_list: { len ( retval ) } ' ) return retval Methods \u00a4 __init__ ( self , timestamp ) special \u00a4 Initialize given specified args. Source code in trestle/transforms/implementations/tanium.py def __init__ ( self , timestamp : str ) -> None : \"\"\"Initialize given specified args.\"\"\" self . _timestamp = timestamp make_list ( self , blob ) \u00a4 Build RuleUse list from input data. Source code in trestle/transforms/implementations/tanium.py def make_list ( self , blob : str ) -> List [ RuleUse ]: \"\"\"Build RuleUse list from input data.\"\"\" retval = [] lines = blob . splitlines () for line in lines : line = line . strip () if line : jdata = json . loads ( line ) if type ( jdata ) is list : for item in jdata : logger . debug ( f 'item: { item } ' ) retval += self . _make_sublist ( item ) else : logger . debug ( f 'jdata: { jdata } ' ) retval += self . _make_sublist ( jdata ) logger . debug ( f 'ru_list: { len ( retval ) } ' ) return retval TaniumOscalFactory \u00a4 Build Tanium OSCAL entities. Source code in trestle/transforms/implementations/tanium.py class TaniumOscalFactory (): \"\"\"Build Tanium OSCAL entities.\"\"\" def __init__ ( self , timestamp : str , rule_use_list : List [ RuleUse ], blocksize : int = 11000 , cpus_max : int = 1 , cpus_min : int = 1 , checking : bool = False , caching : bool = True , aggregate : bool = True ) -> None : \"\"\"Initialize given specified args.\"\"\" self . _rule_use_list = rule_use_list self . _timestamp = timestamp self . _component_map : Dict [ str , SystemComponent ] = {} self . _inventory_map : Dict [ str , InventoryItem ] = {} self . _observation_list : List [ Observation ] = [] self . _ns = 'https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium' self . _cpus = None self . _checking = checking self . _caching = caching self . _aggregate = aggregate self . _result = None # blocksize: default, min self . _blocksize = blocksize if self . _blocksize < 1 : self . _blocksize = 1 # cpus max: default, max, min self . _cpus_max = cpus_max if self . _cpus_max > os . cpu_count (): self . _cpus_max = os . cpu_count () self . _cpus_min = cpus_min if self . _cpus_min > self . _cpus_max : self . _cpus_min = self . _cpus_max if self . _cpus_min < 1 : self . _cpus_min = 1 self . _property_accounting = PropertyAccounting () self . _property_manager = PropertyManager ( caching = caching , checking = checking ) def _is_duplicate_component ( self , rule_use : RuleUse ) -> bool : \"\"\"Check for duplicate component.\"\"\" retval = False component_type = rule_use . component_type component_title = rule_use . component for component in self . _component_map . values (): if component . type != component_type : continue if component . title != component_title : continue retval = True break return retval def _derive_components ( self ) -> None : \"\"\"Derive components from RuleUse list.\"\"\" self . _component_map : Dict [ str , SystemComponent ] = {} for rule_use in self . _rule_use_list : if self . _is_duplicate_component ( rule_use ): continue component_type = rule_use . component_type component_title = rule_use . component # See Note in _get_component_ref. component_description = rule_use . component component_ref = _uuid_component () status = Status1 ( state = 'operational' ) component = SystemComponent ( uuid = component_ref , type = component_type , title = component_title , description = component_description , status = status ) self . _component_map [ component_ref ] = component def _get_component_ref ( self , rule_use : RuleUse ) -> Optional [ str ]: \"\"\"Get component reference for specified rule use.\"\"\" uuid = None for component_ref , component in self . _component_map . items (): if component . type != rule_use . component_type : continue if component . title != rule_use . component : continue # Note: currently title and description are the same, # therefore checking description is not necessary. uuid = component_ref break return uuid def _derive_inventory ( self ) -> None : \"\"\"Derive inventory from RuleUse list.\"\"\" self . _inventory_map : Dict [ str , InventoryItem ] = {} for rule_use in self . _rule_use_list : if rule_use . tanium_client_ip_address in self . _inventory_map : continue inventory = InventoryItem ( uuid = _uuid_inventory (), description = 'inventory' ) inventory . props = [ self . _property_manager . materialize ( name = 'Computer_Name' , value = rule_use . computer_name , ns = self . _ns ), self . _property_manager . materialize ( name = 'Tanium_Client_IP_Address' , value = rule_use . tanium_client_ip_address , ns = self . _ns , class_ = 'scc_inventory_item_id' ), self . _property_manager . materialize ( name = 'IP_Address' , value = rule_use . ip_address , ns = self . _ns ), self . _property_manager . materialize ( name = 'Count' , value = rule_use . count , ns = self . _ns ) ] component_uuid = self . _get_component_ref ( rule_use ) if component_uuid is not None : inventory . implemented_components = [ ImplementedComponent ( component_uuid = component_uuid )] self . _inventory_map [ rule_use . tanium_client_ip_address ] = inventory def _get_inventory_ref ( self , rule_use : RuleUse ) -> str : \"\"\"Get inventory reference for specified rule use.\"\"\" return self . _inventory_map [ rule_use . tanium_client_ip_address ] . uuid def _conditional_include ( self , props : List [ Property ], group : str = None , name : str = None , value : str = None , ns : str = None , class_ : str = None ) -> None : \"\"\"Add non-aggregated property or remember common property.\"\"\" if self . _aggregate : if self . _property_accounting . is_common_property ( group = group , name = name , value = value , ns = ns , class_ = class_ ): # common property self . _property_manager . put_common_property ( group = group , name = name , value = value , ns = ns , class_ = class_ ) return # non-aggregated property props . append ( self . _property_manager . materialize ( name = name , value = value , ns = ns , class_ = class_ )) def _get_observtion_properties ( self , rule_use : RuleUse ) -> List [ Property ]: \"\"\"Get observation properties.\"\"\" props = [] group = self . _get_component_ref ( rule_use ) self . _conditional_include ( props = props , group = group , name = 'Check_ID' , value = rule_use . check_id , ns = self . _ns ) self . _conditional_include ( props = props , group = group , name = 'Check_ID_Benchmark' , value = rule_use . check_id_benchmark , ns = self . _ns , class_ = 'scc_predefined_profile' ) self . _conditional_include ( props = props , group = group , name = 'Check_ID_Version' , value = rule_use . check_id_version , ns = self . _ns , class_ = 'scc_predefined_profile_version' ) self . _conditional_include ( props = props , group = group , name = 'Check_ID_Level' , value = rule_use . check_id_level , ns = self . _ns ) self . _conditional_include ( props = props , group = group , name = 'Rule_ID' , value = rule_use . rule_id , ns = self . _ns , class_ = 'scc_goal_description' ) self . _conditional_include ( props = props , group = group , name = 'Rule_ID' , value = rule_use . rule_id , ns = self . _ns , class_ = 'scc_check_name_id' ) self . _conditional_include ( props = props , group = group , name = 'State' , value = rule_use . state , ns = self . _ns , class_ = 'scc_result' ) self . _conditional_include ( props = props , group = group , name = 'Timestamp' , value = rule_use . timestamp , ns = self . _ns , class_ = 'scc_timestamp' ) return props def _derive_common_property_accounting ( self ) -> None : \"\"\"Derive common properties accounting from RuleUse list.\"\"\" for rule_use in self . _rule_use_list : group = self . _get_component_ref ( rule_use ) self . _property_accounting . count_group ( group = group ) self . _property_accounting . count_property ( group = group , name = 'Check_ID' , value = rule_use . check_id , ns = self . _ns ) self . _property_accounting . count_property ( group = group , name = 'Check_ID_Benchmark' , value = rule_use . check_id_benchmark , ns = self . _ns , class_ = 'scc_predefined_profile' ) self . _property_accounting . count_property ( group = group , name = 'Check_ID_Version' , value = rule_use . check_id_version , ns = self . _ns , class_ = 'scc_predefined_profile_version' ) self . _property_accounting . count_property ( group = group , name = 'Check_ID_Level' , value = rule_use . check_id_level , ns = self . _ns ) self . _property_accounting . count_property ( group = group , name = 'Rule_ID' , value = rule_use . rule_id , ns = self . _ns , class_ = 'scc_goal_description' ) self . _property_accounting . count_property ( group = group , name = 'Rule_ID' , value = rule_use . rule_id , ns = self . _ns , class_ = 'scc_check_name_id' ) self . _property_accounting . count_property ( group = group , name = 'State' , value = rule_use . state , ns = self . _ns , class_ = 'scc_result' ) self . _property_accounting . count_property ( group = group , name = 'Timestamp' , value = rule_use . timestamp , ns = self . _ns , class_ = 'scc_timestamp' ) # parallel process to process one chuck of entire data set def _batch_observations ( self , index : int ) -> Dict [ str , List [ Observation ]]: \"\"\"Derive batch of observations from RuleUse list.\"\"\" observation_partial_map : Dict [ str , List [ Observation ]] = {} # determine which chunk to process batch_size = ( len ( self . _rule_use_list ) // self . _batch_workers ) + 1 start = index * batch_size end = ( index + 1 ) * batch_size end = min ( end , len ( self . _rule_use_list )) logger . debug ( f 'start: { start } end: { end - 1 } ' ) # process just the one chunk for i in range ( start , end ): rule_use = self . _rule_use_list [ i ] observation = Observation ( uuid = _uuid_observation (), description = rule_use . rule_id , methods = [ 'TEST-AUTOMATED' ], collected = rule_use . collected ) subject_uuid = self . _get_inventory_ref ( rule_use ) subject_reference = SubjectReference ( subject_uuid = subject_uuid , type = 'inventory-item' ) observation . subjects = [ subject_reference ] observation . props = self . _get_observtion_properties ( rule_use ) observation_partial_map [ subject_uuid ] = observation_partial_map . get ( subject_uuid , []) + [ observation ] return observation_partial_map @property def _batch_workers ( self ) -> int : \"\"\"Calculate number of parallel processes to employ.\"\"\" if self . _cpus is None : cpus_estimate = len ( self . _rule_use_list ) // self . _blocksize self . _cpus = max ( min ( cpus_estimate , self . _cpus_max ), self . _cpus_min ) logger . debug ( f 'CPUs estimate: { cpus_estimate } available: { os . cpu_count () } selection: { self . _cpus } ' ) return self . _cpus def _derive_observations ( self ) -> None : \"\"\"Derive observations from RuleUse list.\"\"\" self . _observation_map = {} if self . _batch_workers == 1 : # no need for multiprocessing self . _observation_map = self . _batch_observations ( 0 ) else : # use multiprocessing to perform observations creation in parallel pool = multiprocessing . Pool ( processes = self . _batch_workers ) rval_list = pool . map ( self . _batch_observations , range ( self . _batch_workers )) # gather observations from the sundry batch workers for partial_observation_map in rval_list : self . _observation_map = join_key_to_list_dicts ( self . _observation_map , partial_observation_map ) @property def components ( self ) -> List [ SystemComponent ]: \"\"\"OSCAL components.\"\"\" return list ( self . _component_map . values ()) @property def inventory ( self ) -> ValuesView [ InventoryItem ]: \"\"\"OSCAL inventory.\"\"\" return self . _inventory_map . values () @property def observations ( self ) -> List [ Observation ]: \"\"\"OSCAL observations.\"\"\" rval = [] # observations are partitioned by local-definition uuid; join them into one list for key in self . _observation_map : list_ = self . _observation_map [ key ] for observation in list_ : rval . append ( observation ) return rval @property def control_selections ( self ) -> List [ ControlSelection ]: \"\"\"OSCAL control selections.\"\"\" rval = [] rval . append ( ControlSelection ()) return rval @property def reviewed_controls ( self ) -> ReviewedControls : \"\"\"OSCAL reviewed controls.\"\"\" rval = ReviewedControls ( control_selections = self . control_selections ) return rval @property def analysis ( self ) -> List [ str ]: \"\"\"OSCAL statistics.\"\"\" analysis = [] analysis . append ( f 'components: { len ( self . components ) } ' ) analysis . append ( f 'inventory: { len ( self . inventory ) } ' ) analysis . append ( f 'observations: { len ( self . observations ) } ' ) analysis . append ( f 'cache: requests= { self . _property_manager . requests } hits= { self . _property_manager . hits } ' ) return analysis def _get_local_definitions ( self , system_component : SystemComponent ) -> LocalDefinitions1 : \"\"\"Get local definitions.\"\"\" rval = LocalDefinitions1 () for component in self . components : if component . uuid == system_component . uuid : rval . components = [ component ] rval . inventory_items = [] for inventory_item in self . inventory : for implemented_component in inventory_item . implemented_components : if implemented_component . component_uuid == system_component . uuid : rval . inventory_items . append ( inventory_item ) break return rval def _get_local_definitions_uuids ( self , local_definitions : LocalDefinitions1 ) -> List [ str ]: \"\"\"Get inventory uuids for given local definitions.\"\"\" rval = [] if local_definitions . inventory_items : rval = [ inventory_item . uuid for inventory_item in local_definitions . inventory_items ] return rval def _get_observations_for_uuid ( self , uuid_ : str ) -> List [ Observation ]: \"\"\"Get observations for given uuid.\"\"\" rval = 0 if uuid_ in self . _observation_map : rval = [] list_ = self . _observation_map [ uuid_ ] for observation in list_ : rval . append ( observation ) return rval def _get_observations ( self , local_definitions : LocalDefinitions1 ) -> List [ Observation ]: \"\"\"Get observations for given local definitions.\"\"\" rval = [] local_definitions_uuids = self . _get_local_definitions_uuids ( local_definitions ) for uuid_ in local_definitions_uuids : observations = self . _get_observations_for_uuid ( uuid_ ) if observations : rval += observations return rval def _get_properties ( self , group : str ) -> List [ Property ]: \"\"\"Get properties for given group.\"\"\" return self . _property_manager . get_common_properties ( group ) @property def results ( self ) -> List [ Result ]: \"\"\"OSCAL result.\"\"\" if self . _result is None : self . _derive_components () self . _derive_inventory () if self . _aggregate : self . _derive_common_property_accounting () self . _derive_observations () results = [] for component in self . components : local_definitions = self . _get_local_definitions ( component ) observations = self . _get_observations ( local_definitions ) result = Result ( uuid = _uuid_result (), title = 'Tanium' , description = 'Tanium' , start = self . _timestamp , end = self . _timestamp , reviewed_controls = self . reviewed_controls , local_definitions = local_definitions , observations = observations ) component_ref = component . uuid result . props = self . _get_properties ( component_ref ) results . append ( result ) return results Attributes \u00a4 analysis : List [ str ] property readonly \u00a4 OSCAL statistics. components : List [ trestle . oscal . assessment_results . SystemComponent ] property readonly \u00a4 OSCAL components. control_selections : List [ trestle . oscal . assessment_results . ControlSelection ] property readonly \u00a4 OSCAL control selections. inventory : ValuesView [ trestle . oscal . common . InventoryItem ] property readonly \u00a4 OSCAL inventory. observations : List [ trestle . oscal . assessment_results . Observation ] property readonly \u00a4 OSCAL observations. results : List [ trestle . oscal . assessment_results . Result ] property readonly \u00a4 OSCAL result. reviewed_controls : ReviewedControls property readonly \u00a4 OSCAL reviewed controls. Methods \u00a4 __init__ ( self , timestamp , rule_use_list , blocksize = 11000 , cpus_max = 1 , cpus_min = 1 , checking = False , caching = True , aggregate = True ) special \u00a4 Initialize given specified args. Source code in trestle/transforms/implementations/tanium.py def __init__ ( self , timestamp : str , rule_use_list : List [ RuleUse ], blocksize : int = 11000 , cpus_max : int = 1 , cpus_min : int = 1 , checking : bool = False , caching : bool = True , aggregate : bool = True ) -> None : \"\"\"Initialize given specified args.\"\"\" self . _rule_use_list = rule_use_list self . _timestamp = timestamp self . _component_map : Dict [ str , SystemComponent ] = {} self . _inventory_map : Dict [ str , InventoryItem ] = {} self . _observation_list : List [ Observation ] = [] self . _ns = 'https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium' self . _cpus = None self . _checking = checking self . _caching = caching self . _aggregate = aggregate self . _result = None # blocksize: default, min self . _blocksize = blocksize if self . _blocksize < 1 : self . _blocksize = 1 # cpus max: default, max, min self . _cpus_max = cpus_max if self . _cpus_max > os . cpu_count (): self . _cpus_max = os . cpu_count () self . _cpus_min = cpus_min if self . _cpus_min > self . _cpus_max : self . _cpus_min = self . _cpus_max if self . _cpus_min < 1 : self . _cpus_min = 1 self . _property_accounting = PropertyAccounting () self . _property_manager = PropertyManager ( caching = caching , checking = checking ) TaniumResultToOscalARTransformer ( ResultsTransformer ) \u00a4 Interface for Tanium transformer. Source code in trestle/transforms/implementations/tanium.py class TaniumResultToOscalARTransformer ( ResultsTransformer ): \"\"\"Interface for Tanium transformer.\"\"\" def __init__ ( self ) -> None : \"\"\"Initialize.\"\"\" self . _modes = {} @property def analysis ( self ) -> List [ str ]: \"\"\"Return analysis info.\"\"\" return self . _analysis @property def blocksize ( self ) -> int : \"\"\"Return blocksize.\"\"\" return self . _modes . get ( 'blocksize' , 10000 ) @property def cpus_max ( self ) -> int : \"\"\"Return cpus_max.\"\"\" return self . _modes . get ( 'cpus_max' , 1 ) @property def cpus_min ( self ) -> int : \"\"\"Return cpus_min.\"\"\" return self . _modes . get ( 'cpus_min' , 1 ) @property def aggregate ( self ) -> bool : \"\"\"Return aggregate.\"\"\" return self . _modes . get ( 'aggregate' , True ) @property def caching ( self ) -> bool : \"\"\"Return caching.\"\"\" return self . _modes . get ( 'caching' , True ) @property def checking ( self ) -> bool : \"\"\"Return checking.\"\"\" return self . _modes . get ( 'checking' , False ) def set_modes ( self , modes : Dict [ str , Any ]) -> None : \"\"\"Keep modes info.\"\"\" if modes is not None : self . _modes = modes def transform ( self , blob : str ) -> Results : \"\"\"Transform the blob into a Results.\"\"\" ts0 = datetime . datetime . now () results = Results () ru_factory = RuleUseFactory ( self . get_timestamp ()) ru_list = ru_factory . make_list ( blob ) tanium_oscal_factory = TaniumOscalFactory ( self . get_timestamp (), ru_list , self . blocksize , self . cpus_max , self . cpus_min , self . checking , self . caching , self . aggregate ) results . __root__ = tanium_oscal_factory . results ts1 = datetime . datetime . now () self . _analysis = tanium_oscal_factory . analysis self . _analysis . append ( f 'transform time: { ts1 - ts0 } ' ) return results Attributes \u00a4 aggregate : bool property readonly \u00a4 Return aggregate. analysis : List [ str ] property readonly \u00a4 Return analysis info. blocksize : int property readonly \u00a4 Return blocksize. caching : bool property readonly \u00a4 Return caching. checking : bool property readonly \u00a4 Return checking. cpus_max : int property readonly \u00a4 Return cpus_max. cpus_min : int property readonly \u00a4 Return cpus_min. Methods \u00a4 __init__ ( self ) special \u00a4 Initialize. Source code in trestle/transforms/implementations/tanium.py def __init__ ( self ) -> None : \"\"\"Initialize.\"\"\" self . _modes = {} set_modes ( self , modes ) \u00a4 Keep modes info. Source code in trestle/transforms/implementations/tanium.py def set_modes ( self , modes : Dict [ str , Any ]) -> None : \"\"\"Keep modes info.\"\"\" if modes is not None : self . _modes = modes transform ( self , blob ) \u00a4 Transform the blob into a Results. Source code in trestle/transforms/implementations/tanium.py def transform ( self , blob : str ) -> Results : \"\"\"Transform the blob into a Results.\"\"\" ts0 = datetime . datetime . now () results = Results () ru_factory = RuleUseFactory ( self . get_timestamp ()) ru_list = ru_factory . make_list ( blob ) tanium_oscal_factory = TaniumOscalFactory ( self . get_timestamp (), ru_list , self . blocksize , self . cpus_max , self . cpus_min , self . checking , self . caching , self . aggregate ) results . __root__ = tanium_oscal_factory . results ts1 = datetime . datetime . now () self . _analysis = tanium_oscal_factory . analysis self . _analysis . append ( f 'transform time: { ts1 - ts0 } ' ) return results TaniumTransformer ( TaniumResultToOscalARTransformer ) \u00a4 Legacy class name. Source code in trestle/transforms/implementations/tanium.py class TaniumTransformer ( TaniumResultToOscalARTransformer ): \"\"\"Legacy class name.\"\"\" handler: python","title":"tanium"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium","text":"Facilitate Tanium result to NIST OSCAL transformation.","title":"tanium"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.logger","text":"","title":"logger"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.RuleUse","text":"Represents one row of Tanium data. Source code in trestle/transforms/implementations/tanium.py class RuleUse (): \"\"\"Represents one row of Tanium data.\"\"\" def __init__ ( self , tanium_row : Dict [ str , Any ], comply : Dict [ str , str ], default_timestamp : str ) -> None : \"\"\"Initialize given specified args.\"\"\" logger . debug ( f 'tanium-row: { tanium_row } ' ) try : # level 1 keys self . computer_name = tanium_row [ 'Computer Name' ] self . tanium_client_ip_address = tanium_row [ 'Tanium Client IP Address' ] self . ip_address = str ( tanium_row [ 'IP Address' ]) self . count = str ( tanium_row [ 'Count' ]) # comply keys self . check_id = comply [ 'Check ID' ] self . rule_id = comply [ 'Rule ID' ] self . state = comply [ 'State' ] # defaults no_results = '[no results]' self . check_id_level = no_results self . check_id_version = no_results self . check_id_benchmark = no_results self . component = no_results self . component_type = no_results # parse if ';' in self . check_id : items = self . check_id . split ( ';' ) if len ( items ) > 2 : self . check_id_level = items [ 2 ] if len ( items ) > 1 : self . check_id_version = items [ 1 ] if len ( items ) > 0 : self . check_id_benchmark = items [ 0 ] self . component = items [ 0 ] if self . component . startswith ( 'CIS ' ): self . component = self . component [ len ( 'CIS ' ):] if self . component . endswith ( ' Benchmark' ): self . component = self . component [: - len ( ' Benchmark' )] self . component_type = 'Operating System' # timestamp self . timestamp = comply . get ( 'Timestamp' , default_timestamp ) # collected self . collected = default_timestamp except Exception as e : logger . debug ( f 'tanium-row: { tanium_row } ' ) logger . debug ( e ) logger . debug ( traceback . format_exc ()) raise e","title":"RuleUse"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.RuleUse-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.RuleUse.__init__","text":"Initialize given specified args. Source code in trestle/transforms/implementations/tanium.py def __init__ ( self , tanium_row : Dict [ str , Any ], comply : Dict [ str , str ], default_timestamp : str ) -> None : \"\"\"Initialize given specified args.\"\"\" logger . debug ( f 'tanium-row: { tanium_row } ' ) try : # level 1 keys self . computer_name = tanium_row [ 'Computer Name' ] self . tanium_client_ip_address = tanium_row [ 'Tanium Client IP Address' ] self . ip_address = str ( tanium_row [ 'IP Address' ]) self . count = str ( tanium_row [ 'Count' ]) # comply keys self . check_id = comply [ 'Check ID' ] self . rule_id = comply [ 'Rule ID' ] self . state = comply [ 'State' ] # defaults no_results = '[no results]' self . check_id_level = no_results self . check_id_version = no_results self . check_id_benchmark = no_results self . component = no_results self . component_type = no_results # parse if ';' in self . check_id : items = self . check_id . split ( ';' ) if len ( items ) > 2 : self . check_id_level = items [ 2 ] if len ( items ) > 1 : self . check_id_version = items [ 1 ] if len ( items ) > 0 : self . check_id_benchmark = items [ 0 ] self . component = items [ 0 ] if self . component . startswith ( 'CIS ' ): self . component = self . component [ len ( 'CIS ' ):] if self . component . endswith ( ' Benchmark' ): self . component = self . component [: - len ( ' Benchmark' )] self . component_type = 'Operating System' # timestamp self . timestamp = comply . get ( 'Timestamp' , default_timestamp ) # collected self . collected = default_timestamp except Exception as e : logger . debug ( f 'tanium-row: { tanium_row } ' ) logger . debug ( e ) logger . debug ( traceback . format_exc ()) raise e","title":"__init__()"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.RuleUseFactory","text":"Build RuleUse list. Source code in trestle/transforms/implementations/tanium.py class RuleUseFactory (): \"\"\"Build RuleUse list.\"\"\" def __init__ ( self , timestamp : str ) -> None : \"\"\"Initialize given specified args.\"\"\" self . _timestamp = timestamp def _make_sublist ( self , tanium_row : Dict [ str , Any ]) -> List [ RuleUse ]: \"\"\"Build RuleUse sublist from input data item.\"\"\" retval = [] keys = tanium_row for key in keys : if key . startswith ( 'Comply' ): break comply_list = tanium_row [ key ] for comply in comply_list : rule_use = RuleUse ( tanium_row , comply , self . _timestamp ) retval . append ( rule_use ) return retval def make_list ( self , blob : str ) -> List [ RuleUse ]: \"\"\"Build RuleUse list from input data.\"\"\" retval = [] lines = blob . splitlines () for line in lines : line = line . strip () if line : jdata = json . loads ( line ) if type ( jdata ) is list : for item in jdata : logger . debug ( f 'item: { item } ' ) retval += self . _make_sublist ( item ) else : logger . debug ( f 'jdata: { jdata } ' ) retval += self . _make_sublist ( jdata ) logger . debug ( f 'ru_list: { len ( retval ) } ' ) return retval","title":"RuleUseFactory"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.RuleUseFactory-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.RuleUseFactory.__init__","text":"Initialize given specified args. Source code in trestle/transforms/implementations/tanium.py def __init__ ( self , timestamp : str ) -> None : \"\"\"Initialize given specified args.\"\"\" self . _timestamp = timestamp","title":"__init__()"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.RuleUseFactory.make_list","text":"Build RuleUse list from input data. Source code in trestle/transforms/implementations/tanium.py def make_list ( self , blob : str ) -> List [ RuleUse ]: \"\"\"Build RuleUse list from input data.\"\"\" retval = [] lines = blob . splitlines () for line in lines : line = line . strip () if line : jdata = json . loads ( line ) if type ( jdata ) is list : for item in jdata : logger . debug ( f 'item: { item } ' ) retval += self . _make_sublist ( item ) else : logger . debug ( f 'jdata: { jdata } ' ) retval += self . _make_sublist ( jdata ) logger . debug ( f 'ru_list: { len ( retval ) } ' ) return retval","title":"make_list()"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumOscalFactory","text":"Build Tanium OSCAL entities. Source code in trestle/transforms/implementations/tanium.py class TaniumOscalFactory (): \"\"\"Build Tanium OSCAL entities.\"\"\" def __init__ ( self , timestamp : str , rule_use_list : List [ RuleUse ], blocksize : int = 11000 , cpus_max : int = 1 , cpus_min : int = 1 , checking : bool = False , caching : bool = True , aggregate : bool = True ) -> None : \"\"\"Initialize given specified args.\"\"\" self . _rule_use_list = rule_use_list self . _timestamp = timestamp self . _component_map : Dict [ str , SystemComponent ] = {} self . _inventory_map : Dict [ str , InventoryItem ] = {} self . _observation_list : List [ Observation ] = [] self . _ns = 'https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium' self . _cpus = None self . _checking = checking self . _caching = caching self . _aggregate = aggregate self . _result = None # blocksize: default, min self . _blocksize = blocksize if self . _blocksize < 1 : self . _blocksize = 1 # cpus max: default, max, min self . _cpus_max = cpus_max if self . _cpus_max > os . cpu_count (): self . _cpus_max = os . cpu_count () self . _cpus_min = cpus_min if self . _cpus_min > self . _cpus_max : self . _cpus_min = self . _cpus_max if self . _cpus_min < 1 : self . _cpus_min = 1 self . _property_accounting = PropertyAccounting () self . _property_manager = PropertyManager ( caching = caching , checking = checking ) def _is_duplicate_component ( self , rule_use : RuleUse ) -> bool : \"\"\"Check for duplicate component.\"\"\" retval = False component_type = rule_use . component_type component_title = rule_use . component for component in self . _component_map . values (): if component . type != component_type : continue if component . title != component_title : continue retval = True break return retval def _derive_components ( self ) -> None : \"\"\"Derive components from RuleUse list.\"\"\" self . _component_map : Dict [ str , SystemComponent ] = {} for rule_use in self . _rule_use_list : if self . _is_duplicate_component ( rule_use ): continue component_type = rule_use . component_type component_title = rule_use . component # See Note in _get_component_ref. component_description = rule_use . component component_ref = _uuid_component () status = Status1 ( state = 'operational' ) component = SystemComponent ( uuid = component_ref , type = component_type , title = component_title , description = component_description , status = status ) self . _component_map [ component_ref ] = component def _get_component_ref ( self , rule_use : RuleUse ) -> Optional [ str ]: \"\"\"Get component reference for specified rule use.\"\"\" uuid = None for component_ref , component in self . _component_map . items (): if component . type != rule_use . component_type : continue if component . title != rule_use . component : continue # Note: currently title and description are the same, # therefore checking description is not necessary. uuid = component_ref break return uuid def _derive_inventory ( self ) -> None : \"\"\"Derive inventory from RuleUse list.\"\"\" self . _inventory_map : Dict [ str , InventoryItem ] = {} for rule_use in self . _rule_use_list : if rule_use . tanium_client_ip_address in self . _inventory_map : continue inventory = InventoryItem ( uuid = _uuid_inventory (), description = 'inventory' ) inventory . props = [ self . _property_manager . materialize ( name = 'Computer_Name' , value = rule_use . computer_name , ns = self . _ns ), self . _property_manager . materialize ( name = 'Tanium_Client_IP_Address' , value = rule_use . tanium_client_ip_address , ns = self . _ns , class_ = 'scc_inventory_item_id' ), self . _property_manager . materialize ( name = 'IP_Address' , value = rule_use . ip_address , ns = self . _ns ), self . _property_manager . materialize ( name = 'Count' , value = rule_use . count , ns = self . _ns ) ] component_uuid = self . _get_component_ref ( rule_use ) if component_uuid is not None : inventory . implemented_components = [ ImplementedComponent ( component_uuid = component_uuid )] self . _inventory_map [ rule_use . tanium_client_ip_address ] = inventory def _get_inventory_ref ( self , rule_use : RuleUse ) -> str : \"\"\"Get inventory reference for specified rule use.\"\"\" return self . _inventory_map [ rule_use . tanium_client_ip_address ] . uuid def _conditional_include ( self , props : List [ Property ], group : str = None , name : str = None , value : str = None , ns : str = None , class_ : str = None ) -> None : \"\"\"Add non-aggregated property or remember common property.\"\"\" if self . _aggregate : if self . _property_accounting . is_common_property ( group = group , name = name , value = value , ns = ns , class_ = class_ ): # common property self . _property_manager . put_common_property ( group = group , name = name , value = value , ns = ns , class_ = class_ ) return # non-aggregated property props . append ( self . _property_manager . materialize ( name = name , value = value , ns = ns , class_ = class_ )) def _get_observtion_properties ( self , rule_use : RuleUse ) -> List [ Property ]: \"\"\"Get observation properties.\"\"\" props = [] group = self . _get_component_ref ( rule_use ) self . _conditional_include ( props = props , group = group , name = 'Check_ID' , value = rule_use . check_id , ns = self . _ns ) self . _conditional_include ( props = props , group = group , name = 'Check_ID_Benchmark' , value = rule_use . check_id_benchmark , ns = self . _ns , class_ = 'scc_predefined_profile' ) self . _conditional_include ( props = props , group = group , name = 'Check_ID_Version' , value = rule_use . check_id_version , ns = self . _ns , class_ = 'scc_predefined_profile_version' ) self . _conditional_include ( props = props , group = group , name = 'Check_ID_Level' , value = rule_use . check_id_level , ns = self . _ns ) self . _conditional_include ( props = props , group = group , name = 'Rule_ID' , value = rule_use . rule_id , ns = self . _ns , class_ = 'scc_goal_description' ) self . _conditional_include ( props = props , group = group , name = 'Rule_ID' , value = rule_use . rule_id , ns = self . _ns , class_ = 'scc_check_name_id' ) self . _conditional_include ( props = props , group = group , name = 'State' , value = rule_use . state , ns = self . _ns , class_ = 'scc_result' ) self . _conditional_include ( props = props , group = group , name = 'Timestamp' , value = rule_use . timestamp , ns = self . _ns , class_ = 'scc_timestamp' ) return props def _derive_common_property_accounting ( self ) -> None : \"\"\"Derive common properties accounting from RuleUse list.\"\"\" for rule_use in self . _rule_use_list : group = self . _get_component_ref ( rule_use ) self . _property_accounting . count_group ( group = group ) self . _property_accounting . count_property ( group = group , name = 'Check_ID' , value = rule_use . check_id , ns = self . _ns ) self . _property_accounting . count_property ( group = group , name = 'Check_ID_Benchmark' , value = rule_use . check_id_benchmark , ns = self . _ns , class_ = 'scc_predefined_profile' ) self . _property_accounting . count_property ( group = group , name = 'Check_ID_Version' , value = rule_use . check_id_version , ns = self . _ns , class_ = 'scc_predefined_profile_version' ) self . _property_accounting . count_property ( group = group , name = 'Check_ID_Level' , value = rule_use . check_id_level , ns = self . _ns ) self . _property_accounting . count_property ( group = group , name = 'Rule_ID' , value = rule_use . rule_id , ns = self . _ns , class_ = 'scc_goal_description' ) self . _property_accounting . count_property ( group = group , name = 'Rule_ID' , value = rule_use . rule_id , ns = self . _ns , class_ = 'scc_check_name_id' ) self . _property_accounting . count_property ( group = group , name = 'State' , value = rule_use . state , ns = self . _ns , class_ = 'scc_result' ) self . _property_accounting . count_property ( group = group , name = 'Timestamp' , value = rule_use . timestamp , ns = self . _ns , class_ = 'scc_timestamp' ) # parallel process to process one chuck of entire data set def _batch_observations ( self , index : int ) -> Dict [ str , List [ Observation ]]: \"\"\"Derive batch of observations from RuleUse list.\"\"\" observation_partial_map : Dict [ str , List [ Observation ]] = {} # determine which chunk to process batch_size = ( len ( self . _rule_use_list ) // self . _batch_workers ) + 1 start = index * batch_size end = ( index + 1 ) * batch_size end = min ( end , len ( self . _rule_use_list )) logger . debug ( f 'start: { start } end: { end - 1 } ' ) # process just the one chunk for i in range ( start , end ): rule_use = self . _rule_use_list [ i ] observation = Observation ( uuid = _uuid_observation (), description = rule_use . rule_id , methods = [ 'TEST-AUTOMATED' ], collected = rule_use . collected ) subject_uuid = self . _get_inventory_ref ( rule_use ) subject_reference = SubjectReference ( subject_uuid = subject_uuid , type = 'inventory-item' ) observation . subjects = [ subject_reference ] observation . props = self . _get_observtion_properties ( rule_use ) observation_partial_map [ subject_uuid ] = observation_partial_map . get ( subject_uuid , []) + [ observation ] return observation_partial_map @property def _batch_workers ( self ) -> int : \"\"\"Calculate number of parallel processes to employ.\"\"\" if self . _cpus is None : cpus_estimate = len ( self . _rule_use_list ) // self . _blocksize self . _cpus = max ( min ( cpus_estimate , self . _cpus_max ), self . _cpus_min ) logger . debug ( f 'CPUs estimate: { cpus_estimate } available: { os . cpu_count () } selection: { self . _cpus } ' ) return self . _cpus def _derive_observations ( self ) -> None : \"\"\"Derive observations from RuleUse list.\"\"\" self . _observation_map = {} if self . _batch_workers == 1 : # no need for multiprocessing self . _observation_map = self . _batch_observations ( 0 ) else : # use multiprocessing to perform observations creation in parallel pool = multiprocessing . Pool ( processes = self . _batch_workers ) rval_list = pool . map ( self . _batch_observations , range ( self . _batch_workers )) # gather observations from the sundry batch workers for partial_observation_map in rval_list : self . _observation_map = join_key_to_list_dicts ( self . _observation_map , partial_observation_map ) @property def components ( self ) -> List [ SystemComponent ]: \"\"\"OSCAL components.\"\"\" return list ( self . _component_map . values ()) @property def inventory ( self ) -> ValuesView [ InventoryItem ]: \"\"\"OSCAL inventory.\"\"\" return self . _inventory_map . values () @property def observations ( self ) -> List [ Observation ]: \"\"\"OSCAL observations.\"\"\" rval = [] # observations are partitioned by local-definition uuid; join them into one list for key in self . _observation_map : list_ = self . _observation_map [ key ] for observation in list_ : rval . append ( observation ) return rval @property def control_selections ( self ) -> List [ ControlSelection ]: \"\"\"OSCAL control selections.\"\"\" rval = [] rval . append ( ControlSelection ()) return rval @property def reviewed_controls ( self ) -> ReviewedControls : \"\"\"OSCAL reviewed controls.\"\"\" rval = ReviewedControls ( control_selections = self . control_selections ) return rval @property def analysis ( self ) -> List [ str ]: \"\"\"OSCAL statistics.\"\"\" analysis = [] analysis . append ( f 'components: { len ( self . components ) } ' ) analysis . append ( f 'inventory: { len ( self . inventory ) } ' ) analysis . append ( f 'observations: { len ( self . observations ) } ' ) analysis . append ( f 'cache: requests= { self . _property_manager . requests } hits= { self . _property_manager . hits } ' ) return analysis def _get_local_definitions ( self , system_component : SystemComponent ) -> LocalDefinitions1 : \"\"\"Get local definitions.\"\"\" rval = LocalDefinitions1 () for component in self . components : if component . uuid == system_component . uuid : rval . components = [ component ] rval . inventory_items = [] for inventory_item in self . inventory : for implemented_component in inventory_item . implemented_components : if implemented_component . component_uuid == system_component . uuid : rval . inventory_items . append ( inventory_item ) break return rval def _get_local_definitions_uuids ( self , local_definitions : LocalDefinitions1 ) -> List [ str ]: \"\"\"Get inventory uuids for given local definitions.\"\"\" rval = [] if local_definitions . inventory_items : rval = [ inventory_item . uuid for inventory_item in local_definitions . inventory_items ] return rval def _get_observations_for_uuid ( self , uuid_ : str ) -> List [ Observation ]: \"\"\"Get observations for given uuid.\"\"\" rval = 0 if uuid_ in self . _observation_map : rval = [] list_ = self . _observation_map [ uuid_ ] for observation in list_ : rval . append ( observation ) return rval def _get_observations ( self , local_definitions : LocalDefinitions1 ) -> List [ Observation ]: \"\"\"Get observations for given local definitions.\"\"\" rval = [] local_definitions_uuids = self . _get_local_definitions_uuids ( local_definitions ) for uuid_ in local_definitions_uuids : observations = self . _get_observations_for_uuid ( uuid_ ) if observations : rval += observations return rval def _get_properties ( self , group : str ) -> List [ Property ]: \"\"\"Get properties for given group.\"\"\" return self . _property_manager . get_common_properties ( group ) @property def results ( self ) -> List [ Result ]: \"\"\"OSCAL result.\"\"\" if self . _result is None : self . _derive_components () self . _derive_inventory () if self . _aggregate : self . _derive_common_property_accounting () self . _derive_observations () results = [] for component in self . components : local_definitions = self . _get_local_definitions ( component ) observations = self . _get_observations ( local_definitions ) result = Result ( uuid = _uuid_result (), title = 'Tanium' , description = 'Tanium' , start = self . _timestamp , end = self . _timestamp , reviewed_controls = self . reviewed_controls , local_definitions = local_definitions , observations = observations ) component_ref = component . uuid result . props = self . _get_properties ( component_ref ) results . append ( result ) return results","title":"TaniumOscalFactory"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumOscalFactory-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumOscalFactory.analysis","text":"OSCAL statistics.","title":"analysis"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumOscalFactory.components","text":"OSCAL components.","title":"components"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumOscalFactory.control_selections","text":"OSCAL control selections.","title":"control_selections"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumOscalFactory.inventory","text":"OSCAL inventory.","title":"inventory"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumOscalFactory.observations","text":"OSCAL observations.","title":"observations"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumOscalFactory.results","text":"OSCAL result.","title":"results"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumOscalFactory.reviewed_controls","text":"OSCAL reviewed controls.","title":"reviewed_controls"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumOscalFactory-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumOscalFactory.__init__","text":"Initialize given specified args. Source code in trestle/transforms/implementations/tanium.py def __init__ ( self , timestamp : str , rule_use_list : List [ RuleUse ], blocksize : int = 11000 , cpus_max : int = 1 , cpus_min : int = 1 , checking : bool = False , caching : bool = True , aggregate : bool = True ) -> None : \"\"\"Initialize given specified args.\"\"\" self . _rule_use_list = rule_use_list self . _timestamp = timestamp self . _component_map : Dict [ str , SystemComponent ] = {} self . _inventory_map : Dict [ str , InventoryItem ] = {} self . _observation_list : List [ Observation ] = [] self . _ns = 'https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium' self . _cpus = None self . _checking = checking self . _caching = caching self . _aggregate = aggregate self . _result = None # blocksize: default, min self . _blocksize = blocksize if self . _blocksize < 1 : self . _blocksize = 1 # cpus max: default, max, min self . _cpus_max = cpus_max if self . _cpus_max > os . cpu_count (): self . _cpus_max = os . cpu_count () self . _cpus_min = cpus_min if self . _cpus_min > self . _cpus_max : self . _cpus_min = self . _cpus_max if self . _cpus_min < 1 : self . _cpus_min = 1 self . _property_accounting = PropertyAccounting () self . _property_manager = PropertyManager ( caching = caching , checking = checking )","title":"__init__()"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumResultToOscalARTransformer","text":"Interface for Tanium transformer. Source code in trestle/transforms/implementations/tanium.py class TaniumResultToOscalARTransformer ( ResultsTransformer ): \"\"\"Interface for Tanium transformer.\"\"\" def __init__ ( self ) -> None : \"\"\"Initialize.\"\"\" self . _modes = {} @property def analysis ( self ) -> List [ str ]: \"\"\"Return analysis info.\"\"\" return self . _analysis @property def blocksize ( self ) -> int : \"\"\"Return blocksize.\"\"\" return self . _modes . get ( 'blocksize' , 10000 ) @property def cpus_max ( self ) -> int : \"\"\"Return cpus_max.\"\"\" return self . _modes . get ( 'cpus_max' , 1 ) @property def cpus_min ( self ) -> int : \"\"\"Return cpus_min.\"\"\" return self . _modes . get ( 'cpus_min' , 1 ) @property def aggregate ( self ) -> bool : \"\"\"Return aggregate.\"\"\" return self . _modes . get ( 'aggregate' , True ) @property def caching ( self ) -> bool : \"\"\"Return caching.\"\"\" return self . _modes . get ( 'caching' , True ) @property def checking ( self ) -> bool : \"\"\"Return checking.\"\"\" return self . _modes . get ( 'checking' , False ) def set_modes ( self , modes : Dict [ str , Any ]) -> None : \"\"\"Keep modes info.\"\"\" if modes is not None : self . _modes = modes def transform ( self , blob : str ) -> Results : \"\"\"Transform the blob into a Results.\"\"\" ts0 = datetime . datetime . now () results = Results () ru_factory = RuleUseFactory ( self . get_timestamp ()) ru_list = ru_factory . make_list ( blob ) tanium_oscal_factory = TaniumOscalFactory ( self . get_timestamp (), ru_list , self . blocksize , self . cpus_max , self . cpus_min , self . checking , self . caching , self . aggregate ) results . __root__ = tanium_oscal_factory . results ts1 = datetime . datetime . now () self . _analysis = tanium_oscal_factory . analysis self . _analysis . append ( f 'transform time: { ts1 - ts0 } ' ) return results","title":"TaniumResultToOscalARTransformer"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumResultToOscalARTransformer-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumResultToOscalARTransformer.aggregate","text":"Return aggregate.","title":"aggregate"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumResultToOscalARTransformer.analysis","text":"Return analysis info.","title":"analysis"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumResultToOscalARTransformer.blocksize","text":"Return blocksize.","title":"blocksize"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumResultToOscalARTransformer.caching","text":"Return caching.","title":"caching"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumResultToOscalARTransformer.checking","text":"Return checking.","title":"checking"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumResultToOscalARTransformer.cpus_max","text":"Return cpus_max.","title":"cpus_max"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumResultToOscalARTransformer.cpus_min","text":"Return cpus_min.","title":"cpus_min"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumResultToOscalARTransformer-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumResultToOscalARTransformer.__init__","text":"Initialize. Source code in trestle/transforms/implementations/tanium.py def __init__ ( self ) -> None : \"\"\"Initialize.\"\"\" self . _modes = {}","title":"__init__()"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumResultToOscalARTransformer.set_modes","text":"Keep modes info. Source code in trestle/transforms/implementations/tanium.py def set_modes ( self , modes : Dict [ str , Any ]) -> None : \"\"\"Keep modes info.\"\"\" if modes is not None : self . _modes = modes","title":"set_modes()"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumResultToOscalARTransformer.transform","text":"Transform the blob into a Results. Source code in trestle/transforms/implementations/tanium.py def transform ( self , blob : str ) -> Results : \"\"\"Transform the blob into a Results.\"\"\" ts0 = datetime . datetime . now () results = Results () ru_factory = RuleUseFactory ( self . get_timestamp ()) ru_list = ru_factory . make_list ( blob ) tanium_oscal_factory = TaniumOscalFactory ( self . get_timestamp (), ru_list , self . blocksize , self . cpus_max , self . cpus_min , self . checking , self . caching , self . aggregate ) results . __root__ = tanium_oscal_factory . results ts1 = datetime . datetime . now () self . _analysis = tanium_oscal_factory . analysis self . _analysis . append ( f 'transform time: { ts1 - ts0 } ' ) return results","title":"transform()"},{"location":"api_reference/trestle.transforms.implementations.tanium/#trestle.transforms.implementations.tanium.TaniumTransformer","text":"Legacy class name. Source code in trestle/transforms/implementations/tanium.py class TaniumTransformer ( TaniumResultToOscalARTransformer ): \"\"\"Legacy class name.\"\"\" handler: python","title":"TaniumTransformer"},{"location":"api_reference/trestle.transforms.results/","text":"trestle.transforms.results \u00a4 Define Results class returned by transformers. Classes \u00a4 Results ( OscalBaseModel ) pydantic-model \u00a4 Transformer results as a list. Source code in trestle/transforms/results.py class Results ( OscalBaseModel ): \"\"\"Transformer results as a list.\"\"\" __root__ : List [ Result ] = [] __root__ : List [ trestle . oscal . assessment_results . Result ] pydantic-field special \u00a4 handler: python","title":"results"},{"location":"api_reference/trestle.transforms.results/#trestle.transforms.results","text":"Define Results class returned by transformers.","title":"results"},{"location":"api_reference/trestle.transforms.results/#trestle.transforms.results-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.transforms.results/#trestle.transforms.results.Results","text":"Transformer results as a list. Source code in trestle/transforms/results.py class Results ( OscalBaseModel ): \"\"\"Transformer results as a list.\"\"\" __root__ : List [ Result ] = []","title":"Results"},{"location":"api_reference/trestle.transforms.results/#trestle.transforms.results.Results.__root__","text":"handler: python","title":"__root__"},{"location":"api_reference/trestle.transforms.transformer_factory/","text":"trestle.transforms.transformer_factory \u00a4 Define the TransformerFactory and corresponding transformer classes it creates. Classes \u00a4 FromOscalTransformer ( TransformerBase ) \u00a4 Abstract interface for transformers from OSCAL. Source code in trestle/transforms/transformer_factory.py class FromOscalTransformer ( TransformerBase ): \"\"\"Abstract interface for transformers from OSCAL.\"\"\" @abstractmethod def transform ( self , obj : OscalBaseModel ) -> str : \"\"\"Transform the from OSCAL.\"\"\" Methods \u00a4 transform ( self , obj ) \u00a4 Transform the from OSCAL. Source code in trestle/transforms/transformer_factory.py @abstractmethod def transform ( self , obj : OscalBaseModel ) -> str : \"\"\"Transform the from OSCAL.\"\"\" ResultsTransformer ( TransformerBase ) \u00a4 Abstract interface for transformers that specifically return Results. Source code in trestle/transforms/transformer_factory.py class ResultsTransformer ( TransformerBase ): \"\"\"Abstract interface for transformers that specifically return Results.\"\"\" @abstractmethod def transform ( self , blob : str ) -> Results : \"\"\"Transform the blob into Results.\"\"\" Methods \u00a4 transform ( self , blob ) \u00a4 Transform the blob into Results. Source code in trestle/transforms/transformer_factory.py @abstractmethod def transform ( self , blob : str ) -> Results : \"\"\"Transform the blob into Results.\"\"\" ToOscalTransformer ( TransformerBase ) \u00a4 Abstract interface for transformers to OSCAL. Source code in trestle/transforms/transformer_factory.py class ToOscalTransformer ( TransformerBase ): \"\"\"Abstract interface for transformers to OSCAL.\"\"\" @abstractmethod def transform ( self , obj : str ) -> OscalBaseModel : \"\"\"Transform the to OSCAL.\"\"\" Methods \u00a4 transform ( self , obj ) \u00a4 Transform the to OSCAL. Source code in trestle/transforms/transformer_factory.py @abstractmethod def transform ( self , obj : str ) -> OscalBaseModel : \"\"\"Transform the to OSCAL.\"\"\" TransformerBase ( ABC ) \u00a4 Abstract base interface for all transformers. Source code in trestle/transforms/transformer_factory.py class TransformerBase ( ABC ): \"\"\"Abstract base interface for all transformers.\"\"\" # the current time for consistent timestamping _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat () @staticmethod def set_timestamp ( value : str ) -> None : \"\"\"Set the default timestamp value.\"\"\" datetime . datetime . strptime ( value , '%Y-%m- %d T%H:%M:%S%z' ) TransformerBase . _timestamp = value @staticmethod def get_timestamp () -> str : \"\"\"Get the default timestamp value.\"\"\" return TransformerBase . _timestamp @abstractmethod def transform ( self , blob : Any ) -> Any : \"\"\"Transform the blob into a general OscalBaseModel.\"\"\" Methods \u00a4 get_timestamp () staticmethod \u00a4 Get the default timestamp value. Source code in trestle/transforms/transformer_factory.py @staticmethod def get_timestamp () -> str : \"\"\"Get the default timestamp value.\"\"\" return TransformerBase . _timestamp set_timestamp ( value ) staticmethod \u00a4 Set the default timestamp value. Source code in trestle/transforms/transformer_factory.py @staticmethod def set_timestamp ( value : str ) -> None : \"\"\"Set the default timestamp value.\"\"\" datetime . datetime . strptime ( value , '%Y-%m- %d T%H:%M:%S%z' ) TransformerBase . _timestamp = value transform ( self , blob ) \u00a4 Transform the blob into a general OscalBaseModel. Source code in trestle/transforms/transformer_factory.py @abstractmethod def transform ( self , blob : Any ) -> Any : \"\"\"Transform the blob into a general OscalBaseModel.\"\"\" TransformerFactory \u00a4 Perform registration and creation of transformers. Source code in trestle/transforms/transformer_factory.py class TransformerFactory : \"\"\"Perform registration and creation of transformers.\"\"\" def __init__ ( self ) -> None : \"\"\"Initialize the transformers dictionary as empty.\"\"\" self . _transformers : Dict [ str , Type [ TransformerBase ]] = {} def register_transformer ( self , name : str , transformer : Type [ TransformerBase ]) -> None : \"\"\" Register the transformer. This registers transformers in the factory so they may be created by name. Args: name (str): The name of the transformer. transformer (TransformerBase): The transformer class to be registered. Returns: None \"\"\" self . _transformers [ name ] = transformer def get ( self , name : str ) -> TransformerBase : \"\"\" Create an instance of the desired transformer based its name. Args: name (str): The name of the transformer. Returns: An instance of the desired transformer. Raises: TrestleError: if the name does not exist in the registry. \"\"\" t = self . _transformers . get ( name ) if t is not None : return t () raise TrestleError ( f 'Error getting non-registered transform { name } ' ) Methods \u00a4 __init__ ( self ) special \u00a4 Initialize the transformers dictionary as empty. Source code in trestle/transforms/transformer_factory.py def __init__ ( self ) -> None : \"\"\"Initialize the transformers dictionary as empty.\"\"\" self . _transformers : Dict [ str , Type [ TransformerBase ]] = {} get ( self , name ) \u00a4 Create an instance of the desired transformer based its name. Parameters: Name Type Description Default name str The name of the transformer. required Returns: Type Description TransformerBase An instance of the desired transformer. Exceptions: Type Description TrestleError if the name does not exist in the registry. Source code in trestle/transforms/transformer_factory.py def get ( self , name : str ) -> TransformerBase : \"\"\" Create an instance of the desired transformer based its name. Args: name (str): The name of the transformer. Returns: An instance of the desired transformer. Raises: TrestleError: if the name does not exist in the registry. \"\"\" t = self . _transformers . get ( name ) if t is not None : return t () raise TrestleError ( f 'Error getting non-registered transform { name } ' ) register_transformer ( self , name , transformer ) \u00a4 Register the transformer. This registers transformers in the factory so they may be created by name. Parameters: Name Type Description Default name str The name of the transformer. required transformer TransformerBase The transformer class to be registered. required Returns: Type Description None None Source code in trestle/transforms/transformer_factory.py def register_transformer ( self , name : str , transformer : Type [ TransformerBase ]) -> None : \"\"\" Register the transformer. This registers transformers in the factory so they may be created by name. Args: name (str): The name of the transformer. transformer (TransformerBase): The transformer class to be registered. Returns: None \"\"\" self . _transformers [ name ] = transformer handler: python","title":"transformer_factory"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory","text":"Define the TransformerFactory and corresponding transformer classes it creates.","title":"transformer_factory"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.FromOscalTransformer","text":"Abstract interface for transformers from OSCAL. Source code in trestle/transforms/transformer_factory.py class FromOscalTransformer ( TransformerBase ): \"\"\"Abstract interface for transformers from OSCAL.\"\"\" @abstractmethod def transform ( self , obj : OscalBaseModel ) -> str : \"\"\"Transform the from OSCAL.\"\"\"","title":"FromOscalTransformer"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.FromOscalTransformer-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.FromOscalTransformer.transform","text":"Transform the from OSCAL. Source code in trestle/transforms/transformer_factory.py @abstractmethod def transform ( self , obj : OscalBaseModel ) -> str : \"\"\"Transform the from OSCAL.\"\"\"","title":"transform()"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.ResultsTransformer","text":"Abstract interface for transformers that specifically return Results. Source code in trestle/transforms/transformer_factory.py class ResultsTransformer ( TransformerBase ): \"\"\"Abstract interface for transformers that specifically return Results.\"\"\" @abstractmethod def transform ( self , blob : str ) -> Results : \"\"\"Transform the blob into Results.\"\"\"","title":"ResultsTransformer"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.ResultsTransformer-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.ResultsTransformer.transform","text":"Transform the blob into Results. Source code in trestle/transforms/transformer_factory.py @abstractmethod def transform ( self , blob : str ) -> Results : \"\"\"Transform the blob into Results.\"\"\"","title":"transform()"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.ToOscalTransformer","text":"Abstract interface for transformers to OSCAL. Source code in trestle/transforms/transformer_factory.py class ToOscalTransformer ( TransformerBase ): \"\"\"Abstract interface for transformers to OSCAL.\"\"\" @abstractmethod def transform ( self , obj : str ) -> OscalBaseModel : \"\"\"Transform the to OSCAL.\"\"\"","title":"ToOscalTransformer"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.ToOscalTransformer-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.ToOscalTransformer.transform","text":"Transform the to OSCAL. Source code in trestle/transforms/transformer_factory.py @abstractmethod def transform ( self , obj : str ) -> OscalBaseModel : \"\"\"Transform the to OSCAL.\"\"\"","title":"transform()"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.TransformerBase","text":"Abstract base interface for all transformers. Source code in trestle/transforms/transformer_factory.py class TransformerBase ( ABC ): \"\"\"Abstract base interface for all transformers.\"\"\" # the current time for consistent timestamping _timestamp = datetime . datetime . utcnow () . replace ( microsecond = 0 ) . replace ( tzinfo = datetime . timezone . utc ) . isoformat () @staticmethod def set_timestamp ( value : str ) -> None : \"\"\"Set the default timestamp value.\"\"\" datetime . datetime . strptime ( value , '%Y-%m- %d T%H:%M:%S%z' ) TransformerBase . _timestamp = value @staticmethod def get_timestamp () -> str : \"\"\"Get the default timestamp value.\"\"\" return TransformerBase . _timestamp @abstractmethod def transform ( self , blob : Any ) -> Any : \"\"\"Transform the blob into a general OscalBaseModel.\"\"\"","title":"TransformerBase"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.TransformerBase-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.TransformerBase.get_timestamp","text":"Get the default timestamp value. Source code in trestle/transforms/transformer_factory.py @staticmethod def get_timestamp () -> str : \"\"\"Get the default timestamp value.\"\"\" return TransformerBase . _timestamp","title":"get_timestamp()"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.TransformerBase.set_timestamp","text":"Set the default timestamp value. Source code in trestle/transforms/transformer_factory.py @staticmethod def set_timestamp ( value : str ) -> None : \"\"\"Set the default timestamp value.\"\"\" datetime . datetime . strptime ( value , '%Y-%m- %d T%H:%M:%S%z' ) TransformerBase . _timestamp = value","title":"set_timestamp()"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.TransformerBase.transform","text":"Transform the blob into a general OscalBaseModel. Source code in trestle/transforms/transformer_factory.py @abstractmethod def transform ( self , blob : Any ) -> Any : \"\"\"Transform the blob into a general OscalBaseModel.\"\"\"","title":"transform()"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.TransformerFactory","text":"Perform registration and creation of transformers. Source code in trestle/transforms/transformer_factory.py class TransformerFactory : \"\"\"Perform registration and creation of transformers.\"\"\" def __init__ ( self ) -> None : \"\"\"Initialize the transformers dictionary as empty.\"\"\" self . _transformers : Dict [ str , Type [ TransformerBase ]] = {} def register_transformer ( self , name : str , transformer : Type [ TransformerBase ]) -> None : \"\"\" Register the transformer. This registers transformers in the factory so they may be created by name. Args: name (str): The name of the transformer. transformer (TransformerBase): The transformer class to be registered. Returns: None \"\"\" self . _transformers [ name ] = transformer def get ( self , name : str ) -> TransformerBase : \"\"\" Create an instance of the desired transformer based its name. Args: name (str): The name of the transformer. Returns: An instance of the desired transformer. Raises: TrestleError: if the name does not exist in the registry. \"\"\" t = self . _transformers . get ( name ) if t is not None : return t () raise TrestleError ( f 'Error getting non-registered transform { name } ' )","title":"TransformerFactory"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.TransformerFactory-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.TransformerFactory.__init__","text":"Initialize the transformers dictionary as empty. Source code in trestle/transforms/transformer_factory.py def __init__ ( self ) -> None : \"\"\"Initialize the transformers dictionary as empty.\"\"\" self . _transformers : Dict [ str , Type [ TransformerBase ]] = {}","title":"__init__()"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.TransformerFactory.get","text":"Create an instance of the desired transformer based its name. Parameters: Name Type Description Default name str The name of the transformer. required Returns: Type Description TransformerBase An instance of the desired transformer. Exceptions: Type Description TrestleError if the name does not exist in the registry. Source code in trestle/transforms/transformer_factory.py def get ( self , name : str ) -> TransformerBase : \"\"\" Create an instance of the desired transformer based its name. Args: name (str): The name of the transformer. Returns: An instance of the desired transformer. Raises: TrestleError: if the name does not exist in the registry. \"\"\" t = self . _transformers . get ( name ) if t is not None : return t () raise TrestleError ( f 'Error getting non-registered transform { name } ' )","title":"get()"},{"location":"api_reference/trestle.transforms.transformer_factory/#trestle.transforms.transformer_factory.TransformerFactory.register_transformer","text":"Register the transformer. This registers transformers in the factory so they may be created by name. Parameters: Name Type Description Default name str The name of the transformer. required transformer TransformerBase The transformer class to be registered. required Returns: Type Description None None Source code in trestle/transforms/transformer_factory.py def register_transformer ( self , name : str , transformer : Type [ TransformerBase ]) -> None : \"\"\" Register the transformer. This registers transformers in the factory so they may be created by name. Args: name (str): The name of the transformer. transformer (TransformerBase): The transformer class to be registered. Returns: None \"\"\" self . _transformers [ name ] = transformer handler: python","title":"register_transformer()"},{"location":"api_reference/trestle.transforms.transformer_helper/","text":"trestle.transforms.transformer_helper \u00a4 Transformer helper functions. Classes \u00a4 PropertyAccounting \u00a4 Property accounting class. Help transformers do accounting. Each time a new record is processed the transformer calls count_group. For each attribute on that record, the transformer calls count_property. - If the property already exactly exists, then its count is incremented. - Otherwise, a new entry is made and the count for that property is set to 1. When the transformer wants to know if a property (name, value, ns, and class) is common to all records for the group, is_common_property is employed to check that the number of records in the group is equal to the number of duplicates there are for the property. If equal, then the property is common. Source code in trestle/transforms/transformer_helper.py class PropertyAccounting (): \"\"\"Property accounting class. Help transformers do accounting. > Each time a new record is processed the transformer calls count_group. > For each attribute on that record, the transformer calls count_property. - If the property already exactly exists, then its count is incremented. - Otherwise, a new entry is made and the count for that property is set to 1. > When the transformer wants to know if a property (name, value, ns, and class) is common to all records for the group, is_common_property is employed to check that the number of records in the group is equal to the number of duplicates there are for the property. If equal, then the property is common. \"\"\" def __init__ ( self ) -> None : \"\"\"Initialize.\"\"\" self . _group_map : Dict [ str , int ] = {} self . _property_map : Dict [ str , Dict [ str : int ]] = {} def count_group ( self , group : str = None ) -> None : \"\"\"Group accounting.\"\"\" if group not in self . _group_map : self . _group_map [ group ] = 0 self . _group_map [ group ] += 1 def count_property ( self , group : str = None , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> None : \"\"\"Property accounting.\"\"\" key = _segment_separator . join ([ str ( name ), str ( value ), str ( class_ ), str ( ns )]) if group not in self . _property_map : self . _property_map [ group ] = {} if key not in self . _property_map [ group ]: self . _property_map [ group ][ key ] = 0 self . _property_map [ group ][ key ] += 1 def is_common_property ( self , group : str = None , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> bool : \"\"\"Check for common property.\"\"\" rval = False key = _segment_separator . join ([ str ( name ), str ( value ), str ( class_ ), str ( ns )]) if group in self . _group_map and key in self . _property_map [ group ]: rval = self . _group_map [ group ] == self . _property_map [ group ][ key ] return rval Methods \u00a4 __init__ ( self ) special \u00a4 Initialize. Source code in trestle/transforms/transformer_helper.py def __init__ ( self ) -> None : \"\"\"Initialize.\"\"\" self . _group_map : Dict [ str , int ] = {} self . _property_map : Dict [ str , Dict [ str : int ]] = {} count_group ( self , group = None ) \u00a4 Group accounting. Source code in trestle/transforms/transformer_helper.py def count_group ( self , group : str = None ) -> None : \"\"\"Group accounting.\"\"\" if group not in self . _group_map : self . _group_map [ group ] = 0 self . _group_map [ group ] += 1 count_property ( self , group = None , name = None , value = None , class_ = None , ns = None ) \u00a4 Property accounting. Source code in trestle/transforms/transformer_helper.py def count_property ( self , group : str = None , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> None : \"\"\"Property accounting.\"\"\" key = _segment_separator . join ([ str ( name ), str ( value ), str ( class_ ), str ( ns )]) if group not in self . _property_map : self . _property_map [ group ] = {} if key not in self . _property_map [ group ]: self . _property_map [ group ][ key ] = 0 self . _property_map [ group ][ key ] += 1 is_common_property ( self , group = None , name = None , value = None , class_ = None , ns = None ) \u00a4 Check for common property. Source code in trestle/transforms/transformer_helper.py def is_common_property ( self , group : str = None , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> bool : \"\"\"Check for common property.\"\"\" rval = False key = _segment_separator . join ([ str ( name ), str ( value ), str ( class_ ), str ( ns )]) if group in self . _group_map and key in self . _property_map [ group ]: rval = self . _group_map [ group ] == self . _property_map [ group ][ key ] return rval PropertyManager \u00a4 Property manager class. Help transformer manage properties. Use materialize to: fetch a property from cache (if caching), else create a new property instance and keep in cache (if caching). Use put_common_property to: keep common properties for each group. Use get_common_properties to: recall the list of common properties for the group. Source code in trestle/transforms/transformer_helper.py class PropertyManager (): \"\"\"Property manager class. Help transformer manage properties. > Use materialize to: fetch a property from cache (if caching), else create a new property instance and keep in cache (if caching). > Use put_common_property to: keep common properties for each group. > Use get_common_properties to: recall the list of common properties for the group. \"\"\" def __init__ ( self , caching : bool = True , checking : bool = False ) -> None : \"\"\"Initialize.\"\"\" self . _caching = caching self . _checking = checking self . _requests = 0 self . _hits = 0 self . _map_unique : Dict [ str , Any ] = {} self . _map_common : Dict [ str , Dict [ str , Property ]] = {} @property def requests ( self ) -> int : \"\"\"Cache requests.\"\"\" return self . _requests @property def hits ( self ) -> int : \"\"\"Cache hits.\"\"\" return self . _hits def materialize ( self , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> Property : \"\"\"Get property from cache or create new property.\"\"\" self . _requests += 1 # try fetch from cache key = _segment_separator . join ([ str ( name ), str ( value ), str ( class_ ), str ( ns )]) if key in self . _map_unique : self . _hits += 1 return self . _map_unique [ key ] # create new property and put into cache if caching prop = self . _create ( name = name , value = value , class_ = class_ , ns = ns ) if self . _caching : self . _map_unique [ key ] = prop return prop def put_common_property ( self , group : str = None , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> Property : \"\"\"Remember common property.\"\"\" if group not in self . _map_common : self . _map_common [ group ] = {} key = _segment_separator . join ([ str ( name ), str ( value ), str ( class_ ), str ( ns )]) if key not in self . _map_common [ group ]: prop = self . materialize ( name , value , class_ , ns ) self . _map_common [ group ][ key ] = prop def get_common_properties ( self , group : str = None ) -> List [ Property ]: \"\"\"Recall common properties for the group.\"\"\" rval = None if group in self . _map_common : rval = list ( self . _map_common [ group ] . values ()) return rval def _create ( self , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> Property : \"\"\"Create new property.\"\"\" if self . _checking : return Property ( name = name , value = value , class_ = class_ , ns = ns ) return Property . construct ( name = name , value = value , class_ = class_ , ns = ns ) Attributes \u00a4 hits : int property readonly \u00a4 Cache hits. requests : int property readonly \u00a4 Cache requests. Methods \u00a4 __init__ ( self , caching = True , checking = False ) special \u00a4 Initialize. Source code in trestle/transforms/transformer_helper.py def __init__ ( self , caching : bool = True , checking : bool = False ) -> None : \"\"\"Initialize.\"\"\" self . _caching = caching self . _checking = checking self . _requests = 0 self . _hits = 0 self . _map_unique : Dict [ str , Any ] = {} self . _map_common : Dict [ str , Dict [ str , Property ]] = {} get_common_properties ( self , group = None ) \u00a4 Recall common properties for the group. Source code in trestle/transforms/transformer_helper.py def get_common_properties ( self , group : str = None ) -> List [ Property ]: \"\"\"Recall common properties for the group.\"\"\" rval = None if group in self . _map_common : rval = list ( self . _map_common [ group ] . values ()) return rval materialize ( self , name = None , value = None , class_ = None , ns = None ) \u00a4 Get property from cache or create new property. Source code in trestle/transforms/transformer_helper.py def materialize ( self , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> Property : \"\"\"Get property from cache or create new property.\"\"\" self . _requests += 1 # try fetch from cache key = _segment_separator . join ([ str ( name ), str ( value ), str ( class_ ), str ( ns )]) if key in self . _map_unique : self . _hits += 1 return self . _map_unique [ key ] # create new property and put into cache if caching prop = self . _create ( name = name , value = value , class_ = class_ , ns = ns ) if self . _caching : self . _map_unique [ key ] = prop return prop put_common_property ( self , group = None , name = None , value = None , class_ = None , ns = None ) \u00a4 Remember common property. Source code in trestle/transforms/transformer_helper.py def put_common_property ( self , group : str = None , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> Property : \"\"\"Remember common property.\"\"\" if group not in self . _map_common : self . _map_common [ group ] = {} key = _segment_separator . join ([ str ( name ), str ( value ), str ( class_ ), str ( ns )]) if key not in self . _map_common [ group ]: prop = self . materialize ( name , value , class_ , ns ) self . _map_common [ group ][ key ] = prop TransformerHelper \u00a4 OSCAL transformer helper. Source code in trestle/transforms/transformer_helper.py class TransformerHelper (): \"\"\"OSCAL transformer helper.\"\"\" def remove_common_observation_properties ( self , observations : List [ Observation ]) -> List [ Property ]: \"\"\"Remove common observation properties.\"\"\" common_props = [] props = {} # count each property occurrence in each observation props_occurrence_counts = self . _get_property_occurrence_counts ( observations ) # remove common properties from observation for key in props_occurrence_counts . keys (): # skip property if not identical for each and every observation if props_occurrence_counts [ key ] != len ( observations ): continue # remove property from each observation and keep one instance for observation in observations : for prop in observation . props : if key == f ' { prop . name } : { prop . value } : { prop . class_ } ' : props [ key ] = prop observation . props . remove ( prop ) break # formulate list of removed properties for key in props . keys (): common_props . append ( props [ key ]) # return list of removed properties return common_props def _get_property_occurrence_counts ( self , observations : List [ Observation ]): \"\"\"Count each property occurrence in each observation.\"\"\" property_occurences = {} for observation in observations : for prop in observation . props : key = f ' { prop . name } : { prop . value } : { prop . class_ } ' if key not in property_occurences . keys (): property_occurences [ key ] = 0 property_occurences [ key ] += 1 return property_occurences Methods \u00a4 remove_common_observation_properties ( self , observations ) \u00a4 Remove common observation properties. Source code in trestle/transforms/transformer_helper.py def remove_common_observation_properties ( self , observations : List [ Observation ]) -> List [ Property ]: \"\"\"Remove common observation properties.\"\"\" common_props = [] props = {} # count each property occurrence in each observation props_occurrence_counts = self . _get_property_occurrence_counts ( observations ) # remove common properties from observation for key in props_occurrence_counts . keys (): # skip property if not identical for each and every observation if props_occurrence_counts [ key ] != len ( observations ): continue # remove property from each observation and keep one instance for observation in observations : for prop in observation . props : if key == f ' { prop . name } : { prop . value } : { prop . class_ } ' : props [ key ] = prop observation . props . remove ( prop ) break # formulate list of removed properties for key in props . keys (): common_props . append ( props [ key ]) # return list of removed properties return common_props handler: python","title":"transformer_helper"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper","text":"Transformer helper functions.","title":"transformer_helper"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper-classes","text":"","title":"Classes"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.PropertyAccounting","text":"Property accounting class. Help transformers do accounting. Each time a new record is processed the transformer calls count_group. For each attribute on that record, the transformer calls count_property. - If the property already exactly exists, then its count is incremented. - Otherwise, a new entry is made and the count for that property is set to 1. When the transformer wants to know if a property (name, value, ns, and class) is common to all records for the group, is_common_property is employed to check that the number of records in the group is equal to the number of duplicates there are for the property. If equal, then the property is common. Source code in trestle/transforms/transformer_helper.py class PropertyAccounting (): \"\"\"Property accounting class. Help transformers do accounting. > Each time a new record is processed the transformer calls count_group. > For each attribute on that record, the transformer calls count_property. - If the property already exactly exists, then its count is incremented. - Otherwise, a new entry is made and the count for that property is set to 1. > When the transformer wants to know if a property (name, value, ns, and class) is common to all records for the group, is_common_property is employed to check that the number of records in the group is equal to the number of duplicates there are for the property. If equal, then the property is common. \"\"\" def __init__ ( self ) -> None : \"\"\"Initialize.\"\"\" self . _group_map : Dict [ str , int ] = {} self . _property_map : Dict [ str , Dict [ str : int ]] = {} def count_group ( self , group : str = None ) -> None : \"\"\"Group accounting.\"\"\" if group not in self . _group_map : self . _group_map [ group ] = 0 self . _group_map [ group ] += 1 def count_property ( self , group : str = None , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> None : \"\"\"Property accounting.\"\"\" key = _segment_separator . join ([ str ( name ), str ( value ), str ( class_ ), str ( ns )]) if group not in self . _property_map : self . _property_map [ group ] = {} if key not in self . _property_map [ group ]: self . _property_map [ group ][ key ] = 0 self . _property_map [ group ][ key ] += 1 def is_common_property ( self , group : str = None , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> bool : \"\"\"Check for common property.\"\"\" rval = False key = _segment_separator . join ([ str ( name ), str ( value ), str ( class_ ), str ( ns )]) if group in self . _group_map and key in self . _property_map [ group ]: rval = self . _group_map [ group ] == self . _property_map [ group ][ key ] return rval","title":"PropertyAccounting"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.PropertyAccounting-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.PropertyAccounting.__init__","text":"Initialize. Source code in trestle/transforms/transformer_helper.py def __init__ ( self ) -> None : \"\"\"Initialize.\"\"\" self . _group_map : Dict [ str , int ] = {} self . _property_map : Dict [ str , Dict [ str : int ]] = {}","title":"__init__()"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.PropertyAccounting.count_group","text":"Group accounting. Source code in trestle/transforms/transformer_helper.py def count_group ( self , group : str = None ) -> None : \"\"\"Group accounting.\"\"\" if group not in self . _group_map : self . _group_map [ group ] = 0 self . _group_map [ group ] += 1","title":"count_group()"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.PropertyAccounting.count_property","text":"Property accounting. Source code in trestle/transforms/transformer_helper.py def count_property ( self , group : str = None , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> None : \"\"\"Property accounting.\"\"\" key = _segment_separator . join ([ str ( name ), str ( value ), str ( class_ ), str ( ns )]) if group not in self . _property_map : self . _property_map [ group ] = {} if key not in self . _property_map [ group ]: self . _property_map [ group ][ key ] = 0 self . _property_map [ group ][ key ] += 1","title":"count_property()"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.PropertyAccounting.is_common_property","text":"Check for common property. Source code in trestle/transforms/transformer_helper.py def is_common_property ( self , group : str = None , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> bool : \"\"\"Check for common property.\"\"\" rval = False key = _segment_separator . join ([ str ( name ), str ( value ), str ( class_ ), str ( ns )]) if group in self . _group_map and key in self . _property_map [ group ]: rval = self . _group_map [ group ] == self . _property_map [ group ][ key ] return rval","title":"is_common_property()"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.PropertyManager","text":"Property manager class. Help transformer manage properties. Use materialize to: fetch a property from cache (if caching), else create a new property instance and keep in cache (if caching). Use put_common_property to: keep common properties for each group. Use get_common_properties to: recall the list of common properties for the group. Source code in trestle/transforms/transformer_helper.py class PropertyManager (): \"\"\"Property manager class. Help transformer manage properties. > Use materialize to: fetch a property from cache (if caching), else create a new property instance and keep in cache (if caching). > Use put_common_property to: keep common properties for each group. > Use get_common_properties to: recall the list of common properties for the group. \"\"\" def __init__ ( self , caching : bool = True , checking : bool = False ) -> None : \"\"\"Initialize.\"\"\" self . _caching = caching self . _checking = checking self . _requests = 0 self . _hits = 0 self . _map_unique : Dict [ str , Any ] = {} self . _map_common : Dict [ str , Dict [ str , Property ]] = {} @property def requests ( self ) -> int : \"\"\"Cache requests.\"\"\" return self . _requests @property def hits ( self ) -> int : \"\"\"Cache hits.\"\"\" return self . _hits def materialize ( self , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> Property : \"\"\"Get property from cache or create new property.\"\"\" self . _requests += 1 # try fetch from cache key = _segment_separator . join ([ str ( name ), str ( value ), str ( class_ ), str ( ns )]) if key in self . _map_unique : self . _hits += 1 return self . _map_unique [ key ] # create new property and put into cache if caching prop = self . _create ( name = name , value = value , class_ = class_ , ns = ns ) if self . _caching : self . _map_unique [ key ] = prop return prop def put_common_property ( self , group : str = None , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> Property : \"\"\"Remember common property.\"\"\" if group not in self . _map_common : self . _map_common [ group ] = {} key = _segment_separator . join ([ str ( name ), str ( value ), str ( class_ ), str ( ns )]) if key not in self . _map_common [ group ]: prop = self . materialize ( name , value , class_ , ns ) self . _map_common [ group ][ key ] = prop def get_common_properties ( self , group : str = None ) -> List [ Property ]: \"\"\"Recall common properties for the group.\"\"\" rval = None if group in self . _map_common : rval = list ( self . _map_common [ group ] . values ()) return rval def _create ( self , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> Property : \"\"\"Create new property.\"\"\" if self . _checking : return Property ( name = name , value = value , class_ = class_ , ns = ns ) return Property . construct ( name = name , value = value , class_ = class_ , ns = ns )","title":"PropertyManager"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.PropertyManager-attributes","text":"","title":"Attributes"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.PropertyManager.hits","text":"Cache hits.","title":"hits"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.PropertyManager.requests","text":"Cache requests.","title":"requests"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.PropertyManager-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.PropertyManager.__init__","text":"Initialize. Source code in trestle/transforms/transformer_helper.py def __init__ ( self , caching : bool = True , checking : bool = False ) -> None : \"\"\"Initialize.\"\"\" self . _caching = caching self . _checking = checking self . _requests = 0 self . _hits = 0 self . _map_unique : Dict [ str , Any ] = {} self . _map_common : Dict [ str , Dict [ str , Property ]] = {}","title":"__init__()"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.PropertyManager.get_common_properties","text":"Recall common properties for the group. Source code in trestle/transforms/transformer_helper.py def get_common_properties ( self , group : str = None ) -> List [ Property ]: \"\"\"Recall common properties for the group.\"\"\" rval = None if group in self . _map_common : rval = list ( self . _map_common [ group ] . values ()) return rval","title":"get_common_properties()"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.PropertyManager.materialize","text":"Get property from cache or create new property. Source code in trestle/transforms/transformer_helper.py def materialize ( self , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> Property : \"\"\"Get property from cache or create new property.\"\"\" self . _requests += 1 # try fetch from cache key = _segment_separator . join ([ str ( name ), str ( value ), str ( class_ ), str ( ns )]) if key in self . _map_unique : self . _hits += 1 return self . _map_unique [ key ] # create new property and put into cache if caching prop = self . _create ( name = name , value = value , class_ = class_ , ns = ns ) if self . _caching : self . _map_unique [ key ] = prop return prop","title":"materialize()"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.PropertyManager.put_common_property","text":"Remember common property. Source code in trestle/transforms/transformer_helper.py def put_common_property ( self , group : str = None , name : str = None , value : str = None , class_ : str = None , ns : str = None ) -> Property : \"\"\"Remember common property.\"\"\" if group not in self . _map_common : self . _map_common [ group ] = {} key = _segment_separator . join ([ str ( name ), str ( value ), str ( class_ ), str ( ns )]) if key not in self . _map_common [ group ]: prop = self . materialize ( name , value , class_ , ns ) self . _map_common [ group ][ key ] = prop","title":"put_common_property()"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.TransformerHelper","text":"OSCAL transformer helper. Source code in trestle/transforms/transformer_helper.py class TransformerHelper (): \"\"\"OSCAL transformer helper.\"\"\" def remove_common_observation_properties ( self , observations : List [ Observation ]) -> List [ Property ]: \"\"\"Remove common observation properties.\"\"\" common_props = [] props = {} # count each property occurrence in each observation props_occurrence_counts = self . _get_property_occurrence_counts ( observations ) # remove common properties from observation for key in props_occurrence_counts . keys (): # skip property if not identical for each and every observation if props_occurrence_counts [ key ] != len ( observations ): continue # remove property from each observation and keep one instance for observation in observations : for prop in observation . props : if key == f ' { prop . name } : { prop . value } : { prop . class_ } ' : props [ key ] = prop observation . props . remove ( prop ) break # formulate list of removed properties for key in props . keys (): common_props . append ( props [ key ]) # return list of removed properties return common_props def _get_property_occurrence_counts ( self , observations : List [ Observation ]): \"\"\"Count each property occurrence in each observation.\"\"\" property_occurences = {} for observation in observations : for prop in observation . props : key = f ' { prop . name } : { prop . value } : { prop . class_ } ' if key not in property_occurences . keys (): property_occurences [ key ] = 0 property_occurences [ key ] += 1 return property_occurences","title":"TransformerHelper"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.TransformerHelper-methods","text":"","title":"Methods"},{"location":"api_reference/trestle.transforms.transformer_helper/#trestle.transforms.transformer_helper.TransformerHelper.remove_common_observation_properties","text":"Remove common observation properties. Source code in trestle/transforms/transformer_helper.py def remove_common_observation_properties ( self , observations : List [ Observation ]) -> List [ Property ]: \"\"\"Remove common observation properties.\"\"\" common_props = [] props = {} # count each property occurrence in each observation props_occurrence_counts = self . _get_property_occurrence_counts ( observations ) # remove common properties from observation for key in props_occurrence_counts . keys (): # skip property if not identical for each and every observation if props_occurrence_counts [ key ] != len ( observations ): continue # remove property from each observation and keep one instance for observation in observations : for prop in observation . props : if key == f ' { prop . name } : { prop . value } : { prop . class_ } ' : props [ key ] = prop observation . props . remove ( prop ) break # formulate list of removed properties for key in props . keys (): common_props . append ( props [ key ]) # return list of removed properties return common_props handler: python","title":"remove_common_observation_properties()"},{"location":"api_reference/trestle.transforms.transformer_singleton/","text":"trestle.transforms.transformer_singleton \u00a4 Create the singleton transformer factory here. transformer_factory \u00a4 handler: python","title":"transformer_singleton"},{"location":"api_reference/trestle.transforms.transformer_singleton/#trestle.transforms.transformer_singleton","text":"Create the singleton transformer factory here.","title":"transformer_singleton"},{"location":"api_reference/trestle.transforms.transformer_singleton/#trestle.transforms.transformer_singleton.transformer_factory","text":"handler: python","title":"transformer_factory"},{"location":"contributing/DCO/","text":"Developer Certificate of Origin Version 1.1 Copyright (C) 2004, 2006 The Linux Foundation and its contributors. 660 York Street, Suite 102, San Francisco, CA 94110 USA Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed. Developer's Certificate of Origin 1.1 By making a contribution to this project, I certify that: (a) The contribution was created in whole or in part by me and I have the right to submit it under the open source license indicated in the file; or (b) The contribution is based upon previous work that, to the best of my knowledge, is covered under an appropriate open source license and I have the right under that license to submit that work with modifications, whether created in whole or in part by me, under the same open source license (unless I am permitted to submit under a different license), as indicated in the file; or (c) The contribution was provided directly to me by some other person who certified (a), (b) or (c) and I have not modified it. (d) I understand and agree that this project and the contribution are public and that a record of the contribution (including all personal information I submit with it, including my sign-off) is maintained indefinitely and may be redistributed consistent with this project or the open source license(s) involved.","title":"Developer Certificate of Originality"},{"location":"contributing/mkdocs_contributing/","text":"Contributing In General \u00a4 Our project welcomes external contributions. If you have an itch, please feel free to scratch it. To contribute code or documentation, please submit a pull request . A good way to familiarize yourself with the codebase and contribution process is to look for and tackle low-hanging fruit in the issue tracker . Before embarking on a more ambitious contribution, please quickly get in touch with us. Note: We appreciate your effort, and want to avoid a situation where a contribution requires extensive rework (by you or by us), sits in backlog for a long time, or cannot be accepted at all! We have also adopted Contributor Covenant Code of Conduct . Proposing new features \u00a4 If you would like to implement a new feature, please raise an issue labelled enhancement before sending a pull request so the feature can be discussed. This is to avoid you wasting your valuable time working on a feature that the project developers are not interested in accepting into the code base. Fixing bugs \u00a4 If you would like to fix a bug, please raise an issue labelled bug before sending a pull request so it can be tracked. Merge approval \u00a4 The project maintainers use LGTM (Looks Good To Me) in comments on the code review to indicate acceptance. A change requires LGTMs from one of the maintainers. For a list of the maintainers, see the maintainers page. Trestle merging and release workflow \u00a4 trestle is operating on a simple, yet opinionated, method for continuous integration. It's designed to give developers a coherent understanding of the objectives of other past developers. The criteria for this are below. Trestle effectively uses a gitflow workflow with one modification: PR's merge into develop are squash merged as one commit. In trestle's CI environment this results in the following rules: All Commit's MUST be signed off with git commit --signoff irrespective of the author's affiliation. This ensures all code can be attributed. This is enforced by DCO bot and can be overrided by maintainers presuming at least one commit is signed-off. All commits SHOULD use conventional commits This is as github, when only one commit is in a PR, will use the native git commit message as the merge commit title. When only a single commit is provided the commit MUST be an conventional commit and will be checked the Lint PR aciton. All PR's title's MUST be formed as an convention commit This is checked by the Lint PR action All PR's to develop and hotfix PR's to main must close at least one issue by linking the PR to an issue . Trestle will release on demand the default approach for a hot fix should be to merge into develop , followed by releasing to main , unless this will release functionality that is not ready. Each feature/fix/chore (PR into develop) be represented by a single commit into develop / main with a coherent title (in the PR). The trestle preference for doing this is to use squash merge functionality when merging a PR into develop. Developers MUST pass the required CI checks for each PR. Developers are encouraged to use GitHub's automated merge process where possible to keep the number of active PR's low. Merge details for committers: \u00a4 All merges into develop MUST be conducted by a squash-merge All merges from develop into main MUST be done by a merge commit (e.g. preserving the history of commits into the develop branch). Hotfixes into main, not via develop, MUST be done via a squash merge. Merge's into any branch excluding main and develop are at the developers choice. Use of autocommit is encouraged to ensure commit messages and squash vs merge commit are completed properly. Working from a fork \u00a4 In order not to break Github Actions security model SonarCloud will not run on a fork. Given this a maintainer MAY determine that sonar needs to be run and ask you to first merge your branch to a staging branch, after reviewing for security risks in the CI pipeline. From this staging branch sonar would be run and then the code merged. Typing, docstrings and documentation \u00a4 trestle has a goal of using PEP 484 type annotations where possible / practical. The devops process does not strictly enforce typing, however, the expectation is that type coverage is added for new commits with a focus on quality over quantity (e.g. don't add Any everywhere just to meet coverage requirements). Python typing of functions is an active work in progress. mkbuild is used to generate the trestle documenation site . The mkbuild website includes an API reference section generated from the code. Docstrings within the code are expected to follow google style docstrings . Legal \u00a4 Each source file must include a license header for the Apache Software License 2.0. Using the SPDX format is the simplest approach. e.g. # Copyright (c) 2020 IBM Corp. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # https://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. We have tried to make it as easy as possible to make contributions. This applies to how we handle the legal aspects of contribution. We use the same approach - the Developer's Certificate of Origin 1.1 (DCO) - that the Linux\u00ae Kernel community uses to manage code contributions. We simply ask that when submitting a patch for review, the developer must include a sign-off statement in the commit message. Here is an example Signed-off-by line, which indicates that the submitter accepts the DCO: Signed-off-by: John Doe <john.doe@example.com> You can include this automatically when you commit a change to your local git repository using the following command: git commit --signoff Note that DCO signoff is enforced by DCO bot . Missing DCO's will be required to be rebased with a signed off commit before being accepted. Setup - Developing trestle \u00a4 Does trestle run correctly on my platform \u00a4 (Optional) setup a venv for python Run make develop This will install all python dependencies It will also checkout the submodules required for testing. Run make test This should run on all platforms Setting up vscode for python. \u00a4 Use the following commands to setup python: python3 -m venv venv . ./venv/bin/activate # for zsh put .[dev] in quotes as below pip install -q -e \".[dev]\" --upgrade --upgrade-strategy eager Install vscode plugin Python extension for Visual Studio Code Enable yapf for code formatting Enable flake8 for code linting Testing python in vscode \u00a4 Tests should be in the test subdirectory. Each file should be named test_*.py and each test function should be named *_test(). Note that with Python3 there should be no need for init .py in directories. Test discovery should be automatic when you select a .py file for editing. After tests are discovered a flask icon will appear on the left and you can select it to see a panel listing of your tests. In addition your test functions will be annotated with Run/Debug so they can be launched directly from the editor. When everything is set up properly you should be able to step through your test code - which is important. Sometimes the discovery fails - and you may need to resort to uninstalling the python extension and reinstalling it - perhaps also shutting down code and restarting. This is a lightweight operation and seems to be safe and usually fixes any problems. Test disovery will fail or stop if any of the tests have errors in them - so be sure to monitor the Problems panel at the bottom for problems in the code. Note that there are many panels available in Output - so be sure to check Python Test Log for errors and output from the tests. pytest fixtures are available to allow provision of common functionality. See conftest.py and tmp_dir for an example. NIST reference data for testing. \u00a4 Trestle relies on reference data from two NIST repositories for testing: https://github.com/usnistgov/OSCAL https://github.com/usnistgov/oscal-content Both of these repositories are submodules in the trestle project. In order to develop / test trestle the submodules must be checked out with git submodule update --init or make submodules . Code style and formating \u00a4 trestle uses yapf for code formatting and flake8 for code styling. It also uses pre-commit hooks that are integrated into the development process and the CI. When you run make develop you are ensuring that the pre-commit hooks are installed and updated to their latest versions for this repository. This ensures that all delivered code has been properly formatted and passes the linter rules. See the pre-commit configuration file for details on yapf and flake8 configurations. Since yapf and flake8 are installed as part of the pre-commit hooks, running yapf and flake8 manually must be done through pre-commit . See examples below: make code-format make code-lint ...will run yapf and flake8 on the entire repo and is equivalent to: pre-commit run yapf --all-files pre-commit run flake8 --all-files ...and when looking to limit execution to a subset of files do similar to: pre-commit run yapf --files trestle/* pre-commit run flake8 --files trestle/* Note that in both of these cases autogenerated files under trestle/oscal are excluded. Note that for IDE support setup.cfg maintains a cache of flake8 configuration.","title":"Contributing overview"},{"location":"contributing/mkdocs_contributing/#contributing-in-general","text":"Our project welcomes external contributions. If you have an itch, please feel free to scratch it. To contribute code or documentation, please submit a pull request . A good way to familiarize yourself with the codebase and contribution process is to look for and tackle low-hanging fruit in the issue tracker . Before embarking on a more ambitious contribution, please quickly get in touch with us. Note: We appreciate your effort, and want to avoid a situation where a contribution requires extensive rework (by you or by us), sits in backlog for a long time, or cannot be accepted at all! We have also adopted Contributor Covenant Code of Conduct .","title":"Contributing In General"},{"location":"contributing/mkdocs_contributing/#proposing-new-features","text":"If you would like to implement a new feature, please raise an issue labelled enhancement before sending a pull request so the feature can be discussed. This is to avoid you wasting your valuable time working on a feature that the project developers are not interested in accepting into the code base.","title":"Proposing new features"},{"location":"contributing/mkdocs_contributing/#fixing-bugs","text":"If you would like to fix a bug, please raise an issue labelled bug before sending a pull request so it can be tracked.","title":"Fixing bugs"},{"location":"contributing/mkdocs_contributing/#merge-approval","text":"The project maintainers use LGTM (Looks Good To Me) in comments on the code review to indicate acceptance. A change requires LGTMs from one of the maintainers. For a list of the maintainers, see the maintainers page.","title":"Merge approval"},{"location":"contributing/mkdocs_contributing/#trestle-merging-and-release-workflow","text":"trestle is operating on a simple, yet opinionated, method for continuous integration. It's designed to give developers a coherent understanding of the objectives of other past developers. The criteria for this are below. Trestle effectively uses a gitflow workflow with one modification: PR's merge into develop are squash merged as one commit. In trestle's CI environment this results in the following rules: All Commit's MUST be signed off with git commit --signoff irrespective of the author's affiliation. This ensures all code can be attributed. This is enforced by DCO bot and can be overrided by maintainers presuming at least one commit is signed-off. All commits SHOULD use conventional commits This is as github, when only one commit is in a PR, will use the native git commit message as the merge commit title. When only a single commit is provided the commit MUST be an conventional commit and will be checked the Lint PR aciton. All PR's title's MUST be formed as an convention commit This is checked by the Lint PR action All PR's to develop and hotfix PR's to main must close at least one issue by linking the PR to an issue . Trestle will release on demand the default approach for a hot fix should be to merge into develop , followed by releasing to main , unless this will release functionality that is not ready. Each feature/fix/chore (PR into develop) be represented by a single commit into develop / main with a coherent title (in the PR). The trestle preference for doing this is to use squash merge functionality when merging a PR into develop. Developers MUST pass the required CI checks for each PR. Developers are encouraged to use GitHub's automated merge process where possible to keep the number of active PR's low.","title":"Trestle merging and release workflow"},{"location":"contributing/mkdocs_contributing/#merge-details-for-committers","text":"All merges into develop MUST be conducted by a squash-merge All merges from develop into main MUST be done by a merge commit (e.g. preserving the history of commits into the develop branch). Hotfixes into main, not via develop, MUST be done via a squash merge. Merge's into any branch excluding main and develop are at the developers choice. Use of autocommit is encouraged to ensure commit messages and squash vs merge commit are completed properly.","title":"Merge details for committers:"},{"location":"contributing/mkdocs_contributing/#working-from-a-fork","text":"In order not to break Github Actions security model SonarCloud will not run on a fork. Given this a maintainer MAY determine that sonar needs to be run and ask you to first merge your branch to a staging branch, after reviewing for security risks in the CI pipeline. From this staging branch sonar would be run and then the code merged.","title":"Working from a fork"},{"location":"contributing/mkdocs_contributing/#typing-docstrings-and-documentation","text":"trestle has a goal of using PEP 484 type annotations where possible / practical. The devops process does not strictly enforce typing, however, the expectation is that type coverage is added for new commits with a focus on quality over quantity (e.g. don't add Any everywhere just to meet coverage requirements). Python typing of functions is an active work in progress. mkbuild is used to generate the trestle documenation site . The mkbuild website includes an API reference section generated from the code. Docstrings within the code are expected to follow google style docstrings .","title":"Typing, docstrings and documentation"},{"location":"contributing/mkdocs_contributing/#legal","text":"Each source file must include a license header for the Apache Software License 2.0. Using the SPDX format is the simplest approach. e.g. # Copyright (c) 2020 IBM Corp. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # https://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. We have tried to make it as easy as possible to make contributions. This applies to how we handle the legal aspects of contribution. We use the same approach - the Developer's Certificate of Origin 1.1 (DCO) - that the Linux\u00ae Kernel community uses to manage code contributions. We simply ask that when submitting a patch for review, the developer must include a sign-off statement in the commit message. Here is an example Signed-off-by line, which indicates that the submitter accepts the DCO: Signed-off-by: John Doe <john.doe@example.com> You can include this automatically when you commit a change to your local git repository using the following command: git commit --signoff Note that DCO signoff is enforced by DCO bot . Missing DCO's will be required to be rebased with a signed off commit before being accepted.","title":"Legal"},{"location":"contributing/mkdocs_contributing/#setup-developing-trestle","text":"","title":"Setup - Developing trestle"},{"location":"contributing/mkdocs_contributing/#does-trestle-run-correctly-on-my-platform","text":"(Optional) setup a venv for python Run make develop This will install all python dependencies It will also checkout the submodules required for testing. Run make test This should run on all platforms","title":"Does trestle run correctly on my platform"},{"location":"contributing/mkdocs_contributing/#setting-up-vscode-for-python","text":"Use the following commands to setup python: python3 -m venv venv . ./venv/bin/activate # for zsh put .[dev] in quotes as below pip install -q -e \".[dev]\" --upgrade --upgrade-strategy eager Install vscode plugin Python extension for Visual Studio Code Enable yapf for code formatting Enable flake8 for code linting","title":"Setting up vscode for python."},{"location":"contributing/mkdocs_contributing/#testing-python-in-vscode","text":"Tests should be in the test subdirectory. Each file should be named test_*.py and each test function should be named *_test(). Note that with Python3 there should be no need for init .py in directories. Test discovery should be automatic when you select a .py file for editing. After tests are discovered a flask icon will appear on the left and you can select it to see a panel listing of your tests. In addition your test functions will be annotated with Run/Debug so they can be launched directly from the editor. When everything is set up properly you should be able to step through your test code - which is important. Sometimes the discovery fails - and you may need to resort to uninstalling the python extension and reinstalling it - perhaps also shutting down code and restarting. This is a lightweight operation and seems to be safe and usually fixes any problems. Test disovery will fail or stop if any of the tests have errors in them - so be sure to monitor the Problems panel at the bottom for problems in the code. Note that there are many panels available in Output - so be sure to check Python Test Log for errors and output from the tests. pytest fixtures are available to allow provision of common functionality. See conftest.py and tmp_dir for an example.","title":"Testing python in vscode"},{"location":"contributing/mkdocs_contributing/#nist-reference-data-for-testing","text":"Trestle relies on reference data from two NIST repositories for testing: https://github.com/usnistgov/OSCAL https://github.com/usnistgov/oscal-content Both of these repositories are submodules in the trestle project. In order to develop / test trestle the submodules must be checked out with git submodule update --init or make submodules .","title":"NIST reference data for testing."},{"location":"contributing/mkdocs_contributing/#code-style-and-formating","text":"trestle uses yapf for code formatting and flake8 for code styling. It also uses pre-commit hooks that are integrated into the development process and the CI. When you run make develop you are ensuring that the pre-commit hooks are installed and updated to their latest versions for this repository. This ensures that all delivered code has been properly formatted and passes the linter rules. See the pre-commit configuration file for details on yapf and flake8 configurations. Since yapf and flake8 are installed as part of the pre-commit hooks, running yapf and flake8 manually must be done through pre-commit . See examples below: make code-format make code-lint ...will run yapf and flake8 on the entire repo and is equivalent to: pre-commit run yapf --all-files pre-commit run flake8 --all-files ...and when looking to limit execution to a subset of files do similar to: pre-commit run yapf --files trestle/* pre-commit run flake8 --files trestle/* Note that in both of these cases autogenerated files under trestle/oscal are excluded. Note that for IDE support setup.cfg maintains a cache of flake8 configuration.","title":"Code style and formating"},{"location":"contributing/plugins/","text":"Adding plugins to trestle \u00a4 Trestle provides a mechanism for 3rd party providers to extend its command interface via a plugin architecture. All trestle plugins that conforms to this specification will be automatically discovered by trestle if installed, and their command(s) will be added to trestle sub-commands list. Below we describe this plugin mechanism with the help of an example plugin compliance-trestle-fedramp that we created as a separate python project that can be installed via pip . Create the trestle plugin proejct \u00a4 A separate plugin project needs to be created that will conatin the code for plugin and its commands. This plugin can be given any name and should be available for installation via pip . For example, we created a plugin project called compliance-trestle-fedramp which can be installed as pip install compliance-trestle-fedramp . The project name doesn't need to start with compliance-trestle . Project Organization \u00a4 The plugin project should be organized as shown below. compliance-trestle-fedramp \u251c\u2500\u2500 trestle_fedramp \u2502 \u251c\u2500\u2500 __init.py__ \u2502 \u251c\u2500\u2500 commands | | \u251c\u2500\u2500 __init.py__ | | \u251c\u2500\u2500 validate.py \u2502 \u251c\u2500\u2500 <other source files or folder> \u251c\u2500\u2500 <other files or folder> Trestle uses a naming convention to discover the top-level module of the plugin projects. It expects the top-level module to be named trestle_{plugin_name} . This covention must be followed by plugins to be discoverable by trestle. In the above example, the top-level module is named as trestle_fedramp so that it can be autmatically discovered by trestle. All the python source files should be created inside this module (folder). The top-evel module should contain a commands directory where all the plugin command files should be stored. Each command should have its own python file. In the above exaample, validate.py file conatins one command for this plugin. Other python files or folders should be created in the top-level module folder, outside the commands folder. This helps in keeping the commands separate and in their discovery by trestle. Command Creation \u00a4 The plugin command should be created as shown in the below code snippet. from trestle.core.commands.command_docs import CommandBase from trestle.core.commands.command_docs import CommandPlusDocs class ValidateCmd ( CommandBase ): \"\"\"Validate contents of an OSCAL model based on FedRAMP specifications.\"\"\" name = 'fedramp-validate' def _init_arguments ( self ) -> None : logger . debug ( 'Init arguments' ) self . add_argument ( '-f' , '--file' , help = 'OSCAL file to validate.' , type = str , required = True ) self . add_argument ( '-o' , '--output-dir' , help = 'Output directory for validation results.' , type = str , required = True ) def _run ( self , args : argparse . Namespace ) -> int : model_file = pathlib . Path ( args . file ) . resolve () output_dir = pathlib . Path ( args . output_dir ) . resolve () ... ... return 0 if valid else 1 There should be a command class for example, ValidateCmd which should either extend from CommandBase or CommandPlusDocs . Trestle uses ilcli package to create commands. CommandBase extends from ilcli.Command that initializes the command including help messages and input parameters. CommandPlusDocs in turn extends from CommandBase . The difference between CommandBase and CommandPLusDocs is that CommandBase does not require command line parameter trestle-root to be set or the current directory to be a valid trestle root, whereas CommandPlusDocs requires a valid trestle-root and checks for it. Hence, depending upon the requirement of the plugin command it can extend from either of these classes. The docstring of the command class is used as the help message for the command. Input arguments to the command should be specified in _init_arguments method as shown above. The acutal code of the command is contained in _run method. This method is called by ilcli when the command is excuted on the commandline. The command arguments can be accessed from the args input parameter as shown above. The command should return 0 in case of successful execution, or any number greater than 0 in case of failure. Please see trestle.core.commands.common.return_codes.CmdReturnCodes class for specific return codes in case of failure. The command class should conatin the name field which should be set to the desired command name. In the above example, the command is called fedramp-validate . This name is automatically added to the list of sub-command names of trestle during the plugin discovery process. This command can then be invoked as trestle {name} from the commandline e.g., trestle fedramp-validate . Any input parameters to the command can also be passed on the commandline after the command name.","title":"Trestle plugin mechanism"},{"location":"contributing/plugins/#adding-plugins-to-trestle","text":"Trestle provides a mechanism for 3rd party providers to extend its command interface via a plugin architecture. All trestle plugins that conforms to this specification will be automatically discovered by trestle if installed, and their command(s) will be added to trestle sub-commands list. Below we describe this plugin mechanism with the help of an example plugin compliance-trestle-fedramp that we created as a separate python project that can be installed via pip .","title":"Adding plugins to trestle"},{"location":"contributing/plugins/#create-the-trestle-plugin-proejct","text":"A separate plugin project needs to be created that will conatin the code for plugin and its commands. This plugin can be given any name and should be available for installation via pip . For example, we created a plugin project called compliance-trestle-fedramp which can be installed as pip install compliance-trestle-fedramp . The project name doesn't need to start with compliance-trestle .","title":"Create the trestle plugin proejct"},{"location":"contributing/plugins/#project-organization","text":"The plugin project should be organized as shown below. compliance-trestle-fedramp \u251c\u2500\u2500 trestle_fedramp \u2502 \u251c\u2500\u2500 __init.py__ \u2502 \u251c\u2500\u2500 commands | | \u251c\u2500\u2500 __init.py__ | | \u251c\u2500\u2500 validate.py \u2502 \u251c\u2500\u2500 <other source files or folder> \u251c\u2500\u2500 <other files or folder> Trestle uses a naming convention to discover the top-level module of the plugin projects. It expects the top-level module to be named trestle_{plugin_name} . This covention must be followed by plugins to be discoverable by trestle. In the above example, the top-level module is named as trestle_fedramp so that it can be autmatically discovered by trestle. All the python source files should be created inside this module (folder). The top-evel module should contain a commands directory where all the plugin command files should be stored. Each command should have its own python file. In the above exaample, validate.py file conatins one command for this plugin. Other python files or folders should be created in the top-level module folder, outside the commands folder. This helps in keeping the commands separate and in their discovery by trestle.","title":"Project Organization"},{"location":"contributing/plugins/#command-creation","text":"The plugin command should be created as shown in the below code snippet. from trestle.core.commands.command_docs import CommandBase from trestle.core.commands.command_docs import CommandPlusDocs class ValidateCmd ( CommandBase ): \"\"\"Validate contents of an OSCAL model based on FedRAMP specifications.\"\"\" name = 'fedramp-validate' def _init_arguments ( self ) -> None : logger . debug ( 'Init arguments' ) self . add_argument ( '-f' , '--file' , help = 'OSCAL file to validate.' , type = str , required = True ) self . add_argument ( '-o' , '--output-dir' , help = 'Output directory for validation results.' , type = str , required = True ) def _run ( self , args : argparse . Namespace ) -> int : model_file = pathlib . Path ( args . file ) . resolve () output_dir = pathlib . Path ( args . output_dir ) . resolve () ... ... return 0 if valid else 1 There should be a command class for example, ValidateCmd which should either extend from CommandBase or CommandPlusDocs . Trestle uses ilcli package to create commands. CommandBase extends from ilcli.Command that initializes the command including help messages and input parameters. CommandPlusDocs in turn extends from CommandBase . The difference between CommandBase and CommandPLusDocs is that CommandBase does not require command line parameter trestle-root to be set or the current directory to be a valid trestle root, whereas CommandPlusDocs requires a valid trestle-root and checks for it. Hence, depending upon the requirement of the plugin command it can extend from either of these classes. The docstring of the command class is used as the help message for the command. Input arguments to the command should be specified in _init_arguments method as shown above. The acutal code of the command is contained in _run method. This method is called by ilcli when the command is excuted on the commandline. The command arguments can be accessed from the args input parameter as shown above. The command should return 0 in case of successful execution, or any number greater than 0 in case of failure. Please see trestle.core.commands.common.return_codes.CmdReturnCodes class for specific return codes in case of failure. The command class should conatin the name field which should be set to the desired command name. In the above example, the command is called fedramp-validate . This name is automatically added to the list of sub-command names of trestle during the plugin discovery process. This command can then be invoked as trestle {name} from the commandline e.g., trestle fedramp-validate . Any input parameters to the command can also be passed on the commandline after the command name.","title":"Command Creation"},{"location":"contributing/trestle_oscal_object_model/","text":"Using trestle as an object model for OSCAL \u00a4 Trestle provides an object model for OSCAL to ease the development and validation of OSCAL objects that reside in the trestle.oscal module. This functionality, which is built on pydantic and python data classes , allows validation of the OSCAL schema and is leveraged to provide a variety of utility functions including: IO Support for yaml / json / python dict serialisation see OscalBaseModel for trestle enhancements The ability to generate pro-forma objects using trestle.core.generate::generate_sample_model Integration into the flask api framework (demo) Mapping and variance with OSCAL names. \u00a4 The underlying object model that trestle relies on is the json schema published by NIST here . In understanding these models the model reference page is an indispensable source. When generating the python data class based models we have tried to be as faithful as we can to the naming convention provided by OSCAL. This is the hierarchy of rules that we have used: Do not include prepends from the json schema (e.g. assembly_oscal-catalog_catalog becomes the short name catalog ), modules are used for scoping statements OSCAL modules use hyphen case (e.g. system-security-plan ) and this is converted to CamelCase (e.g. SystemSecurityPlan ) Name collisions with reserved words in python are post-pended with an underscore (e.g. class becomes class_ ) If a model is used across multiple OSCAL schemas (e.g. metadata ) it is put into the common module( trestle.oscal.common ), otherwise it will be scoped to a model specifically for that schema. Any unresolved duplicates are resolved by adding an index e.g. class State1 OSCAL Schema mapping \u00a4 This maps between OSCAL values and the corresponding pydantic/python data class in trestle. For example, to get a catalog you would call: from pathlib import Path from trestle.oscal.catalog import Catalog my_catalog = Catalog . oscal_read ( Path ( 'path/to/file.json' )) Oscal schema json schema name Trestle module Trestle class name Catalog catalog catalog trestle.oscal.catalog Profile profile profile trestle.oscal.profile Component Definition component-definition trestle.oscal.component ComponentDefinition System Security Plan system-security-plan trestle.oscal.ssp SystemSecurityPlan Assessment Plan assessment-plan trestle.oscal.assessment_plan AssessmentPlan Assessment Results assessment-results trestle.oscal.assessment_results AssessmentResults Plan of action and milestones plan-of-action-and-milestones trestle.oscal.poam PlanOfActionAndMilestones","title":"Trestle's object model"},{"location":"contributing/trestle_oscal_object_model/#using-trestle-as-an-object-model-for-oscal","text":"Trestle provides an object model for OSCAL to ease the development and validation of OSCAL objects that reside in the trestle.oscal module. This functionality, which is built on pydantic and python data classes , allows validation of the OSCAL schema and is leveraged to provide a variety of utility functions including: IO Support for yaml / json / python dict serialisation see OscalBaseModel for trestle enhancements The ability to generate pro-forma objects using trestle.core.generate::generate_sample_model Integration into the flask api framework (demo)","title":"Using trestle as an object model for OSCAL"},{"location":"contributing/trestle_oscal_object_model/#mapping-and-variance-with-oscal-names","text":"The underlying object model that trestle relies on is the json schema published by NIST here . In understanding these models the model reference page is an indispensable source. When generating the python data class based models we have tried to be as faithful as we can to the naming convention provided by OSCAL. This is the hierarchy of rules that we have used: Do not include prepends from the json schema (e.g. assembly_oscal-catalog_catalog becomes the short name catalog ), modules are used for scoping statements OSCAL modules use hyphen case (e.g. system-security-plan ) and this is converted to CamelCase (e.g. SystemSecurityPlan ) Name collisions with reserved words in python are post-pended with an underscore (e.g. class becomes class_ ) If a model is used across multiple OSCAL schemas (e.g. metadata ) it is put into the common module( trestle.oscal.common ), otherwise it will be scoped to a model specifically for that schema. Any unresolved duplicates are resolved by adding an index e.g. class State1","title":"Mapping and variance with OSCAL names."},{"location":"contributing/trestle_oscal_object_model/#oscal-schema-mapping","text":"This maps between OSCAL values and the corresponding pydantic/python data class in trestle. For example, to get a catalog you would call: from pathlib import Path from trestle.oscal.catalog import Catalog my_catalog = Catalog . oscal_read ( Path ( 'path/to/file.json' )) Oscal schema json schema name Trestle module Trestle class name Catalog catalog catalog trestle.oscal.catalog Profile profile profile trestle.oscal.profile Component Definition component-definition trestle.oscal.component ComponentDefinition System Security Plan system-security-plan trestle.oscal.ssp SystemSecurityPlan Assessment Plan assessment-plan trestle.oscal.assessment_plan AssessmentPlan Assessment Results assessment-results trestle.oscal.assessment_results AssessmentResults Plan of action and milestones plan-of-action-and-milestones trestle.oscal.poam PlanOfActionAndMilestones","title":"OSCAL Schema mapping"},{"location":"contributing/website/","text":"Developing for the trestle documentation website \u00a4 This page describes the developing for the trestle (website) which is deployed at https://ibm.github.io/compliance-trestle . Documentation for use within the github project. \u00a4 Github uses certain files within a project such as /README.md , /CONTRIBUTING.md , LICENSE which are specifically indexed by github. The current documentation website build reuses some of these files, specifically: Contents of README.md Entirety of LICENSE Entirety of CONTRIBUTING.md Entirety of CODE_OF_CONDUCT.md Entirety of CHANGELOG.md Entirely of MAINTAINERS.md Entirely of DCO1.1.txt For this to work correctly no relative links within the github repository should exist. All links should be absolute to the documentation website. Build system and local testing of the website. \u00a4 Trestle has adopted the mkdocs system to generate this website using a small number of extensions to mkdocs. The website can be viewed locally from a clone of the compliance-trestle repo by running make docs-serve in the root directory bringing the website up at https://localhost:8000 . If you experience issues run make develop to ensure the appropriate markdown extensions are in your python environment. make docs-serve performs two actions: Runs the custom automation script scripts/website_automation.py Serves the website on localhost. All documentation specific assets are stored within the ./docs folder. The exception being mkdocs.yml which configures the documentation tree. Before opening a PR users should ensure: No warnings are generated by mkdocs All markdown documents within ./docs are included in the website navigation defined in mkdocs.yml trestle custom automation. \u00a4 In order to streamline development, and ensure the website remains up to date, a small automation script has been built. This automation script principally ensures that: License is consistent with github.com All modules are in the reference documentation running make docs-automation will ensure that the website is ready to deploy. Building the models from the OSCAL schemas. \u00a4 The creation of the OSCAL models in trestle/oscal is a multi-step process: The oscal schemas are downloaded as modules from NIST into the nist-source/json/schema directory. The script scripts/gen-oscal.py loads each schema file and converts it to pydantic/python with datamodel-codegen . The generated python files may need some fixup, so a separate script scripts/fix_any.py is run on each file. Note that there is one schema specific to IBM needs and it is loaded from 3rd-party-schema-documents/IBM_target_schema_v1.0.0.json . The whole process is handled in the Makefile by make code-gen . A normal user would never need to run this but developers may need to, particularly if there are changes to the OSCAL schemas. Also note that the depenedent tools, pydantic and datamodel-codegen, may get updated by doing a fresh make install or make develop , which may then result in a change to the model files. Items handled by fix_any.py . \u00a4 The original motivation for this script was to replace numerous situations where the type assigned to a given variable was simply Any , which meant no type enforcement would apply for that variable, defeating the purpose of the strict type enforcement provided by Pydantic. As of this writing the number of such cases has been reduced to just one - which is handled by the script. Other issues handled by the script are: The current OSCAL schemas have situations where objects are defined within different classes in a schema using the same name, but the contents of those classes may or may not be different. datamodel-codegen handles this by creating separate classes as needed and appending 1, 2 etc. to the names, keeping them distinct. The resulting high level classes that reference them behave as expected, but if components of those classes are added in a granular way by a user or developer, the correct index must be used. To reduce side-effects of the duplicate classes, classes are checked to see if they are identical or not. If they are identical the separate 1, 2 classes are culled and references to them are pointed to the non-indexed class. Currently there are 5 classes that require a separate '1' version: Status, Type, Entry, LocalDefinitions, and Action . In order to guarantee there are no induced forward references in the files, the classes are reordered to minimize the need for forwards, and any that can't be avoided are explicitly provided at the bottom of the file. The generated files have many classes that simply have a __root__ element defined, along with a description. Such classes don't have particular value in such a simple form and could instead simply be defined in the parent class. Seeing the changes induced by fix_any.py on the classes. \u00a4 As a convenience for developers, a separate script, scripts/order_classes.py is available, which orders the classes in a given file alphabetically. This way, if you use the script on files before and after applying fix_any.py you can use a normal diff tool to see the changes made. This is strictly as a development tool for doing the comparison and the resulting files will not work since they will have forward references.","title":"Documentation website"},{"location":"contributing/website/#developing-for-the-trestle-documentation-website","text":"This page describes the developing for the trestle (website) which is deployed at https://ibm.github.io/compliance-trestle .","title":"Developing for the trestle documentation website"},{"location":"contributing/website/#documentation-for-use-within-the-github-project","text":"Github uses certain files within a project such as /README.md , /CONTRIBUTING.md , LICENSE which are specifically indexed by github. The current documentation website build reuses some of these files, specifically: Contents of README.md Entirety of LICENSE Entirety of CONTRIBUTING.md Entirety of CODE_OF_CONDUCT.md Entirety of CHANGELOG.md Entirely of MAINTAINERS.md Entirely of DCO1.1.txt For this to work correctly no relative links within the github repository should exist. All links should be absolute to the documentation website.","title":"Documentation for use within the github project."},{"location":"contributing/website/#build-system-and-local-testing-of-the-website","text":"Trestle has adopted the mkdocs system to generate this website using a small number of extensions to mkdocs. The website can be viewed locally from a clone of the compliance-trestle repo by running make docs-serve in the root directory bringing the website up at https://localhost:8000 . If you experience issues run make develop to ensure the appropriate markdown extensions are in your python environment. make docs-serve performs two actions: Runs the custom automation script scripts/website_automation.py Serves the website on localhost. All documentation specific assets are stored within the ./docs folder. The exception being mkdocs.yml which configures the documentation tree. Before opening a PR users should ensure: No warnings are generated by mkdocs All markdown documents within ./docs are included in the website navigation defined in mkdocs.yml","title":"Build system and local testing of the website."},{"location":"contributing/website/#trestle-custom-automation","text":"In order to streamline development, and ensure the website remains up to date, a small automation script has been built. This automation script principally ensures that: License is consistent with github.com All modules are in the reference documentation running make docs-automation will ensure that the website is ready to deploy.","title":"trestle custom automation."},{"location":"contributing/website/#building-the-models-from-the-oscal-schemas","text":"The creation of the OSCAL models in trestle/oscal is a multi-step process: The oscal schemas are downloaded as modules from NIST into the nist-source/json/schema directory. The script scripts/gen-oscal.py loads each schema file and converts it to pydantic/python with datamodel-codegen . The generated python files may need some fixup, so a separate script scripts/fix_any.py is run on each file. Note that there is one schema specific to IBM needs and it is loaded from 3rd-party-schema-documents/IBM_target_schema_v1.0.0.json . The whole process is handled in the Makefile by make code-gen . A normal user would never need to run this but developers may need to, particularly if there are changes to the OSCAL schemas. Also note that the depenedent tools, pydantic and datamodel-codegen, may get updated by doing a fresh make install or make develop , which may then result in a change to the model files.","title":"Building the models from the OSCAL schemas."},{"location":"contributing/website/#items-handled-by-fix_anypy","text":"The original motivation for this script was to replace numerous situations where the type assigned to a given variable was simply Any , which meant no type enforcement would apply for that variable, defeating the purpose of the strict type enforcement provided by Pydantic. As of this writing the number of such cases has been reduced to just one - which is handled by the script. Other issues handled by the script are: The current OSCAL schemas have situations where objects are defined within different classes in a schema using the same name, but the contents of those classes may or may not be different. datamodel-codegen handles this by creating separate classes as needed and appending 1, 2 etc. to the names, keeping them distinct. The resulting high level classes that reference them behave as expected, but if components of those classes are added in a granular way by a user or developer, the correct index must be used. To reduce side-effects of the duplicate classes, classes are checked to see if they are identical or not. If they are identical the separate 1, 2 classes are culled and references to them are pointed to the non-indexed class. Currently there are 5 classes that require a separate '1' version: Status, Type, Entry, LocalDefinitions, and Action . In order to guarantee there are no induced forward references in the files, the classes are reordered to minimize the need for forwards, and any that can't be avoided are explicitly provided at the bottom of the file. The generated files have many classes that simply have a __root__ element defined, along with a description. Such classes don't have particular value in such a simple form and could instead simply be defined in the parent class.","title":"Items handled by fix_any.py."},{"location":"contributing/website/#seeing-the-changes-induced-by-fix_anypy-on-the-classes","text":"As a convenience for developers, a separate script, scripts/order_classes.py is available, which orders the classes in a given file alphabetically. This way, if you use the script on files before and after applying fix_any.py you can use a normal diff tool to see the changes made. This is strictly as a development tool for doing the comparison and the resulting files will not work since they will have forward references.","title":"Seeing the changes induced by fix_any.py on the classes."},{"location":"plugins/compliance-trestle-fedramp/","text":"compliance-trestle-fedramp plugin \u00a4 This plugin provides functionality for validating an SSP for FedRAMP compliance. It provides both an API interface and a trestle command for performing this validation. trestle fedramp-validate \u00a4 This command allows users to validate existing OSCAL SSP file (in JSON or YAML format) for FedRAMP compliance. For example, trestle fedramp-validate -f /local_dir/ssp.json -o report/ will validate ssp.json file for fedramp complaince and store the validation reports in report folder. The following options are supported: -f or --file : specifies the path of an existing OSCAL SSP file. It may be an absolute or relative path. The file must be in either JSON or YAML format. This is a required option. -o or --output : specifies the name of the output directory where the validation reports will be stored. It may be an absolute or relative path. The output directory should already exist. This is also a required option. The validation reports are created in XML and HTML format and provide details on which part of the SSP are not complaint as per FedRAMP specification.","title":"FedRAMP validation"},{"location":"plugins/compliance-trestle-fedramp/#compliance-trestle-fedramp-plugin","text":"This plugin provides functionality for validating an SSP for FedRAMP compliance. It provides both an API interface and a trestle command for performing this validation.","title":"compliance-trestle-fedramp plugin"},{"location":"plugins/compliance-trestle-fedramp/#trestle-fedramp-validate","text":"This command allows users to validate existing OSCAL SSP file (in JSON or YAML format) for FedRAMP compliance. For example, trestle fedramp-validate -f /local_dir/ssp.json -o report/ will validate ssp.json file for fedramp complaince and store the validation reports in report folder. The following options are supported: -f or --file : specifies the path of an existing OSCAL SSP file. It may be an absolute or relative path. The file must be in either JSON or YAML format. This is a required option. -o or --output : specifies the name of the output directory where the validation reports will be stored. It may be an absolute or relative path. The output directory should already exist. This is also a required option. The validation reports are created in XML and HTML format and provide details on which part of the SSP are not complaint as per FedRAMP specification.","title":"trestle fedramp-validate"},{"location":"reference/third-party-result-schema-SCC/","text":"Schema of Assessment Results for Interchange with IBM Cloud Security and Compliance Center, SCC \u00a4 This document depicts the structure and guidelines for creating an OSCAL result object which would be generated by various transformers for different tools such as Tanium to OSCAL and OSCO to OSCAL. Policy Validation Points (PVPs) such as toolchain that directly generate OSCAL results for sending to SCC Exchange API should follow the structure and guidelines described below. The overall object will be a results element of OSCAL Assessment Result schema wrapped in an outer json object as shown below. { \"results\" : [ { \"result\" : \"object\" }, { \"result\" : \"object\" } ] } Each result object represents one assessment scan and should have the required properties as per OSCAL schema. The start and end represents the start and end datetime of evidence collection activity. The end is optional. In addition to these, the result object may contain details about inventory, list of observations (checks) for each inventory, and findings for profile level controls (such as NIST). { \"uuid\" : \"cd54e9bf-f4d3-45d6-ae3b-6e8255847dc2\" , \"title\" : \"Tanium\" , \"description\" : \"Tanium\" , \"start\" : \"2021-04-05T20:19:11.000+00:00\" , \"end\" : \"2021-04-05T20:19:11.000+00:00\" , \"local-definitions\" : {}, \"reviewed-controls\" : {}, \"observations\" : {}, \"findings\" : {} } The inventory should be included in local-definitions if observations are being reported, but can be omitted if only findings are being reported. As reviewed-controls is required as per OSCAL schema, an empty object should be included if only observations are being reported. Optionally, the controls for which the status is being reported in findings can be captured here. The actual assessment checks being performed on different inventory items should be captured under observations . This can be omitted if only findings are being reported. As findings is required as per OSCAL schema, an empty object can be included if only observations are being reported and no profile controls are being assessed. Otherwise, findings should include the status of profile controls. General Guidance \u00a4 All the properties in the source result (tool specific format) should be represented as properties of the right objects in OSCAL such as inventory-items, observations, etc. The properties should have a tool specific namespace to convey that the property names are exactly same as what is coming from specific tools. Not everything from the non-OSCAL results are relevant (required) by SCC. The relevant properties MUST have SCC specific class such as scc_inventory_item_id, scc_result, etc. This will help SCC identify corresponding information from different tools and handle them appropriately. SCC MUST store the original property names so that when these are retrieved by tools later, they can get back the same name-value pairs as was there in the input data. There must be a pre-defined set of properties (class values) from SCC for each result object component such as inventory-items , components , observations , etc. A property value MUST be a string of appropriate format. Transforms \u00a4 File Unification SCC class for OSCO and Tanium to OSCAL.xlsx contains the SCC class mapping from Tanium and OpenShift Compliance Operator results data to OSCAL. Although other properties are constructed during transformation, only items having SCC class are shown in the table. Inventory \u00a4 Inventory is captured under local-definitions in result object. local-definitions can be used to represent inventory items, components, users, etc. For our purposes only components and inventory-items will be used. Components should be used to represent software, services, etc. whereas inventory-items represent specific machines, VMs, network devices, etc. The inventory items should be associated to a component through implemented-components as shown below. { \"local-definitions\" : { \"components\" : { \"b3e243a1-4660-4f5a-aa85-159b4b2d69ce\" : { \"type\" : \"Operating System\" , \"title\" : \"Windows 10\" , \"description\" : \"Windows 10\" , \"status\" : { \"state\" : \"operational\" } } }, \"inventory-items\" : [ { \"uuid\" : \"c9fb63cf-d21e-4584-88f8-44d67ea33ba0\" , \"description\" : \"inventory\" , \"props\" : [ { \"name\" : \"Computer Name\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"cmp-wn-2106.demo.tanium.local\" }, { \"name\" : \"Tanium Client IP Address\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"192.168.0.120\" , \"class\" : \"scc_inventory_item_id\" }, { \"name\" : \"IP Address\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"['fe80::cd44:4154:61e8:53ae', '192.168.0.120']\" }, { \"name\" : \"Count\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1\" } ], \"implemented-components\" : [ { \"component-uuid\" : \"b3e243a1-4660-4f5a-aa85-159b4b2d69ce\" } ] } ] } } Inventory items have one required property with class scc_inventory_item_id as shown above. Similarly in some other tool's result the scc_inventory_item_id may be specified through some other property. It is the job of the transformation code to appropriately specify class values for required properties. As shown above, non-mandatory property such as count from native result does not have any class specified. The type of the inventory item is specified by linking it to component via implemented-components . Observation \u00a4 Loosely speaking, an observation object equates with results from a goal check, and the observation is uniquely identified by a uuid, e.g., { \"uuid\" : \"00000000-0000-4000-9999-000000000016\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1_L1_Ensure_Enforce_password_history_is_set_to_24_or_more_passwords\" } A sample observation object generated from Tanium result looks like - { \"uuid\" : \"74b605f8-7e8c-41b3-9514-2412692fbe01\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"fail\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-11T22:34:03+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"c8919d2b-3300-4f3f-98f6-15a7104c2e04\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-11T22:34:03.000+00:00\" } An observation has five required properties - scc_predefined_profile - identifies both Goal based Profiles (eg CIS-benchmarks, IBM BP etc) and Control/Regulation based Profiles (eg. NIST, FS Cloud etc). The way the integrators or customers will differentiate between the two types of profiles is by the OSCAL element used i.e., Goal based Profiles are defined in the observation element which carries the goal id (check id) and posture. Control/Regulation based Profiles are defined in the finding element which carries the control posture, the custom profile name, and the mapping of the goal results to NIST controls scc_check_version, scc_predefined_profile_version - gives the version of the goal/profile i.e., CIS benchmark version used for check. scc_goal_description, scc_check_name_id - gives the specific goal check (rule) that was assessed from the scc_predefined_profile. scc_result - gives the outcome of performing the check. Possible values are - \"pass\", \"fail\", \"error\" , \"unknown\", \"notchecked\", \"notapplicable\". scc_timestamp - datetime for this observation. This can be date and time when this observation was performed or reported. Targets such as systems or services MUST be a subject in the observation, which MUST be identified by a uuid-ref value pointing to the subject in local-definitions. Finding \u00a4 A finding represents the assessment of a profile control such as NIST 800-53: AC-1 and the related observations. A sample finding object looks like - { \"uuid\" : \"cde35fad-3922-4046-8ef8-830e77ffd75a\" , \"title\" : \"800-53: IA-5\" , \"description\" : \"800-53: IA-5\" , \"target\" : { \"type\" : \"statement-id\" , \"id-ref\" : \"800-53: IA-5\" , \"props\" : [ { \"name\" : \"Profile\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Windows 10 - NIST 800-53\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"version: 1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Custom ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"800-53: IA-5\" } ], \"status\" : \"not-satisfied\" }, \"related-observations\" : [ { \"observation-uuid\" : \"d8bd1785-b95f-45c9-9fa8-32a362845102\" }, { \"observation-uuid\" : \"d06c6f13-5006-4e2d-b3f3-5cdb577473b1\" } ] } A finding has two required property scc_predefined_profile that gives the name of the profile whose control is specified in \"id-ref\", and scc_predefined_profile_version . If there is no finding associated with a PVP, a single finding will be created (to preserve valid OSCAL) where the UUID maps to a 'all zeros' UUID e.g.: { \"uuid\" : \"00000000-0000-4000-8000-000000000000\" , \"title\" : \"No finding\" , \"description\" : \"No finding.\" }","title":"Integrating with IBM SCC"},{"location":"reference/third-party-result-schema-SCC/#schema-of-assessment-results-for-interchange-with-ibm-cloud-security-and-compliance-center-scc","text":"This document depicts the structure and guidelines for creating an OSCAL result object which would be generated by various transformers for different tools such as Tanium to OSCAL and OSCO to OSCAL. Policy Validation Points (PVPs) such as toolchain that directly generate OSCAL results for sending to SCC Exchange API should follow the structure and guidelines described below. The overall object will be a results element of OSCAL Assessment Result schema wrapped in an outer json object as shown below. { \"results\" : [ { \"result\" : \"object\" }, { \"result\" : \"object\" } ] } Each result object represents one assessment scan and should have the required properties as per OSCAL schema. The start and end represents the start and end datetime of evidence collection activity. The end is optional. In addition to these, the result object may contain details about inventory, list of observations (checks) for each inventory, and findings for profile level controls (such as NIST). { \"uuid\" : \"cd54e9bf-f4d3-45d6-ae3b-6e8255847dc2\" , \"title\" : \"Tanium\" , \"description\" : \"Tanium\" , \"start\" : \"2021-04-05T20:19:11.000+00:00\" , \"end\" : \"2021-04-05T20:19:11.000+00:00\" , \"local-definitions\" : {}, \"reviewed-controls\" : {}, \"observations\" : {}, \"findings\" : {} } The inventory should be included in local-definitions if observations are being reported, but can be omitted if only findings are being reported. As reviewed-controls is required as per OSCAL schema, an empty object should be included if only observations are being reported. Optionally, the controls for which the status is being reported in findings can be captured here. The actual assessment checks being performed on different inventory items should be captured under observations . This can be omitted if only findings are being reported. As findings is required as per OSCAL schema, an empty object can be included if only observations are being reported and no profile controls are being assessed. Otherwise, findings should include the status of profile controls.","title":"Schema of Assessment Results for Interchange with IBM Cloud Security and Compliance Center, SCC"},{"location":"reference/third-party-result-schema-SCC/#general-guidance","text":"All the properties in the source result (tool specific format) should be represented as properties of the right objects in OSCAL such as inventory-items, observations, etc. The properties should have a tool specific namespace to convey that the property names are exactly same as what is coming from specific tools. Not everything from the non-OSCAL results are relevant (required) by SCC. The relevant properties MUST have SCC specific class such as scc_inventory_item_id, scc_result, etc. This will help SCC identify corresponding information from different tools and handle them appropriately. SCC MUST store the original property names so that when these are retrieved by tools later, they can get back the same name-value pairs as was there in the input data. There must be a pre-defined set of properties (class values) from SCC for each result object component such as inventory-items , components , observations , etc. A property value MUST be a string of appropriate format.","title":"General Guidance"},{"location":"reference/third-party-result-schema-SCC/#transforms","text":"File Unification SCC class for OSCO and Tanium to OSCAL.xlsx contains the SCC class mapping from Tanium and OpenShift Compliance Operator results data to OSCAL. Although other properties are constructed during transformation, only items having SCC class are shown in the table.","title":"Transforms"},{"location":"reference/third-party-result-schema-SCC/#inventory","text":"Inventory is captured under local-definitions in result object. local-definitions can be used to represent inventory items, components, users, etc. For our purposes only components and inventory-items will be used. Components should be used to represent software, services, etc. whereas inventory-items represent specific machines, VMs, network devices, etc. The inventory items should be associated to a component through implemented-components as shown below. { \"local-definitions\" : { \"components\" : { \"b3e243a1-4660-4f5a-aa85-159b4b2d69ce\" : { \"type\" : \"Operating System\" , \"title\" : \"Windows 10\" , \"description\" : \"Windows 10\" , \"status\" : { \"state\" : \"operational\" } } }, \"inventory-items\" : [ { \"uuid\" : \"c9fb63cf-d21e-4584-88f8-44d67ea33ba0\" , \"description\" : \"inventory\" , \"props\" : [ { \"name\" : \"Computer Name\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"cmp-wn-2106.demo.tanium.local\" }, { \"name\" : \"Tanium Client IP Address\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"192.168.0.120\" , \"class\" : \"scc_inventory_item_id\" }, { \"name\" : \"IP Address\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"['fe80::cd44:4154:61e8:53ae', '192.168.0.120']\" }, { \"name\" : \"Count\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1\" } ], \"implemented-components\" : [ { \"component-uuid\" : \"b3e243a1-4660-4f5a-aa85-159b4b2d69ce\" } ] } ] } } Inventory items have one required property with class scc_inventory_item_id as shown above. Similarly in some other tool's result the scc_inventory_item_id may be specified through some other property. It is the job of the transformation code to appropriately specify class values for required properties. As shown above, non-mandatory property such as count from native result does not have any class specified. The type of the inventory item is specified by linking it to component via implemented-components .","title":"Inventory"},{"location":"reference/third-party-result-schema-SCC/#observation","text":"Loosely speaking, an observation object equates with results from a goal check, and the observation is uniquely identified by a uuid, e.g., { \"uuid\" : \"00000000-0000-4000-9999-000000000016\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1_L1_Ensure_Enforce_password_history_is_set_to_24_or_more_passwords\" } A sample observation object generated from Tanium result looks like - { \"uuid\" : \"74b605f8-7e8c-41b3-9514-2412692fbe01\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"fail\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-11T22:34:03+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"c8919d2b-3300-4f3f-98f6-15a7104c2e04\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-11T22:34:03.000+00:00\" } An observation has five required properties - scc_predefined_profile - identifies both Goal based Profiles (eg CIS-benchmarks, IBM BP etc) and Control/Regulation based Profiles (eg. NIST, FS Cloud etc). The way the integrators or customers will differentiate between the two types of profiles is by the OSCAL element used i.e., Goal based Profiles are defined in the observation element which carries the goal id (check id) and posture. Control/Regulation based Profiles are defined in the finding element which carries the control posture, the custom profile name, and the mapping of the goal results to NIST controls scc_check_version, scc_predefined_profile_version - gives the version of the goal/profile i.e., CIS benchmark version used for check. scc_goal_description, scc_check_name_id - gives the specific goal check (rule) that was assessed from the scc_predefined_profile. scc_result - gives the outcome of performing the check. Possible values are - \"pass\", \"fail\", \"error\" , \"unknown\", \"notchecked\", \"notapplicable\". scc_timestamp - datetime for this observation. This can be date and time when this observation was performed or reported. Targets such as systems or services MUST be a subject in the observation, which MUST be identified by a uuid-ref value pointing to the subject in local-definitions.","title":"Observation"},{"location":"reference/third-party-result-schema-SCC/#finding","text":"A finding represents the assessment of a profile control such as NIST 800-53: AC-1 and the related observations. A sample finding object looks like - { \"uuid\" : \"cde35fad-3922-4046-8ef8-830e77ffd75a\" , \"title\" : \"800-53: IA-5\" , \"description\" : \"800-53: IA-5\" , \"target\" : { \"type\" : \"statement-id\" , \"id-ref\" : \"800-53: IA-5\" , \"props\" : [ { \"name\" : \"Profile\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Windows 10 - NIST 800-53\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"version: 1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Custom ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"800-53: IA-5\" } ], \"status\" : \"not-satisfied\" }, \"related-observations\" : [ { \"observation-uuid\" : \"d8bd1785-b95f-45c9-9fa8-32a362845102\" }, { \"observation-uuid\" : \"d06c6f13-5006-4e2d-b3f3-5cdb577473b1\" } ] } A finding has two required property scc_predefined_profile that gives the name of the profile whose control is specified in \"id-ref\", and scc_predefined_profile_version . If there is no finding associated with a PVP, a single finding will be created (to preserve valid OSCAL) where the UUID maps to a 'all zeros' UUID e.g.: { \"uuid\" : \"00000000-0000-4000-8000-000000000000\" , \"title\" : \"No finding\" , \"description\" : \"No finding.\" }","title":"Finding"},{"location":"tutorials/trestle_sample_workflow/","text":"Tutorial: Introduction to trestle workflow \u00a4 Here are step-by-step instructions to manipulate a NIST standard OSCAL catalog using the compliance-trestle ( \"trestle\" ) tool. Objective \u00a4 Learn how to split and merge an OSCAL catalog json file using trestle commands and its command line interface (CLI). Trestle simplifies the manipulation and management of large OSCAL documents by allowing controlled deconstruction into smaller components, and later reconstruction after editing those components. And all operations guarantee that the individual files conform to the corresponding OSCAL schema to maintain integrity of the document in the process. This tutorial assumes you have installed Python and installed trestle in a virtual environment per the directions found here . The examples shown will work for linux and mac, but Windows will require the following modifications: use backslashes `\\` for file paths (this is optional in most cases) use copy instead of cp (unless you have cp installed) use md instead of mkdir (unless you have mkdir installed) quotes (') are often not needed unless the text includes spaces, but if quotes are needed they should be double quotes (\") Commands are shown without prompts so they are easy to cut and paste, and responses by trestle are shown with >>> at the start of the line. In actual usage the >>> would not appear. Be sure to include the quotes (' ') as shown in the examples, e.g. merge -e 'catalog.*' [On windows you should probably use double quotes (\") as needed.] In this tutorial you will see sections that contain dropdown that is revealed when you click on them. Below is an example (\"Like this\"). Be sure to click on those sections to see their contents - and then close them if you like. Like this more information in here Step 1: Create a trestle workspace if you don't have one already \u00a4 mkdir my_workspace cd my_workspace trestle init >>> Initialized trestle project successfully in [ user_path ] /my_workspace Step 2: Import a catalog from the trestle sample data directory into your trestle workspace \u00a4 For this tutorial we will use a catalog file from NIST, but we first must import it into the trestle workspace. This can be done either by first downloading the file locally and then importing it, or you can download it directly using its url address. We will import the file directly from the NIST OSCAL github site . The specific catalog is NIST_SP-800-53_rev5_catalog.json Import the file from the url with the following command: trestle import -f https://raw.githubusercontent.com/usnistgov/oscal-content/master/nist.gov/SP800-53/rev5/json/NIST_SP-800-53_rev5_catalog.json -o mycatalog As a reminder, you could also have imported the file from a local directory on your file system, or an sftp:// address. But the file must first be imported to the trestle workspace in order for it to be directly manipulated by trestle as in this tutorial. The import command will also check the validity of the file including the presence of any duplicate uuid's. If the file is manually created please be sure it conforms with the current OSCAL schema (OSCAL version 1.0.2) and has no defined uuid's that are duplicates. If there are any errors the Import will fail and the file must be corrected. Your initial workspace will look like this my_workspace \u2523 .trestle \u2503 \u2523 .keep \u2503 \u2517 config.ini \u2523 assessment-plans \u2503 \u2517 .keep \u2523 assessment-results \u2503 \u2517 .keep \u2523 catalogs \u2503 \u2523 mycatalog \u2503 \u2503 \u2517 catalog.json \u2503 \u2517 .keep \u2523 component-definitions \u2503 \u2517 .keep \u2523 dist \u2503 \u2523 assessment-plans \u2503 \u2503 \u2517 .keep \u2503 \u2523 assessment-results \u2503 \u2503 \u2517 .keep \u2503 \u2523 catalogs \u2503 \u2503 \u2517 .keep \u2503 \u2523 component-definitions \u2503 \u2503 \u2517 .keep \u2503 \u2523 plan-of-action-and-milestones \u2503 \u2503 \u2517 .keep \u2503 \u2523 profiles \u2503 \u2503 \u2517 .keep \u2503 \u2523 system-security-plans \u2503 \u2503 \u2517 .keep \u2503 \u2517 target-definitions \u2503 \u2503 \u2517 .keep \u2523 plan-of-action-and-milestones \u2503 \u2517 .keep \u2523 profiles \u2503 \u2517 .keep \u2523 system-security-plans \u2503 \u2517 .keep \u2517 target-definitions \u2503 \u2517 .keep You will see that the directory now shows your catalog file in my_workspace/catalogs/mycatalog/catalog.json . Note that the .keep files are simply to make sure git does not remove the directories - and can be ignored. Also note that the json file itself is singular (catalog) while the directory above is plural (catalogs). This convention is used throughout trestle because a given model directory like catalogs may contain several individual models - each of which is singular. The imported catalog file size may be larger than the original due to a change in formatting, but the contents should be the same. From here on in this tutorial we will just focus on the catalogs directory since the others are not directly involved. You have now populated your trestle workspace with an OSCAL catalog that you can manipulate. Let's start. Step 3: Split the file into smaller parts \u00a4 The OSCAL schema specifies that a catalog must contain metadata, groups, and back-matter - so this command will pull them out of the original file and place them in separate json files for additional manipulations. To begin splitting the file, first cd to the directory where catalog.json has been placed. cd catalogs/mycatalog trestle split -f ./catalog.json -e 'catalog.metadata,catalog.groups,catalog.back-matter' Here the -f refers to the filename of the json catalog file, and -e refers to the comma-separated list of elements you would like to split from the file. This list does not represent the full file contents of the source catalog.json file, so some contents will be left behind in a much smaller catalog.json file after the split. The elements that were split off will be placed in separate json files next to the new and smaller catalog.json file. Your new catalogs directory with json files split out catalogs \u2517 mycatalog \u2503 \u2523 catalog \u2503 \u2503 \u2523 back-matter.json \u2503 \u2503 \u2523 groups.json \u2503 \u2503 \u2517 metadata.json \u2503 \u2517 catalog.json Note there still remains a catalog.json file, but it is much smaller since the bulk of its contents have been split off. Any split step can be reversed by a corresponding merge operation. In this case we can go backwards with: trestle merge -e 'catalog.metadata,catalog.groups,catalog.back-matter' or simply trestle merge -e 'catalog.*' You can go back and forth splitting and merging, but for the next step please start with the above files split so that metadata.json can be further split. Step 4: Split the metadata into constituent files \u00a4 cd catalog trestle split -f ./metadata.json -e 'metadata.roles,metadata.parties,metadata.responsible-parties' The directory will now look like this, with metadata split into files catalogs \u2517 mycatalog \u2503 \u2523 catalog \u2503 \u2503 \u2523 metadata \u2503 \u2503 \u2503 \u2523 parties.json \u2503 \u2503 \u2503 \u2523 responsible-parties.json \u2503 \u2503 \u2503 \u2517 roles.json \u2503 \u2503 \u2523 back-matter.json \u2503 \u2503 \u2523 groups.json \u2503 \u2503 \u2517 metadata.json \u2503 \u2517 catalog.json Again there remains a metadata.json file but it is smaller than the original. And this step can be reversed with the following: trestle merge -e 'metadata.roles,metadata.parties,metadata.responsible-parties' or simply trestle merge -e 'metadata.*' Step 5: Split metadata further using wildcards \u00a4 cd metadata trestle split -f ./roles.json -e 'roles.*' trestle split -f ./responsible-parties.json -e 'responsible-parties.*' The directory now looks like this, with new subdirectories containing multiple roles and responsible-parties catalogs \u2517 mycatalog \u2503 \u2523 catalog \u2503 \u2503 \u2523 metadata \u2503 \u2503 \u2503 \u2523 responsible-parties \u2503 \u2503 \u2503 \u2503 \u2523 contact__responsible-party.json \u2503 \u2503 \u2503 \u2503 \u2517 creator__responsible-party.json \u2503 \u2503 \u2503 \u2523 roles \u2503 \u2503 \u2503 \u2503 \u2523 00000__role.json \u2503 \u2503 \u2503 \u2503 \u2517 00001__role.json \u2503 \u2503 \u2503 \u2517 parties.json \u2503 \u2503 \u2523 back-matter.json \u2503 \u2503 \u2523 groups.json \u2503 \u2503 \u2517 metadata.json \u2503 \u2517 catalog.json Note that the presence of wildcards caused new directories to be created containing the full lists of roles and responsible parties. You can read the wildcard as split off all roles from roles.json . This split can be reversed with trestle merge -e 'roles.*,responsible-parties.*' Step 6: Split groups and controls with two wildcards \u00a4 This single command will split off all controls in all groups. To do it you need to go back up into the catalog directory where the groups.json file is found: cd .. trestle split -f ./groups.json -e 'groups.*.controls.*' Your directory is now very large with that one command! catalogs \u2517 mycatalog \u2503 \u2523 catalog \u2503 \u2503 \u2523 groups \u2503 \u2503 \u2503 \u2523 00000__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00012__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00013__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00014__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00015__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00016__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00017__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00018__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00019__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00020__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00021__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00022__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00023__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00024__control.json \u2503 \u2503 \u2503 \u2523 00001__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00005__control.json \u2503 \u2503 \u2503 \u2523 00002__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00012__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00013__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00014__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00015__control.json \u2503 \u2503 \u2503 \u2523 00003__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00008__control.json \u2503 \u2503 \u2503 \u2523 00004__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00012__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00013__control.json \u2503 \u2503 \u2503 \u2523 00005__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00012__control.json \u2503 \u2503 \u2503 \u2523 00006__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00011__control.json \u2503 \u2503 \u2503 \u2523 00007__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00009__control.json \u2503 \u2503 \u2503 \u2523 00008__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00006__control.json \u2503 \u2503 \u2503 \u2523 00009__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00007__control.json \u2503 \u2503 \u2503 \u2523 00010__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00012__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00013__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00014__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00015__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00016__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00017__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00018__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00019__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00020__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00021__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00022__control.json \u2503 \u2503 \u2503 \u2523 00011__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00010__control.json \u2503 \u2503 \u2503 \u2523 00012__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00012__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00013__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00014__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00015__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00016__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00017__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00018__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00019__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00020__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00021__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00022__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00023__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00024__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00025__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00026__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00027__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00028__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00029__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00030__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00031__control.json \u2503 \u2503 \u2503 \u2523 00013__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00008__control.json \u2503 \u2503 \u2503 \u2523 00014__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00007__control.json \u2503 \u2503 \u2503 \u2523 00015__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00009__control.json \u2503 \u2503 \u2503 \u2523 00016__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00012__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00013__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00014__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00015__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00016__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00017__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00018__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00019__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00020__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00021__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00022__control.json \u2503 \u2503 \u2503 \u2523 00017__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00012__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00013__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00014__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00015__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00016__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00017__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00018__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00019__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00020__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00021__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00022__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00023__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00024__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00025__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00026__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00027__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00028__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00029__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00030__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00031__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00032__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00033__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00034__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00035__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00036__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00037__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00038__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00039__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00040__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00041__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00042__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00043__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00044__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00045__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00046__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00047__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00048__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00049__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00050__control.json \u2503 \u2503 \u2503 \u2523 00018__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00012__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00013__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00014__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00015__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00016__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00017__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00018__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00019__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00020__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00021__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00022__control.json \u2503 \u2503 \u2503 \u2523 00019__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00011__control.json \u2503 \u2503 \u2503 \u2523 00000__group.json \u2503 \u2503 \u2503 \u2523 00001__group.json \u2503 \u2503 \u2503 \u2523 00002__group.json \u2503 \u2503 \u2503 \u2523 00003__group.json \u2503 \u2503 \u2503 \u2523 00004__group.json \u2503 \u2503 \u2503 \u2523 00005__group.json \u2503 \u2503 \u2503 \u2523 00006__group.json \u2503 \u2503 \u2503 \u2523 00007__group.json \u2503 \u2503 \u2503 \u2523 00008__group.json \u2503 \u2503 \u2503 \u2523 00009__group.json \u2503 \u2503 \u2503 \u2523 00010__group.json \u2503 \u2503 \u2503 \u2523 00011__group.json \u2503 \u2503 \u2503 \u2523 00012__group.json \u2503 \u2503 \u2503 \u2523 00013__group.json \u2503 \u2503 \u2503 \u2523 00014__group.json \u2503 \u2503 \u2503 \u2523 00015__group.json \u2503 \u2503 \u2503 \u2523 00016__group.json \u2503 \u2503 \u2503 \u2523 00017__group.json \u2503 \u2503 \u2503 \u2523 00018__group.json \u2503 \u2503 \u2503 \u2517 00019__group.json \u2503 \u2503 \u2523 metadata \u2503 \u2503 \u2503 \u2523 responsible-parties \u2503 \u2503 \u2503 \u2503 \u2523 contact__responsible-party.json \u2503 \u2503 \u2503 \u2503 \u2517 creator__responsible-party.json \u2503 \u2503 \u2503 \u2523 roles \u2503 \u2503 \u2503 \u2503 \u2523 00000__role.json \u2503 \u2503 \u2503 \u2503 \u2517 00001__role.json \u2503 \u2503 \u2503 \u2517 parties.json \u2503 \u2503 \u2523 back-matter.json \u2503 \u2503 \u2517 metadata.json \u2503 \u2517 catalog.json All 20 groups of controls have been split off, and each one has a corresponding directory with its full list of controls in it. You can then reverse the split with trestle merge -e 'groups.*' Step 7: Collapse the entire directory structure back into a single catalog.json file - possibly after modifying individual files \u00a4 You can collapse everything back to a single catalog.json file after first going up one directory to the mycatalog directory cd .. trestle merge -e 'catalog.*' After all that splitting and merging you are back to this directory structure catalogs \u2517 mycatalog \u2503 \u2517 catalog.json Conclusion \u00a4 This completes the tutorial on using trestle to split and merge an OSCAL catalog file. Not shown here are modifications of the individual files that would be done in an actual use case, but note that if any changes are made that violate the OSCAL schema, trestle will notice them and flag them in the merge. This way not only does trestle allow user-driven decomposition and aggregation of these large, complex files; it also does constant checks on the contents against the required schema to make sure no errors are introduced in the process.","title":"Intro to trestle workflow"},{"location":"tutorials/trestle_sample_workflow/#tutorial-introduction-to-trestle-workflow","text":"Here are step-by-step instructions to manipulate a NIST standard OSCAL catalog using the compliance-trestle ( \"trestle\" ) tool.","title":"Tutorial: Introduction to trestle workflow"},{"location":"tutorials/trestle_sample_workflow/#objective","text":"Learn how to split and merge an OSCAL catalog json file using trestle commands and its command line interface (CLI). Trestle simplifies the manipulation and management of large OSCAL documents by allowing controlled deconstruction into smaller components, and later reconstruction after editing those components. And all operations guarantee that the individual files conform to the corresponding OSCAL schema to maintain integrity of the document in the process. This tutorial assumes you have installed Python and installed trestle in a virtual environment per the directions found here . The examples shown will work for linux and mac, but Windows will require the following modifications: use backslashes `\\` for file paths (this is optional in most cases) use copy instead of cp (unless you have cp installed) use md instead of mkdir (unless you have mkdir installed) quotes (') are often not needed unless the text includes spaces, but if quotes are needed they should be double quotes (\") Commands are shown without prompts so they are easy to cut and paste, and responses by trestle are shown with >>> at the start of the line. In actual usage the >>> would not appear. Be sure to include the quotes (' ') as shown in the examples, e.g. merge -e 'catalog.*' [On windows you should probably use double quotes (\") as needed.] In this tutorial you will see sections that contain dropdown that is revealed when you click on them. Below is an example (\"Like this\"). Be sure to click on those sections to see their contents - and then close them if you like. Like this more information in here","title":"Objective"},{"location":"tutorials/trestle_sample_workflow/#step-1-create-a-trestle-workspace-if-you-dont-have-one-already","text":"mkdir my_workspace cd my_workspace trestle init >>> Initialized trestle project successfully in [ user_path ] /my_workspace","title":"Step 1: Create a trestle workspace if you don't have one already"},{"location":"tutorials/trestle_sample_workflow/#step-2-import-a-catalog-from-the-trestle-sample-data-directory-into-your-trestle-workspace","text":"For this tutorial we will use a catalog file from NIST, but we first must import it into the trestle workspace. This can be done either by first downloading the file locally and then importing it, or you can download it directly using its url address. We will import the file directly from the NIST OSCAL github site . The specific catalog is NIST_SP-800-53_rev5_catalog.json Import the file from the url with the following command: trestle import -f https://raw.githubusercontent.com/usnistgov/oscal-content/master/nist.gov/SP800-53/rev5/json/NIST_SP-800-53_rev5_catalog.json -o mycatalog As a reminder, you could also have imported the file from a local directory on your file system, or an sftp:// address. But the file must first be imported to the trestle workspace in order for it to be directly manipulated by trestle as in this tutorial. The import command will also check the validity of the file including the presence of any duplicate uuid's. If the file is manually created please be sure it conforms with the current OSCAL schema (OSCAL version 1.0.2) and has no defined uuid's that are duplicates. If there are any errors the Import will fail and the file must be corrected. Your initial workspace will look like this my_workspace \u2523 .trestle \u2503 \u2523 .keep \u2503 \u2517 config.ini \u2523 assessment-plans \u2503 \u2517 .keep \u2523 assessment-results \u2503 \u2517 .keep \u2523 catalogs \u2503 \u2523 mycatalog \u2503 \u2503 \u2517 catalog.json \u2503 \u2517 .keep \u2523 component-definitions \u2503 \u2517 .keep \u2523 dist \u2503 \u2523 assessment-plans \u2503 \u2503 \u2517 .keep \u2503 \u2523 assessment-results \u2503 \u2503 \u2517 .keep \u2503 \u2523 catalogs \u2503 \u2503 \u2517 .keep \u2503 \u2523 component-definitions \u2503 \u2503 \u2517 .keep \u2503 \u2523 plan-of-action-and-milestones \u2503 \u2503 \u2517 .keep \u2503 \u2523 profiles \u2503 \u2503 \u2517 .keep \u2503 \u2523 system-security-plans \u2503 \u2503 \u2517 .keep \u2503 \u2517 target-definitions \u2503 \u2503 \u2517 .keep \u2523 plan-of-action-and-milestones \u2503 \u2517 .keep \u2523 profiles \u2503 \u2517 .keep \u2523 system-security-plans \u2503 \u2517 .keep \u2517 target-definitions \u2503 \u2517 .keep You will see that the directory now shows your catalog file in my_workspace/catalogs/mycatalog/catalog.json . Note that the .keep files are simply to make sure git does not remove the directories - and can be ignored. Also note that the json file itself is singular (catalog) while the directory above is plural (catalogs). This convention is used throughout trestle because a given model directory like catalogs may contain several individual models - each of which is singular. The imported catalog file size may be larger than the original due to a change in formatting, but the contents should be the same. From here on in this tutorial we will just focus on the catalogs directory since the others are not directly involved. You have now populated your trestle workspace with an OSCAL catalog that you can manipulate. Let's start.","title":"Step 2: Import a catalog from the trestle sample data directory into your trestle workspace"},{"location":"tutorials/trestle_sample_workflow/#step-3-split-the-file-into-smaller-parts","text":"The OSCAL schema specifies that a catalog must contain metadata, groups, and back-matter - so this command will pull them out of the original file and place them in separate json files for additional manipulations. To begin splitting the file, first cd to the directory where catalog.json has been placed. cd catalogs/mycatalog trestle split -f ./catalog.json -e 'catalog.metadata,catalog.groups,catalog.back-matter' Here the -f refers to the filename of the json catalog file, and -e refers to the comma-separated list of elements you would like to split from the file. This list does not represent the full file contents of the source catalog.json file, so some contents will be left behind in a much smaller catalog.json file after the split. The elements that were split off will be placed in separate json files next to the new and smaller catalog.json file. Your new catalogs directory with json files split out catalogs \u2517 mycatalog \u2503 \u2523 catalog \u2503 \u2503 \u2523 back-matter.json \u2503 \u2503 \u2523 groups.json \u2503 \u2503 \u2517 metadata.json \u2503 \u2517 catalog.json Note there still remains a catalog.json file, but it is much smaller since the bulk of its contents have been split off. Any split step can be reversed by a corresponding merge operation. In this case we can go backwards with: trestle merge -e 'catalog.metadata,catalog.groups,catalog.back-matter' or simply trestle merge -e 'catalog.*' You can go back and forth splitting and merging, but for the next step please start with the above files split so that metadata.json can be further split.","title":"Step 3: Split the file into smaller parts"},{"location":"tutorials/trestle_sample_workflow/#step-4-split-the-metadata-into-constituent-files","text":"cd catalog trestle split -f ./metadata.json -e 'metadata.roles,metadata.parties,metadata.responsible-parties' The directory will now look like this, with metadata split into files catalogs \u2517 mycatalog \u2503 \u2523 catalog \u2503 \u2503 \u2523 metadata \u2503 \u2503 \u2503 \u2523 parties.json \u2503 \u2503 \u2503 \u2523 responsible-parties.json \u2503 \u2503 \u2503 \u2517 roles.json \u2503 \u2503 \u2523 back-matter.json \u2503 \u2503 \u2523 groups.json \u2503 \u2503 \u2517 metadata.json \u2503 \u2517 catalog.json Again there remains a metadata.json file but it is smaller than the original. And this step can be reversed with the following: trestle merge -e 'metadata.roles,metadata.parties,metadata.responsible-parties' or simply trestle merge -e 'metadata.*'","title":"Step 4: Split the metadata into constituent files"},{"location":"tutorials/trestle_sample_workflow/#step-5-split-metadata-further-using-wildcards","text":"cd metadata trestle split -f ./roles.json -e 'roles.*' trestle split -f ./responsible-parties.json -e 'responsible-parties.*' The directory now looks like this, with new subdirectories containing multiple roles and responsible-parties catalogs \u2517 mycatalog \u2503 \u2523 catalog \u2503 \u2503 \u2523 metadata \u2503 \u2503 \u2503 \u2523 responsible-parties \u2503 \u2503 \u2503 \u2503 \u2523 contact__responsible-party.json \u2503 \u2503 \u2503 \u2503 \u2517 creator__responsible-party.json \u2503 \u2503 \u2503 \u2523 roles \u2503 \u2503 \u2503 \u2503 \u2523 00000__role.json \u2503 \u2503 \u2503 \u2503 \u2517 00001__role.json \u2503 \u2503 \u2503 \u2517 parties.json \u2503 \u2503 \u2523 back-matter.json \u2503 \u2503 \u2523 groups.json \u2503 \u2503 \u2517 metadata.json \u2503 \u2517 catalog.json Note that the presence of wildcards caused new directories to be created containing the full lists of roles and responsible parties. You can read the wildcard as split off all roles from roles.json . This split can be reversed with trestle merge -e 'roles.*,responsible-parties.*'","title":"Step 5: Split metadata further using wildcards"},{"location":"tutorials/trestle_sample_workflow/#step-6-split-groups-and-controls-with-two-wildcards","text":"This single command will split off all controls in all groups. To do it you need to go back up into the catalog directory where the groups.json file is found: cd .. trestle split -f ./groups.json -e 'groups.*.controls.*' Your directory is now very large with that one command! catalogs \u2517 mycatalog \u2503 \u2523 catalog \u2503 \u2503 \u2523 groups \u2503 \u2503 \u2503 \u2523 00000__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00012__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00013__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00014__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00015__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00016__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00017__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00018__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00019__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00020__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00021__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00022__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00023__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00024__control.json \u2503 \u2503 \u2503 \u2523 00001__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00005__control.json \u2503 \u2503 \u2503 \u2523 00002__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00012__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00013__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00014__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00015__control.json \u2503 \u2503 \u2503 \u2523 00003__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00008__control.json \u2503 \u2503 \u2503 \u2523 00004__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00012__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00013__control.json \u2503 \u2503 \u2503 \u2523 00005__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00012__control.json \u2503 \u2503 \u2503 \u2523 00006__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00011__control.json \u2503 \u2503 \u2503 \u2523 00007__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00009__control.json \u2503 \u2503 \u2503 \u2523 00008__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00006__control.json \u2503 \u2503 \u2503 \u2523 00009__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00007__control.json \u2503 \u2503 \u2503 \u2523 00010__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00012__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00013__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00014__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00015__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00016__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00017__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00018__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00019__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00020__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00021__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00022__control.json \u2503 \u2503 \u2503 \u2523 00011__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00010__control.json \u2503 \u2503 \u2503 \u2523 00012__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00012__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00013__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00014__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00015__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00016__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00017__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00018__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00019__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00020__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00021__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00022__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00023__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00024__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00025__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00026__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00027__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00028__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00029__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00030__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00031__control.json \u2503 \u2503 \u2503 \u2523 00013__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00008__control.json \u2503 \u2503 \u2503 \u2523 00014__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00007__control.json \u2503 \u2503 \u2503 \u2523 00015__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00009__control.json \u2503 \u2503 \u2503 \u2523 00016__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00012__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00013__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00014__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00015__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00016__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00017__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00018__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00019__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00020__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00021__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00022__control.json \u2503 \u2503 \u2503 \u2523 00017__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00012__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00013__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00014__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00015__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00016__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00017__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00018__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00019__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00020__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00021__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00022__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00023__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00024__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00025__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00026__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00027__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00028__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00029__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00030__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00031__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00032__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00033__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00034__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00035__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00036__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00037__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00038__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00039__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00040__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00041__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00042__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00043__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00044__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00045__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00046__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00047__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00048__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00049__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00050__control.json \u2503 \u2503 \u2503 \u2523 00018__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00011__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00012__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00013__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00014__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00015__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00016__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00017__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00018__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00019__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00020__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00021__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00022__control.json \u2503 \u2503 \u2503 \u2523 00019__group \u2503 \u2503 \u2503 \u2503 \u2517 controls \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00000__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00001__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00002__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00003__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00004__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00005__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00006__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00007__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00008__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00009__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2523 00010__control.json \u2503 \u2503 \u2503 \u2503 \u2503 \u2517 00011__control.json \u2503 \u2503 \u2503 \u2523 00000__group.json \u2503 \u2503 \u2503 \u2523 00001__group.json \u2503 \u2503 \u2503 \u2523 00002__group.json \u2503 \u2503 \u2503 \u2523 00003__group.json \u2503 \u2503 \u2503 \u2523 00004__group.json \u2503 \u2503 \u2503 \u2523 00005__group.json \u2503 \u2503 \u2503 \u2523 00006__group.json \u2503 \u2503 \u2503 \u2523 00007__group.json \u2503 \u2503 \u2503 \u2523 00008__group.json \u2503 \u2503 \u2503 \u2523 00009__group.json \u2503 \u2503 \u2503 \u2523 00010__group.json \u2503 \u2503 \u2503 \u2523 00011__group.json \u2503 \u2503 \u2503 \u2523 00012__group.json \u2503 \u2503 \u2503 \u2523 00013__group.json \u2503 \u2503 \u2503 \u2523 00014__group.json \u2503 \u2503 \u2503 \u2523 00015__group.json \u2503 \u2503 \u2503 \u2523 00016__group.json \u2503 \u2503 \u2503 \u2523 00017__group.json \u2503 \u2503 \u2503 \u2523 00018__group.json \u2503 \u2503 \u2503 \u2517 00019__group.json \u2503 \u2503 \u2523 metadata \u2503 \u2503 \u2503 \u2523 responsible-parties \u2503 \u2503 \u2503 \u2503 \u2523 contact__responsible-party.json \u2503 \u2503 \u2503 \u2503 \u2517 creator__responsible-party.json \u2503 \u2503 \u2503 \u2523 roles \u2503 \u2503 \u2503 \u2503 \u2523 00000__role.json \u2503 \u2503 \u2503 \u2503 \u2517 00001__role.json \u2503 \u2503 \u2503 \u2517 parties.json \u2503 \u2503 \u2523 back-matter.json \u2503 \u2503 \u2517 metadata.json \u2503 \u2517 catalog.json All 20 groups of controls have been split off, and each one has a corresponding directory with its full list of controls in it. You can then reverse the split with trestle merge -e 'groups.*'","title":"Step 6: Split groups and controls with two wildcards"},{"location":"tutorials/trestle_sample_workflow/#step-7-collapse-the-entire-directory-structure-back-into-a-single-catalogjson-file-possibly-after-modifying-individual-files","text":"You can collapse everything back to a single catalog.json file after first going up one directory to the mycatalog directory cd .. trestle merge -e 'catalog.*' After all that splitting and merging you are back to this directory structure catalogs \u2517 mycatalog \u2503 \u2517 catalog.json","title":"Step 7: Collapse the entire directory structure back into a single catalog.json file - possibly after modifying individual files"},{"location":"tutorials/trestle_sample_workflow/#conclusion","text":"This completes the tutorial on using trestle to split and merge an OSCAL catalog file. Not shown here are modifications of the individual files that would be done in an actual use case, but note that if any changes are made that violate the OSCAL schema, trestle will notice them and flag them in the merge. This way not only does trestle allow user-driven decomposition and aggregation of these large, complex files; it also does constant checks on the contents against the required schema to make sure no errors are introduced in the process.","title":"Conclusion"},{"location":"tutorials/work_with_authoring_versions/","text":"Tutorial: Work with template versions when authoring \u00a4 Here are step-by-step instructions on how to work with template versions when authoring content using the compliance-trestle ( \"trestle\" ) tool. Step 1: Create a trestle workspace if you don't have one already \u00a4 mkdir my_workspace cd my_workspace trestle init >>> Initialized trestle project successfully in [ user_path ] /my_workspace Step 2: Setup or create a new template version \u00a4 cd my_workspce trestle author docs setup -tn version_test -tv 0 .0.2 >>> Set template version to 0 .0.2. >>> Template file setup for task version_test at .trestle/author/version_test/0.0.2/template.md >>> Task directory is version_test Note: version 0.0.1 is reserved for unversioned documents. Step 3: Create a new document using a particular template version \u00a4 cd my_workspce trestle author docs create-sample -tn version_test -tv 0 .0.2 >>> Set template version to 0 .0.2. Step 4: Validate documents against a particular template version \u00a4 cd my_workspce trestle author docs validate -tn version_test >>> Instances will be validated against template version specified in their headers. >>> VALID: version_test/version_test_000.md","title":"Work with authoring versions"},{"location":"tutorials/work_with_authoring_versions/#tutorial-work-with-template-versions-when-authoring","text":"Here are step-by-step instructions on how to work with template versions when authoring content using the compliance-trestle ( \"trestle\" ) tool.","title":"Tutorial: Work with template versions when authoring"},{"location":"tutorials/work_with_authoring_versions/#step-1-create-a-trestle-workspace-if-you-dont-have-one-already","text":"mkdir my_workspace cd my_workspace trestle init >>> Initialized trestle project successfully in [ user_path ] /my_workspace","title":"Step 1: Create a trestle workspace if you don't have one already"},{"location":"tutorials/work_with_authoring_versions/#step-2-setup-or-create-a-new-template-version","text":"cd my_workspce trestle author docs setup -tn version_test -tv 0 .0.2 >>> Set template version to 0 .0.2. >>> Template file setup for task version_test at .trestle/author/version_test/0.0.2/template.md >>> Task directory is version_test Note: version 0.0.1 is reserved for unversioned documents.","title":"Step 2: Setup or create a new template version"},{"location":"tutorials/work_with_authoring_versions/#step-3-create-a-new-document-using-a-particular-template-version","text":"cd my_workspce trestle author docs create-sample -tn version_test -tv 0 .0.2 >>> Set template version to 0 .0.2.","title":"Step 3: Create a new document using a particular template version"},{"location":"tutorials/work_with_authoring_versions/#step-4-validate-documents-against-a-particular-template-version","text":"cd my_workspce trestle author docs validate -tn version_test >>> Instances will be validated against template version specified in their headers. >>> VALID: version_test/version_test_000.md","title":"Step 4: Validate documents against a particular template version"},{"location":"tutorials/continuous-compliance/continuous-compliance/","text":"Tutorial: What\u2019s your compliance posture? \u00a4 Introduction \u00a4 The cloud with its continuous integration and continuous deployment is the modern computing paradigm. There is a plethora of cloud environments: public, private, on-premise, hybrid-cloud, multi-cloud, etc. along with a corresponding contingent of vendors. The cloud offers great flexibility where you can choose just one or some combination optimal for each application. But, as demonstrated from time to time, the cloud can be a dangerous place. Hackers, bots, malware, and more are constant threats seeking to find and exploit weakness in your computing solution. To combat them there are strategies to avoid embarrassment and financial ruin from security breeches. Educating your workforce is of paramount importance. Moreover, employing a trust-but-verify strategy will go a long way toward deflecting trouble. The time has come for continuous auditing, and giving stakeholders (such as account owners, application owners, system owners and compliance officers) a current picture of their compliance posture: Are password rules being followed? Are deployed applications using compromised encryption algorithms? Has a user gotten elevated privileges? Are unauthorized open source projects wrongfully part of your application stack? Getting answers to these questions only quarterly or annually is leaving you exposed. Moreover, assuring continuous compliance across multiple cloud vendors can complicate matters. If each has its own compliance regime, then one must become expert in each domain\u2019s compliance solution space, or else be wedded to a single or few providers. That is not an ideal prospect. Common sense dictates that standardization would simplify matters. The National Institute of Standards and Technologies (NIST) is developing the Open Security Controls Assessment Language ( OSCAL ). The compliance- trestle open source github project is an effort to employ OSCAL for compliance standardization and automation. Of great utility is the trestle oscal module that facilitates transformation of data to/from Python object representations in accordance with the OSCAL schemas. Simple Continuous Compliance Architecture \u00a4 Cloud Services can often be configured to monitor (and sometimes enforce) policies. Examples include OpenShift Compliance Operator and Tanium. However, the compliance reporting \u201craw\u201d data produced is unique to each. Two steps are needed to ascertain your compliance posture. Step 1 is to transform available compliance \u201craw\u201d data into standardized form ( OSCAL ). Step 2 is to examine the OSCAL data and assemble a compliance posture for the controls and components of interest. And trestle is the go-to solution. Step 1 \u2013 Transformation \u00a4 The bad news is that a transformer to OSCAL is needed for each Cloud Service type. However, there is plenty of good news: a transformer for your Cloud Service type may already exist, such as: Tanium to OSCAL , OpenShift Compliance Operator to OSCAL once a transformer for a Cloud Service type has been written, it can be open-sourced/re-used writing a transformer is fairly easy: just a few lines of Python code using trestle as a foundation In the case of Tanium, the OSCAL compliance data document is a System Assessment Results fragment with Findings and Observations , while in the case of OpenShift Compliance Operator there are Observations only. Tutorials are available to show you: how to run a transformer , how to write a transformer . Step 2 \u2013 Reporting \u00a4 Coming soon is a trestle tool to assemble the OSCAL fragments documents together using OSCAL compliance configuration data ( System Assessment Plan and System Security Plan ) into a complete System Assessment Results .","title":"Compliance posture"},{"location":"tutorials/continuous-compliance/continuous-compliance/#tutorial-whats-your-compliance-posture","text":"","title":"Tutorial: What\u2019s your compliance posture?"},{"location":"tutorials/continuous-compliance/continuous-compliance/#introduction","text":"The cloud with its continuous integration and continuous deployment is the modern computing paradigm. There is a plethora of cloud environments: public, private, on-premise, hybrid-cloud, multi-cloud, etc. along with a corresponding contingent of vendors. The cloud offers great flexibility where you can choose just one or some combination optimal for each application. But, as demonstrated from time to time, the cloud can be a dangerous place. Hackers, bots, malware, and more are constant threats seeking to find and exploit weakness in your computing solution. To combat them there are strategies to avoid embarrassment and financial ruin from security breeches. Educating your workforce is of paramount importance. Moreover, employing a trust-but-verify strategy will go a long way toward deflecting trouble. The time has come for continuous auditing, and giving stakeholders (such as account owners, application owners, system owners and compliance officers) a current picture of their compliance posture: Are password rules being followed? Are deployed applications using compromised encryption algorithms? Has a user gotten elevated privileges? Are unauthorized open source projects wrongfully part of your application stack? Getting answers to these questions only quarterly or annually is leaving you exposed. Moreover, assuring continuous compliance across multiple cloud vendors can complicate matters. If each has its own compliance regime, then one must become expert in each domain\u2019s compliance solution space, or else be wedded to a single or few providers. That is not an ideal prospect. Common sense dictates that standardization would simplify matters. The National Institute of Standards and Technologies (NIST) is developing the Open Security Controls Assessment Language ( OSCAL ). The compliance- trestle open source github project is an effort to employ OSCAL for compliance standardization and automation. Of great utility is the trestle oscal module that facilitates transformation of data to/from Python object representations in accordance with the OSCAL schemas.","title":"Introduction"},{"location":"tutorials/continuous-compliance/continuous-compliance/#simple-continuous-compliance-architecture","text":"Cloud Services can often be configured to monitor (and sometimes enforce) policies. Examples include OpenShift Compliance Operator and Tanium. However, the compliance reporting \u201craw\u201d data produced is unique to each. Two steps are needed to ascertain your compliance posture. Step 1 is to transform available compliance \u201craw\u201d data into standardized form ( OSCAL ). Step 2 is to examine the OSCAL data and assemble a compliance posture for the controls and components of interest. And trestle is the go-to solution.","title":"Simple Continuous Compliance Architecture"},{"location":"tutorials/continuous-compliance/continuous-compliance/#step-1-transformation","text":"The bad news is that a transformer to OSCAL is needed for each Cloud Service type. However, there is plenty of good news: a transformer for your Cloud Service type may already exist, such as: Tanium to OSCAL , OpenShift Compliance Operator to OSCAL once a transformer for a Cloud Service type has been written, it can be open-sourced/re-used writing a transformer is fairly easy: just a few lines of Python code using trestle as a foundation In the case of Tanium, the OSCAL compliance data document is a System Assessment Results fragment with Findings and Observations , while in the case of OpenShift Compliance Operator there are Observations only. Tutorials are available to show you: how to run a transformer , how to write a transformer .","title":"Step 1 \u2013 Transformation"},{"location":"tutorials/continuous-compliance/continuous-compliance/#step-2-reporting","text":"Coming soon is a trestle tool to assemble the OSCAL fragments documents together using OSCAL compliance configuration data ( System Assessment Plan and System Security Plan ) into a complete System Assessment Results .","title":"Step 2 \u2013 Reporting"},{"location":"tutorials/ssp_profile_catalog_authoring/ssp_profile_catalog_authoring/","text":"Tutorial: SSP, Profile and Catalog Authoring \u00a4 Introduction \u00a4 Trestle has authoring tools that allow conversion of OSCAL documents to markdown for easy editing - and conversion back to OSCAL for validation and automation. The author commands are: catalog-generate converts a control Catalog to individual controls in markdown format for addition or editing of guidance prose and parameters, with parameters stored in a yaml header at the top of the markdown file. catalog-assemble then gathers the prose and parameters and updates the controls in the Catalog to make a new OSCAL Catalog. profile-generate takes a given Profile and converts the controls represented by its resolved profile catalog to individual controls in markdown format, with sections corresponding to the content that the Profile adds to the Catalog, along with both the current values of parameters in the resolved profile catalog - and the values that are being modified by the given profile's SetParameters. The user may edit the content or add more, and profile-assemble then gathers the updated content and creates a new OSCAL Profile that includes those changes. ssp-generate takes a given Profile and its resolved profile catalog, and represents the individual controls as markdown files with sections that prompt for prose regarding the implementation response for items in the statement of the control. ssp-assemble then gathers the response sections and creates an OSCAL System Security Plan comprising the resolved profile catalog and the implementation responses. ssp-filter takes a given ssp and filters its contents based on the controls included in a provided profile. In summary, the catalog tools allow conversion of a Catalog to markdown for editing - and back again to a Catalog. The profile tools similarly convert a Profile's resolved profile catalog to markdown and allow conversion to a new Profile with modified additions that get applied in resolving the profile catalog. Finally, the ssp tools allow the addition of implementation prose to a resolved profile catalog, then combine that prose with the Catalog into an OSCAL System Security Plan. If a yaml header has been added to any of the controls, it will be retained if catalog-generate is run with currently existing markdown for controls. The yaml header can add parameters to the control's implemented requirements when an SSP is assembled from the markdown. The authoring tools are designed to work well in a CI/CD environment where changes are made in a pipeline by people with different responsibilities and authority. In this setting, changes to documents can trigger changes downstream, e.g. the editing of a control would cause an update in the catalog, which could then flow down to an updated SSP. These changes can occur automatically via actions that restrict the potential changes to the generated documents. Examples are the --set-parameters option on the -assemble tools, and both --required-sections and allowed-sections for profile-assemble . If a document change triggers an assemble action, changes to parameters can only occur if the action has --set-parameters in the command. Similarly, profile-assemble will fail if the sections do not meet the requirements specified in the command options. Another feature of the -assemble tools is that they won't create a new OSCAL file if the output already exists and its content would not be changed. This prevents undesired triggering of downstream actions when there is no actual change in content. For a complete standalone demonstration of the SSP generation process with trestle, please see the Trestle SSP Demo . It shows the complete flow from OSCAL json files to a finished Word .docx file. Background on underlying concepts \u00a4 In order to understand the specific operations handled by these commands, it is helpful to clarify some of the underlying OSCAL structures and how they can be edited in markdown form. This tutorial should be viewed in the context of the extensive documentation provided by OSCAL . First, a Catalog is a collection of Controls , and a Profile imports controls and allows modification and additions to the controls, but it does not create new controls. A Profile has one or more Imports that refer either to an actual Catalog, or another Profile that itself is importing from a Catalog or Profile. The profiles can import controls selectively from each source and make additions or modifications to properties of the controls. The final collection of selected and modified controls represents the profile's resolved profile catalog . For clarity, here is a simple depicton of a catalog as a collection of controls: Here is a profile pulling controls from a catalog to make a resolved profile catalog: And here is a more complex situation where a single profile pulls controls from catalogs and profiles: From the diagram it's clear that the profile is performing many tasks under the covers. This is shown in an expanded view of a profile: It's important to note that each profile is importing a selection of controls from each source, then making its own suggested modifications to parameters and other content in those controls. They are suggested in the sense that downstream profiles may override those settings - with priority given to the later profiles in the pipeline. The changes made by upstream profiles may be accepted, or overridden by better choices for a given need. This way the catalogs themselves can remain relatively static, and individual use cases can effectively create a custom catalog based on the original controls plus modifications by other static profiles, and/or the user's custom profile. The authoring tools here provide ways to make those modifications, both to the catalog controls and to the profiles, and to enter the implementation responses that are needed in a System Security Plan. The tools are designed to be used in a continuous generate-edit-assemble cycle, with previous edits retained in each cycle. Each new edit phase can add or modify the current content, allowing a new generate of an OSCAL json document capturing those edits. NOTE: We use json format for specifying OSCAL files in this tutorial, but it is equally applicable to yaml format also. trestle author catalog-generate and trestle author catalog-assemble \u00a4 catalog-generate will take an existing json catalog and write it out as markdown files for each control in a user-specified directory. That directory will contain subdirectories for each group in the catalog, and those directories may contain subdirectories for groups within groups. But controls containing controls are always split out into a series of controls in the same directory - and each control markdown file corresponds to a single control. We now look at the contents of a typical control markdown file. A Control may contain many parts, but only one of them is a Statement, which describes the function of the control. The statement itself is broken down into separate items, each of which may contain parameter id's in \"moustache\" ( {{}} ) brackets. Below is an example of a control as generated in markdown form by the catalog-generate command. --- control-origination: - Service Provider Corporate - Service Provider System Specific responsible-roles: - Customer sort-id: ac-01 x-trestle-set-params: ac-1_prm_1: label: organization-defined personnel or roles values: new value new value ac-1_prm_2: select: choice: - Organization-level - Mission/business process-level - System-level how_many: one_or_more values: - Organization-level - System-level ac-1_prm_3: label: organization-defined official --- # ac-1 - \\[Access Control\\] Policy and Procedures ## Control Statement - \\[a.\\] Develop, document, and disseminate to {{ insert: param, ac-1_prm_1 }}: - \\[1.\\] {{ insert: param, ac-1_prm_2 }} access control policy that: - \\[(a)\\] Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and - \\[(b)\\] Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and - \\[2.\\] Procedures to facilitate the implementation of the access control policy and the associated access controls; - \\[b.\\] Designate an {{ insert: param, ac-1_prm_3 }} to manage the development, documentation, and dissemination of the access control policy and procedures; and - \\[c.\\] Review and update the current access control: - \\[1.\\] Policy {{ insert: param, ac-1_prm_4 }} and following {{ insert: param, ac-1_prm_5 }}; and - \\[2.\\] Procedures {{ insert: param, ac-1_prm_6 }} and following {{ insert: param, ac-1_prm_7 }}. - \\[d.\\] My added item ## Control guidance Access control policy and procedures address the controls in the AC family that are implemented within systems and organizations. The control markdown files rely on brackets around key items that are important in defining the control's properties and structure. \\[Access Control\\] at the top indicates the title of the group containing the control. The name of the control is already known from the name of the markdown file ( ac-1.md ) and the name of the group is already known from the name of the directory containing the group's controls ( ac ) - but the group title must be indicated in the control in a special manner, hence the brackets. The text following the group title is the title of the control itself. All controls in a group should have the same group title or a warning will be indicated in certain trestle operations. In addition, each part label corresponds to the label used in the OSCAL structure for the control statement, and so must be maintained in a special manner - hence the need for brackets on \\[(a)\\] . The items in moustaches ( {{}} ) correspond to the original prose from the control description. The moustaches represent places to substitue parameter values, but no substitutions are ever made until the final SSP generation. The authoring process provides multiple ways to set and change the final parameter values, as described below. catalog-generate is run with the command trestle author catalog-generate --name catalog_name --output markdown_dir , where catalog_name is the name of a catalog already loaded into the trestle workspace, and markdown_dir is the directory into which the markdown files for the controls will be written. A separate directory is created for each group in the catalog. A user then may edit the control statement for the control and add or change the contents. In this case an added item, My added item is shown as item d . You can then assemble the edited controls into a new catalog with the command trestle author catalog-assemble --markdown markdown_dir --output new_catalog . This will load the updated control statements for each control into a new json or yaml catalog named new_catalog . As with profile and ssp generation described below, a yaml header may be provided with the --yaml option that is inserted into the top of each control file. If a control file already exists, as is expected in a continuous cycle of generate-edit-assemble, then the provided header will be merged with the existing header in each control. If a given item in the header is already present in the control, by default the values in the markdown header will be given priority, though this can be overridden by the --overwrite-header-values option, which will give priority to any values coming from the provided yaml header. In all cases, values in the yaml header not already present in the markdown header will be inserted. In the control markdown example above, the header contains some arbitrary values along with a special x-trestle-set-params section containing parameters for some of the parameters in the control. Any parameters for the control in the catalog will appear in the markdown header automatically during catalog-generate . These values may be changed and values for other parameters may be inserted into the markdown header for later use during catalog-assemble . Parameters in the header are shown with a subset of their full OSCAL attributes in order to convey any values they may have along with descriptive text. This amounts to the parameter id, its label if present, any values if present, and any select if present. When a select is present the list of choices is provided along with the how-many option. Note that values is a list in OSCAL, but in many cases it is a list of only one item. As a result, for convenience the values: dictionary may either have one string value (on the same line with values: ) or as an indented - list of multiple values underneath values: . Multiple examples are evident in the sample above, including ac-1_prm_3, which only has a label and no values. Another important item in the header is the sort-id for the control. This specifies how the controls and their parameters are ordered in any aggregated list operation. If it is not specified for a control, the control's id is used for sorting. catalog-assemble is run with the command catalog-assemble --markdown my_md --output my_new_catalog . This will read the markdown for each control and create a new catalog based on any edits to the markdown. Note that you may optionally provide a --name option specifying an original json catalog into which the updated controls are inserted, and the resulting catalog can either replace the original one or output to a different json file. New controls may be added and existing controls may be removed. The main benefit is that the original metadata and other contents of the catalog json file will be retained. You have the option to specify a new --version for the catalog, and an option to regenerate the uuid's in the catalog. Finally, you have the option to use the parameters in the markdown header to update the values in the control. Any parameters and their values present will be added to the control, and any not present will be removed. The parameters themselves are still present but their values are removed. In a typical generate-edit-assemble cycle, the cycle would start with an original json file containing source content and metadata and use that to generate an initial markdown directory of controls. After editing the controls they would be assembled into into a new json file with a different name. But once that new file exists, it can be used as the source for the next generation and the original source document is no longer needed or referred to. For the catalog- editing cycle it would go as: trestle author catalog-generate --name orig_catalog --output md_catalog [user edits the markdown files] trestle author catalog-assemble --name orig_catalog --markdown md_catalog --output assembled_catalog [user makes additional markdown edits] trestle author catalog-assemble --markdown md_catalog --output assembled_catalog The key point here is that the first -assemble needs to use the original catalog for its metadata, backmatter and other items not captured in the markdown controls. But once the output catalog has been created, by default it will be used as the \"original\" or \"parent\" catalog into which changes will be incorporated, unless a different source catalog is specified via --name . Note that catalog-assemble can instantiate a catalog anew from a manually created directory of markdown controls in directories corresponding to groups, but the metadata in the assembled json catalog will contain many REPLACE_ME items that would need to be manually edited in the json file itself. The trestle split and merge tools may help in that case. Once the changes have been made they will be retained if a new catalog-assemble happens with that same output file as the target. Special Note about assemble : In order to avoid triggering actions when a new file is created that has no actual changes in it, catalog-assemble and the other -assemble tools below will check to see if the output file already exists, and if so it will be examined for changes relative to the newly assembled one. If there are no changes the file will not be written out. Note that the check happens before any possible --regeneration of uuid's, and after any possible --version change. This avoids the creation of a new file and new uuid's if there is no change to the version or other file contents relative to the existing output file, but if the specified --version is different from the one in the existing output file, or there is any other difference in the model, a new file will be written out. trestle author profile-generate and trestle author profile-assemble \u00a4 The background text above conveys how a profile pulls controls from catalogs and makes modifications to them, and the trestle profile tools let you change the way those modifications are made. In addition to selecting controls and setting parameters, a profile may add new parts to a control that provide additional guidance specific to a certain use case. profile-generate is run with the command, trestle author profile-generate --name profile_name --output markdown_dir . It will load the specified profile name from the trestle workspace (it must have been imported into the trestle workspace prior) and create its corresponding resolved profile catalog - but without applying any of its Adds of additonal guidance content or SetParameters . It will make all other modifications, but the Adds and SetParameters are kept separate, as shown below: --- control-origination: - Service Provider Corporate - Service Provider System Specific responsible-roles: - Customer x-trestle-set-params: ac-1_prm_1: values: all personnel profile-values: new value from profile ac-1_prm_2: values: new value ac-1_prm_3: values: all meetings profile-values: - some meetings - most meetings ac-1_prm_4: values: monthly x-trestle-sections: ImplGuidance: Implementation Guidance ExpectedEvidence: Expected Evidence my_guidance: My Guidance a_guidance: A Guidance b_guidance: B Guidance NeededExtra: Needed Extra --- # ac-1 - \\[Access Control\\] Policy and Procedures ## Control Statement - \\[a\\] Develop, document, and disseminate to {{ insert: param, ac-1_prm_1 }}: - \\[1\\] {{ insert: param, ac-1_prm_2 }} access control policy that: - \\[a\\] Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and - \\[b\\] Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and - \\[2\\] Procedures to facilitate the implementation of the access control policy and the associated access controls; - \\[b\\] Designate an {{ insert: param, ac-1_prm_3 }} to manage the development, documentation, and dissemination of the access control policy and procedures; and - \\[c\\] Review and update the current access control: - \\[1\\] Policy {{ insert: param, ac-1_prm_4 }} and following {{ insert: param, ac-1_prm_5 }}; and - \\[2\\] Procedures {{ insert: param, ac-1_prm_6 }} and following {{ insert: param, ac-1_prm_7 }}. ## Control guidance Access control policy and procedures address the controls in the AC family that are implemented within systems and organizations. # Editable Content <!-- Make additions and edits below --> <!-- The above represents the contents of the control as received by the profile, prior to additions. --> <!-- If the profile makes additions to the control, they will appear below. --> <!-- The above markdown may not be edited but you may edit the content below, and/or introduce new additions to be made by the profile. --> <!-- If there is a yaml header at the top, parameters and values may be edited. Use --set-parameters to incorporate the changes during assembly. --> <!-- The content here will then replace what is in the profile for this control, after running profile-assemble. --> <!-- The added parts in the profile for this control are below. You may edit them and/or add new ones. --> <!-- Each addition must have a heading of the form ## Control my_addition_name --> <!-- See https://ibm.github.io/compliance-trestle/tutorials/ssp_profile_catalog_authoring/ssp_profile_catalog_authoring for guidance. --> ## Control Implementation Guidance Do it carefully. ## Control Expected Evidence Detailed logs. ## Control Needed Extra Add prose here for required Section: Needed Extra ## Control A Guidance This is A Guidance. ## Control B Guidance This is B Guidance. In the above markdown example, the fixed, uneditable parts of the control are output first (after the header, which can be edited), followed by a separate section marked, Editable Content . And below the editable content are the individual Adds that the profile makes, with each one marked by a header of the form, ## Control guidance_name . You may edit the editable content and you may add new Control guidance headers with your own new content. Please refer to Markdown Specifications for Editable Content section below to learn more on which headers are valid in Trestle. Then the command, trestle author profile-assemble --name original_profile --markdown markdown_dir --output new_profile will create a new OSCAL profile based on the original profile (specified) and the editable content in each control. In a cyclic operation of profile generate-edit-assemble you would simply be re-writing from and to the same json profile, in which case the --name and --output are the same file. For this reason the default value for --name is the given output file name specified by --output and you can just use trestle author profile-assemble --markdown profile_md --output my_profile . This will assemble the markdown profile contents in directory profile_md into a json profile named my_profile but it will first use the existing my_profile json file as the parent profile and incorporate changes (due to user edits) in the markdown version of the profile. Unlike catalog-assemble there must always be a parent json profile to reference during assemble, but like catalog-assemble an explicit value for --name is only needed if the parent file is different from the assembled output file. It's important to note that these operations only apply to the Adds and SetParameters in the profile itself - and nothing upstream of the profile is affected. Nor is anything else in the original profile lost or altered. In the example above, the section, ## Control Implementation Guidance was added by editing the generated control - and after profile-assemble it ended up as new guidance in the assembled profile. As in the other commands, profile-generate allows specification of a yaml header with --yaml , and support of the --overwrite-header-values flag. Also, during assembly with profile-assemble the --set-parameters flag will set parameters in the profile for the control based on the header in the control markdown file. But unlike with catalog-assemble , only those parameter values marked profile-values will be part of the assembled profile's SetParams when you assemble with the --set-parameters flag. For each parameter, the \"incoming\" values for the parameters prior to any changes made by the profile are listed as values: and any pending changes made by the profile are listed as profile-values: . If you don't use the --set-parameters flag then all the original SetParameters in the profile will be retained in the new, assembled profile. But if you do set that flag, then only the header parameters with profile-values: will be added as SetParameters. This lets you see all the incoming values for parameters along with any changes made by the current profile, and you can modify, add, or remove parameter settings as desired in the new profile. Keep in mind that the header in the profile- tools corresponds to the SetParameters in the profile - and not simply the Parameters in the control. For convenience the current incoming values of the control parameters, as set by any upstream profiles, are shown as values - but anything else associated with a parameter, such as profile-values , label , choice will be added to the profile's SetParameters during profile-assemble (if you use the --set-parameters flag.) So entries should be set there only if you want the profile to enforce those entries as SetParameters . As with catalog-assemble described above, a new file is written out only if there are changes to the model relative to an existing output file. Use of Sections in profile-generate and profile-assemble \u00a4 The addition of guidance sections in the profile tools requires special handling because the corresponding parts have both a name and a title, where the name is a short form used as an id in the json schema, while the title is the readable form intended for final presentation. An example is ImplGuidance vs. Implementation Guidance . The trestle authoring tools strive to make the markdown as readable as possible, therefore the headings for sections use the title - which means somehow there is a need for a mapping from the short name to the long title for each section. This mapping is provided in several ways: During profile-generate you may provide a --sections \"ImplGuidance:Implementation Guidance,ExpEvidence:Expected Evidence\" option that would provide title values for ImplGuidance and ExpEvidence . This dictionary mapping is then inserted into the yaml header of each control's markdown. You may also add this mapping directly to a yaml file that is passed in during profile-generate , which is preferable if the list of sections is long. The sections should be entered in the yaml header in a section titled, x-trestle-sections . There is also a --required-sections option during both profile-generate and profile-assemble . This option expects a list of sections as comma-separated short names , e.g. --required-sections \"ImplGuidance,ExpEvidence\" . During profile-generate any required sections will have in the markdown a prompt created for guidance prose to be entered. And during profile-assemble if required sections are specified, those sections must have prose filled in or it will fail with error. Finally, profile-assemble also has an --allowed-sections option that restricts any added guidance to only those allowed sections - and if disallowed sections are present it will fail with error. If --allowed-sections is not specified then any sections found in the markdown will be added to the assembled profile. Note that these section options are all optional and there isn't a need to provide this form of restriction and enforcement. But in order to have such sections read properly and mapped to the intended part names, a mapping must be provided in one of the ways described above. And for certain workflows, if the allowed and required sections are specified by a command that is run as an action outside the user's control, it allows restriction of what changes can or must be made to a profile in terms of added guidance. (Note that the single quotes are required on Unix-like systems, but on Windows they are only needed if the contained string includes spaces, in which case double quotes should be used.) Markdown Specifications for Editable Content. \u00a4 For the ease of editing markdown in Github, Trestle's markdown parser follows Github Flavoured Markdown (GFM) specifications and therefore only certain Control headers will be parsed and added to the control. A valid control header in Trestle is the header that is correctly displayed as such when reading or previewing the edited markdown on Github website. In GFM, headers are considered to be any line of text that has any number of # symbols at the beginning. For example those are all valid headers and will be treated as such by Github: # Valid header ## Valid header ##### Valid header # Valid <ins> header </ins> # Valid header <!-- some comment here --> The headers above are valid Control headers and will be added to the control. However, there are multiple exceptions where the header will not be displayed. The header will not be displayed correctly if it is: Written in the HTML comments <!-- # not a header --> or tags <ins> # not a header </ins> as well as multi-line comments: <!-- # not a header --> or multi-line HTML blocks: <dl> # not a header # not a header <dt># not a header</dt> </dl> Written in the single-line # not a header and multi-line code blocks: # not a header Written in the links [# not a header](url) Trestle will also not support headers inside the blockquotes > # not a header In all cases above Trestle markdown parser will skip such headers and it will be not added to the control. trestle author ssp-generate and trestle author ssp-assemble \u00a4 The ssp-generate sub-command creates a partial SSP (System Security Plan) from a profile and optional yaml header file. ssp-assemble (described below) can later assemble the markdown files into a single json SSP file. The profile contains a list of imports that are either a direct reference to a catalog, or an indirect reference via a profile. There may be multiple imports of either type, and referenced profiles may themselves import either catalogs or profiles. Each profile involved may specify the controls that should be imported, along with any modifications to those controls. This command internally creates a resolved profile catalog and generates a directory containing a set of markdown files, one for each control in the resolved catalog. Each markdown file has the optional yaml header embedded at the start of the file. Example usage for creation of the markdown: trestle author ssp-generate --profile my_prof --yaml /my_yaml_dir/header.yaml --sections 'ImplGuidance:Implementation Guidance,ExpectedEvidence:Expected Evidence' --output my_ssp In this example the profile has previously been imported into the trestle directory. The profile itself must be in the trestle directory, but the imported catalogs and profiles may be URI's with href's as described below. The -s --sections argument specifies the name of Parts in the control for which the corresponding prose should be included in the control's markdown file. The concept is the same as above with profile tools in providing a mapping between all possible short names for guidance and their corresponding long versions that should appear in the markdown headings. In addition, ssp-generate has an --allowed-sections option that specifies a list of section short names that will be included in the markdown. This provides a means for filtering the guidance that appears in the markdown for the controls. Note that unlike in profile-assemble there is no error if sections are present in the control that are not among the \"allowed\" sections. For ssp-generate the allowed sections simply provide a means for filtering the guidance. If you do not specify --allowed-sections then all sections present in the control will appear in the markdown. The generated markdown output will be placed in the trestle subdirectory my_ssp with a subdirectory for each control group. If the imported catalogs or profiles are not at the URI pointed to by the Import href of the profile then the href should be changed using the trestle href command. Similar to catalog-generate , the --yaml and --overwrite-header-values flag may be specified to let the input yaml header overwrite values already specified in the header of the control markdown file. The resulting files look like this: --- control-origination: - Service Provider Corporate - Service Provider System Specific responsible-roles: - Customer x-trestle-sections: ImplGuidance: Implementation Guidance ExpectedEvidence: Expected Evidence guidance: Guidance statement: statement --- # ac-1 - \\[Access Control\\] Policy and Procedures ## Control Statement - \\[a\\] Develop, document, and disseminate to all personnel: - \\[1\\] A thorough access control policy that: - \\[a\\] Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and - \\[b\\] Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and - \\[2\\] Procedures to facilitate the implementation of the access control policy and the associated access controls; - \\[b\\] Designate an officer to manage the development, documentation, and dissemination of the access control policy and procedures; and - \\[c\\] Review and update the current access control: - \\[1\\] Policy weekly and following all meetings; and - \\[2\\] Procedures monthly and following organization-defined events. ## Control Implementation Guidance Do it carefully. ## Control Expected Evidence Detailed logs. ## Control Guidance Access control policy and procedures address the controls in the AC family that are implemented within systems and organizations. ______________________________________________________________________ ## What is the solution and how is it implemented? <!-- Please leave this section blank and enter implementation details in the parts below. --> ______________________________________________________________________ ## Implementation a. Add control implementation description here for item ac-1_smt.a ______________________________________________________________________ ## Implementation b. Add control implementation description here for item ac-1_smt.b ### ACME Component Do the ACME requirements ______________________________________________________________________ ## Implementation c. Add control implementation description here for item ac-1_smt.c ______________________________________________________________________ Each label in the ssp is wrapped in \\[ \\] to indicate it comes directly from the label in the control and is not generated by the markdown viewer. Keep in mind that the actual label is the same but with the \\[ \\] removed. Note that for each statement in the control description there is a corresponding response section in which to provide a detailed response for later inclusion in the final ssp as the control implementation. Also note that the optional final sections are provided, and labeled using the title for the corresponding section. In addition, this is the only control markdown where the moustache ( {{}} ) items have been replaced by the corresponding parameter values in the final resolved profile catalog, so that the prose corresponds to the final intended control and its implementation. The markdown can have guidance per-component in the control, as shown by the line, ### ACME Component . Any prose directly under a ## implementation section will apply to the overall system component, but sections in a sub-header of the form ### will only apply to that particular component. After generating the markdown for the resolved profile catalog you may then edit the files and provide text in the sections with Add control implementation... in them. But do not remove the horizontal rule lines or modify/remove the lines with ### in them, corresponding to system components. If you edit the control markdown files you may run ssp-generate again and your edits will not be overwritten. When writing out the markdown for a control, any existing markdown for that control will be read and the response text for each part will be re-inserted into the new markdown file. If the new markdown has added parts the original responses will be placed correctly in the new file, but if any part is removed from the source control json file then any corresponding prose will be lost after the next ssp-generate . trestle author ssp-assemble \u00a4 After manually edting the markdown and providing the responses for the control implementation requirements, the markdown can be assembled into a single json SSP file with: trestle author ssp-assemble --markdown my_ssp --output my_json_ssp This will assemble the markdown files in the my_ssp directory and create a json SSP with name my_json_ssp in the system-security-plans directory. As indicated for ssp-generate , please do not alter any of the horizontal rule lines or lines indicating the part or control id, e.g. ### ACME Component . You may run ssp-generate and ssp-assemble repeatedly for the same markdown directory, allowing a continuous editing and updating cycle. As with all the assemble tools, you may optionally specify a --name for a corresponding json file into which the updates will be inserted, thereby preserving metadata and other aspects of the model. The result can overwrite the provided model or get directed to a new model. And the version may be updated and the uuid's regenerated. As with the other -assemble tools, if an output file already exists, a new one will only be written if there are changes to the model relative to the existing file. See catalog-assemble for more details. trestle author ssp-filter \u00a4 Once you have an SSP in the trestle directory you can filter its contents with a profile by using the command trestle author ssp-filter . The SSP is assumed to contain a superset of the controls needed by the profile, and the filter operation will generate a new SSP with only those controls needed by the profile. The filter command is invoked as: trestle author ssp-filter --name my_ssp --profile my_profile --output my_culled_ssp Both the SSP and profile must be present in the trestle directory. This command will generate a new SSP in the directory. If the profile makes reference to a control not in the SSP then the routine will fail with an error message. Summary of options used by the catalog , profile and ssp authoring tools. \u00a4 The provided options for the generation and assembly of documents in the ssp workflow is rich and powerful, but can also be confusing. To help see how they all relate please consult the following diagram showing the required and optional command line arguments for each command. The checkboxes indicate required and the open circles represent optional. The options shown are fairly consistent across the -generate and -assemble functions, but some clarification may be needed. For catalog-assemble and profile-assemble you have the option to use an existing json file as a parent model into which new content is inserted - in memory - and the final model may either be written back into that same json file, or a different one - based on --output . If you just want to keep editing and modifying the same original json file you can specify --name and --output to be the same, original json file. But you could also direct it to a new json file while still using an original file as the \"parent.\" A key benefit of referencing an original json file is the resuse of metadata and backmatter - along with everything else separate from the controls. ssp-generate is special because it starts with a profile rather than an ssp, whereas catalog-generate and profile-generate both start with a parent model of the same type. Nonetheless, you still have an option during ssp-assemble to use a given json file as the template into which new content is inserted, and once again you may overwrite that original json file or direct it to a new one using --output .","title":"SSP, Catalog, and Profile Authoring"},{"location":"tutorials/ssp_profile_catalog_authoring/ssp_profile_catalog_authoring/#tutorial-ssp-profile-and-catalog-authoring","text":"","title":"Tutorial: SSP, Profile and Catalog Authoring"},{"location":"tutorials/ssp_profile_catalog_authoring/ssp_profile_catalog_authoring/#introduction","text":"Trestle has authoring tools that allow conversion of OSCAL documents to markdown for easy editing - and conversion back to OSCAL for validation and automation. The author commands are: catalog-generate converts a control Catalog to individual controls in markdown format for addition or editing of guidance prose and parameters, with parameters stored in a yaml header at the top of the markdown file. catalog-assemble then gathers the prose and parameters and updates the controls in the Catalog to make a new OSCAL Catalog. profile-generate takes a given Profile and converts the controls represented by its resolved profile catalog to individual controls in markdown format, with sections corresponding to the content that the Profile adds to the Catalog, along with both the current values of parameters in the resolved profile catalog - and the values that are being modified by the given profile's SetParameters. The user may edit the content or add more, and profile-assemble then gathers the updated content and creates a new OSCAL Profile that includes those changes. ssp-generate takes a given Profile and its resolved profile catalog, and represents the individual controls as markdown files with sections that prompt for prose regarding the implementation response for items in the statement of the control. ssp-assemble then gathers the response sections and creates an OSCAL System Security Plan comprising the resolved profile catalog and the implementation responses. ssp-filter takes a given ssp and filters its contents based on the controls included in a provided profile. In summary, the catalog tools allow conversion of a Catalog to markdown for editing - and back again to a Catalog. The profile tools similarly convert a Profile's resolved profile catalog to markdown and allow conversion to a new Profile with modified additions that get applied in resolving the profile catalog. Finally, the ssp tools allow the addition of implementation prose to a resolved profile catalog, then combine that prose with the Catalog into an OSCAL System Security Plan. If a yaml header has been added to any of the controls, it will be retained if catalog-generate is run with currently existing markdown for controls. The yaml header can add parameters to the control's implemented requirements when an SSP is assembled from the markdown. The authoring tools are designed to work well in a CI/CD environment where changes are made in a pipeline by people with different responsibilities and authority. In this setting, changes to documents can trigger changes downstream, e.g. the editing of a control would cause an update in the catalog, which could then flow down to an updated SSP. These changes can occur automatically via actions that restrict the potential changes to the generated documents. Examples are the --set-parameters option on the -assemble tools, and both --required-sections and allowed-sections for profile-assemble . If a document change triggers an assemble action, changes to parameters can only occur if the action has --set-parameters in the command. Similarly, profile-assemble will fail if the sections do not meet the requirements specified in the command options. Another feature of the -assemble tools is that they won't create a new OSCAL file if the output already exists and its content would not be changed. This prevents undesired triggering of downstream actions when there is no actual change in content. For a complete standalone demonstration of the SSP generation process with trestle, please see the Trestle SSP Demo . It shows the complete flow from OSCAL json files to a finished Word .docx file.","title":"Introduction"},{"location":"tutorials/ssp_profile_catalog_authoring/ssp_profile_catalog_authoring/#background-on-underlying-concepts","text":"In order to understand the specific operations handled by these commands, it is helpful to clarify some of the underlying OSCAL structures and how they can be edited in markdown form. This tutorial should be viewed in the context of the extensive documentation provided by OSCAL . First, a Catalog is a collection of Controls , and a Profile imports controls and allows modification and additions to the controls, but it does not create new controls. A Profile has one or more Imports that refer either to an actual Catalog, or another Profile that itself is importing from a Catalog or Profile. The profiles can import controls selectively from each source and make additions or modifications to properties of the controls. The final collection of selected and modified controls represents the profile's resolved profile catalog . For clarity, here is a simple depicton of a catalog as a collection of controls: Here is a profile pulling controls from a catalog to make a resolved profile catalog: And here is a more complex situation where a single profile pulls controls from catalogs and profiles: From the diagram it's clear that the profile is performing many tasks under the covers. This is shown in an expanded view of a profile: It's important to note that each profile is importing a selection of controls from each source, then making its own suggested modifications to parameters and other content in those controls. They are suggested in the sense that downstream profiles may override those settings - with priority given to the later profiles in the pipeline. The changes made by upstream profiles may be accepted, or overridden by better choices for a given need. This way the catalogs themselves can remain relatively static, and individual use cases can effectively create a custom catalog based on the original controls plus modifications by other static profiles, and/or the user's custom profile. The authoring tools here provide ways to make those modifications, both to the catalog controls and to the profiles, and to enter the implementation responses that are needed in a System Security Plan. The tools are designed to be used in a continuous generate-edit-assemble cycle, with previous edits retained in each cycle. Each new edit phase can add or modify the current content, allowing a new generate of an OSCAL json document capturing those edits. NOTE: We use json format for specifying OSCAL files in this tutorial, but it is equally applicable to yaml format also.","title":"Background on underlying concepts"},{"location":"tutorials/ssp_profile_catalog_authoring/ssp_profile_catalog_authoring/#trestle-author-catalog-generate-and-trestle-author-catalog-assemble","text":"catalog-generate will take an existing json catalog and write it out as markdown files for each control in a user-specified directory. That directory will contain subdirectories for each group in the catalog, and those directories may contain subdirectories for groups within groups. But controls containing controls are always split out into a series of controls in the same directory - and each control markdown file corresponds to a single control. We now look at the contents of a typical control markdown file. A Control may contain many parts, but only one of them is a Statement, which describes the function of the control. The statement itself is broken down into separate items, each of which may contain parameter id's in \"moustache\" ( {{}} ) brackets. Below is an example of a control as generated in markdown form by the catalog-generate command. --- control-origination: - Service Provider Corporate - Service Provider System Specific responsible-roles: - Customer sort-id: ac-01 x-trestle-set-params: ac-1_prm_1: label: organization-defined personnel or roles values: new value new value ac-1_prm_2: select: choice: - Organization-level - Mission/business process-level - System-level how_many: one_or_more values: - Organization-level - System-level ac-1_prm_3: label: organization-defined official --- # ac-1 - \\[Access Control\\] Policy and Procedures ## Control Statement - \\[a.\\] Develop, document, and disseminate to {{ insert: param, ac-1_prm_1 }}: - \\[1.\\] {{ insert: param, ac-1_prm_2 }} access control policy that: - \\[(a)\\] Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and - \\[(b)\\] Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and - \\[2.\\] Procedures to facilitate the implementation of the access control policy and the associated access controls; - \\[b.\\] Designate an {{ insert: param, ac-1_prm_3 }} to manage the development, documentation, and dissemination of the access control policy and procedures; and - \\[c.\\] Review and update the current access control: - \\[1.\\] Policy {{ insert: param, ac-1_prm_4 }} and following {{ insert: param, ac-1_prm_5 }}; and - \\[2.\\] Procedures {{ insert: param, ac-1_prm_6 }} and following {{ insert: param, ac-1_prm_7 }}. - \\[d.\\] My added item ## Control guidance Access control policy and procedures address the controls in the AC family that are implemented within systems and organizations. The control markdown files rely on brackets around key items that are important in defining the control's properties and structure. \\[Access Control\\] at the top indicates the title of the group containing the control. The name of the control is already known from the name of the markdown file ( ac-1.md ) and the name of the group is already known from the name of the directory containing the group's controls ( ac ) - but the group title must be indicated in the control in a special manner, hence the brackets. The text following the group title is the title of the control itself. All controls in a group should have the same group title or a warning will be indicated in certain trestle operations. In addition, each part label corresponds to the label used in the OSCAL structure for the control statement, and so must be maintained in a special manner - hence the need for brackets on \\[(a)\\] . The items in moustaches ( {{}} ) correspond to the original prose from the control description. The moustaches represent places to substitue parameter values, but no substitutions are ever made until the final SSP generation. The authoring process provides multiple ways to set and change the final parameter values, as described below. catalog-generate is run with the command trestle author catalog-generate --name catalog_name --output markdown_dir , where catalog_name is the name of a catalog already loaded into the trestle workspace, and markdown_dir is the directory into which the markdown files for the controls will be written. A separate directory is created for each group in the catalog. A user then may edit the control statement for the control and add or change the contents. In this case an added item, My added item is shown as item d . You can then assemble the edited controls into a new catalog with the command trestle author catalog-assemble --markdown markdown_dir --output new_catalog . This will load the updated control statements for each control into a new json or yaml catalog named new_catalog . As with profile and ssp generation described below, a yaml header may be provided with the --yaml option that is inserted into the top of each control file. If a control file already exists, as is expected in a continuous cycle of generate-edit-assemble, then the provided header will be merged with the existing header in each control. If a given item in the header is already present in the control, by default the values in the markdown header will be given priority, though this can be overridden by the --overwrite-header-values option, which will give priority to any values coming from the provided yaml header. In all cases, values in the yaml header not already present in the markdown header will be inserted. In the control markdown example above, the header contains some arbitrary values along with a special x-trestle-set-params section containing parameters for some of the parameters in the control. Any parameters for the control in the catalog will appear in the markdown header automatically during catalog-generate . These values may be changed and values for other parameters may be inserted into the markdown header for later use during catalog-assemble . Parameters in the header are shown with a subset of their full OSCAL attributes in order to convey any values they may have along with descriptive text. This amounts to the parameter id, its label if present, any values if present, and any select if present. When a select is present the list of choices is provided along with the how-many option. Note that values is a list in OSCAL, but in many cases it is a list of only one item. As a result, for convenience the values: dictionary may either have one string value (on the same line with values: ) or as an indented - list of multiple values underneath values: . Multiple examples are evident in the sample above, including ac-1_prm_3, which only has a label and no values. Another important item in the header is the sort-id for the control. This specifies how the controls and their parameters are ordered in any aggregated list operation. If it is not specified for a control, the control's id is used for sorting. catalog-assemble is run with the command catalog-assemble --markdown my_md --output my_new_catalog . This will read the markdown for each control and create a new catalog based on any edits to the markdown. Note that you may optionally provide a --name option specifying an original json catalog into which the updated controls are inserted, and the resulting catalog can either replace the original one or output to a different json file. New controls may be added and existing controls may be removed. The main benefit is that the original metadata and other contents of the catalog json file will be retained. You have the option to specify a new --version for the catalog, and an option to regenerate the uuid's in the catalog. Finally, you have the option to use the parameters in the markdown header to update the values in the control. Any parameters and their values present will be added to the control, and any not present will be removed. The parameters themselves are still present but their values are removed. In a typical generate-edit-assemble cycle, the cycle would start with an original json file containing source content and metadata and use that to generate an initial markdown directory of controls. After editing the controls they would be assembled into into a new json file with a different name. But once that new file exists, it can be used as the source for the next generation and the original source document is no longer needed or referred to. For the catalog- editing cycle it would go as: trestle author catalog-generate --name orig_catalog --output md_catalog [user edits the markdown files] trestle author catalog-assemble --name orig_catalog --markdown md_catalog --output assembled_catalog [user makes additional markdown edits] trestle author catalog-assemble --markdown md_catalog --output assembled_catalog The key point here is that the first -assemble needs to use the original catalog for its metadata, backmatter and other items not captured in the markdown controls. But once the output catalog has been created, by default it will be used as the \"original\" or \"parent\" catalog into which changes will be incorporated, unless a different source catalog is specified via --name . Note that catalog-assemble can instantiate a catalog anew from a manually created directory of markdown controls in directories corresponding to groups, but the metadata in the assembled json catalog will contain many REPLACE_ME items that would need to be manually edited in the json file itself. The trestle split and merge tools may help in that case. Once the changes have been made they will be retained if a new catalog-assemble happens with that same output file as the target. Special Note about assemble : In order to avoid triggering actions when a new file is created that has no actual changes in it, catalog-assemble and the other -assemble tools below will check to see if the output file already exists, and if so it will be examined for changes relative to the newly assembled one. If there are no changes the file will not be written out. Note that the check happens before any possible --regeneration of uuid's, and after any possible --version change. This avoids the creation of a new file and new uuid's if there is no change to the version or other file contents relative to the existing output file, but if the specified --version is different from the one in the existing output file, or there is any other difference in the model, a new file will be written out.","title":"trestle author catalog-generate and trestle author catalog-assemble"},{"location":"tutorials/ssp_profile_catalog_authoring/ssp_profile_catalog_authoring/#trestle-author-profile-generate-and-trestle-author-profile-assemble","text":"The background text above conveys how a profile pulls controls from catalogs and makes modifications to them, and the trestle profile tools let you change the way those modifications are made. In addition to selecting controls and setting parameters, a profile may add new parts to a control that provide additional guidance specific to a certain use case. profile-generate is run with the command, trestle author profile-generate --name profile_name --output markdown_dir . It will load the specified profile name from the trestle workspace (it must have been imported into the trestle workspace prior) and create its corresponding resolved profile catalog - but without applying any of its Adds of additonal guidance content or SetParameters . It will make all other modifications, but the Adds and SetParameters are kept separate, as shown below: --- control-origination: - Service Provider Corporate - Service Provider System Specific responsible-roles: - Customer x-trestle-set-params: ac-1_prm_1: values: all personnel profile-values: new value from profile ac-1_prm_2: values: new value ac-1_prm_3: values: all meetings profile-values: - some meetings - most meetings ac-1_prm_4: values: monthly x-trestle-sections: ImplGuidance: Implementation Guidance ExpectedEvidence: Expected Evidence my_guidance: My Guidance a_guidance: A Guidance b_guidance: B Guidance NeededExtra: Needed Extra --- # ac-1 - \\[Access Control\\] Policy and Procedures ## Control Statement - \\[a\\] Develop, document, and disseminate to {{ insert: param, ac-1_prm_1 }}: - \\[1\\] {{ insert: param, ac-1_prm_2 }} access control policy that: - \\[a\\] Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and - \\[b\\] Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and - \\[2\\] Procedures to facilitate the implementation of the access control policy and the associated access controls; - \\[b\\] Designate an {{ insert: param, ac-1_prm_3 }} to manage the development, documentation, and dissemination of the access control policy and procedures; and - \\[c\\] Review and update the current access control: - \\[1\\] Policy {{ insert: param, ac-1_prm_4 }} and following {{ insert: param, ac-1_prm_5 }}; and - \\[2\\] Procedures {{ insert: param, ac-1_prm_6 }} and following {{ insert: param, ac-1_prm_7 }}. ## Control guidance Access control policy and procedures address the controls in the AC family that are implemented within systems and organizations. # Editable Content <!-- Make additions and edits below --> <!-- The above represents the contents of the control as received by the profile, prior to additions. --> <!-- If the profile makes additions to the control, they will appear below. --> <!-- The above markdown may not be edited but you may edit the content below, and/or introduce new additions to be made by the profile. --> <!-- If there is a yaml header at the top, parameters and values may be edited. Use --set-parameters to incorporate the changes during assembly. --> <!-- The content here will then replace what is in the profile for this control, after running profile-assemble. --> <!-- The added parts in the profile for this control are below. You may edit them and/or add new ones. --> <!-- Each addition must have a heading of the form ## Control my_addition_name --> <!-- See https://ibm.github.io/compliance-trestle/tutorials/ssp_profile_catalog_authoring/ssp_profile_catalog_authoring for guidance. --> ## Control Implementation Guidance Do it carefully. ## Control Expected Evidence Detailed logs. ## Control Needed Extra Add prose here for required Section: Needed Extra ## Control A Guidance This is A Guidance. ## Control B Guidance This is B Guidance. In the above markdown example, the fixed, uneditable parts of the control are output first (after the header, which can be edited), followed by a separate section marked, Editable Content . And below the editable content are the individual Adds that the profile makes, with each one marked by a header of the form, ## Control guidance_name . You may edit the editable content and you may add new Control guidance headers with your own new content. Please refer to Markdown Specifications for Editable Content section below to learn more on which headers are valid in Trestle. Then the command, trestle author profile-assemble --name original_profile --markdown markdown_dir --output new_profile will create a new OSCAL profile based on the original profile (specified) and the editable content in each control. In a cyclic operation of profile generate-edit-assemble you would simply be re-writing from and to the same json profile, in which case the --name and --output are the same file. For this reason the default value for --name is the given output file name specified by --output and you can just use trestle author profile-assemble --markdown profile_md --output my_profile . This will assemble the markdown profile contents in directory profile_md into a json profile named my_profile but it will first use the existing my_profile json file as the parent profile and incorporate changes (due to user edits) in the markdown version of the profile. Unlike catalog-assemble there must always be a parent json profile to reference during assemble, but like catalog-assemble an explicit value for --name is only needed if the parent file is different from the assembled output file. It's important to note that these operations only apply to the Adds and SetParameters in the profile itself - and nothing upstream of the profile is affected. Nor is anything else in the original profile lost or altered. In the example above, the section, ## Control Implementation Guidance was added by editing the generated control - and after profile-assemble it ended up as new guidance in the assembled profile. As in the other commands, profile-generate allows specification of a yaml header with --yaml , and support of the --overwrite-header-values flag. Also, during assembly with profile-assemble the --set-parameters flag will set parameters in the profile for the control based on the header in the control markdown file. But unlike with catalog-assemble , only those parameter values marked profile-values will be part of the assembled profile's SetParams when you assemble with the --set-parameters flag. For each parameter, the \"incoming\" values for the parameters prior to any changes made by the profile are listed as values: and any pending changes made by the profile are listed as profile-values: . If you don't use the --set-parameters flag then all the original SetParameters in the profile will be retained in the new, assembled profile. But if you do set that flag, then only the header parameters with profile-values: will be added as SetParameters. This lets you see all the incoming values for parameters along with any changes made by the current profile, and you can modify, add, or remove parameter settings as desired in the new profile. Keep in mind that the header in the profile- tools corresponds to the SetParameters in the profile - and not simply the Parameters in the control. For convenience the current incoming values of the control parameters, as set by any upstream profiles, are shown as values - but anything else associated with a parameter, such as profile-values , label , choice will be added to the profile's SetParameters during profile-assemble (if you use the --set-parameters flag.) So entries should be set there only if you want the profile to enforce those entries as SetParameters . As with catalog-assemble described above, a new file is written out only if there are changes to the model relative to an existing output file.","title":"trestle author profile-generate and trestle author profile-assemble"},{"location":"tutorials/ssp_profile_catalog_authoring/ssp_profile_catalog_authoring/#use-of-sections-in-profile-generate-and-profile-assemble","text":"The addition of guidance sections in the profile tools requires special handling because the corresponding parts have both a name and a title, where the name is a short form used as an id in the json schema, while the title is the readable form intended for final presentation. An example is ImplGuidance vs. Implementation Guidance . The trestle authoring tools strive to make the markdown as readable as possible, therefore the headings for sections use the title - which means somehow there is a need for a mapping from the short name to the long title for each section. This mapping is provided in several ways: During profile-generate you may provide a --sections \"ImplGuidance:Implementation Guidance,ExpEvidence:Expected Evidence\" option that would provide title values for ImplGuidance and ExpEvidence . This dictionary mapping is then inserted into the yaml header of each control's markdown. You may also add this mapping directly to a yaml file that is passed in during profile-generate , which is preferable if the list of sections is long. The sections should be entered in the yaml header in a section titled, x-trestle-sections . There is also a --required-sections option during both profile-generate and profile-assemble . This option expects a list of sections as comma-separated short names , e.g. --required-sections \"ImplGuidance,ExpEvidence\" . During profile-generate any required sections will have in the markdown a prompt created for guidance prose to be entered. And during profile-assemble if required sections are specified, those sections must have prose filled in or it will fail with error. Finally, profile-assemble also has an --allowed-sections option that restricts any added guidance to only those allowed sections - and if disallowed sections are present it will fail with error. If --allowed-sections is not specified then any sections found in the markdown will be added to the assembled profile. Note that these section options are all optional and there isn't a need to provide this form of restriction and enforcement. But in order to have such sections read properly and mapped to the intended part names, a mapping must be provided in one of the ways described above. And for certain workflows, if the allowed and required sections are specified by a command that is run as an action outside the user's control, it allows restriction of what changes can or must be made to a profile in terms of added guidance. (Note that the single quotes are required on Unix-like systems, but on Windows they are only needed if the contained string includes spaces, in which case double quotes should be used.)","title":"Use of Sections in profile-generate and profile-assemble"},{"location":"tutorials/ssp_profile_catalog_authoring/ssp_profile_catalog_authoring/#markdown-specifications-for-editable-content","text":"For the ease of editing markdown in Github, Trestle's markdown parser follows Github Flavoured Markdown (GFM) specifications and therefore only certain Control headers will be parsed and added to the control. A valid control header in Trestle is the header that is correctly displayed as such when reading or previewing the edited markdown on Github website. In GFM, headers are considered to be any line of text that has any number of # symbols at the beginning. For example those are all valid headers and will be treated as such by Github: # Valid header ## Valid header ##### Valid header # Valid <ins> header </ins> # Valid header <!-- some comment here --> The headers above are valid Control headers and will be added to the control. However, there are multiple exceptions where the header will not be displayed. The header will not be displayed correctly if it is: Written in the HTML comments <!-- # not a header --> or tags <ins> # not a header </ins> as well as multi-line comments: <!-- # not a header --> or multi-line HTML blocks: <dl> # not a header # not a header <dt># not a header</dt> </dl> Written in the single-line # not a header and multi-line code blocks: # not a header Written in the links [# not a header](url) Trestle will also not support headers inside the blockquotes > # not a header In all cases above Trestle markdown parser will skip such headers and it will be not added to the control.","title":"Markdown Specifications for Editable Content."},{"location":"tutorials/ssp_profile_catalog_authoring/ssp_profile_catalog_authoring/#trestle-author-ssp-generate-and-trestle-author-ssp-assemble","text":"The ssp-generate sub-command creates a partial SSP (System Security Plan) from a profile and optional yaml header file. ssp-assemble (described below) can later assemble the markdown files into a single json SSP file. The profile contains a list of imports that are either a direct reference to a catalog, or an indirect reference via a profile. There may be multiple imports of either type, and referenced profiles may themselves import either catalogs or profiles. Each profile involved may specify the controls that should be imported, along with any modifications to those controls. This command internally creates a resolved profile catalog and generates a directory containing a set of markdown files, one for each control in the resolved catalog. Each markdown file has the optional yaml header embedded at the start of the file. Example usage for creation of the markdown: trestle author ssp-generate --profile my_prof --yaml /my_yaml_dir/header.yaml --sections 'ImplGuidance:Implementation Guidance,ExpectedEvidence:Expected Evidence' --output my_ssp In this example the profile has previously been imported into the trestle directory. The profile itself must be in the trestle directory, but the imported catalogs and profiles may be URI's with href's as described below. The -s --sections argument specifies the name of Parts in the control for which the corresponding prose should be included in the control's markdown file. The concept is the same as above with profile tools in providing a mapping between all possible short names for guidance and their corresponding long versions that should appear in the markdown headings. In addition, ssp-generate has an --allowed-sections option that specifies a list of section short names that will be included in the markdown. This provides a means for filtering the guidance that appears in the markdown for the controls. Note that unlike in profile-assemble there is no error if sections are present in the control that are not among the \"allowed\" sections. For ssp-generate the allowed sections simply provide a means for filtering the guidance. If you do not specify --allowed-sections then all sections present in the control will appear in the markdown. The generated markdown output will be placed in the trestle subdirectory my_ssp with a subdirectory for each control group. If the imported catalogs or profiles are not at the URI pointed to by the Import href of the profile then the href should be changed using the trestle href command. Similar to catalog-generate , the --yaml and --overwrite-header-values flag may be specified to let the input yaml header overwrite values already specified in the header of the control markdown file. The resulting files look like this: --- control-origination: - Service Provider Corporate - Service Provider System Specific responsible-roles: - Customer x-trestle-sections: ImplGuidance: Implementation Guidance ExpectedEvidence: Expected Evidence guidance: Guidance statement: statement --- # ac-1 - \\[Access Control\\] Policy and Procedures ## Control Statement - \\[a\\] Develop, document, and disseminate to all personnel: - \\[1\\] A thorough access control policy that: - \\[a\\] Addresses purpose, scope, roles, responsibilities, management commitment, coordination among organizational entities, and compliance; and - \\[b\\] Is consistent with applicable laws, executive orders, directives, regulations, policies, standards, and guidelines; and - \\[2\\] Procedures to facilitate the implementation of the access control policy and the associated access controls; - \\[b\\] Designate an officer to manage the development, documentation, and dissemination of the access control policy and procedures; and - \\[c\\] Review and update the current access control: - \\[1\\] Policy weekly and following all meetings; and - \\[2\\] Procedures monthly and following organization-defined events. ## Control Implementation Guidance Do it carefully. ## Control Expected Evidence Detailed logs. ## Control Guidance Access control policy and procedures address the controls in the AC family that are implemented within systems and organizations. ______________________________________________________________________ ## What is the solution and how is it implemented? <!-- Please leave this section blank and enter implementation details in the parts below. --> ______________________________________________________________________ ## Implementation a. Add control implementation description here for item ac-1_smt.a ______________________________________________________________________ ## Implementation b. Add control implementation description here for item ac-1_smt.b ### ACME Component Do the ACME requirements ______________________________________________________________________ ## Implementation c. Add control implementation description here for item ac-1_smt.c ______________________________________________________________________ Each label in the ssp is wrapped in \\[ \\] to indicate it comes directly from the label in the control and is not generated by the markdown viewer. Keep in mind that the actual label is the same but with the \\[ \\] removed. Note that for each statement in the control description there is a corresponding response section in which to provide a detailed response for later inclusion in the final ssp as the control implementation. Also note that the optional final sections are provided, and labeled using the title for the corresponding section. In addition, this is the only control markdown where the moustache ( {{}} ) items have been replaced by the corresponding parameter values in the final resolved profile catalog, so that the prose corresponds to the final intended control and its implementation. The markdown can have guidance per-component in the control, as shown by the line, ### ACME Component . Any prose directly under a ## implementation section will apply to the overall system component, but sections in a sub-header of the form ### will only apply to that particular component. After generating the markdown for the resolved profile catalog you may then edit the files and provide text in the sections with Add control implementation... in them. But do not remove the horizontal rule lines or modify/remove the lines with ### in them, corresponding to system components. If you edit the control markdown files you may run ssp-generate again and your edits will not be overwritten. When writing out the markdown for a control, any existing markdown for that control will be read and the response text for each part will be re-inserted into the new markdown file. If the new markdown has added parts the original responses will be placed correctly in the new file, but if any part is removed from the source control json file then any corresponding prose will be lost after the next ssp-generate .","title":"trestle author ssp-generate and trestle author ssp-assemble"},{"location":"tutorials/ssp_profile_catalog_authoring/ssp_profile_catalog_authoring/#trestle-author-ssp-assemble","text":"After manually edting the markdown and providing the responses for the control implementation requirements, the markdown can be assembled into a single json SSP file with: trestle author ssp-assemble --markdown my_ssp --output my_json_ssp This will assemble the markdown files in the my_ssp directory and create a json SSP with name my_json_ssp in the system-security-plans directory. As indicated for ssp-generate , please do not alter any of the horizontal rule lines or lines indicating the part or control id, e.g. ### ACME Component . You may run ssp-generate and ssp-assemble repeatedly for the same markdown directory, allowing a continuous editing and updating cycle. As with all the assemble tools, you may optionally specify a --name for a corresponding json file into which the updates will be inserted, thereby preserving metadata and other aspects of the model. The result can overwrite the provided model or get directed to a new model. And the version may be updated and the uuid's regenerated. As with the other -assemble tools, if an output file already exists, a new one will only be written if there are changes to the model relative to the existing file. See catalog-assemble for more details.","title":"trestle author ssp-assemble"},{"location":"tutorials/ssp_profile_catalog_authoring/ssp_profile_catalog_authoring/#trestle-author-ssp-filter","text":"Once you have an SSP in the trestle directory you can filter its contents with a profile by using the command trestle author ssp-filter . The SSP is assumed to contain a superset of the controls needed by the profile, and the filter operation will generate a new SSP with only those controls needed by the profile. The filter command is invoked as: trestle author ssp-filter --name my_ssp --profile my_profile --output my_culled_ssp Both the SSP and profile must be present in the trestle directory. This command will generate a new SSP in the directory. If the profile makes reference to a control not in the SSP then the routine will fail with an error message.","title":"trestle author ssp-filter"},{"location":"tutorials/ssp_profile_catalog_authoring/ssp_profile_catalog_authoring/#summary-of-options-used-by-the-catalog-profile-and-ssp-authoring-tools","text":"The provided options for the generation and assembly of documents in the ssp workflow is rich and powerful, but can also be confusing. To help see how they all relate please consult the following diagram showing the required and optional command line arguments for each command. The checkboxes indicate required and the open circles represent optional. The options shown are fairly consistent across the -generate and -assemble functions, but some clarification may be needed. For catalog-assemble and profile-assemble you have the option to use an existing json file as a parent model into which new content is inserted - in memory - and the final model may either be written back into that same json file, or a different one - based on --output . If you just want to keep editing and modifying the same original json file you can specify --name and --output to be the same, original json file. But you could also direct it to a new json file while still using an original file as the \"parent.\" A key benefit of referencing an original json file is the resuse of metadata and backmatter - along with everything else separate from the controls. ssp-generate is special because it starts with a profile rather than an ssp, whereas catalog-generate and profile-generate both start with a parent model of the same type. Nonetheless, you still have an option during ssp-assemble to use a given json file as the template into which new content is inserted, and once again you may overwrite that original json file or direct it to a new one using --output .","title":"Summary of options used by the catalog, profile and ssp authoring tools."},{"location":"tutorials/task.ocp4-cis-profile-to-oscal-catalog/transformation/","text":"Tutorial: Setup for and use of ComplianceAsCode profile to OSCAL Catalog transformer \u00a4 Here are step by step instructions for setup and transformation of ComplianceAsCode profile data files into NIST standard OSCAL Catalog using the compliance-trestle tool. Objective \u00a4 How to transform one or more .profile compliance files into a standardized OSCAL.json file. There are 2 short steps shown below. The first is a one-time check/set-up of your environment. The second is a one-command transformation from .profile to OSCAL.json . Step 1: Install trestle in a Python virtual environment \u00a4 Follow the instructions here to install trestle in a virtual environment. Step 2: Transform profile data (CIS benchmarks) \u00a4 Linux, Mac Windows Make these changes: use backslashes `\\` for file paths use `md` instead of mkdir -p put the url in double quotes for `curl` use `more` instead of cat Navigate to trestle workspace. (venv.trestle)$ cd trestle.workspace View configuration information. (venv.trestle)$ trestle task ocp4-cis-profile-to-oscal-catalog -i trestle.core.commands.task:102 WARNING: Config file was not configured with the appropriate section for the task: \"[task.ocp4-cis-profile-to-oscal-catalog]\" Help information for ocp4-cis-profile-to-oscal-catalog task. Purpose: Create catalog from from standard (e.g. CIS benchmark). Configuration flags sit under [task.ocp4-cis-profile-to-oscal-catalog]: input-dir = (required) location to read the compliance-as-code profile files. output-dir = (required) location to write the generated catalog.json file. output-overwrite = (optional) true [default] or false; replace existing output when true. Create data folders. (venv.trestle)$ mkdir -p adjunct-data/cis-benchmarks (venv.trestle)$ mkdir -p adjunct-data/task-files Fetch ComplianceAsCode profile data. (venv.trestle)$ curl 'https://raw.githubusercontent.com/ComplianceAsCode/content/master/products/ocp4/profiles/cis-node.profile' > adjunct-data/cis-benchmarks/cis-node.profile (venv.trestle)$ curl 'https://raw.githubusercontent.com/ComplianceAsCode/content/master/products/ocp4/profiles/cis-node.profile' > adjunct-data/cis-benchmarks/cis.profile Fetch trestle task file. (venv.trestle)$ curl 'https://raw.githubusercontent.com/IBM/compliance-trestle/main/docs/tutorials/task.ocp4-cis-profile-to-oscal-catalog/demo-ocp4-cis-profile-to-oscal-catalog.config' > adjunct-data/task-files/demo-ocp4-cis-profile-to-oscal-catalog.config demo-ocp4-cis-profile-to-oscal-catalog.config [task.ocp4-cis-profile-to-oscal-catalog] input-dir = adjunct-data/cis-benchmarks output-dir = catalogs/ocp4-cis Perform and validate the transform. (venv.trestle)$ trestle task ocp4-cis-profile-to-oscal-catalog -c adjunct-data/task-files/demo-ocp4-cis-profile-to-oscal-catalog.config output: catalogs/ocp4-cis/catalog.json Task: ocp4-cis-profile-to-oscal-catalog executed successfully. (venv.trestle)$ trestle validate --all VALID: Model /home/<user>/trestle.workspace/catalogs/ocp4-cis/catalog.json passed the Validator to confirm the model passes all registered validation tests. View the generated OSCAL. (venv.trestle)$ cat catlogs/ocp4-cis/catalog.json catalog.json { \"catalog\": { \"uuid\": \"19543ebf-4667-48b7-be47-d51154f16fda\", \"metadata\": { \"title\": \"CIS Red Hat OpenShift Container Platform 4 Benchmark\", \"last-modified\": \"2021-12-03T13:52:21+00:00\", \"version\": \"0.29.0\", \"oscal-version\": \"1.0.0\", \"links\": [ { \"href\": \"https://github.com/ComplianceAsCode/content/blob/master/products/ocp4/profiles/cis-node.profile\" }, { \"href\": \"https://github.com/ComplianceAsCode/content/blob/master/products/ocp4/profiles/cis.profile\" } ] }, \"groups\": [ { \"title\": \"1 Control Plane Components\", \"groups\": [ { \"title\": \"1.1 Master Node Configuration Files\", \"controls\": [ { \"id\": \"CIS-1.1.1\", \"title\": \"1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.2\", \"title\": \"1.1.2 Ensure that the API server pod specification file ownership is set to root:root\" }, { \"id\": \"CIS-1.1.3\", \"title\": \"1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.4\", \"title\": \"1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root\" }, { \"id\": \"CIS-1.1.5\", \"title\": \"1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.6\", \"title\": \"1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root\" }, { \"id\": \"CIS-1.1.7\", \"title\": \"1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.8\", \"title\": \"1.1.8 Ensure that the etcd pod specification file ownership is set to root:root (Automated)\" }, { \"id\": \"CIS-1.1.9\", \"title\": \"1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.10\", \"title\": \"1.1.10 Ensure that the Container Network Interface file ownership is set to root:root\" }, { \"id\": \"CIS-1.1.11\", \"title\": \"1.1.11 Ensure that the etcd data directory permissions are set to 700 or more restrictive\" }, { \"id\": \"CIS-1.1.12\", \"title\": \"1.1.12 Ensure that the etcd data directory ownership is set to root:root\" }, { \"id\": \"CIS-1.1.13\", \"title\": \"1.1.13 Ensure that the admin.conf file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.14\", \"title\": \"1.1.14 Ensure that the admin.conf file ownership is set to root:root\" }, { \"id\": \"CIS-1.1.15\", \"title\": \"1.1.15 Ensure that the scheduler.conf file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.16\", \"title\": \"1.1.16 Ensure that the scheduler.conf file ownership is set to root:root\" }, { \"id\": \"CIS-1.1.17\", \"title\": \"1.1.17 Ensure that the controller-manager.conf file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.18\", \"title\": \"1.1.18 Ensure that the controller-manager.conf file ownership is set to root:root\" }, { \"id\": \"CIS-1.1.19\", \"title\": \"1.1.19 Ensure that the OpenShift PKI directory and file ownership is set to root:root\" }, { \"id\": \"CIS-1.1.20\", \"title\": \"1.1.20 Ensure that the OpenShift PKI certificate file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.21\", \"title\": \"1.1.21 Ensure that the OpenShift PKI key file permissions are set to 600\" } ] }, { \"title\": \"1.2 API Server\", \"controls\": [ { \"id\": \"CIS-1.2.1\", \"title\": \"1.2.1 Ensure that the --anonymous-auth argument is set to false\" }, { \"id\": \"CIS-1.2.2\", \"title\": \"1.2.2 Ensure that the --basic-auth-file argument is not set\" }, { \"id\": \"CIS-1.2.3\", \"title\": \"1.2.3 Ensure that the --token-auth-file parameter is not set\" }, { \"id\": \"CIS-1.2.4\", \"title\": \"1.2.4 Ensure that the --kubelet-https argument is set to true\" }, { \"id\": \"CIS-1.2.5\", \"title\": \"1.2.5 Ensure that the --kubelet-client-certificate and --kubelet-client-key arguments are set as appropriate\" }, { \"id\": \"CIS-1.2.6\", \"title\": \"1.2.6 Ensure that the --kubelet-certificate-authority argument is set as appropriate\" }, { \"id\": \"CIS-1.2.7\", \"title\": \"1.2.7 Ensure that the --authorization-mode argument is not set to AlwaysAllow\" }, { \"id\": \"CIS-1.2.8\", \"title\": \"1.2.8 Ensure that the --authorization-mode argument includes Node\" }, { \"id\": \"CIS-1.2.9\", \"title\": \"1.2.9 Ensure that the --authorization-mode argument includes RBAC\" }, { \"id\": \"CIS-1.2.10\", \"title\": \"1.2.10 Ensure that the admission control plugin EventRateLimit is set\" }, { \"id\": \"CIS-1.2.11\", \"title\": \"1.2.11 Ensure that the admission control plugin AlwaysAdmit is not set\" }, { \"id\": \"CIS-1.2.12\", \"title\": \"1.2.12 Ensure that the admission control plugin AlwaysPullImages is set\" }, { \"id\": \"CIS-1.2.13\", \"title\": \"1.2.13 Ensure that the admission control plugin SecurityContextDeny is not set\" }, { \"id\": \"CIS-1.2.14\", \"title\": \"1.2.14 Ensure that the admission control plugin ServiceAccount is set\" }, { \"id\": \"CIS-1.2.15\", \"title\": \"1.2.15 Ensure that the admission control plugin NamespaceLifecycle is set\" }, { \"id\": \"CIS-1.2.16\", \"title\": \"1.2.16 Ensure that the admission control plugin PodSecurityPolicy is set (Automated)\" }, { \"id\": \"CIS-1.2.17\", \"title\": \"1.2.17 Ensure that the admission control plugin NodeRestriction is set (Automated)\" }, { \"id\": \"CIS-1.2.18\", \"title\": \"1.2.18 Ensure that the --insecure-bind-address argument is not set\" }, { \"id\": \"CIS-1.2.19\", \"title\": \"1.2.19 Ensure that the --insecure-port argument is set to 0\" }, { \"id\": \"CIS-1.2.20\", \"title\": \"1.2.20 Ensure that the --secure-port argument is not set to 0\" }, { \"id\": \"CIS-1.2.21\", \"title\": \"1.2.21 Ensure that the --profiling argument is set to false\" }, { \"id\": \"CIS-1.2.22\", \"title\": \"1.2.22 Ensure that the --audit-log-path argument is set\" }, { \"id\": \"CIS-1.2.23\", \"title\": \"1.2.23 Ensure that the audit logs are forwarded off the cluster for retention\" }, { \"id\": \"CIS-1.2.24\", \"title\": \"1.2.24 Ensure that the --audit-log-maxbackup argument is set to 10 or as appropriate\" }, { \"id\": \"CIS-1.2.25\", \"title\": \"1.2.25 Ensure that the --audit-log-maxsize argument is set to 100 or as appropriate\" }, { \"id\": \"CIS-1.2.26\", \"title\": \"1.2.26 Ensure that the --request-timeout argument is set as appropriate\" }, { \"id\": \"CIS-1.2.27\", \"title\": \"1.2.27 Ensure that the --service-account-lookup argument is set to true\" }, { \"id\": \"CIS-1.2.28\", \"title\": \"1.2.28 Ensure that the --service-account-key-file argument is set as appropriate\" }, { \"id\": \"CIS-1.2.29\", \"title\": \"1.2.29 Ensure that the --etcd-certfile and --etcd-keyfile arguments are set as appropriate\" }, { \"id\": \"CIS-1.2.30\", \"title\": \"1.2.30 Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate\" }, { \"id\": \"CIS-1.2.31\", \"title\": \"1.2.31 Ensure that the --client-ca-file argument is set as appropriate\" }, { \"id\": \"CIS-1.2.32\", \"title\": \"1.2.32 Ensure that the --etcd-cafile argument is set as appropriate\" }, { \"id\": \"CIS-1.2.33\", \"title\": \"1.2.33 Ensure that the --encryption-provider-config argument is set as appropriate\" }, { \"id\": \"CIS-1.2.34\", \"title\": \"1.2.34 Ensure that encryption providers are appropriately configured\" }, { \"id\": \"CIS-1.2.35\", \"title\": \"1.2.35 Ensure that the API Server only makes use of Strong Cryptographic Ciphers\" } ] }, { \"title\": \"1.3 Controller Manager\", \"controls\": [ { \"id\": \"CIS-1.3.1\", \"title\": \"1.3.1 Ensure that garbage collection is configured as appropriate\" }, { \"id\": \"CIS-1.3.2\", \"title\": \"1.3.2 Ensure that controller manager healthz endpoints are protected by RBAC. (Automated)\" }, { \"id\": \"CIS-1.3.3\", \"title\": \"1.3.3 Ensure that the --use-service-account-credentials argument is set to true\" }, { \"id\": \"CIS-1.3.4\", \"title\": \"1.3.4 Ensure that the --service-account-private-key-file argument is set as appropriate\" }, { \"id\": \"CIS-1.3.5\", \"title\": \"1.3.5 Ensure that the --root-ca-file argument is set as appropriate\" }, { \"id\": \"CIS-1.3.6\", \"title\": \"1.3.6 Ensure that the RotateKubeletServerCertificate argument is set to true\" }, { \"id\": \"CIS-1.3.7\", \"title\": \"1.3.7 Ensure that the --bind-address argument is set to 127.0.0.1\" } ] }, { \"title\": \"1.4 Scheduler\", \"controls\": [ { \"id\": \"CIS-1.4.1\", \"title\": \"1.4.1 Ensure that the --profiling argument is set to false (info only)\" }, { \"id\": \"CIS-1.4.2\", \"title\": \"1.4.2 Ensure that the --bind-address argument is set to 127.0.0.1\" } ] } ] }, { \"title\": \"2 etcd\", \"controls\": [ { \"id\": \"CIS-2.1\", \"title\": \"2.1 Ensure that the --cert-file and --key-file arguments are set as appropriate\" }, { \"id\": \"CIS-2.2\", \"title\": \"2.2 Ensure that the --client-cert-auth argument is set to true\" }, { \"id\": \"CIS-2.3\", \"title\": \"2.3 Ensure that the --auto-tls argument is not set to true\" }, { \"id\": \"CIS-2.4\", \"title\": \"2.4 Ensure that the --peer-cert-file and --peer-key-file arguments are set as appropriate\" }, { \"id\": \"CIS-2.5\", \"title\": \"2.5 Ensure that the --peer-client-cert-auth argument is set to true\" }, { \"id\": \"CIS-2.6\", \"title\": \"2.6 Ensure that the --peer-auto-tls argument is not set to true\" }, { \"id\": \"CIS-2.7\", \"title\": \"2.7 Ensure that a unique Certificate Authority is used for etcd\" } ] }, { \"title\": \"3 Control Plane Configuration\", \"groups\": [ { \"title\": \"3.1 Authentication and Authorization\", \"controls\": [ { \"id\": \"CIS-3.1.1\", \"title\": \"3.1.1 Client certificate authentication should not be used for users\" } ] }, { \"title\": \"3.2 Logging\", \"controls\": [ { \"id\": \"CIS-3.2.1\", \"title\": \"3.2.1 Ensure that a minimal audit policy is created\" }, { \"id\": \"CIS-3.2.2\", \"title\": \"3.2.2 Ensure that the audit policy covers key security concerns\" } ] } ] }, { \"title\": \"4 Worker Nodes\", \"groups\": [ { \"title\": \"4.1 Worker node configuration\", \"controls\": [ { \"id\": \"CIS-4.1.1\", \"title\": \"4.1.1 Ensure that the kubelet service file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-4.1.2\", \"title\": \"4.1.2 Ensure that the kubelet service file ownership is set to root:root\" }, { \"id\": \"CIS-4.1.3\", \"title\": \"4.1.3 If proxy kubeconfig file exists ensure permissions are set to 644 or more restrictive (Automated)\" }, { \"id\": \"CIS-4.1.4\", \"title\": \"4.1.4 If proxy kubeconfig file exists ensure ownership is set to root:root (Manual)\" }, { \"id\": \"CIS-4.1.5\", \"title\": \"4.1.5 Ensure that the --kubeconfig kubelet.conf file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-4.1.6\", \"title\": \"4.1.6 Ensure that the --kubeconfig kubelet.conf file ownership is set to root:root\" }, { \"id\": \"CIS-4.1.7\", \"title\": \"4.1.7 Ensure that the certificate authorities file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-4.1.8\", \"title\": \"4.1.8 Ensure that the client certificate authorities file ownership is set to root:root\" }, { \"id\": \"CIS-4.1.9\", \"title\": \"4.1.9 Ensure that the kubelet --config configuration file has permissions set to 644 or more restrictive\" }, { \"id\": \"CIS-4.1.10\", \"title\": \"4.1.10 Ensure that the kubelet configuration file ownership is set to root:root\" } ] }, { \"title\": \"4.2 Kubelet\", \"controls\": [ { \"id\": \"CIS-4.2.1\", \"title\": \"4.2.1 Ensure that the --anonymous-auth argument is set to false\" }, { \"id\": \"CIS-4.2.2\", \"title\": \"4.2.2 Ensure that the --authorization-mode argument is not set to AlwaysAllow\" }, { \"id\": \"CIS-4.2.3\", \"title\": \"4.2.3 Ensure that the --client-ca-file argument is set as appropriate\" }, { \"id\": \"CIS-4.2.4\", \"title\": \"4.2.4 Ensure that the --read-only-port argument is set to 0\" }, { \"id\": \"CIS-4.2.5\", \"title\": \"4.2.5 Ensure that the --streaming-connection-idle-timeout argument is not set to 0\" }, { \"id\": \"CIS-4.2.6\", \"title\": \"4.2.6 Ensure that the --protect-kernel-defaults argument is set to true\" }, { \"id\": \"CIS-4.2.7\", \"title\": \"4.2.7 Ensure that the --make-iptables-util-chains argument is set to true\" }, { \"id\": \"CIS-4.2.8\", \"title\": \"4.2.8 Ensure that the --hostname-override argument is not set\" }, { \"id\": \"CIS-4.2.9\", \"title\": \"4.2.9 Ensure that the --event-qps argument is set to 0 or a level which ensures appropriate event capture\" }, { \"id\": \"CIS-4.2.10\", \"title\": \"4.2.10 Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate\" }, { \"id\": \"CIS-4.2.11\", \"title\": \"4.2.11 Ensure that the --rotate-certificates argument is not set to false\" }, { \"id\": \"CIS-4.2.12\", \"title\": \"4.2.12 Verify that the RotateKubeletServerCertificate argument is set to true\" }, { \"id\": \"CIS-4.2.13\", \"title\": \"4.2.13 Ensure that the Kubelet only makes use of Strong Cryptographic Ciphers\" } ] } ] }, { \"title\": \"5 Policies\", \"groups\": [ { \"title\": \"5.1 RBAC and Service Accounts\", \"controls\": [ { \"id\": \"CIS-5.1.1\", \"title\": \"5.1.1 Ensure that the cluster-admin role is only used where required\" }, { \"id\": \"CIS-5.1.2\", \"title\": \"5.1.2 Minimize access to secrets (info)\" }, { \"id\": \"CIS-5.1.3\", \"title\": \"5.1.3 Minimize wildcard use in Roles and ClusterRoles (info)\" }, { \"id\": \"CIS-5.1.4\", \"title\": \"5.1.4 Minimize access to create pods (info)\" }, { \"id\": \"CIS-5.1.5\", \"title\": \"5.1.5 Ensure that default service accounts are not actively used. (info)\" }, { \"id\": \"CIS-5.1.6\", \"title\": \"5.1.6 Ensure that Service Account Tokens are only mounted where necessary (info)\" } ] }, { \"title\": \"5.2 Pod Security Policies / Security Context Constraints\", \"controls\": [ { \"id\": \"CIS-5.2.1\", \"title\": \"5.2.1 Minimize the admission of privileged containers (info)\" }, { \"id\": \"CIS-5.2.2\", \"title\": \"5.2.2 Minimize the admission of containers wishing to share the host process ID namespace (info)\" }, { \"id\": \"CIS-5.2.3\", \"title\": \"5.2.3 Minimize the admission of containers wishing to share the host IPC namespace (info)\" }, { \"id\": \"CIS-5.2.4\", \"title\": \"5.2.4 Minimize the admission of containers wishing to share the host network namespace (info)\" }, { \"id\": \"CIS-5.2.5\", \"title\": \"5.2.5 Minimize the admission of containers with allowPrivilegeEscalation (info)\" }, { \"id\": \"CIS-5.2.6\", \"title\": \"5.2.6 Minimize the admission of root containers (info)\" }, { \"id\": \"CIS-5.2.7\", \"title\": \"5.2.7 Minimize the admission of containers with the NET_RAW capability (info)\" }, { \"id\": \"CIS-5.2.8\", \"title\": \"5.2.8 Minimize the admission of containers with added capabilities (info)\" }, { \"id\": \"CIS-5.2.9\", \"title\": \"5.2.9 Minimize the admission of containers with capabilities assigned (info)\" } ] }, { \"title\": \"5.3 Network Policies and CNI\", \"controls\": [ { \"id\": \"CIS-5.3.1\", \"title\": \"5.3.1 Ensure that the CNI in use supports Network Policies (info)\" }, { \"id\": \"CIS-5.3.2\", \"title\": \"5.3.2 Ensure that all Namespaces have Network Policies defined\" } ] }, { \"title\": \"5.4 Secrets Management\", \"controls\": [ { \"id\": \"CIS-5.4.1\", \"title\": \"5.4.1 Prefer using secrets as files over secrets as environment variables (info)\" }, { \"id\": \"CIS-5.4.2\", \"title\": \"5.4.2 Consider external secret storage (info)\" } ] }, { \"title\": \"5.5 Extensible Admission Control\", \"controls\": [ { \"id\": \"CIS-5.5.1\", \"title\": \"5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller\" } ] }, { \"title\": \"5.6 General Policies\", \"controls\": [ { \"id\": \"CIS-5.6.1\", \"title\": \"5.6.1 Create administrative boundaries between resources using namespaces (info)\" }, { \"id\": \"CIS-5.6.2\", \"title\": \"5.6.2 Ensure Seccomp Profile Pod Definitions (info)\" }, { \"id\": \"CIS-5.6.3\", \"title\": \"5.6.3 Apply Security Context to your Pods and Containers (info)\" }, { \"id\": \"CIS-5.6.4\", \"title\": \"5.6.4 The Default Namespace should not be used (info)\" } ] } ] } ] } } Congratulations! You have completed this tutorial.","title":"Task - ocp4-cis-profile-to-oscal-catalog"},{"location":"tutorials/task.ocp4-cis-profile-to-oscal-catalog/transformation/#tutorial-setup-for-and-use-of-complianceascode-profile-to-oscal-catalog-transformer","text":"Here are step by step instructions for setup and transformation of ComplianceAsCode profile data files into NIST standard OSCAL Catalog using the compliance-trestle tool.","title":"Tutorial: Setup for and use of ComplianceAsCode profile to OSCAL Catalog transformer"},{"location":"tutorials/task.ocp4-cis-profile-to-oscal-catalog/transformation/#objective","text":"How to transform one or more .profile compliance files into a standardized OSCAL.json file. There are 2 short steps shown below. The first is a one-time check/set-up of your environment. The second is a one-command transformation from .profile to OSCAL.json .","title":"Objective"},{"location":"tutorials/task.ocp4-cis-profile-to-oscal-catalog/transformation/#step-1-install-trestle-in-a-python-virtual-environment","text":"Follow the instructions here to install trestle in a virtual environment.","title":"Step 1: Install trestle in a Python virtual environment"},{"location":"tutorials/task.ocp4-cis-profile-to-oscal-catalog/transformation/#step-2-transform-profile-data-cis-benchmarks","text":"Linux, Mac Windows Make these changes: use backslashes `\\` for file paths use `md` instead of mkdir -p put the url in double quotes for `curl` use `more` instead of cat Navigate to trestle workspace. (venv.trestle)$ cd trestle.workspace View configuration information. (venv.trestle)$ trestle task ocp4-cis-profile-to-oscal-catalog -i trestle.core.commands.task:102 WARNING: Config file was not configured with the appropriate section for the task: \"[task.ocp4-cis-profile-to-oscal-catalog]\" Help information for ocp4-cis-profile-to-oscal-catalog task. Purpose: Create catalog from from standard (e.g. CIS benchmark). Configuration flags sit under [task.ocp4-cis-profile-to-oscal-catalog]: input-dir = (required) location to read the compliance-as-code profile files. output-dir = (required) location to write the generated catalog.json file. output-overwrite = (optional) true [default] or false; replace existing output when true. Create data folders. (venv.trestle)$ mkdir -p adjunct-data/cis-benchmarks (venv.trestle)$ mkdir -p adjunct-data/task-files Fetch ComplianceAsCode profile data. (venv.trestle)$ curl 'https://raw.githubusercontent.com/ComplianceAsCode/content/master/products/ocp4/profiles/cis-node.profile' > adjunct-data/cis-benchmarks/cis-node.profile (venv.trestle)$ curl 'https://raw.githubusercontent.com/ComplianceAsCode/content/master/products/ocp4/profiles/cis-node.profile' > adjunct-data/cis-benchmarks/cis.profile Fetch trestle task file. (venv.trestle)$ curl 'https://raw.githubusercontent.com/IBM/compliance-trestle/main/docs/tutorials/task.ocp4-cis-profile-to-oscal-catalog/demo-ocp4-cis-profile-to-oscal-catalog.config' > adjunct-data/task-files/demo-ocp4-cis-profile-to-oscal-catalog.config demo-ocp4-cis-profile-to-oscal-catalog.config [task.ocp4-cis-profile-to-oscal-catalog] input-dir = adjunct-data/cis-benchmarks output-dir = catalogs/ocp4-cis Perform and validate the transform. (venv.trestle)$ trestle task ocp4-cis-profile-to-oscal-catalog -c adjunct-data/task-files/demo-ocp4-cis-profile-to-oscal-catalog.config output: catalogs/ocp4-cis/catalog.json Task: ocp4-cis-profile-to-oscal-catalog executed successfully. (venv.trestle)$ trestle validate --all VALID: Model /home/<user>/trestle.workspace/catalogs/ocp4-cis/catalog.json passed the Validator to confirm the model passes all registered validation tests. View the generated OSCAL. (venv.trestle)$ cat catlogs/ocp4-cis/catalog.json catalog.json { \"catalog\": { \"uuid\": \"19543ebf-4667-48b7-be47-d51154f16fda\", \"metadata\": { \"title\": \"CIS Red Hat OpenShift Container Platform 4 Benchmark\", \"last-modified\": \"2021-12-03T13:52:21+00:00\", \"version\": \"0.29.0\", \"oscal-version\": \"1.0.0\", \"links\": [ { \"href\": \"https://github.com/ComplianceAsCode/content/blob/master/products/ocp4/profiles/cis-node.profile\" }, { \"href\": \"https://github.com/ComplianceAsCode/content/blob/master/products/ocp4/profiles/cis.profile\" } ] }, \"groups\": [ { \"title\": \"1 Control Plane Components\", \"groups\": [ { \"title\": \"1.1 Master Node Configuration Files\", \"controls\": [ { \"id\": \"CIS-1.1.1\", \"title\": \"1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.2\", \"title\": \"1.1.2 Ensure that the API server pod specification file ownership is set to root:root\" }, { \"id\": \"CIS-1.1.3\", \"title\": \"1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.4\", \"title\": \"1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root\" }, { \"id\": \"CIS-1.1.5\", \"title\": \"1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.6\", \"title\": \"1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root\" }, { \"id\": \"CIS-1.1.7\", \"title\": \"1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.8\", \"title\": \"1.1.8 Ensure that the etcd pod specification file ownership is set to root:root (Automated)\" }, { \"id\": \"CIS-1.1.9\", \"title\": \"1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.10\", \"title\": \"1.1.10 Ensure that the Container Network Interface file ownership is set to root:root\" }, { \"id\": \"CIS-1.1.11\", \"title\": \"1.1.11 Ensure that the etcd data directory permissions are set to 700 or more restrictive\" }, { \"id\": \"CIS-1.1.12\", \"title\": \"1.1.12 Ensure that the etcd data directory ownership is set to root:root\" }, { \"id\": \"CIS-1.1.13\", \"title\": \"1.1.13 Ensure that the admin.conf file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.14\", \"title\": \"1.1.14 Ensure that the admin.conf file ownership is set to root:root\" }, { \"id\": \"CIS-1.1.15\", \"title\": \"1.1.15 Ensure that the scheduler.conf file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.16\", \"title\": \"1.1.16 Ensure that the scheduler.conf file ownership is set to root:root\" }, { \"id\": \"CIS-1.1.17\", \"title\": \"1.1.17 Ensure that the controller-manager.conf file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.18\", \"title\": \"1.1.18 Ensure that the controller-manager.conf file ownership is set to root:root\" }, { \"id\": \"CIS-1.1.19\", \"title\": \"1.1.19 Ensure that the OpenShift PKI directory and file ownership is set to root:root\" }, { \"id\": \"CIS-1.1.20\", \"title\": \"1.1.20 Ensure that the OpenShift PKI certificate file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-1.1.21\", \"title\": \"1.1.21 Ensure that the OpenShift PKI key file permissions are set to 600\" } ] }, { \"title\": \"1.2 API Server\", \"controls\": [ { \"id\": \"CIS-1.2.1\", \"title\": \"1.2.1 Ensure that the --anonymous-auth argument is set to false\" }, { \"id\": \"CIS-1.2.2\", \"title\": \"1.2.2 Ensure that the --basic-auth-file argument is not set\" }, { \"id\": \"CIS-1.2.3\", \"title\": \"1.2.3 Ensure that the --token-auth-file parameter is not set\" }, { \"id\": \"CIS-1.2.4\", \"title\": \"1.2.4 Ensure that the --kubelet-https argument is set to true\" }, { \"id\": \"CIS-1.2.5\", \"title\": \"1.2.5 Ensure that the --kubelet-client-certificate and --kubelet-client-key arguments are set as appropriate\" }, { \"id\": \"CIS-1.2.6\", \"title\": \"1.2.6 Ensure that the --kubelet-certificate-authority argument is set as appropriate\" }, { \"id\": \"CIS-1.2.7\", \"title\": \"1.2.7 Ensure that the --authorization-mode argument is not set to AlwaysAllow\" }, { \"id\": \"CIS-1.2.8\", \"title\": \"1.2.8 Ensure that the --authorization-mode argument includes Node\" }, { \"id\": \"CIS-1.2.9\", \"title\": \"1.2.9 Ensure that the --authorization-mode argument includes RBAC\" }, { \"id\": \"CIS-1.2.10\", \"title\": \"1.2.10 Ensure that the admission control plugin EventRateLimit is set\" }, { \"id\": \"CIS-1.2.11\", \"title\": \"1.2.11 Ensure that the admission control plugin AlwaysAdmit is not set\" }, { \"id\": \"CIS-1.2.12\", \"title\": \"1.2.12 Ensure that the admission control plugin AlwaysPullImages is set\" }, { \"id\": \"CIS-1.2.13\", \"title\": \"1.2.13 Ensure that the admission control plugin SecurityContextDeny is not set\" }, { \"id\": \"CIS-1.2.14\", \"title\": \"1.2.14 Ensure that the admission control plugin ServiceAccount is set\" }, { \"id\": \"CIS-1.2.15\", \"title\": \"1.2.15 Ensure that the admission control plugin NamespaceLifecycle is set\" }, { \"id\": \"CIS-1.2.16\", \"title\": \"1.2.16 Ensure that the admission control plugin PodSecurityPolicy is set (Automated)\" }, { \"id\": \"CIS-1.2.17\", \"title\": \"1.2.17 Ensure that the admission control plugin NodeRestriction is set (Automated)\" }, { \"id\": \"CIS-1.2.18\", \"title\": \"1.2.18 Ensure that the --insecure-bind-address argument is not set\" }, { \"id\": \"CIS-1.2.19\", \"title\": \"1.2.19 Ensure that the --insecure-port argument is set to 0\" }, { \"id\": \"CIS-1.2.20\", \"title\": \"1.2.20 Ensure that the --secure-port argument is not set to 0\" }, { \"id\": \"CIS-1.2.21\", \"title\": \"1.2.21 Ensure that the --profiling argument is set to false\" }, { \"id\": \"CIS-1.2.22\", \"title\": \"1.2.22 Ensure that the --audit-log-path argument is set\" }, { \"id\": \"CIS-1.2.23\", \"title\": \"1.2.23 Ensure that the audit logs are forwarded off the cluster for retention\" }, { \"id\": \"CIS-1.2.24\", \"title\": \"1.2.24 Ensure that the --audit-log-maxbackup argument is set to 10 or as appropriate\" }, { \"id\": \"CIS-1.2.25\", \"title\": \"1.2.25 Ensure that the --audit-log-maxsize argument is set to 100 or as appropriate\" }, { \"id\": \"CIS-1.2.26\", \"title\": \"1.2.26 Ensure that the --request-timeout argument is set as appropriate\" }, { \"id\": \"CIS-1.2.27\", \"title\": \"1.2.27 Ensure that the --service-account-lookup argument is set to true\" }, { \"id\": \"CIS-1.2.28\", \"title\": \"1.2.28 Ensure that the --service-account-key-file argument is set as appropriate\" }, { \"id\": \"CIS-1.2.29\", \"title\": \"1.2.29 Ensure that the --etcd-certfile and --etcd-keyfile arguments are set as appropriate\" }, { \"id\": \"CIS-1.2.30\", \"title\": \"1.2.30 Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate\" }, { \"id\": \"CIS-1.2.31\", \"title\": \"1.2.31 Ensure that the --client-ca-file argument is set as appropriate\" }, { \"id\": \"CIS-1.2.32\", \"title\": \"1.2.32 Ensure that the --etcd-cafile argument is set as appropriate\" }, { \"id\": \"CIS-1.2.33\", \"title\": \"1.2.33 Ensure that the --encryption-provider-config argument is set as appropriate\" }, { \"id\": \"CIS-1.2.34\", \"title\": \"1.2.34 Ensure that encryption providers are appropriately configured\" }, { \"id\": \"CIS-1.2.35\", \"title\": \"1.2.35 Ensure that the API Server only makes use of Strong Cryptographic Ciphers\" } ] }, { \"title\": \"1.3 Controller Manager\", \"controls\": [ { \"id\": \"CIS-1.3.1\", \"title\": \"1.3.1 Ensure that garbage collection is configured as appropriate\" }, { \"id\": \"CIS-1.3.2\", \"title\": \"1.3.2 Ensure that controller manager healthz endpoints are protected by RBAC. (Automated)\" }, { \"id\": \"CIS-1.3.3\", \"title\": \"1.3.3 Ensure that the --use-service-account-credentials argument is set to true\" }, { \"id\": \"CIS-1.3.4\", \"title\": \"1.3.4 Ensure that the --service-account-private-key-file argument is set as appropriate\" }, { \"id\": \"CIS-1.3.5\", \"title\": \"1.3.5 Ensure that the --root-ca-file argument is set as appropriate\" }, { \"id\": \"CIS-1.3.6\", \"title\": \"1.3.6 Ensure that the RotateKubeletServerCertificate argument is set to true\" }, { \"id\": \"CIS-1.3.7\", \"title\": \"1.3.7 Ensure that the --bind-address argument is set to 127.0.0.1\" } ] }, { \"title\": \"1.4 Scheduler\", \"controls\": [ { \"id\": \"CIS-1.4.1\", \"title\": \"1.4.1 Ensure that the --profiling argument is set to false (info only)\" }, { \"id\": \"CIS-1.4.2\", \"title\": \"1.4.2 Ensure that the --bind-address argument is set to 127.0.0.1\" } ] } ] }, { \"title\": \"2 etcd\", \"controls\": [ { \"id\": \"CIS-2.1\", \"title\": \"2.1 Ensure that the --cert-file and --key-file arguments are set as appropriate\" }, { \"id\": \"CIS-2.2\", \"title\": \"2.2 Ensure that the --client-cert-auth argument is set to true\" }, { \"id\": \"CIS-2.3\", \"title\": \"2.3 Ensure that the --auto-tls argument is not set to true\" }, { \"id\": \"CIS-2.4\", \"title\": \"2.4 Ensure that the --peer-cert-file and --peer-key-file arguments are set as appropriate\" }, { \"id\": \"CIS-2.5\", \"title\": \"2.5 Ensure that the --peer-client-cert-auth argument is set to true\" }, { \"id\": \"CIS-2.6\", \"title\": \"2.6 Ensure that the --peer-auto-tls argument is not set to true\" }, { \"id\": \"CIS-2.7\", \"title\": \"2.7 Ensure that a unique Certificate Authority is used for etcd\" } ] }, { \"title\": \"3 Control Plane Configuration\", \"groups\": [ { \"title\": \"3.1 Authentication and Authorization\", \"controls\": [ { \"id\": \"CIS-3.1.1\", \"title\": \"3.1.1 Client certificate authentication should not be used for users\" } ] }, { \"title\": \"3.2 Logging\", \"controls\": [ { \"id\": \"CIS-3.2.1\", \"title\": \"3.2.1 Ensure that a minimal audit policy is created\" }, { \"id\": \"CIS-3.2.2\", \"title\": \"3.2.2 Ensure that the audit policy covers key security concerns\" } ] } ] }, { \"title\": \"4 Worker Nodes\", \"groups\": [ { \"title\": \"4.1 Worker node configuration\", \"controls\": [ { \"id\": \"CIS-4.1.1\", \"title\": \"4.1.1 Ensure that the kubelet service file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-4.1.2\", \"title\": \"4.1.2 Ensure that the kubelet service file ownership is set to root:root\" }, { \"id\": \"CIS-4.1.3\", \"title\": \"4.1.3 If proxy kubeconfig file exists ensure permissions are set to 644 or more restrictive (Automated)\" }, { \"id\": \"CIS-4.1.4\", \"title\": \"4.1.4 If proxy kubeconfig file exists ensure ownership is set to root:root (Manual)\" }, { \"id\": \"CIS-4.1.5\", \"title\": \"4.1.5 Ensure that the --kubeconfig kubelet.conf file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-4.1.6\", \"title\": \"4.1.6 Ensure that the --kubeconfig kubelet.conf file ownership is set to root:root\" }, { \"id\": \"CIS-4.1.7\", \"title\": \"4.1.7 Ensure that the certificate authorities file permissions are set to 644 or more restrictive\" }, { \"id\": \"CIS-4.1.8\", \"title\": \"4.1.8 Ensure that the client certificate authorities file ownership is set to root:root\" }, { \"id\": \"CIS-4.1.9\", \"title\": \"4.1.9 Ensure that the kubelet --config configuration file has permissions set to 644 or more restrictive\" }, { \"id\": \"CIS-4.1.10\", \"title\": \"4.1.10 Ensure that the kubelet configuration file ownership is set to root:root\" } ] }, { \"title\": \"4.2 Kubelet\", \"controls\": [ { \"id\": \"CIS-4.2.1\", \"title\": \"4.2.1 Ensure that the --anonymous-auth argument is set to false\" }, { \"id\": \"CIS-4.2.2\", \"title\": \"4.2.2 Ensure that the --authorization-mode argument is not set to AlwaysAllow\" }, { \"id\": \"CIS-4.2.3\", \"title\": \"4.2.3 Ensure that the --client-ca-file argument is set as appropriate\" }, { \"id\": \"CIS-4.2.4\", \"title\": \"4.2.4 Ensure that the --read-only-port argument is set to 0\" }, { \"id\": \"CIS-4.2.5\", \"title\": \"4.2.5 Ensure that the --streaming-connection-idle-timeout argument is not set to 0\" }, { \"id\": \"CIS-4.2.6\", \"title\": \"4.2.6 Ensure that the --protect-kernel-defaults argument is set to true\" }, { \"id\": \"CIS-4.2.7\", \"title\": \"4.2.7 Ensure that the --make-iptables-util-chains argument is set to true\" }, { \"id\": \"CIS-4.2.8\", \"title\": \"4.2.8 Ensure that the --hostname-override argument is not set\" }, { \"id\": \"CIS-4.2.9\", \"title\": \"4.2.9 Ensure that the --event-qps argument is set to 0 or a level which ensures appropriate event capture\" }, { \"id\": \"CIS-4.2.10\", \"title\": \"4.2.10 Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate\" }, { \"id\": \"CIS-4.2.11\", \"title\": \"4.2.11 Ensure that the --rotate-certificates argument is not set to false\" }, { \"id\": \"CIS-4.2.12\", \"title\": \"4.2.12 Verify that the RotateKubeletServerCertificate argument is set to true\" }, { \"id\": \"CIS-4.2.13\", \"title\": \"4.2.13 Ensure that the Kubelet only makes use of Strong Cryptographic Ciphers\" } ] } ] }, { \"title\": \"5 Policies\", \"groups\": [ { \"title\": \"5.1 RBAC and Service Accounts\", \"controls\": [ { \"id\": \"CIS-5.1.1\", \"title\": \"5.1.1 Ensure that the cluster-admin role is only used where required\" }, { \"id\": \"CIS-5.1.2\", \"title\": \"5.1.2 Minimize access to secrets (info)\" }, { \"id\": \"CIS-5.1.3\", \"title\": \"5.1.3 Minimize wildcard use in Roles and ClusterRoles (info)\" }, { \"id\": \"CIS-5.1.4\", \"title\": \"5.1.4 Minimize access to create pods (info)\" }, { \"id\": \"CIS-5.1.5\", \"title\": \"5.1.5 Ensure that default service accounts are not actively used. (info)\" }, { \"id\": \"CIS-5.1.6\", \"title\": \"5.1.6 Ensure that Service Account Tokens are only mounted where necessary (info)\" } ] }, { \"title\": \"5.2 Pod Security Policies / Security Context Constraints\", \"controls\": [ { \"id\": \"CIS-5.2.1\", \"title\": \"5.2.1 Minimize the admission of privileged containers (info)\" }, { \"id\": \"CIS-5.2.2\", \"title\": \"5.2.2 Minimize the admission of containers wishing to share the host process ID namespace (info)\" }, { \"id\": \"CIS-5.2.3\", \"title\": \"5.2.3 Minimize the admission of containers wishing to share the host IPC namespace (info)\" }, { \"id\": \"CIS-5.2.4\", \"title\": \"5.2.4 Minimize the admission of containers wishing to share the host network namespace (info)\" }, { \"id\": \"CIS-5.2.5\", \"title\": \"5.2.5 Minimize the admission of containers with allowPrivilegeEscalation (info)\" }, { \"id\": \"CIS-5.2.6\", \"title\": \"5.2.6 Minimize the admission of root containers (info)\" }, { \"id\": \"CIS-5.2.7\", \"title\": \"5.2.7 Minimize the admission of containers with the NET_RAW capability (info)\" }, { \"id\": \"CIS-5.2.8\", \"title\": \"5.2.8 Minimize the admission of containers with added capabilities (info)\" }, { \"id\": \"CIS-5.2.9\", \"title\": \"5.2.9 Minimize the admission of containers with capabilities assigned (info)\" } ] }, { \"title\": \"5.3 Network Policies and CNI\", \"controls\": [ { \"id\": \"CIS-5.3.1\", \"title\": \"5.3.1 Ensure that the CNI in use supports Network Policies (info)\" }, { \"id\": \"CIS-5.3.2\", \"title\": \"5.3.2 Ensure that all Namespaces have Network Policies defined\" } ] }, { \"title\": \"5.4 Secrets Management\", \"controls\": [ { \"id\": \"CIS-5.4.1\", \"title\": \"5.4.1 Prefer using secrets as files over secrets as environment variables (info)\" }, { \"id\": \"CIS-5.4.2\", \"title\": \"5.4.2 Consider external secret storage (info)\" } ] }, { \"title\": \"5.5 Extensible Admission Control\", \"controls\": [ { \"id\": \"CIS-5.5.1\", \"title\": \"5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller\" } ] }, { \"title\": \"5.6 General Policies\", \"controls\": [ { \"id\": \"CIS-5.6.1\", \"title\": \"5.6.1 Create administrative boundaries between resources using namespaces (info)\" }, { \"id\": \"CIS-5.6.2\", \"title\": \"5.6.2 Ensure Seccomp Profile Pod Definitions (info)\" }, { \"id\": \"CIS-5.6.3\", \"title\": \"5.6.3 Apply Security Context to your Pods and Containers (info)\" }, { \"id\": \"CIS-5.6.4\", \"title\": \"5.6.4 The Default Namespace should not be used (info)\" } ] } ] } ] } } Congratulations! You have completed this tutorial.","title":"Step 2: Transform profile data (CIS benchmarks)"},{"location":"tutorials/task.ocp4-cis-profile-to-oscal-cd/transformation/","text":"Tutorial: Setup for and use of ComplianceAsCode profile to OSCAL Component Definition transformer \u00a4 Here are step by step instructions for setup and transformation of ComplianceAsCode profile data files into NIST standard OSCAL Component Definition using the compliance-trestle tool. Objective \u00a4 How to transform one or more .profile compliance files into a standardized OSCAL.json file. There are 2 short steps shown below. The first is a one-time check/set-up of your environment. The second is a one-command transformation from .profile to OSCAL.json . Step 1: Install trestle in a Python virtual environment \u00a4 Follow the instructions here to install trestle in a virtual environment. Step 2: Transform profile data (CIS benchmarks) \u00a4 Linux, Mac Windows Make these changes: use backslashes `\\` for file paths use `md` instead of mkdir -p put the url in double quotes for `curl` use `more` instead of cat Navigate to trestle workspace. ( venv.trestle ) $ cd trestle.workspace View configuration information. ( venv.trestle ) $ trestle task ocp4-cis-profile-to-oscal-cd -i trestle.core.commands.task:99 WARNING: Config file was not configured with the appropriate section for the task: \"[task.ocp4-cis-profile-to-oscal-cd]\" Help information for ocp4-cis-profile-to-oscal-cd task. Purpose: Create component definition from standard ( e.g. CIS benchmark ) . Configuration flags sit under [ task.ocp4-cis-profile-to-oscal-cd ] : component-name = component name, e.g. OSCO. org-name = organization name, e.g. International Business Machines. org-remarks = organization remarks, e.g. IBM. folder-cac = folder containing compliance-as-code artifacts, e.g adjunct-data/cis-benchmarks/content. output-dir = location to write the generated component-definition.json file. profile-name = profile name, e.g. OCP4 CIS-benchmark v4. profile-mnemonic = profile mnemonic, e.g. ocp4-cis-node. profile-ns = profile ns, e.g. http://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud. profile-version = profile version, e.g. 1 .1. profile-check-version = profile check version, e.g. 0 .1.58. profile-type = profile type, e.g. OCP4. profile-list = profile list is blank separated list of \"<suffix>\" for config entries: profile-file.<suffix>, profile-title.<suffix>, profile-url.<suffix>, e.g. cis cis-node. profile-file.<suffix> = path of the profile file to ingest, e.g. ${ folder -cac } /products/ocp4/profiles/cis-node.profile. profile-title.<suffix> = title of the profile, e.g. CIS Red Hat OpenShift Container Platform 4 Benchmark. profile-url.<suffix> = URL of the profile, e.g. https://github.com/ComplianceAsCode/content/blob/master/products/ocp4/profiles/cis.profile. rule-to-parameters-map = map file for set-parameters, e.g. adjunct-data/task-files/rule2var.json. selected-rules = file with list of selected rules, e.g. adjunct-data/task-files/selected_rules.json. enabled-rules = file with list of enabled rules, e.g. adjunct-data/task-files/enabled_rules.json. Notes: 1 . If a control has selected rules but no enabled rules, then all those selected are included. 2 . If a control has selected and enabled rules, then only those enabled are included. 3 . If a control has no selected rules, then none are included regardless of enabled. Create data folders. ( venv.trestle ) $ mkdir -p adjunct-data/cis-benchmarks ( venv.trestle ) $ mkdir -p adjunct-data/config-files ( venv.trestle ) $ mkdir -p adjunct-data/task-files Fetch ComplianceAsCode data. ( venv.trestle ) $ cd adjunct-data/cis-benchmarks/ ( venv.trestle ) $ git clone https://github.com/ComplianceAsCode/content.git ( venv.trestle ) $ cd - Fetch trestle config and task files. ( venv.trestle ) $ curl 'https://raw.githubusercontent.com/IBM/compliance-trestle/main/docs/tutorials/task.ocp4-cis-profile-to-oscal-cd/demo-ocp4-cis-profile-to-oscal-cd.config' > adjunct-data/config-files/demo-ocp4-cis-profile-to-oscal-cd.config ( venv.trestle ) $ curl 'https://raw.githubusercontent.com/IBM/compliance-trestle/main/docs/tutorials/task.ocp4-cis-profile-to-oscal-cd/selected_rules.json' > adjunct-data/task-files/selected_rules.json ( venv.trestle ) $ curl 'https://raw.githubusercontent.com/IBM/compliance-trestle/main/docs/tutorials/task.ocp4-cis-profile-to-oscal-cd/enabled_rules.json' > adjunct-data/task-files/enabled_rules.json demo-ocp4-cis-profile-to-oscal-cd.config [ task.ocp4-cis-profile-to-oscal-cd ] component-name = OSCO folder-cac = adjunct-data/cis-benchmarks/content org-name = International Business Machines org-remarks = IBM output-dir = component-definitions/ocp4-cis profile-name = OCP4 CIS-benchmark v4 profile-mnemonic = ocp4-cis-node profile-ns = http://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud profile-version = 1 .1 profile-check-version = 0 .1.58 profile-type = OCP4 profile-list = cis-node cis profile-file.cis-node = ${ folder -cac } /products/ocp4/profiles/cis-node.profile profile-url.cis-node = https://github.com/ComplianceAsCode/content/blob/master/products/ocp4/profiles/cis-node.profile profile-title.cis-node = CIS Red Hat OpenShift Container Platform 4 Benchmark profile-file.cis = ${ folder -cac } /products/ocp4/profiles/cis.profile profile-url.cis = https://github.com/ComplianceAsCode/content/blob/master/products/ocp4/profiles/cis.profile profile-title.cis = CIS Red Hat OpenShift Container Platform 4 Benchmark selected-rules = adjunct-data/task-files/selected_rules.json enabled-rules = adjunct-data/task-files/enabled_rules.json selected_rules.json [ \"file_permissions_kube_apiserver\" , \"file_owner_kube_apiserver\" , \"file_groupowner_kube_apiserver\" ] enabled_rules.json [ \"file_permissions_cni_conf\" , \"file_permissions_multus_conf\" , \"file_owner_cni_conf\" , \"file_groupowner_cni_conf\" , \"file_owner_multus_conf\" , \"file_groupowner_multus_conf\" , \"kubelet_eviction_thresholds_set_soft_memory_available\" , \"kubelet_eviction_thresholds_set_soft_nodefs_available\" , \"kubelet_eviction_thresholds_set_soft_nodefs_inodesfree\" , \"kubelet_eviction_thresholds_set_soft_imagefs_available\" , \"kubelet_eviction_thresholds_set_soft_imagefs_inodesfree\" , \"kubelet_eviction_thresholds_set_hard_memory_available\" , \"kubelet_eviction_thresholds_set_hard_nodefs_available\" , \"kubelet_eviction_thresholds_set_hard_nodefs_inodesfree\" , \"kubelet_eviction_thresholds_set_hard_imagefs_available\" , \"kubelet_eviction_thresholds_set_hard_imagefs_inodesfree\" , \"etcd_unique_ca\" , \"file_permissions_kubelet_conf\" , \"file_groupowner_kubelet_conf\" , \"file_owner_kubelet_conf\" , \"file_permissions_worker_ca\" , \"file_owner_worker_ca\" , \"file_groupowner_worker_ca\" , \"kubelet_anonymous_auth\" , \"kubelet_configure_client_ca\" , \"kubelet_enable_streaming_connections\" , \"kubelet_enable_iptables_util_chains\" , \"kubelet_disable_hostname_override\" , \"kubelet_configure_event_creation\" , \"kubelet_configure_tls_cipher_suites\" ] Perform and validate the transform. ( venv.trestle ) $ trestle task ocp4-cis-profile-to-oscal-cd -c adjunct-data/config-files/demo-ocp4-cis-profile-to-oscal-cd.config output: component-definitions/ocp4-cis/component-definition.json Task: ocp4-cis-profile-to-oscal-cd executed successfully. ( venv.trestle ) $ trestle validate --all VALID: Model /home/<user>/trestle.workspace/component-definitions/ocp4-cis/component-definition.json passed the Validator to confirm the model passes all registered validation tests. View the generated OSCAL. ( venv.trestle ) $ cat component-definitions/ocp4-cis/component-definition.json component-definition.json { \"component-definition\" : { \"uuid\" : \"d1b961ee-188b-42b9-943d-e11dc260f9dc\" , \"metadata\" : { \"title\" : \"Component definition for OCP4 profiles\" , \"last-modified\" : \"2022-01-06T22:43:59+00:00\" , \"version\" : \"0.33.0\" , \"oscal-version\" : \"1.0.0\" , \"roles\" : [ { \"id\" : \"prepared-by\" , \"title\" : \"Indicates the organization that created this content.\" }, { \"id\" : \"prepared-for\" , \"title\" : \"Indicates the organization for which this content was created..\" }, { \"id\" : \"content-approver\" , \"title\" : \"Indicates the organization responsible for all content represented in the \\\"document\\\".\" } ], \"parties\" : [ { \"uuid\" : \"d00dff65-e4ae-4344-a206-1e298eff9066\" , \"type\" : \"organization\" , \"name\" : \"International Business Machines\" , \"remarks\" : \"IBM\" }, { \"uuid\" : \"851b55f0-5ba6-4684-8a48-5dad22ba2625\" , \"type\" : \"organization\" , \"name\" : \"Customer\" , \"remarks\" : \"organization to be customized at account creation only for their Component Definition\" }, { \"uuid\" : \"150f9eb7-7fa5-4989-b9be-bc3cba220354\" , \"type\" : \"organization\" , \"name\" : \"ISV\" , \"remarks\" : \"organization to be customized at ISV subscription only for their Component Definition\" } ], \"responsible-parties\" : [ { \"role-id\" : \"prepared-by\" , \"party-uuids\" : [ \"d00dff65-e4ae-4344-a206-1e298eff9066\" ] }, { \"role-id\" : \"prepared-for\" , \"party-uuids\" : [ \"851b55f0-5ba6-4684-8a48-5dad22ba2625\" , \"150f9eb7-7fa5-4989-b9be-bc3cba220354\" ] }, { \"role-id\" : \"content-approver\" , \"party-uuids\" : [ \"d00dff65-e4ae-4344-a206-1e298eff9066\" ] } ] }, \"components\" : [ { \"uuid\" : \"e2ee2b93-6103-42de-b615-65b0b3ff2dc4\" , \"type\" : \"Service\" , \"title\" : \"OSCO\" , \"description\" : \"OSCO\" , \"control-implementations\" : [ { \"uuid\" : \"f9c2699a-2d2c-4ee2-87f3-042d1a9b3a79\" , \"source\" : \"https://github.com/ComplianceAsCode/content/blob/master/products/ocp4/profiles/cis-node.profile\" , \"description\" : \"OSCO implemented controls for CIS Red Hat OpenShift Container Platform 4 Benchmark.\" , \"props\" : [ { \"name\" : \"profile_name\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud\" , \"value\" : \"OCP4 CIS-benchmark v4\" , \"class\" : \"scc_profile_name\" }, { \"name\" : \"profile_mnemonic\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud\" , \"value\" : \"ocp4-cis-node\" , \"class\" : \"scc_profile_mnemonic\" }, { \"name\" : \"profile_version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud\" , \"value\" : \"1.1\" , \"class\" : \"scc_profile_version\" }, { \"name\" : \"profile_check_version\" , \"value\" : \"0.1.58\" } ], \"implemented-requirements\" : [ { \"uuid\" : \"97142b13-bc30-4e72-be7f-36de9149a679\" , \"control-id\" : \"CIS-1.1.1\" , \"description\" : \"Ensure that the API server pod specification file permissions are set to 644 or more restrictive\" , \"props\" : [ { \"name\" : \"XCCDF_rule\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud\" , \"value\" : \"xccdf_org.ssgproject.content_rule_file_permissions_kube_apiserver\" , \"class\" : \"scc_goal_name_id\" , \"remarks\" : \"Verify Permissions on the Kubernetes API Server Pod Specification File\" } ], \"responsible-roles\" : [ { \"role-id\" : \"prepared-by\" , \"party-uuids\" : [ \"d00dff65-e4ae-4344-a206-1e298eff9066\" ] }, { \"role-id\" : \"prepared-for\" , \"party-uuids\" : [ \"851b55f0-5ba6-4684-8a48-5dad22ba2625\" , \"150f9eb7-7fa5-4989-b9be-bc3cba220354\" ] }, { \"role-id\" : \"content-approver\" , \"party-uuids\" : [ \"d00dff65-e4ae-4344-a206-1e298eff9066\" ] } ] }, { \"uuid\" : \"0690e2a7-b228-4954-93fe-c1d55936cfa8\" , \"control-id\" : \"CIS-1.1.2\" , \"description\" : \"Ensure that the API server pod specification file ownership is set to root:root\" , \"props\" : [ { \"name\" : \"XCCDF_rule\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud\" , \"value\" : \"xccdf_org.ssgproject.content_rule_file_owner_kube_apiserver\" , \"class\" : \"scc_goal_name_id\" , \"remarks\" : \"Verify User Who Owns The Kubernetes API Server Pod Specification File\" } ], \"responsible-roles\" : [ { \"role-id\" : \"prepared-by\" , \"party-uuids\" : [ \"d00dff65-e4ae-4344-a206-1e298eff9066\" ] }, { \"role-id\" : \"prepared-for\" , \"party-uuids\" : [ \"851b55f0-5ba6-4684-8a48-5dad22ba2625\" , \"150f9eb7-7fa5-4989-b9be-bc3cba220354\" ] }, { \"role-id\" : \"content-approver\" , \"party-uuids\" : [ \"d00dff65-e4ae-4344-a206-1e298eff9066\" ] } ] }, { \"uuid\" : \"18c61fb2-8603-440d-9d9a-8d6d1e232cd3\" , \"control-id\" : \"CIS-1.1.2\" , \"description\" : \"Ensure that the API server pod specification file ownership is set to root:root\" , \"props\" : [ { \"name\" : \"XCCDF_rule\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud\" , \"value\" : \"xccdf_org.ssgproject.content_rule_file_groupowner_kube_apiserver\" , \"class\" : \"scc_goal_name_id\" , \"remarks\" : \"Verify Group Who Owns The Kubernetes API Server Pod Specification File\" } ], \"responsible-roles\" : [ { \"role-id\" : \"prepared-by\" , \"party-uuids\" : [ \"d00dff65-e4ae-4344-a206-1e298eff9066\" ] }, { \"role-id\" : \"prepared-for\" , \"party-uuids\" : [ \"851b55f0-5ba6-4684-8a48-5dad22ba2625\" , \"150f9eb7-7fa5-4989-b9be-bc3cba220354\" ] }, { \"role-id\" : \"content-approver\" , \"party-uuids\" : [ \"d00dff65-e4ae-4344-a206-1e298eff9066\" ] } ] } ] } ] } ] } } Congratulations! You have completed this tutorial.","title":"Task - ocp4-cis-profile-to-oscal-cd"},{"location":"tutorials/task.ocp4-cis-profile-to-oscal-cd/transformation/#tutorial-setup-for-and-use-of-complianceascode-profile-to-oscal-component-definition-transformer","text":"Here are step by step instructions for setup and transformation of ComplianceAsCode profile data files into NIST standard OSCAL Component Definition using the compliance-trestle tool.","title":"Tutorial: Setup for and use of ComplianceAsCode profile to OSCAL Component Definition transformer"},{"location":"tutorials/task.ocp4-cis-profile-to-oscal-cd/transformation/#objective","text":"How to transform one or more .profile compliance files into a standardized OSCAL.json file. There are 2 short steps shown below. The first is a one-time check/set-up of your environment. The second is a one-command transformation from .profile to OSCAL.json .","title":"Objective"},{"location":"tutorials/task.ocp4-cis-profile-to-oscal-cd/transformation/#step-1-install-trestle-in-a-python-virtual-environment","text":"Follow the instructions here to install trestle in a virtual environment.","title":"Step 1: Install trestle in a Python virtual environment"},{"location":"tutorials/task.ocp4-cis-profile-to-oscal-cd/transformation/#step-2-transform-profile-data-cis-benchmarks","text":"Linux, Mac Windows Make these changes: use backslashes `\\` for file paths use `md` instead of mkdir -p put the url in double quotes for `curl` use `more` instead of cat Navigate to trestle workspace. ( venv.trestle ) $ cd trestle.workspace View configuration information. ( venv.trestle ) $ trestle task ocp4-cis-profile-to-oscal-cd -i trestle.core.commands.task:99 WARNING: Config file was not configured with the appropriate section for the task: \"[task.ocp4-cis-profile-to-oscal-cd]\" Help information for ocp4-cis-profile-to-oscal-cd task. Purpose: Create component definition from standard ( e.g. CIS benchmark ) . Configuration flags sit under [ task.ocp4-cis-profile-to-oscal-cd ] : component-name = component name, e.g. OSCO. org-name = organization name, e.g. International Business Machines. org-remarks = organization remarks, e.g. IBM. folder-cac = folder containing compliance-as-code artifacts, e.g adjunct-data/cis-benchmarks/content. output-dir = location to write the generated component-definition.json file. profile-name = profile name, e.g. OCP4 CIS-benchmark v4. profile-mnemonic = profile mnemonic, e.g. ocp4-cis-node. profile-ns = profile ns, e.g. http://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud. profile-version = profile version, e.g. 1 .1. profile-check-version = profile check version, e.g. 0 .1.58. profile-type = profile type, e.g. OCP4. profile-list = profile list is blank separated list of \"<suffix>\" for config entries: profile-file.<suffix>, profile-title.<suffix>, profile-url.<suffix>, e.g. cis cis-node. profile-file.<suffix> = path of the profile file to ingest, e.g. ${ folder -cac } /products/ocp4/profiles/cis-node.profile. profile-title.<suffix> = title of the profile, e.g. CIS Red Hat OpenShift Container Platform 4 Benchmark. profile-url.<suffix> = URL of the profile, e.g. https://github.com/ComplianceAsCode/content/blob/master/products/ocp4/profiles/cis.profile. rule-to-parameters-map = map file for set-parameters, e.g. adjunct-data/task-files/rule2var.json. selected-rules = file with list of selected rules, e.g. adjunct-data/task-files/selected_rules.json. enabled-rules = file with list of enabled rules, e.g. adjunct-data/task-files/enabled_rules.json. Notes: 1 . If a control has selected rules but no enabled rules, then all those selected are included. 2 . If a control has selected and enabled rules, then only those enabled are included. 3 . If a control has no selected rules, then none are included regardless of enabled. Create data folders. ( venv.trestle ) $ mkdir -p adjunct-data/cis-benchmarks ( venv.trestle ) $ mkdir -p adjunct-data/config-files ( venv.trestle ) $ mkdir -p adjunct-data/task-files Fetch ComplianceAsCode data. ( venv.trestle ) $ cd adjunct-data/cis-benchmarks/ ( venv.trestle ) $ git clone https://github.com/ComplianceAsCode/content.git ( venv.trestle ) $ cd - Fetch trestle config and task files. ( venv.trestle ) $ curl 'https://raw.githubusercontent.com/IBM/compliance-trestle/main/docs/tutorials/task.ocp4-cis-profile-to-oscal-cd/demo-ocp4-cis-profile-to-oscal-cd.config' > adjunct-data/config-files/demo-ocp4-cis-profile-to-oscal-cd.config ( venv.trestle ) $ curl 'https://raw.githubusercontent.com/IBM/compliance-trestle/main/docs/tutorials/task.ocp4-cis-profile-to-oscal-cd/selected_rules.json' > adjunct-data/task-files/selected_rules.json ( venv.trestle ) $ curl 'https://raw.githubusercontent.com/IBM/compliance-trestle/main/docs/tutorials/task.ocp4-cis-profile-to-oscal-cd/enabled_rules.json' > adjunct-data/task-files/enabled_rules.json demo-ocp4-cis-profile-to-oscal-cd.config [ task.ocp4-cis-profile-to-oscal-cd ] component-name = OSCO folder-cac = adjunct-data/cis-benchmarks/content org-name = International Business Machines org-remarks = IBM output-dir = component-definitions/ocp4-cis profile-name = OCP4 CIS-benchmark v4 profile-mnemonic = ocp4-cis-node profile-ns = http://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud profile-version = 1 .1 profile-check-version = 0 .1.58 profile-type = OCP4 profile-list = cis-node cis profile-file.cis-node = ${ folder -cac } /products/ocp4/profiles/cis-node.profile profile-url.cis-node = https://github.com/ComplianceAsCode/content/blob/master/products/ocp4/profiles/cis-node.profile profile-title.cis-node = CIS Red Hat OpenShift Container Platform 4 Benchmark profile-file.cis = ${ folder -cac } /products/ocp4/profiles/cis.profile profile-url.cis = https://github.com/ComplianceAsCode/content/blob/master/products/ocp4/profiles/cis.profile profile-title.cis = CIS Red Hat OpenShift Container Platform 4 Benchmark selected-rules = adjunct-data/task-files/selected_rules.json enabled-rules = adjunct-data/task-files/enabled_rules.json selected_rules.json [ \"file_permissions_kube_apiserver\" , \"file_owner_kube_apiserver\" , \"file_groupowner_kube_apiserver\" ] enabled_rules.json [ \"file_permissions_cni_conf\" , \"file_permissions_multus_conf\" , \"file_owner_cni_conf\" , \"file_groupowner_cni_conf\" , \"file_owner_multus_conf\" , \"file_groupowner_multus_conf\" , \"kubelet_eviction_thresholds_set_soft_memory_available\" , \"kubelet_eviction_thresholds_set_soft_nodefs_available\" , \"kubelet_eviction_thresholds_set_soft_nodefs_inodesfree\" , \"kubelet_eviction_thresholds_set_soft_imagefs_available\" , \"kubelet_eviction_thresholds_set_soft_imagefs_inodesfree\" , \"kubelet_eviction_thresholds_set_hard_memory_available\" , \"kubelet_eviction_thresholds_set_hard_nodefs_available\" , \"kubelet_eviction_thresholds_set_hard_nodefs_inodesfree\" , \"kubelet_eviction_thresholds_set_hard_imagefs_available\" , \"kubelet_eviction_thresholds_set_hard_imagefs_inodesfree\" , \"etcd_unique_ca\" , \"file_permissions_kubelet_conf\" , \"file_groupowner_kubelet_conf\" , \"file_owner_kubelet_conf\" , \"file_permissions_worker_ca\" , \"file_owner_worker_ca\" , \"file_groupowner_worker_ca\" , \"kubelet_anonymous_auth\" , \"kubelet_configure_client_ca\" , \"kubelet_enable_streaming_connections\" , \"kubelet_enable_iptables_util_chains\" , \"kubelet_disable_hostname_override\" , \"kubelet_configure_event_creation\" , \"kubelet_configure_tls_cipher_suites\" ] Perform and validate the transform. ( venv.trestle ) $ trestle task ocp4-cis-profile-to-oscal-cd -c adjunct-data/config-files/demo-ocp4-cis-profile-to-oscal-cd.config output: component-definitions/ocp4-cis/component-definition.json Task: ocp4-cis-profile-to-oscal-cd executed successfully. ( venv.trestle ) $ trestle validate --all VALID: Model /home/<user>/trestle.workspace/component-definitions/ocp4-cis/component-definition.json passed the Validator to confirm the model passes all registered validation tests. View the generated OSCAL. ( venv.trestle ) $ cat component-definitions/ocp4-cis/component-definition.json component-definition.json { \"component-definition\" : { \"uuid\" : \"d1b961ee-188b-42b9-943d-e11dc260f9dc\" , \"metadata\" : { \"title\" : \"Component definition for OCP4 profiles\" , \"last-modified\" : \"2022-01-06T22:43:59+00:00\" , \"version\" : \"0.33.0\" , \"oscal-version\" : \"1.0.0\" , \"roles\" : [ { \"id\" : \"prepared-by\" , \"title\" : \"Indicates the organization that created this content.\" }, { \"id\" : \"prepared-for\" , \"title\" : \"Indicates the organization for which this content was created..\" }, { \"id\" : \"content-approver\" , \"title\" : \"Indicates the organization responsible for all content represented in the \\\"document\\\".\" } ], \"parties\" : [ { \"uuid\" : \"d00dff65-e4ae-4344-a206-1e298eff9066\" , \"type\" : \"organization\" , \"name\" : \"International Business Machines\" , \"remarks\" : \"IBM\" }, { \"uuid\" : \"851b55f0-5ba6-4684-8a48-5dad22ba2625\" , \"type\" : \"organization\" , \"name\" : \"Customer\" , \"remarks\" : \"organization to be customized at account creation only for their Component Definition\" }, { \"uuid\" : \"150f9eb7-7fa5-4989-b9be-bc3cba220354\" , \"type\" : \"organization\" , \"name\" : \"ISV\" , \"remarks\" : \"organization to be customized at ISV subscription only for their Component Definition\" } ], \"responsible-parties\" : [ { \"role-id\" : \"prepared-by\" , \"party-uuids\" : [ \"d00dff65-e4ae-4344-a206-1e298eff9066\" ] }, { \"role-id\" : \"prepared-for\" , \"party-uuids\" : [ \"851b55f0-5ba6-4684-8a48-5dad22ba2625\" , \"150f9eb7-7fa5-4989-b9be-bc3cba220354\" ] }, { \"role-id\" : \"content-approver\" , \"party-uuids\" : [ \"d00dff65-e4ae-4344-a206-1e298eff9066\" ] } ] }, \"components\" : [ { \"uuid\" : \"e2ee2b93-6103-42de-b615-65b0b3ff2dc4\" , \"type\" : \"Service\" , \"title\" : \"OSCO\" , \"description\" : \"OSCO\" , \"control-implementations\" : [ { \"uuid\" : \"f9c2699a-2d2c-4ee2-87f3-042d1a9b3a79\" , \"source\" : \"https://github.com/ComplianceAsCode/content/blob/master/products/ocp4/profiles/cis-node.profile\" , \"description\" : \"OSCO implemented controls for CIS Red Hat OpenShift Container Platform 4 Benchmark.\" , \"props\" : [ { \"name\" : \"profile_name\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud\" , \"value\" : \"OCP4 CIS-benchmark v4\" , \"class\" : \"scc_profile_name\" }, { \"name\" : \"profile_mnemonic\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud\" , \"value\" : \"ocp4-cis-node\" , \"class\" : \"scc_profile_mnemonic\" }, { \"name\" : \"profile_version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud\" , \"value\" : \"1.1\" , \"class\" : \"scc_profile_version\" }, { \"name\" : \"profile_check_version\" , \"value\" : \"0.1.58\" } ], \"implemented-requirements\" : [ { \"uuid\" : \"97142b13-bc30-4e72-be7f-36de9149a679\" , \"control-id\" : \"CIS-1.1.1\" , \"description\" : \"Ensure that the API server pod specification file permissions are set to 644 or more restrictive\" , \"props\" : [ { \"name\" : \"XCCDF_rule\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud\" , \"value\" : \"xccdf_org.ssgproject.content_rule_file_permissions_kube_apiserver\" , \"class\" : \"scc_goal_name_id\" , \"remarks\" : \"Verify Permissions on the Kubernetes API Server Pod Specification File\" } ], \"responsible-roles\" : [ { \"role-id\" : \"prepared-by\" , \"party-uuids\" : [ \"d00dff65-e4ae-4344-a206-1e298eff9066\" ] }, { \"role-id\" : \"prepared-for\" , \"party-uuids\" : [ \"851b55f0-5ba6-4684-8a48-5dad22ba2625\" , \"150f9eb7-7fa5-4989-b9be-bc3cba220354\" ] }, { \"role-id\" : \"content-approver\" , \"party-uuids\" : [ \"d00dff65-e4ae-4344-a206-1e298eff9066\" ] } ] }, { \"uuid\" : \"0690e2a7-b228-4954-93fe-c1d55936cfa8\" , \"control-id\" : \"CIS-1.1.2\" , \"description\" : \"Ensure that the API server pod specification file ownership is set to root:root\" , \"props\" : [ { \"name\" : \"XCCDF_rule\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud\" , \"value\" : \"xccdf_org.ssgproject.content_rule_file_owner_kube_apiserver\" , \"class\" : \"scc_goal_name_id\" , \"remarks\" : \"Verify User Who Owns The Kubernetes API Server Pod Specification File\" } ], \"responsible-roles\" : [ { \"role-id\" : \"prepared-by\" , \"party-uuids\" : [ \"d00dff65-e4ae-4344-a206-1e298eff9066\" ] }, { \"role-id\" : \"prepared-for\" , \"party-uuids\" : [ \"851b55f0-5ba6-4684-8a48-5dad22ba2625\" , \"150f9eb7-7fa5-4989-b9be-bc3cba220354\" ] }, { \"role-id\" : \"content-approver\" , \"party-uuids\" : [ \"d00dff65-e4ae-4344-a206-1e298eff9066\" ] } ] }, { \"uuid\" : \"18c61fb2-8603-440d-9d9a-8d6d1e232cd3\" , \"control-id\" : \"CIS-1.1.2\" , \"description\" : \"Ensure that the API server pod specification file ownership is set to root:root\" , \"props\" : [ { \"name\" : \"XCCDF_rule\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ibm-cloud\" , \"value\" : \"xccdf_org.ssgproject.content_rule_file_groupowner_kube_apiserver\" , \"class\" : \"scc_goal_name_id\" , \"remarks\" : \"Verify Group Who Owns The Kubernetes API Server Pod Specification File\" } ], \"responsible-roles\" : [ { \"role-id\" : \"prepared-by\" , \"party-uuids\" : [ \"d00dff65-e4ae-4344-a206-1e298eff9066\" ] }, { \"role-id\" : \"prepared-for\" , \"party-uuids\" : [ \"851b55f0-5ba6-4684-8a48-5dad22ba2625\" , \"150f9eb7-7fa5-4989-b9be-bc3cba220354\" ] }, { \"role-id\" : \"content-approver\" , \"party-uuids\" : [ \"d00dff65-e4ae-4344-a206-1e298eff9066\" ] } ] } ] } ] } ] } } Congratulations! You have completed this tutorial.","title":"Step 2: Transform profile data (CIS benchmarks)"},{"location":"tutorials/task.tanium-result-to-oscal-ar/transformation/","text":"Tutorial: Setup for and use of Tanium to OSCAL transformer \u00a4 Here are step by step instructions for setup and transformation of Tanium compliance data files into NIST standard OSCAL using the compliance-trestle tool. Objective \u00a4 How to transform a Tanium.results compliance file into a standardized OSCAL.json file. There are 2 short steps shown below. The first is a one-time check/set-up of your environment. The second is a one-command transformation from Tanium.results to OSCAL.json . Step 1: Environment setup \u00a4 Linux, Mac Windows Make these changes: use backslashes `\\` for file paths use `md` instead of mkdir -p put the url in double quotes for `curl` use `more` instead of cat Insure you have a modern Python (3.7, 3.8, 3.9). $ python -V Python 3 .8.3 Setup a virtual environment. $ cd $ python -m venv venv.trestle $ source venv.trestle/bin/activate ( venv.trestle ) $ Insure you have a modern pip (19.x or greater). ( venv.trestle ) $ pip --version pip 19 .2.3 from /home... Install compliance-trestle . ( venv.trestle ) $ pip install compliance-trestle Looking in indexes: https://pypi.org/simple,... Check trestle viability (and view help). ( venv.trestle ) $ trestle -h usage: trestle [ -h ] { init,create,split,merge,replicate,add,remove,validate,import,task,assemble } ... Create trestle workspace. ( venv.trestle ) $ mkdir trestle.workspace ( venv.trestle ) $ cd trestle.workspace ( venv.trestle ) $ trestle init Initialized trestle project successfully in /home/<user>/trestle.workspace Step 2: Transform sample \u00a4 Create Tanium data folders. ( venv.trestle ) $ mkdir -p tanium/tests/data/tasks/tanium/input Fetch sample Tanium data file. It is a \"raw\" Tanium result for which a transformation to OSCAL is desired. ( venv.trestle ) $ curl 'https://raw.githubusercontent.com/IBM/compliance-trestle/develop/tests/data/tasks/tanium/input-doc/Tanium.comply-nist-results' > tanium/tests/data/tasks/tanium/input/Tanium.doc-json sample: Tanium.doc-json { \"Computer Name\" : \"RHEL8\" , \"Tanium Client IP Address\" : \"192.168.0.125\" , \"IP Address\" : [ \"192.168.0.125\" , \"192.168.122.1\" , \"fe80::3c47:1aff:fe33:601\" ], \"Comply - Compliance Findings\" : [ { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" , \"State\" : \"fail\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" }, { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.1.3_Ensure_mounting_of_squashfs_filesystems_is_disabled\" , \"State\" : \"fail\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.3_Ensure_mounting_of_squashfs_filesystems_is_disabled\" }, { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.1.4_Ensure_mounting_of_udf_filesystems_is_disabled\" , \"State\" : \"fail\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.4_Ensure_mounting_of_udf_filesystems_is_disabled\" }, { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.10_Ensure_noexec_option_set_on_vartmp_partition\" , \"State\" : \"pass\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.10_Ensure_noexec_option_set_on_vartmp_partition\" }, { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.14_Ensure_nodev_option_set_on_home_partition\" , \"State\" : \"pass\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.14_Ensure_nodev_option_set_on_home_partition\" }, { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.15_Ensure_nodev_option_set_on_devshm_partition\" , \"State\" : \"pass\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.15_Ensure_nodev_option_set_on_devshm_partition\" }, { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.16_Ensure_nosuid_option_set_on_devshm_partition\" , \"State\" : \"pass\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.16_Ensure_nosuid_option_set_on_devshm_partition\" }, { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.17_Ensure_noexec_option_set_on_devshm_partition\" , \"State\" : \"fail\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.17_Ensure_noexec_option_set_on_devshm_partition\" }, { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.18_Ensure_nodev_option_set_on_removable_media_partitions\" , \"State\" : \"notchecked\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.18_Ensure_nodev_option_set_on_removable_media_partitions\" } ], \"Count\" : \"1\" } Fetch sample trestle tanium-result-to-oscal-ar config file. It informs the trestle command where to read input and write output. ( venv.trestle ) $ curl 'https://raw.githubusercontent.com/IBM/compliance-trestle/develop/tests/data/tasks/tanium/demo-tanium-result-to-oscal-ar.config' > tanium/demo-tanium-result-to-oscal-ar.config sample: demo-tanium-result-to-oscal-ar.config [task.tanium-result-to-oscal-ar] input-dir = tests/data/tasks/tanium/input output-dir = tests/data/tasks/tanium/runtime Perform the transform. ( venv.trestle ) $ cd tanium ( venv.trestle ) $ trestle task tanium-result-to-oscal-ar -c demo-tanium-result-to-oscal-ar.config input: tests/data/tasks/tanium/input/Tanium.doc-json output: tests/data/tasks/tanium/runtime/Tanium.oscal.json inventory: 1 observations: 9 Task: tanium-result-to-oscal-ar executed successfully. View the generated OSCAL. ( venv.trestle ) $ cat tests/data/tasks/tanium/runtime/Tanium.oscal.json sample: Tanium.oscal.json { \"results\" : [ { \"uuid\" : \"f79add8e-488a-45f3-9024-72ecf95c7952\" , \"title\" : \"Tanium\" , \"description\" : \"Tanium\" , \"start\" : \"2021-05-12T13:46:46.000+00:00\" , \"end\" : \"2021-05-12T13:46:46.000+00:00\" , \"local-definitions\" : { \"components\" : { \"1ea447fe-a2af-4110-baae-c70ed5223261\" : { \"type\" : \"Operating System\" , \"title\" : \"Red Hat Enterprise Linux 8\" , \"description\" : \"Red Hat Enterprise Linux 8\" , \"status\" : { \"state\" : \"operational\" } } }, \"inventory-items\" : [ { \"uuid\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"description\" : \"inventory\" , \"props\" : [ { \"name\" : \"Computer Name\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"RHEL8\" }, { \"name\" : \"Tanium Client IP Address\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"192.168.0.125\" , \"class\" : \"scc_inventory_item_id\" }, { \"name\" : \"IP Address\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"['192.168.0.125', '192.168.122.1', 'fe80::3c47:1aff:fe33:601']\" }, { \"name\" : \"Count\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1\" } ], \"implemented-components\" : [ { \"component-uuid\" : \"1ea447fe-a2af-4110-baae-c70ed5223261\" } ] } ] }, \"reviewed-controls\" : { \"control-selections\" : [ {} ] }, \"observations\" : [ { \"uuid\" : \"e67f5fd9-5b1f-4134-a67e-cebdc2e5735c\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"fail\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" }, { \"uuid\" : \"6cb81459-9c25-4a8b-bf3c-d8ff08ee728c\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.3_Ensure_mounting_of_squashfs_filesystems_is_disabled\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.1.3_Ensure_mounting_of_squashfs_filesystems_is_disabled\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.3_Ensure_mounting_of_squashfs_filesystems_is_disabled\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.3_Ensure_mounting_of_squashfs_filesystems_is_disabled\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"fail\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" }, { \"uuid\" : \"9453eaed-db41-4a20-b684-2887de2d9657\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.4_Ensure_mounting_of_udf_filesystems_is_disabled\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.1.4_Ensure_mounting_of_udf_filesystems_is_disabled\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.4_Ensure_mounting_of_udf_filesystems_is_disabled\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.4_Ensure_mounting_of_udf_filesystems_is_disabled\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"fail\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" }, { \"uuid\" : \"a37c2569-8695-4cfe-8b5c-bd8d6eaf9df7\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.10_Ensure_noexec_option_set_on_vartmp_partition\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.10_Ensure_noexec_option_set_on_vartmp_partition\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.10_Ensure_noexec_option_set_on_vartmp_partition\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.10_Ensure_noexec_option_set_on_vartmp_partition\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"pass\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" }, { \"uuid\" : \"b77e1b49-a818-4d43-adaf-69effcbd9219\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.14_Ensure_nodev_option_set_on_home_partition\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.14_Ensure_nodev_option_set_on_home_partition\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.14_Ensure_nodev_option_set_on_home_partition\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.14_Ensure_nodev_option_set_on_home_partition\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"pass\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" }, { \"uuid\" : \"ac25b329-7a4a-45f4-b42b-1cce470e237b\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.15_Ensure_nodev_option_set_on_devshm_partition\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.15_Ensure_nodev_option_set_on_devshm_partition\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.15_Ensure_nodev_option_set_on_devshm_partition\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.15_Ensure_nodev_option_set_on_devshm_partition\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"pass\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" }, { \"uuid\" : \"f9c0f033-f08b-431d-b411-fe1f63c2c98c\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.16_Ensure_nosuid_option_set_on_devshm_partition\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.16_Ensure_nosuid_option_set_on_devshm_partition\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.16_Ensure_nosuid_option_set_on_devshm_partition\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.16_Ensure_nosuid_option_set_on_devshm_partition\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"pass\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" }, { \"uuid\" : \"149a814e-7f80-4e6d-a613-54f027e0d663\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.17_Ensure_noexec_option_set_on_devshm_partition\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.17_Ensure_noexec_option_set_on_devshm_partition\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.17_Ensure_noexec_option_set_on_devshm_partition\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.17_Ensure_noexec_option_set_on_devshm_partition\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"fail\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" }, { \"uuid\" : \"a0e602b5-e587-41c5-846b-675b26cf3e18\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.18_Ensure_nodev_option_set_on_removable_media_partitions\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.18_Ensure_nodev_option_set_on_removable_media_partitions\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.18_Ensure_nodev_option_set_on_removable_media_partitions\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.18_Ensure_nodev_option_set_on_removable_media_partitions\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"notchecked\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" } ], \"findings\" : [ { \"uuid\" : \"00000000-0000-4000-8000-000000000000\" , \"title\" : \"No Finding.\" , \"description\" : \"No Finding.\" } ] } ] } Congratulations! You have bridged Tanium data into an OSCAL Assessment Results using compliance-trestle. Newtown, Victoria","title":"Task - tanium-result-to-oscal-ar"},{"location":"tutorials/task.tanium-result-to-oscal-ar/transformation/#tutorial-setup-for-and-use-of-tanium-to-oscal-transformer","text":"Here are step by step instructions for setup and transformation of Tanium compliance data files into NIST standard OSCAL using the compliance-trestle tool.","title":"Tutorial: Setup for and use of Tanium to OSCAL transformer"},{"location":"tutorials/task.tanium-result-to-oscal-ar/transformation/#objective","text":"How to transform a Tanium.results compliance file into a standardized OSCAL.json file. There are 2 short steps shown below. The first is a one-time check/set-up of your environment. The second is a one-command transformation from Tanium.results to OSCAL.json .","title":"Objective"},{"location":"tutorials/task.tanium-result-to-oscal-ar/transformation/#step-1-environment-setup","text":"Linux, Mac Windows Make these changes: use backslashes `\\` for file paths use `md` instead of mkdir -p put the url in double quotes for `curl` use `more` instead of cat Insure you have a modern Python (3.7, 3.8, 3.9). $ python -V Python 3 .8.3 Setup a virtual environment. $ cd $ python -m venv venv.trestle $ source venv.trestle/bin/activate ( venv.trestle ) $ Insure you have a modern pip (19.x or greater). ( venv.trestle ) $ pip --version pip 19 .2.3 from /home... Install compliance-trestle . ( venv.trestle ) $ pip install compliance-trestle Looking in indexes: https://pypi.org/simple,... Check trestle viability (and view help). ( venv.trestle ) $ trestle -h usage: trestle [ -h ] { init,create,split,merge,replicate,add,remove,validate,import,task,assemble } ... Create trestle workspace. ( venv.trestle ) $ mkdir trestle.workspace ( venv.trestle ) $ cd trestle.workspace ( venv.trestle ) $ trestle init Initialized trestle project successfully in /home/<user>/trestle.workspace","title":"Step 1: Environment setup"},{"location":"tutorials/task.tanium-result-to-oscal-ar/transformation/#step-2-transform-sample","text":"Create Tanium data folders. ( venv.trestle ) $ mkdir -p tanium/tests/data/tasks/tanium/input Fetch sample Tanium data file. It is a \"raw\" Tanium result for which a transformation to OSCAL is desired. ( venv.trestle ) $ curl 'https://raw.githubusercontent.com/IBM/compliance-trestle/develop/tests/data/tasks/tanium/input-doc/Tanium.comply-nist-results' > tanium/tests/data/tasks/tanium/input/Tanium.doc-json sample: Tanium.doc-json { \"Computer Name\" : \"RHEL8\" , \"Tanium Client IP Address\" : \"192.168.0.125\" , \"IP Address\" : [ \"192.168.0.125\" , \"192.168.122.1\" , \"fe80::3c47:1aff:fe33:601\" ], \"Comply - Compliance Findings\" : [ { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" , \"State\" : \"fail\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" }, { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.1.3_Ensure_mounting_of_squashfs_filesystems_is_disabled\" , \"State\" : \"fail\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.3_Ensure_mounting_of_squashfs_filesystems_is_disabled\" }, { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.1.4_Ensure_mounting_of_udf_filesystems_is_disabled\" , \"State\" : \"fail\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.4_Ensure_mounting_of_udf_filesystems_is_disabled\" }, { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.10_Ensure_noexec_option_set_on_vartmp_partition\" , \"State\" : \"pass\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.10_Ensure_noexec_option_set_on_vartmp_partition\" }, { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.14_Ensure_nodev_option_set_on_home_partition\" , \"State\" : \"pass\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.14_Ensure_nodev_option_set_on_home_partition\" }, { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.15_Ensure_nodev_option_set_on_devshm_partition\" , \"State\" : \"pass\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.15_Ensure_nodev_option_set_on_devshm_partition\" }, { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.16_Ensure_nosuid_option_set_on_devshm_partition\" , \"State\" : \"pass\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.16_Ensure_nosuid_option_set_on_devshm_partition\" }, { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.17_Ensure_noexec_option_set_on_devshm_partition\" , \"State\" : \"fail\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.17_Ensure_noexec_option_set_on_devshm_partition\" }, { \"Check ID\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.18_Ensure_nodev_option_set_on_removable_media_partitions\" , \"State\" : \"notchecked\" , \"Rule ID\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.18_Ensure_nodev_option_set_on_removable_media_partitions\" } ], \"Count\" : \"1\" } Fetch sample trestle tanium-result-to-oscal-ar config file. It informs the trestle command where to read input and write output. ( venv.trestle ) $ curl 'https://raw.githubusercontent.com/IBM/compliance-trestle/develop/tests/data/tasks/tanium/demo-tanium-result-to-oscal-ar.config' > tanium/demo-tanium-result-to-oscal-ar.config sample: demo-tanium-result-to-oscal-ar.config [task.tanium-result-to-oscal-ar] input-dir = tests/data/tasks/tanium/input output-dir = tests/data/tasks/tanium/runtime Perform the transform. ( venv.trestle ) $ cd tanium ( venv.trestle ) $ trestle task tanium-result-to-oscal-ar -c demo-tanium-result-to-oscal-ar.config input: tests/data/tasks/tanium/input/Tanium.doc-json output: tests/data/tasks/tanium/runtime/Tanium.oscal.json inventory: 1 observations: 9 Task: tanium-result-to-oscal-ar executed successfully. View the generated OSCAL. ( venv.trestle ) $ cat tests/data/tasks/tanium/runtime/Tanium.oscal.json sample: Tanium.oscal.json { \"results\" : [ { \"uuid\" : \"f79add8e-488a-45f3-9024-72ecf95c7952\" , \"title\" : \"Tanium\" , \"description\" : \"Tanium\" , \"start\" : \"2021-05-12T13:46:46.000+00:00\" , \"end\" : \"2021-05-12T13:46:46.000+00:00\" , \"local-definitions\" : { \"components\" : { \"1ea447fe-a2af-4110-baae-c70ed5223261\" : { \"type\" : \"Operating System\" , \"title\" : \"Red Hat Enterprise Linux 8\" , \"description\" : \"Red Hat Enterprise Linux 8\" , \"status\" : { \"state\" : \"operational\" } } }, \"inventory-items\" : [ { \"uuid\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"description\" : \"inventory\" , \"props\" : [ { \"name\" : \"Computer Name\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"RHEL8\" }, { \"name\" : \"Tanium Client IP Address\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"192.168.0.125\" , \"class\" : \"scc_inventory_item_id\" }, { \"name\" : \"IP Address\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"['192.168.0.125', '192.168.122.1', 'fe80::3c47:1aff:fe33:601']\" }, { \"name\" : \"Count\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1\" } ], \"implemented-components\" : [ { \"component-uuid\" : \"1ea447fe-a2af-4110-baae-c70ed5223261\" } ] } ] }, \"reviewed-controls\" : { \"control-selections\" : [ {} ] }, \"observations\" : [ { \"uuid\" : \"e67f5fd9-5b1f-4134-a67e-cebdc2e5735c\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.1_Ensure_mounting_of_cramfs_filesystems_is_disabled\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"fail\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" }, { \"uuid\" : \"6cb81459-9c25-4a8b-bf3c-d8ff08ee728c\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.3_Ensure_mounting_of_squashfs_filesystems_is_disabled\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.1.3_Ensure_mounting_of_squashfs_filesystems_is_disabled\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.3_Ensure_mounting_of_squashfs_filesystems_is_disabled\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.3_Ensure_mounting_of_squashfs_filesystems_is_disabled\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"fail\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" }, { \"uuid\" : \"9453eaed-db41-4a20-b684-2887de2d9657\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.4_Ensure_mounting_of_udf_filesystems_is_disabled\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.1.4_Ensure_mounting_of_udf_filesystems_is_disabled\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.4_Ensure_mounting_of_udf_filesystems_is_disabled\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1.4_Ensure_mounting_of_udf_filesystems_is_disabled\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"fail\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" }, { \"uuid\" : \"a37c2569-8695-4cfe-8b5c-bd8d6eaf9df7\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.10_Ensure_noexec_option_set_on_vartmp_partition\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.10_Ensure_noexec_option_set_on_vartmp_partition\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.10_Ensure_noexec_option_set_on_vartmp_partition\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.10_Ensure_noexec_option_set_on_vartmp_partition\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"pass\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" }, { \"uuid\" : \"b77e1b49-a818-4d43-adaf-69effcbd9219\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.14_Ensure_nodev_option_set_on_home_partition\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.14_Ensure_nodev_option_set_on_home_partition\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.14_Ensure_nodev_option_set_on_home_partition\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.14_Ensure_nodev_option_set_on_home_partition\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"pass\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" }, { \"uuid\" : \"ac25b329-7a4a-45f4-b42b-1cce470e237b\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.15_Ensure_nodev_option_set_on_devshm_partition\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.15_Ensure_nodev_option_set_on_devshm_partition\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.15_Ensure_nodev_option_set_on_devshm_partition\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.15_Ensure_nodev_option_set_on_devshm_partition\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"pass\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" }, { \"uuid\" : \"f9c0f033-f08b-431d-b411-fe1f63c2c98c\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.16_Ensure_nosuid_option_set_on_devshm_partition\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.16_Ensure_nosuid_option_set_on_devshm_partition\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.16_Ensure_nosuid_option_set_on_devshm_partition\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.16_Ensure_nosuid_option_set_on_devshm_partition\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"pass\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" }, { \"uuid\" : \"149a814e-7f80-4e6d-a613-54f027e0d663\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.17_Ensure_noexec_option_set_on_devshm_partition\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.17_Ensure_noexec_option_set_on_devshm_partition\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.17_Ensure_noexec_option_set_on_devshm_partition\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.17_Ensure_noexec_option_set_on_devshm_partition\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"fail\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" }, { \"uuid\" : \"a0e602b5-e587-41c5-846b-675b26cf3e18\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.18_Ensure_nodev_option_set_on_removable_media_partitions\" , \"props\" : [ { \"name\" : \"Check ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark;1.0.0-1;Level 1 - Server;1;xccdf_org.cisecurity.benchmarks_rule_1.1.18_Ensure_nodev_option_set_on_removable_media_partitions\" }, { \"name\" : \"Check ID Benchmark\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"CIS Red Hat Enterprise Linux 8 Benchmark\" , \"class\" : \"scc_predefined_profile\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_check_version\" }, { \"name\" : \"Check ID Version\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"1.0.0-1\" , \"class\" : \"scc_predefined_profile_version\" }, { \"name\" : \"Check ID Level\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"Level 1 - Server\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.18_Ensure_nodev_option_set_on_removable_media_partitions\" , \"class\" : \"scc_goal_description\" }, { \"name\" : \"Rule ID\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.18_Ensure_nodev_option_set_on_removable_media_partitions\" , \"class\" : \"scc_check_name_id\" }, { \"name\" : \"State\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"notchecked\" , \"class\" : \"scc_result\" }, { \"name\" : \"Timestamp\" , \"ns\" : \"https://ibm.github.io/compliance-trestle/schemas/oscal/ar/tanium\" , \"value\" : \"2021-05-12T13:46:46+00:00\" , \"class\" : \"scc_timestamp\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2d33d2b0-af5c-4c37-85b1-e4f414183de2\" , \"type\" : \"inventory-item\" } ], \"collected\" : \"2021-05-12T13:46:46.000+00:00\" } ], \"findings\" : [ { \"uuid\" : \"00000000-0000-4000-8000-000000000000\" , \"title\" : \"No Finding.\" , \"description\" : \"No Finding.\" } ] } ] } Congratulations! You have bridged Tanium data into an OSCAL Assessment Results using compliance-trestle. Newtown, Victoria","title":"Step 2: Transform sample"},{"location":"tutorials/task.transformer-construction/transformer-construction/","text":"Tutorial: How to build an Oscal Assessment Results \"lite\" with Trestle SDK from your posture result format \u00a4 The compliance-trestle (trestle) project provides helpful modules to assist your standardization efforts. Discussed below are some best practices for automated bridging to NIST OSCAL. Why NIST OSCAL? \u00a4 The Open Security Controls Assessment Language OSCAL is a set of formats expressed in XML, JSON, and YAML that provide machine-readable representations of control catalogs, control baselines, system security plans, and assessment plans and results as adopted by the National Institute of Standards and Technology NIST . Standardizing to OSCAL facilitates data interchange and understandability. Objective \u00a4 The objective here is to transform your compliance data into valid OSCAL, in particular System Assessment Results SAR . Examples of existing transformers included with trestle are for the OpenShift Compliance Operator OSCO and Tanium . Overview \u00a4 You have a source of compliance data that is in non-OSCAL format (spreadsheet, XML, JSON, database, object-store...) and you would like to transform into standardized form in terms of NIST OSCAL. Presumed is an existing method for obtaining the compliance data from the cloud and materializing on disk as one or more files. Source files on disk (pink) is our starting point. OSCAL files on disk (blue) is our ending point. OSCAL object management and emitter Python code are provided by trestle (green). Transformation Python code (yellow) is to be written by you. Other possible code stack configurations (not shown): write your own command module (file interface), but use trestle logic module (data processing) write your own command and logic modules, but rely on trestle OSCAL support and base For example, one could create an auditree-arboretum harvest report (file interface) that employs the trestle osco-result-to-oscal-ar transformation (data processing) module. Choose Mapping Strategy \u00a4 There are 3 potential levels of OSCAL Assessment Results that can be emitted by your transformer. From most complex to least complex they are: a complete SAR a partial SAR comprising Findings with Observations a partial SAR comprising Observations only Below is a snippet from the SAR model with these three levels shown. Although producing a complete SAR is possible, this transformation is not covered here. We focus on partial results, either Observations only or Observations with Findings. Based on the data in hand from your compliance data source, and additional metadata that can be made available at the time of transformation, choose the best fit. Observations only \u00a4 Emitting Observations only requires just rudimentary source data. For example, if each instance of source data includes not much more than: inventory-name: ssg-ocp4-ds-cis-111.222.333.444-pod rule-name: xccdf_org.ssgproject.content_rule_scheduler_profiling_argument rule-result: fail then the best mapping would be to an Observations only. example snippet: instance suitable for mapping to Observation data : <rule-result idref=\"xccdf_org.ssgproject.content_rule_scheduler_profiling_argument\" time=\"2020-08-03T02:26:26+00:00\" severity=\"low\" weight=\"1.000000\"> <result>fail</result> </rule-result> metadata : name : ssg-ocp4-ds-cis-111.222.333.444-pod example snippet: instance OSCAL Observation { \"uuid\" : \"56666738-0f9a-4e38-9aac-c0fad00a5821\" , \"title\" : \"xccdf_org.ssgproject.content_rule_scheduler_profiling_argument\" , \"description\" : \"xccdf_org.ssgproject.content_rule_scheduler_profiling_argument\" , \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"56666738-0f9a-4e38-9aac-c0fad00a5821\" , \"type\" : \"component\" , \"title\" : \"Red Hat OpenShift Kubernetes\" }, { \"uuid-ref\" : \"46aADFAC-A1fd-4Cf0-a6aA-d1AfAb3e0d3e\" , \"type\" : \"inventory-item\" , \"title\" : \"Pod\" , \"props\" : [ { \"name\" : \"target\" , \"value\" : \"kube-br7qsa3d0vceu2so1a90-roksopensca-default-0000026b.iks.mycorp\" }, { \"name\" : \"cluster-name\" , \"value\" : \"ROKS-OpenSCAP-1\" }, { \"name\" : \"cluster-type\" , \"value\" : \"openshift\" }, { \"name\" : \"cluster-region\" , \"value\" : \"us-south\" } ] } ], \"relevant-evidence\" : [ { \"href\" : \"https://github.mycorp.com/degenaro/evidence-locker\" , \"description\" : \"Evidence location.\" , \"props\" : [ { \"name\" : \"rule\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"id\" , \"value\" : \"xccdf_org.ssgproject.content_rule_scheduler_profiling_argument\" }, { \"name\" : \"time\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"timestamp\" , \"value\" : \"2020-08-03T02:26:26+00:00\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"result\" , \"value\" : \"fail\" }, { \"name\" : \"target\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"target\" , \"value\" : \"kube-br7qsa3d0vceu2so1a90-roksopensca-default-0000026b.iks.mycorp\" } ] } ] } Findings with Observations \u00a4 To additionally produce Findings, information about the controls associated with each rule-name is required. The control information can be part of the source data itself or can be provided as one or more supplemental metadata files. If each instance of source data includes: inventory-name: cmp-wn-2115.demo.tanium.local rule-name: xccdf_org.cisecurity.benchmarks_rule_19.7.44.2.1_L2_Ensure_Prevent_Codec_Download_is_set_to_Enabled rule-result: fail control-name: 800-53: SC-18 then the best mapping wound be to Findings with Observations. example snippet: xml instance suitable for mapping to Finding with Observation { \"IP Address\" : \"10.8.68.218\" , \"Computer Name\" : \"cmp-wn-2115.demo.tanium.local\" , \"Comply - JovalCM Results[c2dc8749]\" : [ { \"Benchmark\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"Benchmark Version\" : \"1.5.0.1\" , \"Profile\" : \"Windows 10 - NIST 800-53\" , \"ID\" : \"xccdf_org.cisecurity.benchmarks_rule_19.7.44.2.1_L2_Ensure_Prevent_Codec_Download_is_set_to_Enabled\" , \"Result\" : \"fail\" , \"Custom ID\" : \"800-53: SC-18\" , \"Version\" : \"version: 1\" } ], \"Count\" : \"1\" , \"Age\" : \"600\" } example snippet: instance OSCAL Finding { \"findings\" : [ { \"uuid\" : \"99c0a0de-e34e-4e22-95a1-1d4f24826565\" , \"title\" : \"800-53: IA-5\" , \"description\" : \"800-53: IA-5\" , \"collected\" : \"2021-03-16T13:29:14.000+00:00\" , \"objective-status\" : { \"props\" : [ { \"name\" : \"profile\" , \"ns\" : \"dns://tanium\" , \"class\" : \"source\" , \"value\" : \"NIST 800-53\" }, { \"name\" : \"id-ref\" , \"ns\" : \"dns://tanium\" , \"class\" : \"source\" , \"value\" : \"IA-5\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"STRVALUE\" , \"value\" : \"FAIL\" } ], \"status\" : \"not-satisfied\" }, \"related-observations\" : [ { \"observation-uuid\" : \"61092735-e365-4638-bc2c-ecd0ed407e73\" }, { \"observation-uuid\" : \"95a20b8e-ed0a-4b6c-bf87-8789265c7158\" } ] } ] } example snippet: instance OSCAL Observation { \"observations\" : [ { \"uuid\" : \"61092735-e365-4638-bc2c-ecd0ed407e73\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1_L1_Ensure_Enforce_password_history_is_set_to_24_or_more_passwords\" , \"props\" : [ { \"name\" : \"benchmark\" , \"ns\" : \"dns://tanium\" , \"class\" : \"source\" , \"value\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" }, { \"name\" : \"rule\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"id\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1_L1_Ensure_Enforce_password_history_is_set_to_24_or_more_passwords\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"result\" , \"value\" : \"pass\" }, { \"name\" : \"time\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"timestamp\" , \"value\" : \"2021-03-16T13:29:14+00:00\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2650b9ba-e767-4381-9a3f-127d1552d7d2\" , \"type\" : \"inventory-item\" } ] } ] } example snippet: local definitions { \"results\" : [ { \"uuid\" : \"98028241-8705-4211-bf36-71e1f7aa6192\" , \"title\" : \"Tanium\" , \"description\" : \"Tanium\" , \"start\" : \"2021-03-16T13:29:14.000+00:00\" , \"local-definitions\" : { \"inventory-items\" : [ { \"uuid\" : \"2650b9ba-e767-4381-9a3f-127d1552d7d2\" , \"description\" : \"inventory\" , \"props\" : [ { \"name\" : \"computer-name\" , \"ns\" : \"dns://tanium\" , \"class\" : \" inventory-item\" , \"value\" : \"cmp-wn-2106.demo.tanium.local\" }, { \"name\" : \"computer-ip\" , \"ns\" : \"dns://tanium\" , \"class\" : \" inventory-item\" , \"value\" : \"fe80::3cd5:564b:940e:49ab\" }, { \"name\" : \"profile\" , \"ns\" : \"dns://tanium\" , \"class\" : \" inventory-item\" , \"value\" : \"Windows 10\" } ] } ] } } ] } Implement Mapping Strategy \u00a4 The best practice for building a transformer is to employ layers. Recall that the top two layers (in yellow) are for you to implement, while the bottom two layers (in green) are provided by trestle to assist you. Trestle is a Python based multi-faceted platform that simplifies this task by providing a set of Python classes which enforce adherence to the OSCAL schema, insuring that the produced OSCAL validates. file interfacing (read/write files) data processing (in-memory object structure construction) use of OSCAL versioned platform objects (trestle base and oscal functionality) File Interfacing \u00a4 Write a command line tool, for example a trestle task or auditree-arboretum harvest report that: imports the commensurate data processing module reads the input send input to data processing module receives transformed data from data processing module writes the output Data Processing \u00a4 Write a data processing module that receives data, and optionally metadata, for transformation from native form into OSCAL. Separation from the command line file read/write mechanism allows for module re-use. The module should: import the trestle oscal module receive input data to be transformed receive metadata, optionally transform input into trestle oscal classes hierarchy send transformed OSCAL data in return For the Observation only case, the transform is straight forward. Code should create one Observation for each rule/result pair. For the Findings case, a bit more logic is required. Code should accumulate Observations for each Finding and determine an overall status for it. For example, if 15 Observations are found for Finding control AC-3, where 14 have result=PASS and 1 has result=FAIL, then the overall status for the Finding would be not satisfied with overall result=FAIL. Examples \u00a4 There are 2 transformers in trestle. The osco-result-to-oscal-ar transformer emits OSCAL Observations, the simplest partial result. The tanium-result-to-oscal-ar transformer emits OSCAL Findings, a more complex partial result. Table of approximate lines of code. task-name OSCAL type file interface data processing test cases osco-result-to-oscal-ar Observations only 275 350 400 tanum-to-oscal Findings, with Observations 200 350 300 Contributing \u00a4 Consider contributing your transformer to trestle or auditree-arboretum or other appropriate open source repository.","title":"Transformer construction"},{"location":"tutorials/task.transformer-construction/transformer-construction/#tutorial-how-to-build-an-oscal-assessment-results-lite-with-trestle-sdk-from-your-posture-result-format","text":"The compliance-trestle (trestle) project provides helpful modules to assist your standardization efforts. Discussed below are some best practices for automated bridging to NIST OSCAL.","title":"Tutorial: How to build an Oscal Assessment Results \"lite\" with Trestle SDK from your posture result format"},{"location":"tutorials/task.transformer-construction/transformer-construction/#why-nist-oscal","text":"The Open Security Controls Assessment Language OSCAL is a set of formats expressed in XML, JSON, and YAML that provide machine-readable representations of control catalogs, control baselines, system security plans, and assessment plans and results as adopted by the National Institute of Standards and Technology NIST . Standardizing to OSCAL facilitates data interchange and understandability.","title":"Why NIST OSCAL?"},{"location":"tutorials/task.transformer-construction/transformer-construction/#objective","text":"The objective here is to transform your compliance data into valid OSCAL, in particular System Assessment Results SAR . Examples of existing transformers included with trestle are for the OpenShift Compliance Operator OSCO and Tanium .","title":"Objective"},{"location":"tutorials/task.transformer-construction/transformer-construction/#overview","text":"You have a source of compliance data that is in non-OSCAL format (spreadsheet, XML, JSON, database, object-store...) and you would like to transform into standardized form in terms of NIST OSCAL. Presumed is an existing method for obtaining the compliance data from the cloud and materializing on disk as one or more files. Source files on disk (pink) is our starting point. OSCAL files on disk (blue) is our ending point. OSCAL object management and emitter Python code are provided by trestle (green). Transformation Python code (yellow) is to be written by you. Other possible code stack configurations (not shown): write your own command module (file interface), but use trestle logic module (data processing) write your own command and logic modules, but rely on trestle OSCAL support and base For example, one could create an auditree-arboretum harvest report (file interface) that employs the trestle osco-result-to-oscal-ar transformation (data processing) module.","title":"Overview"},{"location":"tutorials/task.transformer-construction/transformer-construction/#choose-mapping-strategy","text":"There are 3 potential levels of OSCAL Assessment Results that can be emitted by your transformer. From most complex to least complex they are: a complete SAR a partial SAR comprising Findings with Observations a partial SAR comprising Observations only Below is a snippet from the SAR model with these three levels shown. Although producing a complete SAR is possible, this transformation is not covered here. We focus on partial results, either Observations only or Observations with Findings. Based on the data in hand from your compliance data source, and additional metadata that can be made available at the time of transformation, choose the best fit.","title":"Choose Mapping Strategy"},{"location":"tutorials/task.transformer-construction/transformer-construction/#observations-only","text":"Emitting Observations only requires just rudimentary source data. For example, if each instance of source data includes not much more than: inventory-name: ssg-ocp4-ds-cis-111.222.333.444-pod rule-name: xccdf_org.ssgproject.content_rule_scheduler_profiling_argument rule-result: fail then the best mapping would be to an Observations only. example snippet: instance suitable for mapping to Observation data : <rule-result idref=\"xccdf_org.ssgproject.content_rule_scheduler_profiling_argument\" time=\"2020-08-03T02:26:26+00:00\" severity=\"low\" weight=\"1.000000\"> <result>fail</result> </rule-result> metadata : name : ssg-ocp4-ds-cis-111.222.333.444-pod example snippet: instance OSCAL Observation { \"uuid\" : \"56666738-0f9a-4e38-9aac-c0fad00a5821\" , \"title\" : \"xccdf_org.ssgproject.content_rule_scheduler_profiling_argument\" , \"description\" : \"xccdf_org.ssgproject.content_rule_scheduler_profiling_argument\" , \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"56666738-0f9a-4e38-9aac-c0fad00a5821\" , \"type\" : \"component\" , \"title\" : \"Red Hat OpenShift Kubernetes\" }, { \"uuid-ref\" : \"46aADFAC-A1fd-4Cf0-a6aA-d1AfAb3e0d3e\" , \"type\" : \"inventory-item\" , \"title\" : \"Pod\" , \"props\" : [ { \"name\" : \"target\" , \"value\" : \"kube-br7qsa3d0vceu2so1a90-roksopensca-default-0000026b.iks.mycorp\" }, { \"name\" : \"cluster-name\" , \"value\" : \"ROKS-OpenSCAP-1\" }, { \"name\" : \"cluster-type\" , \"value\" : \"openshift\" }, { \"name\" : \"cluster-region\" , \"value\" : \"us-south\" } ] } ], \"relevant-evidence\" : [ { \"href\" : \"https://github.mycorp.com/degenaro/evidence-locker\" , \"description\" : \"Evidence location.\" , \"props\" : [ { \"name\" : \"rule\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"id\" , \"value\" : \"xccdf_org.ssgproject.content_rule_scheduler_profiling_argument\" }, { \"name\" : \"time\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"timestamp\" , \"value\" : \"2020-08-03T02:26:26+00:00\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"result\" , \"value\" : \"fail\" }, { \"name\" : \"target\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"target\" , \"value\" : \"kube-br7qsa3d0vceu2so1a90-roksopensca-default-0000026b.iks.mycorp\" } ] } ] }","title":"Observations only"},{"location":"tutorials/task.transformer-construction/transformer-construction/#findings-with-observations","text":"To additionally produce Findings, information about the controls associated with each rule-name is required. The control information can be part of the source data itself or can be provided as one or more supplemental metadata files. If each instance of source data includes: inventory-name: cmp-wn-2115.demo.tanium.local rule-name: xccdf_org.cisecurity.benchmarks_rule_19.7.44.2.1_L2_Ensure_Prevent_Codec_Download_is_set_to_Enabled rule-result: fail control-name: 800-53: SC-18 then the best mapping wound be to Findings with Observations. example snippet: xml instance suitable for mapping to Finding with Observation { \"IP Address\" : \"10.8.68.218\" , \"Computer Name\" : \"cmp-wn-2115.demo.tanium.local\" , \"Comply - JovalCM Results[c2dc8749]\" : [ { \"Benchmark\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" , \"Benchmark Version\" : \"1.5.0.1\" , \"Profile\" : \"Windows 10 - NIST 800-53\" , \"ID\" : \"xccdf_org.cisecurity.benchmarks_rule_19.7.44.2.1_L2_Ensure_Prevent_Codec_Download_is_set_to_Enabled\" , \"Result\" : \"fail\" , \"Custom ID\" : \"800-53: SC-18\" , \"Version\" : \"version: 1\" } ], \"Count\" : \"1\" , \"Age\" : \"600\" } example snippet: instance OSCAL Finding { \"findings\" : [ { \"uuid\" : \"99c0a0de-e34e-4e22-95a1-1d4f24826565\" , \"title\" : \"800-53: IA-5\" , \"description\" : \"800-53: IA-5\" , \"collected\" : \"2021-03-16T13:29:14.000+00:00\" , \"objective-status\" : { \"props\" : [ { \"name\" : \"profile\" , \"ns\" : \"dns://tanium\" , \"class\" : \"source\" , \"value\" : \"NIST 800-53\" }, { \"name\" : \"id-ref\" , \"ns\" : \"dns://tanium\" , \"class\" : \"source\" , \"value\" : \"IA-5\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"STRVALUE\" , \"value\" : \"FAIL\" } ], \"status\" : \"not-satisfied\" }, \"related-observations\" : [ { \"observation-uuid\" : \"61092735-e365-4638-bc2c-ecd0ed407e73\" }, { \"observation-uuid\" : \"95a20b8e-ed0a-4b6c-bf87-8789265c7158\" } ] } ] } example snippet: instance OSCAL Observation { \"observations\" : [ { \"uuid\" : \"61092735-e365-4638-bc2c-ecd0ed407e73\" , \"description\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1_L1_Ensure_Enforce_password_history_is_set_to_24_or_more_passwords\" , \"props\" : [ { \"name\" : \"benchmark\" , \"ns\" : \"dns://tanium\" , \"class\" : \"source\" , \"value\" : \"CIS Microsoft Windows 10 Enterprise Release 1803 Benchmark\" }, { \"name\" : \"rule\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"id\" , \"value\" : \"xccdf_org.cisecurity.benchmarks_rule_1.1.1_L1_Ensure_Enforce_password_history_is_set_to_24_or_more_passwords\" }, { \"name\" : \"result\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"result\" , \"value\" : \"pass\" }, { \"name\" : \"time\" , \"ns\" : \"dns://xccdf\" , \"class\" : \"timestamp\" , \"value\" : \"2021-03-16T13:29:14+00:00\" } ], \"methods\" : [ \"TEST-AUTOMATED\" ], \"subjects\" : [ { \"uuid-ref\" : \"2650b9ba-e767-4381-9a3f-127d1552d7d2\" , \"type\" : \"inventory-item\" } ] } ] } example snippet: local definitions { \"results\" : [ { \"uuid\" : \"98028241-8705-4211-bf36-71e1f7aa6192\" , \"title\" : \"Tanium\" , \"description\" : \"Tanium\" , \"start\" : \"2021-03-16T13:29:14.000+00:00\" , \"local-definitions\" : { \"inventory-items\" : [ { \"uuid\" : \"2650b9ba-e767-4381-9a3f-127d1552d7d2\" , \"description\" : \"inventory\" , \"props\" : [ { \"name\" : \"computer-name\" , \"ns\" : \"dns://tanium\" , \"class\" : \" inventory-item\" , \"value\" : \"cmp-wn-2106.demo.tanium.local\" }, { \"name\" : \"computer-ip\" , \"ns\" : \"dns://tanium\" , \"class\" : \" inventory-item\" , \"value\" : \"fe80::3cd5:564b:940e:49ab\" }, { \"name\" : \"profile\" , \"ns\" : \"dns://tanium\" , \"class\" : \" inventory-item\" , \"value\" : \"Windows 10\" } ] } ] } } ] }","title":"Findings with Observations"},{"location":"tutorials/task.transformer-construction/transformer-construction/#implement-mapping-strategy","text":"The best practice for building a transformer is to employ layers. Recall that the top two layers (in yellow) are for you to implement, while the bottom two layers (in green) are provided by trestle to assist you. Trestle is a Python based multi-faceted platform that simplifies this task by providing a set of Python classes which enforce adherence to the OSCAL schema, insuring that the produced OSCAL validates. file interfacing (read/write files) data processing (in-memory object structure construction) use of OSCAL versioned platform objects (trestle base and oscal functionality)","title":"Implement Mapping Strategy"},{"location":"tutorials/task.transformer-construction/transformer-construction/#file-interfacing","text":"Write a command line tool, for example a trestle task or auditree-arboretum harvest report that: imports the commensurate data processing module reads the input send input to data processing module receives transformed data from data processing module writes the output","title":"File Interfacing"},{"location":"tutorials/task.transformer-construction/transformer-construction/#data-processing","text":"Write a data processing module that receives data, and optionally metadata, for transformation from native form into OSCAL. Separation from the command line file read/write mechanism allows for module re-use. The module should: import the trestle oscal module receive input data to be transformed receive metadata, optionally transform input into trestle oscal classes hierarchy send transformed OSCAL data in return For the Observation only case, the transform is straight forward. Code should create one Observation for each rule/result pair. For the Findings case, a bit more logic is required. Code should accumulate Observations for each Finding and determine an overall status for it. For example, if 15 Observations are found for Finding control AC-3, where 14 have result=PASS and 1 has result=FAIL, then the overall status for the Finding would be not satisfied with overall result=FAIL.","title":"Data Processing"},{"location":"tutorials/task.transformer-construction/transformer-construction/#examples","text":"There are 2 transformers in trestle. The osco-result-to-oscal-ar transformer emits OSCAL Observations, the simplest partial result. The tanium-result-to-oscal-ar transformer emits OSCAL Findings, a more complex partial result. Table of approximate lines of code. task-name OSCAL type file interface data processing test cases osco-result-to-oscal-ar Observations only 275 350 400 tanum-to-oscal Findings, with Observations 200 350 300","title":"Examples"},{"location":"tutorials/task.transformer-construction/transformer-construction/#contributing","text":"Consider contributing your transformer to trestle or auditree-arboretum or other appropriate open source repository.","title":"Contributing"}]}